<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-715 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-715</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-715</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-20.html">extraction-schema-20</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <p><strong>Paper ID:</strong> paper-255440525</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2301.01817v1.pdf" target="_blank">Evaluation of Induced Expert Knowledge in Causal Structure Learning by NOTEARS</a></p>
                <p><strong>Paper Abstract:</strong> Causal modeling provides us with powerful counterfactual reasoning and interventional mechanism to generate predictions and reason under various what-if scenarios. However, causal discovery using observation data remains a nontrivial task due to unobserved confounding factors, finite sampling, and changes in the data distribution. These can lead to spurious cause-effect relationships. To mitigate these challenges in practice, researchers augment causal learning with known causal relations. The goal of the paper is to study the impact of expert knowledge on causal relations in the form of additional constraints used in the formulation of the nonparametric NOTEARS. We provide a comprehensive set of comparative analyses of biasing the model using different types of knowledge. We found that (i) knowledge that corrects the mistakes of the NOTEARS model can lead to statistically significant improvements, (ii) constraints on active edges have a larger positive impact on causal discovery than inactive edges, and surprisingly, (iii) the induced knowledge does not correct on average more incorrect active and/or inactive edges than expected. We also demonstrate the behavior of the model and the effectiveness of domain knowledge on a real-world dataset.</p>
                <p><strong>Cost:</strong> 0.016</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e715.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e715.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>NOTEARS</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>DAGs with NO TEARS (NOTEARS)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A score-based continuous optimization method that reformulates DAG structure learning as a smooth constrained optimization by encoding acyclicity via a trace-exponential function on the weighted adjacency matrix, enabling gradient-based learning of graphs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>DAGs with no tears: Continuous optimization for structure learning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>NOTEARS (Zheng et al., 2018)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Represents the directed graph as a weighted adjacency matrix W and casts structure recovery as minimizing a data-fit loss L(W) subject to a smooth algebraic acyclicity constraint h(W)=tr(e^{W•W})-d=0, turning an NP-hard combinatorial search into a continuous constrained optimization solved with gradient-based methods and augmented Lagrangian techniques; uses weight thresholding post-optimization to prune small edges.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Observational simulation datasets (ER/SF graphs) and real biological dataset (Sachs et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Non-interactive observational data experiments used in this paper: synthetic nonlinear index-model data generated from Erdos-Renyi and scale-free random DAGs with varying node counts and sample sizes, plus the Sachs single-cell protein-signaling dataset; not an interactive/virtual lab environment nor actively selecting interventions.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Addresses spurious edges arising from finite sampling and model misspecification indirectly via regularization and thresholding; not explicitly designed for latent confounding or selection bias.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Uses L1 regularization (sparsity) on network parameters and post-hoc thresholding of small edge weights to reduce false discoveries.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td>Baseline NOTEARS-MLP (no induced expert constraints) as used in experiments; paper reports deltas relative to this baseline when knowledge is added.</td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>NOTEARS provides the continuous optimization backbone used throughout the paper; its sparsity regularization and thresholding are leveraged to reduce false discoveries but it does not, by itself, incorporate explicit mechanisms for detecting or refuting distractor variables other than through regularization and pruning.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e715.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e715.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Nonparametric-NOTEARS / NOTEARS-MLP</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Learning sparse nonparametric DAGs (NOTEARS-MLP)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A nonparametric extension of NOTEARS that models each structural equation with an MLP and defines adjacency via column norms of first-layer weights, enabling nonlinear causal mechanism learning within the continuous NOTEARS framework.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Learning sparse nonparametric DAGs</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>NOTEARS-MLP (nonparametric NOTEARS)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Replaces linear SEMs with neural-network function approximators f_j (MLPs) and defines W_{ij} as the norm of the i-th input column of the first layer of the j-th MLP; the acyclicity constraint is applied to W(θ) and optimization is performed with augmented Lagrangian and gradient descent, with L1 regularization on θ to promote sparsity.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Same observational datasets as above (synthetic ER/SF simulations and Sachs real dataset)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Non-interactive observational datasets; experiments simulate identifiable nonlinear models and evaluate structural recovery; no active experimentation.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Aims to reduce spurious cause-effect identification due to finite samples or functional misspecification by using flexible nonlinear models plus sparsity regularization and thresholding.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>L1 regularization on network parameters and thresholding of small edge weights to prune likely spurious edges.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td>Baseline NOTEARS-MLP without induced expert constraints used as reference in all delta performance numbers reported in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>NOTEARS-MLP is the estimator used throughout the experiments; its nonparametric capacity allows better modelling of nonlinear causal mechanisms, and when combined with expert constraints it yields statistically significant improvements on FDR/TPR/FPR/SHD compared to the unconstrained baseline.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e715.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e715.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Knowledge-Augmented NOTEARS</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Knowledge-augmented nonparametric NOTEARS (this paper)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>This paper's main contribution: extends NOTEARS-MLP to accept expert causal knowledge as equality/inequality constraints (known inactive/active edges), incorporated into the augmented Lagrangian objective with slack variables and threshold-aware constraint formulation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Knowledge-augmented NOTEARS-MLP (equality/inequality constraints on W(θ))</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Encodes expert knowledge as (i) equality constraints for known-inactive edges (enforce weight ≈ 0) and (ii) inequality constraints for known-active edges (enforce weight above a threshold); transforms inequalities to equalities with slack variables and incorporates these penalties into the augmented Lagrangian objective (additional ρ and α multipliers) alongside the acyclicity penalty and L1 regularization, then re-optimizes the network parameters; uses thresholding to map continuous weights to discrete edges.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Observational synthetic simulations (ER/SF) and Sachs real dataset</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Sequential, offline human-in-the-loop simulation: constraints are induced iteratively based on model mistakes (or redundant/correctly classified edges), but the environment remains observational (no active interventions); the process mimics iterative expert feedback rather than autonomous experimentation.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Explicit constraint incorporation from expert knowledge (known inactive edges to forbid spurious edges; known active edges to force true edges), combined with L1 regularization and post-optimization thresholding to prune spurious small-weight edges.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Targets spurious cause-effect relationships (false positive edges) arising from finite sampling, model mis-specification, and other observational limitations; implicitly mitigates false discoveries (irrelevant variables/edges) but does not provide explicit latent-confounder correction.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>In experiments, detection of spurious signals is performed by identifying misclassified edges in the model's predicted graph (comparison to ground truth) or via expert inspection; these misclassified edges are chosen as candidate constraints to correct spurious relationships.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Downweights spurious edges via L1 regularization on network parameters, threshold-based pruning of small edge weights, and enforcing equality constraints (set weight≈0) for known inactive edges to remove their influence.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Refutation is operationalized by adding constraints that contradict previously estimated edges (forcing W_{ij}=0 or W_{ij}≥threshold) and re-optimizing; improvement or lack thereof is used as empirical evidence that a previously inferred edge was spurious. No formal interventional/refutation tests (do-interventions) are used.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td>Sequential human-in-the-loop correction: at each step, one (or a batch of) misclassified edge(s) identified from the predicted graph are converted into constraints and the model is re-trained; this is an iterative corrective strategy rather than experimental active learning.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>When induced knowledge corrects model mistakes, statistically significant improvements are observed: e.g., for one added correcting constraint (∆=1) -- ∆FDR: inactive -0.018±0.002 (significant), active -0.008±0.001 (significant); ∆TPR: active +0.024±0.003 (significant), inactive -0.007±0.003 (not significant); ∆FPR: inactive -0.023±0.004 (significant), active -0.008±0.003 (significant); ∆SHD: inactive -0.032±0.012, active -0.071±0.011 (both significant). Real-data (Sachs) showed ∆TPR 0.020±0.004 and reductions in reversed-edge rate.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td>Baseline NOTEARS-MLP with no induced expert constraints; inducing redundant (already-correct) knowledge produced near-zero changes (e.g., ∆FDR ≈ -0.00030±0.00017), indicating no harm but little benefit for redundant constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Incorporating expert constraints (especially known-active edges) reliably reduces false discoveries and SHD and increases TPR when the induced knowledge corrects model mistakes; redundant constraints do no harm; constraints on active edges are more informative than inactive ones because they remove more degrees of freedom and more strongly shape the feasible graph space. The method does not actively detect latent confounders nor perform interventional refutations; detection of spurious signals relies on known ground truth or expert identification of misclassifications.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e715.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e715.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Edge Thresholding / Pruning</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Post-optimization edge thresholding (pruning) in NOTEARS</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A simple post-processing step that sets to zero any learned adjacency weight whose magnitude falls below a chosen threshold to reduce false positive edges.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>DAGs with no tears: Continuous optimization for structure learning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Edge weight thresholding (pruning)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>After continuous optimization, apply a threshold w_thresh and prune edges with |w_{ij}| < w_thresh; in the constrained formulation, thresholds are incorporated when converting constraints (e.g., equality constraints become approximate equalities allowing for small weights) and slack variables accommodate the threshold-aware constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Same observational simulation and real datasets</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Applied as a deterministic post-processing step on models learned from observational datasets; not interactive.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Removes small-magnitude learned edges that are likely spurious (irrelevant variables/false positives) by threshold pruning.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Irrelevant variables and small spurious edges resulting from sampling noise or overfitting.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Implicit detection by magnitude: edges below threshold deemed spurious.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Hard zeroing of small weights (pruning); indirectly downweights by L1 during training so combined effect shrinks such weights.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>Contributes to reduced FDR and FPR in the experiments when combined with induced constraints and L1 regularization; specific deltas reported for combined methods are in the knowledge-augmented NOTEARS entry.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Thresholding is a practical, low-cost mechanism for reducing false positives; it is used in the paper both as a standalone pruning mechanism and to shape how equality/inequality constraints are operationalized with slack variables.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e715.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e715.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>L1 Regularization (sparsity)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>L1 parameter regularization for sparse DAG learning</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Sparsity-inducing L1 penalty on network parameters (or derived edge weights) to favor sparse graph solutions and reduce spurious edges.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>L1 regularization on network parameters</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Adds λ||θ||_1 to the optimization objective to penalize large numbers of nonzero parameters, encouraging columns of the first-layer weights to shrink to zero and thus reducing inferred dependencies (edges) between variables; combined with augmented Lagrangian penalties and thresholding.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Observational synthetic and real datasets used in experiments</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Applied as part of the optimization objective during training on observational datasets; not an active or interactive mechanism.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Promotes sparsity to downweight and eliminate spurious edges introduced by noise or overfitting.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Spurious/weak dependencies, false positives due to finite sampling and model expressivity.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Penalizes edge-supporting parameters to shrink weak edges toward zero; used jointly with thresholding to remove them.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>Contributes to overall improvements reported when combined with constraints; high regularization can, however, hurt TPR by removing true active edges (noted in the paper).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>L1 regularization is an important component to control false discoveries but must be tuned carefully because overly strong sparsity can remove true causal edges.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e715.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e715.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Sequential knowledge induction (human-in-the-loop)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Iterative expert-constraint induction for causal structure learning</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An interactive, sequential process where experts (or ground-truth comparisons) supply constraints correcting model mistakes, which are added iteratively and the model is re-optimized to improve learned causal structure.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Sequential knowledge induction (iterative constraint addition)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Start from baseline predicted graph, identify misclassified edges (via expert inspection or comparison to known ground truth), convert a selected misclassification into a constraint (known active or inactive), add it to the constraint set, re-run the constrained NOTEARS-MLP optimization, and iterate; can add one or a batch of corrections per iteration and compute expected vs empirical improvements.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Offline iterative loop over observational datasets (simulations and Sachs)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>A human-in-the-loop offline corrective process rather than an online experimental/virtual-lab intervention strategy; environment remains observational data; the loop simulates domain expert feedback.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Detects candidate spurious edges by locating model misclassifications and uses hard constraints to remove (known-inactive) or enforce (known-active) edges, thereby directly eliminating or validating suspected spurious relationships.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>False positive edges (spurious cause-effect links) identified by experts or ground-truth comparison; indirectly mitigates errors due to sampling and functional misspecification.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Identify misclassified edges in the predicted graph (comparison to ground truth or expert labels) and select them as candidates for induction.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Converted misclassified-inactive edges become equality constraints (W_{ij}=0) or inequality constraints with slack, which effectively zero-out or force stronger weights away from spurious values; combined with L1 and thresholding.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Empirical refutation by contradiction: imposing a constraint that contradicts a previously inferred edge and observing whether re-optimization removes the edge and improves global metrics; no interventional testing is performed.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td>Greedy/random selection of one misclassified edge at each iteration (the paper used random selection among model mistakes) to study per-constraint contribution; can be extended to batch corrections.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>Sequentially adding correcting constraints yields statistically significant metric improvements: e.g., single-correction deltas reported (see Knowledge-Augmented NOTEARS entry) with larger gains for active-edge constraints on SHD and TPR.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td>Baseline (no iterative constraints) NOTEARS-MLP; adding redundant (already-correct) knowledge generated negligible change (sanity-check), while correcting knowledge produced meaningful improvements.</td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Interactive sequential induction of expert constraints is an effective strategy to reduce spurious edges and improve graph recovery, especially when constraints correct genuine model mistakes; random selection of corrections allowed estimation of per-constraint effect, and redundant constraints had no harmful effect.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>DAGs with no tears: Continuous optimization for structure learning <em>(Rating: 2)</em></li>
                <li>Learning sparse nonparametric DAGs <em>(Rating: 2)</em></li>
                <li>Dags with no fears: A closer look at continuous optimization for learning bayesian networks <em>(Rating: 2)</em></li>
                <li>Masked gradient-based causal structure learning <em>(Rating: 1)</em></li>
                <li>Low rank directed acyclic graphs and causal structure learning <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-715",
    "paper_id": "paper-255440525",
    "extraction_schema_id": "extraction-schema-20",
    "extracted_data": [
        {
            "name_short": "NOTEARS",
            "name_full": "DAGs with NO TEARS (NOTEARS)",
            "brief_description": "A score-based continuous optimization method that reformulates DAG structure learning as a smooth constrained optimization by encoding acyclicity via a trace-exponential function on the weighted adjacency matrix, enabling gradient-based learning of graphs.",
            "citation_title": "DAGs with no tears: Continuous optimization for structure learning",
            "mention_or_use": "use",
            "method_name": "NOTEARS (Zheng et al., 2018)",
            "method_description": "Represents the directed graph as a weighted adjacency matrix W and casts structure recovery as minimizing a data-fit loss L(W) subject to a smooth algebraic acyclicity constraint h(W)=tr(e^{W•W})-d=0, turning an NP-hard combinatorial search into a continuous constrained optimization solved with gradient-based methods and augmented Lagrangian techniques; uses weight thresholding post-optimization to prune small edges.",
            "environment_name": "Observational simulation datasets (ER/SF graphs) and real biological dataset (Sachs et al.)",
            "environment_description": "Non-interactive observational data experiments used in this paper: synthetic nonlinear index-model data generated from Erdos-Renyi and scale-free random DAGs with varying node counts and sample sizes, plus the Sachs single-cell protein-signaling dataset; not an interactive/virtual lab environment nor actively selecting interventions.",
            "handles_distractors": null,
            "distractor_handling_technique": null,
            "spurious_signal_types": "Addresses spurious edges arising from finite sampling and model misspecification indirectly via regularization and thresholding; not explicitly designed for latent confounding or selection bias.",
            "detection_method": null,
            "downweighting_method": "Uses L1 regularization (sparsity) on network parameters and post-hoc thresholding of small edge weights to reduce false discoveries.",
            "refutation_method": null,
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": null,
            "performance_without_robustness": "Baseline NOTEARS-MLP (no induced expert constraints) as used in experiments; paper reports deltas relative to this baseline when knowledge is added.",
            "has_ablation_study": true,
            "number_of_distractors": null,
            "key_findings": "NOTEARS provides the continuous optimization backbone used throughout the paper; its sparsity regularization and thresholding are leveraged to reduce false discoveries but it does not, by itself, incorporate explicit mechanisms for detecting or refuting distractor variables other than through regularization and pruning.",
            "uuid": "e715.0"
        },
        {
            "name_short": "Nonparametric-NOTEARS / NOTEARS-MLP",
            "name_full": "Learning sparse nonparametric DAGs (NOTEARS-MLP)",
            "brief_description": "A nonparametric extension of NOTEARS that models each structural equation with an MLP and defines adjacency via column norms of first-layer weights, enabling nonlinear causal mechanism learning within the continuous NOTEARS framework.",
            "citation_title": "Learning sparse nonparametric DAGs",
            "mention_or_use": "use",
            "method_name": "NOTEARS-MLP (nonparametric NOTEARS)",
            "method_description": "Replaces linear SEMs with neural-network function approximators f_j (MLPs) and defines W_{ij} as the norm of the i-th input column of the first layer of the j-th MLP; the acyclicity constraint is applied to W(θ) and optimization is performed with augmented Lagrangian and gradient descent, with L1 regularization on θ to promote sparsity.",
            "environment_name": "Same observational datasets as above (synthetic ER/SF simulations and Sachs real dataset)",
            "environment_description": "Non-interactive observational datasets; experiments simulate identifiable nonlinear models and evaluate structural recovery; no active experimentation.",
            "handles_distractors": null,
            "distractor_handling_technique": null,
            "spurious_signal_types": "Aims to reduce spurious cause-effect identification due to finite samples or functional misspecification by using flexible nonlinear models plus sparsity regularization and thresholding.",
            "detection_method": null,
            "downweighting_method": "L1 regularization on network parameters and thresholding of small edge weights to prune likely spurious edges.",
            "refutation_method": null,
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": null,
            "performance_without_robustness": "Baseline NOTEARS-MLP without induced expert constraints used as reference in all delta performance numbers reported in the paper.",
            "has_ablation_study": true,
            "number_of_distractors": null,
            "key_findings": "NOTEARS-MLP is the estimator used throughout the experiments; its nonparametric capacity allows better modelling of nonlinear causal mechanisms, and when combined with expert constraints it yields statistically significant improvements on FDR/TPR/FPR/SHD compared to the unconstrained baseline.",
            "uuid": "e715.1"
        },
        {
            "name_short": "Knowledge-Augmented NOTEARS",
            "name_full": "Knowledge-augmented nonparametric NOTEARS (this paper)",
            "brief_description": "This paper's main contribution: extends NOTEARS-MLP to accept expert causal knowledge as equality/inequality constraints (known inactive/active edges), incorporated into the augmented Lagrangian objective with slack variables and threshold-aware constraint formulation.",
            "citation_title": "here",
            "mention_or_use": "use",
            "method_name": "Knowledge-augmented NOTEARS-MLP (equality/inequality constraints on W(θ))",
            "method_description": "Encodes expert knowledge as (i) equality constraints for known-inactive edges (enforce weight ≈ 0) and (ii) inequality constraints for known-active edges (enforce weight above a threshold); transforms inequalities to equalities with slack variables and incorporates these penalties into the augmented Lagrangian objective (additional ρ and α multipliers) alongside the acyclicity penalty and L1 regularization, then re-optimizes the network parameters; uses thresholding to map continuous weights to discrete edges.",
            "environment_name": "Observational synthetic simulations (ER/SF) and Sachs real dataset",
            "environment_description": "Sequential, offline human-in-the-loop simulation: constraints are induced iteratively based on model mistakes (or redundant/correctly classified edges), but the environment remains observational (no active interventions); the process mimics iterative expert feedback rather than autonomous experimentation.",
            "handles_distractors": true,
            "distractor_handling_technique": "Explicit constraint incorporation from expert knowledge (known inactive edges to forbid spurious edges; known active edges to force true edges), combined with L1 regularization and post-optimization thresholding to prune spurious small-weight edges.",
            "spurious_signal_types": "Targets spurious cause-effect relationships (false positive edges) arising from finite sampling, model mis-specification, and other observational limitations; implicitly mitigates false discoveries (irrelevant variables/edges) but does not provide explicit latent-confounder correction.",
            "detection_method": "In experiments, detection of spurious signals is performed by identifying misclassified edges in the model's predicted graph (comparison to ground truth) or via expert inspection; these misclassified edges are chosen as candidate constraints to correct spurious relationships.",
            "downweighting_method": "Downweights spurious edges via L1 regularization on network parameters, threshold-based pruning of small edge weights, and enforcing equality constraints (set weight≈0) for known inactive edges to remove their influence.",
            "refutation_method": "Refutation is operationalized by adding constraints that contradict previously estimated edges (forcing W_{ij}=0 or W_{ij}≥threshold) and re-optimizing; improvement or lack thereof is used as empirical evidence that a previously inferred edge was spurious. No formal interventional/refutation tests (do-interventions) are used.",
            "uses_active_learning": false,
            "inquiry_strategy": "Sequential human-in-the-loop correction: at each step, one (or a batch of) misclassified edge(s) identified from the predicted graph are converted into constraints and the model is re-trained; this is an iterative corrective strategy rather than experimental active learning.",
            "performance_with_robustness": "When induced knowledge corrects model mistakes, statistically significant improvements are observed: e.g., for one added correcting constraint (∆=1) -- ∆FDR: inactive -0.018±0.002 (significant), active -0.008±0.001 (significant); ∆TPR: active +0.024±0.003 (significant), inactive -0.007±0.003 (not significant); ∆FPR: inactive -0.023±0.004 (significant), active -0.008±0.003 (significant); ∆SHD: inactive -0.032±0.012, active -0.071±0.011 (both significant). Real-data (Sachs) showed ∆TPR 0.020±0.004 and reductions in reversed-edge rate.",
            "performance_without_robustness": "Baseline NOTEARS-MLP with no induced expert constraints; inducing redundant (already-correct) knowledge produced near-zero changes (e.g., ∆FDR ≈ -0.00030±0.00017), indicating no harm but little benefit for redundant constraints.",
            "has_ablation_study": true,
            "number_of_distractors": null,
            "key_findings": "Incorporating expert constraints (especially known-active edges) reliably reduces false discoveries and SHD and increases TPR when the induced knowledge corrects model mistakes; redundant constraints do no harm; constraints on active edges are more informative than inactive ones because they remove more degrees of freedom and more strongly shape the feasible graph space. The method does not actively detect latent confounders nor perform interventional refutations; detection of spurious signals relies on known ground truth or expert identification of misclassifications.",
            "uuid": "e715.2"
        },
        {
            "name_short": "Edge Thresholding / Pruning",
            "name_full": "Post-optimization edge thresholding (pruning) in NOTEARS",
            "brief_description": "A simple post-processing step that sets to zero any learned adjacency weight whose magnitude falls below a chosen threshold to reduce false positive edges.",
            "citation_title": "DAGs with no tears: Continuous optimization for structure learning",
            "mention_or_use": "use",
            "method_name": "Edge weight thresholding (pruning)",
            "method_description": "After continuous optimization, apply a threshold w_thresh and prune edges with |w_{ij}| &lt; w_thresh; in the constrained formulation, thresholds are incorporated when converting constraints (e.g., equality constraints become approximate equalities allowing for small weights) and slack variables accommodate the threshold-aware constraints.",
            "environment_name": "Same observational simulation and real datasets",
            "environment_description": "Applied as a deterministic post-processing step on models learned from observational datasets; not interactive.",
            "handles_distractors": true,
            "distractor_handling_technique": "Removes small-magnitude learned edges that are likely spurious (irrelevant variables/false positives) by threshold pruning.",
            "spurious_signal_types": "Irrelevant variables and small spurious edges resulting from sampling noise or overfitting.",
            "detection_method": "Implicit detection by magnitude: edges below threshold deemed spurious.",
            "downweighting_method": "Hard zeroing of small weights (pruning); indirectly downweights by L1 during training so combined effect shrinks such weights.",
            "refutation_method": null,
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": "Contributes to reduced FDR and FPR in the experiments when combined with induced constraints and L1 regularization; specific deltas reported for combined methods are in the knowledge-augmented NOTEARS entry.",
            "performance_without_robustness": null,
            "has_ablation_study": false,
            "number_of_distractors": null,
            "key_findings": "Thresholding is a practical, low-cost mechanism for reducing false positives; it is used in the paper both as a standalone pruning mechanism and to shape how equality/inequality constraints are operationalized with slack variables.",
            "uuid": "e715.3"
        },
        {
            "name_short": "L1 Regularization (sparsity)",
            "name_full": "L1 parameter regularization for sparse DAG learning",
            "brief_description": "Sparsity-inducing L1 penalty on network parameters (or derived edge weights) to favor sparse graph solutions and reduce spurious edges.",
            "citation_title": "",
            "mention_or_use": "use",
            "method_name": "L1 regularization on network parameters",
            "method_description": "Adds λ||θ||_1 to the optimization objective to penalize large numbers of nonzero parameters, encouraging columns of the first-layer weights to shrink to zero and thus reducing inferred dependencies (edges) between variables; combined with augmented Lagrangian penalties and thresholding.",
            "environment_name": "Observational synthetic and real datasets used in experiments",
            "environment_description": "Applied as part of the optimization objective during training on observational datasets; not an active or interactive mechanism.",
            "handles_distractors": true,
            "distractor_handling_technique": "Promotes sparsity to downweight and eliminate spurious edges introduced by noise or overfitting.",
            "spurious_signal_types": "Spurious/weak dependencies, false positives due to finite sampling and model expressivity.",
            "detection_method": null,
            "downweighting_method": "Penalizes edge-supporting parameters to shrink weak edges toward zero; used jointly with thresholding to remove them.",
            "refutation_method": null,
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": "Contributes to overall improvements reported when combined with constraints; high regularization can, however, hurt TPR by removing true active edges (noted in the paper).",
            "performance_without_robustness": null,
            "has_ablation_study": false,
            "number_of_distractors": null,
            "key_findings": "L1 regularization is an important component to control false discoveries but must be tuned carefully because overly strong sparsity can remove true causal edges.",
            "uuid": "e715.4"
        },
        {
            "name_short": "Sequential knowledge induction (human-in-the-loop)",
            "name_full": "Iterative expert-constraint induction for causal structure learning",
            "brief_description": "An interactive, sequential process where experts (or ground-truth comparisons) supply constraints correcting model mistakes, which are added iteratively and the model is re-optimized to improve learned causal structure.",
            "citation_title": "here",
            "mention_or_use": "use",
            "method_name": "Sequential knowledge induction (iterative constraint addition)",
            "method_description": "Start from baseline predicted graph, identify misclassified edges (via expert inspection or comparison to known ground truth), convert a selected misclassification into a constraint (known active or inactive), add it to the constraint set, re-run the constrained NOTEARS-MLP optimization, and iterate; can add one or a batch of corrections per iteration and compute expected vs empirical improvements.",
            "environment_name": "Offline iterative loop over observational datasets (simulations and Sachs)",
            "environment_description": "A human-in-the-loop offline corrective process rather than an online experimental/virtual-lab intervention strategy; environment remains observational data; the loop simulates domain expert feedback.",
            "handles_distractors": true,
            "distractor_handling_technique": "Detects candidate spurious edges by locating model misclassifications and uses hard constraints to remove (known-inactive) or enforce (known-active) edges, thereby directly eliminating or validating suspected spurious relationships.",
            "spurious_signal_types": "False positive edges (spurious cause-effect links) identified by experts or ground-truth comparison; indirectly mitigates errors due to sampling and functional misspecification.",
            "detection_method": "Identify misclassified edges in the predicted graph (comparison to ground truth or expert labels) and select them as candidates for induction.",
            "downweighting_method": "Converted misclassified-inactive edges become equality constraints (W_{ij}=0) or inequality constraints with slack, which effectively zero-out or force stronger weights away from spurious values; combined with L1 and thresholding.",
            "refutation_method": "Empirical refutation by contradiction: imposing a constraint that contradicts a previously inferred edge and observing whether re-optimization removes the edge and improves global metrics; no interventional testing is performed.",
            "uses_active_learning": false,
            "inquiry_strategy": "Greedy/random selection of one misclassified edge at each iteration (the paper used random selection among model mistakes) to study per-constraint contribution; can be extended to batch corrections.",
            "performance_with_robustness": "Sequentially adding correcting constraints yields statistically significant metric improvements: e.g., single-correction deltas reported (see Knowledge-Augmented NOTEARS entry) with larger gains for active-edge constraints on SHD and TPR.",
            "performance_without_robustness": "Baseline (no iterative constraints) NOTEARS-MLP; adding redundant (already-correct) knowledge generated negligible change (sanity-check), while correcting knowledge produced meaningful improvements.",
            "has_ablation_study": true,
            "number_of_distractors": null,
            "key_findings": "Interactive sequential induction of expert constraints is an effective strategy to reduce spurious edges and improve graph recovery, especially when constraints correct genuine model mistakes; random selection of corrections allowed estimation of per-constraint effect, and redundant constraints had no harmful effect.",
            "uuid": "e715.5"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "DAGs with no tears: Continuous optimization for structure learning",
            "rating": 2,
            "sanitized_title": "dags_with_no_tears_continuous_optimization_for_structure_learning"
        },
        {
            "paper_title": "Learning sparse nonparametric DAGs",
            "rating": 2,
            "sanitized_title": "learning_sparse_nonparametric_dags"
        },
        {
            "paper_title": "Dags with no fears: A closer look at continuous optimization for learning bayesian networks",
            "rating": 2,
            "sanitized_title": "dags_with_no_fears_a_closer_look_at_continuous_optimization_for_learning_bayesian_networks"
        },
        {
            "paper_title": "Masked gradient-based causal structure learning",
            "rating": 1,
            "sanitized_title": "masked_gradientbased_causal_structure_learning"
        },
        {
            "paper_title": "Low rank directed acyclic graphs and causal structure learning",
            "rating": 1,
            "sanitized_title": "low_rank_directed_acyclic_graphs_and_causal_structure_learning"
        }
    ],
    "cost": 0.01560575,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Evaluation of Induced Expert Knowledge in Causal Structure Learning by NOTEARS</p>
<p>Jawad Chowdhury 
Dept. of Computer Science
University of North Carolina at Charlotte
CharlotteNCUSA</p>
<p>Rezaur Rashid mrashid1@uncc.edu 
Dept. of Computer Science
University of North Carolina at Charlotte
CharlotteNCUSA</p>
<p>Gabriel Terejanu gabriel.terejanu@uncc.edu 
Dept. of Computer Science
University of North Carolina at Charlotte
CharlotteNCUSA</p>
<p>Evaluation of Induced Expert Knowledge in Causal Structure Learning by NOTEARS
CausalityStructured Prediction and LearningSupervised Deep LearningOptimization for Neural Networks
Causal modeling provides us with powerful counterfactual reasoning and interventional mechanism to generate predictions and reason under various what-if scenarios. However, causal discovery using observation data remains a nontrivial task due to unobserved confounding factors, finite sampling, and changes in the data distribution. These can lead to spurious cause-effect relationships. To mitigate these challenges in practice, researchers augment causal learning with known causal relations. The goal of the paper is to study the impact of expert knowledge on causal relations in the form of additional constraints used in the formulation of the nonparametric NOTEARS. We provide a comprehensive set of comparative analyses of biasing the model using different types of knowledge. We found that (i) knowledge that correct the mistakes of the NOTEARS model can lead to statistically significant improvements, (ii) constraints on active edges have a larger positive impact on causal discovery than inactive edges, and surprisingly, (iii) the induced knowledge does not correct on average more incorrect active and/or inactive edges than expected. We also demonstrate the behavior of the model and the effectiveness of domain knowledge on a real-world dataset.</p>
<p>INTRODUCTION</p>
<p>Machine learning models have been breaking records in terms of achieving higher predictive accuracy. Nevertheless, out-of-distribution (OOD) generalization remains a challenge. One solution is adopting causal structures (Lake et al., 2017) to constrain the models and remove spurious correlations. The underlying causal knowledge of the problem of interest can significantly help with domain adaptability and OOD generalization (Magliacane et al., 2017). Furthermore, causal models go beyond the capability of correlation-based models to produce predictions. They provide us with the powerful counterfactual reasoning and interventional mechanism to reason under various what-if scenarios (Pearl, 2009).</p>
<p>Two of the most prominent approaches in observational causal discovery are constraint-based and score-based methods (Spirtes et al., 2000;Pearl and Verma, 1995;Colombo et al., 2012;Chickering, 2002;Ramsey et al., 2017). Although these methods are quite robust if the underlying assumptions are true, they are computationally expensive and their computational complexity increases with the number of system variables due to the combinatorial nature of the DAG constraint. NOTEARS (Zheng et al., 2018) tackles this problem with an algebraic characterization of acyclicity which reduces the combinatorial problem to a continuous constrained optimization. Different approaches (Yu et al., 2019;Lachapelle et al., 2019;Ng et al., 2019;Zheng et al., 2020) have been proposed as the nonlinear or nonparametric extensions of this linear continuous optimization, which provides flexibility in modeling different causal mechanisms.</p>
<p>Learning the causal structure purely based on observational data is not a trivial task due to various limitations such as finite sampling, unobserved confounding factors, selection bias, and measurement errors (Cooper, 1995;Elkan, 2001;Zadrozny, 2004). These can result in spurious cause-effect relationships. To mitigate these challenges in practice, researchers augment causal learning with prior causal relations as featured in software packages such as CausalNex 1 , causal-learn 2 , bnlearn (Scutari, 2009), gCastle (Zhang et al., 2021), and DoWhy (Sharma and Kiciman, 2020). Heindorf et al. (Heindorf et al., 2020) in their work attempts to construct the first large scale open domain causality graph that can be in-cluded in the existing knowledge bases. The work further analyze and demonstrates the benefits of large scale causality graph in causal reasoning. Given a partial ancestral graph (PAG), representing the qualitative knowledge of the causal structure, Jaber et al. (Jaber et al., 2018) in their study compute the interventional distribution from observational data. Combining expert knowledge with structural learning further constrains the search space minimizing the number of spurious mechanisms (Wei et al., 2020) and researchers often leverage these background knowledge by exploiting them as additional constraints for knowledge-enhanced event causality identification . O'Donnell et al. (O'Donnell et al., 2006) use expert knowledge as prior probabilities in learning Bayesian Network (BN) and Gencoglu and Gruber (Gencoglu and Gruber, 2020) use the linear NOTEARS model to incorporate knowledge to detect how different characteristics of the COVID-19 pandemic are causally related to each other. Different experts' causal judgments can be aggregated into collective ones (Bradley et al., 2014) and Alrajeh et al. (Alrajeh et al., 2020) in their work, studied how these judgments can be combined to determine effective interventions. An interesting exploration by Andrews et al. (Andrews et al., 2020) defines tiered background knowledge and shows that with this type of background knowledge the FCI algorithm (Spirtes et al., 2000) is sound and complete.</p>
<p>However, understanding how to effectively incorporate and evaluating the impact of induced knowledge is yet to be explored and we believe knowledge regarding this can mitigate some of the challenges of observational causal discovery. Human expertise can play a vital role to assess the learned model in causal structure learning (Bhattacharjya et al., 2021;Li et al., 2021). In practice, human assessment and validation process often take place in an iterative or sequential manner (Holzinger, 2016;Xin et al., 2018;Yang et al., 2019). In structure learning, this is more realistic for a sufficiently large causal network where one can learn, validate, and induce newly formed knowledge-set in the learning process following sequential feedback loops. The goal of this paper is not to create a new causal discovery algorithm but rather to study this iterative interaction between prior causal knowledge from domain experts that takes the form of model constraints and a state-of-the-art causal structure learning algorithm. Wei et al. (Wei et al., 2020) have been the first to augment NOTEARS with additional optimization constraints to satisfy the Karush-Kuhn-Tucker (KKT) optimality conditions and Fang et al. (Fang et al., 2020) in their work leverages the low rank assumption in the context of causal DAG learning by augmented NOTEARS that shows significant improvements. However, none of them have studied the impact of induced knowledge on causal structure learning by augmenting NOTEARS with the optimization constraints. For completeness, in Section 3, we do provide our formulation of nonparametric NOTEARS (Zheng et al., 2020) with functionality to incorporate causal knowledge in the form of known direct causal and non-causal relations. Nevertheless, in this work, we aim to study the impact of expert causal knowledge on causal structure learning.</p>
<p>The main contributions are summarized as follows. (1) We demonstrate an iterative modeling framework to learn causal relations, impose causal knowledge to constrain the causal graphs, and further evaluate the model's behavior and performance.</p>
<p>(2) We empirically evaluate and demonstrate that: (a) knowledge that corrects model's mistake can lead to statistically significant improvements, (b) constraints on active edges have a larger positive impact on causal discovery than inactive edges, and (c) the induced knowledge does not correct on average more incorrect active and/or inactive edges than expected. Finally, we illustrate the impact of additional knowledge in causal discovery on a real-world dataset.</p>
<p>This paper is structured as follows: Section 2 introduces the background on causal graphical models (CGMs), score-based structure recovery methods, and a study using the score-based approach formulated as a continuous optimization and its recent nonparametric extension. In Section 3, we present our extension of the nonparametric continuous optimization to incorporate causal knowledge in structure learning and detail the proposed knowledge induction process. Section 4 shows the empirical evaluations and comparative analyses of the impact of expert knowledge on the model's performance. Finally, in Section 5, we summarize our findings and provide a brief discussion on future work.</p>
<p>BACKGROUND</p>
<p>In this section, we review the basic concepts related to causal structure learning and briefly cover a recent score-based continuous causal discovery approach using structural equation models (SEMs).</p>
<p>Causal Graphical Model (CGM)</p>
<p>A directed acyclic graph (DAG) is a directed graph without any directed cyclic paths (Spirtes et al., 2000). A causal graphical model CGM(P X , G) can be defined as a pair of a graph G and an observa-tional distribution P X over a set of random variables X = (X 1 , . . . , X d ). The distribution P X is Markovian with respect to G where G = (V, E) is a DAG that encodes the causal structures among the random variables X i ∈ X (Peters et al., 2017). The node i ∈ V corresponds to the random variable X i ∈ X and edges (i, j) ∈ E correspond to the causal relations encoded by G. In a causal graphical model, the joint distribution P x can be factorized as
p(x) = ∏ d i=1 p(x i |x G pa i ) where X G pa i refers to the set of parents (direct causes)
for the variable X i in DAG G and for each X j ∈ X G pa i there is an edge (X j → X i ) ∈ E (Peters et al., 2017).</p>
<p>Score-based Structure Recovery</p>
<p>In a structure recovery method, given n i.i.d. observations in the data matrix X = [x 1 | . . . |x d ] ∈ R n×d , our goal is to learn the underlying causal relations encoded by the DAG G. Most of the approaches follow either a constraint-based or a score-based strategy for observational causal discovery. A score-based approach typically concentrates on identifying the DAG model G that fits the observed set of data X according to some scoring criterion S(G, X) over the discrete space of DAGs D where G ∈ D (Chickering, 2002).</p>
<p>The optimization problem for structure recovery in this case can be defined as follows: min
G S(G, X) subject to G ∈ D(1)
The challenge with Eq. 1 is that the acyclicity constraint in the optimization is combinatorial in nature and scales exponentially with the number of nodes d in the graph. This makes the optimization problem NP-hard (Chickering, 1996;Chickering et al., 2004).</p>
<p>NOTEARS: Continuous Optimization for Structure Learning</p>
<p>NOTEARS (Zheng et al., 2018) is a score-based structure learning approach which reformulates the combinatorial optimization problem to a continuous one through an algebraic characterization of the acyclicity constraint in Eq. 1 via trace exponential. This method encodes the graph G defined over the d nodes to a weighted adjacency matrix
W = [w 1 | . . . |w d ] ∈ R d×d where w i j = 0 if there is an ac- tive edge X i → X j and w i j = 0 if there is not. The weighted adjacency matrix W entails a linear SEM by X i = f i (X) + N i = w T i X + N i ;
where N i is the associated noise. The authors define a smooth score function on the weighted matrix as h(W ) = tr(e W •W ) − d where • is the Hadamard product and e M is the matrix exponential of M. This embedding of the graph G and the characterization of acyclicity turns the optimization in Eq. 1 into its equivalent:
min W ∈R d×d L(W ) subject to h(W ) = 0 (2)
where L(W ) is the least square loss over W and h(W ) score defines the DAG-ness of the graph.</p>
<p>Nonparametric Extension of NOTEARS</p>
<p>A nonparametric extension of the continuous optimization suggested by a subsequent study (Zheng et al., 2020) uses partial derivatives for asserting the dependency of f j on the random variables. The au-
thors define f j ∈ H 1 (R d ) ⊂ L 2 (R d )
over the Sobolev space of square integrable functions whose derivatives are also square integrable. The authors show that f j can be independent of random variable X i if and only if ||∂ i f j || L 2 = 0 where ∂ i denotes partial derivative with respect to the i-th variable. This redefines the weighted adjacency matrix with
W ( f ) = W ( f 1 , . . . , f d ) ∈ R d×d where each W i j encodes the partial dependency of f j on variable X i .
As a result, we can equivalently write Eq. 2 as follows:
min f : f j ∈H 1 (R d ),∀ j∈[d] L( f ) subject to h(W ( f )) = 0(3)
for all X j ∈ X. Two of the general instances proposed by (Zheng et al., 2020) are: NOTEARS-MLP and NOTEARS-Sob. A multilayer perceptron having h number of hidden layers and σ : R → R activation function can be defined as M(X; L) = σ(L (h) σ(. . . σ(L (1) X)) where L (l) denotes the parameters associated with l-th hidden layer. The authors in (Zheng et al., 2020) show that if ||i-th column of L (1) j || 2 = 0 then M j (X; L) will be independent of variable X i which replaces the association of partial derivatives in Eq. 3 and redefines the adjacency matrix as
W (θ) with W (θ) i j = ||i-th column of L (1) j || 2 where θ = (θ 1 , . . . , θ d ); θ k de- noting the set of parameters for the M k (X; L) (k- th MLP).
With the usage of neural networks and the augmented Lagrangian method (Bertsekas, 1997) NOTEARS-MLP solves the constrained problem in Eq. 3 as follows: Figure 1: Knowledge induction process. We induce knowledge by carrying over the existing knowledge set along with a new random correction informed by model mistakes.
min θ F(θ) + λ||θ|| 1 F(θ) = L(θ) + ρ 2 |h(W (θ))| 2 + αh(W (θ))(4)</p>
<p>KNOWLEDGE INDUCTION</p>
<p>In our formulation, we use the multilayer perceptrons of NOTEARS-MLP proposed by (Zheng et al., 2020) as our estimators. We extend this framework to incorporate causal knowledge by characterizing the extra information as additional constraints in the optimization in Eq. 3.</p>
<p>Knowledge Type. We distinguish between these two types of knowledge: (i) known inactive is knowledge from the true inactive edges (absence of direct causal relation), and (ii) known active is knowledge from the true active edges (presence of direct causal relation).</p>
<p>Knowledge Induction Process. We adopt an interactive induction process, where the expert knowledge is informed by the outcome of the causal discovery model. Namely, the knowledge is induced to correct the mistakes of the model in the causal structure, in the hope that the new structure is closer to the true causal graph. This process is applied sequentially by correcting the mistakes of the model at each step.</p>
<p>In the following subsections we present the formulation of the NOTEARS optimization with constrains and detail the sequential induction process.</p>
<p>Expert Knowledge as Constraints</p>
<p>An induced knowledge associated with a true active edge, X i → X j (known active) enforces the corresponding cell in the adjacency matrix to be nonzero, [W (θ)] i j = 0. We consider this knowledge as inequality constraint in our extension of the optimization such that the following statement holds: h p ineq (W (θ)) &gt; 0 (5) where p enumerates over all the inequality constraints due to induction from the set of known active and h ineq is the penalty score associated with the violation of these inequality constraints. On the other hand, knowledge associated with true inactive edge, X i X j (known inactive) enforces the related cell in W (θ) to be equal to zero, [W (θ)] i j = 0 if the induction implies there should not be an edge from X i to X j . We consider this knowledge as equality constraint in our optimization such as:
h q eq (W (θ)) = 0 (6)
where q enumerates over all the equality constraints, induced from the set of known inactive and h eq is the penalty score associated with the violation of these equality constraints. With these additional constraints in Eqs. 5, 6 we extend Eq. 3 to incorporate causal knowledge in the optimization as follows:
min f : f j ∈H 1 (R d ),∀ j∈[d] L( f ) subject to h(W (θ)) = 0, h q eq (W (θ)) = 0, h p ineq (W (θ)) &gt; 0 (7)
NOTEARS uses a thresholding step on the estimated edge weights to reduce false discoveries by pruning all the edges with weights falling below a certain threshold. Because of this, in practice, even the equality constraints in Eq. 6 become inequalities to allow for small weights. Finally, slack variables are introduced in the implementation to transform the inequality constraints into equality constraints (see detailed formulation in Appendix A).</p>
<p>By using the similar strategy suggested by Zheng et al. (Zheng et al., 2020) with augmented Lagrangian method the reframed constrained optimization of Eq. 4 takes the following form:
min θ F(θ) + λ||θ|| 1 F(θ) = L(θ) + ρ 2 |h(W (θ))| 2 + αh(W (θ)) + ∑ p ( ρ ineq 2 |h p ineq (W (θ))| 2 + α p h p ineq (W (θ))) + ∑ q ( ρ eq 2 |h q eq (W (θ))| 2 + α q h q eq (W (θ)))(8)</p>
<p>Sequential Knowledge Induction</p>
<p>In case of knowledge induction, the optimization is run in a sequential manner where the constraints are informed by the causal mistakes made by the model in the previous step. We start with our baseline model without imposing any additional knowledge from the true DAG and get the predicted causal graph denoted by G 0 pred in Figure 1. Then at each iterative step (k + 1), based on the mistakes in the causal graph G k pred predicted by the NOTEARS-MLP, we select one additional random piece of knowledge to correct one of the mistakes, and add it to the set of constraints identified in the previous k steps, and rerun NOTEARS. We note that a batch of corrections can also be selected, however for this work we have focused on estimating the contribution of each piece of knowledge in the form of known active/inactive edge. Our observations are illustrated in Section 4.1, Section 4.2, Section 4.3, and Section 4.4.</p>
<p>Expected Causal Graph. We consider the expected causal graph, G k+1 exp at step (k + 1) by considering the case where all the knowledge has successfully been induced without impacting any other edges. Figure 2d illustrates an example of how we formulate our expected graph for a particular step in the iterative process. We note that the correction might yield a directed graph (Expected Causal Graph) that is not necessary a DAG. The objective is to compare the performance between the causal graph predicted by NOTEARS and the expected causal graph. Our intuition is that the induced knowledge will probably correct additional incorrect edges, see Figure 2g, yielding a performance better than expected.</p>
<p>EXPERIMENTS</p>
<p>To empirically evaluate the impact of additional causal knowledge on causal learning and to keep our experimental setup similar to the study in Ref. (Zheng </p>
<p>Metric</p>
<p>Desirability ∆FDR Lower is better ∆TPR Higher is better ∆FPR Lower is better ∆SHD Lower is better  (Reisach et al., 2021), we have conducted experiments using both unscaled and scaled data to ensure the robustness of our findings and we are pleased to report that our conclusions remain unchanged regardless of the scaling of the data, indicating the stability and reliability of our results. While we present the results using the unscaled data for consistency with the original implementation of NOTEARS (Zheng et al., 2020), it is important to note that our conclusions hold true even when the data is scaled.</p>
<p>Simulation. We investigate the performance of our formulation and the impact of induced knowledge by comparing the DAG estimates with the ground truths. For our simulations with synthetic data, we have considered 16 different combinations following the simulation criteria: two random graph models, Erdos-Renyi (ER) and Scale-Free (SF), number of nodes, d = {10, 20}, sample size, n = {200, 1000}, edge density, s0 = {1d, 4d}. For each of these combinations, we have generated 10 different random graphs or true DAGs (as 10 trials for a particular combination) and corresponding data by following nonlinear data generating process with index models (similar to the study in Ref. (Zheng et al., 2020) for which the underlying true DAGs are identifiable. The results are summarized over all these 160 random true DAGs and datasets. In our simulations, we have considered the regularization parameter, λ = 0.01. We evaluate the performance of causal learning based on the mean and the standard error of different metrics. For statistical significance analysis, we have used t-test with α = 0.05 as the significance level. 
∆SHD pred = SHD(G k+1 pred ) − SHD(G k pred ) (9)
Sanity Check -Redundant Knowledge Does No Harm. As part of our sanity check, we investigate the impact of induced knowledge that matches the causal relationships successfully discovered by the NOTEARS-MLP. Therefore, in this section, we consider the set of edges that our baseline model correctly classifies as our knowledge source. Here, we do not distinguish between the edge types of our induced knowledge (known inactive &amp; active) since our goal is to investigate whether having redundant knowledge as additional constraints affects model's performance or not. The results are illustrated in Table 2.</p>
<p>Our empirical evaluation shows that adding redundant knowledge does not deteriorate the performance of NOTEARS-MLP. Our performed statistical test reflects that the results after inducing the knowledge from the correctly classified edge set are not statistically different than the results from the model without these knowledge inductions. However, we have noticed that the performance gets worse with highly regularized models. This is consistent with observa-tions by Ng et al. (Ng et al., 2020) where sparse DAGs result in missing some of the true active edges.</p>
<p>Knowledge that Corrects Model's Mistake</p>
<p>We first investigate the role of randomly chosen knowledge that corrects model's mistake based on the cause-effect relations of the true graph. Therefore, in this case, we consider the set of misclassified edges from the estimated causal graph as the knowledge source for biasing the model. The results are illustrated in Table 3. Our empirical result shows statistically significant improvements whenever the induced knowledge corrects misclassified edges in the estimated causal graph except for the case of ∆TPR with known inactive edges. However, this behavior is not totally unexpected since knowledge from known inactive edges helps to get rid of false discoveries or false positives, which hardly have impact on true positives.</p>
<p>Known Inactive vs Known Active</p>
<p>In this subsection, we are interested in understanding the impact of different types of induced knowledge on causal discovery to correct the mistakes in the estimated causal graph. As a result, the experimental setup is similar to Section 4.1 where we consider the misclassified edge set as the knowledge source. We consider both known inactive and known active types of knowledge to induce separately and analyze the differences of their impact on the performance. The results are illustrated in Table 4. Based on our statistical test, we have found that inducing known inactive is more effective when we compare the performance based on FDR and FPR as misclassification of inactive edges has more impact on these metrics. On the other hand, the results show that inducing known active is more effective on TPR as misclassification of active edges has more impact on this metric. Interestingly, we have found that known active provides a significant improvement over known inactive in terms of SHD. This can be attributed to the fact that the induced knowledge based on the true inactive edge (known inactive) between two random variables, i.e. from X i to X j allows for two extra degrees of freedom since it is still possible to have no edge at all or an active edge from X j to X i . However, the induced knowledge based on the true active edge doesn't allow any degrees of freedom. This type of knowledge is more restraining for causal graph discovery and therefore carries more information.</p>
<p>Empirical Performance vs Expectation</p>
<p>In this subsection, we are interested in understanding whether inducing knowledge to correct model's mistakes exceeds expected improvement. The experimental setup is similar to Section 4.1 and Section 4.2 where we consider the misclassified edge set as the knowledge source. We have conducted the experiments using both known inactive and known active types of knowledge separately. The expected causal graph, G exp is formulated in a similar manner described in Fig. 2. Table 5 shows the summary of the performance comparison in these cases with the expected results. Our statistical test shows that the induced correct knowledge does not correct on average more incorrect active and/or inactive edges than expected. Therefore, using the information from induced knowledge does not have additional impact than expected in the global optimization scheme. However, this is likely due to the fact that the structure of the expected causal graph, G exp is not well-posed. It's worth noting that G exp isn't necessarily a DAG since there isn't any constraining mechanism to enforce acyclicity as compared to G pred (NOTEARS imposes hard acyclicity constaint in the continuous optimization). Although it is to be noted here that solving an acyclicity constrained optimization problem does not guarantee to return a DAG and Ng et al. (Ng et al., 2022) in their study illustrates on this behavior and proposes the convergence guarantee with a DAG solution.</p>
<p>Real Data</p>
<p>We evaluate the implication of incorporating expert knowledge on the dataset from study in Ref. (Sachs et al., 2005), which is largely used in the literature of probabilistic graphical models with a consensus network accepted by the biological community. This dataset contains the expression levels of phosphorylated proteins and phospholipids in human cells under different conditions. The dataset has d = 11 cell types along with n = 7466 samples of expression levels. As for the ground truth of the underlying causal graph, we considered s 0 = 20 active edges as suggested by the study (Sachs et al., 2005). We have opted for ∆TPR, the percentage difference of edges in agreement (higher is better), and the percentage difference of reversed edges (lower is better) as the evaluation metrics since the performance on these metrics would indicate the significance more distinctively. Similar to the synthetic data analysis, we had 10 trials that we used to summarize our evaluation. Our empirical result (Mean ± Stderr.) shows: ∆TPR as 0.020 ± 0.004, the percentage difference of edges in agreement as 0.393 ± 0.086, and the percentage difference of reversed edges as -0.073 ± 0.030. We have found that with the help of induced knowledge the model shows statistically significant improvement by correctly identifying more active edges and by reducing the number of edges identified in the reverse direction. Due to the limitation of having access only to a subset of the true active edges, our analyses could not include a comparative study on known inactive edges as in the synthetic data case. We assume the performance could have been improved by fine-tuning the model's parameters but since our main focus of this study is entirely based on the analyses regarding the impact of induced knowledge of different types and from different sources on structure learning, we kept the parameter setup similar for all consecutive steps in the knowledge induction process.</p>
<p>CONCLUSIONS</p>
<p>We have studied the impact of expert causal knowledge on causal structure learning and provided a set </p>
<p>Metric</p>
<p>Inactive Active Better ∆FDR -0.019 ± 0.002 -0.008 ± 0.001 inactive ∆TPR -0.007 ± 0.003 0.024 ± 0.003 active ∆FPR -0.023 ± 0.004 -0.009 ± 0.004 inactive ∆SHD -0.033 ± 0.013 -0.072 ± 0.011 active More importantly, we have found that knowledge related to active edges has a larger positive impact on causal discovery than knowledge related to inactive edges which can mostly be attributed to the difference between the number of degrees of freedom each case reduces. This finding suggest that the practitioners may want to prioritize incorporating knowledge regarding presence of an edge whenever applicable. Furthermore, our experimental analysis shows that the induced knowledge does not correct on average more incorrect active and/or inactive edges than expected. This finding is rather surprising to us, as we have expected that every constraint based on a known active/inactive edge to impact and correct more than one edge on average. Our work points to the importance of the humanin-the-loop in causal discovery that we would like to further explore in our future studies. Also, we would like to mention that in our study we adopted hard constraints to accommodate the prior knowledge since we have assumed our priors to be correct. An interesting future direction would be to accommodate the continuous optimization with functionality to allow different levels of confidence on the priors.</p>
<p>B. Additional Results and Summary Statistics</p>
<p>We illustrate here the detailed performance with summary statistics of induced knowledge from our empirical evaluation (∆FDR, ∆TPR, ∆FPR, and ∆SHD for both ∆=1 and ∆=2). Similar to one additional knowledge (∆=1), we calculate the impact of inducing two additional piece of knowledge (∆=2) based on our model's prediction i.e. on the metric SHD (∆SHD 2 pred ) as follows: Table 6 shows the results for inducing redundant knowledge or knowledge that is correctly classified by NOTEARS-MLP. Table 7 shows the detailed results for inducing knowledge that corrects model's mistake. Table 8 shows the detailed results of the difference between the impact of 'known inactive' (knowledge induced from inactive edges) and 'known active' (knowledge induced from active edges) using misclassified edge set as the knowledge source. Table 9 shows the detailed results of the difference between empirical improvements due to knowledge induction vs expected outcomes using misclassified edge set as the knowledge source. Table 10 shows the detailed results for inducing knowledge on the real dataset (from (Sachs et al., 2005)).   Metric ∆ Inactive Active p-value t-stat Better ∆FDR 1 -0.019 ± 0.002 -0.008 ± 0.001 1.30E-04 -3.85
∆SHD 2 pred = SHD(G k+2 pred ) − SHD(G k pred )(12)
Inactive ∆FDR 2 -0.023 ± 0.002 -0.011 ± 0.001 5.58E-04 -3.47</p>
<p>Inactive ∆TPR 1 -0.007 ± 0.003 0.024 ± 0.003 8.13E-14 -7.57 Active ∆TPR 2 -0.001 ± 0.003 0.035 ± 0.004 2. 84E-13 -7.43 Active ∆FPR 1 -0.023 ± 0.004 -0.009 ± 0.004 7.28E-03 -2.69</p>
<p>Inactive ∆FPR 2 -0.021 ± 0.004 -0.015 ± 0.005 3.23E-01 -0.99 No difference ∆SHD 1 -0.033 ± 0.013 -0.072 ± 0.011 1.90E-02 2.35 Active ∆SHD 2 -0.082 ± 0.013 -0.126 ± 0.016 3.28E-02 2.14 Active  Metric ∆ Mean ± Stderr. p-value t-stat Remarks ∆TPR 1 0.020 ± 0.004 8.10E-06 4.60 Improvement ∆TPR 2 0.036 ± 0.005 1.77E-12 7.62 Improvement ∆ % edge in agreement 1 0.393 ± 0.086 8.10E-06 4.60 Improvement ∆ % edge in agreement 2 0.714 ± 0.094 1.77E-12 7.62 Improvement ∆ % edge reversed 1 -0.073 ± 0.030 1.54E-02 -2.45 Improvement ∆ % edge reversed 2 -0.107 ± 0.033 1.29E-03 -3.27 Improvement</p>
<p>Figure 2 :
2Expected graph formulation: (a) true graph, G true , (b) predicted graph by model at step k, G k pred , (c) induced knowledge at step (k +1), (d) expected graph at step (k +1), G k+1 exp . Three different examples of many possible predicted graphs at step (k + 1), G k+1 pred where the model performs (e) less than expectation, (f) par with expectation, and (g) more than expectation.</p>
<p>Table 1 :
1Performance metrics considered with their corresponding desirability.</p>
<p>Table 2 :
2Results for inducing redundant knowledge. et al., 2020), we have used an MLP with 10 hidden units and sigmoid activation functions. In all our experimental setup, we assume the prior knowledge is correct (agrees with the true DAG). Despite the known sensitivity of the NOTEARS algorithm to data scaling, as demonstrated in previous studyMetric 
Mean ± Stderr. 
Remarks 
∆FDR -0.00030 ± 0.00017 No harm 
∆TPR -0.00035 ± 0.00027 No harm 
∆FPR -0.00097 ± 0.00059 No harm 
∆SHD -0.00154 ± 0.00167 No harm </p>
<p>Table 3 :
3Results for inducing knowledge that corrects model's mistake. ∆FPR, and ∆SHD, see alsoTable 1. For example, based on our model's prediction we calculate the impact of inducing one additional piece of knowledge on the metric SHD (∆SHD pred ) as follows:Metric Knowledge Mean ± Stderr. Improvement 
∆FDR 
inactive 
-0.018 ± 0.002 
Significant 
∆FDR 
active 
-0.008 ± 0.001 
Significant 
∆TPR 
inactive 
-0.007 ± 0.003 Not significant 
∆TPR 
active 
0.024 ± 0.003 
Significant 
∆FPR 
inactive 
-0.023 ± 0.004 
Significant 
∆FPR 
active 
-0.008 ± 0.003 
Significant 
∆SHD 
inactive 
-0.032 ± 0.012 
Significant 
∆SHD 
active 
-0.071 ± 0.011 
Significant </p>
<p>Metrics. For the comparative analysis, we consider 
the following performance metrics: False Discovery 
Rate (FDR), True Positive Rate (TPR), False Posi-
tive Rate (FPR), and Structural Hamming Distance 
(SHD). However, since we are evaluating the perfor-
mance over all these 160 random graphs of varying 
sizes, we consider Structural Hamming Distance per 
node (SHD/d) as our SHD measure that scales with 
the number of nodes (FDR, TPR, and FPR scale by 
definition). To evaluate the impact of induced knowl-
edge, we calculate the differences in the metrics at 
different steps (where we have different sizes of in-
duced knowledge set) and referred them as ∆FDR, 
∆TPR, </p>
<p>Table 4 :
4Comparison between the impact of inducing knowledge regarding inactive vs active edges.</p>
<p>Table 5 :
5Comparison between the empirical performance vs expectation.Metric Knowledge 
Empirical 
Expected 
Remarks 
∆FDR 
inactive 
-0.019 ± 0.002 -0.016 ± 0.002 No difference 
∆FDR 
active 
-0.008 ± 0.001 -0.006 ± 0.001 No difference 
∆TPR 
inactive 
-0.007 ± 0.003 -0.002 ± 0.003 No difference 
∆TPR 
active 
0.024 ± 0.003 
0.022 ± 0.002 No difference 
∆FPR 
inactive 
-0.023 ± 0.004 -0.021 ± 0.004 No difference 
∆FPR 
active 
-0.009 ± 0.003 -0.007 ± 0.003 No difference 
∆SHD 
inactive 
-0.033 ± 0.013 -0.047 ± 0.010 No difference 
∆SHD 
active 
-0.072 ± 0.011 -0.056 ± 0.010 No difference </p>
<p>of comparative analyses of biasing the model using 
different types of knowledge. Our findings show that 
knowledge that corrects model's mistakes yields sig-
nificant improvements and it does no harm even in the 
case of redundant knowledge that results in redundant 
constraints. This suggest that the practitioners should 
consider incorporating domain knowledge whenever 
available. </p>
<p>Table 6 :
6Full results for inducing redundant knowledge (Sanity Check).Metric ∆ 
Mean ± Stderr. 
p-value t-stat Remarks 
∆FDR 1 -0.00030 ± 0.00017 
0.076 
-1.770 No harm 
∆FDR 2 -0.00060 ± 0.00021 
0.004 
-2.850 No harm 
∆TPR 1 -0.00035 ± 0.00027 
0.205 
-1.260 No harm 
∆TPR 2 -0.00036 ± 0.00029 
0.227 
-1.210 No harm 
∆FPR 1 -0.00097 ± 0.00059 
0.100 
-1.630 No harm 
∆FPR 2 -0.00183 ± 0.00069 
0.008 
-2.660 No harm 
∆SHD 1 -0.00154 ± 0.00167 
0.356 
-0.920 No harm 
∆SHD 2 -0.00357 ± 0.00188 
0.050 
-1.900 No harm </p>
<p>Table 7 :
7Full results for inducing knowledge that corrects model's mistake (Section 4.1).Metric ∆ Knowledge Mean ± Stderr. 
p-value 
t-stat 
Improvement 
∆FDR 1 
inactive 
-0.018, 0.002 
3.41E-14 -7.800 
Significant 
∆FDR 1 
active 
-0.008, 0.001 
2.51E-08 -5.657 
Significant 
∆FDR 2 
inactive 
-0.023, 0.003 
2.74E-15 -8.221 
Significant 
∆FDR 2 
active 
-0.011, 0.002 
9.06E-08 -5.448 
Significant 
∆TPR 1 
inactive 
-0.007, 0.003 
3.10E-02 -2.164 Not significant 
∆TPR 1 
active 
0.024, 0.003 
8.58E-19 9.191 
Significant 
∆TPR 2 
inactive 
-0.001, 0.003 
8.25E-01 -0.222 Not significant 
∆TPR 2 
active 
0.035, 0.004 
1.16E-19 9.580 
Significant 
∆FPR 1 
inactive 
-0.023, 0.004 
3.81E-08 -5.583 
Significant 
∆FPR 1 
active 
-0.008, 0.003 
1.21E-02 -2.517 
Significant 
∆FPR 2 
inactive 
-0.021, 0.003 
1.04E-08 -5.845 
Significant 
∆FPR 2 
active 
-0.015, 0.005 
6.73E-03 -2.724 
Significant 
∆SHD 1 
inactive 
-0.032, 0.012 
9.74E-03 -2.594 
Significant 
∆SHD 1 
active 
-0.071, 0.011 
1.61E-10 -6.522 
Significant 
∆SHD 2 
inactive 
-0.082, 0.012 
1.93E-10 -6.533 
Significant 
∆SHD 2 
active 
-0.126, 0.016 
3.41E-14 -7.875 
Significant </p>
<p>Table 8 :
8Full results of comparison between the impact of inducing knowledge regarding inactive vs active edges. (Section 4.2).</p>
<p>Table 9 :
9Full results of comparison between the empirical performance vs expectation (Section 4.3).Metric ∆ Knowledge 
Empirical 
Expected 
p-value t-stat 
Remarks 
∆FDR 1 
inactive 
-0.019 ± 0.002 -0.016 ± 0.002 
0.51 
-0.65 No difference 
∆FDR 1 
active 
-0.008 ± 0.001 -0.006 ± 0.001 
0.21 
-1.25 No difference 
∆FDR 2 
inactive 
-0.023 ± 0.002 -0.025 ± 0.002 
0.60 
0.53 No difference 
∆FDR 2 
active 
-0.011 ± 0.002 -0.010 ± 0.002 
0.75 
-0.32 No difference 
∆TPR 1 
inactive 
-0.007 ± 0.003 -0.002 ± 0.003 
0.22 
-1.23 No difference 
∆TPR 1 
active 
0.024 ± 0.003 
0.022 ± 0.002 
0.48 
0.70 No difference 
∆TPR 2 
inactive 
-0.001 ± 0.003 -0.006 ± 0.003 
0.24 
1.17 No difference 
∆TPR 2 
active 
0.035 ± 0.004 
0.028 ± 0.004 
0.18 
1.34 No difference 
∆FPR 1 
inactive 
-0.023 ± 0.004 -0.021 ± 0.004 
0.62 
-0.50 No difference 
∆FPR 1 
active 
-0.009 ± 0.003 -0.007 ± 0.003 
0.79 
-0.27 No difference 
∆FPR 2 
inactive 
-0.021 ± 0.004 -0.030 ± 0.005 
0.18 
1.34 No difference 
∆FPR 2 
active 
-0.015 ± 0.005 -0.018 ± 0.005 
0.61 
0.51 No difference 
∆SHD 1 
inactive 
-0.033 ± 0.013 -0.047 ± 0.010 
0.36 
0.91 No difference 
∆SHD 1 
active 
-0.072 ± 0.011 -0.056 ± 0.010 
0.30 
-1.04 No difference 
∆SHD 2 
inactive 
-0.082 ± 0.013 -0.086 ± 0.013 
0.82 
0.23 No difference 
∆SHD 2 
active 
-0.126 ± 0.016 -0.100 ± 0.017 
0.28 
-1.09 No difference </p>
<p>Table 10 :
10Full results for inducing knowledge in real data (Section 4.4).
ACKNOWLEDGEMENTSResearch was sponsored by the Army Research Office and was accomplished under Grant Number W911NF-22-1-0035. The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of the Army Research Office or the U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for Government purposes notwithstanding any copyright notation herein.APPENDIX A. Threshold Incorporation and Slack VariablesIn Eq. 5, we have seen that our inequality constraint takes the following form: h p ineq (W (θ)) &gt; 0 where p enumerates over each induced knowledge associated with true active edge (known active) X i → X j imposing [W (θ)] i j = 0. NOTEARS uses a thresholding step that reduces false discoveries where any edge weight below the threshold value, w thresh in its absolute value is set to zero. Thus, for any induction from true active edges (X i → X j ) we have the following constraint:We convert inequality constraints in our optimization to equality by introducing a set of slack variables y p such that:i j +W 2 thresh + y p = 0 s.t. y p ≥ 0 (10) In a similar manner, using the threshold value, W thresh our equality constraints (associated with known inactive edges) take the form as:where q enumerates over each induction associated with true inactive edge X i X j imposing [W (θ)] i j = 0.
Combining experts' causal judgments. D Alrajeh, H Chockler, J Y Halpern, Artificial Intelligence. 288103355Alrajeh, D., Chockler, H., and Halpern, J. Y. (2020). Com- bining experts' causal judgments. Artificial Intelli- gence, 288:103355.</p>
<p>On the completeness of causal discovery in the presence of latent confounding with tiered background knowledge. B Andrews, P Spirtes, G F Cooper, PMLRInternational Conference on Artificial Intelligence and Statistics. Andrews, B., Spirtes, P., and Cooper, G. F. (2020). On the completeness of causal discovery in the presence of la- tent confounding with tiered background knowledge. In International Conference on Artificial Intelligence and Statistics, pages 4002-4011. PMLR.</p>
<p>Nonlinear programming. D P Bertsekas, Journal of the Operational Research Society. 483Bertsekas, D. P. (1997). Nonlinear programming. Journal of the Operational Research Society, 48(3):334-334.</p>
<p>Cause-effect association between event pairs in event datasets. D Bhattacharjya, T Gao, N Mattei, D Subramanian, Proceedings of the Twenty-Ninth International Conference on International Joint Conferences on Artificial Intelligence. the Twenty-Ninth International Conference on International Joint Conferences on Artificial IntelligenceBhattacharjya, D., Gao, T., Mattei, N., and Subramanian, D. (2021). Cause-effect association between event pairs in event datasets. In Proceedings of the Twenty-Ninth International Conference on International Joint Con- ferences on Artificial Intelligence, pages 1202-1208.</p>
<p>Aggregating causal judgments. R Bradley, F Dietrich, C List, Philosophy of Science. 814Bradley, R., Dietrich, F., and List, C. (2014). Aggregating causal judgments. Philosophy of Science, 81(4):491- 515.</p>
<p>Learning Bayesian networks is NP-complete. D M Chickering, Learning from data. SpringerChickering, D. M. (1996). Learning Bayesian networks is NP-complete. In Learning from data, pages 121-130. Springer.</p>
<p>Optimal structure identification with greedy search. D M Chickering, Journal of machine learning research. 3Chickering, D. M. (2002). Optimal structure identification with greedy search. Journal of machine learning re- search, 3(Nov):507-554.</p>
<p>Large-sample learning of Bayesian networks is NPhard. M Chickering, D Heckerman, C Meek, Journal of Machine Learning Research. 5Chickering, M., Heckerman, D., and Meek, C. (2004). Large-sample learning of Bayesian networks is NP- hard. Journal of Machine Learning Research, 5.</p>
<p>Learning high-dimensional directed acyclic graphs with latent and selection variables. D Colombo, M H Maathuis, M Kalisch, T S Richardson, The Annals of Statistics. Colombo, D., Maathuis, M. H., Kalisch, M., and Richard- son, T. S. (2012). Learning high-dimensional directed acyclic graphs with latent and selection variables. The Annals of Statistics, pages 294-321.</p>
<p>Causal discovery from data in the presence of selection bias. G Cooper, Proceedings of the Fifth International Workshop on Artificial Intelligence and Statistics. the Fifth International Workshop on Artificial Intelligence and StatisticsCooper, G. (1995). Causal discovery from data in the pres- ence of selection bias. In Proceedings of the Fifth International Workshop on Artificial Intelligence and Statistics, pages 140-150.</p>
<p>The foundations of cost-sensitive learning. C Elkan, International joint conference on artificial intelligence. Lawrence Erlbaum Associates Ltd17Elkan, C. (2001). The foundations of cost-sensitive learn- ing. In International joint conference on artificial in- telligence, volume 17, pages 973-978. Lawrence Erl- baum Associates Ltd.</p>
<p>Low rank directed acyclic graphs and causal structure learning. Z Fang, S Zhu, J Zhang, Y Liu, Z Chen, Y He, arXiv:2006.05691arXiv preprintFang, Z., Zhu, S., Zhang, J., Liu, Y., Chen, Z., and He, Y. (2020). Low rank directed acyclic graphs and causal structure learning. arXiv preprint arXiv:2006.05691.</p>
<p>Causal modeling of twitter activity during Covid-19. O Gencoglu, M Gruber, S Heindorf, Y Scholten, H Wachsmuth, A.-C Ngonga Ngomo, M Potthast, Computation. 8485Gencoglu, O. and Gruber, M. (2020). Causal modeling of twitter activity during Covid-19. Computation, 8(4):85. Heindorf, S., Scholten, Y., Wachsmuth, H., Ngonga Ngomo, A.-C., and Potthast, M. (2020).</p>
<p>Causenet: Towards a causality graph extracted from the web. Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management. the 29th ACM International Conference on Information &amp; Knowledge ManagementCausenet: Towards a causality graph extracted from the web. In Proceedings of the 29th ACM Inter- national Conference on Information &amp; Knowledge Management, pages 3023-3030.</p>
<p>Interactive machine learning for health informatics: when do we need the human-inthe-loop?. A Holzinger, Brain Informatics. 32Holzinger, A. (2016). Interactive machine learning for health informatics: when do we need the human-in- the-loop? Brain Informatics, 3(2):119-131.</p>
<p>Causal identification under Markov equivalence. A Jaber, J Zhang, E Bareinboim, arXiv:1812.06209arXiv preprintJaber, A., Zhang, J., and Bareinboim, E. (2018). Causal identification under Markov equivalence. arXiv preprint arXiv:1812.06209.</p>
<p>S Lachapelle, P Brouillard, T Deleu, S Lacoste-Julien, arXiv:1906.02226Gradient-based neural DAG learning. arXiv preprintLachapelle, S., Brouillard, P., Deleu, T., and Lacoste-Julien, S. (2019). Gradient-based neural DAG learning. arXiv preprint arXiv:1906.02226.</p>
<p>Building machines that learn and think like people. B M Lake, T D Ullman, J B Tenenbaum, S J Gershman, Behavioral and brain sciences. 40Lake, B. M., Ullman, T. D., Tenenbaum, J. B., and Gersh- man, S. J. (2017). Building machines that learn and think like people. Behavioral and brain sciences, 40.</p>
<p>Guided generation of cause and effect. Z Li, X Ding, T Liu, J E Hu, B Van Durme, arXiv:2107.09846arXiv preprintLi, Z., Ding, X., Liu, T., Hu, J. E., and Van Durme, B. (2021). Guided generation of cause and effect. arXiv preprint arXiv:2107.09846.</p>
<p>Knowledge enhanced event causality identification with mention masking generalizations. J Liu, Y Chen, J Zhao, Proceedings of the Twenty-Ninth International Conference on International Joint Conferences on Artificial Intelligence. the Twenty-Ninth International Conference on International Joint Conferences on Artificial IntelligenceLiu, J., Chen, Y., and Zhao, J. (2021). Knowledge enhanced event causality identification with mention masking generalizations. In Proceedings of the Twenty-Ninth International Conference on International Joint Con- ferences on Artificial Intelligence, pages 3608-3614.</p>
<p>Domain adaptation by using causal inference to predict invariant conditional distributions. S Magliacane, T Van Ommen, T Claassen, S Bongers, P Versteeg, J Mooij, arXiv:1707.06422arXiv preprintMagliacane, S., van Ommen, T., Claassen, T., Bongers, S., Versteeg, P., and Mooij, J. M. (2017). Do- main adaptation by using causal inference to pre- dict invariant conditional distributions. arXiv preprint arXiv:1707.06422.</p>
<p>Masked gradient-based causal structure learning. I Ng, Z Fang, S Zhu, Z Chen, Wang , J , arXiv:1910.08527arXiv preprintNg, I., Fang, Z., Zhu, S., Chen, Z., and Wang, J. (2019). Masked gradient-based causal structure learn- ing. arXiv preprint arXiv:1910.08527.</p>
<p>On the role of sparsity and DAG constraints for learning linear DAGs. I Ng, A Ghassami, K Zhang, arXiv:2006.10201arXiv preprintNg, I., Ghassami, A., and Zhang, K. (2020). On the role of sparsity and DAG constraints for learning linear DAGs. arXiv preprint arXiv:2006.10201.</p>
<p>On the convergence of continuous constrained optimization for structure learning. I Ng, S Lachapelle, N R Ke, S Lacoste-Julien, K Zhang, PMLRInternational Conference on Artificial Intelligence and Statistics. Ng, I., Lachapelle, S., Ke, N. R., Lacoste-Julien, S., and Zhang, K. (2022). On the convergence of continuous constrained optimization for structure learning. In In- ternational Conference on Artificial Intelligence and Statistics, pages 8176-8198. PMLR.</p>
<p>Causal discovery with prior information. R T O&apos;donnell, A E Nicholson, B Han, K B Korb, M J Alam, L R Hope, Australasian Joint Conference on Artificial Intelligence. SpringerO'Donnell, R. T., Nicholson, A. E., Han, B., Korb, K. B., Alam, M. J., and Hope, L. R. (2006). Causal discov- ery with prior information. In Australasian Joint Con- ference on Artificial Intelligence, pages 1162-1167. Springer.</p>
<p>Causality. J Pearl, Cambridge university pressPearl, J. (2009). Causality. Cambridge university press.</p>
<p>A theory of inferred causation. J Pearl, T S Verma, Studies in Logic and the Foundations of Mathematics. Elsevier134Pearl, J. and Verma, T. S. (1995). A theory of inferred cau- sation. In Studies in Logic and the Foundations of Mathematics, volume 134, pages 789-811. Elsevier.</p>
<p>Elements of causal inference: foundations and learning algorithms. J Peters, D Janzing, B Schölkopf, The MIT PressPeters, J., Janzing, D., and Schölkopf, B. (2017). Elements of causal inference: foundations and learning algo- rithms. The MIT Press.</p>
<p>A million variables and more: the Fast Greedy Equivalence Search algorithm for learning high-dimensional graphical causal models, with an application to functional magnetic resonance images. J Ramsey, M Glymour, R Sanchez-Romero, C Glymour, International journal of data science and analytics. 32Ramsey, J., Glymour, M., Sanchez-Romero, R., and Gly- mour, C. (2017). A million variables and more: the Fast Greedy Equivalence Search algorithm for learn- ing high-dimensional graphical causal models, with an application to functional magnetic resonance im- ages. International journal of data science and ana- lytics, 3(2):121-129.</p>
<p>Beware of the simulated dag! causal discovery benchmarks may be easy to game. A Reisach, C Seiler, S Weichwald, Advances in Neural Information Processing Systems. 34Reisach, A., Seiler, C., and Weichwald, S. (2021). Beware of the simulated dag! causal discovery benchmarks may be easy to game. Advances in Neural Information Processing Systems, 34:27772-27784.</p>
<p>Causal protein-signaling networks derived from multiparameter single-cell data. K Sachs, O Perez, D Pe&apos;er, D A Lauffenburger, G P Nolan, Science. 3085721Sachs, K., Perez, O., Pe'er, D., Lauffenburger, D. A., and Nolan, G. P. (2005). Causal protein-signaling net- works derived from multiparameter single-cell data. Science, 308(5721):523-529.</p>
<p>M Scutari, arXiv:0908.3817Learning bayesian networks with the bnlearn r package. arXiv preprintScutari, M. (2009). Learning bayesian networks with the bnlearn r package. arXiv preprint arXiv:0908.3817.</p>
<p>Dowhy: An endto-end library for causal inference. A Sharma, E Kiciman, arXiv:2011.04216arXiv preprintSharma, A. and Kiciman, E. (2020). Dowhy: An end- to-end library for causal inference. arXiv preprint arXiv:2011.04216.</p>
<p>Causation, prediction, and search. P Spirtes, C N Glymour, R Scheines, D Heckerman, MIT pressSpirtes, P., Glymour, C. N., Scheines, R., and Heckerman, D. (2000). Causation, prediction, and search. MIT press.</p>
<p>Dags with no fears: A closer look at continuous optimization for learning bayesian networks. D Wei, T Gao, Yu , Y , arXiv:2010.09133arXiv preprintWei, D., Gao, T., and Yu, Y. (2020). Dags with no fears: A closer look at continuous optimization for learning bayesian networks. arXiv preprint arXiv:2010.09133.</p>
<p>Accelerating human-inthe-loop machine learning: Challenges and opportunities. D Xin, L Ma, J Liu, S Macke, S Song, A Parameswaran, Proceedings of the second workshop on data management for end-to-end machine learning. the second workshop on data management for end-to-end machine learningXin, D., Ma, L., Liu, J., Macke, S., Song, S., and Parameswaran, A. (2018). Accelerating human-in- the-loop machine learning: Challenges and opportu- nities. In Proceedings of the second workshop on data management for end-to-end machine learning, pages 1-4.</p>
<p>A study on interaction in human-in-the-loop machine learning for text analytics. Y Yang, E Kandogan, Y Li, P Sen, W S Lasecki, IUI Workshops. Yang, Y., Kandogan, E., Li, Y., Sen, P., and Lasecki, W. S. (2019). A study on interaction in human-in-the-loop machine learning for text analytics. In IUI Workshops.</p>
<p>DAG-GNN: DAG structure learning with graph neural networks. Y Yu, J Chen, T Gao, Yu , M , PMLRInternational Conference on Machine Learning. Yu, Y., Chen, J., Gao, T., and Yu, M. (2019). DAG-GNN: DAG structure learning with graph neural networks. In International Conference on Machine Learning, pages 7154-7163. PMLR.</p>
<p>Learning and evaluating classifiers under sample selection bias. B Zadrozny, Proceedings of the twenty-first international conference on Machine learning. the twenty-first international conference on Machine learning114Zadrozny, B. (2004). Learning and evaluating classi- fiers under sample selection bias. In Proceedings of the twenty-first international conference on Machine learning, page 114.</p>
<p>K Zhang, S Zhu, M Kalander, I Ng, J Ye, Z Chen, L Pan, arXiv:2111.15155gcastle: A python toolbox for causal discovery. arXiv preprintZhang, K., Zhu, S., Kalander, M., Ng, I., Ye, J., Chen, Z., and Pan, L. (2021). gcastle: A python toolbox for causal discovery. arXiv preprint arXiv:2111.15155.</p>
<p>. X Zheng, B Aragam, P Ravikumar, E P Xing, Zheng, X., Aragam, B., Ravikumar, P., and Xing, E. P. (2018).</p>
<p>arXiv:1803.01422DAGs with no tears: Continuous optimization for structure learning. arXiv preprintDAGs with no tears: Continuous op- timization for structure learning. arXiv preprint arXiv:1803.01422.</p>
<p>Learning sparse nonparametric DAGs. X Zheng, C Dan, B Aragam, P Ravikumar, E Xing, PMLRInternational Conference on Artificial Intelligence and Statistics. Zheng, X., Dan, C., Aragam, B., Ravikumar, P., and Xing, E. (2020). Learning sparse nonparametric DAGs. In International Conference on Artificial Intelligence and Statistics, pages 3414-3425. PMLR.</p>            </div>
        </div>

    </div>
</body>
</html>