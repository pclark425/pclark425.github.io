<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2338 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2338</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2338</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-63.html">extraction-schema-63</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <p><strong>Paper ID:</strong> paper-257405271</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2303.04217v1.pdf" target="_blank">AI for Science: An Emerging Agenda</a></p>
                <p><strong>Paper Abstract:</strong> This report documents the programme and the outcomes of Dagstuhl Seminar 22382"Machine Learning for Science: Bridging Data-Driven and Mechanistic Modelling". Today's scientific challenges are characterised by complexity. Interconnected natural, technological, and human systems are influenced by forces acting across time- and spatial-scales, resulting in complex interactions and emergent behaviours. Understanding these phenomena -- and leveraging scientific advances to deliver innovative solutions to improve society's health, wealth, and well-being -- requires new ways of analysing complex systems. The transformative potential of AI stems from its widespread applicability across disciplines, and will only be achieved through integration across research domains. AI for science is a rendezvous point. It brings together expertise from $\mathrm{AI}$ and application domains; combines modelling knowledge with engineering know-how; and relies on collaboration across disciplines and between humans and machines. Alongside technical advances, the next wave of progress in the field will come from building a community of machine learning researchers, domain experts, citizen scientists, and engineers working together to design and deploy effective AI tools. This report summarises the discussions from the seminar and provides a roadmap to suggest how different communities can collaborate to deliver a new wave of progress in AI and its application for scientific discovery.</p>
                <p><strong>Cost:</strong> 0.034</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2338.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2338.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Poultry-CNN</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Deep convolutional neural networks for poultry fecal image disease diagnosis</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Farm- and lab-annotated fecal-image dataset used to train CNN classifiers (VGG16, InceptionV3, MobileNetV2, Xception) to detect poultry diseases (Coccidiosis, Salmonella, Newcastle) from smartphone images, with lightweight models prioritized for mobile deployment.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Poultry diseases diagnostics models using deep learning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Agricultural/veterinary diagnostics (poultry disease surveillance)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Enable rapid, farm-level diagnosis of common poultry diseases from images of feces to reduce time-to-diagnosis and prevent flock loss where lab testing is slow or inaccessible.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Moderate: authors collected 1,255 laboratory-labeled fecal images (with PCR diagnostics) and 6,812 farm-captured photos annotated by agricultural experts; labels exist (multi-class) but dataset size is limited relative to modern vision corpora and likely imbalanced across classes.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Unstructured images (RGB photos) captured in heterogeneous farm conditions; labeled multi-class; mobile-phone-resolution variability and domain shift between lab and farm images.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Medium: visual classification with non-trivial intra-class variability and noise from imaging conditions; model must generalize across farms and devices; computational constraints for on-device inference.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Applied but emerging: veterinary diagnostics is established but automated image-based fecal diagnosis is novel in this context; domain expertise used for annotation and validation.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Medium - practical deployment requires interpretable, robust predictions (high-stakes for farmers), but mechanistic biological causality is not strictly required for the classifier to be useful; explainability and confidence calibration are important.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Convolutional Neural Networks (VGG16, InceptionV3, MobileNetV2, Xception) with transfer learning and fine-tuning</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Baseline CNN and several standard vision architectures were trained on combined lab- and farm-labeled images; models were fine-tuned (with batch-norm layers sometimes frozen) and evaluated on farm-labeled test set; MobileNetV2 selected for deployment due to light weight and generalization properties.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Supervised deep learning (transfer learning / fine-tuning)</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>High applicability: image classification is a natural formulation; mobile deployment constraints motivated model choice (MobileNetV2). Limitations include limited labeled data, domain shift (lab vs farm), and need for careful calibration and UX design to incentivize farmer use.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td>Reported test accuracies (farm-labeled test set): baseline CNN 83.06%, VGG16 85.85%, InceptionV3 94.79%, MobileNetV2 87.46%, Xception 88.27%; after fine-tuning with batch-norm freezing: VGG16 95.01%, InceptionV3 95.45%, MobileNetV2 98.02%, Xception 98.24%; F1 scores >75% across four classes.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Models achieved high accuracy after fine-tuning; MobileNetV2 recommended for deployment due to lightweight architecture and good generalization; open questions remain about field robustness, incentive structures for farmer uptake, and deployment logistics.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>High potential impact in low-resource settings: faster on-farm diagnosis could reduce flock losses, accelerate interventions, and decentralize disease surveillance; scalable via mobile app but dependent on sustained data collection and validation.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared multiple standard CNN architectures; fine-tuning markedly improved performance relative to baseline training; MobileNetV2 favored over larger models due to compute/weight trade-offs for on-device inference.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Availability of paired lab-confirmed labels to ground truth farm images, expert annotation, transfer learning from pre-trained vision models, and engineering choices for lightweight inference (MobileNetV2) contributed to success; potential failure factors include domain shift, limited diversity of data, and deployment incentives.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Supervised CNNs, when fine-tuned on a modest but well-annotated farm+lab image dataset and constrained for mobile deployment, can deliver high diagnostic accuracy, but success depends critically on ground-truth lab labels, handling domain shift, and choosing architectures appropriate to deployment constraints.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2338.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2338.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Tree-Segmentation-Biomass</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Satellite image segmentation and allometric modelling for tree counting and biomass estimation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Use of fully convolutional neural networks on high-resolution satellite imagery (and 3D LiDAR point-cloud neural nets) to segment tree crowns, count trees across sampling sites (~90,000 labeled trees from 400 sites), and estimate biomass via allometric equations integrated with ML outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>An unexpectedly large count of trees in the west african sahara and sahel</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Environmental monitoring / forestry / carbon accounting</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Estimate number, distribution, canopy area, and biomass of trees across large regions (e.g., West African Sahara and Sahel) to inform ecosystem management and carbon storage estimates.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Moderate: labeled dataset built from satellite images including ~90,000 trees across 400 sampling sites; domain data available but sparse spatially relative to continental scales; additional LiDAR available in some areas for direct biomass inference.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>High-resolution remote-sensing imagery (raster), high-dimensional pixel data, plus optional LiDAR 3D point clouds; labeled segmentation masks for tree crowns; multimodal when combining imagery and LiDAR.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>High: heterogeneous vegetation types, visual confounders (surrounding vegetation), differing sensor resolutions; converting crown metrics to biomass uses separate allometric models introducing propagation of uncertainty over large areas.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Established domain models exist (allometry, forest ecology) but ML-based large-scale mapping is emergent; strong domain expertise required to interpret and combine outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>High for final scientific use: mechanistic/biophysical understanding (allometry) is required to translate pixel-level outputs into biomass and carbon estimates; domain constraints needed to reduce bias.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Fully convolutional neural networks for image segmentation; 3D point-cloud neural networks for LiDAR-based biomass estimation; pipeline integration with allometric models</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Train FCNs to segment tree crowns in satellite imagery, derive canopy areas and tree counts, then apply allometric equations to estimate dry mass/biomass; where LiDAR available, use 3D point-cloud neural networks to directly infer biomass, avoiding DEM dependence.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Supervised deep learning (image segmentation) and hybrid ML-mechanistic integration</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Appropriate: segmentation directly matches the task of crown detection; LiDAR-based networks provide higher accuracy where available; limitations include generalization across vegetation types and propagation of allometric model biases when scaling.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td>Dataset scale: ~90,000 labeled trees across 400 sites; no single aggregate accuracy metric provided in the report, but LiDAR-based 3D networks produce highly accurate results without requiring DEM when available.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Approach enabled detailed mapping and biomass estimates; domain experts were needed to distinguish trees from surrounding vegetation; small per-tree biomass errors can scale to large aggregate biases, requiring careful uncertainty accounting.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>High: enables large-scale monitoring of tree cover and carbon stocks, supporting forestry management, climate policy, and land-use planning; scalable across regions with satellite coverage but sensitive to transferability.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared image segmentation + allometry vs direct LiDAR regression: LiDAR direct inference yields higher accuracy and avoids DEM dependence; allometric approaches vary by tree type and can introduce bias when generalized.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Large labeled sampling set, integration of domain allometry knowledge, expert annotation to guide segmentation, and use of LiDAR where available; success limited by choice/fit of allometric models and spatial coverage of ground truth.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Combining supervised segmentation of remote sensing imagery with domain mechanistic transformations (allometry) can produce scalable biomass estimates, but uncertainty and bias from allometric models and spatial gaps in training labels are primary constraints on accuracy.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2338.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2338.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>FLUXNET-hybrid</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>FLUXNET-style hybrid physics-informed machine learning for global carbon dynamics</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Combining observational flux tower data and physics-informed modelling to produce a data-driven statistical model of global carbon dynamics ('how the Earth breathes'), integrating multi-scale observations with mechanistic process knowledge.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Earth system science / carbon cycle modelling / climate science</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Scale sparse local ecosystem observations of carbon exchange (e.g., from flux towers) to robust global representations of carbon uptake and dynamics to inform climate projections.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Sparse to moderate: local observational coverage exists for some ecosystems, but observational coverage is insufficient to directly scale to global maps without modelling; data are multi-source and heterogeneously labeled.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Multimodal: time-series measurements from flux towers, spatial covariates (vegetation, climate), and mechanistic model outputs; heterogeneous granularity across sites.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Very high: multi-scale interactions (molecular to planetary), nonlinear dynamics, heterogeneity across biospheres, and need to extrapolate beyond observed conditions (dataset shifts due to climate change).</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Highly developed mechanistic models exist (biogeochemical cycle models) and active community (FLUXNET); integrating ML with domain models is an emerging subfield.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>High: preserving physical plausibility and respecting conservation laws is critical for credible global carbon projections; hybrid models that encode physics are preferred.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Hybrid physics-informed machine learning / data-driven emulation integrated with mechanistic models</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Leverage observational data to train statistical components that complement mechanistic process models (e.g., learn parameters or residuals), build emulators/surrogates for components, and integrate across scales to generate simulations.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Physics-informed ML / hybrid modeling / simulation-based inference</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Well-suited: ML can learn empirical patterns and fill observational gaps when combined with mechanistic constraints; limitations include uncertainty management when extrapolating and the need for domain-grounded priors.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td>No single numeric performance metrics provided in the report; FLUXNET-style syntheses are described as producing useful global pictures but sensitive to spatial coverage gaps.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Hybrid approaches improve interpretability and reliability relative to pure statistical models; they enable integrating heterogeneous data but require careful uncertainty quantification and domain collaboration.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>High scientific and policy impact if trusted global carbon dynamics estimates can be produced; supports digital twin ambitions and climate decision-making at different scales.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared conceptually to pure mechanistic or pure statistical modeling: hybrid approaches aim to capture strengths of both; no empirical numeric comparison reported here.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Availability of mechanistic knowledge to constrain models, strategic selection of components to emulate, cross-scale integration methods, and diagnostic checks for computational faithfulness.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Physics-informed hybrid ML is a promising route to scale sparse ecosystem observations to global carbon dynamics, but its effectiveness hinges on integrating mechanistic constraints, managing extrapolation uncertainty, and careful diagnostic validation.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2338.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2338.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Ice-Emulation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Machine learning emulators and surrogate models for ice-sheet and cryosphere simulations</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Use of ML to emulate ice-sheet system components or streamline simulation granularity selection (e.g., deciding appropriate spatial resolution) to accelerate simulations and support coupled ocean-atmosphere-ice analyses.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Cryosphere science / sea-level rise estimation</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Improve computational speed and integration of ice-sheet models with coupled climate components to better estimate ice loss contributions to sea-level rise and facilitate scenario experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Heterogeneous: observational velocity and ice measurements exist but are limited; model simulation outputs available for emulation training but true global observational coverage is lacking.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Spatially-resolved geophysical fields (gridded), time series, and simulation outputs; multi-modal when coupling with ocean/atmosphere models.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Very high: nonlinear continuum mechanics, long-term dynamics, multi-scale coupling (ice-ocean-atmosphere), and sensitivity to resolution choices.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Mature mechanistic modelling tradition (glaciology), but ML emulation is an emerging augmentation; strong domain expertise required.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>High: physical fidelity matters for sea-level estimates; emulators must respect conservation and known physical behaviour to be adopted.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Surrogate modeling / emulation (ML-based) and hybrid ML-mechanistic pipelines</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Train ML surrogates to approximate expensive components of ice-sheet simulations or to select optimal granularity (spatial resolution) for coupled runs; use these to accelerate parameter sweeps or enable integrated simulations.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Simulation emulation / hybrid physics-ML</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Methodologically promising and applicable to reduce compute cost, but domain usefulness depends on whether emulation addresses concrete research needs; some projects succeeded methodologically but lacked clear research questions.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td>No concrete numerical speedup or accuracy metrics provided in the report; success described as mixed—methodologically feasible but variable domain impact.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Emulation can substantially speed components but must target domain-relevant bottlenecks and be validated for physical realism; misalignment with domain questions reduces impact.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Moderate-to-high if focused on domain-relevant components: can enable broader scenario ensembles and sensitivity analyses; risk of misplaced effort if not co-designed with domain scientists.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared conceptually to running full mechanistic models and to simpler downscaling choices; empirical comparisons not provided here.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Clear articulation of domain need, co-design with glaciologists, rigorous validation for physical plausibility, and uncertainty quantification are key to success.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>ML-based emulators can accelerate ice-sheet modelling, but their practical value depends on close alignment with domain research needs, rigorous physical validation, and careful uncertainty accounting.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2338.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2338.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Lens-SBI</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Simulation-based inference and neural models for gravitational lensing and dark matter substructure inference</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Use of mechanistic forward modelling combined with ML-aided inference (simulation-based inference, differentiable probabilistic programming, neural networks for complex source modelling) to extract constraints on dark matter from gravitational lensing observations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Simulation-based approaches to astrophysics dark matter searches</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Astrophysics / cosmology / dark matter inference via strong gravitational lensing</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Infer properties of dark matter substructure (microscopic particle properties) from macroscopic lensing observations, requiring models of lens mass (dark + baryonic), complex background source morphology, and instrument noise.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Observational data abundant in modern surveys but noisy and high-dimensional (images); simulations are used extensively to generate training and likelihood-free inference datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>High-dimensional image data (telescope images), instrument noise characteristics, and forward-simulated realizations of lensing with/without substructure; multi-scale and morphological complexity.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Very high: inverse problem with degenerate solutions; high-dimensional latent space (source morphology, lens parameters, substructure properties); expensive forward simulations.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Observational cosmology and lensing theory mature; application of SBI and differentiable programming is a rapidly developing research area.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>High - scientific interpretability and physically-plausible posterior constraints are required to claim new physics; models must be tethered to astrophysical priors and instrument models.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Simulation-based inference (neural density/ration estimators, differentiable probabilistic programming) combined with neural networks for modelling complex background sources</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Use large suites of forward simulations to train neural density or ratio estimators (likelihood-free inference) and neural source models (e.g., continuous neural fields) to marginalize over complex background morphology; compare simulated outputs to telescope observations to infer dark matter-consistent parameter regions.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Simulation-based inference / likelihood-free inference / hybrid mechanistic-ML</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Highly applicable given the ability to forward-simulate lensing under different dark matter scenarios; challenges include calibration of learned posteriors and ensuring computational faithfulness.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td>No single aggregate numbers provided in the report; authors note rapid progress across models and approaches but highlight need for robustness checks and trustworthy constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Promising: ML helps model complex background sources and accelerates inference, but care is required because SBI methods can yield overconfident posteriors; community is developing conservative estimation methods (e.g., BNRE) and diagnostics.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>High scientific impact if methods yield robust, physically-plausible constraints on dark matter models; can leverage next-generation surveys to test particle physics hypotheses.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Alternative is classical likelihood-based inference with simplified source/lens models, which is often intractable or biased; SBI offers scalability and expressivity but demands new diagnostics to guarantee reliability.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Ability to generate realistic forward simulations, incorporation of instrument noise models, hybridization with physically-motivated priors, and development of conservative SBI diagnostics are central to success.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Combining forward simulations with neural inference and expressive source models enables extraction of dark-matter-sensitive signals from lensing data, but validity depends on robust SBI diagnostics and conservative posterior approximation to avoid overconfident physical claims.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2338.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e2338.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SingleCell-ML</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Machine learning pipelines for single-cell transcriptomics (dimensionality reduction, clustering, trajectory and causal inference)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Application of dimensionality reduction (PCA, variational autoencoders), graph-based clustering, classification, trajectory inference, and causal gene-regulation inference to high-dimensional single-cell RNA-seq data (tens of thousands of cells, ~30k genes).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Single-cell transcriptomics</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Genomics / developmental biology / single-cell transcriptomics</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Reconstruct cell differentiation pathways, cell types, and gene regulatory dynamics from single-cell RNA sequencing to build atlases of development and disease-relevant cell states.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Abundant in some contexts: modern scRNA-seq produces datasets with tens of thousands of cells per experiment but may have batch effects and technical artefacts; labeled cell-type annotations can be limited.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>High-dimensional sparse count data (genes × cells), often preprocessed (normalization), with batch structure and multimodal metadata; graphs used for relationships.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>High: very high dimensionality (~30k genes), sparsity, technical noise (dropouts), batch effects, and complex branching trajectories; many downstream steps form long analysis pipelines.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Rapidly maturing: experimental protocols and analysis toolkits are established, but methodological benchmarking and pipeline robustness remain active issues.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>High for scientific insight: interpretability and causal inference (gene regulation mechanisms) are often desired beyond black-box clustering, and correcting batch effects must preserve biology.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Dimensionality reduction (PCA, variational autoencoders), graph-based clustering, trajectory inference (diffusion pseudotime), causal inference methods; deep learning for integration and denoising</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Use unsupervised and semi-supervised ML methods to reduce dimensionality, cluster cells into types, infer developmental trajectories, correct batch effects (regression, graph methods, deep learning), and apply causal inference pipelines to identify putative regulatory drivers.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Unsupervised / semi-supervised learning, representation learning, causal inference</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Highly applicable: ML is essential for handling scale and noise in scRNA-seq; benchmarking is required to select appropriate integration and correction methods for specific downstream objectives.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td>No single metric provided in the report; referenced benchmarking studies (e.g., atlas-level benchmarking) exist to compare integration methods; performance depends strongly on pipeline choices and evaluation criteria.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>ML methods enable reconstruction of lineage and cell-type structure and have been applied successfully in diverse studies; challenges include preserving biologically relevant signals while removing technical confounders and choosing appropriate benchmarks.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>High: enables creation of cell atlases, identification of disease-associated cell states, and potential clinical translations; reproducibility and validation remain essential for trustworthy biological conclusions.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Many integration methods (regression, dimensionality reduction, deep learning, graph-based) exist; benchmarking is needed to determine the best method for a given task, and no single method universally dominates.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>High-quality experimental design, careful preprocessing and batch-correction, domain expertise for validation, and use of benchmarking frameworks to select methods are keys to success.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Representation learning and graph-based ML are indispensable for extracting developmental trajectories and cell-type structure from high-dimensional single-cell data, but scientific validity requires careful artifact correction, benchmarking, and interpretability to translate ML outputs into biological insight.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2338.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e2338.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SBI-NeuralRatio/BNRE</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Simulation-based inference with neural density/rate estimators and conservative variants (Balanced Neural Ratio Estimation)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Neural density/ration estimators are trained on simulation output to approximate posteriors for complex mechanistic models (likelihood-free inference); Balanced Neural Ratio Estimation (BNRE) is a variant designed to produce more conservative posterior approximations to avoid overconfidence.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Towards reliable simulation-based inference and beyond</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Broad (astrophysics, particle physics, neuroscience, systems biology) - any domain with expensive forward simulators and intractable likelihoods</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Infer model parameters for mechanistic simulators where likelihood functions are intractable by training neural estimators on simulated data to approximate posterior distributions.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Varies by domain: relies heavily on ability to generate large numbers of simulations (compute-bound) rather than labeled observational datasets; observed data required for posterior conditioning.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Simulation outputs are often high-dimensional (images, time-series, summary statistics); paired parameter-simulation datasets used for supervised training of density/ration estimators.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>High: intractable likelihoods, high-dimensional observations and latent spaces, potential model misspecification, and need for uncertainty quantification.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Rapidly maturing: SBI methods have seen rapid adoption across scientific domains, but trustworthiness and diagnostics are active research concerns.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>High: users require calibrated, interpretable posteriors connected to mechanistic model assumptions; overconfident posteriors are a key risk.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Neural density estimation / neural ratio estimation / neural posterior estimation; Balanced Neural Ratio Estimation (BNRE) for conservative posteriors</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Train deep neural networks (density/ratiometric classifiers) on paired (parameters, simulated data) to approximate posterior or likelihood ratios; BNRE modifies training or objective to bias approximations towards conservative (less overconfident) estimates; active learning can be used to allocate simulation budget efficiently.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Likelihood-free inference / simulation-based inference / deep generative modeling</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Highly applicable for complex simulators; caveats include computational expense for large simulation budgets and risk of unfaithful posterior approximations without diagnostic checks.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td>Specific numerical performance varies by application; reported community concerns include occurrences of overconfident posteriors (Hermans et al. 2021) and improvements via BNRE (qualitative claims of increased conservatism).</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Enables parameter inference where classical likelihood-based inference is infeasible; but contemporary methods can produce unreliable posteriors without checks; BNRE and diagnostic methods improve trustworthiness.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>High: opens inference for complex mechanistic models across sciences, enabling parameter estimation and hypothesis testing previously intractable; trustworthy adoption requires diagnostics and conservative methods.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Alternatives include approximate Bayesian computation (ABC) and MCMC on approximated likelihoods; SBI neural methods scale better but can be less calibrated; BNRE attempts to trade some sharpness for reliability.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Large, realistic simulation datasets, careful choice of summary statistics or representation, conservative estimation strategies (BNRE), and rigorous diagnostic checks for computational faithfulness are keys to success.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Neural SBI methods permit likelihood-free parameter inference for complex simulators, but maintaining calibrated, conservative posteriors requires methodological safeguards (e.g., BNRE) and domain-targeted diagnostic checks.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2338.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e2338.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SchroedingerBridge-Diffusion</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Schrödinger bridge formulations and diffusion-based models for generative modelling and inference</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Formulation of diffusion-based generative models and inference as a Schrödinger bridge problem, solved via iterative algorithms (IPF/Sinkhorn) or ML approximations to find most likely stochastic evolution between two distributions given a reference process.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Solving schrödinger bridges via maximum likelihood</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Generative modelling, sampling, probabilistic inference applicable across scientific domains (e.g., inverse problems, density estimation, sampling)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Construct expressive generative models and sampling algorithms by framing generation as finding stochastic interpolations (bridges) between initial and target distributions, enabling complex sampling and inference tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Depends on application; diffusion approaches generally require adequate data for learning score functions or transition dynamics; can also be combined with prior stochastic processes.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Typically high-dimensional continuous data (images, continuous fields, distributions); methods operate on probability distributions rather than labeled pairs.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>High: learning high-dimensional continuous transformations, stability of iterative training (score matching), and computational cost of iterative refinements.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Rapidly developing in ML; emerging applications in scientific inference and sampling.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Low-to-medium depending on use: when used as black-box samplers, mechanistic insight is limited; when combined with domain knowledge (reference processes), more interpretability is possible.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Diffusion models / Schrödinger bridge-based generative models (iterative proportional fitting, score-based methods)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Frame generation as optimizing a stochastic evolution between two distributions and train neural networks to parameterize drift or score functions; algorithms leverage IPF/Sinkhorn and maximum-likelihood formulations to solve SBP approximations.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Generative modeling / probabilistic inference / likelihood-based diffusion methods</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Applicable across many inference and generative tasks, particularly where complex continuous distributions need to be modelled or sampled; requires computational resources and careful training.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td>No single quantitative metric provided in report; cited works show competitive results in generative modeling benchmarks compared to other approaches.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Provides a unifying theoretical lens linking inference, sampling, and optimal transport; practical implementations demonstrate competitive generative quality and flexibility for inference tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Significant for building flexible samplers and generative models in scientific domains (e.g., inverse problems, density estimation), especially where principled stochastic interpolations are useful.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Related to score-based diffusion models and optimal transport approaches; SBP unifies heuristics and allows borrowing techniques across fields (sampling, transport, inference).</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Robust training of score/drift networks, computational budget for iterative procedures, and leveraging problem structure (reference dynamics) help success.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Viewing diffusion generative models through the Schrödinger bridge lens unifies sampling and inference, enabling principled construction of stochastic interpolations that can be leveraged across scientific inverse and generative tasks.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2338.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e2338.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PDE-VB</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Variational Bayes for inverse problems in partial differential equations</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Applying Variational Bayes (VB) as a computationally tractable alternative to MCMC for Bayesian inverse problems governed by PDEs, enabling parameter inference for large-scale engineering and geophysical problems (e.g., material properties, ice sheet modelling).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Partial differential equations and Variational Bayes</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Computational engineering / geophysics / ice-sheet and ice-core modelling</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Infer spatially-distributed or material parameters in PDE-governed systems from noisy observations, where direct posterior sampling (MCMC) is computationally infeasible.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Problem-dependent: observational data may be limited and noisy; forward PDE solvers can generate simulations but are costly, motivating efficient inference approximations.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Structured scientific data (spatially-distributed measurements, time series) coupled with PDE model outputs; posterior is over functional parameters or fields.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Very high: ill-posed inverse problems, high-dimensional parameter spaces (fields), computationally expensive forward solves, and need for regularization/prior structure.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Mature mathematical theory for PDE inverse problems exists; application of VB as scalable inference tool is emerging and gaining traction.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>High: mechanistic PDE models are central and domain priors are crucial; interpretability is necessary for scientific conclusions.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Variational Bayes approximations to Bayesian inverse problems, probabilistic programming, generative models</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Pose posterior approximation as optimization over a tractable variational family instead of sampling; apply VB in conjunction with probabilistic programming languages to infer parameters of PDE models; trade-off between approximation quality and computational tractability.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Bayesian inference / variational inference / probabilistic numerics</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Appropriate for large-scale PDE inverse problems where MCMC is infeasible; VB yields faster approximate posteriors but may underestimate uncertainty and requires careful choice of variational family.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td>No single numeric metrics provided here; the report notes VB is computationally tractable for large problems where MCMC is infeasible.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>VB enables practical inference at scale but has shortcomings (approximation bias); limitations of probabilistic programming languages and differentiable formulations were highlighted.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>High for engineering and geophysical parameter estimation where scale forbids MCMC; facilitates integration of data with mechanistic PDE models.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared to MCMC (gold standard) — VB is computationally cheaper but introduces approximation error; comparisons should weigh tractability vs posterior fidelity.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Choosing expressive variational families, problem-specific regularization/prior knowledge, differentiable solvers, and careful diagnostics to assess approximation fidelity are crucial.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Variational Bayes provides a tractable pathway to Bayesian inverse inference for large-scale PDE problems, enabling practical parameter estimation when MCMC is infeasible, but requires careful control of approximation bias and diagnostics.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2338.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e2338.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ProbNum-ODE</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Probabilistic numerics and ODE filters/smoothers for mechanistic modelling</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Probabilistic numerical methods (PN) treat numerical tasks (ODE solution, integration) as statistical inference problems, using ODE filters and smoothers to produce uncertainty-aware numerical solutions and facilitate joint inference of mechanistic model parameters and states.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Probabilistic Numerics: Computation as Machine Learning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Mechanistic modelling across sciences (dynamical systems, systems biology, physics)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Solve ODE-governed mechanistic models while accounting for numerical uncertainty and enable joint inference of parameters and states in a Bayesian framework.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Problem-dependent: requires observational time-series data for parameter/state inference; ODE solvers produce approximate trajectories used within the PN framework.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Time series of measurements and mechanistic ODE models; state-space representations amenable to filtering/smoothing.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Medium-to-high: nonlinear ODEs with uncertain parameters, irregular sampling, and noise; traditional deterministic solvers ignore numerical uncertainty propagated into inference.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Emerging methodological field with established theoretical foundations; increasing adoption in mechanistic modeling applications.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>High: methods explicitly leverage mechanistic ODE structure and are used to quantify uncertainty in mechanistic inference.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Probabilistic numerics (ODE filters and smoothers / Bayesian ODE solvers / Gaussian-process-based solvers)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Formulate numerical solution of ODEs as Bayesian inference; use filtering/smoothing algorithms to obtain posterior distributions over solution trajectories and incorporate these into downstream parameter inference workflows.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Probabilistic numerics / Bayesian inference</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Highly applicable for mechanistic models where uncertainty quantification of numerical error matters; useful for joint parameter-state estimation in noisy data settings.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td>No single numeric measure reported in the report; methods shown to enable uncertainty-aware numerical solutions and facilitate parameter inference in example applications.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Adds principled uncertainty quantification to numerical solutions, improving downstream inference robustness; computational overhead relative to deterministic solvers is a consideration.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Moderate-to-high for scientific domains reliant on ODE modelling (systems biology, neuroscience), enabling more honest propagation of solver uncertainty into scientific conclusions.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared to classical deterministic ODE solvers followed by separate inference — probabilistic numerics yields joint, uncertainty-aware solutions but at higher computational cost.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Accurate modeling of solver error via expressive priors, computational efficiency of filtering algorithms, and integration with parameter inference pipelines.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Treating numerical solution of mechanistic ODEs as an inference problem provides principled uncertainty estimates for downstream scientific inference, improving robustness when solver error is non-negligible.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2338.10">
                <h3 class="extraction-instance">Extracted Data Instance 10 (e2338.10)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LatentForce-GP</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Latent force models: Gaussian processes informed by differential operators</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Latent force models combine Gaussian process priors with mechanistic differential operators (via Green's functions) to yield 'grey-box' models that incorporate mechanistic structure and learn latent forcing functions from data.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Linear latent force models using Gaussian processes</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Grey-box modeling across engineering, ecology, and systems biology</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Integrate partial mechanistic knowledge (differential operator structure) with data-driven latent force estimation to model complex systems where some physics is known but forcing terms are unknown.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Varies: typically uses observational time-series or spatial data; GP frameworks can work with limited data but Bayesian inference benefits from adequate observations.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Time-series or spatially-resolved measurements; models combine linear/nonlinear differential operators with GP-modeled latent functions.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Medium-to-high: complexity arises from solving convolution integrals with Green's functions and inferring latent functions in potentially high-dimensional spaces.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Established research area with multiple extensions (nonlinear, black-box inference) and cross-domain applications; growing practical adoption.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Medium-high: relies on known differential operator structure; interpretability stems from mechanistic components.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Latent force models (Gaussian process priors convolved with Green's functions of differential operators)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Construct covariance functions by integrating Green's functions of mechanistic differential operators with covariance of latent forcings; perform Bayesian inference (GP regression/inversion) to learn latent forces and system responses.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Hybrid physics-ML / Gaussian process regression</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Well-suited for 'grey-box' problems where mechanistic operators are known but forcing terms are unknown or partially observed.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td>No single metric provided in report; referenced TPAMI and ICML works demonstrate applicability with favorable predictive performance in multiple domains.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Provides interpretable, physics-consistent models able to extrapolate better than purely data-driven models when mechanistic structure is informative.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>High for domains with partial mechanistic knowledge: enables principled integration of theory and data with uncertainty quantification.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Outperforms purely data-driven models when operator structure constrains dynamics; compared to full mechanistic models, latent force models allow data-driven estimation of unknown forcings.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Availability of correct mechanistic operator specification, expressive GP kernels, and scalable inference methods for large datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Latent force models effectively bridge mechanistic differential equations and data-driven learning, enabling interpretable inference of unknown forcings while respecting known system structure.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2338.11">
                <h3 class="extraction-instance">Extracted Data Instance 11 (e2338.11)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Virtual-Lab-Centaurs</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Virtual laboratories and AI 'scientific centaurs' (AI sidekicks for experimental design and automation)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Concept and prototypes for virtual laboratories that integrate measurement devices, simulations, and AI-driven decision-making, paired with AI assistants (centaurs) that help domain experts design and run experiments, elicit tacit knowledge, and operate with partial or evolving goals.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Virtual laboratories for science, assisted by collaborative AI</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Cross-domain (drug discovery, experimental sciences, lab automation)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Accelerate experimental cycles and decision-making in labs by simulating experiments, proposing actions, and assisting human researchers with task planning and information elicitation.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Varies: virtual labs require integration of instrument data streams, simulation outputs, and historical experimental records; data richness depends on lab digitization level.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Multimodal: time-series instrument metadata, experimental protocols, simulation outputs, textual experiment notes; often semi-structured.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>High socio-technical complexity: coordinating multi-agent planning, partial observability, variable user goals, and integration with lab hardware and safety constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Conceptual and early-stage prototyping; research on AI assistants and virtual labs is emerging but not yet broadly standardized in domains.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Medium-to-high: assistants must model domain processes sufficiently to propose informative experiments while remaining interpretable and aligned with expert priors.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Multi-agent decision-making, Bayesian reinforcement learning (Bayes-adaptive POMDPs), generative user models, active knowledge elicitation</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Design agents that model user goals and uncertain experiment outcomes, leverage virtual lab simulators to plan experiments, use active elicitation to incorporate expert knowledge and adapt to evolving objectives, and combine reinforcement learning with Bayesian updates for decision-making.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Reinforcement learning / active learning / human-AI collaboration</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Promising for accelerating iterative experimental workflows; practical adoption requires robust integration with lab infrastructure and elicitation of domain tacit knowledge.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td>No quantitative field metrics reported; conceptual prototypes and prior work indicate potential for speeding design cycles but empirical validation is ongoing.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Potential to scale experimental throughput and capture tacit expertise; challenges include user trust, explainability, and aligning AI proposals with human values and safety.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>High long-term: could materially speed discovery (e.g., drug discovery), democratize lab expertise, and reduce repetitive manual tasks, subject to careful human-AI interface design.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Alternatives include manual experiment design and automated high-throughput platforms without intelligent planning; virtual labs add decision intelligence and adaptive planning.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>High-quality simulation fidelity, effective human-AI interfaces, mechanisms for eliciting and encoding expert tacit knowledge, and institutional adoption incentives.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Virtual laboratories and AI sidekicks can amplify scientific productivity by combining simulation-driven planning with interactive knowledge elicitation, but real-world impact requires robust UX, trust-building, and integration with laboratory practices.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2338.12">
                <h3 class="extraction-instance">Extracted Data Instance 12 (e2338.12)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Building-Mapping-VectorRisk</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Satellite-building-feature extraction for vector-borne disease risk mapping</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Application of satellite imagery analysis tools to extract building features at household and city scales and investigate relationships between built environment characteristics (e.g., roofing material) and mosquito prevalence/malaria risk.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Mapping africa's buildings with satellite imagery</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Epidemiology / public health (vector-borne disease risk mapping)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Characterize built-environment features that correlate with vector presence to inform public-health interventions and risk mapping for diseases like malaria.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Moderate: large-scale satellite imagery and building maps are available (e.g., Google/other mapping projects); health outcome and entomological data may be more limited and spatially heterogenous.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>High-resolution satellite imagery (raster), extracted building footprints/features (vector), linked to epidemiological/geospatial datasets at household or neighborhood scales.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Medium: causal inference complicated by confounding (socioeconomic factors), spatial heterogeneity, and measurement noise in remotely-sensed proxies.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Emerging application of ML to epidemiology with existing remote-sensing pipelines; domain expertise required to interpret correlational findings for policy.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>High for policy translation: mechanistic insight into why features affect vector ecology is desirable to avoid spurious policy actions; interpretability and fairness considerations are crucial.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Image-based building detection/feature extraction (CNNs / segmentation) and spatial statistical analysis linking features to disease prevalence</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Use pretrained or custom CNNs/segmentation models to detect buildings and extract roofing/material features from satellite imagery, aggregate features across scales, and correlate or model relationships with vector prevalence and disease incidence.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Supervised deep learning (remote sensing) + spatial statistical modelling / epidemiological analysis</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Appropriate: satellite-based feature extraction is well-suited for large-scale mapping, but inferences about disease risk require careful confounder control and local validation.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td>Report references show associations (e.g., metal roofing associated with lower mosquito prevalence) but no universal numeric performance metrics in the report; mapping products have been produced at continental scale.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Enables multi-scale analyses linking environmental features to disease risk; warns that assimilation of such features into policy pipelines can hide assumptions and risk marginalizing communities if not handled ethically.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Moderate-to-high: supports targeted interventions and surveillance in resource-limited settings, but must be combined with local validation and equitable policy design.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Alternative is ground-based surveys which are accurate but costly and slow; satellite-based methods are scalable but need ground-truthing for causal interpretation.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>High-quality labeled building datasets, integration with epidemiological data, domain expertise to control confounding, and transparent communication about assumptions and limitations.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Remote-sensing feature extraction via ML provides scalable proxies for built-environment risk factors tied to vector-borne diseases, but translating correlations into actionable, equitable policy requires mechanistic validation and careful handling of assumptions.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Poultry diseases diagnostics models using deep learning <em>(Rating: 2)</em></li>
                <li>An unexpectedly large count of trees in the west african sahara and sahel <em>(Rating: 2)</em></li>
                <li>Solving schrödinger bridges via maximum likelihood <em>(Rating: 2)</em></li>
                <li>Linear latent force models using Gaussian processes <em>(Rating: 2)</em></li>
                <li>The frontier of simulation-based inference <em>(Rating: 2)</em></li>
                <li>Towards reliable simulation-based inference with balanced neural ratio estimation <em>(Rating: 2)</em></li>
                <li>Real-time gravitational wave science with neural posterior estimation <em>(Rating: 2)</em></li>
                <li>Probabilistic Numerics: Computation as Machine Learning <em>(Rating: 2)</em></li>
                <li>Mapping africa's buildings with satellite imagery <em>(Rating: 1)</em></li>
                <li>Virtual laboratories: Transforming research with ai <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2338",
    "paper_id": "paper-257405271",
    "extraction_schema_id": "extraction-schema-63",
    "extracted_data": [
        {
            "name_short": "Poultry-CNN",
            "name_full": "Deep convolutional neural networks for poultry fecal image disease diagnosis",
            "brief_description": "Farm- and lab-annotated fecal-image dataset used to train CNN classifiers (VGG16, InceptionV3, MobileNetV2, Xception) to detect poultry diseases (Coccidiosis, Salmonella, Newcastle) from smartphone images, with lightweight models prioritized for mobile deployment.",
            "citation_title": "Poultry diseases diagnostics models using deep learning",
            "mention_or_use": "use",
            "scientific_problem_domain": "Agricultural/veterinary diagnostics (poultry disease surveillance)",
            "problem_description": "Enable rapid, farm-level diagnosis of common poultry diseases from images of feces to reduce time-to-diagnosis and prevent flock loss where lab testing is slow or inaccessible.",
            "data_availability": "Moderate: authors collected 1,255 laboratory-labeled fecal images (with PCR diagnostics) and 6,812 farm-captured photos annotated by agricultural experts; labels exist (multi-class) but dataset size is limited relative to modern vision corpora and likely imbalanced across classes.",
            "data_structure": "Unstructured images (RGB photos) captured in heterogeneous farm conditions; labeled multi-class; mobile-phone-resolution variability and domain shift between lab and farm images.",
            "problem_complexity": "Medium: visual classification with non-trivial intra-class variability and noise from imaging conditions; model must generalize across farms and devices; computational constraints for on-device inference.",
            "domain_maturity": "Applied but emerging: veterinary diagnostics is established but automated image-based fecal diagnosis is novel in this context; domain expertise used for annotation and validation.",
            "mechanistic_understanding_requirements": "Medium - practical deployment requires interpretable, robust predictions (high-stakes for farmers), but mechanistic biological causality is not strictly required for the classifier to be useful; explainability and confidence calibration are important.",
            "ai_methodology_name": "Convolutional Neural Networks (VGG16, InceptionV3, MobileNetV2, Xception) with transfer learning and fine-tuning",
            "ai_methodology_description": "Baseline CNN and several standard vision architectures were trained on combined lab- and farm-labeled images; models were fine-tuned (with batch-norm layers sometimes frozen) and evaluated on farm-labeled test set; MobileNetV2 selected for deployment due to light weight and generalization properties.",
            "ai_methodology_category": "Supervised deep learning (transfer learning / fine-tuning)",
            "applicability": "High applicability: image classification is a natural formulation; mobile deployment constraints motivated model choice (MobileNetV2). Limitations include limited labeled data, domain shift (lab vs farm), and need for careful calibration and UX design to incentivize farmer use.",
            "effectiveness_quantitative": "Reported test accuracies (farm-labeled test set): baseline CNN 83.06%, VGG16 85.85%, InceptionV3 94.79%, MobileNetV2 87.46%, Xception 88.27%; after fine-tuning with batch-norm freezing: VGG16 95.01%, InceptionV3 95.45%, MobileNetV2 98.02%, Xception 98.24%; F1 scores &gt;75% across four classes.",
            "effectiveness_qualitative": "Models achieved high accuracy after fine-tuning; MobileNetV2 recommended for deployment due to lightweight architecture and good generalization; open questions remain about field robustness, incentive structures for farmer uptake, and deployment logistics.",
            "impact_potential": "High potential impact in low-resource settings: faster on-farm diagnosis could reduce flock losses, accelerate interventions, and decentralize disease surveillance; scalable via mobile app but dependent on sustained data collection and validation.",
            "comparison_to_alternatives": "Compared multiple standard CNN architectures; fine-tuning markedly improved performance relative to baseline training; MobileNetV2 favored over larger models due to compute/weight trade-offs for on-device inference.",
            "success_factors": "Availability of paired lab-confirmed labels to ground truth farm images, expert annotation, transfer learning from pre-trained vision models, and engineering choices for lightweight inference (MobileNetV2) contributed to success; potential failure factors include domain shift, limited diversity of data, and deployment incentives.",
            "key_insight": "Supervised CNNs, when fine-tuned on a modest but well-annotated farm+lab image dataset and constrained for mobile deployment, can deliver high diagnostic accuracy, but success depends critically on ground-truth lab labels, handling domain shift, and choosing architectures appropriate to deployment constraints.",
            "uuid": "e2338.0"
        },
        {
            "name_short": "Tree-Segmentation-Biomass",
            "name_full": "Satellite image segmentation and allometric modelling for tree counting and biomass estimation",
            "brief_description": "Use of fully convolutional neural networks on high-resolution satellite imagery (and 3D LiDAR point-cloud neural nets) to segment tree crowns, count trees across sampling sites (~90,000 labeled trees from 400 sites), and estimate biomass via allometric equations integrated with ML outputs.",
            "citation_title": "An unexpectedly large count of trees in the west african sahara and sahel",
            "mention_or_use": "use",
            "scientific_problem_domain": "Environmental monitoring / forestry / carbon accounting",
            "problem_description": "Estimate number, distribution, canopy area, and biomass of trees across large regions (e.g., West African Sahara and Sahel) to inform ecosystem management and carbon storage estimates.",
            "data_availability": "Moderate: labeled dataset built from satellite images including ~90,000 trees across 400 sampling sites; domain data available but sparse spatially relative to continental scales; additional LiDAR available in some areas for direct biomass inference.",
            "data_structure": "High-resolution remote-sensing imagery (raster), high-dimensional pixel data, plus optional LiDAR 3D point clouds; labeled segmentation masks for tree crowns; multimodal when combining imagery and LiDAR.",
            "problem_complexity": "High: heterogeneous vegetation types, visual confounders (surrounding vegetation), differing sensor resolutions; converting crown metrics to biomass uses separate allometric models introducing propagation of uncertainty over large areas.",
            "domain_maturity": "Established domain models exist (allometry, forest ecology) but ML-based large-scale mapping is emergent; strong domain expertise required to interpret and combine outputs.",
            "mechanistic_understanding_requirements": "High for final scientific use: mechanistic/biophysical understanding (allometry) is required to translate pixel-level outputs into biomass and carbon estimates; domain constraints needed to reduce bias.",
            "ai_methodology_name": "Fully convolutional neural networks for image segmentation; 3D point-cloud neural networks for LiDAR-based biomass estimation; pipeline integration with allometric models",
            "ai_methodology_description": "Train FCNs to segment tree crowns in satellite imagery, derive canopy areas and tree counts, then apply allometric equations to estimate dry mass/biomass; where LiDAR available, use 3D point-cloud neural networks to directly infer biomass, avoiding DEM dependence.",
            "ai_methodology_category": "Supervised deep learning (image segmentation) and hybrid ML-mechanistic integration",
            "applicability": "Appropriate: segmentation directly matches the task of crown detection; LiDAR-based networks provide higher accuracy where available; limitations include generalization across vegetation types and propagation of allometric model biases when scaling.",
            "effectiveness_quantitative": "Dataset scale: ~90,000 labeled trees across 400 sites; no single aggregate accuracy metric provided in the report, but LiDAR-based 3D networks produce highly accurate results without requiring DEM when available.",
            "effectiveness_qualitative": "Approach enabled detailed mapping and biomass estimates; domain experts were needed to distinguish trees from surrounding vegetation; small per-tree biomass errors can scale to large aggregate biases, requiring careful uncertainty accounting.",
            "impact_potential": "High: enables large-scale monitoring of tree cover and carbon stocks, supporting forestry management, climate policy, and land-use planning; scalable across regions with satellite coverage but sensitive to transferability.",
            "comparison_to_alternatives": "Compared image segmentation + allometry vs direct LiDAR regression: LiDAR direct inference yields higher accuracy and avoids DEM dependence; allometric approaches vary by tree type and can introduce bias when generalized.",
            "success_factors": "Large labeled sampling set, integration of domain allometry knowledge, expert annotation to guide segmentation, and use of LiDAR where available; success limited by choice/fit of allometric models and spatial coverage of ground truth.",
            "key_insight": "Combining supervised segmentation of remote sensing imagery with domain mechanistic transformations (allometry) can produce scalable biomass estimates, but uncertainty and bias from allometric models and spatial gaps in training labels are primary constraints on accuracy.",
            "uuid": "e2338.1"
        },
        {
            "name_short": "FLUXNET-hybrid",
            "name_full": "FLUXNET-style hybrid physics-informed machine learning for global carbon dynamics",
            "brief_description": "Combining observational flux tower data and physics-informed modelling to produce a data-driven statistical model of global carbon dynamics ('how the Earth breathes'), integrating multi-scale observations with mechanistic process knowledge.",
            "citation_title": "",
            "mention_or_use": "use",
            "scientific_problem_domain": "Earth system science / carbon cycle modelling / climate science",
            "problem_description": "Scale sparse local ecosystem observations of carbon exchange (e.g., from flux towers) to robust global representations of carbon uptake and dynamics to inform climate projections.",
            "data_availability": "Sparse to moderate: local observational coverage exists for some ecosystems, but observational coverage is insufficient to directly scale to global maps without modelling; data are multi-source and heterogeneously labeled.",
            "data_structure": "Multimodal: time-series measurements from flux towers, spatial covariates (vegetation, climate), and mechanistic model outputs; heterogeneous granularity across sites.",
            "problem_complexity": "Very high: multi-scale interactions (molecular to planetary), nonlinear dynamics, heterogeneity across biospheres, and need to extrapolate beyond observed conditions (dataset shifts due to climate change).",
            "domain_maturity": "Highly developed mechanistic models exist (biogeochemical cycle models) and active community (FLUXNET); integrating ML with domain models is an emerging subfield.",
            "mechanistic_understanding_requirements": "High: preserving physical plausibility and respecting conservation laws is critical for credible global carbon projections; hybrid models that encode physics are preferred.",
            "ai_methodology_name": "Hybrid physics-informed machine learning / data-driven emulation integrated with mechanistic models",
            "ai_methodology_description": "Leverage observational data to train statistical components that complement mechanistic process models (e.g., learn parameters or residuals), build emulators/surrogates for components, and integrate across scales to generate simulations.",
            "ai_methodology_category": "Physics-informed ML / hybrid modeling / simulation-based inference",
            "applicability": "Well-suited: ML can learn empirical patterns and fill observational gaps when combined with mechanistic constraints; limitations include uncertainty management when extrapolating and the need for domain-grounded priors.",
            "effectiveness_quantitative": "No single numeric performance metrics provided in the report; FLUXNET-style syntheses are described as producing useful global pictures but sensitive to spatial coverage gaps.",
            "effectiveness_qualitative": "Hybrid approaches improve interpretability and reliability relative to pure statistical models; they enable integrating heterogeneous data but require careful uncertainty quantification and domain collaboration.",
            "impact_potential": "High scientific and policy impact if trusted global carbon dynamics estimates can be produced; supports digital twin ambitions and climate decision-making at different scales.",
            "comparison_to_alternatives": "Compared conceptually to pure mechanistic or pure statistical modeling: hybrid approaches aim to capture strengths of both; no empirical numeric comparison reported here.",
            "success_factors": "Availability of mechanistic knowledge to constrain models, strategic selection of components to emulate, cross-scale integration methods, and diagnostic checks for computational faithfulness.",
            "key_insight": "Physics-informed hybrid ML is a promising route to scale sparse ecosystem observations to global carbon dynamics, but its effectiveness hinges on integrating mechanistic constraints, managing extrapolation uncertainty, and careful diagnostic validation.",
            "uuid": "e2338.2"
        },
        {
            "name_short": "Ice-Emulation",
            "name_full": "Machine learning emulators and surrogate models for ice-sheet and cryosphere simulations",
            "brief_description": "Use of ML to emulate ice-sheet system components or streamline simulation granularity selection (e.g., deciding appropriate spatial resolution) to accelerate simulations and support coupled ocean-atmosphere-ice analyses.",
            "citation_title": "",
            "mention_or_use": "mention",
            "scientific_problem_domain": "Cryosphere science / sea-level rise estimation",
            "problem_description": "Improve computational speed and integration of ice-sheet models with coupled climate components to better estimate ice loss contributions to sea-level rise and facilitate scenario experiments.",
            "data_availability": "Heterogeneous: observational velocity and ice measurements exist but are limited; model simulation outputs available for emulation training but true global observational coverage is lacking.",
            "data_structure": "Spatially-resolved geophysical fields (gridded), time series, and simulation outputs; multi-modal when coupling with ocean/atmosphere models.",
            "problem_complexity": "Very high: nonlinear continuum mechanics, long-term dynamics, multi-scale coupling (ice-ocean-atmosphere), and sensitivity to resolution choices.",
            "domain_maturity": "Mature mechanistic modelling tradition (glaciology), but ML emulation is an emerging augmentation; strong domain expertise required.",
            "mechanistic_understanding_requirements": "High: physical fidelity matters for sea-level estimates; emulators must respect conservation and known physical behaviour to be adopted.",
            "ai_methodology_name": "Surrogate modeling / emulation (ML-based) and hybrid ML-mechanistic pipelines",
            "ai_methodology_description": "Train ML surrogates to approximate expensive components of ice-sheet simulations or to select optimal granularity (spatial resolution) for coupled runs; use these to accelerate parameter sweeps or enable integrated simulations.",
            "ai_methodology_category": "Simulation emulation / hybrid physics-ML",
            "applicability": "Methodologically promising and applicable to reduce compute cost, but domain usefulness depends on whether emulation addresses concrete research needs; some projects succeeded methodologically but lacked clear research questions.",
            "effectiveness_quantitative": "No concrete numerical speedup or accuracy metrics provided in the report; success described as mixed—methodologically feasible but variable domain impact.",
            "effectiveness_qualitative": "Emulation can substantially speed components but must target domain-relevant bottlenecks and be validated for physical realism; misalignment with domain questions reduces impact.",
            "impact_potential": "Moderate-to-high if focused on domain-relevant components: can enable broader scenario ensembles and sensitivity analyses; risk of misplaced effort if not co-designed with domain scientists.",
            "comparison_to_alternatives": "Compared conceptually to running full mechanistic models and to simpler downscaling choices; empirical comparisons not provided here.",
            "success_factors": "Clear articulation of domain need, co-design with glaciologists, rigorous validation for physical plausibility, and uncertainty quantification are key to success.",
            "key_insight": "ML-based emulators can accelerate ice-sheet modelling, but their practical value depends on close alignment with domain research needs, rigorous physical validation, and careful uncertainty accounting.",
            "uuid": "e2338.3"
        },
        {
            "name_short": "Lens-SBI",
            "name_full": "Simulation-based inference and neural models for gravitational lensing and dark matter substructure inference",
            "brief_description": "Use of mechanistic forward modelling combined with ML-aided inference (simulation-based inference, differentiable probabilistic programming, neural networks for complex source modelling) to extract constraints on dark matter from gravitational lensing observations.",
            "citation_title": "Simulation-based approaches to astrophysics dark matter searches",
            "mention_or_use": "use",
            "scientific_problem_domain": "Astrophysics / cosmology / dark matter inference via strong gravitational lensing",
            "problem_description": "Infer properties of dark matter substructure (microscopic particle properties) from macroscopic lensing observations, requiring models of lens mass (dark + baryonic), complex background source morphology, and instrument noise.",
            "data_availability": "Observational data abundant in modern surveys but noisy and high-dimensional (images); simulations are used extensively to generate training and likelihood-free inference datasets.",
            "data_structure": "High-dimensional image data (telescope images), instrument noise characteristics, and forward-simulated realizations of lensing with/without substructure; multi-scale and morphological complexity.",
            "problem_complexity": "Very high: inverse problem with degenerate solutions; high-dimensional latent space (source morphology, lens parameters, substructure properties); expensive forward simulations.",
            "domain_maturity": "Observational cosmology and lensing theory mature; application of SBI and differentiable programming is a rapidly developing research area.",
            "mechanistic_understanding_requirements": "High - scientific interpretability and physically-plausible posterior constraints are required to claim new physics; models must be tethered to astrophysical priors and instrument models.",
            "ai_methodology_name": "Simulation-based inference (neural density/ration estimators, differentiable probabilistic programming) combined with neural networks for modelling complex background sources",
            "ai_methodology_description": "Use large suites of forward simulations to train neural density or ratio estimators (likelihood-free inference) and neural source models (e.g., continuous neural fields) to marginalize over complex background morphology; compare simulated outputs to telescope observations to infer dark matter-consistent parameter regions.",
            "ai_methodology_category": "Simulation-based inference / likelihood-free inference / hybrid mechanistic-ML",
            "applicability": "Highly applicable given the ability to forward-simulate lensing under different dark matter scenarios; challenges include calibration of learned posteriors and ensuring computational faithfulness.",
            "effectiveness_quantitative": "No single aggregate numbers provided in the report; authors note rapid progress across models and approaches but highlight need for robustness checks and trustworthy constraints.",
            "effectiveness_qualitative": "Promising: ML helps model complex background sources and accelerates inference, but care is required because SBI methods can yield overconfident posteriors; community is developing conservative estimation methods (e.g., BNRE) and diagnostics.",
            "impact_potential": "High scientific impact if methods yield robust, physically-plausible constraints on dark matter models; can leverage next-generation surveys to test particle physics hypotheses.",
            "comparison_to_alternatives": "Alternative is classical likelihood-based inference with simplified source/lens models, which is often intractable or biased; SBI offers scalability and expressivity but demands new diagnostics to guarantee reliability.",
            "success_factors": "Ability to generate realistic forward simulations, incorporation of instrument noise models, hybridization with physically-motivated priors, and development of conservative SBI diagnostics are central to success.",
            "key_insight": "Combining forward simulations with neural inference and expressive source models enables extraction of dark-matter-sensitive signals from lensing data, but validity depends on robust SBI diagnostics and conservative posterior approximation to avoid overconfident physical claims.",
            "uuid": "e2338.4"
        },
        {
            "name_short": "SingleCell-ML",
            "name_full": "Machine learning pipelines for single-cell transcriptomics (dimensionality reduction, clustering, trajectory and causal inference)",
            "brief_description": "Application of dimensionality reduction (PCA, variational autoencoders), graph-based clustering, classification, trajectory inference, and causal gene-regulation inference to high-dimensional single-cell RNA-seq data (tens of thousands of cells, ~30k genes).",
            "citation_title": "Single-cell transcriptomics",
            "mention_or_use": "use",
            "scientific_problem_domain": "Genomics / developmental biology / single-cell transcriptomics",
            "problem_description": "Reconstruct cell differentiation pathways, cell types, and gene regulatory dynamics from single-cell RNA sequencing to build atlases of development and disease-relevant cell states.",
            "data_availability": "Abundant in some contexts: modern scRNA-seq produces datasets with tens of thousands of cells per experiment but may have batch effects and technical artefacts; labeled cell-type annotations can be limited.",
            "data_structure": "High-dimensional sparse count data (genes × cells), often preprocessed (normalization), with batch structure and multimodal metadata; graphs used for relationships.",
            "problem_complexity": "High: very high dimensionality (~30k genes), sparsity, technical noise (dropouts), batch effects, and complex branching trajectories; many downstream steps form long analysis pipelines.",
            "domain_maturity": "Rapidly maturing: experimental protocols and analysis toolkits are established, but methodological benchmarking and pipeline robustness remain active issues.",
            "mechanistic_understanding_requirements": "High for scientific insight: interpretability and causal inference (gene regulation mechanisms) are often desired beyond black-box clustering, and correcting batch effects must preserve biology.",
            "ai_methodology_name": "Dimensionality reduction (PCA, variational autoencoders), graph-based clustering, trajectory inference (diffusion pseudotime), causal inference methods; deep learning for integration and denoising",
            "ai_methodology_description": "Use unsupervised and semi-supervised ML methods to reduce dimensionality, cluster cells into types, infer developmental trajectories, correct batch effects (regression, graph methods, deep learning), and apply causal inference pipelines to identify putative regulatory drivers.",
            "ai_methodology_category": "Unsupervised / semi-supervised learning, representation learning, causal inference",
            "applicability": "Highly applicable: ML is essential for handling scale and noise in scRNA-seq; benchmarking is required to select appropriate integration and correction methods for specific downstream objectives.",
            "effectiveness_quantitative": "No single metric provided in the report; referenced benchmarking studies (e.g., atlas-level benchmarking) exist to compare integration methods; performance depends strongly on pipeline choices and evaluation criteria.",
            "effectiveness_qualitative": "ML methods enable reconstruction of lineage and cell-type structure and have been applied successfully in diverse studies; challenges include preserving biologically relevant signals while removing technical confounders and choosing appropriate benchmarks.",
            "impact_potential": "High: enables creation of cell atlases, identification of disease-associated cell states, and potential clinical translations; reproducibility and validation remain essential for trustworthy biological conclusions.",
            "comparison_to_alternatives": "Many integration methods (regression, dimensionality reduction, deep learning, graph-based) exist; benchmarking is needed to determine the best method for a given task, and no single method universally dominates.",
            "success_factors": "High-quality experimental design, careful preprocessing and batch-correction, domain expertise for validation, and use of benchmarking frameworks to select methods are keys to success.",
            "key_insight": "Representation learning and graph-based ML are indispensable for extracting developmental trajectories and cell-type structure from high-dimensional single-cell data, but scientific validity requires careful artifact correction, benchmarking, and interpretability to translate ML outputs into biological insight.",
            "uuid": "e2338.5"
        },
        {
            "name_short": "SBI-NeuralRatio/BNRE",
            "name_full": "Simulation-based inference with neural density/rate estimators and conservative variants (Balanced Neural Ratio Estimation)",
            "brief_description": "Neural density/ration estimators are trained on simulation output to approximate posteriors for complex mechanistic models (likelihood-free inference); Balanced Neural Ratio Estimation (BNRE) is a variant designed to produce more conservative posterior approximations to avoid overconfidence.",
            "citation_title": "Towards reliable simulation-based inference and beyond",
            "mention_or_use": "use",
            "scientific_problem_domain": "Broad (astrophysics, particle physics, neuroscience, systems biology) - any domain with expensive forward simulators and intractable likelihoods",
            "problem_description": "Infer model parameters for mechanistic simulators where likelihood functions are intractable by training neural estimators on simulated data to approximate posterior distributions.",
            "data_availability": "Varies by domain: relies heavily on ability to generate large numbers of simulations (compute-bound) rather than labeled observational datasets; observed data required for posterior conditioning.",
            "data_structure": "Simulation outputs are often high-dimensional (images, time-series, summary statistics); paired parameter-simulation datasets used for supervised training of density/ration estimators.",
            "problem_complexity": "High: intractable likelihoods, high-dimensional observations and latent spaces, potential model misspecification, and need for uncertainty quantification.",
            "domain_maturity": "Rapidly maturing: SBI methods have seen rapid adoption across scientific domains, but trustworthiness and diagnostics are active research concerns.",
            "mechanistic_understanding_requirements": "High: users require calibrated, interpretable posteriors connected to mechanistic model assumptions; overconfident posteriors are a key risk.",
            "ai_methodology_name": "Neural density estimation / neural ratio estimation / neural posterior estimation; Balanced Neural Ratio Estimation (BNRE) for conservative posteriors",
            "ai_methodology_description": "Train deep neural networks (density/ratiometric classifiers) on paired (parameters, simulated data) to approximate posterior or likelihood ratios; BNRE modifies training or objective to bias approximations towards conservative (less overconfident) estimates; active learning can be used to allocate simulation budget efficiently.",
            "ai_methodology_category": "Likelihood-free inference / simulation-based inference / deep generative modeling",
            "applicability": "Highly applicable for complex simulators; caveats include computational expense for large simulation budgets and risk of unfaithful posterior approximations without diagnostic checks.",
            "effectiveness_quantitative": "Specific numerical performance varies by application; reported community concerns include occurrences of overconfident posteriors (Hermans et al. 2021) and improvements via BNRE (qualitative claims of increased conservatism).",
            "effectiveness_qualitative": "Enables parameter inference where classical likelihood-based inference is infeasible; but contemporary methods can produce unreliable posteriors without checks; BNRE and diagnostic methods improve trustworthiness.",
            "impact_potential": "High: opens inference for complex mechanistic models across sciences, enabling parameter estimation and hypothesis testing previously intractable; trustworthy adoption requires diagnostics and conservative methods.",
            "comparison_to_alternatives": "Alternatives include approximate Bayesian computation (ABC) and MCMC on approximated likelihoods; SBI neural methods scale better but can be less calibrated; BNRE attempts to trade some sharpness for reliability.",
            "success_factors": "Large, realistic simulation datasets, careful choice of summary statistics or representation, conservative estimation strategies (BNRE), and rigorous diagnostic checks for computational faithfulness are keys to success.",
            "key_insight": "Neural SBI methods permit likelihood-free parameter inference for complex simulators, but maintaining calibrated, conservative posteriors requires methodological safeguards (e.g., BNRE) and domain-targeted diagnostic checks.",
            "uuid": "e2338.6"
        },
        {
            "name_short": "SchroedingerBridge-Diffusion",
            "name_full": "Schrödinger bridge formulations and diffusion-based models for generative modelling and inference",
            "brief_description": "Formulation of diffusion-based generative models and inference as a Schrödinger bridge problem, solved via iterative algorithms (IPF/Sinkhorn) or ML approximations to find most likely stochastic evolution between two distributions given a reference process.",
            "citation_title": "Solving schrödinger bridges via maximum likelihood",
            "mention_or_use": "use",
            "scientific_problem_domain": "Generative modelling, sampling, probabilistic inference applicable across scientific domains (e.g., inverse problems, density estimation, sampling)",
            "problem_description": "Construct expressive generative models and sampling algorithms by framing generation as finding stochastic interpolations (bridges) between initial and target distributions, enabling complex sampling and inference tasks.",
            "data_availability": "Depends on application; diffusion approaches generally require adequate data for learning score functions or transition dynamics; can also be combined with prior stochastic processes.",
            "data_structure": "Typically high-dimensional continuous data (images, continuous fields, distributions); methods operate on probability distributions rather than labeled pairs.",
            "problem_complexity": "High: learning high-dimensional continuous transformations, stability of iterative training (score matching), and computational cost of iterative refinements.",
            "domain_maturity": "Rapidly developing in ML; emerging applications in scientific inference and sampling.",
            "mechanistic_understanding_requirements": "Low-to-medium depending on use: when used as black-box samplers, mechanistic insight is limited; when combined with domain knowledge (reference processes), more interpretability is possible.",
            "ai_methodology_name": "Diffusion models / Schrödinger bridge-based generative models (iterative proportional fitting, score-based methods)",
            "ai_methodology_description": "Frame generation as optimizing a stochastic evolution between two distributions and train neural networks to parameterize drift or score functions; algorithms leverage IPF/Sinkhorn and maximum-likelihood formulations to solve SBP approximations.",
            "ai_methodology_category": "Generative modeling / probabilistic inference / likelihood-based diffusion methods",
            "applicability": "Applicable across many inference and generative tasks, particularly where complex continuous distributions need to be modelled or sampled; requires computational resources and careful training.",
            "effectiveness_quantitative": "No single quantitative metric provided in report; cited works show competitive results in generative modeling benchmarks compared to other approaches.",
            "effectiveness_qualitative": "Provides a unifying theoretical lens linking inference, sampling, and optimal transport; practical implementations demonstrate competitive generative quality and flexibility for inference tasks.",
            "impact_potential": "Significant for building flexible samplers and generative models in scientific domains (e.g., inverse problems, density estimation), especially where principled stochastic interpolations are useful.",
            "comparison_to_alternatives": "Related to score-based diffusion models and optimal transport approaches; SBP unifies heuristics and allows borrowing techniques across fields (sampling, transport, inference).",
            "success_factors": "Robust training of score/drift networks, computational budget for iterative procedures, and leveraging problem structure (reference dynamics) help success.",
            "key_insight": "Viewing diffusion generative models through the Schrödinger bridge lens unifies sampling and inference, enabling principled construction of stochastic interpolations that can be leveraged across scientific inverse and generative tasks.",
            "uuid": "e2338.7"
        },
        {
            "name_short": "PDE-VB",
            "name_full": "Variational Bayes for inverse problems in partial differential equations",
            "brief_description": "Applying Variational Bayes (VB) as a computationally tractable alternative to MCMC for Bayesian inverse problems governed by PDEs, enabling parameter inference for large-scale engineering and geophysical problems (e.g., material properties, ice sheet modelling).",
            "citation_title": "Partial differential equations and Variational Bayes",
            "mention_or_use": "use",
            "scientific_problem_domain": "Computational engineering / geophysics / ice-sheet and ice-core modelling",
            "problem_description": "Infer spatially-distributed or material parameters in PDE-governed systems from noisy observations, where direct posterior sampling (MCMC) is computationally infeasible.",
            "data_availability": "Problem-dependent: observational data may be limited and noisy; forward PDE solvers can generate simulations but are costly, motivating efficient inference approximations.",
            "data_structure": "Structured scientific data (spatially-distributed measurements, time series) coupled with PDE model outputs; posterior is over functional parameters or fields.",
            "problem_complexity": "Very high: ill-posed inverse problems, high-dimensional parameter spaces (fields), computationally expensive forward solves, and need for regularization/prior structure.",
            "domain_maturity": "Mature mathematical theory for PDE inverse problems exists; application of VB as scalable inference tool is emerging and gaining traction.",
            "mechanistic_understanding_requirements": "High: mechanistic PDE models are central and domain priors are crucial; interpretability is necessary for scientific conclusions.",
            "ai_methodology_name": "Variational Bayes approximations to Bayesian inverse problems, probabilistic programming, generative models",
            "ai_methodology_description": "Pose posterior approximation as optimization over a tractable variational family instead of sampling; apply VB in conjunction with probabilistic programming languages to infer parameters of PDE models; trade-off between approximation quality and computational tractability.",
            "ai_methodology_category": "Bayesian inference / variational inference / probabilistic numerics",
            "applicability": "Appropriate for large-scale PDE inverse problems where MCMC is infeasible; VB yields faster approximate posteriors but may underestimate uncertainty and requires careful choice of variational family.",
            "effectiveness_quantitative": "No single numeric metrics provided here; the report notes VB is computationally tractable for large problems where MCMC is infeasible.",
            "effectiveness_qualitative": "VB enables practical inference at scale but has shortcomings (approximation bias); limitations of probabilistic programming languages and differentiable formulations were highlighted.",
            "impact_potential": "High for engineering and geophysical parameter estimation where scale forbids MCMC; facilitates integration of data with mechanistic PDE models.",
            "comparison_to_alternatives": "Compared to MCMC (gold standard) — VB is computationally cheaper but introduces approximation error; comparisons should weigh tractability vs posterior fidelity.",
            "success_factors": "Choosing expressive variational families, problem-specific regularization/prior knowledge, differentiable solvers, and careful diagnostics to assess approximation fidelity are crucial.",
            "key_insight": "Variational Bayes provides a tractable pathway to Bayesian inverse inference for large-scale PDE problems, enabling practical parameter estimation when MCMC is infeasible, but requires careful control of approximation bias and diagnostics.",
            "uuid": "e2338.8"
        },
        {
            "name_short": "ProbNum-ODE",
            "name_full": "Probabilistic numerics and ODE filters/smoothers for mechanistic modelling",
            "brief_description": "Probabilistic numerical methods (PN) treat numerical tasks (ODE solution, integration) as statistical inference problems, using ODE filters and smoothers to produce uncertainty-aware numerical solutions and facilitate joint inference of mechanistic model parameters and states.",
            "citation_title": "Probabilistic Numerics: Computation as Machine Learning",
            "mention_or_use": "use",
            "scientific_problem_domain": "Mechanistic modelling across sciences (dynamical systems, systems biology, physics)",
            "problem_description": "Solve ODE-governed mechanistic models while accounting for numerical uncertainty and enable joint inference of parameters and states in a Bayesian framework.",
            "data_availability": "Problem-dependent: requires observational time-series data for parameter/state inference; ODE solvers produce approximate trajectories used within the PN framework.",
            "data_structure": "Time series of measurements and mechanistic ODE models; state-space representations amenable to filtering/smoothing.",
            "problem_complexity": "Medium-to-high: nonlinear ODEs with uncertain parameters, irregular sampling, and noise; traditional deterministic solvers ignore numerical uncertainty propagated into inference.",
            "domain_maturity": "Emerging methodological field with established theoretical foundations; increasing adoption in mechanistic modeling applications.",
            "mechanistic_understanding_requirements": "High: methods explicitly leverage mechanistic ODE structure and are used to quantify uncertainty in mechanistic inference.",
            "ai_methodology_name": "Probabilistic numerics (ODE filters and smoothers / Bayesian ODE solvers / Gaussian-process-based solvers)",
            "ai_methodology_description": "Formulate numerical solution of ODEs as Bayesian inference; use filtering/smoothing algorithms to obtain posterior distributions over solution trajectories and incorporate these into downstream parameter inference workflows.",
            "ai_methodology_category": "Probabilistic numerics / Bayesian inference",
            "applicability": "Highly applicable for mechanistic models where uncertainty quantification of numerical error matters; useful for joint parameter-state estimation in noisy data settings.",
            "effectiveness_quantitative": "No single numeric measure reported in the report; methods shown to enable uncertainty-aware numerical solutions and facilitate parameter inference in example applications.",
            "effectiveness_qualitative": "Adds principled uncertainty quantification to numerical solutions, improving downstream inference robustness; computational overhead relative to deterministic solvers is a consideration.",
            "impact_potential": "Moderate-to-high for scientific domains reliant on ODE modelling (systems biology, neuroscience), enabling more honest propagation of solver uncertainty into scientific conclusions.",
            "comparison_to_alternatives": "Compared to classical deterministic ODE solvers followed by separate inference — probabilistic numerics yields joint, uncertainty-aware solutions but at higher computational cost.",
            "success_factors": "Accurate modeling of solver error via expressive priors, computational efficiency of filtering algorithms, and integration with parameter inference pipelines.",
            "key_insight": "Treating numerical solution of mechanistic ODEs as an inference problem provides principled uncertainty estimates for downstream scientific inference, improving robustness when solver error is non-negligible.",
            "uuid": "e2338.9"
        },
        {
            "name_short": "LatentForce-GP",
            "name_full": "Latent force models: Gaussian processes informed by differential operators",
            "brief_description": "Latent force models combine Gaussian process priors with mechanistic differential operators (via Green's functions) to yield 'grey-box' models that incorporate mechanistic structure and learn latent forcing functions from data.",
            "citation_title": "Linear latent force models using Gaussian processes",
            "mention_or_use": "use",
            "scientific_problem_domain": "Grey-box modeling across engineering, ecology, and systems biology",
            "problem_description": "Integrate partial mechanistic knowledge (differential operator structure) with data-driven latent force estimation to model complex systems where some physics is known but forcing terms are unknown.",
            "data_availability": "Varies: typically uses observational time-series or spatial data; GP frameworks can work with limited data but Bayesian inference benefits from adequate observations.",
            "data_structure": "Time-series or spatially-resolved measurements; models combine linear/nonlinear differential operators with GP-modeled latent functions.",
            "problem_complexity": "Medium-to-high: complexity arises from solving convolution integrals with Green's functions and inferring latent functions in potentially high-dimensional spaces.",
            "domain_maturity": "Established research area with multiple extensions (nonlinear, black-box inference) and cross-domain applications; growing practical adoption.",
            "mechanistic_understanding_requirements": "Medium-high: relies on known differential operator structure; interpretability stems from mechanistic components.",
            "ai_methodology_name": "Latent force models (Gaussian process priors convolved with Green's functions of differential operators)",
            "ai_methodology_description": "Construct covariance functions by integrating Green's functions of mechanistic differential operators with covariance of latent forcings; perform Bayesian inference (GP regression/inversion) to learn latent forces and system responses.",
            "ai_methodology_category": "Hybrid physics-ML / Gaussian process regression",
            "applicability": "Well-suited for 'grey-box' problems where mechanistic operators are known but forcing terms are unknown or partially observed.",
            "effectiveness_quantitative": "No single metric provided in report; referenced TPAMI and ICML works demonstrate applicability with favorable predictive performance in multiple domains.",
            "effectiveness_qualitative": "Provides interpretable, physics-consistent models able to extrapolate better than purely data-driven models when mechanistic structure is informative.",
            "impact_potential": "High for domains with partial mechanistic knowledge: enables principled integration of theory and data with uncertainty quantification.",
            "comparison_to_alternatives": "Outperforms purely data-driven models when operator structure constrains dynamics; compared to full mechanistic models, latent force models allow data-driven estimation of unknown forcings.",
            "success_factors": "Availability of correct mechanistic operator specification, expressive GP kernels, and scalable inference methods for large datasets.",
            "key_insight": "Latent force models effectively bridge mechanistic differential equations and data-driven learning, enabling interpretable inference of unknown forcings while respecting known system structure.",
            "uuid": "e2338.10"
        },
        {
            "name_short": "Virtual-Lab-Centaurs",
            "name_full": "Virtual laboratories and AI 'scientific centaurs' (AI sidekicks for experimental design and automation)",
            "brief_description": "Concept and prototypes for virtual laboratories that integrate measurement devices, simulations, and AI-driven decision-making, paired with AI assistants (centaurs) that help domain experts design and run experiments, elicit tacit knowledge, and operate with partial or evolving goals.",
            "citation_title": "Virtual laboratories for science, assisted by collaborative AI",
            "mention_or_use": "mention",
            "scientific_problem_domain": "Cross-domain (drug discovery, experimental sciences, lab automation)",
            "problem_description": "Accelerate experimental cycles and decision-making in labs by simulating experiments, proposing actions, and assisting human researchers with task planning and information elicitation.",
            "data_availability": "Varies: virtual labs require integration of instrument data streams, simulation outputs, and historical experimental records; data richness depends on lab digitization level.",
            "data_structure": "Multimodal: time-series instrument metadata, experimental protocols, simulation outputs, textual experiment notes; often semi-structured.",
            "problem_complexity": "High socio-technical complexity: coordinating multi-agent planning, partial observability, variable user goals, and integration with lab hardware and safety constraints.",
            "domain_maturity": "Conceptual and early-stage prototyping; research on AI assistants and virtual labs is emerging but not yet broadly standardized in domains.",
            "mechanistic_understanding_requirements": "Medium-to-high: assistants must model domain processes sufficiently to propose informative experiments while remaining interpretable and aligned with expert priors.",
            "ai_methodology_name": "Multi-agent decision-making, Bayesian reinforcement learning (Bayes-adaptive POMDPs), generative user models, active knowledge elicitation",
            "ai_methodology_description": "Design agents that model user goals and uncertain experiment outcomes, leverage virtual lab simulators to plan experiments, use active elicitation to incorporate expert knowledge and adapt to evolving objectives, and combine reinforcement learning with Bayesian updates for decision-making.",
            "ai_methodology_category": "Reinforcement learning / active learning / human-AI collaboration",
            "applicability": "Promising for accelerating iterative experimental workflows; practical adoption requires robust integration with lab infrastructure and elicitation of domain tacit knowledge.",
            "effectiveness_quantitative": "No quantitative field metrics reported; conceptual prototypes and prior work indicate potential for speeding design cycles but empirical validation is ongoing.",
            "effectiveness_qualitative": "Potential to scale experimental throughput and capture tacit expertise; challenges include user trust, explainability, and aligning AI proposals with human values and safety.",
            "impact_potential": "High long-term: could materially speed discovery (e.g., drug discovery), democratize lab expertise, and reduce repetitive manual tasks, subject to careful human-AI interface design.",
            "comparison_to_alternatives": "Alternatives include manual experiment design and automated high-throughput platforms without intelligent planning; virtual labs add decision intelligence and adaptive planning.",
            "success_factors": "High-quality simulation fidelity, effective human-AI interfaces, mechanisms for eliciting and encoding expert tacit knowledge, and institutional adoption incentives.",
            "key_insight": "Virtual laboratories and AI sidekicks can amplify scientific productivity by combining simulation-driven planning with interactive knowledge elicitation, but real-world impact requires robust UX, trust-building, and integration with laboratory practices.",
            "uuid": "e2338.11"
        },
        {
            "name_short": "Building-Mapping-VectorRisk",
            "name_full": "Satellite-building-feature extraction for vector-borne disease risk mapping",
            "brief_description": "Application of satellite imagery analysis tools to extract building features at household and city scales and investigate relationships between built environment characteristics (e.g., roofing material) and mosquito prevalence/malaria risk.",
            "citation_title": "Mapping africa's buildings with satellite imagery",
            "mention_or_use": "use",
            "scientific_problem_domain": "Epidemiology / public health (vector-borne disease risk mapping)",
            "problem_description": "Characterize built-environment features that correlate with vector presence to inform public-health interventions and risk mapping for diseases like malaria.",
            "data_availability": "Moderate: large-scale satellite imagery and building maps are available (e.g., Google/other mapping projects); health outcome and entomological data may be more limited and spatially heterogenous.",
            "data_structure": "High-resolution satellite imagery (raster), extracted building footprints/features (vector), linked to epidemiological/geospatial datasets at household or neighborhood scales.",
            "problem_complexity": "Medium: causal inference complicated by confounding (socioeconomic factors), spatial heterogeneity, and measurement noise in remotely-sensed proxies.",
            "domain_maturity": "Emerging application of ML to epidemiology with existing remote-sensing pipelines; domain expertise required to interpret correlational findings for policy.",
            "mechanistic_understanding_requirements": "High for policy translation: mechanistic insight into why features affect vector ecology is desirable to avoid spurious policy actions; interpretability and fairness considerations are crucial.",
            "ai_methodology_name": "Image-based building detection/feature extraction (CNNs / segmentation) and spatial statistical analysis linking features to disease prevalence",
            "ai_methodology_description": "Use pretrained or custom CNNs/segmentation models to detect buildings and extract roofing/material features from satellite imagery, aggregate features across scales, and correlate or model relationships with vector prevalence and disease incidence.",
            "ai_methodology_category": "Supervised deep learning (remote sensing) + spatial statistical modelling / epidemiological analysis",
            "applicability": "Appropriate: satellite-based feature extraction is well-suited for large-scale mapping, but inferences about disease risk require careful confounder control and local validation.",
            "effectiveness_quantitative": "Report references show associations (e.g., metal roofing associated with lower mosquito prevalence) but no universal numeric performance metrics in the report; mapping products have been produced at continental scale.",
            "effectiveness_qualitative": "Enables multi-scale analyses linking environmental features to disease risk; warns that assimilation of such features into policy pipelines can hide assumptions and risk marginalizing communities if not handled ethically.",
            "impact_potential": "Moderate-to-high: supports targeted interventions and surveillance in resource-limited settings, but must be combined with local validation and equitable policy design.",
            "comparison_to_alternatives": "Alternative is ground-based surveys which are accurate but costly and slow; satellite-based methods are scalable but need ground-truthing for causal interpretation.",
            "success_factors": "High-quality labeled building datasets, integration with epidemiological data, domain expertise to control confounding, and transparent communication about assumptions and limitations.",
            "key_insight": "Remote-sensing feature extraction via ML provides scalable proxies for built-environment risk factors tied to vector-borne diseases, but translating correlations into actionable, equitable policy requires mechanistic validation and careful handling of assumptions.",
            "uuid": "e2338.12"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Poultry diseases diagnostics models using deep learning",
            "rating": 2,
            "sanitized_title": "poultry_diseases_diagnostics_models_using_deep_learning"
        },
        {
            "paper_title": "An unexpectedly large count of trees in the west african sahara and sahel",
            "rating": 2,
            "sanitized_title": "an_unexpectedly_large_count_of_trees_in_the_west_african_sahara_and_sahel"
        },
        {
            "paper_title": "Solving schrödinger bridges via maximum likelihood",
            "rating": 2,
            "sanitized_title": "solving_schrödinger_bridges_via_maximum_likelihood"
        },
        {
            "paper_title": "Linear latent force models using Gaussian processes",
            "rating": 2,
            "sanitized_title": "linear_latent_force_models_using_gaussian_processes"
        },
        {
            "paper_title": "The frontier of simulation-based inference",
            "rating": 2,
            "sanitized_title": "the_frontier_of_simulationbased_inference"
        },
        {
            "paper_title": "Towards reliable simulation-based inference with balanced neural ratio estimation",
            "rating": 2,
            "sanitized_title": "towards_reliable_simulationbased_inference_with_balanced_neural_ratio_estimation"
        },
        {
            "paper_title": "Real-time gravitational wave science with neural posterior estimation",
            "rating": 2,
            "sanitized_title": "realtime_gravitational_wave_science_with_neural_posterior_estimation"
        },
        {
            "paper_title": "Probabilistic Numerics: Computation as Machine Learning",
            "rating": 2,
            "sanitized_title": "probabilistic_numerics_computation_as_machine_learning"
        },
        {
            "paper_title": "Mapping africa's buildings with satellite imagery",
            "rating": 1,
            "sanitized_title": "mapping_africas_buildings_with_satellite_imagery"
        },
        {
            "paper_title": "Virtual laboratories: Transforming research with ai",
            "rating": 1,
            "sanitized_title": "virtual_laboratories_transforming_research_with_ai"
        }
    ],
    "cost": 0.03411775,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>AI for Science: An Emerging Agenda
March 9, 2023 7 Mar 2023</p>
<p>Philipp Berens 
Kyle Cranmer 
University of Wisconsin -Madison
USA</p>
<p>Neil D Lawrence 
University of Cambridge
UK</p>
<p>Ulrike Von Luxburg 
Jessica Montgomery 
University of Cambridge
UK</p>
<p>AI for Science: An Emerging Agenda
March 9, 2023 7 Mar 2023* Universität Tübingen, DE 1
This report documents the programme and the outcomes of Dagstuhl Seminar 22382 "Machine Learning for Science: Bridging Data-Driven and Mechanistic Modelling".Today's scientific challenges are characterised by complexity. Interconnected natural, technological, and human systems are influenced by forces acting across time-and spatial-scales, resulting in complex interactions and emergent behaviours. Understanding these phenomena -and leveraging scientific advances to deliver innovative solutions to improve society's health, wealth, and well-being -requires new ways of analysing complex systems.The transformative potential of AI stems from its widespread applicability across disciplines, and will only be achieved through integration across research domains. AI for science is a rendezvous point. It brings together expertise from AI and application domains; combines modelling knowledge with engineering know-how; and relies on collaboration across disciplines and between humans and machines. Alongside technical advances, the next wave of progress in the field will come from building a community of machine learning researchers, domain experts, citizen scientists, and engineers working together to design and deploy effective AI tools.This report summarises the discussions from the seminar and provides a roadmap to suggest how different communities can collaborate to deliver a new wave of progress in AI and its application for scientific discovery.</p>
<p>Summary</p>
<p>Today's scientific challenges are characterised by complexity. Interconnected natural, technological, and human systems are influenced by forces acting across time-and spatial-scales, resulting in complex interactions and emergent behaviours. Understanding these phenomena -and leveraging scientific advances to deliver innovative solutions to improve society's health, wealth, and well-being -requires new ways of analysing complex systems.</p>
<p>Artificial intelligence (AI) offers a set of tools to help make sense of this complexity. In an environment where more data is available from more sources than ever before -and at scales from the atomic to the astronomical -the analytical tools provided by recent advances in AI could play an important role in unlocking a new wave of research and innovation. The term AI today describes a collection of tools and methods, which replicate aspects of intelligence in computer systems. Many recent advances in the field stem from progress in machine learning, an approach to AI in which computer systems learn how to perform a task, based on data.</p>
<p>Signals of the potential for AI in science can already be seen in many domains. AI has been deployed in climate science to investigate how Earth's systems are responding to climate change; in agricultural science to monitor animal health; in development studies, to support communities to manage local resources more effectively; in astrophysics to understand the properties of black holes, dark matter, and exoplanets; and in developmental biology to map pathways of cellular development from genes to organs. These successes illustrate the wider advances that AI could enable in science. In so doing, these applications also offer insights into the science of AI, suggesting pathways to understand the nature of intelligence and the learning strategies that can deliver intelligent behaviour in computer systems.</p>
<p>Further progress will require a new generation of AI models. AI for science calls for modelling approaches that can: facilitate sophisticated simulations of natural, physical, or social systems, enabling researchers to use data to interrogate the forces that shape such systems; untangle complicated cause-effect relationships by combining the ability to learn from data with structured knowledge of the world; and work adaptively with domain experts, assisting them in the lab and connecting data-derived insights to pre-existing domain knowledge. Creating these models will disrupt traditional divides between disciplines and between datadriven and mechanistic modelling.</p>
<p>The roadmap presented here suggests how these different communities can collaborate to deliver a new wave of progress in AI and its application for scientific discovery. By coalescing around the shared challenges for AI in science, the research community can accelerate technical progress, while deploying tools that tackle real-world challenges. By creating user-friendly toolkits, and implementing best practices in software and data engineering, researchers can support wider adoption of effective AI methods. By investing in people working at the interface of AI and science -through skills-building, convening, and support for interdisciplinary collaborations -research institutions can encourage talented researchers to develop and adopt new AI for science methods. By contributing to a community of research and practice, individual researchers and institutions can help share insights and expand the pool of researchers working at the interface of AI and science. Together, these actions can drive a paradigm shift in science, enabling progress in AI and unlocking a new wave of AI-enabled innovations.</p>
<p>The transformative potential of AI stems from its widespread applicability across disciplines, and will only be achieved through integration across research domains. AI for science is a rendezvous point. It brings together expertise from AI and application domains; combines modelling knowledge with engineering know-how; and relies on collaboration across disciplines and between humans and machines. Alongside technical advances, the next wave of progress in the field will come from building a community of machine learning researchers, domain experts, citizen scientists, and engineers working together to design and deploy effective AI tools.</p>
<p>Introduction: bridging data driven and mechanistic modelling</p>
<p>The 21 st century has been characterised as the century of complexity. 1 Shifting social, economic, environmental, and technological forces have created increasingly interconnected communities, affected by 'wicked' problems in domains such as health, climate, and economics [1]. This complexity is reflected in today's scientific agenda: whether in natural, physical, medical, environmental, or social sciences, researchers are often interested in the dynamics of complex systems and the phenomena that emerge from them. Science has always proceeded through the collection of data. Through their experiments and observations, researchers collect data about the world, use this data to develop models or theories of how the world works, make predictions from those models, then test those predictions, leading to further refinements to the model and the underpinning theory. Digitisation of daily activities-in the lab, and elsewhere -means that researchers today have access to more data from a greater range of sources than ever before. In parallel, more sophisticated tools to collect data have opened new scales of scientific inquiry, from detailed patterns of gene expression to light signals from other galaxies. Data proliferation is both a signal of the complexity of today's environment, and an opportunity to make sense of such complexity.</p>
<p>Advances in artificial intelligence (AI) have produced new analytical tools to make sense of these data sources. The term 'AI' today describes a collection of methods and approaches to create computer systems that can perform tasks that would typically be associated with 'intelligent' behaviour in living systems. 2 In this document, the term AI is used broadly, to refer to algorithmic decision-making systems that combine data, mathematical models, and compute power to make predictions about the world.</p>
<p>AI is already unlocking progress across research disciplines:</p>
<p>• In Earth sciences, it is helping researchers investigate how different parts of the Earth's biosphere interact, and are affected by climate change. 3 • In climate science, it supports modelling efforts to reconstruct historical climate patterns, enabling more accurate predictions of future climate variability. 4 • In agricultural science, it is helping farmers access faster diagnoses of animal diseases, enabling more effective responses. 5 • In astrophysics, it is advancing understandings of the nature of dark matter and its role in the Universe. 6 • In developmental biology, it is generating insights into the genetic processes that shape how cells develop and differentiate into specialist roles. 7 • In environmental science, it allows researchers to analyse the features of natural environments more accurately, aiding land and resource managers. 8 • In neuroscience, it can help model how different neural circuits fire to deliver different behaviours in animals. 9 The diversity of these successes illustrates the transformative potential of AI for research across the natural, physical, social, medical, and computer sciences, arts, humanities, and engineering. By enabling researchers to extract insights from a greater volume of data, drawn from a wider variety of sources, and operating across multiple dimensions and scales, AI could unlock new understandings of the world. In so doing, AI could influence the conduct of science itself. AI-enabled analytical tools mean researchers can now generate sophisticated simulations of natural or physical systems, creating 'digital siblings' of real-world systems that can be used for experimentation and analysis. Machine learning models that combine the ability to learn adaptively from data with the ability to make structured predictions reflecting the laws of nature can help researchers untangle the web of cause-effect relationships that drive the dynamics of complex systems. AI-assisted laboratory processes could increase the efficiency of experiments, and support researchers to develop and test new hypotheses.</p>
<p>Achieving this potential will require advances in the science of AI, the design of AI systems that serve scientific goals, and the engineering of such systems to operate safely and effectively in practice. These advances in turn rely on interdisciplinary collaborations that connect domain expertise to the development of machine learning models, and feed the insights generated by such models back into the domain of study. As interest in the potential of AI to drive a new wave of research grows, the challenge for the field is to identify technical and operational strategies to realise this potential. In the process, new questions arise about the future of 'AI for science'; whether this will emerge as a distinct field, characterised by its own research agenda and priorities, or whether its benefits can be best achieved through separate, domain-focused sub-fields, which seek to integrate AI into business-as-usual across research disciplines.</p>
<p>In response, this document proposes a roadmap for 'AI for science'. Synthesising insights from recent attempts to deploy AI for scientific discovery, it proposes a research agenda that can help develop more powerful AI tools and the areas for action that can provide an enabling environment for their deployment. It starts by exploring core research themes -in simulation, causality, and encoding domain knowledge -then draws from these ideas to propose a research agenda and action plan to support further progress. The ideas presented are inspired by discussions at 'Machine Learning for Science: Bridging Mechanistic and Data Driven Modelling Approaches', a Dagstuhl seminar convened in September 2022 (see Annex 1). Abstracts from the talks given at the seminar are shown throughout this document. These talks and the discussions they provoked should be credited for the ideas that have shaped it. Thank you to the speakers and participants for their thoughtful contributions to both the seminar and the development of this work.</p>
<p>Snapshots of AI in science</p>
<p>Across domains, AI is being deployed to advance the frontiers of science. The snapshots below introduce some current areas of research in AI for science, and explore the issues raised by these research projects. Across these snapshots, some common themes emerge:</p>
<p>• How can researchers most effectively combine observations, data-driven models, and physical models to enhance understanding of complex systems? To answer this question, methods are needed to integrate different types of model, operating across different levels of granularity, while managing the impact of the uncertainties that emerge when a machine learning model is integrated in a wider system. New approaches to simulation and emulation can support progress in tackling these challenges, alongside new strategies for examining the robustness or performance of machine learning models.</p>
<p>• How do the outputs from an AI system align with what researchers already know about the world, and how can such systems help uncover causal relationships in data? Advances in causal machine learning are needed to connect the laws and principles already established in many areas of research with data-driven methods.</p>
<p>• How can AI be integrated into the scientific process safely and robustly? Effective integration will rely on the ability to encode domain knowledge in AI systems, the design of interfaces that facilitate interaction between humans and AI, and the development of mechanisms for sharing knowledge and know-how about how to use AI in practice.</p>
<p>In Earth sciences</p>
<p>The Earth is a complex system, 10 comprised of terrestrial, marine, and atmospheric biospheres that interact with each other and are shaped by biological, chemical, and physical processes that exchange energy across scales from the molecular to the planetary. It is also a unique system: researchers have yet to discover other planets that replicate its dynamics. Studies of the Earth system therefore rely on observations and physical models, which describe the dynamics of energy exchange from first principles and use those principles to build models of the Earth's sub-systems. As climate change perturbs this complex system, it is increasingly important to have accurate models that can be used to analyse how the Earth will respond to increasing carbon dioxide levels. The challenge for Earth system science is to build more complex models that represent the web of relationships between biospheres under changing conditions, without generating overwhelming uncertainties and while generating actionable insights that can be used by individuals, organisations, and policymakers to understand the localised impact of changing environmental conditions [2]. For example, how much carbon dioxide is absorbed by different biospheres can be affected by diverse factors including volume and type of vegetation cover, water and drought stress in different areas, and local temperature, which have implications for how carbon dioxide contributes to climate change. Researchers have access to data that describes local uptake of carbon dioxide by some ecosystems, such as tropical rainforest, European beech forest, or Mediterranean savanna, for example, but lack sufficient observational coverage to scale from these local observations to accurate global representations of carbon exchange. One response to this challenge is to leverage data-driven models to knit together the different mechanistic models that describe (for example) carbon, water, and energy cycles in different biospheres.</p>
<p>By starting with observational data and combining this with physics-informed modelling, researchers can leverage machine learning to create simulations that can generate new understandings of how complex systems function. Taking this approach, the FLUXNET project combines observed data on carbon emissions from different sources to generate a data-driven picture of global carbon dynamics. By combining data across scales to establish a statistical model of global carbon dynamics, this project can generate simulations of how the Earth breathes [3]. The ability to integrate across scales and combine models of different Earth sub-systems can also contribute to wider efforts to build a 'digital twin' of the Earth, with the aim of better understanding the implications of climate change across biospheres and communities.</p>
<p>As the Earth's climate changes, 11 researchers anticipate that local environmental conditions will change and extreme weather events will increase. Understanding the impact of these changes is important for those seeking to develop appropriate responses, for example developing environmental management plans or planning human activities.</p>
<p>How a landscape responds to changing environmental conditions will vary depending on the local climate, characteristics of the terrain (vegetation type, for example), and human activities in the area. Under changing climate conditions, as extrapolation beyond known limits becomes necessary, the assumptions or abstractions that form the basis of a model can be rendered invalid. Relying solely on either mechanistic descriptions of the system -the impact of temperature on plant growth, for example 12 -or statistical models could result in inaccuracies. Machine learning can help respond to this challenge, through the creation of hybrid models that combine an understanding of the physical laws with model parameters learned from data. Researchers often already have access to known physical parameters for a system (for example, the equations that govern how water evaporates to air). These parameters can be fed into a machine learning model that will learn other patterns. Known equations specify the chemical and physical processes; machine learning can then help elucidate the other biological forces at play. Integrating this physical structure in the model helps make it both more interpretable to the domain scientists and more reliable in its predictions. The resulting model can accurately forecast the impact of climate change on the features of local landscapes, operating within the bounds set by the laws of physics [5]. Ice loss 13 has been the greatest contributor to sea-level rise in recent decades [6]. Large volumes of fresh water are stored as ice: NASA estimates that if all the world's glaciers and ice sheets melted, sea levels globally would rise by over 60 metres, flooding all coastal cities [7]. Researchers can estimate the contribution that melting ice makes to sea level rise through mechanistic models that describe the underlying physical processes (that turn ice to water) and through observational data about the velocity of ice sheet movement. Machine learning could offer a toolkit to make these models more accurate, connecting ice sheet models to ocean and atmospheric models, and integrating different data types in hybrid mechanistic-data models.</p>
<p>Efforts to build such models, however, illustrate the complexity of designing tools to meet domain needs. Projects in this space have considered emulating the ice sheet system -or its individual components -to see if models could be run faster; though successful methodologically, it has not been clear that such efforts address a clear research need. Another approach is to use machine learning to streamline simulations, for instance by identifying the most effective level of granularity for different models (is a spatial breakdown of 5km or 10km more interesting?). An important lesson from such collaborations is the specificity of domain needs: machine learning is a tool for research, but just because researchers have a hammer, does not mean every research problem is a nail. Effectively deploying machine learning for research requires both suitable AI toolkits and an understanding of which toolkits are best deployed for which challenges.</p>
<p>In environmental and agricultural sciences</p>
<p>Poultry farming 14 is a vital source of income and food for many communities in Tanzania. 4.6 million households in the country raise approximately 36 million chickens, but despite the importance of this activity, poultry farming suffers from relatively low productivity due to the prevalence of disease. Efforts to tackle poultry diseases such as Salmonella, Newcastle disease, and coccidiosis are held back by the accessibility of diagnostic processes and lack of data. Diagnosis currently requires lab analysis of droppings, which can take 3-4 days. Once disease is confirmed, farmers often lose their entire farm's flock.</p>
<p>Farm-level tests and diagnostics could increase the effectiveness of disease surveillance and treatment, giving farmers rapid access to information about the diseases affecting their flock and action plans about how to manage outbreaks. With mobile phones ubiquitous across the country -there are almost 49 million mobile phone subscriptions in Tanzania -there are opportunities for new uses of local data to detect disease outbreaks.</p>
<p>By collecting images of droppings from farms, researchers have been creating a dataset to train a machine learning system that can identify the symptoms of these diseases. Fecal images are taken on farms, annotated with diagnostic information from agricultural disease experts and the results of lab tests, then used to train an image recognition system to automate the diagnosis process [8]. System robustness and accuracy is vital, given the significant implications of a positive diagnosis, and careful design is necessary to incentivise farmers to make use of the app.</p>
<p>Collaboration with experts from different domains is central to developing this system. Input from farmers is needed to collect data and test the system in practice; from veterinary pathologists to help annotate the data and ensure the system's accuracy; and from technologists to develop an AI system that is effective in deployment as an app on mobile phones. These collaborations also open opportunities for new forms of citizen science, as farmers and local communities are engaged in efforts to develop and maintain an open toolkit for disease diagnosis, providing a gateway for communities to take ownership of machine learning as a tool to serve their needs. Trees and forests 15 play a crucial role in maintaining healthy ecosystems. Despite this, an estimated ten million hectares of forest are lost globally each year due to reforestation, with only around half of this balanced by tree-planting efforts [9]. Africa experienced an annual rate of forest loss of approximately 3.9 million hectares per year from 2010-2020. This loss has implications for biodiversity and people, with trees a vital contributor to ecosystem services such as carbon storage, food provision, and shelter. In this shifting landscape, understanding the number and distribution of trees is important for the development of forestry management plans and for understanding the carbon storage implications of changes to land use.</p>
<p>To estimate the number and biomass of trees in the West African Sahara and Sahel, researchers have used satellite imagery of 90,000 trees from 400 sampling sites to create a labelled dataset for use in machine learning. Using an image segmentation tool to identify the location of trees, an automated system was able to count the number of trees, with domain experts guiding the system to distinguish trees from surrounding vegetation. This tree count can then be used to estimate the biomass of trees in the area, and predict the amount of carbon they store; the prediction is generated using allometric calculations, which translate the properties of the tree to its carbon storage potential. In this approach, machine learning measures the properties of the ecosystem from satellite images, then these properties are used to feed mechanistic models that describe the ecosystem's physical functions [10]. This opens the possibility of new tools to estimate tree cover, leveraging these insights for more effective environmental management. However, in the process, care is needed to manage the type and nature of the uncertainties created by different modelling approaches. Different allometric models, for example, can be more or less suited to different types of tree cover [11], meaning that the method for estimating biomass from satellite imagery can be subject to biases when applied across a large area. A small error in the calculation of the biomass from one tree can have a cumulatively large effect when that method is scaled to country-level. The type and nature of such uncertainties need to be considered when a machine learning model is used within a wider system. Vector borne diseases 16 account for more than 17% of diseases in people and over 700,000 deaths annually [12]. Changes to the climate and patterns of land use, amongst other factors, are bringing human populations into contact with new vectors of disease. In Africa, for example, populations of mosquitoes carrying malaria that might previously have been found mainly in rural areas are spreading into cities.</p>
<p>Tools to characterise building features from satellite imagery have already been developed and made available for use. 17 Leveraging these to analyse multi-scale data -from household to city-level-researchers are investigating how the built environment influences people's risk of contracting mosquito-borne disease. For example, it has been found that the prevalence of mosquitos in an area is related to the type of roofing used in construction; metal roofing tends to be associated with lower mosquito prevalence, potentially due to the high temperatures they attract during the day [14]. These insights can be deployed by policymakers in the development of appropriate policy responses [15].</p>
<p>Decisions made on the basis of insights generated by machine learning models will be influenced by the assumptions made in those models. In the context of housing, for example, the decision about which type of housing to identify as 'at risk' or which building materials to flag as 'problematic' may have significant consequences for individuals or communities. When those decisions are assimilated within a model or analysis before a downstream 'policy decision', the implications for those communities of different courses of action may be obscured, creating a risk of marginalising or disadvantaging individuals or groups. The assumptions are built into the model, and how visible those assumptions are made to different user groups, can have significant social and scientific consequences.</p>
<p>In physical sciences</p>
<p>Understanding the nature of dark matter 18 is one of the biggest unsolved challenges of particle physics today. The matter that researchers can measure using cosmological observations makes up about 5% of the Universe [16]. While not directly observable, evidence for the existence of dark matter can be found in a variety of phenomena not otherwise accounted for by currently known laws of physics: stars rotate around galaxies faster than might be expected; the pattern of fluctuations in primordial microwave observations indicate that there were sources of gravitation in the early Universe beyond ordinary matter; light bends around galaxy clusters due to gravitational effects from dark matter.</p>
<p>Despite knowing that dark matter exists and that it plays an important role in how the Universe formed, its particle composition or properties remains unclear. Investigating these properties is the focus of large-scale experimental studies, for example in particle colliders. 19 A variety of data could contain information about the properties of dark matter, from studies of cosmic rays, cosmic microwave radiation, properties of stars, gravitational lensing studies, and more. These datasets are complex: they are typically high-dimensional, represent complex relationships between the micro-physics and macro-phenomenon in a system, and may contain artefacts or noise from the instruments used to collect them. To make use of this data, researchers need to account for this complexity and tether their models to assumptions about physical processes.</p>
<p>The challenge for machine learning in astro-particle physics research is to extract insights about the particle composition of dark matter from the macroscopic patterns that can be observed in the Universe. For example, gravitational lensing is a phenomenon in which the pathway of light traveling through the Universe is deflected due to the influence of gravity from an intervening mass, distorting how this background light is observed [18]. Gravitational lensing effects arising from dark matter clumps ("substructure") could hold information about the structure of dark matter at a microscopic level. To infer the presence of substructure of these lensing systems, researchers need models that describe the effect of dark matter, ordinary matter, and the wider environment while simultaneously modelling the form of the background light, which can be a morphologically-complex galaxy. By letting a machine learning model, like a neural network, describe the complex background light source, it is possible to make predictions about how the light might appear after being lensed with and also without the impact of dark matter clumps. By performing many simulations considering various possibilities, researchers can compare these with observations from telescopes and understand which dark matter theories are compatible with the data.</p>
<p>Rapid progress in this field is generating a variety of models and approaches. In its next wave of development, further research is needed to test how trustworthy these methods are, by assessing their performance in generating physically plausible results and robust constraints on the properties of dark matter and other forms of new physics [19]. How particles move 20 across their environment is a shared area of interest for many domains. In chemistry, for example, researchers are often interested in how molecules diffuse, and where they end up distributed, based on the physical forces that shape their movement over time. The analogy of particle movement can also be applied as an abstraction of larger scale physical processes, such as in agent-based models for crowd simulation. 21 In these systems the initial system state is represented in an initial probability distribution, the scientific objective can then also be represented as a target distribution. The dynamics underpinning this diffusion are formalised mathematically in the Schrödinger bridge problem. This long-standing problem is concerned with finding the most likely paths along which particles move from their starting distribution to their distribution at a defined point in time, based on experimentally-observed start and end positions. In general, finding analytic solutions to the Schrödinger bridge problem is intractable, but machine learning tools are providing new approaches for finding approximate numerical solutions that can be deployed across domains [22].</p>
<p>In biological sciences</p>
<p>The development and differentiation of cells into tissues and organs 22 is a complicated process, shaped by hormonal and genetic influences on cell growth [23]. Advances in genomics have allowed researchers to characterise the genetic material of different organisms; more recent progress in single-cell genomics extends this ability to the single-cell level, unlocking detailed analysis of how genetic activity determines cellular function.</p>
<p>Single-cell RNA studies examine how ribonucleic acids (RNA) shape cellular properties and development pathways. The RNA profiles created by genetic sequencing techniques allow researchers to identify which genes are active in a cell. The question for the field today is how to move from these single-cell analyses to an atlas of cell development that shows how cells specialise and form tissues or organs.</p>
<p>By combining statistical and machine learning techniques, researchers can reconstruct the gene dynamics -which genes are activated at which time -that influence cell development [24]. Cells in the small intestine, for example, undergo a pattern of differentiation that takes them from their base state to highly specialised units, able to variously secrete mucus, absorb nutrients, or respond to hormones. By studying what genes are expressed in a cell at an early stage, researchers can predict how the cell will specialise and identify which genetic changes are associated with that specialisation, opening opportunities to treat intestinal diseases [25].</p>
<p>Building these models relies on effective data management. Lab processes can inject artefacts into datasets, for example batch effects arising from how cells were grown or harvested for study, which need to be removed from data before analysis. Effective data correction maintains biologically-relevant information, while removing noise from the data. A variety of tools exist for this correction, including regression models, dimensionality reduction, graph methods, and deep learning. For domain researchers to be able to identify the tools that are useful for them, benchmarking studies are vital in identifying the most effective data integration method for their purpose [26]. However, there remain open questions about how best to benchmark the performance of a system when there are complex pipelines of analysis involved. Understanding the end-to-end nature of an analytical pipeline can be difficult, and new approaches to assessing performance may be needed. To understand how the brain works, 23 neuroscientists develop mathematical models that describe the activity of individual neurons, and how these connect across brain networks. Models on the mechanistic level take the form of differential equations. These models are based on experimental data, from experiments that examine how neurons respond to different signals or perturbations. To build a computational model from this data, it is first necessary to find which factors influence how a neuron acts, creating a set of parameters that determine how the model works. This process of finding parameters is often labour-intensive, relying on trial-and-error, which limits researchers' ability to scale models across complex neural networks. Machine learning can help streamline that model definition process, by predicting which models are more likely to be compatible with data. By automatically identifying model parameters, researchers can rapidly develop simulations of complex structures, such as brains or nervous systems in different animals [27].</p>
<p>Talks given during this workshop session</p>
<p>Machine-learning-model-data-integration for a better understanding of the Earth System</p>
<p>Markus Reichstein</p>
<p>The Earth is a complex dynamic networked system. Machine learning, i.e. derivation of computational models from data, has already made important contributions to predict and understand components of the Earth system, specifically in climate, remote sensing and environmental sciences. For instance, classifications of land cover types, prediction of land-atmosphere and ocean-atmosphere exchange, or detection of extreme events have greatly benefited from these approaches. Such data-driven information has already changed how Earth system models are evaluated and further developed. However, many studies have not yet sufficiently addressed and exploited dynamic aspects of systems, such as memory effects for prediction and effects of spatial context, e.g. for classification and change detection. In particular new developments in deep learning offer great potential to overcome these limitations. Yet, a key challenge and opportunity is to integrate (physical-biological) system modelling approaches with machine learning into hybrid modelling approaches, which combines physical consistency and machine learning versatility. A couple of examples are given with focus on the terrestrial biosphere, where the combination of system-based and machine-learning-based modelling helps our understanding of aspects of the Earth system.</p>
<p>Poultry Diseases Diagnostics Models using Deep Learning</p>
<p>Dina Machuve</p>
<p>Coccidiosis, Salmonella, and Newcastle are the common poultry diseases that curtail poultry production if they are not detected early. In Tanzania, these diseases are not detected early due to limited access to agricultural support services by poultry farmers. Deep learning techniques have the potential for early diagnosis of these poultry diseases. In this study, a deep Convolutional Neural Network (CNN) model was developed to diagnose poultry diseases by classifying healthy and unhealthy fecal images. Unhealthy fecal images may be symptomatic of Coccidiosis, Salmonella, and Newcastle diseases. We collected 1,255 laboratory-labeled fecal images and fecal samples used in Polymerase Chain Reaction diagnostics to annotate the laboratory-labeled fecal images. We took 6,812 poultry fecal photos using an Open Data Kit. Agricultural support experts annotated the farm-labeled fecal images. Then we used a baseline CNN model, VGG16, InceptionV3, MobileNetV2, and Xception models. We trained models using farm and laboratory-labeled fecal images and then fine-tuned them. The test set used farm-labeled images. The test accuracies results without fine-tuning were 83.06% for the baseline CNN, 85.85% for VGG16, 94.79% for InceptionV3, 87.46% for MobileNetV2, and 88.27% for Xception. Finetuning while freezing the batch normalization layer improved model accuracies, resulting in 95.01% for VGG16, 95.45% for InceptionV3, 98.02% for MobileNetV2, and 98.24% for Xception, with F1 scores for all classifiers above 75% in all four classes. Given the lighter weight of the trained MobileNetV2 and its better ability to generalize, we recommend deploying this model for the early detection of poultry diseases at the farm level.</p>
<p>There are open questions about the deployment of the model at the farm level and potential areas for further research.</p>
<p>Simulation-based approaches to astrophysics dark matter searches</p>
<p>Siddharth Mishra-Sharma</p>
<p>We are at the dawn of a data-rich era in astrophysics and cosmology, with the capacity to extract useful scientific insights often limited by our ability to efficiently model complex processes that give rise to the data rather than the volume and nature of observations itself. I will describe recent progress in applying mechanistic forward modeling techniques to a range of astrophysical observations with the goal of searching for signatures of new physics, in particular the nature of dark matter. These leverage developments in machine learning-aided inference, e.g. using simulation-based inference as well as differentiable probabilistic programming, while encoding domain knowledge, in order to maximize the scientific output of current as well as future experiments.</p>
<p>Single-cell transcriptomics</p>
<p>Maren Büttner</p>
<p>Cells are the fundamental units of life. Understanding cellular processes is a basis for improving human health, disease diagnosis and monitoring. The advent of single-cell transcriptomics (scRNA-seq) allows characterizing the gene expression patterns of entire organs and organisms at single cell resolution. The human genome encodes more than 30.000 genes, and high-throughput scRNA-seq methods create samples with tens of thousands of cell measurements. The analysis of such data requires a variety of methods from the machine learning field, e.g. dimensionality reduction techniques from PCA to variational autoencoders, graph-based clustering, classification of cell types, trajectory inference and causal inference of gene regulation to understand cell fate decision making. To date, scRNA-seq is a widely applied research technique, which has the potential for standard application in the clinics. My presentation focusses on current approaches for large-scale scRNA-seq data, current open questions, and implications for human health. Progress in remote sensing technology and machine learning algorithms enables scaling up the monitoring of ecosystems. This leads to new knowledge about their status and dynamics, which will be helpful in land degradation assessment (e.g., deforestation), in mitigating poverty (e.g., food security, agroforestry, wood products), and in managing climate change (e.g., carbon sequestration).</p>
<p>We apply deep learning for the mapping of individual trees and forests. Tree crowns are segmented in satellite imagery using fully convolutional neural networks. This provides detailed measurements of the canopy area and of the distribution of trees within and outside forests. Allometric equations are applied to estimate the biomasses (and thereby the stored carbon) of the individual trees. We use iterative gradient-based optimization of the allometric models and suggest techniques such as jackknife+ for quantifying the uncertainty of the model predictions. Tree biomass can also be directly inferred from LiDAR (laser imaging, detection, and ranging) measurements using 3D point cloud neural networks. This leads to highly accurate results without requiring a digital elevation model.</p>
<p>In a new project, we consider risk assessment of vector-borne diseases based on deep learning and remote sensing. Malaria risk is related to the housing conditions, for example, the type of roofing material, which can be determined from satellite images.</p>
<p>Partial differential equations and Variational Bayes</p>
<p>Ieva Kazlauskaite</p>
<p>Inverse problems involving partial differential equations (PDEs) are widely used in science and engineering. Although such problems are generally ill-posed, different regularisation approaches have been developed to ameliorate this problem. Among them is the Bayesian formulation, where a prior probability measure is placed on the quantity of interest. The resulting posterior probability measure is usually analytically intractable. The Markov Chain Monte Carlo (MCMC) method has been the go-to method for sampling from those posterior measures. MCMC is computationally infeasible for large-scale problems that arise in engineering practice. Lately, Variational Bayes (VB) has been recognised as a more computationally tractable method for Bayesian inference, approximating a Bayesian posterior distribution with a simpler trial distribution by solving an optimisation problem. The talk covered some recent experiences of applying Bayesian inference, generative models and probabilistic programming languages in the context of learning material properties in civil engineering and in ice sheet and ice core modelling. The main shortcomings of PPLs and differentiable problems were highlighted.</p>
<p>The Schrödinger bridge problem</p>
<p>Francisco Vargas</p>
<p>Recent works in diffusion-based models have been achieving competitive results across generative modelling and inference, in this presentation we propose to explore a unifying framework based on Schrodinger bridges to explore/explain diffusion-based methodology. The Schrödinger bridge problem (SBP) finds the most likely stochastic evolution between two probability distributions given a prior (reference) stochastic evolution. Recently SBP based methodology has made its way into generative modelling , sampling, and inference. In this talk we propose the exploration of a unifying framework for the aforementioned works based on the renowned IPF/Sinkhorn algorithm. The motivation behind this is to cast a unifying lens via the Schrodinger perspective relating inference, sampling and transport, in a way that we can leverage many of the useful techniques and heuristics from each field to benefit each other.</p>
<p>Building effective simulations 3.1 Moving upstream</p>
<p>Science proceeds through hypothesis, observation and analysis. For hundreds of years, researchers have advanced the frontiers of knowledge by collecting data, compressing those observations into a model, then computing that model to create representations of how the world works, generating new insights about natural and physical phenomena and theories about the systems from which those phenomena emerge in the process [28]. These mathematical models rely on numerical methods: algorithms that help solve mathematical problems where no analytical solution is available. Today, data collection and the basic computational tasks involved in its analysis -linear algebra, optimisation, simulation, and so on -remain consistent features of the scientific process. Progress in machine learning, however, has changed the modelling landscape.</p>
<p>'AI for science' offers a data-centric approach to modelling and simulating the world. Operating alongside the traditional mathematical models that are central to many disciplines, machine learning provides data-centric analytical methods that can be integrated across the scientific pipeline, for example enabling sophisticated simulations of real-world systems. These simulations can be used to inform model development, test hypotheses and shape areas of research focus, or unlock insights from complex data.</p>
<p>Nurturing a diversity of approaches</p>
<p>Simulations are a well-established tool for scientific discovery. Their fundamental task is to allow data sampling from a model where the differences between simulation and the real world are reduced as far as feasible, to enable experimentation or testing of the impact of different perturbations, while allowing some measure of simplification of the system. Effective simulators allow researchers to move from theory to an understanding of what data should look like.</p>
<p>Domains such as particle physics, protein folding, climate science, and others, have developed complex simulations that use known theories and parameters of interest to make predictions about the system of study. AI for science can be brought in to speed up some of these through surrogate models. Machine learning can complement 'traditional' approaches to scientific simulation, adding components that model the most uncertain elements of a system to strongly mechanistic models that might otherwise be too restrictive in their assumptions.</p>
<p>Much early excitement surrounding AI for science was rooted in the reverse process, asking: instead of starting with theory, could researchers instead start with the large amounts of data available in many areas of research and, from that data, build an understanding of what an underpinning theory might be? Given a set of observations, is it possible to find parameters for a model that result in simulations that reflect the measured data? Such simulation-based inference (SBI) offers the opportunity to generate novel insights across scientific disciplines.</p>
<p>To enable such analysis, machine learning methods are needed that can extract insights from high-dimensional, multi-modal data, in ways that are labour-and compute-efficient [29]. The field of probabilistic numerics offers a way to flexibly combine information from mechanistic models with insights from data, solving numerical problems through statistical approaches [30]. Operationalising these methods to create effective data-driven simulations requires balancing different model characteristics. The model's parameters must be specified to a sufficient level of granularity to describe the real-world system, while operating at a level of abstraction that is amenable to analysis and computation; almost all models are 'wrong' or falsifiable because of this, but some level of abstraction is necessary to make them useful for analysis. The simulation must also be designed to be robust, and able to generate inferences that align with real-world observations.</p>
<p>Truth, truthiness, and interfacing with the real world</p>
<p>The excitement underpinning AI for science stems from the aspiration to unearth new understandings of the world, leveraging data to advance the frontiers of knowledge. While subject to their own limitations, the scientific community has developed checks and balances to scrutinise new knowledge and maintain the rigour of scientific inquiry. Recent years have seen a variety of challenges or benchmarks emerge in the machine learning community that have come to represent the field's expected standards of performance from algorithms on defined tasks. However, these standards do not necessarily align with the expectations of domain researchers [31]. As data-centric simulations are integrated into scientific process, machine learning researchers must consider their responsibility in maintaining the integrity of the domains into which they are deployed, raising the question: what guardrails are needed to ensure researchers can be confident in the outputs from machine learning-enabled simulations?</p>
<p>A variety of diagnostic tests can help. Core to many of these diagnostics is analysis of whether a model is computationally faithful. In short: the inferences generated by a simulation should reflect those from observations [31]. One approach to checking this alignment is to consider the consistency of distributions from inferred and observed datasets. If the model is a good fit, the data it generates should broadly match the data observed through experimentation.</p>
<p>Underpinning these diagnostics is a fundamental question about how to manage uncertainty, in a context where different failure modes have different implications. Put simply: when a model fails, is it worse to be over-confident in its results, or over-conservative? In the scientific context, over-confidence seems more likely to result in negative outcomes, whether through giving misleading interpretations or results or driving lines of enquiry in unproductive directions. Machine learning methods can be designed for conservatism, reducing the risk of false positives.</p>
<p>Implementing a schedule of model building, computing, critiquing, and repeating can refine this process. One lesson from experiences of building machine learning-enabled simulations is that there can be a disconnect between how machine learning approaches inference and model building, and how the same task is approached by domain scientists. From a domain perspective, model building seems naturally an iterative process: collect data, fit a model, find errors or areas for improvement, update the model, and so on. This iterative process is guided by expert intuition and knowledge; deep understanding of the system under study and how it responds to perturbation. Machine learning research has developed practices for prior elicitation -using domain knowledge to shape the structure of probabilistic models -but the nuances of this domain intuition are often not easily captured a priori, instead emerging when models fail as an informal sense of what 'feels' like it should be true. This qualitative input is vital in building effective simulations. It requires close collaboration, which in turn requires an investment of time and energy from domain communities, generated through mutual trust, incentives, and long-term relationship-building.</p>
<p>Connecting simulation to practice</p>
<p>Computational tools are central to the effective deployment of machine learning-enabled simulation. The function and form of such tools must align with the requirements of the community deploying them. Designing computational systems to match user needs -and work effectively in practice -requires both effective software engineering and close collaboration with domain groups that can articulate the requirements and expectations of those working in the field. To remain effective over the longer-term, such systems must leverage effective software engineering practices, including embedding version control and building interfaces that work with other models and systems. Those practices, and the software systems that emerge from them, must be designed for the needs of those using the system, drawing from existing best practices in software engineering, but adapting those practices to reflect the needs of the domain for deployment.</p>
<p>Constructing computational tools requires a mix of technical insight and craft skill -of knowledge and know-how. Tools produced by the machine learning community differ in their usefulness on different problems: some work well for certain tasks, but not for others. Without access to such craft skills, those outside the 'AI for science' community can find it challenging to determine which tools to use for which purposes, reducing the generalisability of existing methods and approaches. This challenge becomes particularly visible when practitioners are tightly integrated into the analysis pipeline, such as in applications in developmental biology, in the developing world, and in data-centric engineering. Widening access to the field will require user guides that characterise which simulations are effective for which tasks or purposes, supported by case studies or user stories that help demystify how machine learning can work in practice.</p>
<p>Directions</p>
<p>Machine learning typically requires an explicit representation of a likelihood, but these are often difficult to compute. Further advances in SBI are necessary to allow researchers to identify model parameters from data.</p>
<p>• Techniques such as likelihood-free inference can enhance existing Bayesian methods for inferring posterior estimations [32].</p>
<p>• Building surrogate models, 24 using Bayesian approaches for simulation planning to optimise information gain, 25 or deploying emulations [35] can also enhance the efficiency of simulations.</p>
<p>• Probabilistic numerics offers a route to develop statistically-optimal algorithms that are amenable to comprehensive uncertainty quantification, leveraging Gaussian Processbased Ordinary Differential Equation (ODE) solvers to pursue simulation as an inference problem [36].</p>
<p>Operationalising these approaches will also require new toolkits to support implementation of probabilistic numerical methods. 26 Computational faithfulness -alignment of inferred parameters with scientific knowledgecan be achieved through:</p>
<p>• Diagnostic checks in the self-consistency of the Bayesian joint distribution, which measure the scientific quality of the regions computed by Bayesian SBI methods [31,38]. Checking for self-consistency gives a sense whether the model is 'good enough' (ie whether the inference engine gives a good sense of the posterior).</p>
<p>• Enforcing conservative neural ratio estimation through binary classifier specification, producing more conservative posterior approximations [39].</p>
<p>• Hybrid modelling, which combines machine learning components learned from data with the mechanistic components specified by existing domain knowledge [40].</p>
<p>• Further study of the impact of model misspecification could also help generate new robustness diagnostic checks [41].</p>
<p>'Digital twins' have recently received much attention as a tool to exploit sophisticated simulations. In Earth sciences, for example, ambitious efforts to develop a digital twin of the Earth propose to allow more accurate forecasting, visualisation, or scenario-testing of the 24 See above, and [33]. 25 See, for example, [34]. 26 See, for example, the previous Dagstuhl meeting on this topic: https://www.probabilistic-numerics. org/meetings/2021_Dagstuhl/ and [37].</p>
<p>impact of climate change and efforts to mitigate it. 27 The challenge is to integrate different models or components of a system -for example, connecting atmospheric models, with land models, with models of human behaviour -in a way that represents the complete Earth system. That requires consideration of the different levels of granularity with which these different models operate: economic models of human behaviour, for example, operate with different assumptions and levels of enquiry in comparison to physical models of ocean circulation. The full range of granularities becomes apparent when considering that specific applications, such as disease monitoring on poultry farms, sit within the wider ecosystem of the natural and built environment. A digital twin needs to make choices about what levels of granularity it is operating at, from the scale of the poultry farm to the planet. The questions that emerge from such ambitions is: what level of granularity is helpful or necessary to deliver effective results? And what interfaces between diverse models might be possible?</p>
<p>3.6 Talks given during this workshop session 3.6.1 Information from data and compute in scientific inference</p>
<p>Philipp Hennig</p>
<p>Simulations are central to scientific inference. Simulators are typically treated as black boxes, with the inference loop wrapped around them. This approach is convenient for the programming scientists, but can be highly inefficient. Probabilistic numerical methods represent computational and empirical data in the same language, which allows for inference from mechanistic knowledge and empirical data in one combined step. I will argue that scientific computing needs to embrace such new computational paradigms to truly leverage ML in science, which also requires rethinking scientific codebases.</p>
<p>ODE filters and smoothers: probabilistic numerics for mechanistic modelling</p>
<p>Hans Kersting</p>
<p>Probabilistic numerics (PN) unifies statistical and numerical approximations by formulating them in the same language of statistical (Bayesian) inference. For ODEs, a well-established probabilistic numerical method is ODE filters and smoothers which can help to deal more aptly with uncertainty in mechanistic modeling. In the first half of this talk, we will first introduce PN and then present ODE filters/smoothers as a specific instance of PN. In the second half, we will discuss how ODE filters/smoothers can improve mechanistic modeling in the natural sciences and present a recent application of inferring the parameters of real-word dynamical system.</p>
<p>Four short stories on simulation-based inference</p>
<p>Jakob Macke</p>
<p>Many fields of science make extensive use of simulations expressing mechanistic forward models, requiring the use of simulation-based inference methods. I will share experiences and lessons learned from four applications: Describing the dynamics and energy consumptions of neural networks in the stomatogastric ganglion; inferring parameters of gravitational wave models; optimising single-molecule localisation microscopy, and building computational models of the fly visual system. I will try to convey some thoughts on the challenges and shortcomings of current approaches. 27 For example: [42].</p>
<p>Towards reliable simulation-based inference and beyond</p>
<p>Gilles Louppe</p>
<p>Modern approaches for simulation-based inference build upon deep learning surrogates to enable approximate Bayesian inference with computer simulators. In practice, the estimated posteriors' computational faithfulness is, however, rarely guaranteed. For example, Hermans et al., 2021 have shown that current simulation-based inference algorithms can produce posteriors that are overconfident, hence risking false inferences. In this talk, we will review the main inference algorithms and present Balanced Neural Ratio Estimation (BNRE), a variation of the NRE algorithm designed to produce posterior approximations that tend to be more conservative, hence improving their reliability.</p>
<p>3.6.5 Modeling the data collection process: My journey</p>
<p>Thomas G. Dietterich</p>
<p>In this talk, I will describe three examples of my attempts to integrate subject-matter knowledge with machine learning. The first example involves predicting grasshopper infestations. I will sketch the methodology in which we first modeled the life cycle of the grasshoppers to capture the factors that affect their population. Unfortunately, most variables of interest were not measured, so we used the model to guide the construction of proxy variables. Ultimately, this project did not succeed, but it is hard to determine whether this is due to modeling problems or to the chaotic nature of the biological phenomenon.</p>
<p>4 Connecting data to causality 4</p>
<p>.1 Causality in science and data</p>
<p>Most scientific endeavours have a causal element: researchers want to characterise how a system works, why it works that way, and what happens when it is perturbed. How researchers identify cause-and-effect relationships varies across domains. For some disciplines, the process of hypothesis design -data collection -model development provides the core structure for interrogating how a system works. In others, where experimentation is more difficult, researchers may rely on natural experiments and observations to compare the response of a system under different conditions. Those studying the Earth system, for example, have little scope to replicate planetary conditions, so instead rely on observational data and modelling to identify the impact of different interventions. These different approaches, however, share a modelling approach in which researchers provide variables to create structural, causal models.</p>
<p>In contrast, machine learning proceeds by learning representations or rules from data, based on statistical information, rather than structured rules about how a system works (such as physical laws). Causal inference -the ability to identify cause-and-effect relationships in data -has been a core aim of AI research, in service of both wider ambitions to replicate intelligence in machines and efforts to create AI systems that are robust in deployment. However, in many respects efforts to integrate causal inference into AI systems have yet to deliver [43].</p>
<p>An apocryphal story in AI tells of efforts by US researchers during the 1980s to train a computer system that could distinguish between images of tanks from the US and USSR. The resulting system delivered high accuracy on its training data, but failed repeatedly in practice. The system was subsequently found to be classifying images based on their resolution and background features -is the image grainy? Does it contain snow? -rather than the tanks themselves. It found patterns in the data that were co-incident, rather than causal. That same error has real-world implications for the AI systems deployed today. In medical sciences, AI systems trained to detect collapsed lungs from medical images have been proven inaccurate, after the model was found to have learned to detect the tube inserted into the lung to enable a patient to breath as a response to its collapse, rather than the physical features of the lung itself [44]. In medical sciences, deployment of such systems could put patient care at risk. In social sciences, these AI design and data bias failures can combine to marginalise vulnerable populations [45].</p>
<p>Conversely, an understanding of the structures within data can improve the accuracy of machine learning analyses. In exoplanet discovery, for example, machine learning is used as a tool to detect variations in light signals from large-scale astronomical datasets. The movement of exoplanets around stars results in periodic changes to the light signals from those stars, as the planet obscures them in its transit. Machine learning can detect those signals and predict where exoplanets might be located, but the data is often noisy. Noticing that the structure of this noise was consistent across a number of stars, which were too distant from each other to be interacting, researchers concluded that instrumentation effects were distorting the data, and developed a method to model those effects and remove them from exoplanet predictions. The result was an efficient method for exoplanet identification that subsequently contributed to the discovery of the first potentially habitable planet [46].</p>
<p>Causal models as a route to advancing the science of AI and AI for science</p>
<p>Many of these errors in misdiagnosing cause-effect relationships arise from a core assumption in many machine learning methods: that data follows an independent and identical distribution (IID). In practice, almost all data from real-world, or complex, systems will violate this assumption, given the interconnectedness of different variables. The task of causality in machine learning is to create models that can manage this violation, distinguishing between patterns in data that simply co-occur and patterns that are causal. The resulting AI systems would be able to solve a task in many different environments, based on an understanding of the fundamental causal mechanisms in a system [47]. They would be more robust in deployment, being less likely to make incorrect predictions as the environment in which they operate changes, and could be more efficient to train and deploy. They would also represent a step towards replicating human-or animal-like intelligence, being able to solve a task in many different environments. In these regards, causal machine learning offers a route to balancing the widespread utility of statistical modelling with the strengths of physical models. Causality allows models to operate at a level of abstraction beyond strongly mechanistic approaches, such as those based on differential equations, moving along a continuum from mechanistic to data-driven modelling. They provide researchers with the ability to make accurate predictions under conditions of dataset shift (enable out of distribution generalisation); can provide insights into the physical processes that drive the behaviour of a system; unlock progress towards AI systems that 'think' in the sense of acting in an imagined space; while also leveraging insights that can be learned from data, but not otherwise detected. 28 They also offer opportunities to explore counterfactuals in complex systems, asking what the impact of different interventions could have been, opening a door to the development of simulation-based decision-making tools. 29 Achieving this potential requires technical developments in a number of directions, but can also yield more effective AI systems. Such systems would:</p>
<p>• Be able to operate on out of distribution data, performing the task for which they are trained in environments with varying conditions.</p>
<p>• Be able to learn how to perform a task based on relatively few examples of that task in different conditions, or be able to rapidly adapt what they have learned for application in new environments through transfer, one-shot, or lifelong learning approaches.</p>
<p>• Support users to analyse the impact of different interventions on a system, providing explanations or ways of attributing credit to different actions.</p>
<p>• Respond to different ways of transmitting information between individuals and groups, enabling effective communication with their users or other forms of cultural learning.</p>
<p>From methods to application</p>
<p>Achieving the level of technical sophistication required for causal modelling requires careful model design, based on close collaboration between machine learning and domain scientists. The process of specifying what to represent in a causal machine learning system involves a series of 'micro-decisions' about how to construct the model, negotiated by integrating machine learning and domain expertise. In this regard, causal machine learning can be a positive catalyst for deeper interdisciplinary collaboration; model construction can be a convening point for sharing understandings between domains. However, the level of detail required can also be in tension with efforts to promote widespread adoption of AI methods across research. The availability of easy-to-use, off-the-shelf AI tools has been an enabler for adoption in many domains. The hand-crafted approach inherent to current causal methods renders them less accessible to non-expert users. Part of the challenge for the field is to make such methods more broadly accessible through open-source toolkits or effective software engineering practices. This tension between specification and learning also highlights the importance of nurturing a diversity of methods across the spectrum from data-driven to mechanistic modelling. The domain (or, how much prior knowledge is available and what knowledge should be included), research question of interest, and other practical factors (including, for example, compute budget), will shape where along this spectrum researchers wish to target their modelling efforts.</p>
<p>While pursuing practical applications, advances in causal inference could help answer broader questions about the nature of intelligence and the role of causal representations in human understanding of how the worlds work. Much of human understanding of the world arises from observing cause and effect; seeing what reaction follows an intervention -that an object falls when dropped, for example -in a way that generalises across circumstances and does not require detailed understanding of mathematical or physical laws. Integrating this ability into machine learning would help create systems that could be deployed on a variety of tasks. The process of building causal machine learning forces researchers to interrogate the nature of causal representations -What are they? How are they constructed from the interaction between intelligent agents and the world? By what mechanism can such agents connect low-level observations to high-level causal variables? -which may in turn support wider advances in the science of AI.</p>
<p>Directions</p>
<p>Causality in machine learning is a long-standing and complex challenge. In the context of scientific discovery, learning strategy, model design, and encoding domain knowledge all play a role in helping identify cause-effect relationships.</p>
<p>Different learning strategies can improve the 'generalisability' of machine learning, increasing its performance on previously unseen tasks, based on learning underlying structure of a task or environment in ways that can contribute to broader understandings of causality. Such learning strategies include:</p>
<p>• Transfer learning, taking learning from one task or domain and applying it in another.</p>
<p>• Multi-task learning, enabling a system to solve multiple tasks in multiple environments.</p>
<p>• Adversarial learning, to reduce the vulnerability of models to performance degradation on out-of-distribution data.</p>
<p>• Causal representation learning, defining variables that are related by causal models [46].</p>
<p>• Reinforcement learning strategies that reward agents for identifying policies based on invariances over different conditions. Across these new learning approaches, attempts to establish causal mechanisms are also prompting progress in machine learning theory, through statistical formulations of core principles [49].</p>
<p>Combining different methods can also enhance the functionality of an AI system. For example:</p>
<p>• Neural ODEs have been shown to identify causal structures in time series data [50].</p>
<p>• Describing causal effects as objective functions in constrained optimisation problems can deliver a form of stochastic causal programming [51].</p>
<p>• Technical interventions [52] can constrain or optimise a model towards causal outcomes. As with simulation design, diagnostic checks can also help identify cause-effect relationships by examining model outputs against 'reality criteria', 30 which compare outputs to real-world results.</p>
<p>There are also a variety of approaches to representing existing scientific knowledge in machine learning models, notably by specifying the assumptions made about the world through symmetries, invariances, and physical laws (see Figure 1).</p>
<p>Talks given during this workshop session</p>
<p>Causality, causal digital twins, and their applications</p>
<p>Bernhard Schölkopf</p>
<ol>
<li>
<p>Desiderata for causal machine learning: work with (and benefit from) non-IID data, multi-task/multi-environment, sample-efficient, OOD, generalisation from observation of marginals, interventional.</p>
</li>
<li>
<p>Modelling taxonomy: differential equations, causal models, statistical models.</p>
</li>
<li>
<p>How to get from one level to the next.</p>
</li>
<li>
<p>How to transfer between statistical models that share the same underlying causal model.</p>
</li>
</ol>
<p>5.</p>
<p>The assumption of independent causal mechanisms (ICM) (for example, invariance/autonomy) and sparse mechanism design.</p>
<ol>
<li>
<p>How to derive the arrow of time from ICM and algorithmic information theory.</p>
</li>
<li>
<p>Statistical formulation of ICM: causal de Finetti.</p>
</li>
<li>
<p>Application to exoplanet discovery and Covid-19 vaccine scenarios.</p>
</li>
<li>
<p>Causal representations as (a) causal digital twins and (b) AI models.</p>
</li>
</ol>
<p>Invariance: From Causality to Distribution Generalization</p>
<p>Jonas Peters</p>
<p>Assume that we observe data from a response Y and a set of covariates X under different experimental conditions (or environments). Rather than focusing on the model that is most predictive, it has been suggested to take into account the invariance of a model. This can help us to infer causal structure (Which covariates are causes of Y ?) and find models that generalize better (How well does the model perform on an unseen environment?). We show a few applications of these general principles and discuss first steps towards understanding the corresponding theoretical guarantees and limits.</p>
<p>Can we discover dynamical laws from observation?</p>
<p>Niki Kilbertus I will start with a brief introduction to identifiability of ODE systems from a unique continuous or discrete observed solution trajectory. Then, I will provide an overview of modern approaches to inferring dynamical laws (in the form of ODEs) from observational data with a particular focus on interpretability and symbolic methods. Finally, I will describe our recent attempts and results at inferring scalar ODEs in symbolic form from a single irregularly sampled, noisy solution trajectory.</p>
<p>Invariances and equivariances in machine learning</p>
<p>Soledad Villar</p>
<p>In this talk, we give an overview of the progress in the last few years by several research groups in designing machine learning methods that repeat physical laws. Some of these frameworks make use of irreducible representations, some make use of high-order tensor objects, and some apply symmetry enforcing constraints. Our work shows that it is simple to parameterise universally approximating functions that are equivariant under actions of the Euclidean, Lorentz, and Poincare group at any dimensionality. The key observation is that O(d)-equivariant (and related group-equivariant) functions can be universally expressed in terms of a lightweight collection of dimensionless scalars (scalar products and scalar contractions of the scarla, vector, and tensor inputs). We complement our theory with numerical examples that show that the scalar-based method is simple and efficient, and mention ongoing work on cosmology simulations.</p>
<p>Divide-and-Conquer Equation Learning with R2 and Bayesian Model Evidence</p>
<p>Bubacarr Bah</p>
<p>Deep learning is a powerful method for tasks like predictions and classification, but lacks interpretability and analytic access. Instead of fitting up to millions of parameters, an intriguing alternative for a wide range of problems would be to learn the governing equations from data. Resulting models would be concise, parameters can be interpreted, the model can adjust to shifts in data, and analytic analysis allows for extra insights. Common challenges are model complexity identification, stable feature selection, expressivity, computational feasibility, and scarce data. In our work, the mentioned challenges are addressed by combining existing methods in a novel way. We choose multiple regression as a framework and argue how a surprisingly large space of model equations can be captured. For feature selection, we exploit the computationally cheap coefficient of determination (R2) to loop through millions of models, and by using a divide-and-conquer strategy, we are able to rule out remaining models in the equation class. Final model selection is achieved by exact values of the Bayesian model evidence with empirical priors, which is known to identify suitable model complexity without relying on mass data. Random polynomials, and a couple of chaotic systems are used as examples.  Figure 1: Models along a spectrum from classical i.i.d models to strongly mechanistic differential equation models introduce aspects of causality and symmetries to create a continuum between mechanistic and data-driven worlds. Statistical or data-driven models are weakly mechanistic (i.e. they include smoothness assumptions or similar).</p>
<p>Encoding domain knowledge</p>
<p>Where's My [Science] Jetpack?</p>
<p>Humans have a long history of imagining futures where human progress is accelerated by intelligent machines. Embedded in these visions for the future are aspirations that AI can be a faithful servant, easing daily activities or enhancing human activities [54]. As with many emerging technologies, the reality of AI today looks different to these Sci-Fi futures. 31 Practical experiences of deploying AI highlights a range of potential failure modes, often rooted in insufficient contextual awareness, misspecification of user needs, or misunderstanding of environmental dynamics [55].</p>
<p>Today's science builds on thousands of years of attempts to understand the world, which can be leveraged to design AI that serves scientific goals. The result should be a collaborative endeavour between humans and machines. Researchers need the analytical power of AI to make sense of the world, while AI needs input from human understandings of the domain in which it is deployed to function effectively; both need well-designed human-machine interfaces to make this collaboration work. In this context, effective integration of domain knowledge into AI systems is vital, and three (broad) strategies have emerged to facilitate this encoding: algorithmic design; AI integration in the lab; and effective communication and collaboration.</p>
<p>Encoding domain knowledge through model design</p>
<p>Traditional modelling approaches make use of well-defined rules or equations that explain the dynamics of the system under study. The laws of physics, for example, describe how energy moves through a system, based on conservation principles. These laws are complemented by mathematical symmetries that arise from our abstract representations of physical objects and describe what features of an object remain consistent, despite changes or transformations in a system [56]. There may also be known invariances in a system: factors that do not change under any perturbations or that change in a defined way [57]. Building on this existing knowledge, and connecting to efforts to generate causal understandings of the world through machine learning, an area of growing interest has been the design of machine learning models that respect these rules or symmetries.</p>
<p>The principle underpinning this design strategy is that it is possible to move across a continuum from statistical (data-driven) models to strongly mechanistic models, creating hybrid systems whose outputs should be constrained by what is physically feasible, while also leveraging insights from data ( Figure 1).  At one end of that continuum, mechanistic models would obey known laws or principles in a strongly deterministic way; at the other, statistical models encode fewer assumptions and rely more on data [58]. The addition of invariances and symmetries, alongside other forms of domain knowledge, allows bridging between these two model classes (Figure 1). Models that describe how much heat is absorbed by the oceans under conditions of climate change, for example, should obey the laws of thermodynamics and energy conservation. By encoding the domain knowledge that has yielded these fundamental laws, such as the conservation of momentum or energy, researchers can ensure the outputs of a machine learning model will have a physically allowable expression. This encoding can come from integrating equations, symmetries, or invariances into model design. These encodings constrain the operation of a machine learning system to align with the known dynamics of physical systems. The resulting models might be expected to produce more accurate results, with smaller generalisation errors, and with better out-of-distribution generalisation.</p>
<p>Scientific centaurs</p>
<p>Complementing modelling strategies to encode scientific knowledge are deployment strategies to use AI in the lab. The lab has long provided a physical hub for collaboration and knowledgegeneration, its function and form having remained broadly consistent across centuries of scientific progress. Today, the digitisation of experimental equipment and laboratory processes offers opportunities to integrate AI in experimental design and create new virtual labs.</p>
<p>By combining data from measurement devices, simulations of laboratory processes, and computational models of research or user objectives, these virtual labs provide a digital sibling of in-person research activities that can be used to optimise such activities. In drug discovery, for example, virtual labs could accelerate the testing and analysis processes that identify candidate drugs from potential drug targets. Instead of relying on physical testing of such starting molecules, multiple rounds of virtual testing can rapidly simulate the processes of drug design, manufacture, testing, and analysis to assess which starting molecules are more (or less) likely to be viable candidate drugs [59]. As a result, AI can help accelerate the research process.</p>
<p>Advances in machine learning methods to enable effective simulations, causal modelling, and encoding pre-existing domain insights -while packaging such methods into usable toolkits -are all necessary foundations for such digital siblings. Moving from virtual laboratory to 'AI assistants' requires further advances in AI system design to create AI agents that can elicit guidance or input from their domain experts. Such agents would not only provide useful intuitions for scientific modelling, but would serve as 'scientific sidekicks', actively helping researchers to drive their research.</p>
<p>This new type of AI assistant would combine the ability to model the research problem of interest with the ability to model the goals and preferences of their expert users, even when the user themselves might not be able to clearly articulate those goals. As a starting point, these systems would need to support forms of user interaction that can extract user knowledge, leveraging this to identify appropriate courses of action. To operate in contexts where user goals might be uncertain and user behaviour might change in response to the outputs of the AI system, these AI sidekicks will need insights from cognitive science, studies of team decision-making, and new learning strategies based on limited examples. The sophisticated user modelling so-created would unlock new forms of human-AI collaboration; scientific centaurs that combine both human and machine intelligence [60].</p>
<p>Enabling communication across domains</p>
<p>Underpinning these efforts to integrate pre-existing knowledge into the design and deployment of AI systems is a feedback loop between domain and machine learning research, in which each elicits from and feeds into the other. This loop requires the ability to exchange knowledge and insights across disciplines through interdisciplinary collaboration and communication.</p>
<p>Matching model to user need requires shared understandings of the research question at hand, the constraints -whether from data, compute, funding, or time and energy availablethat affect different collaborators, and the user needs of the domain environment. While AI researchers might be tempted to develop complex models, showcasing assorted theoretical and methodological advances in the field, from a domain perspective, a relatively 'simple' model may seem preferable. Collaborators need to be able to mutually explore what is possible, while also considering what is useful.</p>
<p>To complete the loop, outputs from machine learning models need to feed back into the application domain: insights from AI need to be accessible in ways that allow the transfer of learning from model to user. This implies some level of explainability. It is not sufficient for an AI system to produce highly accurate results; those results must also be interpretable by a domain researcher. As the complexity of AI systems increases, however, understanding why these systems have produced a particular result becomes increasingly challenging. While not an issue for all machine learning methods, this complexity often results in difficulties explaining the functioning of AI systems.</p>
<p>In response, AI researchers have developed a variety of different methods to interrogate how AI systems work, or why a particular output has been produced. Again, to understand which of these methods is desirable in the context of a scientific application, researchers must collaborate closely with domain experts. In the context of pharmaceutical experiments where the aim is to measure how many target cells are killed off at different dosages of a drug (or drug combination), for example, researchers might be seeking to 'sense-check' how different drug dosages affect the model, before investigating specific drugs more rigorously. In astronomical studies, researchers are often working with high-dimensional datasets with many confounding correlations. For example, gravitational waves are ripples in space-time catalysed by the movement of massive bodies in space, such as planets or stars [61]. These invisible phenomena are studied at observatories across the world, 32 based on models to describe wave signals and the 'noise' generated by instruments that measure them [62]. Measurements of gravitational waves can be used to infer the properties of black holes that create them, such as their location, mass, and spin, using simulation-based inference to characterise the source of a wave, given the data that detects it. To make such methods more efficient than existing analytical tools, researchers need to take into account the structure that sits underneath it: for example, gravitational wave detectors are located across the globe, and their location affects the angle at which they detect waves hitting the Earth. This structure can be exploited through data sampling strategies to help make machine learning more efficient [62]. An alternative, however, is to use deterministic models that already reflect relevant physical laws [63]. Across these approaches, software packages play an important role in enabling communication and dissemination of methods for wider use. 33 </p>
<p>Directions</p>
<p>New modelling approaches and mathematical innovations offer exciting opportunities to integrate domain knowledge, symmetries and invariances into AI systems [64]. Integration can be achieved in different ways:</p>
<p>• Data augmentation can help exploit invariances and symmetries, resulting in improved model performance, by including in the data domain knowledge for a model to ingest.</p>
<p>• Symmetries can be embedded in the design of deep learning systems, for example by using the same convolutional filters in different locations of an image, CNNs can leverage translation and rotation symmetries.</p>
<p>• Latent force models allow representations of known symmetries alongside probabilistic factors, enabling integration of mechanistic models with unknown forces [65,66].</p>
<p>• Architectural features can restrict model focus to outputs that satisfy symmetries, for example using weight sharing, irreducible representations, or invoking symmetries as constraints. 34 • Loss functions can be deployed to penalise predictions that fail to satisfy physical constraints or symmetries.</p>
<p>In the process, emerging mathematical questions include: how can AI learn invariances from data? And is it possible to quantify the performance gain achieved through this?</p>
<p>Research to develop AI assistants in the lab raises interesting questions about learning strategies and human-machine collaboration. These AI agents would need to be able to learn how to assist another agent, in a multi-agent decision-making scenario, where goals might be unclear, uncertain, or changeable. To tackle this challenge:</p>
<p>• Decision-making with delayed reward or zero-shot learning can help agents solve tasks when there is little or nothing known about the reward function, and no previous behaviour to learn from.</p>
<p>• Interactive knowledge elicitation [70], combining prior knowledge from cognitive science with learning from data [71], and generative user models [72] can support more effective interactions between user and machine.</p>
<p>Across these areas, care is needed in the design of the points of interaction between human and AI system. A core question here is: how can AI researchers extract domain knowledge from relevant experts and integrate it into a machine learning model? Insights from human-machine 32 See, for example, the LIGO project. Information available at: https://www.ligo.caltech.edu 33 See, for example: https://lscsoft.docs.ligo.org/bilby/ 34 See, for example: [67,68,69] interaction studies and collaborative decision-making systems are necessary to create effective interfaces between human and machine, based on factors such as:</p>
<p>• What forms of visualisation are helpful for human users?</p>
<p>• What types of interpretability or explainability are needed for a user to achieve their desired interactions?</p>
<p>• What might be the unintended consequences of human-machine interaction, such as over-confidence in results or over-reliance on the AI system?</p>
<p>• What 'theory of mind' is needed to anticipate how human users might be likely to respond to an AI system?</p>
<p>A challenge in these interactions is that much of the relevant knowledge held by the domain expert might be qualitative: an intuition of how a system works, developed over a long period of study, rather than quantifiable insights.</p>
<p>Talks given during this workshop session</p>
<p>Virtual laboratories for science, assisted by collaborative AI</p>
<p>Samuel Kaski</p>
<p>I introduced two ideas: virtual laboratories for science, aiming to introduce an interface between algorithms and domain science that enables AI-driven scale advantages, and AI-based 'sidekick' assistants, able to help other agents research their goals, even when they are not able to yet specify the goal explicitly, or it is evolving. Such assistants would ultimately be able to help human domain experts run experiments in the virtual laboratories. I invited researchers to join the virtual laboratory movement, both domain scientists in hosting a virtual laboratory in their field and methods researchers in contributing new methods to virtual laboratories, simply by providing compatible interfaces in their code. For developing the assistants, I introduced the basic problem of agents that are able to help other agents reach their goals, also in zero-short settings, formulated the problem, and introduced solutions in the simplified setting of prior knowledge elicitation, and in AI-assistted decision and design tasks.</p>
<p>Making data analysis more like classical physics</p>
<p>David W. Hogg</p>
<p>The laws of physics are very structured: They involve coordinate-free forms, they are equivariant to a panoply of group actions, and they can be written entirely in terms of dimensionless, invariant quantities. We find that many existing machine-learning methods can be very straightforwardly modified to obey the rules that physical law must obey; physics structure can be implemented without big engineering efforts. We also find that these modifications often lead to improvements in generalization, including out-of-sample generalization, in natural-science contexts. We have some intuitions about why.</p>
<p>The second example is work by Dan Sheldon on analysis of doppler radar to extract bird biomass and motion. The radar measures the radial velocity modulo a constant (i.e., the velocity wraps around to zero). Previous work had attempted to "unwrap" the data using heuristics. Dan instead incorporated the modulus operation into the likelihood function and then developing an algorithm for maximizing this somewhat nasty likelihood. The result has revolutionized radar analysis and has been deployed in the BirdCast product from the Cornell Lab of Ornithology.</p>
<p>The third example is the species occupancy model introduced by MacKenzie et al (2002). When human observers conduct wildlife surveys, they may fail to detect a species even though the species is present. The occupancy model combines this detection probability with a habitat model. However, the expressiveness of the two models (detection and habitat) must be carefully controlled. Rebecca Hutchinson and I learned this when we tried to replace the linear logistic regression models with boosted trees.</p>
<p>In all cases, downstream use of the estimates that come from such data collection models must be aware of the measurement uncertainties. How can we correctly quantify those uncertainties and incorporate them in the downstream analysis? Maybe there are lessons ecologists can learn from physicists?</p>
<p>Latent force models</p>
<p>Mauricio A.Álvarez</p>
<p>A latent force model is a Gaussian process with a covariance function inspired by a differential operator. Such a covariance function is obtained by performing convolution integrals between Green's functions associated with the differential operators, and covariance functions associated with latent functions. Latent force models have been used in several different fields for grey box modelling and Bayesian inversion. In this talk, I will introduce latent force models and several recent works in my group where we have extended this framework to non-linear problems.</p>
<p>Translating mechanistic understandings to stochastic models</p>
<p>Carl Henrik Ek</p>
<p>Statistical learning holds the promise of being the glue that allows us to improve knowledge parametrised explicitly by a mechanistic model with implicit knowledge through empirical evidence. Statistical inference provides a narrative of how to integrate these two sources of information leading to an explanation of the empirical evidence in "light" of the explicit knowledge. While the two sources of knowledge are exchangeable in terms of predictive performance they are not if our focus is that of statistical learning as a tool for science where we want to derive new knowledge.</p>
<p>In this talk we will focus on challenges associated with translating our mechanistic understanding into stochastic models such that they can be integrated with data. In particular, we will focus on the challenges of translating composite knowledge. We will show how these structures and the computational intractabilities they lead to make knowledge discovery challenging.</p>
<p>The perceived 'success' of machine learning comes from application where we have large volumes of data such that only simple and generic models are needed in order to regularise the problem. This means that much of the progress that have been made with predictive models are challenging to translate into useful mechanisms for scientific applications. In this talk we will focus on challenges associated with translating our mechanistic understanding into stochastic models such that they can be integrated with data. In specific we will focus on the challenges of translating composite knowledge. We will show how these structures and the computational intractabilities they lead to makes knowledge discovery challenging. We will discuss properties that we desire from such structures and highlight the large gap that exists with current inference mechanism.</p>
<p>6 A research agenda in AI for science 'AI for science' sits at a nexus of disciplines, methods, and communities. Both AI and 'science' (broadly defined) share a core interest in learning from data. From this interest emerge different research directions: for AI, questions about the nature of intelligence and how to understand the learning process in humans and machines; for science, the outputs of this learning process are the focus, with the aim of adding new knowledge about natural, physical, and social systems. A distinctive feature of the emerging 'AI for science' agenda is the ability to move between these worlds, using AI to drive progress in science and taking inspiration from science to inspire progress in AI. The result is a continuum of modelling approaches along a spectrum from strongly mechanistic to statistical models, which allow researchers to introduce or operate at different levels of abstraction.</p>
<p>The AI for science community therefore combines the ambitions of AI research with domain-specific goals to advance the frontiers of research and innovation in their discipline, with an engineering focus on designing systems that work in deployment, while operating across scales from the nano-to the interstellar. From these interfaces emerges a research agenda that -if successful -promises to accelerate progress across disciplines. Inspired by discussions at the Dagstuhl workshop, a list of research questions arising from this agenda is given in Annex 2. These span three themes: Building AI systems for science: Attempts to deploy AI in the context of scientific discovery have exposed a collection of gaps in current machine learning and AI capabilities. Further work is needed to develop the technical capabilities that will allow AI to be used more effectively in research and innovation; developing those capabilities also offers opportunities to contribute to wider attempts to deliver sophisticated AI systems. Areas for progress include:</p>
<p>• Advancing methods, software and toolkits for high-quality simulation and emulation, which integrate effective uncertainty quantification and leverage advances in machine learning robustness to ensure they operate safely and effectively.</p>
<p>• Detecting scientifically meaningful structure in data, through advances in causal machine learning.</p>
<p>• Encoding domain knowledge in AI systems through integration of scientific laws, principles, symmetries, or invariances in machine learning models, and through virtual, autonomous systems to make research more effective.</p>
<p>Combining human and machine intelligence: Effective deployment of AI in science requires effective interactions between human, domain and machine intelligence across all stages of the deployment pathway. AI systems can be made more effective by integrating pre-existing knowledge about the system of study, but mechanisms are needed to extract and encode that knowledge. Effective interfaces are also required in the reverse direction.</p>
<p>Translating the outputs of AI analysis to increased human capability requires an understanding of what insights are relevant, how they are best communicated, and the cultural environment that shapes the conduct of science. Areas for progress include:</p>
<p>• Designing interfaces between humans and machines or AI agents that can extract, formalise, and assimilate knowledge that domain researchers have acquired, including tacit knowledge, and that communicate new knowledge back to the user as actionable insights.</p>
<p>• Building mechanisms for explainability that allow researchers to interrogate why and how an AI system delivered a particular result, with the explanations provided being tailored to user need.</p>
<p>• Accelerating the pace of knowledge creation and use, through systems that mine the existing research knowledge base or that automate repetitive or time-consuming elements of the research process.</p>
<p>Creating new interfaces</p>
<p>Mechanistic models Data-driven models</p>
<p>AI researchers Domain researchers</p>
<p>Integrating modelling approaches to create a continuum of methods from data-driven to mechanistic.</p>
<p>Interdisciplinary collaborations to co-design novel AI-enabled solutions.</p>
<p>Extracting insights from data-driven models and feeding them into domain models to create more effective systems.</p>
<p>Developing high-performing AI methods and tools, through building effective simulations, developing causal machine learning, and encoding domain knowledge. Figure 3: Interfaces between machine learning and domain researchers, and between data-driven and mechanistic models.</p>
<p>Influencing practice and adoption: By learning from recent experiences of deploying AI for science, the field has an opportunity to promote wider uptake and progress in both scientific domains and in AI research. This requires capturing both the knowledge that the community has already generated, about how to design AI systems, and the know-how about how to overcome practical challenges that accompanies it, while taking action to grow the community of researchers excited about the potential of AI in science. Areas for progress include:</p>
<p>• Supporting new applications, through challenge-led research programmes that promote interdisciplinary collaborations and support co-design of AI systems to help tackle scientific challenges.</p>
<p>• Developing toolkits and user guides that allow researchers to understand which AI tools are suitable for which purposes, and how to deploy those tools in practice.</p>
<p>• Sharing skills and know-how, through community outreach that disseminates knowledge and know-how in how to use AI.</p>
<p>Together, these areas for action highlight the importance of interfaces -between researchers and between modelling approaches -in shaping the development of AI for science ( Figure 3).</p>
<p>Accelerating progress in AI for science</p>
<p>Building on the impressive advances that machine learning has already supported in many domains, widespread adoption of AI for research has the potential to catalyse a new wave of innovations that in turn could drive greater health, wealth, and wellbeing. The question facing researchers, funders, and policymakers today is how to harness that potential. The challenge is to build capability across the research landscape, connect areas of expertise to areas of need, and to accelerate the transfer of successful ideas between domains.</p>
<p>The experiences of deploying AI for science described in this document, and the research agenda that results from these experiences, suggest a roadmap for action. That roadmap charts a pathway to create an enabling environment for AI in science, by advancing research that delivers AI methods to support scientific discovery, building tools and resources to make AI accessible, championing interdisciplinary research and the people pursuing it, and nurturing a community at the interface of these different domains. Progress across these areas can unlock scientific and methodological advances in AI for science, while also helping answer an emerging question about whether there exists a core discipline of 'AI for science'. The shared themes and interests that emerge from research projects at the interface of AI and scientific domains suggest that there is potential for 'AI for science' to surface as a distinct speciality in computer science. In parallel, domain-specific efforts to drive the adoption of AI as an enabler of innovation are also needed to deliver the benefits of AI for scientific discovery.</p>
<p>Advance new methods and applications</p>
<p>Efforts to deploy AI in the context of research have highlighted cross-cutting challenges where further progress in AI methods and theory is needed to create tools that can be used more reliably and effectively in the scientific context. Effective simulations are needed to study the dynamics of complex systems; causal methods to understand why those dynamics emerge; and integration of domain knowledge to relate those understandings to the wider world. While elements of these research challenges are shared with other fields -topics such as robustness, explainability, and human-machine interaction also come to the fore in fields such as AI ethics, for example -they share an intersection in the use of AI for science, in the context of efforts to bridge mechanistic and data-driven modelling.</p>
<p>Alongside these 'AI' challenges are a collection of 'science' challenges, where researchers, policymakers and publics have aspirations for AI to deliver real-world benefits. 35 Such challenges offer the opportunity to accelerate progress in AI, while facilitating interdisciplinary exchanges, and opening the field to input from citizen science or other public engagement initiatives. In developing these research missions, care is needed to define cross-cutting questions or challenges that broaden scientific imaginations, rather than restricting them. The process of converting a complicated scientific problem into something tractable with AI necessarily involves some narrowing of focus; to be successful, mission-led innovation efforts must achieve this focus without losing meaning, or creating benchmarks that misrepresent the complexity of the real-world challenge.</p>
<p>Defining shared challenges could help rally the AI for science community and drive progress in both methods and applications of AI in science. There already exists examples of how such challenges can build coalitions of researchers across domains from which the field can draw inspiration. These include the GREAT08 project, which developed image analysis techniques to study gravitational lensing [73]; the Open Problems in Single Cell Biology challenge, which convened the machine learning community to make progress in Multimodal Single-Cell Data Integration; 36 and the SENSORIUM challenge, focused on advancing understandings of how the brain processes visual inputs. 37 </p>
<p>Invest in tools and toolkits</p>
<p>Complementing these efforts to build and share knowledge, well-designed software tools can help make accessible the craft skills (or know-how) that make AI for science projects successful.</p>
<p>Modelling is a core component of all AI for science projects. In some aspects, the task for the field can be thought of as charting a path between the statistician, whose effectiveness comes from proximity to the domain but whose methods struggle to scale, and the mathematician, whose tools are adopted across domains but with some loss of meaning as the distance between method-generator and adopter increases. The energy already invested in building effective machine learning models can be leveraged for wider progress across domains through investment in toolkits that support the generalisation of effective approaches. Wide-spectrum modelling tools could offer 'off the shelf' solutions to common AI for science research questions. The challenge for such toolkits is to create an effective interface between tool and user. Connecting with the field of human-computer interaction could generate design insights or protocols to help create more effective human-AI interfaces.</p>
<p>Best practices in software engineering can help, through documentation that supports users to successfully deploy modelling tools. User guides -or taxonomies of which models are best suited for which purposes and under what circumstances -can also help make accessible to non-expect users the accumulated know-how that machine learning researchers have gained through years of model development and deployment.</p>
<p>A related engineering challenge is that of data management and pipeline-building. To interrogate how a model works, why a result was achieved, or whether an AI system is working effectively, researchers often benefit from being able to track which data contributed to which output. The data management best practices that allow such tracking need to be embedded across AI for science projects. Data management frameworks -such as the FAIR data principles -have already been developed with the intention of making data more available, and useful, for research. Further investment is now needed in efforts to implement those principles in practice.</p>
<p>Investment in these foundational tools and resources can help build understanding of which AI methods can be used and for what purposes, lowering the barriers to adopting AI methods across disciplines.</p>
<p>Build capability across disciplines</p>
<p>Central to progress in both research and toolkit engineering is the availability of talented researchers with a passion for advancing science through AI. People matter at all stages of the AI development and deployment pipeline. Successful projects rely on researchers who are motivated to work at the interface of different domains; collaborators who can explain and communicate core concepts in their work across disciplinary boundaries; engineers who can translate the needs of different users into AI toolkits; and convenors that can inspire wider engagement with the AI for science agenda.</p>
<p>Building these capabilities requires multiple points of engagement. Domain researchers need access to learning and development activities that allow them to understand and use foundational methods in machine learning, whether as formal training or through the availability of tutorials or user guides. AI researchers need access to the scientific knowledge that should shape the methods they develop, the skills to translate their advanced knowledge to materials that can be shared for wider use, and the capacity to dedicate time and resource to learning about domain needs. 38 Both need skills in communication, organisation, and convening to operate across disciplines. Without such capability-building, disciplines risk remaining siloed; domains developing unrealistic expectations about what AI can deliver in practice, and AI losing touch with the scientific questions that are most meaningful to domains.</p>
<p>Institutional incentives shape how individuals engage (or not) with such interdisciplinary exchanges. Interdisciplinary research often takes longer and lacks the outlets for recognition available to those working in single domains, affecting both the motivation of and opportunities for career progression that are open to those working at the interface of different disciplines. Much of the engineering work required to make data and AI accessible beyond a specific project and useful to a wider community is also traditionally unrecognised by academic incentive structures. Aligning individual and institutional incentives in support of interdisciplinarity is a long-standing challenge in research, and one that becomes more critical to address in the context of developments in AI. In this context, there may be new opportunities to recognise and reward successes in AI for science, whether through new fellowships, prizes, or ways of promoting the work done by those at this interface.</p>
<p>Grow communities of research and practice</p>
<p>The areas for action described above feed into and from each other. Progress in research and application can be leveraged to inspire a generation of researchers to pursue interdisciplinary projects; effective toolkits can make such progress more likely; skills-building initiatives can prime researchers to be able to use these toolkits; and so on, to create an environment where researchers and research advances transition smoothly across disciplines, leading to a rising AI tide that lifts all disciplines. Communities of research and practice are the backdrop for creating such positive feedback loops.</p>
<p>A collection of AI for science initiatives are already building links across the research landscape. The Machine Learning for Science Cluster of Excellence at the University of Tübingen is leveraging the strength of its local ecosystem in AI to drive wider progress in research and innovation; 39 the Accelerate Programme for Scientific Discovery at the University of Cambridge is building bridges across disciplines, building a community passionate about opportunities in AI for science; 40 the University of Copenhagen's SCIENCE AI Centre provides a focal point for AI research and education in its Faculty for Science; 41 New York University's Center for Data Science hosts interdisciplinary faculty pursuing innovative research and education; 42 the University of Wisconsin-Madison's American Family Insurance Data Science Institute is developing strategic partnerships to accelerate the use of data science in research; 43 new investments by Schmidt Futures across a network of research institutions are supporting new postdoctoral fellowships at the interface of AI and sciences [74]. Together, these initiatives demonstrate the appetite for progress in AI for science.</p>
<p>There is an opportunity today to leverage these emerging interests into a wider movement. Existing initiatives can drive capability-building, by making training and user guides open, reaching out to engage domain researchers in skills-building activities, and fostering best practice in software and data engineering across disciplines. The links they establish across research domains can form the basis of new communication channels, whether through discussion forums, research symposia, or newsletters to share developments at the interface of AI and science. These communications can be deployed to raise the profile of people and projects at this interface, celebrating successes, sharing lessons, and demonstrating the value of interdisciplinary work. Together, they can help develop an infrastructure for AI in science.</p>
<p>That infrastructure may also benefit from new institutional interventions to address longstanding challenges in interdisciplinary AI. New journals could provide an outlet to publish and recognise high-quality AI for science research, bringing in contributions from multiple disciplines and helping translate lessons across areas of work. Membership organisations could help foster a sense of belonging and community for researchers working at the interface of AI, science, and engineering, developing career pathways and incentives. Efforts to convene across disciplines can also catalyse new connections and collaborations.</p>
<p>Emerging from these efforts is a paradigm shift in how to drive progress in science. Historically, a small number of foundational texts have been the catalyst that changed how researchers studied the world; Newton's Principia; Darwin's Origin of Species; and so on. For much of its modern history, scientific knowledge has been transmitted through textbooks; canonical descriptions of the current state of knowledge. Today, the transformative potential of AI is driven by its pervasiveness; its impact in science will be achieved through integration across disciplines. This integration requires widespread mobilisation, convening machine learning researchers, domain experts, citizen scientists, and affected communities to shape how AI technologies are developed and create an amenable environment for their deployment. It takes a community.</p>
<p>AI and science: building the interface</p>
<p>Advances in AI have disrupted traditional ways of thinking about modelling in science. Where researchers might previously have conceptualised models as mechanistic -reflecting known forces in the world -or data-driven, the 'AI for science' methods that are emerging today reject this separation. They are both, combining insights from mechanistic and data-driven methods, integrating methods to create something new. What follows from these developments is a spectrum of modelling approaches, which researchers can deploy flexibly in response to the research question of interest.</p>
<p>Today, the field of AI for science is characterised by intersections. Between AI and scientific domains; between science and engineering; between knowledge and know-how; between human and machine. It operates across disciplinary boundaries, across scales from the atomic to the universal, and across both the mission to understand intelligence and the quest to deploy human intelligence to understand the world. Emerging from these missions is a continuum of models and methods that allow researchers to work across domains, extracting the knowledge that humans have acquired, and levels of inquiry, enhancing that knowledge and returning it in actionable form.</p>
<p>As both a domain itself and an enabler of other disciplines, the power of AI in science lies in its ability to convene diverse perspectives in ways that accelerates progress across research areas. AI for science is a rendezvous point. Its next wave of development will come from taking strength from its diversity, and bringing more people into its community.</p>
<p>B Research questions arising from the 'AI for science research agenda' discussion during the Dagstuhl workshop Building AI systems for science</p>
<p>• How can AI systems accurately generalise from finite observations? How can they detect causality or structure from finite observations?</p>
<p>• What is the computational cost of complexity, and what methods can help manage this?</p>
<p>• What forms of system calibration and uncertainty quantification are useful in the context of scientific discovery? Are theoretical guarantees necessary?</p>
<p>• What new forms of explainability or interpretability could facilitate the deployment of AI in science?</p>
<p>• How could AI support generalisation from a small number of observations? What methods could enable few-or one-shot learning?</p>
<p>• How can AI researchers build meaningful models from data to accurately represent causal mechanisms in the system of study? How can researchers identify the most effective model for their system of study?</p>
<p>• What does it mean to understand a model? How can researchers combine explainability with complexity?</p>
<p>• How can AI methods be made robust and easy to use in deployment by domain scientists?</p>
<p>• How can advances in simulation methods be applied in domains where the system at hand is less easily described by equations?</p>
<p>• What advances are needed to expand the use of simulations in science? How can AI help simulate laboratory experiments or environments, helping make more efficient different elements of the scientific process? How might this be expanding in the long-term, for example to planning experimental design or helping identify where data is missing?</p>
<p>• How can 'digital siblings' be used to explore the impact of different interventions on complex systems?</p>
<p>Combining human and machine intelligence</p>
<p>• How can AI researchers best extract, formalise and assimilate the knowledge that domain researchers have acquired? What forms of knowledge representation can formalise scientific understandings of the world, translating these to objective functions for AI systems? What forms of human-AI engagement can make use of the 'qualitative' knowledge -or intuitions about a system -that domain researchers have accumulated?</p>
<p>• How can AI capture the qualitative understanding that researchers have of their domain to more accurately or effectively characterise a system?</p>
<p>• How can AI be effectively deployed to mine the existing research knowledge base -for example, papers, databases, and so on -to extract new insights?</p>
<p>• Where can automation support research progress? Which elements of the scientific process could be automated, and where is human input vital?</p>
<p>• What forms of collaboration are needed to effectively specify helpful outputs from an AI system?</p>
<p>• How can insights from AI analysis be returned to researchers in an actionable way? What mix of AI design, engineering, social interaction, and education can make effective interfaces between domain researchers and AI systems?</p>
<p>• How can the outputs of AI systems be made interpretable for scientific users?</p>
<p>• How can AI researchers better understand and design for the forms of interpretability that resonate with domain researchers?</p>
<p>• What processes of collaboration or co-design can help describe what scientists 'need to know' from an AI system?</p>
<p>• What best practices or methods can be deployed to effectively communicate uncertainty from AI systems to human users?</p>
<p>B.1 Influencing practice and adoption</p>
<p>• What are the craft skills in AI for science? What 'know-how' is necessary to make AI work effectively in practice?</p>
<p>• What skills-building or forms of outreach can help take AI tools out of the AI community and into 'the lab' ?</p>
<p>• How has machine learning been used most effectively for research and innovation? What best practices, or lessons, do existing efforts in AI for science offer?</p>
<p>• Which AI tools are suitable for which purposes, disciplines, or experimental designs? Is it possible to create a taxonomy for science?</p>
<p>• Are there generalisable methods or conclusions that can be taken from domain-specific efforts to deploy AI for science?</p>
<p>ecosystem properties: Combining machine learning and mechanistic models Christian Igel Joint work with Martin Brandt, Rasmus Fensholt, Compton J. Tucker, Ankit Kariryaa, Kjeld Rasmussen, Christin Abel, Jennifer Small, Jerome Chave, Laura Vang Rasmussen, Pierre Hiernaux, Abdoul Aziz Diouf, Laurent Kergoat, Ole Mertz, Fabian Gieseke, Sizhuo Li, Katherine Melo. https://doi.org/10.1038/s41586-020-2824-5]Brandt, M., Tucker, C.J., Kariryaa, A. et al. An unexpectedly large count of trees in the West African Sahara and Sahel. Nature 587, 78-82 (2020).</p>
<p>Figure 2 :
2Strategies for integrating domain insights: including information in data and including information as prior knowledge.</p>
<p>In pursuing this agenda, researchers can leverage well-35 See, for example: the EU's Innovation Missions https://research-and-innovation.ec. europa.eu/funding/funding-opportunities/funding-programmes-and-open-calls/horizon-europe/ eu-missions-horizon-europe_en and UN SDG's https://sdgs.un.org/goals 36 For further information, see: https://openproblems.bio/neurips_2021/ 37 For further information, see: https://sensorium2022.net/home established protocols in open-sourcing materials and sharing documentation to help ensure research advances are rapidly and effectively disseminated across disciplines. The result should be more effective methods, and an agile research environment where researchers can flex methods across disciplines.
This quote is attributed to Stephen Hawking, in an interview with the San Jose Mercury News in January 2000.2 While not the only branch of the field, machine learning is the approach to AI that has delivered many of the recent advances in AI. Machine learning is an approach to AI in which models process data, learning from that data to identify patterns or make predictions. In this document, the terms machine learning and AI are used interchangeably.3 These examples are inspired by talks given at the Dagstuhl seminar; these are provided later in the document. This example is inspired by Markus Reichstein's talk.4 This example is inspired by Ieva Kazlauskaitė's talk.5 This example is inspired by Dina Machuve's talk.6 This example is inspired by Siddharth Mishra-Sharma's talk.7 This example is inspired by Maren Büttner's talk.8 This example is inspired by Christian Igel's talk.
This example is inspired by Jakob Macke's talk.
This example is inspired by Markus Reichstein's talk, the abstract for which is provided later in this document.
This example is inspired by Markus Reichstein's talk, the abstract for which is provided later in this document.12 Under conditions of extreme temperature, patterns of stomatal opening and closing in plants changes. See, for example[4].13 This example is inspired by Ieva Kazlauskaitė's talk, the abstract for which is provided later in this document.
This example is inspired by Dina Machuve's talk, the abstract for which is provided later in this document.15 This example is inspired by Christian Igel's talk, the abstract for which is provided later in this document.
This example is inspired by Christian Igel's talk, the abstract for which is provided later in this document.17 For example:[13].18 This example is inspired by Siddharth Mishra Sharma's talk, as well as insights from Gilles Louppe's talk, the abstracts for which are provided later in this document.19 For example:[17] 
This example is inspired by Francisco Vargas's talk, the abstract for which is provided later in this document.21 Examples of agent-based models for crowd simulation include:[20,21].22 This example is inspired by Maren Büttner's talk, the abstract for which is provided later in this document.
This example is inspired by Jakob Macke's talk, the abstract for which is provided later in this document.
For reference, see the table on page 11 of reference[46].29 Such tools may have particular relevance in policy. For example:[48].
Including syntactic, semantic, and pragmatic elements:[53].
The title of this section is inspired by: https://www.fantasticfiction.com/w/daniel-h-wilson/ where-s-my-jetpack.htm
AcknowledgmentsThe Accelerate Programme for Scientific Discovery would like to thank Schmidt Futures for its continuing support, and the donation that enables its work.
A comparison here can be drawn with the development of statistics as an enabling discipline for many domains: statisticians have devoted time to understanding domain practices and integrating their work within those practices, often dedicating significant resource to understand the nature of the datasets with which they are working, before introducing modelling ideas. 39Programme website available atA comparison here can be drawn with the development of statistics as an enabling discipline for many domains: statisticians have devoted time to understanding domain practices and integrating their work within those practices, often dedicating significant resource to understand the nature of the datasets with which they are working, before introducing modelling ideas. 39 Programme website available at: https://uni-tuebingen.de/en/research/core-research/ cluster-of-excellence-machine-learning/home/.</p>
<p>Dilemmas in a general theory of planning. W J Horst, Melvin M Rittel, Webber, Policy sciences. 42Chichester: J. Wiley &amp; SonsReprinted in N. Cross, ed. Developments in design methodologyHorst W. J. Rittel and Melvin M. Webber. Dilemmas in a general theory of planning. Policy sciences, 4(2):155-169, 1973. Reprinted in N. Cross, ed. Developments in design methodology, pp. 135-44. Chichester: J. Wiley &amp; Sons, 1984.</p>
<p>Localized impacts and economic implications from high temperature disruption days under climate change. Tim Summers, Erik Mackie, Risa Ueno, Charles Simpson, J Scott Hosking, Tudor Suciu, Andrew Coburn, Emily Shuckburgh, Climate Resilience and Sustainability. 1235Tim Summers, Erik Mackie, Risa Ueno, Charles Simpson, J. Scott Hosking, Tudor Suciu, Andrew Coburn, and Emily Shuckburgh. Localized impacts and economic implications from high temperature disruption days under climate change. Climate Resilience and Sustainability, 1(2):e35, 2022.</p>
<p>Terrestrial gross carbon dioxide uptake: global distribution and covariation with climate. Christian Beer, Markus Reichstein, Enrico Tomelleri, Philippe Ciais, Martin Jung, Nuno Carvalhais, Christian Rödenbeck, M Arain, Dennis Baldocchi, Gordon B Bonan, A Bondeau, A Cescatti, G Lasslop, A Lindroth, M Lomas, S Luyssaert, H Margolis, K W Oleson, O Roupsard, E Veenendaal, N Viovy, C Williams, F I Woodward, D Papale, Science. 3295993Christian Beer, Markus Reichstein, Enrico Tomelleri, Philippe Ciais, Martin Jung, Nuno Carvalhais, Christian Rödenbeck, M. Altaf Arain, Dennis Baldocchi, Gordon B. Bonan, A. Bondeau, A. Cescatti, G. Lasslop, A. Lindroth, M. Lomas, S. Luyssaert, H. Margolis, K. W. Oleson, O. Roupsard, E. Veenendaal, N. Viovy, C. Williams, F. I. Woodward, and D. Papale. Terrestrial gross carbon dioxide uptake: global distribution and covariation with climate. Science, 329(5993):834-838, 2010.</p>
<p>Extreme heat increases stomatal conductance and drought-induced mortality risk in vulnerable plant species. M Renée, Diana Marchin, Alessandro Backes, Michelle R Ossola, Mark G Leishman, David S Tjoelker, Ellsworth, Global Change Biology. 283Renée M. Marchin, Diana Backes, Alessandro Ossola, Michelle R. Leishman, Mark G. Tjoelker, and David S. Ellsworth. Extreme heat increases stomatal conductance and drought-induced mortality risk in vulnerable plant species. Global Change Biology, 28(3):1133-1146, 2022.</p>
<p>Predicting landscapes from environmental conditions using generative networks. Christian Requena-Mesa, Markus Reichstein, Miguel Mahecha, Basil Kraft, Joachim Denzler, Pattern Recognition: 41st DAGM German Conference, DAGM GCPR 2019. Dortmund, GermanySpringer41Christian Requena-Mesa, Markus Reichstein, Miguel Mahecha, Basil Kraft, and Joachim Denzler. Predicting landscapes from environmental conditions using generative networks. In Pattern Recognition: 41st DAGM German Conference, DAGM GCPR 2019, Dortmund, Germany, September 10-13, 2019, Proceedings 41, pages 203-217. Springer, 2019.</p>
<p>IPCC special report on the ocean and cryosphere in a changing climate. Ipcc, IPCC Intergovernmental Panel on Climate Change. IPCC. IPCC special report on the ocean and cryosphere in a changing climate. IPCC Intergovernmental Panel on Climate Change: Geneva, Switzerland, 2019.</p>
<p>Understanding sea level. NASANASA. Understanding sea level,. available from: https://sealevel.nasa.gov/ understanding-sea-level/global-sea-level/ice-melt.</p>
<p>Poultry diseases diagnostics models using deep learning. Dina Machuve, Ezinne Nwankwo, Neema Mduma, Jimmy Mbelwa, Frontiers in Artificial Intelligence. 168Dina Machuve, Ezinne Nwankwo, Neema Mduma, and Jimmy Mbelwa. Poultry diseases diagnostics models using deep learning. Frontiers in Artificial Intelligence, page 168, 2022.</p>
<p>Forests and deforestation. H Ritchie, M Roser, Published online at OurWorldIn-Data.orgH. Ritchie and M. Roser. Forests and deforestation. Published online at OurWorldIn- Data.org, https://ourworldindata.org/forests-and-deforestation, 2021.</p>
<p>Morgane Dendoncker, and Rasmus Fensholt. An unexpectedly large count of trees in the west african sahara and sahel. Martin Brandt, J Compton, Ankit Tucker, Kjeld Kariryaa, Christin Rasmussen, Jennifer Abel, Jerome Small, Laura Chave, Pierre Vang Rasmussen, Aziz Hiernaux, Laurent Diouf, Ole Kergoat, Christian Mertz, Fabian Igel, Johannes Gieseke, Sizhuo Schöning, Li, Nature. 5877832Martin Brandt, Compton J. Tucker, Ankit Kariryaa, Kjeld Rasmussen, Christin Abel, Jennifer Small, Jerome Chave, Laura Vang Rasmussen, Pierre Hiernaux, Abdoul Aziz Diouf, Laurent Kergoat, Ole Mertz, Christian Igel, Fabian Gieseke, Johannes Schöning, Sizhuo Li, Katherine Melocik, Jesse Meyer, Scott Sinno, Eric Romero, Erin Glennie, Amandine Montagu, Morgane Dendoncker, and Rasmus Fensholt. An unexpectedly large count of trees in the west african sahara and sahel. Nature, 587(7832):78-82, 2020.</p>
<p>Allometric equations to estimate the dry mass of sahel woody plants mapped with very-high resolution satellite imagery. Pierre Hiernaux, Hassane Bil-Assanou, Christian Issoufou, Ankit Igel, Moussa Kariryaa, Jérôme Kourouma, Eric Chave, Patrice Mougin, Savadogo, Forest Ecology and Management. 529120653Pierre Hiernaux, Hassane Bil-Assanou Issoufou, Christian Igel, Ankit Kariryaa, Moussa Kourouma, Jérôme Chave, Eric Mougin, and Patrice Savadogo. Allometric equations to estimate the dry mass of sahel woody plants mapped with very-high resolution satellite imagery. Forest Ecology and Management, 529:120653, 2023.</p>
<p>Taking the sting out of vector borne diseases. Luis Hernandez-Triana, Ssuzanna Bell, APHA Science Blog. Luis Hernandez-Triana and Ssuzanna Bell. Taking the sting out of vector borne diseases. APHA Science Blog, available at: https://aphascience.blog.gov.uk/2022/07/06/ vector-borne-diseases/, 2022.</p>
<p>Mapping africa's buildings with satellite imagery. John Quinn, Google Research Blog. John Quinn. Mapping africa's buildings with satellite imagery. Google Research Blog, avail- able at: https://ai.googleblog.com/2021/07/mapping-africas-buildings-with. html, 2021.</p>
<p>Reduced mosquito survival in metal-roof houses may contribute to a decline in malaria transmission in sub-saharan africa. W Steve, Musa Lindsay, Julia Jawara, Jane Mwesigwa, Nabie Achan, John Bayoh, Balla Bradley, Matthew J Kandeh, Jakob Kirby, Mike Knudsen, Macdonald, Scientific reports. 917770Steve W Lindsay, Musa Jawara, Julia Mwesigwa, Jane Achan, Nabie Bayoh, John Bradley, Balla Kandeh, Matthew J. Kirby, Jakob Knudsen, Mike Macdonald, et al. Reduced mosquito survival in metal-roof houses may contribute to a decline in malaria transmission in sub-saharan africa. Scientific reports, 9(1):7770, 2019.</p>
<p>New research to combat malaria mosquitoes in african metropolises. Royal Danish Academy, Royal Danish Academy. New research to combat malaria mosquitoes in african metropolises. Available at: https://royaldanishacademy.com/news/ ny-forskning-skal-bekaempe-malariamyg-i-afrikanske-storbyer, 2022.</p>
<p>Dark energy, dark matter. NASANASA. Dark energy, dark matter. Available at: https://science.nasa.gov/ astrophysics/focus-areas/what-is-dark-energy. Last accessed March 4th 2023.</p>
<p>The ATLAS Collaboration et al. The ATLAS experiment at the CERN large hadron collider. Jinst. 38003The ATLAS Collaboration et al. The ATLAS experiment at the CERN large hadron collider. Jinst, 3:S08003, 2008.</p>
<p>Strong lensing source reconstruction using continuous neural fields. Siddharth Mishra, - Sharma, Ge Yang, 2022Technical reportSiddharth Mishra-Sharma and Ge Yang. Strong lensing source reconstruction using continuous neural fields. Technical report, 2022.</p>
<p>. Cora Dvorkin, Siddharth Mishra-Sharma, Brian Nord, V Ashley Villar, Camille Avestruz, Keith Bechtol, Andrew J Aleksandraćiprijanović, Connolly, H Lehman, Gautham Garrison, Francisco Narayan, Villaescusa-Navarro, Machine learning and cosmology. 2022Technical reportCora Dvorkin, Siddharth Mishra-Sharma, Brian Nord, V. Ashley Villar, Camille Avestruz, Keith Bechtol, AleksandraĆiprijanović, Andrew J. Connolly, Lehman H. Garrison, Gautham Narayan, and Francisco Villaescusa-Navarro. Machine learning and cosmology. Technical report, 2022.</p>
<p>Crowd flow forecasting via agent-based simulations with sequential latent parameter estimation from aggregate observation. Fumiyasu Makinoshima, Yusuke Oishi, Scientific Reports. 121Fumiyasu Makinoshima and Yusuke Oishi. Crowd flow forecasting via agent-based simulations with sequential latent parameter estimation from aggregate observation. Scientific Reports, 12(1):1-13, 2022.</p>
<p>Simulating crowds in real time with agent-based modelling and a particle filter. Nicolas Malleson, Kevin Minors, Le-Minh Kieu, Jonathan A Ward, Andrew West, Alison Heppenstall, Journal of Artificial Societies and Social Simulation. 2333Nicolas Malleson, Kevin Minors, Le-Minh Kieu, Jonathan A. Ward, Andrew West, and Alison Heppenstall. Simulating crowds in real time with agent-based modelling and a particle filter. Journal of Artificial Societies and Social Simulation, 23(3):3, 2020.</p>
<p>Solving schrödinger bridges via maximum likelihood. Francisco Vargas, Pierre Thodoroff, Austen Lamacraft, Neil D Lawrence, Entropy. 2391134Francisco Vargas, Pierre Thodoroff, Austen Lamacraft, and Neil D. Lawrence. Solving schrödinger bridges via maximum likelihood. Entropy, 23(9):1134, 2021.</p>
<p>Development and organization of cell types and tissues. K V Krishnamurthy, S. John Bir Bahadur, Padma Adams, Venkatasubramanian, Plant Diversity, Organization, Function and Improvement. IK. V. Krishnamurthy, Bir Bahadur, S. John Adams, and Padma Venkatasubramanian. Development and organization of cell types and tissues. Plant Biology and Biotechnology: Volume I: Plant Diversity, Organization, Function and Improvement, pages 73-111, 2015.</p>
<p>Diffusion pseudotime robustly reconstructs lineage branching. Laleh Haghverdi, Maren Büttner, F Alexander Wolf, Florian Buettner, Fabian J Theis, Nature methods. 1310Laleh Haghverdi, Maren Büttner, F. Alexander Wolf, Florian Buettner, and Fabian J. Theis. Diffusion pseudotime robustly reconstructs lineage branching. Nature methods, 13(10):845-848, 2016.</p>
<p>Non-canonical Wnt/PCP signalling regulates intestinal stem cell lineage priming towards enteroendocrine and paneth cell fates. Anika Böttcher, Maren Büttner, Sophie Tritschler, Michael Sterr, Alexandra Aliluev, Lena Oppenländer, Ingo Burtscher, Steffen Sass, Martin Irmler, Johannes Beckers, Christoph Ziegenhain, Wolfgang Enard, Andrea C Schamberger, Fien M Verhamme, Oliver Eickelberg, Fabian J Theis, Heiko Lickert, Nature cell biology. 231Anika Böttcher, Maren Büttner, Sophie Tritschler, Michael Sterr, Alexandra Aliluev, Lena Oppenländer, Ingo Burtscher, Steffen Sass, Martin Irmler, Johannes Beckers, Christoph Ziegenhain, Wolfgang Enard, Andrea C. Schamberger, Fien M. Verhamme, Oliver Eickelberg, Fabian J. Theis, and Heiko Lickert. Non-canonical Wnt/PCP signalling regulates intestinal stem cell lineage priming towards enteroendocrine and paneth cell fates. Nature cell biology, 23(1):23-31, 2021.</p>
<p>Benchmarking atlas-level data integration in single-cell genomics. D Malte, Maren Luecken, Kridsadakorn Büttner, Anna Chaichoompu, Marta Danese, Michaela F Interlandi, Müller, C Daniel, Luke Strobl, Martin Zappia, Maria Dugas, Fabian J Colomé-Tatché, Theis, Nature methods. 191Malte D. Luecken, Maren Büttner, Kridsadakorn Chaichoompu, Anna Danese, Marta Interlandi, Michaela F. Müller, Daniel C Strobl, Luke Zappia, Martin Dugas, Maria Colomé-Tatché, and Fabian J. Theis. Benchmarking atlas-level data integration in single-cell genomics. Nature methods, 19(1):41-50, 2022.</p>
<p>Training deep neural density estimators to identify mechanistic models of neural dynamics. eLife. J Pedro, Jan-Matthis Gonçalves, Michael Lueckmann, Marcel Deistler, Nonnenmacher, Giacomo Kaanöcal, Chaitanya Bassetto, Chintaluri, F William, Sara A Podlaski, Tim P Haddad, David S Vogels, Jakob H Greenberg, Macke, 956261Pedro J Gonçalves, Jan-Matthis Lueckmann, Michael Deistler, Marcel Nonnenmacher, KaanÖcal, Giacomo Bassetto, Chaitanya Chintaluri, William F Podlaski, Sara A. Haddad, Tim P. Vogels, David S. Greenberg, and Jakob H. Macke. Training deep neural density estimators to identify mechanistic models of neural dynamics. eLife, 9:e56261, 2020.</p>
<p>Build, compute, critique, repeat: Data analysis with latent variable models. David M Blei, Annual Review of Statistics and Its Application. 1David M. Blei. Build, compute, critique, repeat: Data analysis with latent variable models. Annual Review of Statistics and Its Application, 1:203-232, 2014.</p>
<p>The frontier of simulation-based inference. Kyle Cranmer, Johann Brehmer, Gilles Louppe, Proceedings of the National Academy of Sciences. 11748Kyle Cranmer, Johann Brehmer, and Gilles Louppe. The frontier of simulation-based inference. Proceedings of the National Academy of Sciences, 117(48):30055-30062, 2020.</p>
<p>Philipp Hennig, Michael A Osborne, Hans P Kersting, Probabilistic Numerics: Computation as Machine Learning. Cambridge University PressPhilipp Hennig, Michael A. Osborne, and Hans P. Kersting. Probabilistic Numerics: Computation as Machine Learning. Cambridge University Press, 2022.</p>
<p>A trust crisis in simulation-based inference? your posterior approximations can be unfaithful. Joeri Hermans, Arnaud Delaunoy, François Rozet, Antoine Wehenkel, Gilles Louppe, 2021Technical reportJoeri Hermans, Arnaud Delaunoy, François Rozet, Antoine Wehenkel, and Gilles Louppe. A trust crisis in simulation-based inference? your posterior approximations can be unfaithful. Technical report, 2021.</p>
<p>Fast likelihoodfree cosmology with neural density estimators and active learning. Justin Alsing, Tom Charnock, Stephen Feeney, Benjamin Wandelt, Monthly Notices of the Royal Astronomical Society. 4883Justin Alsing, Tom Charnock, Stephen Feeney, and Benjamin Wandelt. Fast likelihood- free cosmology with neural density estimators and active learning. Monthly Notices of the Royal Astronomical Society, 488(3):4440-4458, 07 2019.</p>
<p>Simulation intelligence: Towards a new generation of scientific methods. Alexander Lavin, Hector Zenil, Brooks Paige, David Krakauer, Justin Gottschlich, Tim Mattson, Anima Anandkumar, Sanjay Choudry, Kamil Rocki, Atılım Güneş Baydin, 2021Technical reportAlexander Lavin, Hector Zenil, Brooks Paige, David Krakauer, Justin Gottschlich, Tim Mattson, Anima Anandkumar, Sanjay Choudry, Kamil Rocki, Atılım Güneş Baydin, et al. Simulation intelligence: Towards a new generation of scientific methods. Technical report, 2021.</p>
<p>Active sciencing. Kyle Cranmer, Lukas Heinrich, Tim Head, Gilles Louppe, Kyle Cranmer, Lukas Heinrich, Tim head, and Gilles Louppe. Active sciencing. Available from https://github.com/cranmer/active_sciencing, 2017.</p>
<p>Flexible and efficient simulation-based inference for models of decision-making. eLife. Jan Boelts, Jan-Matthis Lueckmann, Richard Gao, Jakob H Macke, 1177220Jan Boelts, Jan-Matthis Lueckmann, Richard Gao, and Jakob H. Macke. Flexible and efficient simulation-based inference for models of decision-making. eLife, 11:e77220, 2022.</p>
<p>Uncertainty-Aware Numerical Solutions of ODEs by Bayesian Filtering. Hans Kersting, Eberhard Karls Universität TübingenPhD thesisHans Kersting. Uncertainty-Aware Numerical Solutions of ODEs by Bayesian Filtering. PhD thesis, Eberhard Karls Universität Tübingen, 2021.</p>
<p>A probabilistic state space model for joint inference from differential equations and data. Jonathan Schmidt, Nicholas Krämer, Philipp Hennig, Advances in Neural Information Processing Systems. 34Jonathan Schmidt, Nicholas Krämer, and Philipp Hennig. A probabilistic state space model for joint inference from differential equations and data. Advances in Neural Information Processing Systems, 34:12374-12385, 2021.</p>
<p>Inferring dark matter substructure with astrometric lensing beyond the power spectrum. Siddharth Mishra, - Sharma, Machine Learning: Science and Technology. 31Siddharth Mishra-Sharma. Inferring dark matter substructure with astrometric lensing beyond the power spectrum. Machine Learning: Science and Technology, 3(1):01LT03, 2022.</p>
<p>Towards reliable simulation-based inference with balanced neural ratio estimation. Arnaud Delaunoy, Joeri Hermans, François Rozet, Antoine Wehenkel, Gilles Louppe, Technical reportArnaud Delaunoy, Joeri Hermans, François Rozet, Antoine Wehenkel, and Gilles Louppe. Towards reliable simulation-based inference with balanced neural ratio estimation. Tech- nical report, 2022.</p>
<p>Robust hybrid learning with expert augmentation. Antoine Wehenkel, Jens Behrmann, Hsiang Hsu, Guillermo Sapiro, Gilles Louppe, Jörn-Henrik Jacobsen, 2022Technical reportAntoine Wehenkel, Jens Behrmann, Hsiang Hsu, Guillermo Sapiro, Gilles Louppe, and Jörn-Henrik Jacobsen. Robust hybrid learning with expert augmentation. Technical report, 2022.</p>
<p>Investigating the impact of model misspecification in neural simulation-based inference. Patrick Cannon, Daniel Ward, Sebastian M Schmon, 2022Technical reportPatrick Cannon, Daniel Ward, and Sebastian M. Schmon. Investigating the impact of model misspecification in neural simulation-based inference. Technical report, 2022.</p>
<p>Destination Earth -new digital twin of the Earth will help tackle climate change and protect nature. European CommissionEuropean Commission. Destination Earth -new digital twin of the Earth will help tackle climate change and protect nature. Available at https://ec.europa.eu/commission/ presscorner/detail/en/IP_22_1977, 2022.</p>
<p>Toward causal representation learning. Bernhard Schölkopf, Francesco Locatello, Stefan Bauer, Nan Rosemary Ke, Nal Kalchbrenner, Anirudh Goyal, Yoshua Bengio, Proceedings of the IEEE. 1095Bernhard Schölkopf, Francesco Locatello, Stefan Bauer, Nan Rosemary Ke, Nal Kalch- brenner, Anirudh Goyal, and Yoshua Bengio. Toward causal representation learning. Proceedings of the IEEE, 109(5):612-634, 2021.</p>
<p>Impact of confounding thoracic tubes and pleural dehiscence extent on artificial intelligence pneumothorax detection in chest radiographs. Johannes Rueckel, Lena Trappmann, Balthasar Schachtner, Philipp Wesp, Friedrich Boj, Nicola Hoppe, Jens Fink, Julien Ricke, Michael Dinkel, Bastian Oliver Ingrisch, Sabel, Investigative Radiology. 5512Johannes Rueckel, Lena Trappmann, Balthasar Schachtner, Philipp Wesp, Boj Friedrich Hoppe, Nicola Fink, Jens Ricke, Julien Dinkel, Michael Ingrisch, and Bastian Oliver Sabel. Impact of confounding thoracic tubes and pleural dehiscence extent on artificial intelligence pneumothorax detection in chest radiographs. Investigative Radiology, 55(12):792-798, 2020.</p>
<p>How a machine learns prejudice. Scientific American Blogs. Jesse Emspak, Jesse Emspak. How a machine learns prejudice. Scientific Ameri- can Blogs, available at: https://www.scientificamerican.com/article/ how-a-machine-learns-prejudice/, 2016.</p>
<p>Causality for machine learning. Bernhard Schölkopf, Probabilistic and Causal Inference: The Works of Judea Pearl. Bernhard Schölkopf. Causality for machine learning. In Probabilistic and Causal Inference: The Works of Judea Pearl, pages 765-804. 2022.</p>
<p>Elements of Causal Inference: Foundations and Learning Algorithms. Jonas Peters, Dominik Janzing, Bernhard Schölkopf, The MIT PressCambridge, MA, USAJonas Peters, Dominik Janzing, and Bernhard Schölkopf. Elements of Causal Inference: Foundations and Learning Algorithms. The MIT Press, Cambridge, MA, USA, 2017.</p>
<p>Causal analysis of covid-19 spread in germany. Atalanti Mastakouri, Bernhard Schölkopf, Advances in Neural Information Processing Systems. 33Atalanti Mastakouri and Bernhard Schölkopf. Causal analysis of covid-19 spread in germany. Advances in Neural Information Processing Systems, 33:3153-3163, 2020.</p>
<p>Causal de Finetti: On the identification of invariant causal structure in exchangeable data. Siyuan Guo, Viktor Tóth, Bernhard Schölkopf, Ferenc Huszár, 2022Technical reportSiyuan Guo, Viktor Tóth, Bernhard Schölkopf, and Ferenc Huszár. Causal de Finetti: On the identification of invariant causal structure in exchangeable data. Technical report, 2022.</p>
<p>Beyond predictions in neural odes: Identification and interventions. Hananeh Aliee, Fabian J Theis, Niki Kilbertus, 2021Technical reportHananeh Aliee, Fabian J. Theis, and Niki Kilbertus. Beyond predictions in neural odes: Identification and interventions. Technical report, 2021.</p>
<p>Stochastic causal programming for bounding treatment effects. Kirtan Padh, Jakob Zeitler, David Watson, Matt Kusner, Ricardo Silva, Niki Kilbertus, 2022Technical reportKirtan Padh, Jakob Zeitler, David Watson, Matt Kusner, Ricardo Silva, and Niki Kilbertus. Stochastic causal programming for bounding treatment effects. Technical report, 2022.</p>
<p>Distributional robustness of k-class estimators and the pulse. Martin Emil , Jakobsen , Jonas Peters, The Econometrics Journal. 252Martin Emil Jakobsen and Jonas Peters. Distributional robustness of k-class estimators and the pulse. The Econometrics Journal, 25(2):404-432, 2022.</p>
<p>Über Wirklichkeitskriterien. Suhrkamp, Frankfurt am Main. Michael Stadler, Peter Kruse, GermanyMichael Stadler and Peter Kruse.Über Wirklichkeitskriterien. Suhrkamp, Frankfurt am Main, Germany, 1990.</p>
<p>Ai narratives: portrayals and perceptions of artificial intelligence and why they matter. The Royal Society. The Royal Society. Ai narratives: portrayals and perceptions of artificial intelligence and why they matter. Available at: https://royalsociety.org/topics-policy/projects/ ai-narratives/, 2018.</p>
<p>Challenges in deploying machine learning: a survey of case studies. Andrei Paleyes, Raoul-Gabriel Urma, Neil D Lawrence, ACM Computing Surveys. 556Andrei Paleyes, Raoul-Gabriel Urma, and Neil D. Lawrence. Challenges in deploying machine learning: a survey of case studies. ACM Computing Surveys, 55(6):1-29, 2022.</p>
<p>Scalars are universal: Equivariant machine learning, structured like classical physics. Soledad Villar, David W Hogg, Kate Storey-Fisher, Weichi Yao, Ben Blum-Smith, Advances in Neural Information Processing Systems. 34Soledad Villar, David W. Hogg, Kate Storey-Fisher, Weichi Yao, and Ben Blum-Smith. Scalars are universal: Equivariant machine learning, structured like classical physics. Advances in Neural Information Processing Systems, 34:28848-28863, 2021.</p>
<p>Machine learning strategies for systems with invariance properties. Julia Ling, Reese Jones, Jeremy Templeton, Journal of Computational Physics. 318Julia Ling, Reese Jones, and Jeremy Templeton. Machine learning strategies for systems with invariance properties. Journal of Computational Physics, 318:22-35, 2016.</p>
<p>Introduction to learning and inference in computational systems biology. Neil D Lawrence, Learning and Inference in Computational Systems Biology, chapter. Neil D. Lawrence, Mark Girolami, Magnus Rattray, and Guido SanguinettiCambridge, MAMIT PressNeil D. Lawrence. Introduction to learning and inference in computational systems biology. In Neil D. Lawrence, Mark Girolami, Magnus Rattray, and Guido Sanguinetti, editors, Learning and Inference in Computational Systems Biology, chapter 1. MIT Press, Cambridge, MA, 2010.</p>
<p>Virtual laboratories: Transforming research with ai. Arto Klami, Theodoros Damoulas, Ola Engkvist, Patrick Rinke, Samuel Kaski, 2022Technical reportArto Klami, Theodoros Damoulas, Ola Engkvist, Patrick Rinke, and Samuel Kaski. Virtual laboratories: Transforming research with ai. Technical report, 2022.</p>
<p>Best-response bayesian reinforcement learning with bayes-adaptive pomdps for centaurs. Mustafa Mert, Ç Elikok, Frans A Oliehoek, Samuel Kaski, International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS) 2022. 2022Mustafa Mert Ç elikok, Frans A. Oliehoek, and Samuel Kaski. Best-response bayesian rein- forcement learning with bayes-adaptive pomdps for centaurs. In International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS) 2022, 2022.</p>
<p>What is a gravitational wave? Available at. NASANASA. What is a gravitational wave? Available at: https://spaceplace.nasa.gov/ gravitational-waves/en/.</p>
<p>Real-time gravitational wave science with neural posterior estimation. Maximilian Dax, Stephen R Green, Jonathan Gair, Jakob H Macke, Alessandra Buonanno, Bernhard Schölkopf, Phys. Rev. Lett. 127241103Maximilian Dax, Stephen R. Green, Jonathan Gair, Jakob H. Macke, Alessandra Buo- nanno, and Bernhard Schölkopf. Real-time gravitational wave science with neural posterior estimation. Phys. Rev. Lett., 127:241103, Dec 2021.</p>
<p>Black-box density function estimation using recursive partitioning. Erik Bodin, Zhenwen Dai, Neill Campbell, Carl Henrik Ek, International Conference on Machine Learning. PMLR139Erik Bodin, Zhenwen Dai, Neill Campbell, and Carl Henrik Ek. Black-box density function estimation using recursive partitioning. In International Conference on Machine Learning, volume 139, pages 1015-1025. PMLR, 2021.</p>
<p>Dimensionless machine learning: Imposing exact units equivariance. Soledad Villar, Weichi Yao, W David, Ben Hogg, Bianca Blum-Smith, Dumitrascu, 2022Technical reportSoledad Villar, Weichi Yao, David W Hogg, Ben Blum-Smith, and Bianca Dumitrascu. Dimensionless machine learning: Imposing exact units equivariance. Technical report, 2022.</p>
<p>Linear latent force models using Gaussian processes. Mauricio A Álvarez, David Luengo, Neil D Lawrence, TPAMI. 3511Mauricio A.Álvarez, David Luengo, and Neil D. Lawrence. Linear latent force models using Gaussian processes. TPAMI, 35(11):2693-2705, 5 2013.</p>
<p>Black-box inference for non-linear latent force models. Wil Ward, Tom Ryder, Dennis Prangle, Mauricio Alvarez, International Conference on Artificial Intelligence and Statistics. PMLR108Wil Ward, Tom Ryder, Dennis Prangle, and Mauricio Alvarez. Black-box inference for non-linear latent force models. In International Conference on Artificial Intelligence and Statistics, volume 108, pages 3088-3098. PMLR, 2020.</p>
<p>On the generalization of equivariance and convolution in neural networks to the action of compact groups. Risi Kondor, Shubhendu Trivedi, International Conference on Machine Learning. PMLR80Risi Kondor and Shubhendu Trivedi. On the generalization of equivariance and convolution in neural networks to the action of compact groups. In International Conference on Machine Learning, volume 80, pages 2747-2755. PMLR, 2018.</p>
<p>Invariant and equivariant graph networks. Heli Haggai Maron, Nadav Ben-Hamu, Yaron Shamir, Lipman, Technical reportHaggai Maron, Heli Ben-Hamu, Nadav Shamir, and Yaron Lipman. Invariant and equivariant graph networks. Technical report, 2018.</p>
<p>On the universality of rotation equivariant point cloud networks. Nadav Dym, Haggai Maron, Technical reportNadav Dym and Haggai Maron. On the universality of rotation equivariant point cloud networks. Technical report, 2020.</p>
<p>Improving genomicsbased predictions for precision medicine through active elicitation of expert knowledge. Iiris Sundin, Tomi Peltola, Luana Micallef, Homayun Afrabandpey, Marta Soare, Pedram Muntasir Mamun Majumder, Chen Daee, Baris He, Aki Serim, Caroline Havulinna, Giulio Heckman, Pekka Jacucci, Samuel Marttinen, Kaski, Bioinformatics. 3413Iiris Sundin, Tomi Peltola, Luana Micallef, Homayun Afrabandpey, Marta Soare, Muntasir Mamun Majumder, Pedram Daee, Chen He, Baris Serim, Aki Havulinna, Caroline Heckman, Giulio Jacucci, Pekka Marttinen, and Samuel Kaski. Improving genomics- based predictions for precision medicine through active elicitation of expert knowledge. Bioinformatics, 34(13):i395-i403, 06 2018.</p>
<p>Parameter inference for computational cognitive models with approximate bayesian computation. Antti Kangasrääsiö, P P Jussi, Antti Jokinen, Andrew Oulasvirta, Samuel Howes, Kaski, Cognitive science. 43612738Antti Kangasrääsiö, Jussi PP Jokinen, Antti Oulasvirta, Andrew Howes, and Samuel Kaski. Parameter inference for computational cognitive models with approximate bayesian computation. Cognitive science, 43(6):e12738, 2019.</p>
<p>Toward ai assistants that let designers design. Antti Sebastiaan De Peuter, Samuel Oulasvirta, Kaski, 2021Technical reportSebastiaan De Peuter, Antti Oulasvirta, and Samuel Kaski. Toward ai assistants that let designers design. Technical report, 2021.</p>
<p>Results of the great08 challenge: an image analysis competition for cosmological lensing. Sarah Bridle, T Sreekumar, Matthias Balan, Marc Bethge, Stefan Gentile, Catherine Harmeling, Michael Heymans, Reshad Hirsch, Mike Hosseini, Donnacha Jarvis, Kirk, Monthly Notices of the Royal Astronomical Society. 4053Sarah Bridle, Sreekumar T Balan, Matthias Bethge, Marc Gentile, Stefan Harmeling, Catherine Heymans, Michael Hirsch, Reshad Hosseini, Mike Jarvis, Donnacha Kirk, et al. Results of the great08 challenge: an image analysis competition for cosmological lensing. Monthly Notices of the Royal Astronomical Society, 405(3):2044-2061, 2010.</p>
<p>Schmidt futures launches $148m global initiative to accelerate ai use in postdoctoral research. Schmidt Futures. Schmidt Futures. Schmidt futures launches $148m global initiative to accelerate ai use in postdoctoral research. Available at availableat:https://www.schmidtfutures.com/ schmidt-futures-launches-148m-global-initiative-to-accelerate-ai-use-in-postdoctoral-resear 2022.</p>
<p>A Participants at Machine Learning for Science: Bridging Data-driven and Mechanistic Modelling. 22382A Participants at Machine Learning for Science: Bridg- ing Data-driven and Mechanistic Modelling (Dagstuhl Seminar 22382, 18-23 September 2022)</p>
<p>Ulrike von Luxburg. Thank you to all those who contributed to Dagstuhl Seminar 22382, discussions at which are the foundation for this paper. Organisers: Philipp, Kyle Berens, Neil D Cranmer, Jessica Lawrence, Montgomery, • Mauricio AÁlvarez (University of Manchester, GBOrganisers: Philipp Berens, Kyle Cranmer, Neil D. Lawrence, Jessica Montgomery, Ulrike von Luxburg. Thank you to all those who contributed to Dagstuhl Seminar 22382, discussions at which are the foundation for this paper: • Mauricio AÁlvarez (University of Manchester, GB)</p>
<p>. Bah Bubacarr, AIMSSouth Africa -Cape Town, ZA• Bubacarr Bah (AIMS South Africa -Cape Town, ZA)</p>
<p>. Jessica Beasley, Collective Next -Boston, US)• Jessica Beasley (Collective Next -Boston, US)</p>
<p>. • Philipp, Berens, Universität Tübingen, DE• Philipp Berens (Universität Tübingen, DE)</p>
<p>. • Maren, Büttner, Helmholtz Zentrum München &amp; Universität Bonn• Maren Büttner (Helmholtz Zentrum München &amp; Universität Bonn)</p>
<p>. Cranmer • Kyle, University of Wisconsin -Madison, US)• Kyle Cranmer (University of Wisconsin -Madison, US)</p>
<p>. • Thomas, G Dietterich, Oregon State University -Corvallis, US)• Thomas G. Dietterich (Oregon State University -Corvallis, US)</p>
<p>. • Carl, Henrik Ek, University of Cambridge, GB• Carl Henrik Ek (University of Cambridge, GB)</p>
<p>. Stuart Feldman, Schmidt Futures -New York, US• Stuart Feldman (Schmidt Futures -New York, US)</p>
<p>. • Asja, Fischer, Ruhr-Universität Bochum, DE• Asja Fischer (Ruhr-Universität Bochum, DE)</p>
<p>. Hennig • Philipp, Universität Tübingen, DE• Philipp Hennig (Universität Tübingen, DE)</p>
<p>. • David, W Hogg, New York University, US• David W. Hogg (New York University, US)</p>
<p>. • Christian Igel, University of Copenhagen, DK• Christian Igel (University of Copenhagen, DK)</p>
<p>. Samuel Kaski, Aalto University, FI)• Samuel Kaski (Aalto University, FI)</p>
<p>. • Ieva Kazlauskaite, University of Cambridge, GB• Ieva Kazlauskaite (University of Cambridge, GB)</p>
<p>. Kersting Hans, INRIA -Paris• Hans Kersting (INRIA -Paris, FR)</p>
<p>. • Niki Kilbertus ( Tu München, A I De &amp; Helmholtz, München, DE• Niki Kilbertus (TU München, DE &amp; Helmholtz AI München, DE)</p>
<p>. • Neil, D Lawrence, University of Cambridge, GB• Neil D. Lawrence (University of Cambridge, GB)</p>
<p>. Gilles Louppe, University of Liège, BE• Gilles Louppe (University of Liège, BE)</p>
<p>. Jakob Macke, Universität Tübingen, DE• Jakob Macke (Universität Tübingen, DE)</p>
<p>. • Dina Machuve, DevData Analytics -A, TZ)• Dina Machuve (DevData Analytics -A, TZ)</p>
<p>. Eric Meissner, University of Cambridge, GB• Eric Meissner (University of Cambridge, GB)</p>
<p>. • Siddharth Mishra-Sharma, MIT -Cambridge, US• Siddharth Mishra-Sharma (MIT -Cambridge, US)</p>
<p>. Jessica Montgomery, University of Cambridge, GB• Jessica Montgomery (University of Cambridge, GB)</p>
<p>. • Jonas Peters, University of Copenhagen, DK• Jonas Peters (University of Copenhagen, DK)</p>
<p>. Aditya Ravuri, University of Cambridge, GB• Aditya Ravuri (University of Cambridge, GB)</p>
<p>. • Markus Reichstein, MPI für Biogeochemistry -Jena, DE)• Markus Reichstein (MPI für Biogeochemistry -Jena, DE)</p>
<p>. Bernhard Schölkopf, MPI für Intelligente Systeme -Tübingen, DE)• Bernhard Schölkopf (MPI für Intelligente Systeme -Tübingen, DE)</p>
<p>. Francisco Vargas, University of Cambridge, GB• Francisco Vargas (University of Cambridge, GB)</p>
<p>. Soledad Villar, Johns Hopkins University -Baltimore, US)• Soledad Villar (Johns Hopkins University -Baltimore, US)</p>
<p>. • Ulrike Von Luxburg, Universität Tübingen, DE• Ulrike von Luxburg (Universität Tübingen, DE)</p>
<p>. Wolf • Verena, Universität des Saarlandes -Saarbrücken, DE)• Verena Wolf (Universität des Saarlandes -Saarbrücken, DE)</p>            </div>
        </div>

    </div>
</body>
</html>