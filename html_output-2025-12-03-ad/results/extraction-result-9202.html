<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-9202 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-9202</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-9202</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-162.html">extraction-schema-162</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <p><strong>Paper ID:</strong> paper-247244536</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2203.02034v2.pdf" target="_blank">Data-Efficient and Interpretable Tabular Anomaly Detection</a></p>
                <p><strong>Paper Abstract:</strong> Anomaly detection (AD) plays an important role in numerous applications. In this paper, we focus on two understudied aspects of AD that are critical for integration into real-world applications. First, most AD methods cannot incorporate labeled data that are often available in practice in small quantities and can be crucial to achieve high accuracy. Second, most AD methods are not interpretable, a bottleneck that prevents stakeholders from understanding the reason behind the anomalies. In this paper, we propose a novel AD framework, DIAD, that adapts a white-box model class, Generalized Additive Models, to detect anomalies using a partial identification objective which naturally handles noisy or heterogeneous features. DIAD can incorporate a small amount of labeled data to further boost AD performances in semi-supervised settings. We demonstrate the superiority of DIAD compared to previous work in both unsupervised and semi-supervised settings on multiple datasets. We also present explainability capabilities of DIAD, on its rationale behind predicting certain samples as anomalies.</p>
                <p><strong>Cost:</strong> 0.006</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <p class="empty-note">No extracted data.</p>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <p class="empty-note">No potentially relevant new papers extracted.</p>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-9202",
    "paper_id": "paper-247244536",
    "extraction_schema_id": "extraction-schema-162",
    "extracted_data": [],
    "potentially_relevant_new_papers": [],
    "cost": 0.006265,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Data-Efficient and Interpretable Tabular Anomaly Detection
4 Jun 2023</p>
<p>Chun-Hao Chang chkchang21@gmail.com 
USA Sercan Arik</p>
<p>Meta Usa 
Google Cloud AI
USA</p>
<p>Jinsung Yoon jinsungyoon@google.com 
Google Cloud AI
USA</p>
<p>Madeleine Udell udell@stanford.edu 
Stanford University
USA</p>
<p>Tomas Pfister tpfister@google.com 
Google Cloud AI
USA</p>
<p>Data-Efficient and Interpretable Tabular Anomaly Detection
4 Jun 20236A2AF2763B63D7387E7376E172F48A9610.1145/3580305.3599294arXiv:2203.02034v2[cs.LG]CCS CONCEPTS â€¢ Computing methodologies â†’ Semi-supervised learning settings; Anomaly detection Anomaly Detection, Interpretability
Anomaly detection (AD) plays an important role in numerous applications.In this paper, we focus on two understudied aspects of AD that are critical for integration into real-world applications.First, most AD methods cannot incorporate labeled data that are often available in practice in small quantities and can be crucial to achieve high accuracy.Second, most AD methods are not interpretable, a bottleneck that prevents stakeholders from understanding the reason behind the anomalies.In this paper, we propose a novel AD framework, DIAD, that adapts a white-box model class, Generalized Additive Models, to detect anomalies using a partial identification objective which naturally handles noisy or heterogeneous features.DIAD can incorporate a small amount of labeled data to further boost AD performances in semi-supervised settings.We demonstrate the superiority of DIAD compared to previous work in both unsupervised and semi-supervised settings on multiple datasets.We also present explainability capabilities of DIAD, on its rationale behind predicting certain samples as anomalies.</p>
<p>INTRODUCTION</p>
<p>Anomaly detection (AD) has numerous real-world applications, especially for tabular data, including detection of fraudulent transactions, intrusions related to cybersecurity, and adverse outcomes in healthcare.When the real-world tabular AD applications are considered, there are various challenges constituting a fundamental bottleneck for penetration of fully-automated machine learning solutions:</p>
<p>â€¢ Noisy and irrelevant features: Tabular data often contain noisy or irrelevant features caused by measurement noise, outlier features and inconsistent units.Even a change in a small subset of features may trigger anomaly identification.â€¢ Heterogeneous features: Unlike image or text, tabular data features can have values with significantly different types (numerical, boolean, categorical, and ordinal), ranges and distributions.â€¢ Small labeled data: In many applications, often a small portion of the labeled data is available.AD accuracy can be significantly boosted with the information from these labeled samples as they may contain crucial information on representative anomalies and help ignore irrelevant ones.â€¢ Interpretability: Without interpretable outputs, humans cannot understand the rationale behind anomaly predictions, that would enable more trust and actions to improve the model performance.</p>
<p>Verification of model accuracy is particularly challenging for high dimensional tabular data, as they are not easy to visualize for humans.An interpretable AD model should be able to identify important features used to predict anomalies.Conventional local explainability methods like SHAP [20] and LIME [25] are proposed for supervised learning and may not be straightforward to generalize to unsupervised or semi-supervised AD.</p>
<p>Conventional AD methods fail to address the above -their performance often deteriorates with noisy features (Sec.6), they cannot incorporate labeled data, and cannot provide interpretability.</p>
<p>In this paper, we aim to address these challenges by proposing a novel framework, Data-efficient Interpretable AD (DIAD).DIAD's model architecture is inspired by Generalized Additive Models (GAMs) and GA 2 M (see Sec. 3), that have been shown to obtain high accuracy and interpretability for tabular data [4,6,16], and have been used in applications like finding outlier patterns and auditing fairness [33].We propose to employ intuitive notions of Partial Identification (PID) as an AD objective and learn them with a differentiable GA 2 M (NodeGA 2 M, Chang et al. [5]).Our design is based on the principle that PID scales to high-dimensional features and handles heterogeneous features well, while the differentiable GAM allows fine-tuning with labeled data and retain interpretability.In addition, PID requires clear-cut thresholds like trees which are provided by NodeGA 2 M. While combining PID with NodeGA 2 M, we introduce multiple methodological innovations, including estimating and normalizing a sparsity metric as the anomaly scores, integrating a regularization for an inductive bias appropriate for AD, and using deep representation learning via fine-tuning with a differentiable AUC loss.The latter is crucial to take advantage of a small amount of labeled samples well and constitutes a more 'data-efficient' method compared to other AD approaches -e.g.DIAD improves from 87.1% to 89.4% AUC with 5 labeled anomalies compared to unsupervised AD.Overall, our innovations lead to strong empirical results -DIAD outperforms other alternatives significantly, both in unsupervised and semi-supervised settings.DIAD's outperformance is especially prominent on largescale datasets containing heterogeneous features with complex relationships between them.In addition to accuracy gains, DIAD also provides a rationale on why an example is classified as anomalous using the GA 2 M graphs, and insights on the impact of labeled data on the decision boundary, a novel explainability capability that provides both local and global understanding on the AD tasks.</p>
<p>RELATED WORK</p>
<p>Overview of AD methods.Table 1 summarizes representative AD works and compares to DIAD.AD methods for training with only normal data have been widely studied [21].Isolation Forest (IF) [17] grows decision trees randomly -the shallower the tree depth for a sample is, the more anomalous it is predicted.However, it shows performance degradation when feature dimensionality increases.Robust Random Cut Forest (RRCF, [11]) further improves IF by choosing features to split based on the range, but is sensitive to scale.PIDForest [9] zooms on the features with large variances, for more robustness to noisy or irrelevant features.</p>
<p>There are also AD methods based on generative approaches, that learn to reconstruct input features, and use the error of reconstructions or density to identify anomalies.Bergmann et al. [2] employs auto-encoders for image data.DAGMM [39] first learns an autoencoder and then uses a Gaussian Mixture Model to estimate the density in the low-dimensional latent space.Since these are based on reconstructing input features, they may not be directly adapted to high-dimensional tabular data with noisy and heterogeneous features.</p>
<p>Recently, methods with pseudo-tasks have been proposed as well.A major one is to predict geometric transformations [1,8] and using prediction errors to detect anomalies.Qiu et al. [24] shows improvements with a set of diverse transformations.CutPaste [14] learns to classify images with replaced patches, combined with density estimation in the latent space.Lastly, several recent works focus on contrastive learning.Tack et al. [32] learns to distinguish synthetic images from the original.Sohn et al. [31] first learns a distribution-augmented contrastive representation and then uses a one-class classifier to identify anomalies.Self-Contrastive Anomaly Detection (SCAD) [29] aims to distinguish in-window vs. out-ofwindow features by a sliding window and utilizes the error to identify anomalies.</p>
<p>Explainable AD.A few AD works focus on explainability as overviewed in Pang and Aggarwal [21].Liu et al. [18], Vinh et al. [34] explains anomalies using off-the-shelf detectors that might come with limitations as they are not fully designed for the AD task.Liznerski et al. [19] proposes identifying anomalies with a oneclass classifier (OCC) with an architecture such that each output unit corresponds to a receptive field in the input image.Kauffmann et al. [12] also uses an OCC network but instead utilizes a saliency method for visualizations.These approaches can show the parts of images that lead to anomalies, however, their applicability is limited to image data, and they can not provide meaningful global explanations as GAMs.</p>
<p>Semi-supervised AD.Several works have been proposed for semi-supervised AD.Das et al. [7], similar to ours, proposes a twostage approach that first learns an IF on unlabeled data, and then updates the leaf weights of IF using labeled data.This approach can not update the tree structure learned in the first stage, which we</p>
<p>Unlabeled data Noisy features Heterogenous features Labeled data Interpretability
PIDForest âœ“ âœ“ âœ“ âœ— âœ— DAGMM âœ“ âœ— âœ— âœ— âœ“ GOAD âœ“ âœ“ âœ“ âœ— âœ— Deep SAD âœ“ âœ“ âœ“ âœ“ âœ— SCAD âœ“ âœ— âœ“ âœ— âœ“ DevNet âœ— âœ“ âœ“ âœ“ âœ— DIAD (Ours) âœ“ âœ“ âœ“ âœ“ âœ“
show to be crucial for high performance (Sec.6.4).Deep SAD [27] extends deep OCC DSVDD [26] to semi-supervised setting.However, this approach is not interpretable and underperforms unsupervised OCC-SVM on tabular data in their paper while DIAD outperforms it.DevNet [22] formulates AD as a regression problem and achieves better sample complexity with limited labeled data.Yoon et al. [37] trains embeddings in self-supervised way [13] with consistency loss [30] and achieves state-of-the-art semi-supervised learning accuracy on tabular data.Our method instead relies on unsupervised AD objective and later fine-tune on labeled AD ones that could work better in the AD settings where labels are often sparse.We quantitatively compared with them in Sec.6.2.</p>
<p>3 PRELIMINARIES: GA 2 M AND NODEGA 2 M</p>
<p>We first overview the NodeGA 2 M model that we adopt in our framework, DIAD.</p>
<p>GA 2 M. GAMs and GA 2 Ms are designed to be interpretable with their functional forms only focusing on the 1st or 2nd order feature interactions and foregoing any 3rd-order or higher interactions.Specifically, given an input  âˆˆ R  , label , a link function  (e.g. is log(/1 âˆ’ ) in binary classification), the constant / bias term  0 , the main effects for  (â„) feature   , and 2-way feature interactions    â€² , the GA 2 M models are expressed as:
GA 2 M: ğ‘”(ğ‘¦) = ğ‘“ 0 + âˆ‘ï¸ ğ· ğ‘—=1 ğ‘“ ğ‘— (ğ‘¥ ğ‘— ) + âˆ‘ï¸ ğ· ğ‘—=1 âˆ‘ï¸ ğ‘— â€² &gt; ğ‘— ğ‘“ ğ‘— ğ‘— â€² (ğ‘¥ ğ‘— , ğ‘¥ ğ‘— â€² ).(1)
Unlike other high capacity models like DNNs that utilize all feature interactions, GA 2 M are restricted to only lower-order, 2-way interactions.This allows visualizations of   or    â€² independently as a 1-D line plot and 2-D heatmap (called shape plots), providing a convenient way to gain insights behind the rationale of the model.On many real-world datasets, they can yield competitive accuracy, while providing simple explanations for humans to understand the model's decisions.Note these visualizations are always faithful to the model since there is no approximation involved.[5] is a differentiable extension of GA 2 M which uses the neural trees to learn feature functions   and    â€² .Specifically, NodeGA 2 M consists of  layers where each layer has  differentiable oblivious decision trees (ODT) whose outputs are combined with weighted superposition, yielding the model's final output.An ODT functions as a decision tree with all nodes at the same depth sharing the same input features and thresholds, enabling parallel computation and better scaling.Specifically, an ODT of depth  compares chosen  input features to  thresholds, and returns one of the 2  possible options.  chooses what features to split, thresholds   , and leaf weights  âˆˆ R 2  , and its tree outputs â„() are given as:
NodeGA 2 M. NodeGA 2 Mâ„(ğ’™) = ğ‘¾ â€¢ I(ğ¹ 1 (ğ’™) âˆ’ ğ‘ 1 ) I(ğ‘ 1 âˆ’ ğ¹ 1 (ğ’™)) âŠ— . . . âŠ— I(ğ¹ ğ¶ (ğ’™) âˆ’ ğ‘ ğ¶ ) I(ğ‘ ğ¶ âˆ’ ğ¹ ğ¶ (ğ’™)) ,(2)
where I is an indicator (step) function, âŠ— is the outer product and â€¢ is the inner product.To make ODT differentiable and in GA 2 M form, Chang et al. [5] replaces the non-differentiable operations   and I with differentiable relaxations via softmax and sigmoid-like functions.Each tree is allowed to interact with at most two features so there are no third-or higher-order interactions in the model.We provide more details in Appendix.B.</p>
<p>PARTIAL IDENTIFICATION AND SPARSITY AS THE ANOMALY SCORE</p>
<p>We consider the Partial Identification (PID) [9] as an AD objective given its benefits in minimizing the adversarial impact of noisy and heterogeneous features (e.g.mixture of multiple discrete and continuous types), particularly for tree-based models.By way of motivation, consider the data for all patients admitted to ICU -we might treat patients with blood pressure (BP) of 300 as anomalous, since very few people have more than 300 and the BP of 300 would be in such "sparse" feature space.</p>
<p>To formalize this intuition, we first introduce the concept of 'volume'.We consider the maximum and minimum value of each feature value and define the volume of a tree leaf as the product of the proportion of the splits within the minimum and maximum value.For example, assuming the maximum value of BP is 400 and minimum value is 0, the tree split of 'BP â‰¥ 300' has a volume 0.25.We define the sparsity   of a tree leaf  as the ratio between the volume of the leaf   and the ratio of data in the leaf   as   =   /  .Correspondingly, we propose treating higher sparsity as more anomalous -let's assume only less than 0.1% patients having values more than 300 and the volume of 'BP â‰¥ 300' being 0.25, then the anomalous level of such patient is the sparsity 0.25/0.1%.To learn effectively splitting of regions with high vs. low sparsity i.e. high v.s.low anomalousness, PIDForest [9] employs random forest with each tree maximizing the variance of sparsity across tree leafs to splits the space into a high (anomalous) and a low (normal) sparsity regions.Note that the expected sparsity weighted by the number of data samples in each leaf by definition is 1.Given each tree leaf , the ratio of data in the leaf is   , sparsity   :
E[ğ‘ ] = âˆ‘ï¸ ğ‘™ [ğ· ğ‘™ ğ‘  ğ‘™ ] = âˆ‘ï¸ ğ‘™ [ğ· ğ‘™ ğ‘‰ ğ‘™ ğ· ğ‘™ ] = âˆ‘ï¸ ğ‘™ [ğ‘‰ ğ‘™ ] = 1.(3)
Therefore, maximizing the variance becomes equivalent to maximizing the second moment, as the first moment is 1:
max Var[ğ‘ ] = max âˆ‘ï¸ ğ‘™ ğ· ğ‘™ ğ‘  2 ğ‘™ = max âˆ‘ï¸ ğ‘™ ğ‘‰ 2 ğ‘™ /ğ· ğ‘™ .(4)</p>
<p>DIAD FRAMEWORK</p>
<p>In DIAD framework, we propose optimizing the tree structures of NodeGA 2 M by gradients to maximize the PID objective -the variance of sparsity -meanwhile setting the leaf weights  in Eq. 2 as the sparsity of each leaf, so the final output is the sum of all sparsity values (anomalous levels) across trees.We overview the DIAD in Alg. 1.Details of DIAD framework are described below.</p>
<p>Estimating PID.The PID objective is based on estimating the ratio of volume   and the ratio of data   for each leaf .However, exact calculation of the volume is not trivial in an efficient way for an oblivious decision tree as it requires complex rules extractions.Instead, we sample random points, uniformly in the input space, and count the number of the points that end up at each tree leaf as the empirical mean.More points in a leaf would indicate a larger volume.To avoid the zero count in the denominator, we employ Laplacian smoothing, adding a constant  to each count. 1 Similarly, we estimate   by counting the data ratio in each batch.We add  to both   and   .</p>
<p>Normalizing sparsity.The sparsity and thus the trees' outputs can have very large values up to 100s and can create challenges to gradient optimizations for the downstream layers of trees, and thus inferior performance in semi-supervised setting (Sec.6.4).To address this, similar to batch normalization, we propose linearly scaling the estimated sparsity to be in [-1, 1] to normalize the tree outputs.We note that the linear scaling still preserves the ranking of the examples as the final score is a sum operation across all sparsity.Specifically, for each leaf , the sparsity   is:
Åğ‘™ = ğ‘‰ ğ‘™ /ğ· ğ‘™ , ğ‘  ğ‘™ = 2Å ğ‘™ /(max ğ‘™ Åğ‘™ âˆ’ min ğ‘™ Åğ‘™ ) âˆ’ 1.
(
)5
Temperature annealing.We observe that the soft relaxation approach for tree splits in NodeGA 2 M, EntMoid (which replace I in Eq. 2) does not perform well with the PID objective.We attribute this to Entmoid (similar to Sigmoid) being too smooth, yielding the resulting value similar across splits.Thus, we propose to make the split gradually from soft to hard operation during optimization:
Entmoid(ğ’™/ğ‘‡ ) â†’ I(6)
as optimization goes by linearly decresing  â†’ 0</p>
<p>Updating leafs' weight.When updating the leaf weights  in Eq. 2 in each step to be sparsity, to stabilize its noisy estimation due to mini-batch and random sampling, we apply damping to the updates.Specifically, given the step , sparsity    for each leaf , and the update rate  (we use  = 0.1):
ğ‘¤ ğ‘– ğ‘™ = (1 âˆ’ ğ›¾)ğ‘¤ (ğ‘– âˆ’1) ğ‘™ + ğ›¾ğ‘  ğ‘– ğ‘™ .(7)</p>
<p>Algorithm 1 DIAD training</p>
<p>Input: Mini-batch  , tree model M, smoothing ,   is an entry of the leaf weights matrix  (Eq.2) for each tree  and leaf 
ğ‘¿ = MinMaxTransform(ğ‘‹ , min=âˆ’1, max=1) ğ‘¿ ğ‘¼ âˆ¼ ğ‘ˆ [âˆ’1, 1] {Data uniformly from [-1, 1]} ğ¸ ğ‘¡ğ‘™ = M (ğ‘¿ ), ğ¸ ğ‘¡ğ‘™ ğ‘ˆ = M (ğ‘¿ ğ‘¼ ) {Count how many data in each leaf ğ‘™ of tree ğ‘¡ for ğ‘¿, ğ‘¿ ğ‘¼ . See Alg. 2.} ğ¸ ğ‘¡ğ‘™ = ğ¸ ğ‘¡ğ‘™ + ğ›¿, ğ¸ ğ‘¡ğ‘™ ğ‘ˆ = ğ¸ ğ‘¡ğ‘™ ğ‘ˆ + ğ›¿ {Smooth the counts} ğ‘‰ ğ‘¡ğ‘™ = ğ¸ ğ‘¡ğ‘™ ğ‘› â€² ğ¸ ğ‘¡ğ‘™ â€² {Volume ratio} ğ· ğ‘¡ğ‘™ = ğ¸ ğ‘¡ğ‘™ ğ‘ˆ ğ‘› â€² ğ¸ ğ‘¡ğ‘™ â€² ğ‘ˆ {Data ratio} ğ‘€ ğ‘¡ğ‘™ = ğ‘‰ 2 ğ‘¡ğ‘™ ğ‘ƒ ğ‘¡ğ‘™ {Second moments} ğ¿ ğ‘€ = âˆ’ ğ‘¡,ğ‘™ ğ‘€ ğ‘¡ğ‘™ {Maximize the second moments} Åğ‘¡ğ‘™ = ğ‘‰ ğ‘¡ğ‘™ /ğ· ğ‘¡ğ‘™ {Sparsity} ğ‘  ğ‘¡ğ‘™ = ( 2Å ğ‘¡ğ‘™ (max Åğ‘¡ğ‘™ âˆ’min Åğ‘¡ğ‘™ ) âˆ’ 1) {Scale to [-1, 1] (Eq. 5)} ğ‘¤ ğ‘¡ğ‘™ = (1 âˆ’ ğ›¾)ğ‘¤ ğ‘¡ğ‘™ + ğ›¾ğ‘  ğ‘¡ğ‘™ {Update
tree weights -Eq.7} Optimize   by Adam optimizer (Inference) Anomaly Score  =    {sum of sparsity of all trees}.</p>
<p>Regularization.To encourage diverse trees, we introduce a novel regularization approach: per-tree dropout noise on the estimated momentum.We further restrict each tree to only split on % of features randomly to promote diverse trees (see Appendix.C for details).</p>
<p>Incorporating labeled data.At the second stage of fine-tuning using labeled data, we optimize the differentiable AUC loss [7,36] which has been shown effective in imbalanced data setting.Note that we optimize both the tree structures and leaf weights of the DIAD.Specifically, given a randomly-sampled mini-batch of labeled positive/negative samples   /  , and the model M, the objective is:
ğ¿ ğ‘ƒ ğ‘ = 1/|ğ‘‹ ğ‘ƒ ||ğ‘‹ ğ‘ | âˆ‘ï¸ ğ‘¥ ğ‘ âˆˆğ‘‹ ğ‘ƒ ,ğ‘¥ ğ‘› âˆˆğ‘‹ ğ‘ max(M (ğ‘¥ ğ‘› ) âˆ’M (ğ‘¥ ğ‘ ), 0). (8)
We show the benefit of this AUC loss compared to Binary Cross Entropy (BCE) in Sec.6.4.</p>
<p>Training data sampling.Similar to Pang et al. [22], we upsample the positive samples such that they have similar count with the negative samples, at each batch.We show the benefit of this over uniform sampling (see Sec. 6.4).</p>
<p>Theoretical result. DIAD prioritizes training on informative features rather than noise:</p>
<p>Proposition 1.Given uniform noise   and non-uniform features   , DIAD prioritizes cutting   over   because the variance of sparsity of   is larger than   as sample size goes to infinity.</p>
<p>Here, we show that the variance of sparsity of uniform features would go to 0 under large sample sizes.Without loss of generality, we assume that the decision tree has a single cut in  âˆˆ (0, 1) in a uniform feature   âˆˆ [0, 1], and we denote the sparsity of the left segment as  1 and the right as  2 .The sparsity  1 is defined as
ğ‘‰ 1
  where the  1 =  is the volume, and the   is the data ratio i.e. Figure 2: The Spearman correlation of methods' performance rankings.DIAD is correlated with SCAD as they both perform better in larger datasets.PIDForest underperforms on larger datasets, and its correlation with DIAD is low, despite having similar objectives.
ğ· 1 = ğ‘ 1
 where  1 is the counts of samples in segment 1 between 0 and , and  is the total samples.Since   is a uniform feature, the counts  1 become a Binomial distribution with  samples and probability :
ğ‘ 1 âˆ¼ Bern(ğ‘›, ğ‘™), ğ‘ 2 âˆ¼ Bern(ğ‘›, 1 âˆ’ ğ‘™). As ğ‘› â†’ âˆ, ğ· 1 â†’ ğ‘™ because E[ğ· ğ‘™ ] = E[ğ‘ ğ‘™ ] ğ‘› = ğ‘™ and ğ‘‰ ğ‘ğ‘Ÿ [ğ· 1 ] = ğ‘‰ ğ‘ğ‘Ÿ [ğ‘ ğ‘™ ] ğ‘› 2 = ğ‘™ (1âˆ’ğ‘™ ) ğ‘› â†’ 0.
Therefore, as number of examples grow, the sparsity  1 =     â†’   = 1.Similarly,  2 â†’ 1.For any uniform noise, since both sparsity  1 ,  2 converges to 1 as  â†’ âˆ no matter where the cut  is, the variance of sparsity converges to 0. Thus, the objective of DIAD which maximizes the variance of sparsity would prefer splitting other non-uniform features since there is no gain in variance of sparsity when splitting on the uniform noise.This explains why DIAD is resilent to noisy settings in Table 9.</p>
<p>EXPERIMENTS</p>
<p>We evaluate DIAD on various datasets, in both unsupervised and semi-supervised settings.Detailed settings and additional results are provided in the Appendix.</p>
<p>Unsupervised Anomaly Detection</p>
<p>We compare methods on 20 tabular datasets, including 14 datasets from Gopalan et al. [9] and 6 larger datasets from Pang et al. [22]. 2e run and average results with 8 different random seeds.</p>
<p>Baselines.We compare DIAD with SCAD [29], a recently-proposed deep learning based AD method, and other competitive methods including PIDForest [9], COPOD [15], PCA, k-nearest neighbors (kNN), RRCF [11], LOF [3] and OC-SVM [28].To summarize performance across multiple datasets, we consider the averaged AUC (the higher, the better), as well as the average rank (the lower, the better) to avoid a few datasets dominating the results.</p>
<p>Table 2 shows that DIAD's performance is better than others on most datasets.We also showed DIAD outperformed another deeplearning baseline: NeuTral AD [24] in Appendix J. To analyze the similarity of performances, Fig. 2 shows the Spearman correlation between rankings.Compared to the PIDForest which has similar objectives, DIAD often underperforms on smaller datasets such as on Musk and Thyroid, but outperforms on larger datasets such as on Backdoor, Celeba, Census and Donors.DIAD is correlated with SCAD as they both perform better on larger datasets, attributed to better utilizing deep representation learning.PIDForest underperforms on larger datasets, and its correlation with DIAD is low despite having similar objectives.</p>
<p>Next, we show the robustness of AD methods with additional noisy features.We follow the experimental settings from Gopalan et al. [9] to include 50 additional noisy features which are randomly sampled from [âˆ’1, 1] on Thyroid and Mammography datasets, and their noisy versions.Table .3 shows that the performance of DIAD is more robust with additional noisy features (76.1â†’71.1,85.0â†’83.1),while others show significant performance degradation.On Thyroid (noise), SCAD decreases from 75.9â†’49.5,KNN from 75.1â†’49.5,and COPOD from 77.6â†’60.5.</p>
<p>Semi-supervised Anomaly Detection</p>
<p>Next, we focus on the semi-supervised setting and show DIAD can take advantage of small amount of labeled data in a superior way.</p>
<p>We divide the data into 64%-16%-20% train-val-test splits and within the training set, we consider that only a small part of data is labeled.We assume the existence of labels for a small subset of the training set (5, 15, 30, 60 or 120 positives and the corresponding negatives to have the same anomaly ratio).</p>
<p>The validation set is used for model selection and we report the averaged performances evaluated on 10 disjoint data splits.We compare to 3 baselines: (1) DIAD w/o PT: optimized with labeled data without the first AD pre-training stage, (2) CST: VIME with consistency loss [38] which regularizes the model to make similar predictions between unlabeled data under dropout noise injection, (3) DevNet [22]: a state-of-the-art semi-supervised AD approach.Further details are provided in Appendix.C.2.</p>
<p>Fig. 3 shows the AUC across 8 of 15 datasets (the rest can be found in Appendix.G).The proposed version of DIAD (blue) outperforms DIAD without the first stage pre-training (orange) consistently on 14 of 15 datasets (except Census), which demonstrates that learning the PID objective with unlabeled data improves the performance.Second, neither the VIME with consistency loss (green) or DevNet (red) always improves the performance compared to the supervised setting.Table 4 shows the average AUC of all methods in semisupervised AD.Overall, DIAD outperforms all baselines and shows improvements over the unlabeled setting.In Appendix.D, we show similar results in average ranks metric rather than AUC.</p>
<p>Qualitative analyses on DIAD explanations</p>
<p>Explaining anomalous prediction.DIAD provides value to the users by providing insights on why a sample is predicted as anomalous.We demonstrate this by focusing on Mammography dataset and showing the explanations obtained by DIAD for anomalous samples.The task is to detect breast cancer from radiological scans, specifically the presence of clusters of microcalcifications that appear bright on a mammogram.The 11k images are segmented and preprocessed using standard computer vision pipelines and 6 image-related features are extracted, including the area of the cell, constrast, and noise.Fig. 4 shows the data samples that are predicted to be the most anomalous and its rationale behind DIAD on top 4 factors contributing more to the anomaly score.The unusually-high 'Contrast' (Fig. 4(a)) is a major factor in the way image differs from other samples.The unusually high noise (Fig. 4(b)) and 'Large area' (Fig. 4(c)) are other ones.In addition, Fig. 4(d) shows 2-way interactions and the insights by it on why the sample is anomalous.The sample has 'middle area' and 'middle gray level', which constitute a rare combination in the dataset.Overall, these visualizations shed light into which features are the most important ones for a sample being considered as anomalous, and how the value of the features affect the anomaly likelihood.We show another example of DIAD explanations on the "Celeba" dataset.Celeba consists of 200K pictures of celebrities and annotated with 40 attributes including "Bald", "Hair", "Mastache", "Attractive" etc.We train the DIAD on these 40 sets of attributes and treat the "Bald" attribute as outliers since it accounts for only 3% of all celebrities.Here we show the most anomalous example deemed by the DIAD in Fig. 5    (a-d), showing Gray Hair, Mustache, Receding Hairline, and Rosy Cheeks are very anomalous in the data.We also show the top 4 interactions in (e-h), indicating the combination of Rosy Cheeks with Mustache, Goatee, Necktie and Side Burns are even more anomalous deemed by DIAD.We also show the least anomalous (normal) example deemed by DIAD in the Celeba dataset in Fig. 6.The lack of "Receding Hairline", "Rosy Cheeks", "Pale Skin", and "Gray Hair" are pretty common and thus DIAD outputs a negative normalized sparsity value.Given Celeba mostly consists of young to middle-aged celebrities, attributes resembling elderly are correctly deemed as anomalous and vice versa.</p>
<p>Qualitative analyses on the impact of fine-tuning with labeled data.Fig. 7 visualizes how predictions change before and after fine-tuning with labeled samples on Donors dataset.Donors dataset consists of 620k educational proposals for K12 level with 10 features.The anomalies are defined as the top 5% ranked proposals as outstanding.We show visualizations before and after fine-tuning.Here the darker/lighter red in the background indicates high/low data density and thus less/more anomalous.In (a, b) we show the two features that after fine-tuning (blue) the magnitude increases which shows the labels agree with the notion of data sparsity learned before fine-tuning (orange).In (c, d) the label information disagrees with the notion of sparsity; thus, the magnitude changes or decreases after the fine-tuning.</p>
<p>Proportion' increase in magnitude after fine-tuning, indicating that the sparsity (as a signal of anomaly likelihood) of these is consistent with the labels.Conversely, Figs.Here the darker/lighter red in the background indicates high/low data density and thus less/more anomalous.In (a) T3, the labeled information agrees with the anomaly specified in PID, so after fine-tuning the magnitude increases.In (b, c, d) the label information disagrees with the anomalous levels specified in PID especially when the value are small; thus, the magnitude changes or decreases after the fine-tuning.</p>
<p>less density as more anomalous -in this case 'Fully Funded'=0 is treated as more anomalous.In fact, 'Fully Funded' is a well-known indicator of outstanding proposals, so after fine-tuning, the model learns that 'Fully Funded'=1 in fact contributes to a higher anomaly score.This underlines the importance of incorporating labeled data to improve AD accuracy.</p>
<p>We further show another case study of DIAD explanations on "Thyroid" datasets before and after fine-tuning that also indicates the discrepancy between unsupervised AD objective and labeled anomalies.Thyroid datasets contains 7200 samples with 6 features and 500 of labels are labeled as "hyperfunctioning".In Fig. 8, we visualize 4 attributes: (a) T3, (b) T4U, (c) TBG, and (d) TT4.And the dark red in the backgrounds indicates the high data density by bucketizing the x-axis into 64 bins and counts the number of examples for each bin.First, in T3 feature, before fine-tuning (orange) the model predicts a higher anomaly for values above 0 since they have little density and have mostly white region.After fine-tuning on labeled data (blue), the model further strengthens its belief that values bigger than 0 are anomalous.However, in T4U, TBG and TT4 features (b-d), before fine-tuning (orange) the model conversely indicates higher values are anomalous due to its larger volume and smaller density (white).But after fine-tuning (blue) on the labels the model moves to an opposite direction that the smaller feature value is more anomalous.This shows that the used unsupervised anomaly objective, PID, is in conflict with the human-defined anomalies in these features.Thanks to this insight, we may decide not to optimize the PID on these features or manually edit the GAM graph predictions [35], a unique capability other AD methods lack.</p>
<p>Ablation and sensitivity analysis</p>
<p>To analyze the major constituents of DIAD, we perform ablation analyses, presented in Table 5.We show that fine-tuning with AUC outperforms BCE.Sparsity normalization plays an important role in fine-tuning, since sparsity could have values up to 10 4 which negatively affect fine-tuning.Upsampling the positive samples also contributesto performance improvements.Finally, to compare with Das et al. [7] which updates the leaf weights of a trained IF [17] to incorporate labeled data, we propose a variant that only fine-tunes the leaf weights using labeled data in the second stage without changing the tree structure learned in the first stage, which substantially decreases the performance.Using differentiable trees that update both leaf structures and weights is also shown to be important.</p>
<p>In practice we might not have a large validation dataset, as in Sec.6.2, thus, it would be valuable to show strong performance with a small validation dataset.In Supp.E, we reduce the validation dataset size to only 4% of the labeled data and find DIAD still consistently outperforms others.Additional results can be found in Appendix.E. We also perform sensitivity analysis in Appendix.F that varies hyperparameters in the unsupervised AD benchmarks.Our method is quite stable with less than 2% differences across a variety of hyperparameters on many different datasets.</p>
<p>DISCUSSIONS AND CONCLUSIONS</p>
<p>As unsupervised AD methods rely on approximate objectives to discover anomalies such as reconstruction loss, predicting geometric transformations, or contrastive learning, the objectives inevitably would not align with labels on some datasets, as inferred from the performance ranking fluctuations across datasets and confirmed in Sec.6.3 before and after fine-tuning.This motivates for incorporating labeled data to boost performance, and interpretability to find out whether the model could be trusted and whether the approximate objective aligns with human-defined labels.</p>
<p>Our framework consists of multiple novel contributions that are key for highly accurate and interpretable AD: we introduce a novel way to estimate and normalize sparsity, modify the architecture by temperature annealing, propose a novel regularization for improved generalization, and introduce semi-supervised AD via supervised fine-tuning of the unsupervised learnt representations.These play a crucial role in pushing the state-of-the-art in both unsupervised and semi-supervised AD benchmarks.Furthermore, by limiting to learning only up to second order feature interactions, DIAD provides unique interpretability capabilities that provide both local and global explanations crucial in high-stakes applications such as finance or healthcare.In future, we plan to conduct explainability evaluations with user studies, and develope methods that could provide more sparse explanations in the case of high-dimensional settings.</p>
<p>D THE AVERAGE RANK PERFORMANCE OF SEMI-SUPERVISED AD RESULTS</p>
<p>The average AUC for semi-supervised AD results (Table 4) might not represent the entire picture, so we provide the average ranks as well in Table 7.Our method still consistently outperforms other methods.</p>
<p>E SEMI-SUPERVISED AD RESULTS WITH SMALLER VALIDATION SET</p>
<p>When we have a small set of labeled data, how should we split it between the train and validation datasets when optimizing semi-supervised methods?In Sec.6.2 we use 64%-16%-20% for train-val-test splits, and 16% of validation set could be too large for some real-world settings.Does our method still outperform others under a smaller validation set?</p>
<p>To answer this, we experiment with a much smaller validation set with only 50% and 25% of original validation set (i.e.8% and 4% of total datasets).In Table 8, we show the average AD performance across 15 datasets with varying size of validation data.With decreasing validation size all methods decrease the performance slightly, our method still consistently outperforms others.</p>
<p>F SENSITIVITY ANALYSIS</p>
<p>We perform sensitivity analyses from our default hyperparameter in the unsupervised AD benchmarks.We exclude Census, NYC taxi, SMTP, and HTTP datasets since some hyperparameters can not be run, resulting in total 14 datasets each with 4 different random seeds.In Fig. 9, besides showing the average of all datasets (blue), we also group datasets by their sample sizes into 3 groups: (1)  &gt; 10 5 (Orange, 3 datasets), (2) 10 5 &gt;  &gt; 10 4 (green, 5 datasets), and (4)  &lt; 10 4 (red, 6 datasets).Overall, DIAD shows quite stable performance between 82-84 except when (c) No. trees= 50 and (h) smoothing â‰¤ 10.We also find that 3 hyperparameters: (a) batch size, (b) No. Layers, and (d) Tree depth that the large group (orange) has an opposite trend than the small group (red).Large datasets yield better results with smaller batch sizes, larger layers, and shallower tree depths.Avg AUC (%)</p>
<p>G SEMI-SUPERVISED AD FIGURES</p>
<p>We experiment with 15 datasets and measure the performanceunder a different number of anomalies.We split the dataset into 64-16-20 train-val-test splits and run 10 times to report the mean and standard error.We show the performance in Fig. 10.</p>
<p>H MORE VISUAL EXPLANATIONS</p>
<p>We show another example of DIAD explanations on the "Backdoor" dataset.It consists of 95K samples and 196 features that record the backdoor network attacks with the attacks as anomalies against the 'normal' class, which is extracted from the UNSW-NB 15 data set.In Fig. 11, we show two most anomalous examples deemd by DIAD.The Fig. 11(a-c) shows the top 3 contributing factors for one example and the "protocol=HMP" solely determines its high abnormity since the rest of the two features have only little sparsity.A user can thus decide if he wants to trust such explanation and finds out if such protocol is indeed anomalous.The Fig. 11(d-f) shows the top 3 contributing factors for the other example and both the "protocol=ICMP" and "state=ECO" contributes to its high sparsity (1.5, and 1.2 respectively).And other features are relatively quite normal.</p>
<p>In addition, we find the setup of NeuTral AD is different from DIAD -they assume the training data is completely clean, and they assume they have some labeled data to tune hyperparameters, while we assume that no labeled data is accessed and no hyperparameter tuning based on labels is allowed.It might be the root cause of its inferior performance.</p>
<p>DIAD</p>
<p>Figure 1 :
1
Figure 1: Overview of the proposed DIAD framework.During training, first an unsupervised AD model is fitted employing interpretable GA 2 M models and PID loss with unlabeled data.Then, the trained unsupervised model is fined-tuned with a small amount of labeled data using a differentiable AUC loss.At inference, both the anomaly score and explanations are provided, based on the visualizations of top contributing features.The example sample in the figure is shown to have an anomaly score, explained by the cell size feature having high value.</p>
<p>. The top 4 contributing factors are shown in (</p>
<p>Figure 3 :
3
Figure 3: Semi-supervised AD performance on 8 tabular datasets (out of 15) with varying number of anomalies.Our method 'DIAD' (blue) outperforms other semi-supervised baselines.Summarized results can be found in Table.4.Remaining plots with 7 tabular datasets are provided in Appendix.G.</p>
<p>4 .
4
Figure 3: Semi-supervised AD performance on 8 tabular datasets (out of 15) with varying number of anomalies.Our method 'DIAD' (blue) outperforms other semi-supervised baselines.Summarized results can be found in Table.4.Remaining plots with 7 tabular datasets are provided in Appendix.G.</p>
<p>Figure 4 :
4
Figure 4: Explanations of the most anomalous samples on the Mammography dataset.We show the top 4 contributing features ordered by the sparsity (Sp) value (anomalous levels) of our model, with 3 features (a-c) and 1 two-way interaction (d).(a-c) x-axis is the feature value, and y-axis is the model's predicted sparsity (higher sparsity represents more likelihood of being anomalous).Model's predicted sparsity is shown as the blue line.The red backgrounds indicate the data density and the green line indicates the value of the most anomalous sample with Sp (y-value) as its sparsity.The model finds it anomalous as it has high Contrast, Noise and Area, different from values that a majority of other samples have.(d) x-axis is the Area and y-axis is the Gray Level with color indicating the sparsity (blue/red indicates anomalous/normal).The green dot is the value of the data that has 0.05 sparsity (dark blue).</p>
<p>Figs. 7 a &amp; b show that both 'Great Chat' and 'Great Messages</p>
<p>Figure 5 :
5
Figure 5: DIAD decision making visualizations of the most anomalous image of the CelebA dataset.The top 4 contributing mains are shown in (a-d) where the green dots are the image's attributes and the blue line is the model's prediction.This celebrity has gray hair, Mustache, receding hairline, and rosy cheeks which make DIAD predict him as very anomalous in the dataset.The top 4 2-way interactions are shown in (e-h) where the combination of the Rosy Cheeks with Mustache (e), Goatee (f), Necktie (g), and Side Burns (h) make him even more anomalous.</p>
<p>Figure 6 :Figure 7 :
67
Figure 6: DIAD decision making visualizations of the least anomalous celebrity in the CelebA dataset, showing its least 4anomalous features.The lack of "receding hariline", "rosy cheeks", "pale skin", and "gray hair" make DIAD deem him as the most normal subject indicated by the negative sparsity.</p>
<p>Figure 8 :
8
Figure8: AD decision making visualizations on the Thyroid dataset before (orange) and after (blue) fine-tuning on the labeled samples.Here the darker/lighter red in the background indicates high/low data density and thus less/more anomalous.In (a) T3, the labeled information agrees with the anomaly specified in PID, so after fine-tuning the magnitude increases.In (b, c, d) the label information disagrees with the anomalous levels specified in PID especially when the value are small; thus, the magnitude changes or decreases after the fine-tuning.</p>
<p>Figure 9 :
9
Figure 9: Sensitivity analysis.Y-axis shows the average AUC across 14 datasets, and X-axis shows the varying hyperparameters.The dashed line is the default hyperparameter.We show 4 groups: (1) All datasets (Blue), (2)  &gt; 10 5 (Orange), (3) 10 5 &gt;  &gt; 10 4 (green), and (4)  &lt; 10 4 (red).</p>
<p>Figure 10 :
10
Figure 10: Semi-supervised AD performance on 8 tabular datasets (out of 15) with varying number of anomalies.Our method 'DIAD' (blue) outperforms other semi-supervised baselines.Table.4 summarizes the comparisons.</p>
<p>Table 1 :
1
Comparison of AD approaches.</p>
<p>Table 2 :
2
Unsupervised AD performance (% of AUC) on 18 datasets for DIAD and 9 baselines.Metrics with standard error overlapped with the best number are bolded.Methods without randomness don't have standard error.We show the number of samples (N) and the number of features (P), ordered by N.
DIAD PIDForestIFCOPOD PCA SCADGIF kNN RRCF LOF OC-SVM NPVowels 78.3 Â± 0.9 74.0 Â± 1.074.9 Â± 2.549.660.6 90.8 Â± 2.1 79.0 Â± 1.5 97.5 80.8 Â± 0.3 5.777.81K 12Siesmic 72.2 Â± 0.4 73.0 Â± 0.370.7 Â± 0.272.768.2 65.3 Â± 1.6 53.3 Â± 4.4 74.0 69.7 Â± 1.0 44.760.13K 15Musk90.8 Â± 0.9 100.0 Â± 0.0 100.0 Â± 0.094.6 100.0 93.3 Â± 0.7 93.2 Â± 2.8 37.3 99.8 Â± 0.1 58.457.33K 166Satimage 99.7 Â± 0.0 98.2 Â± 0.399.3 Â± 0.197.497.7 98.0 Â± 1.3 98.9 Â± 0.6 93.6 99.2 Â± 0.2 46.042.16K 36Thyroid 76.1 Â± 2.5 88.2 Â± 0.881.4 Â± 0.977.667.3 75.9 Â± 2.2 57.6 Â± 6.0 75.1 74.0 Â± 0.5 26.354.77K 6A. T.78.3 Â± 0.6 81.4 Â± 0.678.6 Â± 0.678.079.2 79.3 Â± 0.7 56.4 Â± 6.8 63.4 69.9 Â± 0.4 43.767.07K 10NYC57.3 Â± 0.9 57.2 Â± 0.655.3 Â± 1.056.451.1 64.5 Â± 0.9 49.0 Â± 3.2 69.7 54.4 Â± 0.5 32.950.010K 10Mammo. 85.0 Â± 0.3 84.8 Â± 0.485.7 Â± 0.590.588.6 69.8 Â± 2.7 82.5 Â± 0.3 83.9 83.2 Â± 0.2 28.087.211K 6CPU91.9 Â± 0.2 93.2 Â± 0.191.6 Â± 0.293.985.8 87.5 Â± 0.3 78.1 Â± 0.9 72.4 78.6 Â± 0.3 44.079.418K 10M. T.81.2 Â± 0.2 81.6 Â± 0.382.7 Â± 0.580.983.4 81.8 Â± 0.4 73.9 Â± 12.9 75.9 74.7 Â± 0.4 49.979.623K 10Campaign 71.0 Â± 0.8 78.6 Â± 0.870.4 Â± 1.978.373.4 72.0 Â± 0.5 64.1 Â± 3.9 72.0 65.5 Â± 0.3 46.366.741K 62smtp86.8 Â± 0.5 91.9 Â± 0.290.5 Â± 0.791.282.3 82.2 Â± 2.0 76.7 Â± 5.3 89.5 88.9 Â± 2.3 9.584.195K 3Backdoor 91.1 Â± 2.5 74.2 Â± 2.674.8 Â± 4.178.988.7 91.8 Â± 0.6 66.9 Â± 8.4 66.8 75.4 Â± 0.7 28.686.195K 196Celeba 77.2 Â± 1.9 67.1 Â± 4.870.3 Â± 0.875.178.6 75.4 Â± 2.6 61.6 Â± 6.0 56.7 61.7 Â± 0.3 56.368.5203K 39Fraud 95.7 Â± 0.2 94.7 Â± 0.394.8 Â± 0.194.795.2 95.5 Â± 0.2 80.4 Â± 0.8 93.4 87.5 Â± 0.4 52.594.8285K 29Census 65.6 Â± 2.1 53.4 Â± 8.161.9 Â± 1.967.466.1 58.4 Â± 0.9 58.8 Â± 2.5 64.6 55.7 Â± 0.1 45.053.4299K 500http99.3 Â± 0.1 99.2 Â± 0.2 100.0 Â± 0.099.299.6 99.3 Â± 0.1 91.1 Â± 7.0 23.1 98.4 Â± 0.2 64.799.4567K 3Donors 87.7 Â± 6.2 61.1 Â± 1.378.3 Â± 0.781.582.9 65.5 Â± 11.8 80.3 Â± 18.2 61.2 64.1 Â± 0.0 40.270.2619K 10Average82.580.781.281.080.580.371.270.6 76.8 40.271.0--Rank3.64.44.04.24.24.76.36.66.79.86.8--</p>
<p>Table 3 :
3DIAD PIDForest GIFIFCOPOD PCA SCAD kNN RRCF LOF OC-SVMThyroid76.1 Â± 2.5 88.2 Â± 0.8 57.6 Â± 6.0 81.4 Â± 0.977.667.3 75.9 Â± 2.2 75.1 74.0 Â± 0.5 26.354.7Thyroid (noise)71.1 Â± 1.2 76.0 Â± 2.9 49.4 Â± 1.2 64.4 Â± 1.660.561.4 49.5 Â± 1.6 49.5 53.6 Â± 1.1 50.849.4Mammography85.0 Â± 0.3 84.8 Â± 0.4 82.5 Â± 0.3 85.7 Â± 0.590.588.6 69.8 Â± 2.7 83.9 83.2 Â± 0.2 28.087.2Mammography (noise) 83.1 Â± 0.4 82.0 Â± 2.2 72.7 Â± 5.4 71.4 Â± 2.072.476.8 69.4 Â± 2.4 81.7 79.1 Â± 0.7 37.287.2Average â†“3.57.59.115.617.68.913.4 13.9 12.2 -16.82.7
Unsupervised AD performance (% of AUC) with additional 50 noisy features for DIAD and 9 baselines.We find both DIAD and OC-SVM deteriorate around 2-3% while other methods deteriorate 7-17% on average.</p>
<p>Table 4 :
4
Performance in semi-supervised AD setting.We show the average % of AUC across 15 datasets with varying number of anomalies.
No. Anomalies 05 15 30 60 120DIAD87.1 89.4 90.0 90.4 89.4 91.0DIAD w/o PT-86.2 87.6 88.3 87.2 88.8CST-85.3 86.5 87.1 86.6 88.8DevNet-83.0 84.8 85.4 83.9 85.4</p>
<p>Table 5 :
5
Ablation study for semi-supervised AD.
No. Anomalies5 15 30 60 120DIAD89.4 90.0 90.4 89.4 91.0Only AUC88.9 89.4 90.0 89.1 90.7Only BCE88.8 89.3 89.4 88.3 89.2Unnormalized sparsity 84.1 85.6 85.7 84.2 85.6No upsampling88.6 89.1 89.4 88.5 90.1Only finetune leaf weights 84.8 85.7 86.6 85.7 88.3</p>
<p>Table 7 :
7
Average ranks of AUC across 15 datasets in the Semi-supervised AD result.
No. Anomalies 5 15 30 60 120DIAD1.3 1.3 1.3 1.3 1.2DIAD w/o PT2.3 2.6 2.6 2.5 2.9CST3.2 3.1 3.1 3.0 2.7DevNet3.1 3.0 3.1 3.2 3.2</p>
<p>Table 8 :
8
Summary of Semi-supervised AD performances with varying size of validation set (4%, 8% and 16% of total datasets).We show the average % of AUC across 15 datasets with varying number of anomalies.Our method DIAD still outperforms others consistently.
25% val data (4% of total data)50% val data (8% of total data)100% val data (16% of total data)No. Anomalies515306012051530601205153060120DIAD w/o PT85.4 87.1 86.9 86.4 87.9 85.7 86.9 88.0 86.9 87.5 86.2 87.6 88.3 87.2 88.8DIAD89.0 89.3 89.7 89.1 90.4 89.2 89.7 90.0 89.2 90.6 89.4 90.0 90.4 89.4 91.0CST83.9 84.9 85.7 85.6 88.2 84.2 85.7 85.8 86.2 87.9 85.3 86.5 87.1 86.6 88.8DevNet82.0 83.4 84.4 82.0 84.6 83.0 85.0 85.5 83.6 85.5 83.0 84.8 85.4 83.9 85.4</p>
<p>Table. 4 summarizes the comparisons.</p>
<p>Â± 2.5 76.5 Â± 1.1 71.8 Â± 3.7 70.9 Â± 0.9 70.7 Â± 2.2 Mammography 85.0 Â± 0.3 42.6 Â± 1.4 37.5 Â± 3.7 32.1 Â± 1.3 28.0 Â± 5.3 Siesmic 72.2 Â± 0.4 55.7 Â± 2.7 60.1 Â± 0.6 45.9 Â± 3.0 46.1 Â± 1.3 Campaign 71.0 Â± 0.8 70.3 Â± 4.0 63.9 Â± 0.9 74.8 Â± 0.7 74.4 Â± 0.4 Fraud 95.7 Â± 0.2 82.7 Â± 5.4 91.3 Â± 0.8 96.3 Â± 0.3 96.8 Â± 0.1 Received 20 February 2007; revised 12 March 2009; accepted 5 June 2009
NeuTral AD(Thyroid) (Arrhy) (KDDRev) (KDD)Thyroid 76.1 Avg 80.065.664.964.063.2
It is empirically observed to be important to set a large ğ›¿, around 50-100, to encourage the models ignoring the tree leaves with fewer counts.
We did not use all
datasets in ODDS used in SCAD[29] because some are small or overlap with datasets from[9].
A PSEUDO CODE FOR SOFT DIFFERENTIABLE OBLIVIOUS TREES -ALG. 2Here, we show the pseudo code of differentiable trees.Algorithm 2 Soft decision tree trainingInput: Mini-batch  âˆˆ R Ã— , Temperature  1 , 2 ( 1 , 2 âˆ’ â†’ 0) Symbols: Tree Depth , Entmoid  Trainable Parameters: Feature selection logits  1 ,  2 âˆˆ R  , split Thresholds  âˆˆ R  , split slope  âˆˆ R  ,  = [ 1 ,  2 ,  1 , ...]  âˆˆ R  Ã— {Alternating  1 ,  2 so only 2 chosen features per tree}  =  â€¢ EntMax( / 1 , dim=0) âˆˆ R Ã— {Weighted sum to soft-select features with temperature  1 } for  = 1 to  doâ€¢ 2 ) {Soft binary split of the feature value with temperature  2 } end forB DETAILS OF MAKING TREE OPERATIONS DIFFERENTIABLEBoth   () and I would prevent differentiability.To address this,   () is replaced with a weighted sum of features with temperature annealing that makes it gradually sharper:where   âˆˆ R  is a trainable vector per layer  per tree, and entmax[23]is the entmax normalization, as the sparse version of softmax whose output sum equals to 1.As  â†’ 0, the output of entmax gradually becomes one-hot and   () picks only one feature.Similarly, the step function I is replaced with entmoid, which is a sparse sigmoid with outputs between 0 and 1. Differentiability of all operations (entmax, entmoid, outer/inner products), render ODT differentiable to optimize parameters  ,   and[5].C HYPERPARAMETERSHere we list the hyperparameters we use for both unsupervised and semi-supervised experiments.C.1 Unsupervised ADSince it's hard to tune hyperparameters in unsupervised setting, for fair comparisons, we use all baselines with default hyperparameters.Here we list the default hyperparameter for DIAD in Table6.Here we explain each specific hyperparameter:â€¢ Batch size: the sample size of mini-batch.â€¢ LR: learning rate.â€¢ : the hyperparameter used to update the sparsity in each leaf (Eq.7).â€¢ Steps: the total number of training steps.We find 2000 works well across our datasets.â€¢ LR warmup steps: we do the learning rate warmup[10]that linearly increases the learning rate from 0 to 1e-3 in the first 1000 steps.â€¢ Smoothing : the smoothing count for our volume and data ratio estimation.â€¢ Per tree dropout: the dropout noise we use for the update of each tree.â€¢ Arch: we adopt the GAMAtt architecture form the NodeGAM[5].â€¢ No. layer: the number of layers of trees.â€¢ No. trees: the number of trees per layer.â€¢ Additional tree dimension: the dimension of the tree's output.If more than 0, it appends an additional dimension in the output of each tree.â€¢ Tree depth: the depth of tree.â€¢ Dim Attention: since we use the GAMAtt architecture, this determines the size of the attention embedding.We find tuning more than 32 will lead to insufficient memory in our GPU, and in general 8-16 works well.â€¢ Column subsample (): this controls how many proportion of features a tree can operate on.â€¢ Temp annealing steps (K), Min Temp: these control how fast the temperature linearly decays from 1 to the minimum temperature (0.1) in K steps.After K training steps, the entmax or entmoid become max or step functions in the model.Then, for each baseline we use the same architecture but tune the hyperparameters:â€¢ CST: the overall loss is calcualted as follows (Eq.7, 8, 9 in[38]):The consistency loss   is:where the   (, ) is to use dropout mask  to remove features and impute it with the marginal feature distribution, and the masks are sampled  times.Since the accuracy is quite stable across different , and when  â‰¥ 20 (Fig.10,[38]), we select  = 1 and  = 20, and search the dropout rate   from [0.05, 0.1, 0.2, 0.35, 0.5, 0.7] and the learning rate [2e-3, 1e-3].â€¢ DevNet: they first randomly sample 5000 Gaussian samples with 0 mean and 1 standard deviation and calculate the mean   and standard deviation   :where   âˆ¼  (0, 1),   = standard deviation of { 1 ,  2 ...,  5000 }.Then they calculate the loss (Eq.6, 7 in[22]):The  is the deep neural network and the  is set to 5. In short, they try to increase the output of anomalies ( = 1) to be bigger than  and let the output of normal data ( = 0) to be close to 0. We tune learning rates from [2e-3, 1e-3, 5e-4] for DevNet.The remaining results from Appendix D to J could be found in https://1drv.ms/b/s!ArHmmFHCSXTIhax1cKqJVPu0mLBRtg?e=QGFaJS.I MORE NOISE INJECTION EXPERIMENTSWe show more experimental results to see how methods perform under noise injection in Table9, following the procedures described in Sec.6 and Table3.In additional to Thyroid and Mammograph, we further compare with Siesmic, Campaign, and Fraud.We find that overall DIAD and OC-SVM only deterioriates around 1-2% while others can deterioriate up to 3-11% on average, showing DIAD's superiority of noise resistance.J COMPARISON WITH DEEP-LEARNING BASELINE NEUTRAL ADWe compare DIAD with NeuTral AD on 5 selected representative datasets (Thyroid, Mammography, Siesmic, Campaign, and Fraud datasets) using the same setup as our noise injection experiment in Supp.I. Since for each dataset Neural AD has a different hyperparameter, we ran with all 4 hyperparameters used in the Neural AD paper for 4 tabular datasets (Thyroid, Arrhy, KDDRev, KDD).As can be seen in the below table, we find different hyperparameters of NeuTral AD achieve different AD accuracies but on average are consistently inferior to DIAD.
Classification-Based Anomaly Detection for General Data. Liron Bergman, Yedid Hoshen, International Conference on Learning Representations. 2019</p>
<p>Improving Unsupervised Defect Segmentation by Applying Structural Similarity to Autoencoders. Paul Bergmann, Sindy LÃ¶we, Michael Fauser, David Sattlegger, Carsten Steger, VISIGRAPP (5: VISAPP). 2019</p>
<p>LOF: identifying density-based local outliers. Markus M Breunig, Hans-Peter Kriegel, Raymond T Ng, JÃ¶rg Sander, Proceedings of the 2000 ACM SIGMOD international conference on Management of data. the 2000 ACM SIGMOD international conference on Management of data2000</p>
<p>Intelligible models for healthcare: Predicting pneumonia risk and hospital 30-day readmission. Rich Caruana, Yin Lou, Johannes Gehrke, Paul Koch, Marc Sturm, Noemie Elhadad, Proceedings of the 21th ACM SIGKDD international conference on knowledge discovery and data mining. the 21th ACM SIGKDD international conference on knowledge discovery and data mining2015</p>
<p>NODE-GAM: Neural Generalized Additive Model for Interpretable Deep Learning. Chun-Hao Chang, Rich Caruana, Anna Goldenberg, International Conference on Learning Representations. 2021</p>
<p>How interpretable and trustworthy are gams. Chun-Hao Chang, Sarah Tan, Ben Lengerich, Anna Goldenberg, Rich Caruana, Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining. the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining2021</p>
<p>Incorporating feedback into tree-based anomaly detection. Shubhomoy Das, Weng-Keen Wong, Alan Fern, Thomas G Dietterich, Md Amran Siddiqui, arXiv:1708.094412017. 2017arXiv preprint</p>
<p>Deep anomaly detection using geometric transformations. Izhak Golan, Ran El-Yaniv, Advances in neural information processing systems. 2018. 201831</p>
<p>PIDForest: Anomaly Detection via Partial Identification. Parikshit Gopalan, Sharan Vatsal, Udi Wieder, Advances in Neural Information Processing Systems. 322019. 2019</p>
<p>Priya Goyal, Piotr DollÃ¡r, Ross Girshick, Pieter Noordhuis, Lukasz Wesolowski, Aapo Kyrola, Andrew Tulloch, Yangqing Jia, Kaiming He, arXiv:1706.02677Accurate, large minibatch sgd: Training imagenet in 1 hour. 2017. 2017arXiv preprint</p>
<p>Robust random cut forest based anomaly detection on streams. Sudipto Guha, Nina Mishra, Gourav Roy, Okke Schrijvers, International conference on machine learning. PMLR2016</p>
<p>Towards explaining anomalies: a deep Taylor decomposition of one-class models. Jacob Kauffmann, Klaus-Robert MÃ¼ller, GrÃ©goire Montavon, Pattern Recognition. 1011071982020. 2020</p>
<p>BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. Proceedings of NAACL-HLT. Jacob Devlin, Ming-Wei Chang, Kenton , Lee Kristina, Toutanova , NAACL-HLT2019</p>
<p>CutPaste: Self-Supervised Learning for Anomaly Detection and Localization. Chun-Liang Li, Kihyuk Sohn, Jinsung Yoon, Tomas Pfister, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern Recognition2021</p>
<p>COPOD: copula-based outlier detection. Zheng Li, Yue Zhao, Nicola Botta, Cezar Ionescu, Xiyang Hu, 2020 IEEE International Conference on Data Mining (ICDM). IEEE2020</p>
<p>ControlBurn: Feature Selection by Sparse Forests. Brian Liu, Miaolan Xie, Madeleine Udell, Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining. the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining2021</p>
<p>Isolation forest. Tony Fei, Kai Ming Liu, Zhi-Hua Ting, Zhou, 2008 eighth ieee international conference on data mining. IEEE2008</p>
<p>LP-Explain: Local Pictorial Explanation for Outliers. Haoyu Liu, Fenglong Ma, Yaqing Wang, Shibo He, Jiming Chen, Jing Gao, 2020 IEEE International Conference on Data Mining (ICDM). IEEE2020</p>
<p>Explainable Deep One-Class Classification. Philipp Liznerski, Lukas Ruff, Robert A Vandermeulen, Billy Joe Franks, Marius Kloft, Klaus Robert Muller, International Conference on Learning Representations. 2021</p>
<p>A Unified Approach to Interpreting Model Predictions. M Scott, Su-In Lundberg, ; I Lee, U V Guyon, S Luxburg, H Bengio, R Wallach, S Fergus, Advances in Neural Information Processing Systems. R Vishwanathan, Garnett, Curran Associates, Inc201730</p>
<p>Toward Explainable Deep Anomaly Detection. Guansong Pang, Charu Aggarwal, 10.1145/3447548.34707942021Association for Computing MachineryNew York, NY, USA</p>
<p>Deep anomaly detection with deviation networks. Guansong Pang, Chunhua Shen, Anton Van Den, Hengel, Proceedings of the 25th ACM SIGKDD international conference on knowledge discovery &amp; data mining. the 25th ACM SIGKDD international conference on knowledge discovery &amp; data mining2019</p>
<p>Sparse Sequence-to-Sequence Models. Ben Peters, Vlad Niculae, AndrÃ© Ft Martins, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. the 57th Annual Meeting of the Association for Computational Linguistics2019</p>
<p>Chen Qiu, Timo Pfrommer, Marius Kloft, Stephan Mandt, Maja Rudolph, arXiv:2103.16440Neural Transformation Learning for Deep Anomaly Detection Beyond Images. 2021. 2021arXiv preprint</p>
<p>Explaining the predictions of any classifier. Marco Tulio Ribeiro, Sameer Singh, Carlos Guestrin, Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining. the 22nd ACM SIGKDD international conference on knowledge discovery and data mining2016Why should i trust you?</p>
<p>Deep one-class classification. Lukas Ruff, Robert Vandermeulen, Nico Goernitz, Lucas Deecke, Ahmed Shoaib, Alexander Siddiqui, Emmanuel Binder, Marius MÃ¼ller, Kloft, International conference on machine learning. PMLR2018</p>
<p>Deep Semi-Supervised Anomaly Detection. Lukas Ruff, Robert A Vandermeulen, Nico GÃ¶rnitz, Alexander Binder, Emmanuel MÃ¼ller, Klaus-Robert MÃ¼ller, Marius Kloft, International Conference on Learning Representations. 2019</p>
<p>Estimating the support of a high-dimensional distribution. Bernhard SchÃ¶lkopf, John C Platt, John Shawe-Taylor, Alex J Smola, Robert C Williamson, Neural computation. 132001. 2001</p>
<p>Anomaly Detection for Tabular Data with Internal Contrastive Learning. Tom Shenkar, Lior Wolf, International Conference on Learning Representations. 2022</p>
<p>Fixmatch: Simplifying semi-supervised learning with consistency and confidence. Kihyuk Sohn, David Berthelot, Nicholas Carlini, Zizhao Zhang, Han Zhang, Colin A Raffel, Ekin Dogus Cubuk, Alexey Kurakin, Chun-Liang Li, Advances in neural information processing systems. 332020. 2020</p>
<p>Learning and Evaluating Representations for Deep One-Class Classification. Kihyuk Sohn, Chun-Liang Li, Jinsung Yoon, Minho Jin, Tomas Pfister, International Conference on Learning Representations. 2021</p>
<p>Csi: Novelty detection via contrastive learning on distributionally shifted instances. Jihoon Tack, Sangwoo Mo, Jongheon Jeong, Jinwoo Shin, Advances in neural information processing systems. 332020. 2020</p>
<p>Distill-and-compare: Auditing black-box models using transparent model distillation. Sarah Tan, Rich Caruana, Giles Hooker, Yin Lou, AIES. 2018</p>
<p>Discovering outlying aspects in large datasets. Xuan Nguyen, Jeffrey Vinh, Simone Chan, James Romano, Christopher Bailey, Kotagiri Leckie, Jian Ramamohanarao, Pei, Data mining and knowledge discovery. 302016. 2016</p>
<p>J Zijie, Alex Wang, Harsha Kale, Peter Nori, Mark Stella, Duen Nunnally, Mihaela Horng Chau, Jennifer Wortman Vorvoreanu, Rich Vaughan, Caruana, arXiv:2112.03245Gam changer: Editing generalized additive models with interactive visualization. 2021. 2021arXiv preprint</p>
<p>Optimizing classifier performance via an approximation to the Wilcoxon-Mann-Whitney statistic. Lian Yan, Robert H Dodier, Michael Mozer, Richard H Wolniewicz, Proceedings of the 20th international conference on machine learning. the 20th international conference on machine learning2003icml-03</p>
<p>Vime: Extending the success of self-and semi-supervised learning to tabular domain. Jinsung Yoon, Yao Zhang, James Jordon, Mihaela Van Der Schaar, Advances in Neural Information Processing Systems. 332020. 2020</p>
<p>Vime: Extending the success of self-and semi-supervised learning to tabular domain. Jinsung Yoon, Yao Zhang, James Jordon, Mihaela Van Der Schaar, Advances in Neural Information Processing Systems. 332020. 2020</p>
<p>Deep autoencoding gaussian mixture model for unsupervised anomaly detection. Bo Zong, Qi Song, Martin Renqiang Min, Wei Cheng, Cristian Lumezanu, Daeki Cho, Haifeng Chen, International conference on learning representations. 2018</p>            </div>
        </div>

    </div>
</body>
</html>