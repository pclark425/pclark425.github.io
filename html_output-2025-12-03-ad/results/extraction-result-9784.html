<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-9784 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-9784</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-9784</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-165.html">extraction-schema-165</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used to distill, extract, or synthesize qualitative laws, principles, or generalizable rules from large numbers of scholarly input papers, including details of the methods, domains, evaluation, and results.</div>
                <p><strong>Paper ID:</strong> paper-e2accdea0eba27a1d5716bd83be1b3eb06c0cc0b</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/e2accdea0eba27a1d5716bd83be1b3eb06c0cc0b" target="_blank">Large language model based framework for automated extraction of genetic interactions from unstructured data</a></p>
                <p><strong>Paper Venue:</strong> PLoS ONE</p>
                <p><strong>Paper TL;DR:</strong> GIX, an automated and robust Gene Interaction Extraction framework, based on pre-trained Large Language models fine-tuned through extensive evaluations on various gene/protein interaction corpora including LLL and RegulonDB, is proposed and demonstrated that the proposed method performs as well as manual relation extraction, with enhanced robustness.</p>
                <p><strong>Paper Abstract:</strong> Extracting biological interactions from published literature helps us understand complex biological systems, accelerate research, and support decision-making in drug or treatment development. Despite efforts to automate the extraction of biological relations using text mining tools and machine learning pipelines, manual curation continues to serve as the gold standard. However, the rapidly increasing volume of literature pertaining to biological relations poses challenges in its manual curation and refinement. These challenges are further compounded because only a small fraction of the published literature is relevant to biological relation extraction, and the embedded sentences of relevant sections have complex structures, which can lead to incorrect inference of relationships. To overcome these challenges, we propose GIX, an automated and robust Gene Interaction Extraction framework, based on pre-trained Large Language models fine-tuned through extensive evaluations on various gene/protein interaction corpora including LLL and RegulonDB. GIX identifies relevant publications with minimal keywords, optimises sentence selection to reduce computational overhead, simplifies sentence structure while preserving meaning, and provides a confidence factor indicating the reliability of extracted relations. GIX’s Stage-2 relation extraction method performed well on benchmark protein/gene interaction datasets, assessed using 10-fold cross-validation, surpassing state-of-the-art approaches. We demonstrated that the proposed method, although fully automated, performs as well as manual relation extraction, with enhanced robustness. We also observed GIX’s capability to augment existing datasets with new sentences, incorporating newly discovered biological terms and processes. Further, we demonstrated GIX’s real-world applicability in inferring E. coli gene circuits.</p>
                <p><strong>Cost:</strong> 0.015</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e9784.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e9784.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used to distill, extract, or synthesize qualitative laws, principles, or generalizable rules from large numbers of scholarly input papers, including details of the methods, domains, evaluation, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GIX</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Gene Interaction Extraction (GIX) framework</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A three-stage automated framework that uses pre-trained domain-specific large language models to extract binary transcriptional regulatory relations (gene/protein interactions) from unstructured scientific abstracts, including pre-processing (relevance/sentence filtering), relation extraction via fine-tuned BioBERT and BERN2 NER, and post-processing with entity refinement and a numeric confidence factor.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Large language model based framework for automated extraction of genetic interactions from unstructured data</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_name</strong></td>
                            <td>BioBERT and BERN2 (used together within GIX)</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_description</strong></td>
                            <td>BioBERT: a BERT-based transformer model pre-trained on biomedical corpora (PubMed abstracts and PMC articles) and fine-tuned here for sentence-level classification and relation extraction. BERN2: a pre-trained biomedical named entity recognition and normalization tool (BERT-based) used for extracting and normalizing gene/protein entity mentions; invoked via its RESTful API and used without further fine-tuning in the pipeline.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Molecular biology / biomedical text mining (extraction of transcriptional regulatory relations and gene regulatory networks)</td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_description</strong></td>
                            <td>Collections of PubMed abstracts retrieved by keyword queries (examples: for B. subtilis and E. coli experiments GIX retrieved 371 and 954 abstracts respectively), plus standard benchmark PPI/interaction corpora used for fine-tuning and evaluation (BioInfer, HPRD50, IEPA, LLL). Preprocessing included restricting to organism keywords, sentence tokenization, two-stage sentence eliminators (BioBERT classifier and BERN2-based entity-count filter), and further refinement of extracted entity phrases.</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_law_type</strong></td>
                            <td>Binary transcriptional regulatory rules / causal relations (agent/controller gene -> target gene expression), i.e., generalizable regulatory statements about activation/repression relationships between genes/proteins.</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_law_example</strong></td>
                            <td>Examples from extracted sentences: 'Both SigK and GerE were essential for ykvP expression' (interpreted as SigK -> ykvP), 'TrpE-dependent trpR expression' (TrpE -> trpR), and CRP-cyclic-AMP regulating deoC/deoA/deoB/deoD (CRP-cAMP -> deo* genes).</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_methodology</strong></td>
                            <td>Fine-tune BioBERT for two classification tasks: (i) Sentence eliminator 1 (binary classifier to filter sentences that do/don't discuss regulatory interactions) and (ii) Relation-extraction classifier (Stage-2) that classifies labeled sentence variants as positive/negative for a relation. Use BERN2 for NER/NEN and as Sentence eliminator 2 to discard sentences with fewer than two gene/protein entities. Use an entity-labelling anonymization scheme: replace the tested pair with $GENE_AGENT# and $GENE_TARGET# and replace all other entities with 'BLANK' to reduce complexity while preserving sentence context. Post-processing includes entity-name refinement (splitting phrases, re-running BERN2, spellcheck heuristics) and computing a Confidence Factor (CF) per extracted relation combining aggregated classifier scores across sentences (sum of per-sentence prediction scores) and prior-knowledge signals from curated databases (discrete P values aggregated with weighting K).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>10-fold cross-validation for Stage-2 relation extraction on benchmark datasets (BioInfer, HPRD50, IEPA, LLL). Additional evaluations by (a) comparing extracted relations from PubMed abstracts against manual curation in the LLL benchmark (Exp2) and SubtiWiki for B. subtilis, and (b) comparing against RegulonDB curated E. coli interactions (Exp3). ROC analysis was used to select CF thresholds (γ). Reported metrics: Precision, Recall, F-score; also counts of relations recovered and cross-document confirmations.</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>GIX (Stage-2 relation-extraction model) outperformed prior state-of-the-art methods on four benchmark datasets: reported P/R/F (GIX RE) — BioInfer: 91.1 / 92.9 / 92.0; HPRD50: 91.5 / 93.3 / 92.2; IEPA: 89.4 / 89.5 / 88.9; LLL: 93.9 / 92.4 / 93.9. In Exp2 (LLL-focused), the full framework matched the relation-extraction model's P/R/F (86.30 / 79.35 / 81.29) while extracting additional corroborating sentences (130 true interactions confirmed 255 times overall), enabling augmentation of datasets with new sentences. In Exp3 (E. coli / RegulonDB), GIX processed 954 abstracts, extracted 2,866 refined interactions, and recovered 456 of 578 abstract-level curated interactions; an additional 622 GIX-extracted regulations were consistent with RegulonDB relations annotated from other article segments. Confidence thresholds and prior-knowledge weighting (K) were used to trade off precision/recall (example thresholds: γ=0.88 for LLL, γ=1.5 for E. coli; K chosen empirically, e.g., 2 for E. coli).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Direct comparison to many prior ML/DL baselines (DNN, Bi-LSTM, MCCNN, RCNN, iLSTM+tAttn, etc.) on the same benchmarks showed GIX RE achieved substantially higher F-scores (improvements reported in paper up to ~12-13.7% on some datasets, e.g., HPRD50). Against manual curation: GIX recovered a large fraction of curated relations and provided multiple independent sentence confirmations per relation, effectively augmenting manual datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>reported_limitations</strong></td>
                            <td>Focus limited to abstracts (authors note extracting from full-text is more complex due to access and parsing issues); potential loss of candidate sentences during aggressive preprocessing; some errors arise from NER mis-tagging or incomplete entity phrase refinement; directionality ambiguity in sentences (not all sentences clearly indicate agent->target), requiring prior-knowledge heuristics; computational cost in per-word NER refinement (mitigated with heuristics); reliance on curated databases for CF amplification may bias toward previously known regulators.</td>
                        </tr>
                        <tr>
                            <td><strong>bias_or_hallucination_issues</strong></td>
                            <td>Authors explicitly note publication bias (positive results more likely published) which can skew extracted relations; extraction errors include false positives due to complex sentence structure, POS/NER tagging errors, and conditional relations that may not indicate true regulatory causation. The paper does not claim LLM-style creative hallucination but emphasizes use of CF and prior-knowledge checks to reduce spurious outputs and the nontrivial possibility that extracted relations are not experimentally true without further validation.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Large language model based framework for automated extraction of genetic interactions from unstructured data', 'publication_date_yy_mm': '2024-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9784.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e9784.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used to distill, extract, or synthesize qualitative laws, principles, or generalizable rules from large numbers of scholarly input papers, including details of the methods, domains, evaluation, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BioBERT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>BioBERT (Biomedical BERT)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A domain-adapted BERT transformer pre-trained on large biomedical corpora (PubMed and PMC) that provides contextualized embeddings and is fine-tuned in this work for sentence classification and binary relation extraction of gene/protein interactions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Large language model based framework for automated extraction of genetic interactions from unstructured data</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_name</strong></td>
                            <td>BioBERT</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_description</strong></td>
                            <td>BERT-based transformer pre-trained on biomedical text (PubMed abstracts and PMC full-text articles), used here and fine-tuned for (i) a sentence-level regulatory/non-regulatory classifier (Sentence Eliminator 1) and (ii) a relation-classification model applying entity-labelling and anonymization to predict binary relations between gene/protein pairs.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Biomedical NLP — extraction of gene/protein regulatory relations from abstracts</td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_description</strong></td>
                            <td>Fine-tuning used expert-annotated PPI/relation corpora (BioInfer, HPRD50, IEPA, and LLL); testing performed via 10-fold cross-validation on these corpora and on PubMed-abstract-derived datasets for specific organisms (B. subtilis, E. coli) assembled via keyword searches.</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_law_type</strong></td>
                            <td>Binary causal/regulatory rules between gene/protein entities (agent -> target regulatory assertions)</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_law_example</strong></td>
                            <td>From labeled sentences: 'Both SigK and GerE were essential for ykvP expression' interpreted as SigK (agent) -> ykvP (target).</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_methodology</strong></td>
                            <td>Fine-tuning BioBERT on positive/negative labeled sentences for relation extraction; use of an anonymization labeling scheme replacing candidate pair with $GENE_AGENT# and $GENE_TARGET# and other entities replaced by 'BLANK' to focus the model on the evaluated pair; per-sentence prediction scores aggregated across sentences for each candidate relation.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>10-fold cross-validation on benchmark PPI corpora (BioInfer, HPRD50, IEPA, LLL) with Precision/Recall/F-score reporting; cross-dataset generalization experiments (fine-tune on non-LLL corpora and test on LLL); comparisons to prior models.</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>When fine-tuned as part of GIX, BioBERT-based relation extraction achieved top performance across benchmarks (e.g., F-scores of 92.0 on BioInfer and 93.9 on LLL) outperforming prior DL and kernel-based methods.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Significantly outperformed prior methods listed in the paper (e.g., DNN, RCNN, iLSTM+tAttn) on the evaluated benchmarks; improvements attributed to domain pretraining plus the anonymization/entity-labelling strategy.</td>
                        </tr>
                        <tr>
                            <td><strong>reported_limitations</strong></td>
                            <td>Performance depends on fine-tuning data domain alignment; accuracy can drop when fine-tuning and test domains differ (authors discuss generalization issues and mitigate by combining diverse datasets). Also sensitive to NER accuracy and sentence complexity; requires GPU resources and hyperparameter tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>bias_or_hallucination_issues</strong></td>
                            <td>Paper notes general risks from publication bias and false positives; BioBERT outputs are probabilistic classifier scores that can reflect confused signals when sentences are ambiguous or lack clear directionality—mitigated in pipeline by post-processing and CF aggregation rather than claimed to be immune to hallucination.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Large language model based framework for automated extraction of genetic interactions from unstructured data', 'publication_date_yy_mm': '2024-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9784.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e9784.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used to distill, extract, or synthesize qualitative laws, principles, or generalizable rules from large numbers of scholarly input papers, including details of the methods, domains, evaluation, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BERN2</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>BERN2 (Biomedical Entity Recognition and Normalization tool, version 2)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A pre-trained biomedical named entity recognition and normalization system used to identify gene/protein mentions, provide entity types and probability scores, and perform entity normalization (NEN) within the GIX pipeline; employed both to filter sentences with fewer than two entities and to refine entity names during post-processing.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Large language model based framework for automated extraction of genetic interactions from unstructured data</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_name</strong></td>
                            <td>BERN2</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_description</strong></td>
                            <td>A biomedical NER/NEN tool (BERT-based as described in the paper) that outputs JSON annotations (entity phrase, type, probability) accessible via a RESTful API; used without additional fine-tuning in GIX to detect and normalize gene/protein entities and to provide per-annotation confidence scores.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Biomedical named entity recognition and normalization within relation-extraction pipelines</td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_description</strong></td>
                            <td>Applied to individual sentences tokenized from PubMed abstracts (and to candidate entity phrase words during refinement) to detect gene/protein mentions; used across benchmark corpora and across the organism-specific PubMed retrievals (B. subtilis, E. coli).</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_law_type</strong></td>
                            <td>Enabling technology for extracting binary qualitative regulatory relations by reliably locating and normalizing entity mentions (not itself a law extractor but critical to extracting causal rules).</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_law_example</strong></td>
                            <td>Helps produce the refined entity pair 'SigK -> ykvP' from the sentence 'Both SigK and GerE were essential for ykvP expression' by identifying 'SigK' and 'ykvP' as gene entities and normalizing names for aggregation across papers.</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_methodology</strong></td>
                            <td>Used directly via its API for (a) Sentence Eliminator 2 (remove sentences with <2 gene/protein mentions), (b) NEN to normalize entity mentions, and (c) entity-name refinement where multi-word entity phrases are split and re-submitted to BERN2; also supplies per-entity probability scores used in refinement pipelines.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>NER performance indirectly evaluated via downstream relation-extraction metrics and by manual checks during refinement (e.g., number of relations eliminated because BERN2 failed to extract canonical gene names); the pipeline also uses curated databases to validate normalized entities.</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>BERN2 enabled reliable filtering of irrelevant sentences and improved aggregation of relations across papers via normalization; some entity phrases required additional splitting and spellcheck heuristics when BERN2 returned incomplete names.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>The authors note BERN2 outperforms previous BioNER tools (cited in background) and that its normalization capability contributed to the higher end-to-end RE performance of GIX compared with systems that lacked robust normalization.</td>
                        </tr>
                        <tr>
                            <td><strong>reported_limitations</strong></td>
                            <td>BERN2 occasionally returns group phrases or misses the canonical gene/protein token requiring further per-word refinement and spellcheck heuristics; invoking BERN2 per-word can be computationally expensive for large corpora, so authors use lists of frequent non-entity words to reduce checks.</td>
                        </tr>
                        <tr>
                            <td><strong>bias_or_hallucination_issues</strong></td>
                            <td>Issues identified are typical NER failure modes (incorrect entity spans, missed canonical names) rather than LLM hallucination; such NER errors can propagate to false relation predictions and are explicitly handled in post-processing.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Large language model based framework for automated extraction of genetic interactions from unstructured data', 'publication_date_yy_mm': '2024-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>BioBERT: a pre-trained biomedical language representation model for biomedical text mining <em>(Rating: 2)</em></li>
                <li>BioInfer: a corpus for information extraction in the biomedical domain <em>(Rating: 2)</em></li>
                <li>Learning language in logic—genic interaction extraction challenge <em>(Rating: 2)</em></li>
                <li>RelEx—Relation extraction using dependency parse trees <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-9784",
    "paper_id": "paper-e2accdea0eba27a1d5716bd83be1b3eb06c0cc0b",
    "extraction_schema_id": "extraction-schema-165",
    "extracted_data": [
        {
            "name_short": "GIX",
            "name_full": "Gene Interaction Extraction (GIX) framework",
            "brief_description": "A three-stage automated framework that uses pre-trained domain-specific large language models to extract binary transcriptional regulatory relations (gene/protein interactions) from unstructured scientific abstracts, including pre-processing (relevance/sentence filtering), relation extraction via fine-tuned BioBERT and BERN2 NER, and post-processing with entity refinement and a numeric confidence factor.",
            "citation_title": "Large language model based framework for automated extraction of genetic interactions from unstructured data",
            "mention_or_use": "use",
            "llm_model_name": "BioBERT and BERN2 (used together within GIX)",
            "llm_model_description": "BioBERT: a BERT-based transformer model pre-trained on biomedical corpora (PubMed abstracts and PMC articles) and fine-tuned here for sentence-level classification and relation extraction. BERN2: a pre-trained biomedical named entity recognition and normalization tool (BERT-based) used for extracting and normalizing gene/protein entity mentions; invoked via its RESTful API and used without further fine-tuning in the pipeline.",
            "application_domain": "Molecular biology / biomedical text mining (extraction of transcriptional regulatory relations and gene regulatory networks)",
            "input_corpus_description": "Collections of PubMed abstracts retrieved by keyword queries (examples: for B. subtilis and E. coli experiments GIX retrieved 371 and 954 abstracts respectively), plus standard benchmark PPI/interaction corpora used for fine-tuning and evaluation (BioInfer, HPRD50, IEPA, LLL). Preprocessing included restricting to organism keywords, sentence tokenization, two-stage sentence eliminators (BioBERT classifier and BERN2-based entity-count filter), and further refinement of extracted entity phrases.",
            "qualitative_law_type": "Binary transcriptional regulatory rules / causal relations (agent/controller gene -&gt; target gene expression), i.e., generalizable regulatory statements about activation/repression relationships between genes/proteins.",
            "qualitative_law_example": "Examples from extracted sentences: 'Both SigK and GerE were essential for ykvP expression' (interpreted as SigK -&gt; ykvP), 'TrpE-dependent trpR expression' (TrpE -&gt; trpR), and CRP-cyclic-AMP regulating deoC/deoA/deoB/deoD (CRP-cAMP -&gt; deo* genes).",
            "extraction_methodology": "Fine-tune BioBERT for two classification tasks: (i) Sentence eliminator 1 (binary classifier to filter sentences that do/don't discuss regulatory interactions) and (ii) Relation-extraction classifier (Stage-2) that classifies labeled sentence variants as positive/negative for a relation. Use BERN2 for NER/NEN and as Sentence eliminator 2 to discard sentences with fewer than two gene/protein entities. Use an entity-labelling anonymization scheme: replace the tested pair with $GENE_AGENT# and $GENE_TARGET# and replace all other entities with 'BLANK' to reduce complexity while preserving sentence context. Post-processing includes entity-name refinement (splitting phrases, re-running BERN2, spellcheck heuristics) and computing a Confidence Factor (CF) per extracted relation combining aggregated classifier scores across sentences (sum of per-sentence prediction scores) and prior-knowledge signals from curated databases (discrete P values aggregated with weighting K).",
            "evaluation_method": "10-fold cross-validation for Stage-2 relation extraction on benchmark datasets (BioInfer, HPRD50, IEPA, LLL). Additional evaluations by (a) comparing extracted relations from PubMed abstracts against manual curation in the LLL benchmark (Exp2) and SubtiWiki for B. subtilis, and (b) comparing against RegulonDB curated E. coli interactions (Exp3). ROC analysis was used to select CF thresholds (γ). Reported metrics: Precision, Recall, F-score; also counts of relations recovered and cross-document confirmations.",
            "results_summary": "GIX (Stage-2 relation-extraction model) outperformed prior state-of-the-art methods on four benchmark datasets: reported P/R/F (GIX RE) — BioInfer: 91.1 / 92.9 / 92.0; HPRD50: 91.5 / 93.3 / 92.2; IEPA: 89.4 / 89.5 / 88.9; LLL: 93.9 / 92.4 / 93.9. In Exp2 (LLL-focused), the full framework matched the relation-extraction model's P/R/F (86.30 / 79.35 / 81.29) while extracting additional corroborating sentences (130 true interactions confirmed 255 times overall), enabling augmentation of datasets with new sentences. In Exp3 (E. coli / RegulonDB), GIX processed 954 abstracts, extracted 2,866 refined interactions, and recovered 456 of 578 abstract-level curated interactions; an additional 622 GIX-extracted regulations were consistent with RegulonDB relations annotated from other article segments. Confidence thresholds and prior-knowledge weighting (K) were used to trade off precision/recall (example thresholds: γ=0.88 for LLL, γ=1.5 for E. coli; K chosen empirically, e.g., 2 for E. coli).",
            "comparison_to_baseline": "Direct comparison to many prior ML/DL baselines (DNN, Bi-LSTM, MCCNN, RCNN, iLSTM+tAttn, etc.) on the same benchmarks showed GIX RE achieved substantially higher F-scores (improvements reported in paper up to ~12-13.7% on some datasets, e.g., HPRD50). Against manual curation: GIX recovered a large fraction of curated relations and provided multiple independent sentence confirmations per relation, effectively augmenting manual datasets.",
            "reported_limitations": "Focus limited to abstracts (authors note extracting from full-text is more complex due to access and parsing issues); potential loss of candidate sentences during aggressive preprocessing; some errors arise from NER mis-tagging or incomplete entity phrase refinement; directionality ambiguity in sentences (not all sentences clearly indicate agent-&gt;target), requiring prior-knowledge heuristics; computational cost in per-word NER refinement (mitigated with heuristics); reliance on curated databases for CF amplification may bias toward previously known regulators.",
            "bias_or_hallucination_issues": "Authors explicitly note publication bias (positive results more likely published) which can skew extracted relations; extraction errors include false positives due to complex sentence structure, POS/NER tagging errors, and conditional relations that may not indicate true regulatory causation. The paper does not claim LLM-style creative hallucination but emphasizes use of CF and prior-knowledge checks to reduce spurious outputs and the nontrivial possibility that extracted relations are not experimentally true without further validation.",
            "uuid": "e9784.0",
            "source_info": {
                "paper_title": "Large language model based framework for automated extraction of genetic interactions from unstructured data",
                "publication_date_yy_mm": "2024-05"
            }
        },
        {
            "name_short": "BioBERT",
            "name_full": "BioBERT (Biomedical BERT)",
            "brief_description": "A domain-adapted BERT transformer pre-trained on large biomedical corpora (PubMed and PMC) that provides contextualized embeddings and is fine-tuned in this work for sentence classification and binary relation extraction of gene/protein interactions.",
            "citation_title": "Large language model based framework for automated extraction of genetic interactions from unstructured data",
            "mention_or_use": "use",
            "llm_model_name": "BioBERT",
            "llm_model_description": "BERT-based transformer pre-trained on biomedical text (PubMed abstracts and PMC full-text articles), used here and fine-tuned for (i) a sentence-level regulatory/non-regulatory classifier (Sentence Eliminator 1) and (ii) a relation-classification model applying entity-labelling and anonymization to predict binary relations between gene/protein pairs.",
            "application_domain": "Biomedical NLP — extraction of gene/protein regulatory relations from abstracts",
            "input_corpus_description": "Fine-tuning used expert-annotated PPI/relation corpora (BioInfer, HPRD50, IEPA, and LLL); testing performed via 10-fold cross-validation on these corpora and on PubMed-abstract-derived datasets for specific organisms (B. subtilis, E. coli) assembled via keyword searches.",
            "qualitative_law_type": "Binary causal/regulatory rules between gene/protein entities (agent -&gt; target regulatory assertions)",
            "qualitative_law_example": "From labeled sentences: 'Both SigK and GerE were essential for ykvP expression' interpreted as SigK (agent) -&gt; ykvP (target).",
            "extraction_methodology": "Fine-tuning BioBERT on positive/negative labeled sentences for relation extraction; use of an anonymization labeling scheme replacing candidate pair with $GENE_AGENT# and $GENE_TARGET# and other entities replaced by 'BLANK' to focus the model on the evaluated pair; per-sentence prediction scores aggregated across sentences for each candidate relation.",
            "evaluation_method": "10-fold cross-validation on benchmark PPI corpora (BioInfer, HPRD50, IEPA, LLL) with Precision/Recall/F-score reporting; cross-dataset generalization experiments (fine-tune on non-LLL corpora and test on LLL); comparisons to prior models.",
            "results_summary": "When fine-tuned as part of GIX, BioBERT-based relation extraction achieved top performance across benchmarks (e.g., F-scores of 92.0 on BioInfer and 93.9 on LLL) outperforming prior DL and kernel-based methods.",
            "comparison_to_baseline": "Significantly outperformed prior methods listed in the paper (e.g., DNN, RCNN, iLSTM+tAttn) on the evaluated benchmarks; improvements attributed to domain pretraining plus the anonymization/entity-labelling strategy.",
            "reported_limitations": "Performance depends on fine-tuning data domain alignment; accuracy can drop when fine-tuning and test domains differ (authors discuss generalization issues and mitigate by combining diverse datasets). Also sensitive to NER accuracy and sentence complexity; requires GPU resources and hyperparameter tuning.",
            "bias_or_hallucination_issues": "Paper notes general risks from publication bias and false positives; BioBERT outputs are probabilistic classifier scores that can reflect confused signals when sentences are ambiguous or lack clear directionality—mitigated in pipeline by post-processing and CF aggregation rather than claimed to be immune to hallucination.",
            "uuid": "e9784.1",
            "source_info": {
                "paper_title": "Large language model based framework for automated extraction of genetic interactions from unstructured data",
                "publication_date_yy_mm": "2024-05"
            }
        },
        {
            "name_short": "BERN2",
            "name_full": "BERN2 (Biomedical Entity Recognition and Normalization tool, version 2)",
            "brief_description": "A pre-trained biomedical named entity recognition and normalization system used to identify gene/protein mentions, provide entity types and probability scores, and perform entity normalization (NEN) within the GIX pipeline; employed both to filter sentences with fewer than two entities and to refine entity names during post-processing.",
            "citation_title": "Large language model based framework for automated extraction of genetic interactions from unstructured data",
            "mention_or_use": "use",
            "llm_model_name": "BERN2",
            "llm_model_description": "A biomedical NER/NEN tool (BERT-based as described in the paper) that outputs JSON annotations (entity phrase, type, probability) accessible via a RESTful API; used without additional fine-tuning in GIX to detect and normalize gene/protein entities and to provide per-annotation confidence scores.",
            "application_domain": "Biomedical named entity recognition and normalization within relation-extraction pipelines",
            "input_corpus_description": "Applied to individual sentences tokenized from PubMed abstracts (and to candidate entity phrase words during refinement) to detect gene/protein mentions; used across benchmark corpora and across the organism-specific PubMed retrievals (B. subtilis, E. coli).",
            "qualitative_law_type": "Enabling technology for extracting binary qualitative regulatory relations by reliably locating and normalizing entity mentions (not itself a law extractor but critical to extracting causal rules).",
            "qualitative_law_example": "Helps produce the refined entity pair 'SigK -&gt; ykvP' from the sentence 'Both SigK and GerE were essential for ykvP expression' by identifying 'SigK' and 'ykvP' as gene entities and normalizing names for aggregation across papers.",
            "extraction_methodology": "Used directly via its API for (a) Sentence Eliminator 2 (remove sentences with &lt;2 gene/protein mentions), (b) NEN to normalize entity mentions, and (c) entity-name refinement where multi-word entity phrases are split and re-submitted to BERN2; also supplies per-entity probability scores used in refinement pipelines.",
            "evaluation_method": "NER performance indirectly evaluated via downstream relation-extraction metrics and by manual checks during refinement (e.g., number of relations eliminated because BERN2 failed to extract canonical gene names); the pipeline also uses curated databases to validate normalized entities.",
            "results_summary": "BERN2 enabled reliable filtering of irrelevant sentences and improved aggregation of relations across papers via normalization; some entity phrases required additional splitting and spellcheck heuristics when BERN2 returned incomplete names.",
            "comparison_to_baseline": "The authors note BERN2 outperforms previous BioNER tools (cited in background) and that its normalization capability contributed to the higher end-to-end RE performance of GIX compared with systems that lacked robust normalization.",
            "reported_limitations": "BERN2 occasionally returns group phrases or misses the canonical gene/protein token requiring further per-word refinement and spellcheck heuristics; invoking BERN2 per-word can be computationally expensive for large corpora, so authors use lists of frequent non-entity words to reduce checks.",
            "bias_or_hallucination_issues": "Issues identified are typical NER failure modes (incorrect entity spans, missed canonical names) rather than LLM hallucination; such NER errors can propagate to false relation predictions and are explicitly handled in post-processing.",
            "uuid": "e9784.2",
            "source_info": {
                "paper_title": "Large language model based framework for automated extraction of genetic interactions from unstructured data",
                "publication_date_yy_mm": "2024-05"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "BioBERT: a pre-trained biomedical language representation model for biomedical text mining",
            "rating": 2
        },
        {
            "paper_title": "BioInfer: a corpus for information extraction in the biomedical domain",
            "rating": 2
        },
        {
            "paper_title": "Learning language in logic—genic interaction extraction challenge",
            "rating": 2
        },
        {
            "paper_title": "RelEx—Relation extraction using dependency parse trees",
            "rating": 1
        }
    ],
    "cost": 0.014644749999999998,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>RESEARCH ARTICLE</h1>
<h2>Large language model based framework for automated extraction of genetic interactions from unstructured data</h2>
<p>Jaskaran Kaur Gill ${ }^{1 <em>}$, Madhu Chetty ${ }^{1 </em>}$, Suryani Lim ${ }^{1}$, Jennifer Hallinan ${ }^{1,2}$<br>1 Health Innovation and Transformation Centre, Federation University, Ballarat, Victoria, Australia, 2 BioThink, Brisbane, Queensland, Australia<br>* jaskarankaurgill@students.federation.edu.au (JKG); madhu.chetty@federation.edu.au (MC)</p>
<h2>6 OPEN ACCESS</h2>
<p>Citation: Gill JK, Chetty M, Lim S, Hallinan J (2024) Large language model based framework for automated extraction of genetic interactions from unstructured data. PLoS ONE 19(5): e0303231. https://doi.org/10.1371/journal.pone.0303231</p>
<p>Editor: Michal Plaszynski, Kitami Institute of Technology, JAPAN</p>
<p>Received: September 26, 2023
Accepted: April 23, 2024
Published: May 21, 2024
Peer Review History: PLOS recognizes the benefits of transparency in the peer review process; therefore, we enable the publication of all of the content of peer review and author responses alongside final, published articles. The editorial history of this article is available here: https://doi.org/10.1371/journal.pone.0303231</p>
<p>Copyright: © 2024 Gill et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</p>
<p>Data Availability Statement: The GIX framework code, pseudocode, datasets, extracted relations, models, and relevant data used in this study are available on GitHub at https://github.com/ JaskaranKaurGill1/Gene-Interaction-Extraction.</p>
<h2>Abstract</h2>
<p>Extracting biological interactions from published literature helps us understand complex biological systems, accelerate research, and support decision-making in drug or treatment development. Despite efforts to automate the extraction of biological relations using text mining tools and machine learning pipelines, manual curation continues to serve as the gold standard. However, the rapidly increasing volume of literature pertaining to biological relations poses challenges in its manual curation and refinement. These challenges are further compounded because only a small fraction of the published literature is relevant to biological relation extraction, and the embedded sentences of relevant sections have complex structures, which can lead to incorrect inference of relationships. To overcome these challenges, we propose GIX, an automated and robust Gene Interaction Extraction framework, based on pre-trained Large Language models fine-tuned through extensive evaluations on various gene/protein interaction corpora including LLL and RegulonDB. GIX identifies relevant publications with minimal keywords, optimises sentence selection to reduce computational overhead, simplifies sentence structure while preserving meaning, and provides a confidence factor indicating the reliability of extracted relations. GIX's Stage-2 relation extraction method performed well on benchmark protein/gene interaction datasets, assessed using 10-fold cross-validation, surpassing state-of-the-art approaches. We demonstrated that the proposed method, although fully automated, performs as well as manual relation extraction, with enhanced robustness. We also observed GIX's capability to augment existing datasets with new sentences, incorporating newly discovered biological terms and processes. Further, we demonstrated GIX's real-world applicability in inferring E. coli gene circuits.</p>
<h2>Introduction and motivation</h2>
<p>The scientific literature holds significant biological insights about issues such as disease-causing mutations, health intervention methods, genome analysis, and potential drug targets. In this research, we focused on the inference of transcriptional regulatory behaviour by identifying genome-wide relationships among macromolecular entities such as genes, proteins, and RNAs [1]. The identification of such relations is relevant in developing accurate computational</p>
<p>Funding: The author(s) received no specific funding for this work.</p>
<p>Competing interests: The authors have declared that no competing interests exist.
models of genetic networks, providing insights into disease progression, intracellular functions, and drug behaviour.</p>
<p>The automated acquisition of prior knowledge from unstructured text is crucial but challenging, given the exponential growth in the published literature due to recent technological advancements in scientific research [2]. Medline (PubMed) reported a doubling of indexed articles on Gene Regulatory Networks in the last decade, reflecting increased interest in understanding genomic interactions at a cellular level, both experimentally and computationally [3]. Despite the huge number of papers available, only those with experimentally observed transcriptional links are relevant to the extraction of relationships among biological entities. Further, only sections containing key sentences can be used for identifying biological interactions. These sentences reference multiple biological entities, and have complex structures comprising several clauses and technical terminology [4]. Biological experiments are susceptible to errors during data collection, demanding substantial efforts to establish the relevance and authenticity of extracted regulations. Thus, most structured databases such as TRANSFAC [5] and RegulonDB [6], rely on human experts to pre-process scientific papers, extract domain-related relations, and authenticate the information [7].</p>
<p>Manually curating genomic repositories and annotating genetic relationships from literature is time-consuming and challenging [8]. Traditional reading and summarising lack scalability, are subject to personal interpretations, and are time-consuming. Automating the preprocessing of scientific literature and post-processing of extracted information using Natural Language Processing (NLP) techniques can address these limitations. Several researchers have studied automating pre-processing and post-processing for accurately extracting relations from unstructured data. Most pre-processing techniques involve the extraction of all available abstracts within a specific timeline from online resources such as PubMed [9-11]. However, these steps, while effective in domains with simple concepts and interactions, prove inefficient in the complex biological domain, with entity relations specific to organisms, cell function, or disease conditions.</p>
<p>In the relation extraction (RE) stage following pre-processing, statistical methods aim to capture entity relationships through feature extraction [1]. Approaches such as sentence simplification [12], link grammar parsing [13], and a combination of vector and tree-based kernels [14] enhance protein-protein interaction (PPI) relation extraction in simpler sentences. However, these methods face limitations in handling complex biological sentences, and simplification can lead to overfitting and information loss. These methods heavily depend on tools like MedPost (a POS tagger) or existing biological knowledge bases. Fundel et al. [15] reported that most of the false interactions predicted by RelEx, a rule-based parse tree NLP technique, are due to incorrectly tagged entities, POS-label error, or insufficient rule-based sentence construction. Recently introduced pre-trained neural network models provide substantial benefits when capturing both syntactic and semantic information, surpassing the capabilities of machine learning methods and word embedding techniques [16-18]. Despite the specific biomedical training of BioBERT (a pre-trained Bert-based model), its improvement in relation extraction tasks is marginal [19]. The complex sentence structure describing causal dependency still limits the applicability of RE techniques. Despite rigorous pre-processing and RE, inferred interactions may still contain noisy entities, inaccurate predictions, and conditional relations. A post-processing step such as unsupervised clustering [20] and confidence level calculation [21], if integrated with prior knowledge and model prediction confidence, can further refine results by eliminating falsely predicted named entities and relations.</p>
<p>Researchers have tackled different stages of relation extraction from the literature, including pre-processing, post-processing, and relation extraction itself. However, there is no overarching framework that comprehensively addresses all aspects of biological relation extraction.</p>
<p>While specific tools and technologies may evolve or change over time, a well-designed framework offers a stable underlying structure, methodology, or approach. To this end, we propose systematic, automated and robust Gene Interaction Extraction (GIX), that efficiently identifies relevant publications with minimal keywords, optimises sentence selection, and provides a confidence factor for the reliability of extracted biological relations. GIX is a novel three-stage framework for Gene Interaction Extraction, involving: (i) Pre-processing; (ii) Relation extraction; and (iii) Post-processing. Leveraging the fine-tuned pre-trained domain-specific NLP models, GIX is designed to optimally extract regulatory links among genes/proteins in a set of abstracts from PubMed. It automates all of the processes required for biological RE, and eliminates the manual intervention required to gather and transform problem-specific data into an acceptable RE format. The pre-processing phase involves an abstract search for target-network information, selecting sentences on transcriptional regulation to eliminate irrelevant text, reduce computational overload, and improve accuracy. In the Relation Extraction stage, we harness the biological contextual understanding of BioBERT and BERN2 (a pre-trained Bertbased Bio-named entity recognition model). Additionally, an entity-labelling schema is proposed to enhance the accuracy of relation prediction. This schema works by reducing sentence complexity without compromising grammatical structure, avoiding information loss. In postprocessing, BERN2 and tailored NLP techniques refine extracted biological relational entity names, incorporating a novel confidence measure to authenticate regulations and sources and improve accuracy by eliminating false positives.</p>
<p>Several experiments were performed using datasets including BioInfer [22], HPRD50 [15], IEPA [23], and LLL [24]. The proposed RE model (Stage-2 of the framework) achieved a significant improvement of $13.7 \%$ in F-Score for HPRD50 compared to the previous best-performing method. GIX, achieved superior performance in RE from dataset LLL and database RegulonDB. In experiments with LLL, our results showed that our GIX framework not only achieved optimum accuracy but also reported multiple relation dictating sentences per regulation, as opposed to the single-sentence per relation manner common in benchmark datasets.</p>
<p>The structure of the paper is as follows: an overview of the relevant preliminaries is provided in the "Background" section. The "Methods" section details the processes and models used in our three-staged GIX framework. In the "Results" section, we cover the experimental setup of benchmark datasets, present their respective results, and discuss the outcomes. Lastly, the "Conclusion" section concludes the paper and explores future directions.</p>
<h1>Background</h1>
<h2>Unstructured text and relation extraction</h2>
<p>Structured data, such as tables and databases, have a consistent layout and predictable pattern. In contrast, unstructured data such as written and spoken text lacks a predefined structure, making it difficult to process [25]. These data can consist of diverse languages, and contain grammatical errors, abbreviations, and context-dependent meanings. It is difficult to retrieve only relevant data, because of the size of datasets, the diversity of publications, and the rapid evolution of multidisciplinary fields. Efforts to standardise vocabulary in biomedical literature, such as MeSH, help tackle unstructured data by assigning terms, aiding in information retrieval and relation extraction, thereby enhancing biomedical research. RE is more challenging than named entity recognition or classification, due to the lack of explicit markers for relationships and the complex contextual dependencies between entities, which make it hard to accurately identify and extract the underlying relationships from unstructured text. RE tasks can be classified into one of two categories: (1) rule-based methods which identify pre-defined patterns; and (2) machine-learning (ML) models which treat RE as a classification problem</p>
<p>[26]. ML based RE approaches have been further classified into kernel-based, feature-based, and deep learning (DL) categories. Various ML methods have been used to extract regulations among genes and gene products However, building and training RE models is a complex and time-consuming task, as the models need to be trained using a large dataset. Advanced NLP techniques, including text mining, RE, and named entity recognition, have proved very effective in extracting meaningful information from complex and variable unstructured text [27].</p>
<h1>Pre-trained large language models</h1>
<p>In recent years, pre-trained models based on NLP techniques have been shown to work effectively with unstructured text, and have been used in a range of applications. Being pre-trained on large data, they require little or no training. Well known large language models (LLM) such as Embeddings from Language Models (ELMO) [28] and Bidirectional Encoder Representations from Transformers (BERT) [29] are pre-trained on massive amounts of text data, allowing them to learn rich linguistic patterns and semantics. ELMO introduced contextual word embeddings, in which each word representation is dynamically generated based on the surrounding context. BERT is a transformer-based model that learns bidirectional contextual representations of words. Both ELMO and BERT models have demonstrated excellent performance across various NLP tasks, including named entity recognition, part-of-speech tagging, sentiment analysis, and RE [30-33]. However, BERT has been shown to surpass ELMO in performance, as it learns bidirectional contextual representations, enabling a deeper understanding of semantic relationships [34]. The domain-specific LLMs perform RE by capturing specific knowledge, thus improving accuracy. BioBERT, the BERT model optimized for biomedical text mining, is domain-specific, and is pre-trained on PubMed abstracts and PMC articles [19]. BioBERT can easily be fine-tuned to perform text extraction tasks, and has been successfully applied to tasks such as the allocation of phenotypes to protein-protein interactions and the extraction of drug-drug interactions [35,36]. It has outperformed other state-of-the-art NLP-based RE methods in the biological domain [19].</p>
<h2>Named entity recognition</h2>
<p>Named entity recognition (NER) and biological NER (BioNER), identifies biological entities such as genes, proteins, diseases, drugs, and miRNAs [37]. BioNER methods fall into one of three categories: (1) knowledge-based; (2) rule-based; or (3) machine learning [38]. A knowl-edge-based approach uses an existing database or dictionary to identify known entities. Such methods are simple to implement, but limit NER tagging to known entities [39]. The rulebased approach tends to overfit and fails to generalise, and thus is ineffective when applied to all cases. State-of-the-art machine learning techniques use POS tags and apply grammatical structure and interdependencies within a text to conveniently identify the named entities. Gene and protein names have been labelled using a combination of conditional random fields (CRF) and bidirectional long short-term memory (LSTM) architecture [40]. ML models such as Support Vector Machines (SVMs) and hidden Markov models have been used for BioNER. Although ML techniques perform better than other traditional methods, they require a large amount of manually annotated training data [38]. Pre-trained language models such as BioBERT can be fine-tuned to easily perform BioNER without needing a large amount of training data. BERN2, a BioNER tool reported in 2022, not only supports NER, but also allows named entity normalization (NEN). NEN allows mapping recognised named entities to a common or canonical form ensuring uniform representation of named entities. BERN2 has outperformed existing BioNER tools, including BERN, on several applications, including the identification of diseases, drugs, species, genes, and proteins.</p>
<h1>Datasets</h1>
<p>Some of the comprehensive repositories of curated protein and genetic interactions collected from the scientific literature are BioInfer [22], HPRD50 [15], IEPA [23], and LLL [24]. These resources are commonly used as benchmark datasets with which to study RE [15,41,42]. BioInfer contains a total of 9,666 full dependency annotations of gene, protein, and RNA regulations from 1,100 sentences. HPRD50 includes 50 abstracts from Human Protein Reference Database (HPRD) for direct regulation relation annotation. IEPA, is an Interaction Extraction Performance Assessment of 300 abstracts using two named biochemical entities. LLL, the Learning Language in Logic challenge, contains 330 gene/protein interactions labelled as regulatory from 77 unique sentences. Processing these datasets for RE requires a combination of advanced NLP techniques, domain knowledge, and careful pre-processing to handle the wide range of interaction types, varying sentence structures, and the need to disambiguate entities and their relationships.</p>
<p>RegulonDB is a manually annotated, publicly available database containing transcriptional regulations in Escherichia coli, also known as E. coli [6]. The database contains transcription factor (TF) regulations including TF-gene, TF- transcriptional unit, TF-operon, and TF-TF. Each regulation is classified as weak or strong based on the type of experiment used to identify the interaction. For instance, a ChIP analysis with statistical validation is considered to provide stronger evidence than ChIP-chip only or ChIP-sequence analysis.</p>
<h2>Methods</h2>
<p>This section addresses the improvement of the prediction accuracy of genetic interactions using the published literature. We propose an automated framework involving two Large Language Models (LLM)—BioBERT and BERN2—which are pre-trained on a large corpus of biological data. The overall architecture of the proposed LLM based framework is presented in Fig 1. The framework has three stages: (i) Stage-1: Pre-processing; (ii) Stage-2: Relation extraction; and (iii) Stage-3: Post-processing. The pre-processing and post-processing stages in GIX play a crucial role in addressing the inherent imbalance in biological datasets. In a sentence with 2 entities, the number of potential relationships, taking direction into consideration is</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Fig 1. Schematic of fully automated relation extraction using an LLM based GIX framework. The white blocks signify the processes, and the grey blocks indicate the tools utilised within those processes.
https://doi.org/10.1371/journal.pone.0303231.g001</p>
<p>two. As the number of entities in a sentence increase, the possible relationships amongst them can grow exponentially. However, the number of true relationships does not grow at a similar pace, thereby, leading to a situation when the number of non-interactions far exceed the number of interactions and resulting to imbalance dataset. The pre-processing (Stage-1) and postprocessing stages (Stage-2) in GIX are designed to recognise non-relation entity pairs, to decrease the number of sentences classified as true negatives. This reduces the gap between the two classes, which contributes to the imbalance, thereby enhancing the overall performance and accuracy of relation extraction. We begin with the explanation for each component of Stage-1.</p>
<h1>Pre-processing</h1>
<p>In Stage-1, we pre-process the input publications to extract only highly relevant text. This task is challenging because genomic transcriptional regulations can differ between organisms, and molecular entities may behave differently under different cell conditions. We formulated a search criterion which ensured the extracted literature's association to the specified conditional parameters. Known attributes of the target network, such as the organism and cell function, were included to in narrow down the search to closely related literature. As published papers often include a keywords section that helps indexers, these were also used to establish relevance. Multi-cellular organisms may exhibit different regulatory relations under different cell conditions; thus, the use of additional criteria can significantly improve the quality of obtained literature, thereby improving the accuracy and relevancy of extracted relations. The chosen set of keywords used for this study is outlined in the experiment section under "Selection of Keywords."</p>
<p>The Bio.Entrez module facilitates data retrieval from PubMed, a comprehensive biomedical literature database [43]. To find relevant PubMed articles, we crafted a search query using PubMed Bio.Entrez utilities. The PubMed search query requires a set of keywords and specifies the maximum number of documents to retrieve, resulting in a list of PubMed IDs ranked by relevance according to the provided keywords. With the retrieved PubMed IDs, we used the web scraping tool BeautifulSoup [44], a Python library, to extract titles and abstracts from the papers on PubMed. The set of abstracts obtained using the selected keywords is further processed to eliminate those papers which do not contain a reference to the organism, either in its full form, or as abbreviations.</p>
<p>Sentence tokenization. We split the final set of abstracts into individual sentences using Punkt sentence tokenizer from the Natural Language Toolkit (NLTK) [45]. Punkt is a pretrained unsupervised machine learning model designed for detecting sentence boundaries. Then the tokenized sentences undergo two consecutive sentence elimination processes: the first utilises a fine-tuned BioBERT (biobert_v1.1_pubmed) classification model, and the second involves BERN2, as detailed in the subsequent sections.</p>
<p>Sentence eliminator 1. Sentence eliminator 1 identifies and removes sentences that do not discuss a regulatory interaction. A fine-tuning dataset was created from annotated PPI corpus sentences. The specific datasets used for fine-tuning and testing in each experiment are outlined in the results sections. To create the fine-tuning dataset, sentences dictating at least one regulatory relationship receive a positive classification label, while the rest are labelled as negative. Once finetuned, the BioBERT model evaluates test sentences, assigning a classification of 0 if there are no genetic interactions or if the sentence discusses non-regulation, and 1 if the sentence contains a relational context of a gene/protein interaction. Sentences classified as 0 are eliminated, while those classified as 1 undergo further evaluation for the presence of named entities.</p>
<p>Sentence eliminator 2. For the second sentence elimination step, since at least two entities are involved in a regulatory relationship, all sentences that contain fewer than two gene or protein entities are excluded. This elimination is carried out using BERN2, without any additional fine-tuning, to recognise gene and protein entities in a sentence. BERN2 can be implemented through their RESTFUL API [46]. For each sentence, BERN2 produces a JSON list of annotations, containing the entity phrase, its entity type, and a probability score. Sentences are eliminated if the annotation list contains fewer than two gene/protein entities.</p>
<h1>Relation extraction</h1>
<p>In Stage-2 of GIX, we used BERN2 for NER and fine-tuned BioBERT for relation classification. Through fine-tuning on expert-annotated data, pre-trained models efficiently transfer general language knowledge to domain-specific tasks, resulting in improved task performance and adaptability. In this work, our goal was to extract binary relations according to their suitability for comparison, interpretability, and scalability. To extract binary relations, each entity pair in a sentence is substituted with a label to clearly identify both the agent and target entities involved in the relationship. Sentence eliminator-2, filters out sentences with fewer than two gene/protein entities, so the sentences undergoing processing for relation classification invariably contain a minimum of two gene/protein entities, irrespective of the presence or absence of an actual relationship. The labelling criteria remain consistent for all sentences before relation extraction. To extract binary relations, each entity pair in a sentence is substituted with a label to clearly identify both the agent and target entities involved in the relationship. The first entity of a pair is replaced with \$GENE_AGENT# and the latter is substituted with \$GENE_TARGET#. The selected entity labels are descriptive, unique, and ensure consistency. Despite the advantages of selected labels, the structural complexity and presence of multiple entities in biological sentences can hinder the sequence classifier model's ability to recognize the labeled entities. To address this issue, any entity in a sentence other than the current pair is replaced with the word "BLANK", so that the model can easily identify the pair in consideration during classification. For example, in Fig 2, three genes-SigK, GerE, and $y k v P$-appear in the sentence, and for the gene pair Sigk (\$GENE_AGENT#) and $y k v P$ (\$GENE_TARGET#) the remaining third gene is labelled BLANK. BioBERT, pre-trained on biomedical data, has a contextual understanding of complex biological terms and is able to manage this style of labelling. While the selected labelling tags (\$GENE_TARGET#, \$GENE_AGENT#) in complex sentences may not effectively highlight the target of the classification task and thereby limit model performance, anonymizing the entities additional to the tagged pair using "BLANK" effectively suppresses the unwanted entity without altering the lexical and semantical structure of the sentence.</p>
<p>The output of the RE process is a set of entity pairs from BioBERT, with classification prediction values varying between 0 and 1 .</p>
<h2>Post-processing</h2>
<p>The extracted relations may still contain wrongly predicted interactions or entities, due to the biological complexity of the relationships. We cannot assume that all stated relations in</p>
<p>Original sentence: Both SigK and GerE were essential for ykvP expression
Tagged sentence: Both \$GENE_AGENT# and BLANK were essential for \$GENE_TARGET# expression</p>
<p>Fig 2. Illustration of NER tagging in sentences with multiple gene or gene products.
https://doi.org/10.1371/journal.pone.0303231.g002</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Entity names <br> extracted by <br> GIX (stage-2)</th>
<th style="text-align: left;">Removing additional <br> description words in entity <br> names such as protein, <br> gene, and regulator</th>
<th style="text-align: left;">Identifying <br> precise entity <br> names using <br> BERN2</th>
<th style="text-align: left;">Identifying <br> gene/protein names <br> missed by BERN2</th>
<th style="text-align: left;">Refined entity <br> names</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>Fig 3. Entity name refinement.
https://doi.org/10.1371/journal.pone.0303231.g003
published text are necessarily correct. Positive results are more likely to be published than negative or inconclusive results. This bias can lead to an overrepresentation of certain findings, which can skew the domain knowledge. Studies with small sample sizes, which are not representative of a larger population, may contain results that are unreliable or not generalizable. Additionally, even though our entity labelling schema aims to identify the controlling (\$GENE_AGENT#) and child (\$GENE_TARGET#) entities in a relationship, not all sentences clearly indicate the direction of the interaction. In such cases, information about known controlling entities, such as regulatory genes or transcriptional factors, in the target network can help identify the direction of the relation. In the post-processing stage, we therefore evaluate the trueness of each extracted relation based on several factors, including whether the relation was extracted from multiple documents, its existence in online repositories, and whether it involves a known regulator.</p>
<p>Refinement. The entire three-step refinement process is illustrated in Fig 3.
Before establishing well-known true regulations, the extracted relational entity names are refined. During NER, BERN2 may recognize a group of words or phrases as the named entity. For instance, consider the following sentence:
"The Dnak suppressor protein interacts with molecular chaperones to assist in protein folding and prevent misfolding or aggregation."</p>
<p>The phrase "Dnak suppressor protein" is identified as a gene/protein entity by BERN2, helping to reduce the structural complexity of the sentence. However, we need to extract only the entity name "Dnak" to successfully group regulations extracted from different research papers. To extract just the entity name, we split the phrases and process the individual words for NER using BERN2 (Fig 4). As depicted in example (ii) in Fig 4, the BERN2 tagged entity may not contain the entity name at all. Such entity relations are incomplete, and thus should be eliminated. For larger datasets, the use of BERN2 to process each word in an entity name can become computationally expensive. To address this issue, we created a list of the most repetitive non-entity words (available on the Gene-Interaction-Extraction GitHub repository
<img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Fig 4. Gene name refinement using BERN2.
https://doi.org/10.1371/journal.pone.0303231.g004</p>
<p>https://github.com/JaskaranKaurGill1/Gene-Interaction-Extraction) reflecting which nonentity words are most frequently removed before passing on to BERN2.</p>
<p>If BERN2 is unable to recognise the gene/protein name from a phrase without the adjoining words, the refined entities which return null names are checked to detect any missing genes or proteins. Most gene/protein names consist of letters, numbers, and symbols that may not conform to typical English language words, leading the spellchecker to flag them as potentially misspelled. Thus, the checking is done by using the word spell check tool from Textblob [47] to label individual words in entity names and identify incorrectly spelled words. If a word in an entity is incorrectly spelt, it is considered to be a protein or gene name, whereas if it is correctly spelt, it is assumed to be descriptive. The output of the refinement process is a set of entity-pairs composed only of gene or protein names.</p>
<p>Confidence factor. We developed a new measure, the Confidence Factor $C F_{e_{a} e_{t}}$, to indicate the likelihood of existence of each of the interactions identified as existing between the agent/controller entity $e_{a}$ and the target entity $e_{t}$. For each entity pair $e_{a} e_{t}$, its corresponding $C F_{e_{a} e_{t}}$ is computed as follows.</p>
<p>$$
\begin{gathered}
C F_{e_{a} e_{t}}=\sum_{s=1}^{n} v_{s}+K \sum_{T=1}^{M} P_{e_{a} e_{t}}^{T} \
=C F_{1}+K * C F_{2} \
P_{e_{a} e_{t}}=\left{\begin{array}{l}
1, e_{a} \text { is known agent but relation } e_{a} e_{t} \text { is unknown } \
3, e_{a} e_{t} \text { is known relation } \
0, \text { otherwise }
\end{array}\right.
\end{gathered}
$$</p>
<p>Here, the variable $n$ denotes the total number of unique sentences obtained from GIX predicting $e_{a} e_{t}$, i.e. the regulation between $e_{a}$ and $e_{t}$. The variable $v_{s}$ is the RE classifier prediction of regulation $e_{a} e_{t}$, of the $s^{\text {th }}$ sentence. It is obtained as the Stage-2 output of the GIX and has a value between 0 and 1 . The parameter $P_{e_{a} e_{t}}$ represents the prior knowledge about both the agent entity $\left(e_{a}\right)$ and its interaction $\left(e_{a} e_{t}\right)$ with the target entity $e_{t}$. The constant $M$ is the total number of curated databases under consideration. $K$ is a factor balancing the influence of terms $\sum_{s=1}^{n} v_{s}$ and $\sum_{T=1}^{M} P_{e_{a} e_{t}}^{T}$ (also referred to as $C F_{1}$ and $C F_{2}$ ). As shown in Fig 5, the discrete variable $P_{e_{a} e_{t}}$ of Eq 2 can acquire three different values for three different conditions, namely, (i) If $e_{a}$ is known to be a controller gene and the relation $e_{a} e_{t}$ is unknown, $P_{e_{a} e_{t}}=1$; (ii) If $e_{a} e_{t}$ is a known relation, the value of $P_{e_{a} e_{t}}$ is given a higher value of 3 compared to (i) accounting for the presence of two entities and a connecting arc; (iii) For other conditions, $P_{e_{a} e_{t}}=0$.
<img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Fig 5. Role of prior knowledge component $\mathrm{CF}<em 1="1">{2}$ with respect to $\mathrm{CF}</em>$ is a known relation. https://doi.org/10.1371/journal.pone.0303231.g005}$ on overall confidence factor $C F_{e_{a} e_{t}}$. (i) No prior knowledge is available (ii) $e_{a}$ is a known controlling entity but $e_{a} e_{t}$ is an unknown relation (iii) $e_{a} e_{t</p>
<p>A specific regulation can appear multiple times in each sentence. For example, in the sentence
"The study found that the upregulation of TrpE was associated with an increased expression of trpR in the cell line, and this TrpE-dependent trpR expression initiates the enzyme activity."</p>
<p>The relation between $\operatorname{TrpE}$ and $\operatorname{trpR}$ appears twice with two different values of $v_{s}$. In such situations, the average value of $v_{s}$ is considered. Previously curated annotations of a genetic interaction can also be used to validate the correctness of the GIX's extracted relation. The manually curated databases cite multiple published papers reporting genomic interactions. For instance, RegulonDB confirms the transcriptional interaction between TF CRP-cyclic-AMP and its target genes deoC, deoA, deoB, and deoD, from 16 sources. Similarly, interactions confirmed from a higher number of experimental and/or analytical sources will have a higher $C F_{v_{s} v_{s}}$ and thus, are more likely to be true. A threshold value $\left(C F_{v_{s} v_{s}}=\gamma\right)$ is defined, and all regulations with $C F_{v_{s} v_{s}}&lt;\gamma$ are treated as false positive. The final output of the framework will be a set of highly confident extracted entity pairs and their corresponding $C F_{v_{s} v_{s}}$ values, representing the accuracy of the retrieved relationships.</p>
<h1>Results</h1>
<p>We first describe the experimental setup, including the hyperparameter configuration and evaluation metrics used. Subsequently, we discuss the selection of keywords for the extraction of relevant information from the target-related literature. We conducted three independent experiments to assess the effectiveness of GIX. The first experiment (Exp1) demonstrated the Relation Extraction Capability (Stage-2) of the GIX framework using four well-known benchmark datasets for gene/protein interactions. The second experiment (Exp2) evaluated automated extraction using GIX against the manual curation of a benchmark dataset. The third experiment (Exp3) evaluated GIX against the manual curation of a real-world database of transcriptional regulations. Finally, as a demonstration of the significance of GIX-extracted relations with their confidence factors, we used the relations for constructing gene regulatory networks.</p>
<h2>Experimental setup</h2>
<p>We implemented our models using PyTorch transformers: an open-source library for machine and deep learning models [48]. The framework was written in Python 3.10.11 in Google Colab Pro. The hyper-parameters setup for the BioBERT model is given in Table 1. We trained our model on Google Colab using a GPU (Tesla P100-PCIE-16GB) with a BertAdam optimizer.</p>
<p>Table 1. Hyperparameters used for the RE classification model.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Hyper-parameters</th>
<th style="text-align: left;">Value</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Model</td>
<td style="text-align: left;">biobert_v1.1_pubmed</td>
</tr>
<tr>
<td style="text-align: center;">Token max length</td>
<td style="text-align: left;">256/ 512 depending on the average length of sentences of the dataset</td>
</tr>
<tr>
<td style="text-align: center;">Optimizer</td>
<td style="text-align: left;">BertAdam</td>
</tr>
<tr>
<td style="text-align: center;">Batch Size</td>
<td style="text-align: left;">8</td>
</tr>
<tr>
<td style="text-align: center;">Number of epochs</td>
<td style="text-align: left;">$10 / 20$ depending on the dataset size.</td>
</tr>
<tr>
<td style="text-align: center;">Learning rate (BertAdam)</td>
<td style="text-align: left;">$2 e-5$</td>
</tr>
<tr>
<td style="text-align: center;">Warmup (BertAdam)</td>
<td style="text-align: left;">0.1</td>
</tr>
<tr>
<td style="text-align: center;">Learning rate decay (Weight decay rate)</td>
<td style="text-align: left;">0.01</td>
</tr>
</tbody>
</table>
<p>https://doi.org/10.1371/journal.pone.0303231.t001</p>
<p>To assess the model performance, the metrics Recall (R), Precision (P), and F-score (F) were evaluated. Recall and Precision provide complementary insights into the performance of a model. Recall measures the proportion of relevant instances correctly identified, while Precision represents the accuracy of the model's positive predictions. The F-score provides a balanced assessment of a model's performance by considering both Precision and Recall, offering a single metric with which to evaluate classification accuracy.</p>
<h1>Selection of keywords</h1>
<p>The choice of the correct set of keywords is crucial to GIX performance in target-related literature search. Our choice was based on predefining certain attributes of the required output. These attributes specify the type of relation being extracted, determining whether they pertain to a particular organism or a specific cell function. Incorporating these attributes makes the keyword selection process effective in focusing our search on finding literature directly related to specific aspects of the target network. We identified frequently used keywords in published papers related to genetic entity regulation and interaction. Fig 6 depicts the 20 most repeated keywords among papers used by RegulonDB for the manual extraction of the transcriptional relations of Escherichia coli. The name of the organism embodying the regulatory system is the most repeated keyword, and is thus included as one of the preferred keywords. Other important words-"gene regulation", "gene expression", "transcriptome", "transcription factor", "regulation", and "posttranscriptional regulation"-which are repeated frequently are also included as search terms. Thus, the selected set of keywords for this research is the combination of the common words "gene regulation gene expression transcriptional" and the name of the target organism.</p>
<h2>Exp1- Relation extraction capability (Stage-2) of the GIX framework</h2>
<p>The performance of our RE with its improved entity-labelling schema (Stage-2 of the GIX framework, referred as GIX RE) was investigated using four well-known benchmark gene/protein interaction datasets: BioInfer, HPRD50, IEPA, and LLL. The distribution of positively and negatively annotated sentences for these four datasets is given in Table 2.
<img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Fig 6. Top 20 most repeated keywords included in papers referenced by RegulonDB for TF-binding sites.
https://doi.org/10.1371/journal.pone.0303231.g006</p>
<p>Table 2. Distribution of positive and negative classifications in five benchmark PPI corpora.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Dataset</th>
<th style="text-align: right;">Positive</th>
<th style="text-align: right;">Negative</th>
<th style="text-align: right;">Unique Sentences</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">BioInfer</td>
<td style="text-align: right;">2534</td>
<td style="text-align: right;">7132</td>
<td style="text-align: right;">1100</td>
</tr>
<tr>
<td style="text-align: left;">IEPA</td>
<td style="text-align: right;">335</td>
<td style="text-align: right;">482</td>
<td style="text-align: right;">486</td>
</tr>
<tr>
<td style="text-align: left;">HPRD50</td>
<td style="text-align: right;">163</td>
<td style="text-align: right;">270</td>
<td style="text-align: right;">145</td>
</tr>
<tr>
<td style="text-align: left;">LLL</td>
<td style="text-align: right;">164</td>
<td style="text-align: right;">166</td>
<td style="text-align: right;">77</td>
</tr>
</tbody>
</table>
<p>https://doi.org/10.1371/journal.pone.0303231.t002
To evaluate a model's performance and generalisation ability, we employed the widely used 10 -fold cross validation provided by the KFold library from Scikit-Learn [49] to each of the four datasets (HPRD50, BioInfer, IEPA and LLL). In brief, the method involves dividing the dataset into 10 equal subsets, with 9 subsets used for fine-tuning and the isolated $10^{\text {th }}$ subset used for testing. For each dataset, the process is repeated 10 times using a different fold as the test set, and each time, the relation classification model gets fine-tuned from scratch (original setting). The overall accuracy is determined by averaging the results from the 10 individual experiments (folds) conducted on each dataset (shown in Fig 7). This ensures comprehensive evaluation across diverse data samples, contributing to the model's robustness and generalisability. This approach has been commonly used in several state-of-the-art methods in different domains including Biological relation extraction,e.g. Bi-LSTM [50], MCCNN [51], GK [52], NHGK [53], EDG ([54], PIPE [42], WWSK [55], RCNN [56], DNN [57], RNN + CNN [56] and iLSTM+tAttn [41]. We used a token length of 256 for BioInfer, HPRD50, IEPA, and LLL. The smaller datasets, HPRD50, IEPA, and LLL, required 20 epochs for fine-tuning, whereas the larger dataset, BioInfer, achieved stability in just 10 epochs. The performance of the proposed RE with the improved entity-labelling schema (Stage 2 of GIX), compared with other state-of-the-art methods, is given in Table 3.</p>
<p>GIX outperformed all RE methods/models in Precision, Recall, and F-score for all four datasets: BioInfer, HPRD50, IEPA, and LLL. GIX produced a significant improvement of $12 \%$ in Precision on HPRD50 compared to the previous best model. BioBERT's improved performance in biological RE compared to traditional models like CNN and LSTM can be attributed to its pre-training on biological text, capturing contextual word representations, and transfer learning capabilities. The combination of BERN2's ability for normalization of named entities, along with the proposed anonymization of entities reduces sentence complexity without altering the lexical structure, and thus contributes to enhancing the model's accuracy of prediction. The robustness of the superior performance of GIX was further confirmed by its consistent performance across all four datasets.
<img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Fig 7. The 10 -fold cross-validation process for evaluating the relation extraction capability (Stage-2) of the GIX. Here, each iteration consists of equally divided 10 folds of the dataset, where 9 folds (white blocks) are used for fine-tuning, and the 10th fold (grey block) is used for testing. The overall performance $(\Theta)$ is obtained by averaging the performance of each iteration $(\Theta i)$. The notations $P, R$ and $F$ represent Precision, Recall, and F-score.
https://doi.org/10.1371/journal.pone.0303231.g007</p>
<p>Table 3. Ten-fold cross-validation results (\%) P: Precision; R: Recall; F: F-score.</p>
<table>
<thead>
<tr>
<th>Methods</th>
<th>BioInfer</th>
<th></th>
<th></th>
<th>HPRD50</th>
<th></th>
<th></th>
<th>IEPA</th>
<th></th>
<th></th>
<th>LLL</th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>P</td>
<td>R</td>
<td>F</td>
<td>P</td>
<td>R</td>
<td>F</td>
<td>P</td>
<td>R</td>
<td>F</td>
<td>P</td>
<td>R</td>
<td>F</td>
</tr>
<tr>
<td>DNN [57]</td>
<td>53.9</td>
<td>72.9</td>
<td>61.6</td>
<td>58.7</td>
<td>92.4</td>
<td>71.3</td>
<td>71.8</td>
<td>79.4</td>
<td>74.2</td>
<td>76.0</td>
<td>91.0</td>
<td>81.4</td>
</tr>
<tr>
<td>Bi-LSTM [50]</td>
<td>87.0</td>
<td>87.4</td>
<td>87.2</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>RNN + CNN [58]</td>
<td>56.7</td>
<td>67.3</td>
<td>61.3</td>
<td>69.6</td>
<td>82.7</td>
<td>75.1</td>
<td>64.3</td>
<td>65.8</td>
<td>63.4</td>
<td>72.5</td>
<td>87.2</td>
<td>76.5</td>
</tr>
<tr>
<td>MCCNN [51]</td>
<td>81.3</td>
<td>78.1</td>
<td>79.6</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>GK [52]</td>
<td>56.7</td>
<td>67.2</td>
<td>61.3</td>
<td>69.6</td>
<td>82.7</td>
<td>75.1</td>
<td>64.3</td>
<td>65.8</td>
<td>63.4</td>
<td>72.5</td>
<td>87.2</td>
<td>76.5</td>
</tr>
<tr>
<td>CK [59]</td>
<td>65.7</td>
<td>71.1</td>
<td>68.1</td>
<td>67.5</td>
<td>78.6</td>
<td>71.7</td>
<td>68.5</td>
<td>76.1</td>
<td>70.9</td>
<td>77.6</td>
<td>86</td>
<td>80.1</td>
</tr>
<tr>
<td>NHGK [53]</td>
<td>59.3</td>
<td>68.1</td>
<td>63.4</td>
<td>72.4</td>
<td>79.8</td>
<td>75.3</td>
<td>67.8</td>
<td>85.3</td>
<td>74.6</td>
<td>86.2</td>
<td>92.1</td>
<td>89.1</td>
</tr>
<tr>
<td>EDG [54]</td>
<td>57.6</td>
<td>59.9</td>
<td>58.7</td>
<td>69.9</td>
<td>76.2</td>
<td>72.9</td>
<td>76.7</td>
<td>83.3</td>
<td>79.9</td>
<td>92.1</td>
<td>78.2</td>
<td>84.6</td>
</tr>
<tr>
<td>PIPE [42]</td>
<td>68.6</td>
<td>70.3</td>
<td>69.4</td>
<td>62.5</td>
<td>83.3</td>
<td>71.4</td>
<td>63.8</td>
<td>81.2</td>
<td>71.5</td>
<td>73.2</td>
<td>89.6</td>
<td>80.6</td>
</tr>
<tr>
<td>WWSK [55]</td>
<td>61.8</td>
<td>54.2</td>
<td>57.6</td>
<td>66.7</td>
<td>69.2</td>
<td>67.8</td>
<td>73.7</td>
<td>71.8</td>
<td>72.9</td>
<td>76.9</td>
<td>91.2</td>
<td>82.4</td>
</tr>
<tr>
<td>iLSTM+tAttn [41]</td>
<td>88.9</td>
<td>89.3</td>
<td>89.1</td>
<td>78.6</td>
<td>78.7</td>
<td>78.5</td>
<td>81.7</td>
<td>82.3</td>
<td>81.3</td>
<td>84.8</td>
<td>84.3</td>
<td>84.2</td>
</tr>
<tr>
<td>RCNN [56]</td>
<td>87.4</td>
<td>86.5</td>
<td>86.9</td>
<td>74.9</td>
<td>82.8</td>
<td>77.7</td>
<td>71.6</td>
<td>80.6</td>
<td>75.5</td>
<td>80.5</td>
<td>87.2</td>
<td>83.2</td>
</tr>
<tr>
<td>GIX RE</td>
<td>91.1</td>
<td>92.9</td>
<td>92.0</td>
<td>91.5</td>
<td>93.3</td>
<td>92.2</td>
<td>89.4</td>
<td>89.5</td>
<td>88.9</td>
<td>93.9</td>
<td>92.4</td>
<td>93.9</td>
</tr>
</tbody>
</table>
<p>https://doi.org/10.1371/journal.pone.0303231.t003</p>
<h1>Exp2- comparison of GIX with manual curation of a benchmark dataset</h1>
<p>The objective of this experiment was to evaluate the performance of GIX in capturing genetic relations against a manually curated benchmark dataset. We experimented using the known target network information for the LLL dataset. The other three datasets, IEPA, HPRD50 and BioInfer, contain generic interactions involving different organisms, including humans and model organisms, while the relations present in the fourth dataset, LLL, are confined to a single bacterial species, Bacillus subtilis. In GIX, fine-tuning is required for both the Sentence Eliminator 1 (Stage-1) and Relation Classification (Stage-2), as they use a variant of the BioBERT model. As given in Table 4, the fine-tuning was performed using sentences from the HPRD50, BioInfer, and IEPA datasets, while the testing was done using the independent LLL dataset. The LLL dataset contains sentences containing genetic interactions of type action, regulation, binding, and promotion of cell transcription activity in B. subtilis. The keywords used to extract information from PubMed about transcription in B. subtilis from the abstracts of published literature were "Bacillus subtilis gene expression regulation transcriptional". The maximum number of retrieved articles was set to 1000 , so that only highly relevant papers were extracted.</p>
<p>The search for transcriptional regulations in Bacillus subtilis returned 371 abstracts containing 2,865 sentences. The Sentence Eliminator-1 and Sentence Eliminator-2 rejected 1,184 and 692 sentences, respectively, leaving 989 sentences for RE. The process extracted 1,120 relations from these sentences. Through the refinement step in the GIX post-processing stage, the extracted relations were further processed and condensed into 706 interactions (shown in Fig 8).</p>
<p>Table 4. Dataset used for fine-tuning of BioBERT models for RE classification and sentence elimination 1.</p>
<p>|   | Experiments |  |  | Relation extraction
classification |  |   |
| --- | --- | --- | --- | --- | --- | --- |
|  Dataset | Experiment with benchmark dataset
(Exp2): LLL | Experiment real-world database (Exp3):
RegulonDB | Positive | Negative |  |   |
|  LLL |  | x | 164 | 166 |  |   |
|  IEPA | x | x | 335 | 482 |  |   |
|  HPRD50 | x | x | 163 | 270 |  |   |
|  BioInfer | x | x | 2000 | 2500 |  |   |</p>
<p>https://doi.org/10.1371/journal.pone.0303231.t004</p>
<p><img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Fig 8. GIX's extraction process for Bacillus subtilis relations illustrating outputs at each step (dark grey blocks) and inputs such as datasets, databases, or target-specific keywords (light grey blocks).</p>
<p>https://doi.org/10.1371/journal.pone.0303231.g008</p>
<p>To calculate $C F_{r_{a} r_{b}}$ using Eq 1, prior information about known regulators and regulations was obtained from Subtiwiki [60], a comprehensive online resource and database dedicated to the bacterium Bacillus subtilis. As depicted in Fig 9, we observed that the $C F_{r_{a} r_{b}}$ of the majority of relations when not considering prior knowledge, lay between 0.9 and 1. To achieve a balanced impact of prior knowledge and literature-based extraction on the overall CF, we set $K$ to</p>
<p><img alt="img-6.jpeg" src="img-6.jpeg" /></p>
<p>Fig 9. Confidence factor $\left(C F_{r_{a} r_{b}}\right)$ of the extracted relations for Bacillus subtilis distribution of $C F_{r_{a} r_{b}}$ with and without prior knowledge.</p>
<p>https://doi.org/10.1371/journal.pone.0303231.g009</p>
<p><img alt="img-7.jpeg" src="img-7.jpeg" /></p>
<p><strong>Fig 10. ROC curve analysis used to determine the optimum threshold (γ) using relations extracted using GIX from 77 sentences in the LLL dataset.</strong></p>
<p><a href="https://doi.org/10.1371/journal.pone.0303231.g010">https://doi.org/10.1371/journal.pone.0303231.g010</a></p>
<ol>
<li>The impact of the <em>CF_{x,y}_{t}i</em> is evident in Fig 9, which shows an increase in the number of relations within higher <em>CF_{x,y}_{t}i</em> intervals with the activation of the prior knowledge component. After incorporating the prior knowledge component, the threshold value, γ, for <em>CF_{x,y}_{t}i</em> was set at 0.88. This setting was experimentally determined after performing ROC curve analysis to identify the best trade-off between true positive rate and false positive rate (shown in Fig 10). With γ = 0.88, 590 interactions were extracted.</li>
</ol>
<p>Table 5 displays the results of two experiments labeled as Exp2-(i) GIX-RE (only relation extraction model) and Exp2-(ii) GIX (Full Framework). In experiment Exp2-(i), only the relation extraction model of GIX, corresponding to Stage-2 of the framework, is utilized. The datasets used for fine-tuning of the relation classification model for experiment Exp2-(i) include HPRD50, IEPA, and BioInfer while LLL dataset is used for testing. In experiment Exp2-(ii), the full GIX framework is under investigation. Here, the fine-tuning datasets consist of HPRD50, IEPA, and BioInfer. While the testing dataset comprises of sentences extracted from PubMed related to <em>Bacillus Subtilis</em> regulatory interactions. These two experiments demonstrate that GIX, using just a few target-related keywords instead of the manually refined and formatted sentences was able to maintain a similar level of accuracy of extracted interactions without losing any of the sentences. The GIX framework is therefore robust, because, despite the elimination of a large number (2,109) of sentences during pre-processing and the loss of</p>
<p><strong>Table 5. Performance comparison of relation extraction from LLL sentences (i) using the GIX RE model and LLL sentences from the dataset, and (ii) using the GIX Framework and target-related keywords.</strong></p>
<table>
<thead>
<tr>
<th>Method</th>
<th>Precision</th>
<th>Recall</th>
<th>F-score</th>
<th>Number of instances confirming true interactions found</th>
</tr>
</thead>
<tbody>
<tr>
<td>GIX RE (LLL– 330 sentences)</td>
<td>86.30</td>
<td>79.35</td>
<td>81.29</td>
<td>130</td>
</tr>
<tr>
<td>GIX (Full Framework)</td>
<td>86.30</td>
<td>79.35</td>
<td>81.29</td>
<td>255</td>
</tr>
</tbody>
</table>
<p>https://doi.org/10.1371/journal.pone.0303231.t005</p>
<p>almost half of the interactions due to post-processing refinement, there was no loss of information when using GIX. Furthermore, 130 out of 164 true interactions were confirmed 255 times by GIX by extracting the same interactions from multiple sentences, demonstrating its ability to leverage several sources for identifying true regulations. As a result, we augmented the dataset with an additional 125 sentences with labelled entities containing LLL's true regulations. This experiment also demonstrated GIX's proficiency in efficiently enriching benchmark datasets with sentences containing newly introduced terminologies, biological processes, and relationships.</p>
<p>We observed a difference between model accuracies when fine-tuning and testing sentences belong to the same dataset (LLL) and when the model was fine-tuned on non-LLL data (BioInfer, HPRD50, and IEPA) and tested on LLL. The disparities in accuracies can be attributed to differences in the fine-tuning data. The use of non-related datasets in Exp2 is realistic because in the real-world, often, the data is not always truly aligned with the training dataset. In past, the attempts by researchers at generalisation have been less successful with their accuracies decreasing significantly. For instance, in ([41], the model that was trained using only BioInfer and tested on LLL exhibited a low accuracy of $33.50 \%$. In contrast, our proposed model has a Precision of $86.30 \%$ which is a slight decrease from Exp1 but still higher than other models. Combination of diverse non-related datasets (BioInfer, IEPA and HPRD50) has led to better generalisation and hence improved performance.</p>
<h1>Exp3- comparison of GIX with manual curation of a real-world database</h1>
<p>We used E. coli interactions available in the database RegulonDB to evaluate GIX's ability to automatically extract TF-gene, TF-transcriptional unit, TF-operon, and TF-TF regulations. The extracted relationships are validated using known relations from RegulonDB, ensuring accuracy, and the overall confidence factor is adjusted based on this ground truth for evaluating GIXbased relationships against manually curated ones by RegulonDB. The database maintains references to articles for each curated interaction. The corpus neither records the article segment (such as Abstract, Introduction, or Conclusions) nor the sentences used to report the interaction. To evaluate the performance of GIX, we compared the accuracy of extraction of regulations by GIX with the RegulonDB regulations that had been curated from abstracts. We identified 578 unique interactions in 554 associated papers that mention the entities (gene/protein name) in at least one sentence of the abstract. For sake of convenience, throughout the paper, these 578 interactions are referred as abstract-level relations. The datasets used for fine-tuning the Sentence Eliminator- 1 (Stage-1) and the Relation Classification (Stage-2) were the four available benchmark datasets, BioInfer, HPRD50, IEPA and LLL. The testing dataset was formulated using sentences not found in the fine-tuning data sets. These sentences were extracted by GIX through keyword-based extraction from PubMed. The sentences comprising the testing dataset, obtained from published literature, are related to E. coli, while the benchmark datasets used for fine-tuning represent different domains. For example, the IEPA dataset is focused on biochemical relations and the LLL is dedicated to Bacillus subtilis. Thus, there is no overlap between the content of these four datasets and the E. coli-related sentences used for testing. The keywords used to extract the abstracts of published literature describing E. coli transcription from PubMed were "E coli Escherichia coli gene expression regulation transcriptional". To ensure the extraction of only highly relevant papers, the maximum number of retrieved articles was set to 1000 . As in the previous experiment, we determined the threshold value $\gamma$ for CF , which was set at 1.5 . The inputs and outputs of each process in GIX for Exp3 are depicted in Fig 11.</p>
<p>As depicted in Fig 12, in the absence of prior knowledge, the $\mathrm{CF}<em 2="2">{1}$ associated with the majority of relations is distributed within the ranges $[0,2]$ and $[4,10]$. As per Eq 2, $\mathrm{CF}</em>$ will vary</p>
<p><img alt="img-8.jpeg" src="img-8.jpeg" /></p>
<p>Fig 11. GIX's extraction process for Escherichia coli relations illustrating the outputs at each step (dark grey blocks) and inputs such as datasets, databases, or target-specific keywords (light grey blocks).</p>
<p>https://doi.org/10.1371/journal.pone.0303231.g011</p>
<p>between 0 and 3. To balance the influence of prior knowledge and extraction based on existing literature on the cumulative CF, we set the parameter <em>K</em> to 2, after averaging the higher values within the ranges of CF<sup>1</sup> and subsequently dividing by the maximum value of CF<sup>2</sup>. To compute the CF<sub>e<sub>i</sub>F<sub>i</sub></sub> value using Eq 1 and validate the extracted relations, we used the regulatory interactions TF-TF, TF-operon, TF-gene, TF-TU, and the regulators annotated in RegulonDB as prior knowledge.</p>
<p>We retrieved 954 abstracts containing 7,358 sentences. During pre-processing, 4,022 sentences were eliminated, leaving 3,336 sentences. The RE stage extracted 8,014 positive entity pairs from within these 3,336 sentences. After post-processing refinement, we extracted 2,866 interactions. Upon evaluating the extracted relations against the 578 abstract-level interactions, 456 interactions were accurately identified. An additional 622 GIX extracted regulations were confirmed by relationships from RegulonDB that have not been annotated from abstracts of</p>
<p><img alt="img-9.jpeg" src="img-9.jpeg" /></p>
<p>Fig 12. (i) Confidence factor (CF<sub>e<sub>i</sub>F<sub>i</sub></sub>) pertaining to the extracted relations for the <em>E. coli</em> distribution CF<sub>e<sub>i</sub>F<sub>i</sub></sub> of without prior knowledge (PR) (ii) the percentage of relations extracted whose confidence factor CF<sub>e<sub>i</sub>F<sub>i</sub></sub> was influenced by prior knowledge.</p>
<p>https://doi.org/10.1371/journal.pone.0303231.g012</p>
<p>referenced literature. Of the regulations extracted by GIX, 92% were influenced by prior knowledge in their computed CF. Fig 12 shows that a significant number of relations with high confidence values are either known relations or have a known controlling entity. The interaction yielding the highest confidence value, of 24.65, was $C y t R \rightarrow C R P$. The high confidence value of the extracted relations provides a strong certainty in the accuracy and reliability of the extracted information.</p>
<h1>Application of GIX</h1>
<p>Transcriptional regulation relations automatically extracted using GIX are important for understanding biological processes, particularly in the area of gene regulatory network inference. In this section, we demonstrate the way in which the output generated by GIX can serve not only as a basis for the inference of Gene Regulatory Networks (GRNs) but can also incorporate. $C F_{r_{e}, r_{r}}$ to provide valuable information about the reliability of each interaction.</p>
<p>For GRN inference, we chose the top 500 GIX-extracted transcriptional regulations of E. coli obtained in Experiment Exp3. The selection was based on the $C F_{r_{e}, r_{r}}$ assigned to each relation. We used Cytoscape [61], an open-source software platform, to visualize the network (Fig 13). With the confidence factor of each relation used as its corresponding weight, an arc appears thicker for higher $C F_{r_{e}, r_{r}}$. The node size corresponds directly to the in-degree of the node. The GRN can help understand the complex regulatory mechanisms governing gene expression in E. coli. These networks can also serve as prior knowledge for reconstructing GRNs using more advanced computational methodologies and address the excessive computational overhead.</p>
<p>Biological circuits offer valuable insights into molecular-level interactions, especially within GRNs. From the presented GRN network for E. coli, entities CRP, fnr, CytR, fis, MarA, $\operatorname{csgD}$ stand out as the key regulatory genes, regulating 77 genes among themselves. Identifying controller genes is crucial as they govern gene expression, influencing cell state and offer help in developing targeted treatments for genetic disorders like cancer. GRNs exhibit sparsity, evident in the presented network where 334 genes exhibit only 500 interactions. Further, it may also be noted that due to the high cost of wet lab experiments to determine interactions, exhaustive exploration of relationships among thousands of genes becomes impractical. While significant efforts have been made to develop advanced computational methods for inferring relationships using gene expression data, yet the noisy and scarce nature of the data poses
<img alt="img-10.jpeg" src="img-10.jpeg" /></p>
<p>Fig 13. Network diagram of 500 extracted E. coli gene/protein relations visualized using Cytoscape [61].
https://doi.org/10.1371/journal.pone.0303231.g013</p>
<p>several challenges in achieving improved accuracy and efficiency. Integrating relationships obtained via GIX as a-priori knowledge in the reconstruction process can significantly reduce convergence time, enhance overall accuracy, and facilitate the discovery of new relations. This iterative process, once refined, allows for cost-effective high-throughput experiments targeting specific entities, reducing the overall expense of uncovering crucial relationships.</p>
<h1>Conclusions</h1>
<p>GIX (Gene Interaction Extraction), our systematic and robust relation extraction framework, focuses on mining biological entity interactions from journal paper abstracts using domainspecific strategies and pre-trained attention-based models. The methodology underlying the GIX framework involves three stages: (i) pre-processing, (ii) relation extraction, and (iii) postprocessing. The pre-processing stage uses a selection of keywords to obtain abstracts of highly relevant literature. Sentences that do not contain functional interactions and entity pairs are automatically excluded at this stage. In the relation extraction stage, the pre-trained large language models BERN2 and BioBERT are used for NER and RE. The associated entity-labelling schema reduces sentence complexity and improves model prediction accuracy. The post-processing stage refines the extracted relations by removing incorrectly recognised entities and assigns a novel confidence factor to quantify the correctness of an extracted relation. This confidence factor depends on both the information from multiple documents that corroborate a given regulatory relationships, and the pre-existing knowledge available from manually curated databases. The performance of GIX was validated using four benchmark datasets of gene/protein interactions. GIX's relation extraction ability surpassed the performance of previous state-of-the-art methods. GIX's performance against manually curated datasets and repositories was robust. We also observed the ability of GIX to augment existing datasets with new sentences from abstracts of published literature containing newly discovered terminologies and biological processes. The application of GIX to infer an E. coli gene regulatory network demonstrated its ability to work effectively with real world data.</p>
<p>Despite the rapid execution and high performance of pre-trained domain-specific large language models, the RE techniques described in the existing literature remain primarily confined to paper abstracts. The title, author list, affiliation, abstract, and keywords are easily available on Medline's PubMed repository. Designing a method to automatically extract text from the body of the paper may require source-specific code, authentication requirements and additional permissions to run data-scraping web services. Therefore, automatically extracting pieces of text from the body of the paper is relatively a more complex task than extracting text from abstracts. While the proposed method has focused on extracting relations using abstracts of publications, the approach is generic, and it can be easily extended for extracting relations using entire documents. For future work, we aim to extend GIX's applicability by seamlessly integrating extracted genetic relationships as prior knowledge for improved GRN reconstruction. Additionally, we will explore GIX's ability to identify multi-sentential relationships, providing a more comprehensive understanding of complex biological interactions.</p>
<h2>Author Contributions</h2>
<p>Conceptualization: Jaskaran Kaur Gill, Madhu Chetty.
Data curation: Jaskaran Kaur Gill.
Formal analysis: Jaskaran Kaur Gill, Madhu Chetty.
Investigation: Jaskaran Kaur Gill.</p>
<p>Methodology: Jaskaran Kaur Gill, Madhu Chetty.
Supervision: Madhu Chetty, Suryani Lim, Jennifer Hallinan.
Validation: Jaskaran Kaur Gill.
Visualization: Jaskaran Kaur Gill.
Writing - original draft: Jaskaran Kaur Gill.
Writing - review \&amp; editing: Jaskaran Kaur Gill, Madhu Chetty, Suryani Lim, Jennifer Hallinan.</p>
<h1>References</h1>
<ol>
<li>Zhou D, Zhong D, He Y. Biomedical Relation Extraction: From Binary to Complex. Computational and mathematical methods in medicine. 2014; 2014: 298473-18. https://doi.org/10.1155/2014/298473 PMID: 25214883</li>
<li>Zhang Y, Lin H, Yang Z, Wang J, Sun Y, Xu B, et al. Neural network-based approaches for biomedical relation classification: A review. Journal of Biomedical Informatics. 2019; 99: 103294. https://doi.org/ 10.1016/j.jbi.2019.103294 PMID: 31557530</li>
<li>Corlan AD. Medline trend: automated yearly statistics of PubMed results for any query. [Online].; 2004 [cited 2023 Jan 15. Available from: http://dan.corlan.net/medline-trend.html.</li>
<li>Singhal A, Leaman R, Catlett N, Lemberger T, McEntyre J, Polson S, et al. Pressing needs of biomedical text mining in biocuration and beyond: opportunities and challenges. Database. 2016; 2016: baw161.</li>
<li>Fogel GB, Weekes DG, Varga G, Dow ER, Craven AM, Harlow HB, et al. A statistical analysis of the TRANSFAC database. BioSystems. 2005; 81(2): 137-154. https://doi.org/10.1016/j.biosystems.2005. 03.003 PMID: 15941617</li>
<li>Gama-Castro S, Salgado H, Santos-Zavaleta A, Ledezma-Tejeida D, Muñiz-Rascado L, García-Sotelo JS, et al. RegulonDB version 9.0: high-level integration of gene regulation, coexpression, motif clustering and beyond. Nucleic acids research. 2016; 44(D1): D133-143. https://doi.org/10.1093/nar/gkv1156 PMID: 26527724</li>
<li>Hong L, Lin J, Li S, Wan F, Yang H, Jiang T, et al. A novel machine learning framework for automated biomedical relation extraction from large-scale literature repositories. Nature Machine Intelligence. 2020; 2: 347-355.</li>
<li>Jung H, Lee BG. Research trends in text mining: Semantic network and main path analysis of selected journals. Expert Systems with Applications. 2020; 162.</li>
<li>Sangrak Lim JK. Chemical-gene relation extraction using recursive neural network. Database. 2018; 2018.</li>
<li>Sanger M, Leser U. Large-scale entity representation learning for biomedical relationship extraction. Bioinformatics. 2021;: 236-242. https://doi.org/10.1093/bioinformatics/btaa674 PMID: 32726411</li>
<li>Karaa WBA, Mannai M, Dey N, Ashour AS, Olariu I. Gene-Disease-Food Relation Extraction from Biomedical Database. In Proceedings of the 7th international workshop soft computing applications (SOFA 2016); 2018.</li>
<li>Miwa M, Sætre R, Miyao Y, Tsujii J. Entity-Focused Sentence Simplification for Relation Extraction. In Proceedings of the 23rd International Conference on Computational Linguistics; 2010; Coling 2010.</li>
<li>Phuong TM, Lee D, Lee KH. Learning Rules to Extract Protein Interactions from Biomedical Text. Advances in Knowledge Discovery and Data Mining. 2003;: 148-158.</li>
<li>Chowdhury MFM, Lavelli A. Impact of less skewed distributions on efficiency and effectiveness of biomedical relation extraction. Proceedings of coling 2012: Posters. 2012.</li>
<li>Fundel K, Küffner R, Zimmer R. RelEx—Relation extraction using dependency parse trees. Bioinformatics. 2007; 23(3): 365-371. https://doi.org/10.1093/bioinformatics/btl616 PMID: 17142812</li>
<li>Zhou W, Huang K, Ma T, Huang J. Document-Level Relation Extraction with Adaptive Thresholding and Localized Context Pooling. In In Proceedings of the AAAI conference on artificial intelligence; 2021. p. $14612-14620$.</li>
<li>
<p>Akkasi A, Moens MF. Causal relationship extraction from biomedical text using deep neural models: A comprehensive survey. Journal of biomedical informatics. 2021; 119: 103820. https://doi.org/10.1016/j. jbi.2021.103820 PMID: 34044157</p>
</li>
<li>
<p>Yang S, Yoo S, Jeong O. DeNERT-KG: Named Entity and Relation Extraction Model Using DQN, Knowledge Graph, and BERT. Appl. Sci. 2020; 10: 6429.</p>
</li>
<li>Lee J, Yoon W, Kim S, Kim D, Kim S, So CH, et al. BioBERT: a pre-trained biomedical language representation model for biomedical text mining. Bioinformatics. 2020; 36(4): 1234-1240. https://doi.org/10. 1093/bioinformatics/btz682 PMID: 31501885</li>
<li>Panyam NC, Verspoor K, Cohn T, Ramamohanarao K. Exploiting graph kernels for high performance biomedical relation extraction. J Biomed Semant. 2018; 9(7). https://doi.org/10.1186/s13326-017-0168-3 PMID: 29382397</li>
<li>Lamurias A, Clarke LA, Couto FM. Extracting microRNA-gene relations from biomedical literature using distant supervision. PLoS ONE. 2017; 12(3): e0171929. https://doi.org/10.1371/journal.pone.0171929 PMID: 28263989</li>
<li>Pyysalo S, Ginter F, Heimonen J, Björne J, Boberg J, Järvinen J, et al. BioInfer: a corpus for information extraction in the biomedical domain. BMC bioinformatics. 2007; 8(1): 50-50. https://doi.org/10.1186/ 1471-2105-8-50 PMID: 17291334</li>
<li>Airola A, Pyysalo S, Bjorne J, Pahikkala T, Ginter F, Salakoski T. A graph kernel for protein-protein interaction extraction. In Proceedings of the workshop on current trends in biomedical natural language processing; 2008. p. 1-9.</li>
<li>Nédellec C. Learning language in logic—genic interaction extraction challenge. In Learning language in logic workshop (LLL05); 2005: ACM-Association for Computing Machinery.</li>
<li>Zhang Q, Chen M, Liu L. A Review on Entity Relation Extraction. In Second International Conference on Mechanical, Control and Computer Engineering (ICMCCE); 2017. p. 178-183.</li>
<li>Onye SC, Akkeles A, Dimililer N. Review of Biomedical Relation Extraction. European International Journal of Science and Technology. 2017; 6(1).</li>
<li>Nasar Z, Jaffry SW, Malik MK. Named Entity Recognition and Relation Extraction: State-of-the-Art. ACM Computing Surveys. 2021; 54(1): 1-39.</li>
<li>Maslennikova E. ELMo Word Representations For News Protection. CLEF (Working Notes). 2019.</li>
<li>Devlin J, Chang MW, Lee K, Toutanova K. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. arXiv preprint arXiv:1810.04805. 2018.</li>
<li>Acheampong FA, Nunoo-Mensah H, Chen W. Transformer models for text-based emotion detection: a review of BERT-based approaches. Artificial Intelligence Review. 2021;: 1-41.</li>
<li>Cohn C. BERT Efficacy on Scientific and Medical Datasets: A Systematic Literature Review. DePaul University. 2020.</li>
<li>Affi M, Latiri C. BE-BLC: BERT-ELMO-Based Deep Neural Network Architecture for English Named Entity Recognition Task. Procedia Computer Science. 2021; 192: 168-181.</li>
<li>Selvarajah J, Nawarathna RD. A Lucrative Model for Identifying Potential Adverse Effects from Biomedical Texts by Augmenting BERT and ELMo. In Singapore S, editor. Proceedings of International Conference on Sustainable Expert Systems: ICSES 2020.; 2021.</li>
<li>Peng Y, Yan S, Lu Z. Transfer Learning in Biomedical Natural Language Processing: An Evaluation of BERT and ELMo on Ten Benchmarking Datasets. arXiv preprint arXiv:1906.05474. 2019.</li>
<li>Zhu Y, Li L, Lu H, Zhou A, Qin X. Extracting drug-drug interactions from texts with BioBERT and multiple entity-aware attentions. Journal of biomedical informatics. 2020; 106: 103451. https://doi.org/10.1016/j. jbi.2020.103451 PMID: 32454243</li>
<li>Elangovan A, Davis M, Verspoor K. Assigning function to protein-protein interactions: a weakly supervised BioBERT based approach using PubMed abstracts. arXiv preprint arXiv:2008.08727. 2020.</li>
<li>Song B, Li F, Liu Y, Zeng X. Deep learning methods for biomedical named entity recognition: a survey and qualitative comparison. Briefings in Bioinformatics. 2021; 22(6). https://doi.org/10.1093/bib/ bbab282 PMID: 34308472</li>
<li>Zhu F, Patumcharoenpol P, Zhang C, Yang Y, Chan J, Meechai A, et al. Biomedical text mining and its applications in cancer research. Journal of Biomedical Informatics. 2013; 46(2): 200-211. https://doi. org/10.1016/j.jbi.2012.10.007 PMID: 23159498</li>
<li>Song M, Kim WC, Lee D, Heo GE, Kang KY. PKDE4J: Entity and relation extraction for public knowledge discovery. Journal of Biomedical Informatics. 2015; 57: 320-332. https://doi.org/10.1016/j.jbi. 2015.08.008 PMID: 26277115</li>
<li>Gridach M. Character-level neural network for biomedical named entity recognition. Journal of Biomedical Informatics. 2017; 70: 85-91. https://doi.org/10.1016/j.jbi.2017.05.002 PMID: 28502909</li>
<li>Ahmed M, Islam J, Samee MR, Mercer RE. Identifying Protein-Protein Interaction using Tree LSTM and Structured Attention. In 2019 IEEE 13th international conference on semantic computing (ICSC); 2019. p. 224-231.</li>
</ol>            </div>
        </div>

    </div>
</body>
</html>