<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2077 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2077</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2077</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-53.html">extraction-schema-53</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or automated systems that generate novel outputs (scientific hypotheses, molecules, proofs, predictions) and how those outputs are validated, including performance metrics, false positive rates, and differences between generation and validation capabilities.</div>
                <p><strong>Paper ID:</strong> paper-278782614</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2505.15047v2.pdf" target="_blank">PiFlow: Principle-aware Scientific Discovery with Multi-Agent Collaboration</a></p>
                <p><strong>Paper Abstract:</strong> Large Language Model (LLM)-based multi-agent systems (MAS) demonstrate remarkable potential for scientific discovery. Existing approaches, however, often automate scientific discovery using predefined workflows that lack rationality constraints. This often leads to aimless hypothesizing and a failure to consistently link hypotheses with evidence, thereby hindering the systematic reduction of uncertainty. Overcoming these limitations fundamentally requires a principled approach to exploration. We introduce PiFlow, an information-theoretical framework, treating automated scientific discovery as a structured uncertainty reduction problem guided by principles (e.g., scientific laws). In evaluations across three distinct scientific domains -- discovering nanomaterial structures, bio-molecules, and superconductor candidates with targeted properties -- our method significantly improves discovery efficiency, reflected by a 73.55\% increase in the Area Under the Curve (AUC) of property values versus exploration steps, and enhances solution quality by 94.06\% compared to a vanilla agent system. Overall, PiFlow serves as a Plug-and-Play method, establishing a novel paradigm shift in highly efficient automated scientific discovery, paving the way for more robust and accelerated AI-driven research. Code is publicly available at our \href{https://github.com/amair-lab/PiFlow}{GitHub}.</p>
                <p><strong>Cost:</strong> 0.027</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2077.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2077.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or automated systems that generate novel outputs (scientific hypotheses, molecules, proofs, predictions) and how those outputs are validated, including performance metrics, false positive rates, and differences between generation and validation capabilities.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PiFlow</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>PiFlow: Principle-Aware Scientific Discovery Framework</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A plug-and-play information-theoretic controller for LLM-based multi-agent scientific discovery that selects and scores natural-language 'principles' via a Min–Max optimization balancing cumulative regret (exploitation) and information gain (exploration), and steers hypothesis generation accordingly.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>PiFlow</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>decision-theoretic controller + multi-agent framework (Min–Max optimization using LLM embeddings as proxies)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>materials science, chemistry, drug discovery (multi-domain / domain-agnostic)</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>scientific principles (natural-language), hypothesis steering commands (explore/validate/refine)</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_level</strong></td>
                            <td>moderately novel (algorithmic: new principle-level Min–Max selection; outputs are novel recombinations of LLM knowledge guided by information-theoretic objective)</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>selects or refines textual scientific principles (proposed by LLM agents or experts) and issues directives that bias subsequent hypothesis generation; selection uses a Min–Max adversarial objective approximated by a weighted sum of (1) exploitation scores computed from past outcomes and (2) exploration scores approximated by semantic distance between principle embeddings.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td>integrated Hypothesis–Validation loop using external experiment agents that call surrogate validation functions (high‑fidelity simulators / ML surrogate models); PiFlow uses the resulting principle–outcome trajectory T_t to re-score principles and guide future generation.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_performance</strong></td>
                            <td>Empirical generation/steering performance reported via task metrics: NHO AUC=63.51% ±11.18, SQ=76.82% ±4.54; MBO AUC=46.11% ±16.25, SQ=84.55% ±29.63; SPO AUC=21.51% ±2.80, SQ=34.85% ±1.19 (24-step runs, reported in Table 1 and Table 5). These metrics reflect the quality of generated candidates when guided by PiFlow.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_performance</strong></td>
                            <td>Validation is performed by surrogate models with reported predictive quality: NHO surrogate r^2≈0.98; MBO surrogate r^2≈0.91; SPO surrogate r^2≈0.91. The reported SQ and AUC are computed against these surrogate validation outputs; no separate precision/recall etc. for validation of PiFlow outputs are provided.</td>
                        </tr>
                        <tr>
                            <td><strong>false_positive_rate</strong></td>
                            <td>not reported (no explicit FPR provided). The paper does not report the rate at which generated candidates declared promising were invalidated by validation; only aggregate AUC/SQ metrics are given.</td>
                        </tr>
                        <tr>
                            <td><strong>false_negative_rate</strong></td>
                            <td>not reported (no explicit FNR provided).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_novelty</strong></td>
                            <td>No direct numeric breakdown by novelty; conceptually, PiFlow is designed so validation performance (lower regret, higher SQ) improves as information gain falls — empirical evidence shows sublinear average regret (fitted T^{-0.5}, c=1.37, r^2=0.96) and a positive association between information gain and regret. The paper reports PiFlow recovers from deliberately incorrect (novel but false) initial principles, indicating robustness as novelty increases, but does not quantify validation accuracy as a function of novelty.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_validation_comparison</strong></td>
                            <td>Paper explicitly discusses a generation/validation asymmetry: LLM agents can generate many principles/hypotheses quickly (high generation capability) while real-world validation is expensive; in experiments, validation is approximated via surrogate models so validation throughput is high, but the authors note that this is a proxy and that true wet-lab validation lags generation. PiFlow aims to reduce this gap by prioritizing hypotheses expected to be informative (thus lowering wasted validation effort).</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>Yes — PiFlow's theoretical objective includes mutual information I(h_t; f* | H_{t-1}) and uses proxies: semantic-distance of principle embeddings as a surrogate for information gain; empirical traces of information gain vs regret are plotted. The system tracks information-gain proxies and regret over iterations.</td>
                        </tr>
                        <tr>
                            <td><strong>calibration_quality</strong></td>
                            <td>Not quantified numerically. The paper provides theoretical/regret alignment and empirical curves (regret vs iterations) but does not report calibration metrics (e.g., reliability diagrams) for confidence estimates of generated hypotheses.</td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td>Qualitative examples: PiFlow found high-performing out-of-structure candidates in experiments (e.g., nanohelix g-factor ≈1.6, molecule pChEMBL ≈7.24, superconductor T_c ≈103 K). No formal OOD numeric benchmark is provided; robustness ablations show recovery from deliberately incorrect initial principles (Expert-Incorrect) indicating adaptive OOD robustness but no explicit OOD error rates.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_proxy_metrics</strong></td>
                            <td>Yes — the system relies on proxy metrics: surrogate-model outputs (high‑fidelity ML/simulator r^2) as ground-truth for validation; and for exploration, semantic-distance in LLM embedding space is used as a proxy for mutual information (information gain). AUC and SQ are composite metrics that assess generation+validation over time.</td>
                        </tr>
                        <tr>
                            <td><strong>human_validation_required</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>human_validation_frequency</strong></td>
                            <td>Recommended for real-world deployment; in the experiments validation used automated surrogates only. The paper explicitly notes real-world lab validation is prohibitively expensive and implies that human/experimental validation would be necessary for final candidates — frequency unspecified but would increase with claim novelty and domain risk.</td>
                        </tr>
                        <tr>
                            <td><strong>formal_verification_used</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>domain_formalization_level</strong></td>
                            <td>empirical (drug discovery, materials science) — semi-formal models (surrogates) used for validation; the empirical nature increases the generation-validation gap relative to highly formal domains like mathematics.</td>
                        </tr>
                        <tr>
                            <td><strong>gap_mitigation_strategies</strong></td>
                            <td>Min–Max adversarial selection of principles (balances exploitation/regret minimization and exploration/information gain); semantic-distance driven exploration to prioritize novel but informative principles; thresholded actions (refine/validate/explore) to avoid wasted validation; plug-and-play integration with existing experiment agents and surrogates to streamline validation. Ablations show improved AUC/SQ and recovery from incorrect principles, demonstrating effectiveness.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_supporting_gap</strong></td>
                            <td>Authors document: (1) LLM hallucinations and aimless hypothesizing in prior work; (2) high variance in agent trajectories (large std in baseline results), indicating generation variability; (3) the need to use surrogate models because real validation is expensive; (4) examples where unguided agents (Vanilla) explore aimlessly with poor AUC (e.g., Vanilla AUC in NHO 35.96% vs PiFlow 63.51%), implying generation alone does not ensure validated discoveries.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_contradicting_gap</strong></td>
                            <td>Within the surrogate-experiment setting, PiFlow's integration with automated validation yields consistent improvements in validated outcomes (higher SQ/AUC), suggesting that when high‑fidelity automated validators are available, the generation–validation gap can be largely closed in silico. The paper does not provide evidence of generation strictly outpacing validation in the surrogate setting.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_ratio</strong></td>
                            <td>Not directly quantified as a numeric ratio. Notes: PiFlow per-decision complexity O(t^2 * d) (dominated by embedding similarity calculations) but can be optimized; PiFlow reduced token consumption by up to ~27% vs Vanilla and itself contributes only ~1.2–1.5% of tokens. Validation cost in experiments is low because surrogate models are used; authors emphasize wet-lab validation would be substantially more expensive (no numeric ratio provided).</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2077.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2077.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or automated systems that generate novel outputs (scientific hypotheses, molecules, proofs, predictions) and how those outputs are validated, including performance metrics, false positive rates, and differences between generation and validation capabilities.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>QwenMax</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>QwenMax (foundation LLM used by agents)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A large language model employed as the base LLM for Hypothesis and Experiment agents in PiFlow experiments; used both for generating principle/hypothesis text and computing sentence embeddings for semantic-distance proxies.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>QwenMax</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>large language model (LLM)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>general-purpose LLM applied to materials, chemistry, biology tasks</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>natural-language principles, hypotheses, prompts, and embeddings</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_level</strong></td>
                            <td>in-distribution to moderately novel — generates recombined textual principles from pretraining knowledge; novelty dependent on prompts and PiFlow steering</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>autoregressive LLM sampling conditioned on Planner/Prompt and PiFlow directives; generates candidate principles and natural-language hypotheses</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td>LLM outputs are validated via the external Hypothesis–Validation loop (surrogate model evaluations); QwenMax also provides embeddings for PiFlow's exploration proxy.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_performance</strong></td>
                            <td>When used with PiFlow, runs achieved reported system AUC/SQ (e.g., PiFlow overall metrics where QwenMax served as base: NHO AUC 63.51% SQ 76.82%); standalone LLM generation quality not separately quantified.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_performance</strong></td>
                            <td>Not applicable for LLM itself; validation performed by surrogate models. No numeric validation performance for QwenMax-proposed hypotheses alone.</td>
                        </tr>
                        <tr>
                            <td><strong>false_positive_rate</strong></td>
                            <td>not reported for QwenMax-generated hypotheses</td>
                        </tr>
                        <tr>
                            <td><strong>false_negative_rate</strong></td>
                            <td>not reported</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_novelty</strong></td>
                            <td>Paper reports model-choice sensitivity: QwenMax achieved highest AUC (63.51%) among models tested, indicating model selection affects generation quality, but no per‑novelty breakdown.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_validation_comparison</strong></td>
                            <td>LLM generates many candidate principles/hypotheses quickly; validation throughput depends on surrogate; paper highlights mismatch between rapid generation and costly real-world validation (surrogates hide real gap).</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>QwenMax embeddings used as proxy for semantic distance; no calibrated uncertainty outputs (probabilities/certainty estimates) reported for generated hypotheses.</td>
                        </tr>
                        <tr>
                            <td><strong>calibration_quality</strong></td>
                            <td>not reported</td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td>Not explicitly reported; ablations across different LLMs show performance variance (Tables 9), suggesting differing OOD robustness.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_proxy_metrics</strong></td>
                            <td>Uses embedding-based semantic distance (from QwenMax) as a proxy for information gain; embeddings are central to exploration scoring.</td>
                        </tr>
                        <tr>
                            <td><strong>human_validation_required</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>human_validation_frequency</strong></td>
                            <td>unspecified</td>
                        </tr>
                        <tr>
                            <td><strong>formal_verification_used</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>domain_formalization_level</strong></td>
                            <td>empirical (applied to experimental domains)</td>
                        </tr>
                        <tr>
                            <td><strong>gap_mitigation_strategies</strong></td>
                            <td>Combined with PiFlow steering and surrogate validation to reduce wasted validation effort.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_supporting_gap</strong></td>
                            <td>LLM-driven hypotheses alone (Vanilla Agent using same LLM) performed poorly compared to PiFlow-guided runs, demonstrating that LLM generation needs strategic steering to yield validated discoveries.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_contradicting_gap</strong></td>
                            <td>When integrated with PiFlow and good surrogates, QwenMax enabled high validated outcomes, indicating generation can be reconciled with validation in-silico.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_ratio</strong></td>
                            <td>Not provided (token consumption data given globally: PiFlow reduces token consumption by up to 27% and PiFlow token share 1.2–1.5%).</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2077.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2077.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or automated systems that generate novel outputs (scientific hypotheses, molecules, proofs, predictions) and how those outputs are validated, including performance metrics, false positive rates, and differences between generation and validation capabilities.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Surrogate Models</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>High-fidelity surrogate validation models (DFT-trained ML and GNN/LightGBM surrogates)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Task-specific surrogate models stood in for wet‑lab/DFT experiments to validate hypotheses: LightGBM for nanohelix g-factor (r^2≈0.9802), GNN for molecular bioactivity (r^2≈0.91), and a surrogate for superconductors (r^2≈0.91); these were used as the f*(·) validation functions in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>surrogate validation models (LightGBM, GNN, supervised ML)</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>machine-learning surrogate models / simulators</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>materials science (nanohelix), drug discovery (bioactivity), superconductor prediction</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>numeric property predictions (g-factor, pChEMBL, T_c)</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_level</strong></td>
                            <td>in-distribution for training/test splits; used as ground-truth proxies rather than generative novelty</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>N/A (these models validate candidate outputs produced by the generative agents)</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td>Direct prediction of target property for each candidate hypothesis; these predictions are treated as validation outcomes in the Hypothesis–Validation loop</td>
                        </tr>
                        <tr>
                            <td><strong>generation_performance</strong></td>
                            <td>N/A</td>
                        </tr>
                        <tr>
                            <td><strong>validation_performance</strong></td>
                            <td>Reported surrogate predictive quality: NHO LightGBM r^2≈0.9802; MBO GNN r^2≈0.91; SPO surrogate r^2≈0.91. These high r^2 values are reported as justification for using surrogates as validation proxies.</td>
                        </tr>
                        <tr>
                            <td><strong>false_positive_rate</strong></td>
                            <td>not reported (depends on domain thresholding; paper reports SQ and AUC computed relative to theoretical maximums rather than FP/FN rates)</td>
                        </tr>
                        <tr>
                            <td><strong>false_negative_rate</strong></td>
                            <td>not reported</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_novelty</strong></td>
                            <td>Surrogates are trained on available data and may underperform on extreme OOD candidates; the paper acknowledges surrogates are approximations and that exact real-world validation could differ, but does not quantify degradation vs novelty.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_validation_comparison</strong></td>
                            <td>Surrogates provide rapid validation enabling many iterations; paper emphasizes this inflates validation throughput compared to real-world wet-lab, so generation/validation balance in silico is not representative of physical experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>Not extensively reported; r^2 provided as global fit metric. The paper does not report per-prediction uncertainty intervals or calibrated uncertainties from surrogates.</td>
                        </tr>
                        <tr>
                            <td><strong>calibration_quality</strong></td>
                            <td>Not reported (no calibration curves or predictive intervals provided).</td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td>Not quantified; authors caution that surrogates are proxies and that real-world validation could reveal discrepancies for highly novel candidates.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_proxy_metrics</strong></td>
                            <td>Primary validation proxies are surrogate model predicted values (used to compute SQ, AUC).</td>
                        </tr>
                        <tr>
                            <td><strong>human_validation_required</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>human_validation_frequency</strong></td>
                            <td>Suggested for final confirmation of high-value candidates (frequency not specified).</td>
                        </tr>
                        <tr>
                            <td><strong>formal_verification_used</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>domain_formalization_level</strong></td>
                            <td>empirical (data-driven surrogate models reflecting experimental/DFT outputs)</td>
                        </tr>
                        <tr>
                            <td><strong>gap_mitigation_strategies</strong></td>
                            <td>Use high-quality surrogates (high r^2) to reduce wasted real experiments; incorporate PiFlow to prioritize informative experiments, thereby reducing validation burden.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_supporting_gap</strong></td>
                            <td>Paper explicitly notes 'direct hypothesis validation in real-world labs is prohibitively expensive' and uses surrogates for validation; this highlights the validation-resource bottleneck versus generation speed.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_contradicting_gap</strong></td>
                            <td>High surrogate r^2 suggests in-silico validation is strong; within the simulated environment generation and validation are well aligned.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_ratio</strong></td>
                            <td>Not given as a numeric ratio; surrogate validation is treated as low-cost in experiments, while authors emphasize real-world (wet-lab) validation would be orders of magnitude more expensive.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2077.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2077.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or automated systems that generate novel outputs (scientific hypotheses, molecules, proofs, predictions) and how those outputs are validated, including performance metrics, false positive rates, and differences between generation and validation capabilities.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ChemToolAgent</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ChemToolAgent (tool-enabled chemistry agent)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An existing tool-integrated agent for chemistry tasks that PiFlow was integrated with in a plug-and-play manner; used as both Hypothesizer and Experimenter in an 8-iteration integration demonstrating PiFlow's generalizability.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Chemtoolagent: The impact of tools on language agents for chemistry problem solving.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>ChemToolAgent</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>tool-augmented multi-agent LLM system</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>chemistry / drug discovery</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>candidate molecular designs (SMILES), natural-language principles</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_level</strong></td>
                            <td>moderately novel (generates new molecule proposals guided by tools and LLM reasoning)</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>LLM + specialized chemical tools (e.g., database lookups) to produce molecule candidates and principles</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td>In the integration run, validated via surrogate bioactivity predictor (pChEMBL); ChemToolAgent's built-in tools were used for candidate checking; PiFlow provided EXPLORE/REFINE directives to guide iterations.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_performance</strong></td>
                            <td>Integration run produced a molecule with reported pChEMBL ≈5.90 after 8 iterations (Table 6); in broader MBO experiments PiFlow found pChEMBL ≈7.24.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_performance</strong></td>
                            <td>Validated in-silico by the MBO surrogate (r^2≈0.91); no per-candidate FP/FN rates provided.</td>
                        </tr>
                        <tr>
                            <td><strong>false_positive_rate</strong></td>
                            <td>not reported</td>
                        </tr>
                        <tr>
                            <td><strong>false_negative_rate</strong></td>
                            <td>not reported</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_novelty</strong></td>
                            <td>Not explicitly quantified. Integration shows PiFlow can steer tool-enabled agents to improved validated outputs without architecture modifications.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_validation_comparison</strong></td>
                            <td>ChemToolAgent can generate candidates aided by tools; PiFlow improved the strategic selection and thus improved validated outcomes (pChEMBL increase over naive runs).</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>Not reported for ChemToolAgent itself; PiFlow's proxies used to guide exploration.</td>
                        </tr>
                        <tr>
                            <td><strong>calibration_quality</strong></td>
                            <td>not reported</td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td>Not reported</td>
                        </tr>
                        <tr>
                            <td><strong>validation_proxy_metrics</strong></td>
                            <td>Relies on surrogate pChEMBL predictions and tool checks (e.g., plausibility/validity of SMILES).</td>
                        </tr>
                        <tr>
                            <td><strong>human_validation_required</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>human_validation_frequency</strong></td>
                            <td>unspecified</td>
                        </tr>
                        <tr>
                            <td><strong>formal_verification_used</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>domain_formalization_level</strong></td>
                            <td>empirical (chemistry/drug discovery)</td>
                        </tr>
                        <tr>
                            <td><strong>gap_mitigation_strategies</strong></td>
                            <td>PiFlow provides strategic guidance (EXPLORE/REFINE) to focus ChemToolAgent on informative searches, reducing wasted validation effort.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_supporting_gap</strong></td>
                            <td>Authors note PiFlow guided ChemToolAgent to a pChEMBL=5.90 without architecture changes, demonstrating that strategic steering improves validated outcomes where tool-enabled generation alone might be inefficient.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_contradicting_gap</strong></td>
                            <td>Successful plug-and-play integration suggests when good validators and tools exist, generation+validation can be effectively coupled in-silico.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_ratio</strong></td>
                            <td>Not specified; integration run used 8 iterations and surrogate validation; PiFlow token overhead small (~1.2–1.5%).</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2077.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2077.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or automated systems that generate novel outputs (scientific hypotheses, molecules, proofs, predictions) and how those outputs are validated, including performance metrics, false positive rates, and differences between generation and validation capabilities.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Bayesian Optimization (BO)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Bayesian Optimization (baseline optimizer)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A classical black-box optimization baseline that requires a manually defined parameterized search space; compared to PiFlow across tasks to assess performance under epistemic uncertainty.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Bayesian Optimization</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>sequential model-based optimizer (Gaussian process or surrogate-based BO)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>optimization for materials/molecular design</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>candidate parameter vectors / molecular suggestions (if parameterized)</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_level</strong></td>
                            <td>in-distribution/structured-search — typically conservative exploration within a predefined parameter space</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>acquisition-function-driven search (e.g., expected improvement) over a manually engineered parameter space</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td>evaluated using the same surrogate validation models as PiFlow in the experiments</td>
                        </tr>
                        <tr>
                            <td><strong>generation_performance</strong></td>
                            <td>Reported in Table 5: NHO BO AUC=68.86% ±5.86, SQ=78.76% ±0.77 (competitive on structured NHO task); MBO BO AUC=34.76% ±4.21, SQ=31.61% ±0.19 (much worse than PiFlow on MBO); SPO BO AUC=38.15% ±4.02, SQ=32.38% ±0.32.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_performance</strong></td>
                            <td>Same surrogate validators used; performance reported above is BO's validated outcomes.</td>
                        </tr>
                        <tr>
                            <td><strong>false_positive_rate</strong></td>
                            <td>not reported</td>
                        </tr>
                        <tr>
                            <td><strong>false_negative_rate</strong></td>
                            <td>not reported</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_novelty</strong></td>
                            <td>BO is strong on structured, well-parameterized tasks (NHO) but underperforms on ill-structured, combinatorial/discrete tasks (MBO) where PiFlow's principle-level shifts achieve domain-shifting jumps; no numeric novelty-dependent validation metrics reported.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_validation_comparison</strong></td>
                            <td>BO's generation (proposals) is constrained by manually defined search space and tends to require domain engineering; PiFlow can do domain-shifting leaps via principle reasoning, leading to better validated outcomes on ill-structured tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>BO inherently quantifies uncertainty via surrogate predictive distributions (GP variance), but the paper does not report BO calibration metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>calibration_quality</strong></td>
                            <td>not reported</td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td>BO performs poorly when good parametrization is missing (MBO). PiFlow outperforms BO in such cases.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_proxy_metrics</strong></td>
                            <td>BO uses surrogate-model predicted objective as validation signal in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>human_validation_required</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>human_validation_frequency</strong></td>
                            <td>unspecified</td>
                        </tr>
                        <tr>
                            <td><strong>formal_verification_used</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>domain_formalization_level</strong></td>
                            <td>varies — BO requires a well-formalized parameterization; performance degrades in poorly formalized empirical spaces.</td>
                        </tr>
                        <tr>
                            <td><strong>gap_mitigation_strategies</strong></td>
                            <td>BO mitigates generation-validation gap via principled uncertainty sampling, but needs hand-crafted search spaces; PiFlow offers an alternative by operating at principle level to reduce wasted validation.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_supporting_gap</strong></td>
                            <td>Comparative results show BO's reliance on expert parameterization can limit validated discovery in ill-structured problems (MBO) where PiFlow excels.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_contradicting_gap</strong></td>
                            <td>BO is competitive or superior on well-structured tasks (NHO), indicating that in some domains validation can keep up with generation when the search space is well defined.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_ratio</strong></td>
                            <td>Not specified.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2077.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e2077.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or automated systems that generate novel outputs (scientific hypotheses, molecules, proofs, predictions) and how those outputs are validated, including performance metrics, false positive rates, and differences between generation and validation capabilities.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Vanilla Agent System</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Vanilla LLM-based Multi-Agent System (no PiFlow strategic layer)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A baseline multi-agent system using the same LLM and experiment tools but without PiFlow's principle-aware strategic steering; demonstrates performance floor of unguided generation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Vanilla Agent System</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>LLM-based multi-agent system (roleplay agents) without principled strategic layer</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>materials, chemistry, superconductors (same tasks as PiFlow)</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>natural-language hypotheses and candidate parameterizations/molecules</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_level</strong></td>
                            <td>variable — LLM-driven novelty but unguided, often aimless</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>roleplaying LLM agents generate hypotheses based on prompts without PiFlow steering</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td>same surrogate validators as PiFlow</td>
                        </tr>
                        <tr>
                            <td><strong>generation_performance</strong></td>
                            <td>Table 1 reports baseline (Vanilla) performance: NHO AUC=35.96% ±22.38, SQ=46.76% ±7.29; MBO AUC=29.71% ±12.66, SQ=49.22% ±8.30; SPO AUC=11.39% ±11.33, SQ=14.16% ±13.37 — high variance and lower average performance than PiFlow.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_performance</strong></td>
                            <td>Validation via surrogates; validated outputs were poorer on average vs PiFlow as shown by AUC/SQ.</td>
                        </tr>
                        <tr>
                            <td><strong>false_positive_rate</strong></td>
                            <td>not reported</td>
                        </tr>
                        <tr>
                            <td><strong>false_negative_rate</strong></td>
                            <td>not reported</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_novelty</strong></td>
                            <td>High variance indicates many generated outputs are low quality or lead to cumulative error; PiFlow's higher AUC suggests guided generation yields higher validated yield especially early in runs.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_validation_comparison</strong></td>
                            <td>Unguided generation outpaces useful validation (many generated hypotheses are low-value), resulting in low validated yield and high variance in trajectories.</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>No explicit uncertainty-tracking mechanism described for Vanilla system beyond stochastic LLM outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>calibration_quality</strong></td>
                            <td>not reported</td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td>Poorer than PiFlow; no explicit OOD metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_proxy_metrics</strong></td>
                            <td>Relies on same surrogate models for validation; AUC/SQ used to compare validated results.</td>
                        </tr>
                        <tr>
                            <td><strong>human_validation_required</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>human_validation_frequency</strong></td>
                            <td>unspecified</td>
                        </tr>
                        <tr>
                            <td><strong>formal_verification_used</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>domain_formalization_level</strong></td>
                            <td>empirical</td>
                        </tr>
                        <tr>
                            <td><strong>gap_mitigation_strategies</strong></td>
                            <td>None intrinsic; PiFlow is proposed to mitigate the generation-validation inefficiency observed here.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_supporting_gap</strong></td>
                            <td>Vanilla's poor AUC and high variance are presented as evidence that raw LLM generation without principled steering produces many uninformative hypotheses that waste validation budget.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_contradicting_gap</strong></td>
                            <td>None provided.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_ratio</strong></td>
                            <td>Token usage: Vanilla consumed more tokens than PiFlow; PiFlow-MAS reduced token consumption by up to ~27% relative to Vanilla (Table 7).</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2077.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e2077.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or automated systems that generate novel outputs (scientific hypotheses, molecules, proofs, predictions) and how those outputs are validated, including performance metrics, false positive rates, and differences between generation and validation capabilities.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ReAct</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ReAct: Reasoning and Acting LLM agent method</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A baseline agentic method combining chain-of-thought reasoning with actions for stepwise hypothesis generation and tool use; used as one baseline in comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>React: Synergizing reasoning and acting in language models.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>ReAct</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>LLM agent method (reasoning + action loop)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>general-purpose agentic reasoning applied to scientific discovery tasks in experiments</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>natural-language reasoning traces and candidate hypotheses/actions</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_level</strong></td>
                            <td>in-distribution/derivative of LLM capabilities; structured reasoning rather than novel discovery mechanism</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>LLM produces alternating reasoning (chain-of-thought) and action outputs to propose experiments</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td>Generated experiments are validated by surrogates in the paper's experiments</td>
                        </tr>
                        <tr>
                            <td><strong>generation_performance</strong></td>
                            <td>Table 1: ReAct baseline performance: NHO AUC=35.85% ±7.12, SQ=41.96% ±0.82; MBO AUC=29.61% ±9.74, SQ=43.11% ±9.98; SPO AUC=5.29% ±0.69, SQ=6.41% ±0.96 — lower than PiFlow.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_performance</strong></td>
                            <td>Validated via surrogate models; ReAct's validated outputs inferior to PiFlow's as measured by AUC/SQ.</td>
                        </tr>
                        <tr>
                            <td><strong>false_positive_rate</strong></td>
                            <td>not reported</td>
                        </tr>
                        <tr>
                            <td><strong>false_negative_rate</strong></td>
                            <td>not reported</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_novelty</strong></td>
                            <td>No explicit breakdown; the paper remarks that explicit chain-of-thought can cause cognitive fixation, and ablations showed disabling explicit 'Think' sometimes improved performance, suggesting ReAct-like explicit reasoning may hurt exploration of novel hypotheses.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_validation_comparison</strong></td>
                            <td>ReAct's generation (explicit reasoning + action) can lead to local fixation and lower validated yields compared to PiFlow's principled exploration/exploitation trade-off.</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>Not central to ReAct; no explicit uncertainty quantification reported in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>calibration_quality</strong></td>
                            <td>not reported</td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td>Not specifically reported.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_proxy_metrics</strong></td>
                            <td>Uses surrogate validation same as others.</td>
                        </tr>
                        <tr>
                            <td><strong>human_validation_required</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>human_validation_frequency</strong></td>
                            <td>unspecified</td>
                        </tr>
                        <tr>
                            <td><strong>formal_verification_used</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>domain_formalization_level</strong></td>
                            <td>empirical</td>
                        </tr>
                        <tr>
                            <td><strong>gap_mitigation_strategies</strong></td>
                            <td>No specific strategies beyond ReAct's built-in reasoning/action structure; PiFlow shown empirically to outperform ReAct.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_supporting_gap</strong></td>
                            <td>ReAct baseline's lower AUC/SQ and susceptibility to chain-of-thought fixation are used to motivate need for PiFlow-style strategic guidance.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_contradicting_gap</strong></td>
                            <td>Not provided.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_ratio</strong></td>
                            <td>Not specified.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2077.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e2077.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or automated systems that generate novel outputs (scientific hypotheses, molecules, proofs, predictions) and how those outputs are validated, including performance metrics, false positive rates, and differences between generation and validation capabilities.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MPO</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Meta Plan Optimization (MPO)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A baseline that uses a trained LLM planner to provide high‑level guidance; compared to PiFlow to evaluate explicit structured strategic guidance vs learned planner-based guidance.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Mpo: Boosting llm agents with meta plan optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>MPO (Meta Plan Optimization)</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>trained LLM planner (policy/plan-level model)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>general-purpose planning applied to scientific discovery</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>high-level plans/checklists for agent actions</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_level</strong></td>
                            <td>incremental (learned planner over LLM capabilities)</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>trained planner LLM outputs stepwise plans that guide agents</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td>Plans lead to hypotheses validated by surrogate models in experiments</td>
                        </tr>
                        <tr>
                            <td><strong>generation_performance</strong></td>
                            <td>Table 1: MPO baseline: NHO AUC=43.99% ±2.79, SQ=51.29% ±7.77; MBO AUC=31.18% ±9.12, SQ=57.28% ±5.85; SPO AUC=12.68% ±7.75, SQ=33.20% ±23.75. Performance better than some baselines but generally worse than PiFlow.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_performance</strong></td>
                            <td>Validated via surrogates; MPO produced validated outcomes inferior to PiFlow per AUC/SQ.</td>
                        </tr>
                        <tr>
                            <td><strong>false_positive_rate</strong></td>
                            <td>not reported</td>
                        </tr>
                        <tr>
                            <td><strong>false_negative_rate</strong></td>
                            <td>not reported</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_novelty</strong></td>
                            <td>MPO's fixed plan-like guidance can be agnostic to scientific principles and may not adapt well when plans fail; no explicit per-novelty metrics reported.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_validation_comparison</strong></td>
                            <td>MPO generates plans but lacks PiFlow's algorithmic principle-level selection; as a result, validation yields lower AUC/SQ in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>Not described for MPO</td>
                        </tr>
                        <tr>
                            <td><strong>calibration_quality</strong></td>
                            <td>not reported</td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td>Not explicitly measured.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_proxy_metrics</strong></td>
                            <td>Surrogate validation metrics used (AUC/SQ).</td>
                        </tr>
                        <tr>
                            <td><strong>human_validation_required</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>human_validation_frequency</strong></td>
                            <td>unspecified</td>
                        </tr>
                        <tr>
                            <td><strong>formal_verification_used</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>domain_formalization_level</strong></td>
                            <td>empirical</td>
                        </tr>
                        <tr>
                            <td><strong>gap_mitigation_strategies</strong></td>
                            <td>MPO attempts to mitigate via learned planning; PiFlow empirically outperforms it via explicit information-theoretic tradeoffs.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_supporting_gap</strong></td>
                            <td>MPO's inferior AUC/SQ indicates learned planning alone may not sufficiently align generation with validation under high epistemic uncertainty.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_contradicting_gap</strong></td>
                            <td>None provided.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_ratio</strong></td>
                            <td>Not specified.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2077.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e2077.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or automated systems that generate novel outputs (scientific hypotheses, molecules, proofs, predictions) and how those outputs are validated, including performance metrics, false positive rates, and differences between generation and validation capabilities.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Hypothesis–Validation MAS</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Hypothesis–Validation Multi-Agent System (Hypothesis Agent, Experiment Agent, Planner Agent)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The core agent loop used in experiments: a Hypothesis Agent proposes a single, testable hypothesis (grounded in a principle), an Experiment Agent executes a single experiment (calls a surrogate validator), and a Planner (informed by PiFlow) coordinates the loop.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Hypothesis–Validation MAS</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>LLM-based multi-agent system (role-based agents)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>materials, chemistry, superconductors (applied across domains)</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>scientific hypotheses (single testable candidate per iteration) and experimental candidates</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_level</strong></td>
                            <td>variable — novelty depends on principles/hypotheses proposed by LLM(s) and PiFlow steering</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>LLM Hypothesis Agent uses principle text and Planner directives to produce a single testable hypothesis and experimental candidate (one experiment per iteration)</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td>Experiment Agent executes the candidate via surrogate model (f*(·)) and reports numeric outcomes to the trajectory T_t; Planner and PiFlow update principle scores accordingly.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_performance</strong></td>
                            <td>Performance aggregated as AUC and SQ across tasks when agents are used with and without PiFlow (see PiFlow/Vanilla metrics).</td>
                        </tr>
                        <tr>
                            <td><strong>validation_performance</strong></td>
                            <td>Depends on surrogate quality; validation outcomes feed back to PiFlow and Planner to influence subsequent generation.</td>
                        </tr>
                        <tr>
                            <td><strong>false_positive_rate</strong></td>
                            <td>not reported</td>
                        </tr>
                        <tr>
                            <td><strong>false_negative_rate</strong></td>
                            <td>not reported</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_novelty</strong></td>
                            <td>System enforces single-hypothesis-per-iteration constraint to reduce noise; PiFlow improves the yield of validated high-quality outputs despite LLM stochasticity.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_validation_comparison</strong></td>
                            <td>Paper emphasizes separation of responsibilities (Hypothesizer proposes, Experimenter validates) to maintain rigorous loop; generation capability (many hypotheses) still outpaces physical validation, motivating PiFlow's principle-level selection.</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>Historical trajectory T_t used to estimate exploitation/exploration scores; mutual-information proxies used for uncertainty-driven exploration.</td>
                        </tr>
                        <tr>
                            <td><strong>calibration_quality</strong></td>
                            <td>not reported</td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td>Demonstrated recovery from poor initialization and incorrect principles in ablations; no formal OOD error metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_proxy_metrics</strong></td>
                            <td>AUC and SQ (computed from surrogate outputs) measure end-to-end generation+validation performance.</td>
                        </tr>
                        <tr>
                            <td><strong>human_validation_required</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>human_validation_frequency</strong></td>
                            <td>unspecified</td>
                        </tr>
                        <tr>
                            <td><strong>formal_verification_used</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>domain_formalization_level</strong></td>
                            <td>empirical</td>
                        </tr>
                        <tr>
                            <td><strong>gap_mitigation_strategies</strong></td>
                            <td>PiFlow steering imposed on the MAS reduces wasted validation by prioritizing informative hypotheses; enforced design of single-experiment-per-iteration reduces combinatorial validation waste.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_supporting_gap</strong></td>
                            <td>The necessity of PiFlow and the relative poor performance of Unguided MAS demonstrate that raw multi-agent generation can produce many low-value hypotheses that burden validation.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_contradicting_gap</strong></td>
                            <td>When combined with surrogate validators and PiFlow, the MAS achieves high validated outcomes, indicating the gap can be narrowed in-silico.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_ratio</strong></td>
                            <td>Not provided; token consumption stats show PiFlow-MAS used fewer tokens than Vanilla in NHO and lower overall costs in some tasks (Table 7).</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Chemtoolagent: The impact of tools on language agents for chemistry problem solving. <em>(Rating: 2)</em></li>
                <li>React: Synergizing reasoning and acting in language models. <em>(Rating: 2)</em></li>
                <li>Mpo: Boosting llm agents with meta plan optimization. <em>(Rating: 2)</em></li>
                <li>Darwin series: Domain specific large language models for natural science. <em>(Rating: 1)</em></li>
                <li>Atomagents: Alloy design and discovery through physics-aware multi-modal multi-agent artificial intelligence. <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2077",
    "paper_id": "paper-278782614",
    "extraction_schema_id": "extraction-schema-53",
    "extracted_data": [
        {
            "name_short": "PiFlow",
            "name_full": "PiFlow: Principle-Aware Scientific Discovery Framework",
            "brief_description": "A plug-and-play information-theoretic controller for LLM-based multi-agent scientific discovery that selects and scores natural-language 'principles' via a Min–Max optimization balancing cumulative regret (exploitation) and information gain (exploration), and steers hypothesis generation accordingly.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "PiFlow",
            "system_type": "decision-theoretic controller + multi-agent framework (Min–Max optimization using LLM embeddings as proxies)",
            "scientific_domain": "materials science, chemistry, drug discovery (multi-domain / domain-agnostic)",
            "output_type": "scientific principles (natural-language), hypothesis steering commands (explore/validate/refine)",
            "novelty_level": "moderately novel (algorithmic: new principle-level Min–Max selection; outputs are novel recombinations of LLM knowledge guided by information-theoretic objective)",
            "generation_method": "selects or refines textual scientific principles (proposed by LLM agents or experts) and issues directives that bias subsequent hypothesis generation; selection uses a Min–Max adversarial objective approximated by a weighted sum of (1) exploitation scores computed from past outcomes and (2) exploration scores approximated by semantic distance between principle embeddings.",
            "validation_method": "integrated Hypothesis–Validation loop using external experiment agents that call surrogate validation functions (high‑fidelity simulators / ML surrogate models); PiFlow uses the resulting principle–outcome trajectory T_t to re-score principles and guide future generation.",
            "generation_performance": "Empirical generation/steering performance reported via task metrics: NHO AUC=63.51% ±11.18, SQ=76.82% ±4.54; MBO AUC=46.11% ±16.25, SQ=84.55% ±29.63; SPO AUC=21.51% ±2.80, SQ=34.85% ±1.19 (24-step runs, reported in Table 1 and Table 5). These metrics reflect the quality of generated candidates when guided by PiFlow.",
            "validation_performance": "Validation is performed by surrogate models with reported predictive quality: NHO surrogate r^2≈0.98; MBO surrogate r^2≈0.91; SPO surrogate r^2≈0.91. The reported SQ and AUC are computed against these surrogate validation outputs; no separate precision/recall etc. for validation of PiFlow outputs are provided.",
            "false_positive_rate": "not reported (no explicit FPR provided). The paper does not report the rate at which generated candidates declared promising were invalidated by validation; only aggregate AUC/SQ metrics are given.",
            "false_negative_rate": "not reported (no explicit FNR provided).",
            "performance_vs_novelty": "No direct numeric breakdown by novelty; conceptually, PiFlow is designed so validation performance (lower regret, higher SQ) improves as information gain falls — empirical evidence shows sublinear average regret (fitted T^{-0.5}, c=1.37, r^2=0.96) and a positive association between information gain and regret. The paper reports PiFlow recovers from deliberately incorrect (novel but false) initial principles, indicating robustness as novelty increases, but does not quantify validation accuracy as a function of novelty.",
            "generation_validation_comparison": "Paper explicitly discusses a generation/validation asymmetry: LLM agents can generate many principles/hypotheses quickly (high generation capability) while real-world validation is expensive; in experiments, validation is approximated via surrogate models so validation throughput is high, but the authors note that this is a proxy and that true wet-lab validation lags generation. PiFlow aims to reduce this gap by prioritizing hypotheses expected to be informative (thus lowering wasted validation effort).",
            "uncertainty_quantification": "Yes — PiFlow's theoretical objective includes mutual information I(h_t; f* | H_{t-1}) and uses proxies: semantic-distance of principle embeddings as a surrogate for information gain; empirical traces of information gain vs regret are plotted. The system tracks information-gain proxies and regret over iterations.",
            "calibration_quality": "Not quantified numerically. The paper provides theoretical/regret alignment and empirical curves (regret vs iterations) but does not report calibration metrics (e.g., reliability diagrams) for confidence estimates of generated hypotheses.",
            "out_of_distribution_performance": "Qualitative examples: PiFlow found high-performing out-of-structure candidates in experiments (e.g., nanohelix g-factor ≈1.6, molecule pChEMBL ≈7.24, superconductor T_c ≈103 K). No formal OOD numeric benchmark is provided; robustness ablations show recovery from deliberately incorrect initial principles (Expert-Incorrect) indicating adaptive OOD robustness but no explicit OOD error rates.",
            "validation_proxy_metrics": "Yes — the system relies on proxy metrics: surrogate-model outputs (high‑fidelity ML/simulator r^2) as ground-truth for validation; and for exploration, semantic-distance in LLM embedding space is used as a proxy for mutual information (information gain). AUC and SQ are composite metrics that assess generation+validation over time.",
            "human_validation_required": true,
            "human_validation_frequency": "Recommended for real-world deployment; in the experiments validation used automated surrogates only. The paper explicitly notes real-world lab validation is prohibitively expensive and implies that human/experimental validation would be necessary for final candidates — frequency unspecified but would increase with claim novelty and domain risk.",
            "formal_verification_used": false,
            "domain_formalization_level": "empirical (drug discovery, materials science) — semi-formal models (surrogates) used for validation; the empirical nature increases the generation-validation gap relative to highly formal domains like mathematics.",
            "gap_mitigation_strategies": "Min–Max adversarial selection of principles (balances exploitation/regret minimization and exploration/information gain); semantic-distance driven exploration to prioritize novel but informative principles; thresholded actions (refine/validate/explore) to avoid wasted validation; plug-and-play integration with existing experiment agents and surrogates to streamline validation. Ablations show improved AUC/SQ and recovery from incorrect principles, demonstrating effectiveness.",
            "evidence_supporting_gap": "Authors document: (1) LLM hallucinations and aimless hypothesizing in prior work; (2) high variance in agent trajectories (large std in baseline results), indicating generation variability; (3) the need to use surrogate models because real validation is expensive; (4) examples where unguided agents (Vanilla) explore aimlessly with poor AUC (e.g., Vanilla AUC in NHO 35.96% vs PiFlow 63.51%), implying generation alone does not ensure validated discoveries.",
            "evidence_contradicting_gap": "Within the surrogate-experiment setting, PiFlow's integration with automated validation yields consistent improvements in validated outcomes (higher SQ/AUC), suggesting that when high‑fidelity automated validators are available, the generation–validation gap can be largely closed in silico. The paper does not provide evidence of generation strictly outpacing validation in the surrogate setting.",
            "computational_cost_ratio": "Not directly quantified as a numeric ratio. Notes: PiFlow per-decision complexity O(t^2 * d) (dominated by embedding similarity calculations) but can be optimized; PiFlow reduced token consumption by up to ~27% vs Vanilla and itself contributes only ~1.2–1.5% of tokens. Validation cost in experiments is low because surrogate models are used; authors emphasize wet-lab validation would be substantially more expensive (no numeric ratio provided).",
            "uuid": "e2077.0"
        },
        {
            "name_short": "QwenMax",
            "name_full": "QwenMax (foundation LLM used by agents)",
            "brief_description": "A large language model employed as the base LLM for Hypothesis and Experiment agents in PiFlow experiments; used both for generating principle/hypothesis text and computing sentence embeddings for semantic-distance proxies.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "QwenMax",
            "system_type": "large language model (LLM)",
            "scientific_domain": "general-purpose LLM applied to materials, chemistry, biology tasks",
            "output_type": "natural-language principles, hypotheses, prompts, and embeddings",
            "novelty_level": "in-distribution to moderately novel — generates recombined textual principles from pretraining knowledge; novelty dependent on prompts and PiFlow steering",
            "generation_method": "autoregressive LLM sampling conditioned on Planner/Prompt and PiFlow directives; generates candidate principles and natural-language hypotheses",
            "validation_method": "LLM outputs are validated via the external Hypothesis–Validation loop (surrogate model evaluations); QwenMax also provides embeddings for PiFlow's exploration proxy.",
            "generation_performance": "When used with PiFlow, runs achieved reported system AUC/SQ (e.g., PiFlow overall metrics where QwenMax served as base: NHO AUC 63.51% SQ 76.82%); standalone LLM generation quality not separately quantified.",
            "validation_performance": "Not applicable for LLM itself; validation performed by surrogate models. No numeric validation performance for QwenMax-proposed hypotheses alone.",
            "false_positive_rate": "not reported for QwenMax-generated hypotheses",
            "false_negative_rate": "not reported",
            "performance_vs_novelty": "Paper reports model-choice sensitivity: QwenMax achieved highest AUC (63.51%) among models tested, indicating model selection affects generation quality, but no per‑novelty breakdown.",
            "generation_validation_comparison": "LLM generates many candidate principles/hypotheses quickly; validation throughput depends on surrogate; paper highlights mismatch between rapid generation and costly real-world validation (surrogates hide real gap).",
            "uncertainty_quantification": "QwenMax embeddings used as proxy for semantic distance; no calibrated uncertainty outputs (probabilities/certainty estimates) reported for generated hypotheses.",
            "calibration_quality": "not reported",
            "out_of_distribution_performance": "Not explicitly reported; ablations across different LLMs show performance variance (Tables 9), suggesting differing OOD robustness.",
            "validation_proxy_metrics": "Uses embedding-based semantic distance (from QwenMax) as a proxy for information gain; embeddings are central to exploration scoring.",
            "human_validation_required": true,
            "human_validation_frequency": "unspecified",
            "formal_verification_used": false,
            "domain_formalization_level": "empirical (applied to experimental domains)",
            "gap_mitigation_strategies": "Combined with PiFlow steering and surrogate validation to reduce wasted validation effort.",
            "evidence_supporting_gap": "LLM-driven hypotheses alone (Vanilla Agent using same LLM) performed poorly compared to PiFlow-guided runs, demonstrating that LLM generation needs strategic steering to yield validated discoveries.",
            "evidence_contradicting_gap": "When integrated with PiFlow and good surrogates, QwenMax enabled high validated outcomes, indicating generation can be reconciled with validation in-silico.",
            "computational_cost_ratio": "Not provided (token consumption data given globally: PiFlow reduces token consumption by up to 27% and PiFlow token share 1.2–1.5%).",
            "uuid": "e2077.1"
        },
        {
            "name_short": "Surrogate Models",
            "name_full": "High-fidelity surrogate validation models (DFT-trained ML and GNN/LightGBM surrogates)",
            "brief_description": "Task-specific surrogate models stood in for wet‑lab/DFT experiments to validate hypotheses: LightGBM for nanohelix g-factor (r^2≈0.9802), GNN for molecular bioactivity (r^2≈0.91), and a surrogate for superconductors (r^2≈0.91); these were used as the f*(·) validation functions in experiments.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "surrogate validation models (LightGBM, GNN, supervised ML)",
            "system_type": "machine-learning surrogate models / simulators",
            "scientific_domain": "materials science (nanohelix), drug discovery (bioactivity), superconductor prediction",
            "output_type": "numeric property predictions (g-factor, pChEMBL, T_c)",
            "novelty_level": "in-distribution for training/test splits; used as ground-truth proxies rather than generative novelty",
            "generation_method": "N/A (these models validate candidate outputs produced by the generative agents)",
            "validation_method": "Direct prediction of target property for each candidate hypothesis; these predictions are treated as validation outcomes in the Hypothesis–Validation loop",
            "generation_performance": "N/A",
            "validation_performance": "Reported surrogate predictive quality: NHO LightGBM r^2≈0.9802; MBO GNN r^2≈0.91; SPO surrogate r^2≈0.91. These high r^2 values are reported as justification for using surrogates as validation proxies.",
            "false_positive_rate": "not reported (depends on domain thresholding; paper reports SQ and AUC computed relative to theoretical maximums rather than FP/FN rates)",
            "false_negative_rate": "not reported",
            "performance_vs_novelty": "Surrogates are trained on available data and may underperform on extreme OOD candidates; the paper acknowledges surrogates are approximations and that exact real-world validation could differ, but does not quantify degradation vs novelty.",
            "generation_validation_comparison": "Surrogates provide rapid validation enabling many iterations; paper emphasizes this inflates validation throughput compared to real-world wet-lab, so generation/validation balance in silico is not representative of physical experiments.",
            "uncertainty_quantification": "Not extensively reported; r^2 provided as global fit metric. The paper does not report per-prediction uncertainty intervals or calibrated uncertainties from surrogates.",
            "calibration_quality": "Not reported (no calibration curves or predictive intervals provided).",
            "out_of_distribution_performance": "Not quantified; authors caution that surrogates are proxies and that real-world validation could reveal discrepancies for highly novel candidates.",
            "validation_proxy_metrics": "Primary validation proxies are surrogate model predicted values (used to compute SQ, AUC).",
            "human_validation_required": true,
            "human_validation_frequency": "Suggested for final confirmation of high-value candidates (frequency not specified).",
            "formal_verification_used": false,
            "domain_formalization_level": "empirical (data-driven surrogate models reflecting experimental/DFT outputs)",
            "gap_mitigation_strategies": "Use high-quality surrogates (high r^2) to reduce wasted real experiments; incorporate PiFlow to prioritize informative experiments, thereby reducing validation burden.",
            "evidence_supporting_gap": "Paper explicitly notes 'direct hypothesis validation in real-world labs is prohibitively expensive' and uses surrogates for validation; this highlights the validation-resource bottleneck versus generation speed.",
            "evidence_contradicting_gap": "High surrogate r^2 suggests in-silico validation is strong; within the simulated environment generation and validation are well aligned.",
            "computational_cost_ratio": "Not given as a numeric ratio; surrogate validation is treated as low-cost in experiments, while authors emphasize real-world (wet-lab) validation would be orders of magnitude more expensive.",
            "uuid": "e2077.2"
        },
        {
            "name_short": "ChemToolAgent",
            "name_full": "ChemToolAgent (tool-enabled chemistry agent)",
            "brief_description": "An existing tool-integrated agent for chemistry tasks that PiFlow was integrated with in a plug-and-play manner; used as both Hypothesizer and Experimenter in an 8-iteration integration demonstrating PiFlow's generalizability.",
            "citation_title": "Chemtoolagent: The impact of tools on language agents for chemistry problem solving.",
            "mention_or_use": "use",
            "system_name": "ChemToolAgent",
            "system_type": "tool-augmented multi-agent LLM system",
            "scientific_domain": "chemistry / drug discovery",
            "output_type": "candidate molecular designs (SMILES), natural-language principles",
            "novelty_level": "moderately novel (generates new molecule proposals guided by tools and LLM reasoning)",
            "generation_method": "LLM + specialized chemical tools (e.g., database lookups) to produce molecule candidates and principles",
            "validation_method": "In the integration run, validated via surrogate bioactivity predictor (pChEMBL); ChemToolAgent's built-in tools were used for candidate checking; PiFlow provided EXPLORE/REFINE directives to guide iterations.",
            "generation_performance": "Integration run produced a molecule with reported pChEMBL ≈5.90 after 8 iterations (Table 6); in broader MBO experiments PiFlow found pChEMBL ≈7.24.",
            "validation_performance": "Validated in-silico by the MBO surrogate (r^2≈0.91); no per-candidate FP/FN rates provided.",
            "false_positive_rate": "not reported",
            "false_negative_rate": "not reported",
            "performance_vs_novelty": "Not explicitly quantified. Integration shows PiFlow can steer tool-enabled agents to improved validated outputs without architecture modifications.",
            "generation_validation_comparison": "ChemToolAgent can generate candidates aided by tools; PiFlow improved the strategic selection and thus improved validated outcomes (pChEMBL increase over naive runs).",
            "uncertainty_quantification": "Not reported for ChemToolAgent itself; PiFlow's proxies used to guide exploration.",
            "calibration_quality": "not reported",
            "out_of_distribution_performance": "Not reported",
            "validation_proxy_metrics": "Relies on surrogate pChEMBL predictions and tool checks (e.g., plausibility/validity of SMILES).",
            "human_validation_required": true,
            "human_validation_frequency": "unspecified",
            "formal_verification_used": false,
            "domain_formalization_level": "empirical (chemistry/drug discovery)",
            "gap_mitigation_strategies": "PiFlow provides strategic guidance (EXPLORE/REFINE) to focus ChemToolAgent on informative searches, reducing wasted validation effort.",
            "evidence_supporting_gap": "Authors note PiFlow guided ChemToolAgent to a pChEMBL=5.90 without architecture changes, demonstrating that strategic steering improves validated outcomes where tool-enabled generation alone might be inefficient.",
            "evidence_contradicting_gap": "Successful plug-and-play integration suggests when good validators and tools exist, generation+validation can be effectively coupled in-silico.",
            "computational_cost_ratio": "Not specified; integration run used 8 iterations and surrogate validation; PiFlow token overhead small (~1.2–1.5%).",
            "uuid": "e2077.3"
        },
        {
            "name_short": "Bayesian Optimization (BO)",
            "name_full": "Bayesian Optimization (baseline optimizer)",
            "brief_description": "A classical black-box optimization baseline that requires a manually defined parameterized search space; compared to PiFlow across tasks to assess performance under epistemic uncertainty.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "Bayesian Optimization",
            "system_type": "sequential model-based optimizer (Gaussian process or surrogate-based BO)",
            "scientific_domain": "optimization for materials/molecular design",
            "output_type": "candidate parameter vectors / molecular suggestions (if parameterized)",
            "novelty_level": "in-distribution/structured-search — typically conservative exploration within a predefined parameter space",
            "generation_method": "acquisition-function-driven search (e.g., expected improvement) over a manually engineered parameter space",
            "validation_method": "evaluated using the same surrogate validation models as PiFlow in the experiments",
            "generation_performance": "Reported in Table 5: NHO BO AUC=68.86% ±5.86, SQ=78.76% ±0.77 (competitive on structured NHO task); MBO BO AUC=34.76% ±4.21, SQ=31.61% ±0.19 (much worse than PiFlow on MBO); SPO BO AUC=38.15% ±4.02, SQ=32.38% ±0.32.",
            "validation_performance": "Same surrogate validators used; performance reported above is BO's validated outcomes.",
            "false_positive_rate": "not reported",
            "false_negative_rate": "not reported",
            "performance_vs_novelty": "BO is strong on structured, well-parameterized tasks (NHO) but underperforms on ill-structured, combinatorial/discrete tasks (MBO) where PiFlow's principle-level shifts achieve domain-shifting jumps; no numeric novelty-dependent validation metrics reported.",
            "generation_validation_comparison": "BO's generation (proposals) is constrained by manually defined search space and tends to require domain engineering; PiFlow can do domain-shifting leaps via principle reasoning, leading to better validated outcomes on ill-structured tasks.",
            "uncertainty_quantification": "BO inherently quantifies uncertainty via surrogate predictive distributions (GP variance), but the paper does not report BO calibration metrics.",
            "calibration_quality": "not reported",
            "out_of_distribution_performance": "BO performs poorly when good parametrization is missing (MBO). PiFlow outperforms BO in such cases.",
            "validation_proxy_metrics": "BO uses surrogate-model predicted objective as validation signal in experiments.",
            "human_validation_required": true,
            "human_validation_frequency": "unspecified",
            "formal_verification_used": false,
            "domain_formalization_level": "varies — BO requires a well-formalized parameterization; performance degrades in poorly formalized empirical spaces.",
            "gap_mitigation_strategies": "BO mitigates generation-validation gap via principled uncertainty sampling, but needs hand-crafted search spaces; PiFlow offers an alternative by operating at principle level to reduce wasted validation.",
            "evidence_supporting_gap": "Comparative results show BO's reliance on expert parameterization can limit validated discovery in ill-structured problems (MBO) where PiFlow excels.",
            "evidence_contradicting_gap": "BO is competitive or superior on well-structured tasks (NHO), indicating that in some domains validation can keep up with generation when the search space is well defined.",
            "computational_cost_ratio": "Not specified.",
            "uuid": "e2077.4"
        },
        {
            "name_short": "Vanilla Agent System",
            "name_full": "Vanilla LLM-based Multi-Agent System (no PiFlow strategic layer)",
            "brief_description": "A baseline multi-agent system using the same LLM and experiment tools but without PiFlow's principle-aware strategic steering; demonstrates performance floor of unguided generation.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "Vanilla Agent System",
            "system_type": "LLM-based multi-agent system (roleplay agents) without principled strategic layer",
            "scientific_domain": "materials, chemistry, superconductors (same tasks as PiFlow)",
            "output_type": "natural-language hypotheses and candidate parameterizations/molecules",
            "novelty_level": "variable — LLM-driven novelty but unguided, often aimless",
            "generation_method": "roleplaying LLM agents generate hypotheses based on prompts without PiFlow steering",
            "validation_method": "same surrogate validators as PiFlow",
            "generation_performance": "Table 1 reports baseline (Vanilla) performance: NHO AUC=35.96% ±22.38, SQ=46.76% ±7.29; MBO AUC=29.71% ±12.66, SQ=49.22% ±8.30; SPO AUC=11.39% ±11.33, SQ=14.16% ±13.37 — high variance and lower average performance than PiFlow.",
            "validation_performance": "Validation via surrogates; validated outputs were poorer on average vs PiFlow as shown by AUC/SQ.",
            "false_positive_rate": "not reported",
            "false_negative_rate": "not reported",
            "performance_vs_novelty": "High variance indicates many generated outputs are low quality or lead to cumulative error; PiFlow's higher AUC suggests guided generation yields higher validated yield especially early in runs.",
            "generation_validation_comparison": "Unguided generation outpaces useful validation (many generated hypotheses are low-value), resulting in low validated yield and high variance in trajectories.",
            "uncertainty_quantification": "No explicit uncertainty-tracking mechanism described for Vanilla system beyond stochastic LLM outputs.",
            "calibration_quality": "not reported",
            "out_of_distribution_performance": "Poorer than PiFlow; no explicit OOD metrics.",
            "validation_proxy_metrics": "Relies on same surrogate models for validation; AUC/SQ used to compare validated results.",
            "human_validation_required": true,
            "human_validation_frequency": "unspecified",
            "formal_verification_used": false,
            "domain_formalization_level": "empirical",
            "gap_mitigation_strategies": "None intrinsic; PiFlow is proposed to mitigate the generation-validation inefficiency observed here.",
            "evidence_supporting_gap": "Vanilla's poor AUC and high variance are presented as evidence that raw LLM generation without principled steering produces many uninformative hypotheses that waste validation budget.",
            "evidence_contradicting_gap": "None provided.",
            "computational_cost_ratio": "Token usage: Vanilla consumed more tokens than PiFlow; PiFlow-MAS reduced token consumption by up to ~27% relative to Vanilla (Table 7).",
            "uuid": "e2077.5"
        },
        {
            "name_short": "ReAct",
            "name_full": "ReAct: Reasoning and Acting LLM agent method",
            "brief_description": "A baseline agentic method combining chain-of-thought reasoning with actions for stepwise hypothesis generation and tool use; used as one baseline in comparisons.",
            "citation_title": "React: Synergizing reasoning and acting in language models.",
            "mention_or_use": "use",
            "system_name": "ReAct",
            "system_type": "LLM agent method (reasoning + action loop)",
            "scientific_domain": "general-purpose agentic reasoning applied to scientific discovery tasks in experiments",
            "output_type": "natural-language reasoning traces and candidate hypotheses/actions",
            "novelty_level": "in-distribution/derivative of LLM capabilities; structured reasoning rather than novel discovery mechanism",
            "generation_method": "LLM produces alternating reasoning (chain-of-thought) and action outputs to propose experiments",
            "validation_method": "Generated experiments are validated by surrogates in the paper's experiments",
            "generation_performance": "Table 1: ReAct baseline performance: NHO AUC=35.85% ±7.12, SQ=41.96% ±0.82; MBO AUC=29.61% ±9.74, SQ=43.11% ±9.98; SPO AUC=5.29% ±0.69, SQ=6.41% ±0.96 — lower than PiFlow.",
            "validation_performance": "Validated via surrogate models; ReAct's validated outputs inferior to PiFlow's as measured by AUC/SQ.",
            "false_positive_rate": "not reported",
            "false_negative_rate": "not reported",
            "performance_vs_novelty": "No explicit breakdown; the paper remarks that explicit chain-of-thought can cause cognitive fixation, and ablations showed disabling explicit 'Think' sometimes improved performance, suggesting ReAct-like explicit reasoning may hurt exploration of novel hypotheses.",
            "generation_validation_comparison": "ReAct's generation (explicit reasoning + action) can lead to local fixation and lower validated yields compared to PiFlow's principled exploration/exploitation trade-off.",
            "uncertainty_quantification": "Not central to ReAct; no explicit uncertainty quantification reported in experiments.",
            "calibration_quality": "not reported",
            "out_of_distribution_performance": "Not specifically reported.",
            "validation_proxy_metrics": "Uses surrogate validation same as others.",
            "human_validation_required": true,
            "human_validation_frequency": "unspecified",
            "formal_verification_used": false,
            "domain_formalization_level": "empirical",
            "gap_mitigation_strategies": "No specific strategies beyond ReAct's built-in reasoning/action structure; PiFlow shown empirically to outperform ReAct.",
            "evidence_supporting_gap": "ReAct baseline's lower AUC/SQ and susceptibility to chain-of-thought fixation are used to motivate need for PiFlow-style strategic guidance.",
            "evidence_contradicting_gap": "Not provided.",
            "computational_cost_ratio": "Not specified.",
            "uuid": "e2077.6"
        },
        {
            "name_short": "MPO",
            "name_full": "Meta Plan Optimization (MPO)",
            "brief_description": "A baseline that uses a trained LLM planner to provide high‑level guidance; compared to PiFlow to evaluate explicit structured strategic guidance vs learned planner-based guidance.",
            "citation_title": "Mpo: Boosting llm agents with meta plan optimization.",
            "mention_or_use": "use",
            "system_name": "MPO (Meta Plan Optimization)",
            "system_type": "trained LLM planner (policy/plan-level model)",
            "scientific_domain": "general-purpose planning applied to scientific discovery",
            "output_type": "high-level plans/checklists for agent actions",
            "novelty_level": "incremental (learned planner over LLM capabilities)",
            "generation_method": "trained planner LLM outputs stepwise plans that guide agents",
            "validation_method": "Plans lead to hypotheses validated by surrogate models in experiments",
            "generation_performance": "Table 1: MPO baseline: NHO AUC=43.99% ±2.79, SQ=51.29% ±7.77; MBO AUC=31.18% ±9.12, SQ=57.28% ±5.85; SPO AUC=12.68% ±7.75, SQ=33.20% ±23.75. Performance better than some baselines but generally worse than PiFlow.",
            "validation_performance": "Validated via surrogates; MPO produced validated outcomes inferior to PiFlow per AUC/SQ.",
            "false_positive_rate": "not reported",
            "false_negative_rate": "not reported",
            "performance_vs_novelty": "MPO's fixed plan-like guidance can be agnostic to scientific principles and may not adapt well when plans fail; no explicit per-novelty metrics reported.",
            "generation_validation_comparison": "MPO generates plans but lacks PiFlow's algorithmic principle-level selection; as a result, validation yields lower AUC/SQ in experiments.",
            "uncertainty_quantification": "Not described for MPO",
            "calibration_quality": "not reported",
            "out_of_distribution_performance": "Not explicitly measured.",
            "validation_proxy_metrics": "Surrogate validation metrics used (AUC/SQ).",
            "human_validation_required": true,
            "human_validation_frequency": "unspecified",
            "formal_verification_used": false,
            "domain_formalization_level": "empirical",
            "gap_mitigation_strategies": "MPO attempts to mitigate via learned planning; PiFlow empirically outperforms it via explicit information-theoretic tradeoffs.",
            "evidence_supporting_gap": "MPO's inferior AUC/SQ indicates learned planning alone may not sufficiently align generation with validation under high epistemic uncertainty.",
            "evidence_contradicting_gap": "None provided.",
            "computational_cost_ratio": "Not specified.",
            "uuid": "e2077.7"
        },
        {
            "name_short": "Hypothesis–Validation MAS",
            "name_full": "Hypothesis–Validation Multi-Agent System (Hypothesis Agent, Experiment Agent, Planner Agent)",
            "brief_description": "The core agent loop used in experiments: a Hypothesis Agent proposes a single, testable hypothesis (grounded in a principle), an Experiment Agent executes a single experiment (calls a surrogate validator), and a Planner (informed by PiFlow) coordinates the loop.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Hypothesis–Validation MAS",
            "system_type": "LLM-based multi-agent system (role-based agents)",
            "scientific_domain": "materials, chemistry, superconductors (applied across domains)",
            "output_type": "scientific hypotheses (single testable candidate per iteration) and experimental candidates",
            "novelty_level": "variable — novelty depends on principles/hypotheses proposed by LLM(s) and PiFlow steering",
            "generation_method": "LLM Hypothesis Agent uses principle text and Planner directives to produce a single testable hypothesis and experimental candidate (one experiment per iteration)",
            "validation_method": "Experiment Agent executes the candidate via surrogate model (f*(·)) and reports numeric outcomes to the trajectory T_t; Planner and PiFlow update principle scores accordingly.",
            "generation_performance": "Performance aggregated as AUC and SQ across tasks when agents are used with and without PiFlow (see PiFlow/Vanilla metrics).",
            "validation_performance": "Depends on surrogate quality; validation outcomes feed back to PiFlow and Planner to influence subsequent generation.",
            "false_positive_rate": "not reported",
            "false_negative_rate": "not reported",
            "performance_vs_novelty": "System enforces single-hypothesis-per-iteration constraint to reduce noise; PiFlow improves the yield of validated high-quality outputs despite LLM stochasticity.",
            "generation_validation_comparison": "Paper emphasizes separation of responsibilities (Hypothesizer proposes, Experimenter validates) to maintain rigorous loop; generation capability (many hypotheses) still outpaces physical validation, motivating PiFlow's principle-level selection.",
            "uncertainty_quantification": "Historical trajectory T_t used to estimate exploitation/exploration scores; mutual-information proxies used for uncertainty-driven exploration.",
            "calibration_quality": "not reported",
            "out_of_distribution_performance": "Demonstrated recovery from poor initialization and incorrect principles in ablations; no formal OOD error metrics.",
            "validation_proxy_metrics": "AUC and SQ (computed from surrogate outputs) measure end-to-end generation+validation performance.",
            "human_validation_required": true,
            "human_validation_frequency": "unspecified",
            "formal_verification_used": false,
            "domain_formalization_level": "empirical",
            "gap_mitigation_strategies": "PiFlow steering imposed on the MAS reduces wasted validation by prioritizing informative hypotheses; enforced design of single-experiment-per-iteration reduces combinatorial validation waste.",
            "evidence_supporting_gap": "The necessity of PiFlow and the relative poor performance of Unguided MAS demonstrate that raw multi-agent generation can produce many low-value hypotheses that burden validation.",
            "evidence_contradicting_gap": "When combined with surrogate validators and PiFlow, the MAS achieves high validated outcomes, indicating the gap can be narrowed in-silico.",
            "computational_cost_ratio": "Not provided; token consumption stats show PiFlow-MAS used fewer tokens than Vanilla in NHO and lower overall costs in some tasks (Table 7).",
            "uuid": "e2077.8"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Chemtoolagent: The impact of tools on language agents for chemistry problem solving.",
            "rating": 2
        },
        {
            "paper_title": "React: Synergizing reasoning and acting in language models.",
            "rating": 2
        },
        {
            "paper_title": "Mpo: Boosting llm agents with meta plan optimization.",
            "rating": 2
        },
        {
            "paper_title": "Darwin series: Domain specific large language models for natural science.",
            "rating": 1
        },
        {
            "paper_title": "Atomagents: Alloy design and discovery through physics-aware multi-modal multi-agent artificial intelligence.",
            "rating": 1
        }
    ],
    "cost": 0.02688975,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>PIFLOW: PRINCIPLE-AWARE SCIENTIFIC DISCOVERY WITH MULTI-AGENT COLLABORATION
29 Sep 2025</p>
<p>Yingming Pu puyingming@westlake.edu.cn 
Westlake University</p>
<p>Zhejiang University</p>
<p>Tao Lin lintao@westlake.edu.cn 
Westlake University</p>
<p>Hongyu Chen 
Westlake University</p>
<p>PIFLOW: PRINCIPLE-AWARE SCIENTIFIC DISCOVERY WITH MULTI-AGENT COLLABORATION
29 Sep 20254F713FDD384AC04AC4B03B23021AAF14arXiv:2505.15047v2[cs.LG]
Large Language Model (LLM)-based multi-agent systems (MAS) demonstrate remarkable potential for scientific discovery.Existing approaches, however, often automate scientific discovery using predefined workflows that lack rationality constraints.This often leads to aimless hypothesizing and a failure to consistently link hypotheses with evidence, thereby hindering the systematic reduction of uncertainty.Overcoming these limitations fundamentally requires a principled approach to exploration.We introduce PiFlow, an information-theoretical framework, treating automated scientific discovery as a structured uncertainty reduction problem guided by principles (e.g., scientific laws).In evaluations across three distinct scientific domains -discovering nanomaterial structures, bio-molecules, and superconductor candidates with targeted properties -our method significantly improves discovery efficiency, reflected by a 73.55% increase in the Area Under the Curve (AUC) of property values versus exploration steps, and enhances solution quality by 94.06% compared to a vanilla agent system.Overall, PiFlow serves as a Plug-and-Play method, establishing a novel paradigm shift in highly efficient automated scientific discovery, paving the way for more robust and accelerated AI-driven research.</p>
<p>INTRODUCTION</p>
<p>Large Language Model (LLM)-based Multi-Agent Systems (MAS) have significantly impacted automated scientific discovery (Minaee et al., 2024;Wang et al., 2023;Zhang et al., 2024c) across a wide range of fundamental fields, including chemistry (Liu et al., 2024;Ghafarollahi &amp; Buehler, 2024a;Yang et al., 2024c;Inoue et al., 2024), biology (Xiao et al., 2024;Nagarajan et al., 2025;Averly et al., 2025;Ghafarollahi &amp; Buehler, 2024b), physics (Jaiswal et al., 2024), and material science (Takahara et al., 2025;Ghafarollahi &amp; Buehler, 2025;Ansari et al., 2024;Wan et al., 2024;Zhang et al., 2024b).</p>
<p>Although proficient in executing experiments within predefined workflows (Lu et al., 2024;Lai &amp; Pu, 2025), these systems often generate hypotheses that lack clear direction, leading to the uncertainty establishing clear links between hypotheses and their supporting or refuting evidence (AI4Science &amp; Quantum, 2023; Zhou et al., 2024;Baek et al., 2024;Schmidgall et al., 2025;Prabhakar et al., 2025;Xie et al., 2023a).Such a disconnect indicates inefficient exploration.Moreover, many of these approaches are tailored for specific tasks, often relying on meticulous prompt engineering that heavily incorporates domain knowledge (as detailed in Appendix D).Consequently, their ability to adapt to new scientific domains is often limited without substantial modifications (Zhang et al., 2025;Kumbhar et al., 2025).These issues culminate in three primary challenges: (a) aimless hypothesizing; (b) unmaintained connections between hypotheses and evidence during exploration, hindering systematic validation and (c) limited generalization ability, where systems effective in one scenario (e.g., material science) often require substantial rework to be applicable in others.</p>
<p>To address these limitations, we introduce PiFlow, an information-theoretic framework for structured uncertainty reduction in scientific discovery.Viewing scientific exploration as a game against an unknown and challenging nature, where robust strategies are paramount, PiFlow employs Min-Max Principle ( )
p i
Figure 1: Illustration of the potential of a scientific principle in drug discovery.PiFlow directs exploration to prioritize hypotheses aligned with high-potential principles (or their variants), thereby iteratively guiding the discovery towards optimal candidate molecules.</p>
<p>optimization: minimizing cumulative regret for exploitation, while maximizing information gain for efficient hypothesis exploration.As a Plug-and-Play module, PiFlow integrates with MAS capable of hypothesizing and experimentation.Inspired by the challenge of navigating vast hypothesis spaces, PiFlow operates by using fundamental scientific principles, which may be initially proposed by or refined using LLMs.</p>
<p>The iterative selection of principles progressively reduces uncertainty in hypothesizing and the interpretation of evidence, dynamically steering exploration by prioritizing those scientific principles that offer the highest instructive value for continued exploration.Figure 1 illustrates PiFlow's method for assessing and utilizing scientific principles within a drug discovery context.</p>
<p>This principle-aware approach yields systematic information gain: PiFlow selects high-potential principles and then guides hypothesizing via three actions, i.e., exploring, validating, or refining their scope and formulation.Thus, PiFlow progressively optimizes its guiding scientific principles to effectively steer hypothesizing.Furthermore, leveraging its Min-Max optimization, PiFlow theoretically achieves cumulative regret growth of O( √ T ) over T exploration steps (a detailed proof is provided in Appendix F).This sublinear regret underscores its guaranteed efficiency in navigating complex discovery landscapes.In summary, our contributions are:</p>
<p>(a) We propose a novel paradigm for principle-aware scientific discovery, built upon an information-theoretical foundation that offers convergence guarantees.</p>
<p>(b) We develop PiFlow, a Plug-and-Play framework that seamlessly integrates with existing MAS to enable focused exploration, thereby enhancing discovery efficiency and flexibility.</p>
<p>(c) We conduct extensive experiments across three distinct scenarios, demonstrating the broad applicability and significant performance improvements achieved by PiFlow.</p>
<p>RELATED WORK</p>
<p>LANGUAGE MODELS FOR SCIENTIFIC DISCOVERY</p>
<p>Recently, large language models (LLM) have advanced scientific discovery with automation and rational design (Ren et al., 2025;Ma et al., 2024).The internal knowledge of LLMs has demonstrated promising capability in focused chemical and material discovery (Yang et al., 2024c;Zhou et al., 2024;Pu et al., 2024;Ghafarollahi &amp; Buehler, 2024c).While tool-integrated LLMs like SciAgents (Ghafarollahi &amp; Buehler, 2024d), DARWIN (Xie et al., 2023a) and HoneyComb (Zhang et al., 2024a) improve domain-specific reasoning and recall of factual insights, they still struggle to integrate physicochemical laws effectively when refining insights for design, risking biased proposals and inefficient exploration due to inherent hallucinations of LLMs (Zhang et al., 2023b).Human-AI frameworks address this issue by leveraging the knowledge of domain experts (Reddy &amp; Shojaee, 2024; Eythorsson &amp; Clark, 2025), yet remain limited to the scope of hypothesis generation (Alkan et al., 2025), leading to insufficient exploration of complex chemical spaces (Luo et al., 2025).Surveys highlight persistent gaps in efficiency and interpretability (Zhang et al., 2024c;Han et al., 2024), underscoring the need for principled scientific discovery management beyond automated LLM reasoning (Ramos et al., 2024).</p>
<p>APPROACHES OF MULTI-AGENT COLLABORATION</p>
<p>Multi-agent systems (MAS) show promise for complex tasks (Lu et al., 2024;Ghafarollahi &amp; Buehler, 2024d;Ni &amp; Buehler, 2023), yet their application to scientific discovery reveals limitations in current collaboration mechanisms (Tran et al., 2025).Rule-based methods (Zhang et al., 2023a) offer consistency but their predefined rules lack the flexibility to incorporate nuanced scientific principles (e.g., physicochemical laws) or adapt to unexpected findings, hindering dynamic exploration.Roleplaying approaches (Tran et al., 2025;He et al., 2024) leverage agent expertise, yet rigid roles can impede adaptation in scientific research (Ramirez-Medina et al., 2025;Lu et al., 2024;Ghafarollahi &amp; Buehler, 2024d), and ensuring collective adherence to scientific principles when interpreting experimental insights is challenging.Model-based methods (Xu et al., 2023;Mu et al., 2023;Li et al., 2023) aim for adaptability by learning from uncertainty, but struggle to build world models that accurately capture complex scientific phenomena and integrate guiding laws (Hao et al., 2023), thereby impairing the balance between information perception and strategic, principle-guided reasoning.</p>
<p>Consequently, existing MAS paradigms often lack a dedicated awareness and systematic application of scientific principles during hypothesis generation and refinement (Gridach et al., 2025;Luo et al., 2025;Reddy &amp; Shojaee, 2024;Su et al., 2024).This highlights a critical need for an explicitly principle-aware multi-agent collaboration framework.Our work addresses this gap, proposing a method where the collaborative discovery process is robustly guided by scientific principles to achieve more efficient and reliable outcomes.</p>
<p>METHODOLOGY</p>
<p>OVERVIEW</p>
<p>We propose a principle-aware MAS designed to enhance scientific discovery via focused hypothesizing and structured exploration of hypothesis-evidence connections.Figure 2 illustrates the architecture.Its core comprises a Hypothesis-Validation loop that iteratively generates and tests hypotheses.PiFlow guides this loop by optimizing accumulated principle-outcome data.Strategic insights dynamically optimized by PiFlow are relayed through a Planner agent (A P ) to the Hypothesis Agent within the loop.Subsequent sections will elaborate on PiFlow's specific architecture and its information-theoretical underpinnings.</p>
<p>ARCHITECTURE</p>
<p>Our proposed principle-aware system leverages LLM-based MAS to conduct scientific discovery through strategic hypothesizing.The framework is comprised of two core, interconnected components:</p>
<p>(1) an MAS that executes a Hypothesis-Validation loop, and (2) PiFlow, which serves as the strategic director for this loop.Definition 3.1 (Scientific Principles).The scientific principles are foundational concepts, established laws, or patterns, articulated as natural language statements, that explain phenomena within a specific scientific domain.These principles serve as high-level conceptual building blocks from which specific, testable hypotheses can be derived.This conceptualization aligns with broader discussions on the nature of scientific knowledge (Poincaré, 1906).</p>
<p>Hypothesis-Validation Loop.As depicted in the right-hand side of Figure 2, the Hypothesis-Validation loop constitutes the core operational cycle and incorporates two LLM-based agents: Hypothesis Agent (A H ) and Experiment Agent (A E ), detailed below:</p>
<p>(a) Hypothesis.Initially, a set of dynamically growing candidate principles P = {p 1 , p   This iterative process progressively establishes a record of principle-outcome pairs, T t = {⟨p k , y k ⟩} t k=1 , linking each hypothesized principle p k to its observed experimental outcome y k .While this loop systematically generates valuable evidence in trajectory T t , the selection of potential principles for subsequent hypotheses can lack strategic direction if not externally guided.This may lead to inefficient exploration of the principle space or premature convergence on suboptimal findings.</p>
<p>Hypothesis steering with PiFlow.To address the potential inefficiencies in principle selection and to instill strategic direction, the PiFlow component is introduced.It leverages the dynamically growing set of principle-outcome pairs, T t as its primary input.Two steps are conducted to steer the hypothesizing:</p>
<p>(a) High-potential principle acquisition.After an initial phase of evidence collection, during which T t is populated, PiFlow activates its core mechanism: an adversarial Min-Max optimization (detailed in Section 3.3).This optimization process analyzes T t to identify a principle, p * (e.g., p 2 in Figure 2), predicted to balance the exploitation and exploration, i.e., have the highest potential, for advancing the scientific inquiry.(b) Principle steering for hypothesizing.Following the identification of the highest-potential principle p * by the Min-Max optimization, PiFlow assigns a potential score to all principles in P.This scoring enables a threshold-based partitioning: principles with high scores (e.g., p ′ 2 ) drive refinement; those with medium scores trigger further validation (p 2 → p ′ 2 ); and low scores prompt exploration of new conceptual areas.This closed-loop feedback mechanism ensures that the Hypothesis-Validation cycle is continuously and adaptively steered by strategic insights derived from the system's cumulative experience, as embodied in T t .We provide a detailed analysis of the distinction from prompt engineering at Appendix E, and an illustrative example at Appendix H.</p>
<p>Plug-and-Play Modularity of PiFlow.The hypothesis steering mechanism above, which includes PiFlow and its interfacing Planner agent A P , has been intentionally engineered as a modular, Plug-and-Play system.This architectural choice ensures that principle-aware guidance can be readily integrated to enhance MAS engaged in scientific discovery as a part of prompts.As demonstrated in Appendix K, we successfully integrate PiFlow with existing ChemToolAgent (Yu et al., 2024) without any architecture modifications.This adaptability positions PiFlow as a pivotal enhancement for automated scientific inquiry.</p>
<p>MIN-MAX OPTIMIZATION IN PIFL O W</p>
<p>In our proposed method, strategic principle selection is achieved through a Min-Max optimization, as presented in Eq. 1.This approach is designed to balance the exploitation of established, high-potential principles (which then guide the formulation of specific hypotheses) with the exploration of novel ones, while explicitly incorporating information acquisition efficiency:
min π∈Π max f * ∈F E π T t=1 (v * − f * (h t )) − λ • I(h t ; f * |H t−1 )(1)
where π ∈ Π represents the decision-making policy for selecting principles and f * ∈ F is the evaluation function (e.g., an experimental tool) that characterizes the quantitative outcome yielded from hypothesis h t ∈ H, where H is the hypothesis space.Over T iterations, the policy π aims to minimize the objective function in Eq. 1.This objective strategically balances: (1) the summation for cumulative regret, encouraging exploitation of known high-potential principles, and (2) the mutual information, thereby effectively maximizing information gain to foster exploration.This structure allows PiFlow to navigate the complex trade-offs between these two goals.</p>
<p>Minimizing cumulative fegret (exploitation).The first term,
T t=1 (v * − f * (h t ))
, represents the cumulative regret over T iterations.Here, v * is a theoretical optimal outcome value, and f * (h t ) is the outcome from hypothesis h t .By minimizing this term, the policy π is driven to exploit known high-potential principles and hypotheses to achieve outcomes as close as possible to the optimum v * .This encourages the refinement and validation of promising avenues.</p>
<p>Maximizing information gain (exploration).</p>
<p>The second term −λ • I(h t ; f * |H t−1 ) promotes exploration.The policy π seeks to minimize this term, which is equivalent to maximizing the mutual information I(h t ; f * |H t−1 ).This mutual information quantifies the expected reduction in uncertainty about the true evaluation function f * upon observing the outcome of hypothesis h t , given all past observations
H t−1 = {(h m , y m )} t−1 m=1 .
The trade-off parameter λ &gt; 0 controls the balance between minimizing regret (exploitation) and maximizing information gain (exploration).A larger λ places more emphasis on information acquisition.</p>
<p>Remark (The dependencies of f * in I(h t ; f * |H t−1 )) .The informativeness of a proposed hypothesis h t is inherently dependent on the nature of the true underlying evaluation function f * .The adversarial nature of the max f * operator means that the policy π must select hypotheses h t that are expected to be informative even if f * were to manifest in a way that makes h t minimally revealing, thus ensuring robustness in information acquisition.</p>
<p>Building upon the theoretical framework above, we derive a computationally tractable algorithm (Algorithm 1) that serves as a principled approximation of the abstract Min-Max objective in Eq. 1.The full rationale and derivation for this approximation are detailed in Appendix G.</p>
<p>In summary, the Min-Max adversarial formulation underpinning PiFlow provides strong theoretical guarantees, notably sublinear regret bounds (formalized in Theorem 1, with proof in Appendix F).Importantly, its operational behavior, which involves practical approximations of this Min-Max solution, demonstrates consistent alignment with these theoretical expectations, as empirically validated in Section 5.4.</p>
<p>Theorem 1 (Informal).The Min-Max optimization in PiFlow formulates a trade-off between exploitation (minimizing regret) and exploration (maximizing information gain).Under conditions of finite entropy H(f * ) and bounded evaluation function f * , this optimization provides two key theoretical guarantees: (1) As information gain decreases, the expected regret also decreases; (2) the cumulative regret grows at a sublinear rate of O √ T .</p>
<p>EXPERIMENT</p>
<p>SETTINGS</p>
<p>To rigorously evaluate the effectiveness and versatility of our PiFlow framework, we conducted experiments across three distinct scientific discovery scenarios.While direct hypothesis validation in real-world labs is prohibitively expensive, we employ high-fidelity surrogate models deployed locally, which serve as the primary evaluation tool.Across all scenarios (Section 4.2), we frame the scientific discovery challenge as a unified task: "Find a candidate in a complex parameter space that maximizes a target property (e.g., bio-activity)."</p>
<p>To ensure a fair comparison and focus on core capabilities, all agents utilize QwenMax (Yang et al., 2024a) as the base LLM and are prohibited from accessing external search tools.The complete experimental setup is detailed in Appendix S, and the role-playing prompts for PiFlow are provided in Appendix T.</p>
<p>EXPERIMENTAL SCENARIOS</p>
<p>To comprehensively assess PiFlow's performance, we design three scenarios that represent canonical challenges in scientific exploration: optimization in continuous, discrete, and mixed parameter spaces:</p>
<p>Nanohelix Optimization (NHO).We use a surrogate model (r 2 = 0.98) trained on DFT-simulated data following Wu et al. (2025) to predict nanohelix chirality from four continuous geometric parameters, enabling efficient exploration of the design space (Appendix S.1).</p>
<p>Molecular Bio-activity Optimization (MBO).We build a surrogate model (r 2 = 0.91) to predict bio-activity from SMILES strings, trained on 50,000 molecules from ChEMBL35 (Zdrazil et al., 2023).This facilitates high-throughput screening in a discrete chemical space.(Appendix S.2).</p>
<p>Superconductor Optimization (SPO).Following Hamidieh (2018), we train a surrogate model (r 2 = 0.91) to map a material's mixed continuous and discrete compositional features to its critical temperature (T c ), accelerating the discovery of room-temperature superconductors.(Appendix S.3).</p>
<p>BASELINES</p>
<p>To evaluate the strategic guidance of PiFlow under uncertainty, we therefore benchmark against the following baselines: (1) Reasoning and Acting (ReAct) (Yao et al., 2022).ReAct enables agents to iteratively formulate hypotheses, design/execute experiments, and interpret results.It represents a foundational approach to structured reasoning.(2) Meta Plan Optimization (MPO) (Xiong et al., 2025).MPO employs a trained LLM planner that provides high-level, general guidance.This serves as a direct counterpoint to PiFlow's explicit, structured mechanism for principled uncertainty reduction.</p>
<p>(3) Vanilla Agent System (Vanilla).This baseline consists of an MAS operating without any principled strategic oversight.It is intended to establish a performance floor, demonstrating the limitations of unguided exploration reliant solely on agent role-playing.</p>
<p>While other advanced frameworks exist, such as Agent-Oriented Planning (AOP) (Li et al., 2024) and Reason for Future, Act for Now (RAFA) (Liu et al., 2023), their design objectives diverge from the scope of our evaluation.AOP is optimized for tasks with well-defined structures rather than initial epistemic uncertainty, while RAFA focuses on completing predefined goals rather than the iterative, de novo evidence-gathering process central to PiFlow.Therefore, our curated selection of baselines is specifically designed to isolate and evaluate our contribution to discovery efficiency in uncertain environments.</p>
<p>EVALUATION METRICS</p>
<p>Two metrics are employed to evaluate the performance of PiFlow, as detailed below:</p>
<p>Solution Quality (SQ).We measure the optimal objective value with a percentage relative to the theoretical maximum value µ absolute , denoted as:
SQ = max{y k | ⟨p k , y k ⟩ ∈ T t } µ absolute × 100%.(2)
Specifically, for NHO, the theoretical maximum is reported as µ g-factor absolute = 2.0 following Greenfield et al. (2021).The larger the g-factor, the stronger the chirality.For MBO, a strict threshold of µ pchembl absolute = 6.5 has been reported (Lenselink et al., 2017) for lead compound optimization stage, larger value indicates a higher bio-activity and vice versa.For SPO, the reference value is set to be 25 • C , which is equal to room temperature 298.15K, denoted as µ Tc absolute = 298.15K.Area Under the Curve (AUC).Exploration efficiency requires both (1) rapid convergence and (2) high objective values.We quantify these two factors by defining the AUC metric.Given the trajectory ⟨p k , y k ⟩ ∈ T t across t steps, AUC is computed via the trapezoidal rule.For meaningful  comparisons, we normalize by the maximum possible area:
AUC = t−1 i=1 yi+yi+1 2 µ absolute • (t − 1) × 100%(3)
In summary, SQ measures the quality of the final outcome, while AUC evaluates the entire discovery process by rewarding both speed and consistency.The detailed rationale for these metric designs is provided in Appendix R.2.</p>
<p>RESULTS</p>
<p>PERFORMANCE COMPARISON</p>
<p>We use SQ to compare the overall capability of reaching the objective solution, and AUC to assess the efficiency, reflecting progress towards better outcomes over the exploration process.</p>
<p>Table 1 demonstrates that PiFlow achieves significant improvements over all baselines across three benchmarks of NHO, MBO, and SPO.In terms of achieving the target property, measured by SQ, PiFlow consistently leads, outperforming ReAct, MPO, and Vanilla systems by an average of approximately 207.6%, 34.1%, and 94.1%.Additionally, as shown in Figure 3, PiFlow is always the fastest one in reaching the best solution while exploring.More details about models' response analysis can be seen at Appendix I.</p>
<p>It is worth noting the considerable std observed in our results.This variance is inherent to the stochastic nature of LLM-based agents and can be attributed to the phenomenon of cumulative error.An early suboptimal decision or flawed hypothesis can set an agent on an inefficient discovery trajectory, with reasoning errors compounding over subsequent iterations.This instability highlights why relying solely on the final SQ can be insufficient.In contrast, the AUC provides a more holistic performance measure.A high AUC, as consistently demonstrated by PiFlow, indicates that the agent not only found a high-quality solution but also maintained a robust and efficient path, thereby successfully mitigating the primary risk of cumulative error.</p>
<p>Takeaway: PiFlow substantially outperforms all baselines in SQ and exploration efficiency (AUC).Its strategic robustness is evidenced by its high AUC, which mitigates the cumulative errors of LLMs, and by its success from modest starting points that simulate realistic initial uncertainty (see Appendix P.2).</p>
<p>Preprint.Under review.</p>
<p>ABLATION STUDY</p>
<p>We conduct several ablations to evaluate PiFlow.For these studies, conducted on the NHO task, performance is evaluated based on the same metrics, AUC (%) and SQ (%).</p>
<p>Plug-and-Play.To isolate the direct benefit of PiFlow, we compared the performance with two different LLMs, GPT4.1-mini and Qwen3-32B under the setting of w/ and w/o PiFlow.This is achieved by only including or excluding the steered principle to the Planner Agent via prompt, which then directs subsequent hypothesizing and validation.</p>
<p>As shown in Thought Mode Effect.</p>
<p>We also conduct ablations on the internal thought mode of the LLM (referred to as Think in Table 3).This is for agents based on Qwen3-32B and Qwen3-8B models, which support ON/OFF <think>...</think> generation with system prompt including or excluding /no_think.This mode is intended to enable more explicit reasoning steps.Interestingly, for both Qwen3-32B and Qwen3-8B, disabling the Thought Mode leads to improved performance, as shown at Table 3.We hypothesize that this phenomenon is due to cognitive fixation.As the key issue is, how do LLM propose scientific hypothesis, forcing the LLM to generate an explicit Chain-of-Thought may cause it to commit prematurely to its own initial line of reasoning.If the first step in its logic is flawed, the entire chain can be led astray, creating a cognitive fixation that is hard to escape.In contrast, disabling the think mode may force the model to rely more on its powerful, holistic pattern-matching capabilities, allowing it to make more intuitive leaps directly from the data (PiFlow's guidance and the experimental history) to a hypothesis, bypassing potentially flawed intermediate reasoning steps.</p>
<p>Takeaway: Our ablations confirm PiFlow is a robust, plug-and-play enhancement that consistently boosts performance across models.Concurrently, we find that an agent's internal reasoning is critical: disabling explicit "Think" modes paradoxically improves performance, suggesting that avoiding cognitive fixation allows the LLM to better leverage holistic pattern-matching.This highlights the synergy between high-level strategic guidance from PiFlow and internal reasoning.</p>
<p>FURTHER ANALYSES OF ROBUSTNESS</p>
<p>We conducted extensive analyses to probe the robustness and practical utility of PiFlow.The key findings are as follows:</p>
<p>Recovery from poor initialization.The system demonstrates resilience by successfully recovering from deliberately incorrect initial principles, eventually matching the performance of a run guided by correct initialization.This underscores the robustness of the Min-Max (Appendix P).</p>
<p>Temporal dynamics of principle evaluation.PiFlow continuously re-evaluates the utility of scientific principles as new evidence is gathered.This allows it to dynamically discard initially promising but ultimately flawed avenues while elevating principles that prove more fruitful later, showcasing an adaptive balance between exploration and exploitation (Appendix N).</p>
<p>Superior performance against numerical search.On complex tasks with ill-defined search spaces, PiFlow substantially outperforms Bayesian Optimization, achieving an SQ of 84.55% versus BO's 38.15% in the MBO task, without requiring manual parameter space engineering (Appendix J).Seamless plug-and-play integration.We validate the practicality of PiFlow through a successful integration with ChemToolAgent (Yu et al., 2024), guiding it to a high-value molecule (pChEMBL of 5.90) without requiring any architectural modifications (Appendix K).</p>
<p>Manageable computational complexity.The core decision mechanism of PiFlow has a computational complexity of O(t 2 • d), where t = |T t | and d is the embedding dimension.This could be optimized to near-linear time for large-scale tasks (Appendix L).</p>
<p>Cost-effectiveness.Superior performance is achieved cost-effectively, reducing token consumption by up to 27% compared to the Vanilla Agent.PiFlow constitutes only 1.5% tokens (Appendix M).</p>
<p>Generalizability and controllability.PiFlow is compatible with various LLMs, and its behavior can be tuned via the λ hyperparameter, for which we provide a clear heuristic (Appendices O, Q).</p>
<p>THEORETICAL ALIGNMENT</p>
<p>To empirically validate the theoretical guarantees (Theorem 1) of PiFlow, we analyze key aspects of its exploration dynamics, including (1) the bound of average regret and (2) the relationship between regret and information gain, as shown in Figure 4.</p>
<p>(Theoretical Prediction 1) Average regret decay with O 1 √ T .Figure 4a presents the average regret as a function of iterations on a log-log scale.The alignment evidenced by average regret trajectories adhering to the T −0.5 decay (fitted c • T −0.5 with c = 1.37, r 2 = 0.96), a pattern most runs consistently follow.Notably, one run (ID=1), after an initial sharp regret decrease, shows a transient increase before resuming decay.This illustrates PiFlow's robust exploration avoiding potential local optima with a characteristic of its Min-Max strategy.</p>
<p>(Theoretical Prediction 2) As information gain decreases, the expected regret also decreases.As shown in Figure 4b, the scatter plot of regret versus information gain (points colored by iteration) reveals a clear positive association, confirmed by a fitted trend line: lower information gain generally corresponds to lower regret.Early iterations (higher information gain and regret) transition to later iterations (lower information gain and regret).</p>
<p>Empirical validation of exploration strategy.Figure 4c displays the trajectory of PiFlow on the NHO objective landscape, which is visualized via Principal Component Analysis (PCA) with contours indicating g-factor values.The path demonstrates a principled strategy: initial broad exploration (iterations 1-16), followed by navigating a low-quality "valley" to escape a local optimum (iterations 16-21), and culminating in efficient convergence to a high-g-factor region (iterations 21-24).This progression empirically validates how our theoretical design translates into effective discovery.</p>
<p>Takeaway: Our empirical analysis corroborates the theoretical guarantees of PiFlow, demonstrating that its strategy is both principled and effective.The alignment of regret dynamics with the predicted sublinear rate and its coupling with information gain validates a robust mechanism that translates theoretical efficiency into a practical ability to escape local optima and converge reliably.</p>
<p>CONCLUSION</p>
<p>In conclusion, we propose PiFlow, a Plug-and-Play module to strategically guide the Hypothesis-Validation loop through a steering mechanism to address challenges of aimless hypothesizing and unclear connections between hypotheses and evidence.Our approach utilizes a Min-Max optimization that explicitly balances exploitation of high-potential principles with exploration of novel hypotheses, guaranteed by a sublinear average regret bound.Extensive experiments demonstrate that PiFlow can adaptively navigate complex hypothesis spaces without premature convergence on suboptimal solutions, yielding significant improvements over baselines.A detailed discussion of its current limitations and future potential is provided in Appendix C. We hope PiFlow can contribute to advancing automated scientific discovery, inspiring further exploration and innovation.</p>
<p>A USE OF LARGE LANGUAGE MODELS</p>
<p>We utilized a large language model to assist with proofreading and polishing the language in this manuscript.</p>
<p>B BROADER IMPACT</p>
<p>PiFlow addresses critical bottlenecks in AI-driven scientific discovery where uncertainty leads to aimless exploration.Our method innovatively frames discovery as a structured uncertainty reduction problem.By using an information-theoretic approach within a hypothesis-validation loop, PiFlow systematically filters for instructive scientific principles.Ultimately, PiFlow establishes a new paradigm for automated research, enabling more targeted exploration and accelerating the generation of impactful scientific insights.In Materials Discovery, it speeds the identification of novel compounds like advanced nanomaterials or superconductors, as shown in our tasks.For Biological Discovery, it enhances the search for effective molecules and the understanding of complex systems.Its principles promise similar advancements in other data-intensive fields, from chemistry to medical sciences, facing vast and uncertain hypothesis spaces.</p>
<p>C LIMITATION AND FUTURE WORK</p>
<p>While PiFlow shows notable improvements through its principled Min-Max optimization, its practical implementation approximates a key theoretical component.This means the current system may not fully capture all nuances of true, model-based information gain, especially the direct adversarial interplay with all possible manifestations of the unknown evaluation function f * from the theoretical objective.</p>
<p>Future research could explore more direct estimations of mutual information for this heuristic within the PiFlow framework to potentially further enhance its strategic guidance.Furthermore, we observed that disabling the LLM's "Thought Mode" surprisingly improves performance, suggesting that forced Chain-of-Thought can induce cognitive fixation.This finding motivates the development of more flexible reasoning frameworks for agents, aiming to better balance deliberate logic with intuitive generation.</p>
<p>D DETAILED METHODOLOGICAL REVIEW</p>
<p>A hallmark and fundamental limitation of many contemporary LLM-based agent systems in scientific discovery is their limited generalizability.As detailed in Table 4, these frameworks are often characterized by a tight coupling between their core logic and a specific scientific domain.This means their implementations, tool integrations, and most critically, their prompt engineering strategies are meticulously tailored for a single scenario, such as organic chemistry or materials science.Although systems like The AI Scientist (Lu et al., 2024) and Agent Laboratory (Schmidgall et al., 2025) demonstrate strong capabilities in scientific research, they are specifically designed for AI domain, along with a focus of the whole workflow rather than strategic decision-making problem.Consequently, transferring these systems to a new domain necessitates significant re-engineering, restricting their out-of-the-box applicability and hindering the development of truly universal systems.</p>
<p>In contrast, our PiFlow is designed to overcome this challenge by decoupling the strategic decision-making layer from the task execution layer.By architecting PiFlow as a domainagnostic, Plug-and-Play module, it provides strategic guidance to a minimal hypothesis-testing MAS without embedding domain-specific knowledge within its own logic.This architectural choice yields superior flexibility and obviates the need for extensive, domain-specific prompt engineering for the strategic component, enabling seamless adaptation across diverse scientific fields.</p>
<p>Take-away: PiFlow introduces a domain-agnostic, plug-and-play architecture by decoupling strategic decision-making from domain-specific execution.This design overcomes the critical generalizability limitations inherent in tightly-coupled scientific agent systems.Protein-protein interactions analysis (Ghafarollahi &amp; Buehler, 2025) Automating alloy design and discovery using physics-aware multimodal multi-agent AI Alloy design and discovery (Takahara et al., 2025) Accelerating inorganic materials design using generative AI agents.</p>
<p>Inorganic materials design LIDDIA (Averly et al., 2025) Language-based intelligent agent for drug discovery tasks.</p>
<p>Drug discovery dZiner (Ansari et al., 2024) Rational inverse design of materials facilitated by AI agents.</p>
<p>Inverse design of materials MOOSE-Chem (Yang et al., 2024c) Utilizing Large Language Models for rediscovering unseen chemistry scientific hypotheses.We define a scientific principle following Definition 3.1.Formally, each principle is represented as a structured text proposition that can be algorithmically scored by our MinMax optimization (as exampled in Figure 1).Unlike arbitrary text strings, these principles is supposed to be with logical consistency, and this structural requirement is what distinguishes them from general prompts.In short, principles represent foundational concepts or established patterns within a domain (e.g., "higher hydrophobicity often correlates with better cell membrane penetration").These "principles", whether has been validated or not, can be proposed by experts or, crucially, extracted from the LLM's own vast pre-trained knowledge.They serve as high-level starting points to generate specific, testable hypotheses.</p>
<p>The core distinction of our PiFlow from prompt engineering lies not in the format of the guidance (which is text), but in the algorithmic generation of that guidance:</p>
<p>• Prompt engineering baseline.The agent quickly became trapped in local optima.Its process was highly repetitive (e.g., repeatedly stating "The system's behavior is governed by the interplay..."), and it eventually stagnated, making only meaningless tweaks to the gfactor (e.g., 1.1012 → • • • → 1.1030).This demonstrates the limitation of a static, unguided hypothesis-testing loop.</p>
<p>• Systematic breakthroughs with PiFlow.In contrast, the PiFlow-guided agent demonstrated structured, cumulative learning:</p>
<ol>
<li>(Early 1 3 iterations) Principled exploration: It begins with diverse hypotheses to maximize information gain.2. (Medium stage) Discovery: It identified non-monotonic relationships (e.g., "deviations beyond an optimal configuration reduce chirality"), forming a natural language-based identification.3. (Late stage) Paradigm Shift: Ultimately, it synthesized the principle of "minimal radius + maximal turns + optimized pitch", causing a decisive shift in the search space from (fiber_radius=40, helix_radius=70) to (fiber_radius=20, helix_radius=20) and identifying the non-linear sensitivity of the pitch parameter.This unlocked the significant g-factor improvement (0.84 → 1.28 → 1.41 → 1.51).</li>
</ol>
<p>The core of PiFlow is to force the LLM to structure its disorganized internal knowledge into explicit, falsifiable hypotheses.The PiFlow then uses quantitative feedback from experiments to iteratively refine its understanding regarding the task.The value is not in feeding the LLM new knowledge, but in providing a strategic framework to systematically test and organize the knowledge it already possesses, yielding a loop of LLM Knowledge → External Evidence → Guided LLM Action, rather than LLM → LLM.</p>
<p>In summary, the algorithmic core lies in Equation 1and Algorithm 1: the Min-Max optimization systematically balances regret minimization with information gain maximization.This is operationalized through dynamic principle scoring that updates based on accumulated evidence T t = ⟨p k , y k ⟩k = 1 t .Advanced prompt engineering lacks this principled mathematical framework for evidence integration and strategic trade-offs.</p>
<p>Take-away: Instead of relying on static prompts that lead to local optima, PiFlow employs a Min-Max optimization to algorithmically generate and refine structured, falsifiable principles.By systematically integrating experimental feedback, it transforms the LLM's latent knowledge into a dynamic, self-correcting engine for scientific discovery, enabling cumulative learning and strategic breakthroughs.</p>
<p>F PROOF OF THE THEOREM</p>
<p>We recall the elements here and formally proof the convergence along with boundary of the system.</p>
<p>Here we denote π is the language model policy from policy space Π, f * is the acquisition function from function space F, h t is the hypothesis at time step t, H t−1 = {h 1 , h 2 , . . ., h t−1 } is the history of hypotheses, v * is the SQ achievable by any hypothesis, and
I(h t ; f * | H t−1 ) is the conditional mutual information.
According to the original formulation (Eq.1), the cumulative regret can be expressed as
R T (π, f * ) = E π T t=1 (v * − f * (h t ))
and the cumulative information gain is
IG T (π, f * ) = E π T t=1 I(h t ; f * |H t−1 )
Information gain approaches zero.With information theory, the mutual information can be written as:
I(h t ; f * |H t−1 ) = H(f * |H t−1 ) − H(f * |H t−1 , h t )
A critical property for convergence is that the total information gain is bounded,
∞ t=1 I(h t ; f * | H t−1 ) ≤ H(f * ) &lt; ∞
This follows from the chain rule of mutual information,
T t=1 I(h t ; f * | H t−1 ) = I(H T ; f * ) ≤ H(f * )
Since the entropy H(f * ) is finite, the cumulative information gain is bounded regardless of how many steps T we take.This implies that:
lim t→∞ I(h t ; f * | H t−1 ) = 0.
In other words, the marginal information gained from each new hypothesis must eventually approach zero.</p>
<p>As information gain decreases, the expected regret also decreases.As we mentioned before, the regret R T (π, f * ) is defined as:
R T (π, f * ) = E T [v * − f * (h t )]. Now apply Jensen's Inequality, let X = v * − f * (h t ), we have E[X 2 | H t−1 ] = E[(v * − f * (h t )) 2 | H t−1 ]. Use ϕ(x) = x 2 , as it is convex, giving (E[X | H t−1 ]) 2 ≤ E[X 2 | H t−1 ],
take square roots:
E[v * − f * (h t ) | H t−1 ] ≤ E[(v * − f * (h t )) 2 | H t−1 ].
Now we deal with the second moment of the regret.As the v * is constant, therefore, with the variance formula, we have
E (v * − f * (h t )) 2 | H t−1 = Var(f * (h t ) | H t−1 ) + (v * − E[f * (h t ) | H t−1 ]) 2
Both terms (variance and bias) are non-negative, and our goal is to bound this expression.The variance term Var(f * (h t ) | H t−1 ) captures the uncertainty in f * (h t ) given the history.</p>
<p>Since the information theory proofed that, the variance of a function can be bounded by mutual information, akin to entropy bounds H(f * ) ≤ log(|F |), for the first term, we have
Var(f * (h t ) | H t−1 ) ≤ c • I(h t ; f * | H t−1 ),
where c is constant that depends on the range of f * , this follows because the mutual information bounds the expected variance of conditional expectations.</p>
<p>Since we can direct view the f * (h t ) as a random variable over the joint distribution of f * and h t , we can apply a concentration inequality.A standard result in information-directed sampling states that for a bounded random variable like f * (h t ) here, the second moment of the regret (v * − f * (h t )) can be bounded as:
E (v * − f * (h t )) 2 | H t−1 ≤ c • I(h t ; f * | H t−1 ),
where the constant c depends on |F|.</p>
<p>Finally, we get the inequality of R T (π, f * ):
R T (π, f * ) ≤ E T [(v * − f * (h t )) 2 | H t−1 ] ≤ c • I(h t ; f * | H t−1 )
This inequality demonstrates that as the information gain I(h t ; f * | H t−1 ) decreases, the expected regret also diminishes.</p>
<p>The cumulative regret grows at a rate O( √ T ).Based on the inequality in the last step and to find the cumulative regret bound, we need to sum this inequality over all time steps:
T t=1 R t (π, f * ) ≤ c • T t=1 I(h t ; f * |H t−1 )
Applying the Cauchy-Schwartz inequality:
T t=1 I(h t ; f * |H t−1 ) ≤ T • T t=1 I(h t ; f * |H t−1 )
Since we've already established that the total information gain is bounded:
T t=1 I(h t ; f * |H t−1 ) ≤ H(f * )
We can substitute this bound:
T t=1 I(h t ; f * |H t−1 ) ≤ T • H(f * )
Therefore, the cumulative regret is bounded by:
T t=1 R t (π, f * ) ≤ c • T • H(f * )
This demonstrates that the cumulative regret grows at a rate of O( √ T ), which is sublinear in T .This result implies that while the total regret increases with step, the average regret per time step decreases at a rate of O( 1 √ T ).</p>
<p>G ALGORITHMIC REALIZATION OF THE MIN-MAX FRAMEWORK G.1 PRACTICAL PROXIES FOR REGRET AND INFORMATION GAIN</p>
<p>Algorithm 1 provides a computationally tractable implementation of the abstract Min-Max optimization strategy presented in Eq. 1.It translates the theoretical concepts of regret minimization (exploitation) and information gain maximization (exploration) into concrete, efficiently computable metrics, enabling PiFlow to guide the scientific discovery process effectively.The bridge between theory and practice is established as follows:</p>
<p>Approximating exploitation (minimizing cumulative regret).The theoretical objective of minimizing cumulative regret, T t=1 (v * − f * (h t )), is centered on favoring principles that consistently yield high-value outcomes f * (h).In our practical implementation, the compute_exploitation_scores function directly approximates this goal.It leverages the historical trajectory of principle-outcome pairs, T t = {⟨p k , y k ⟩} t k=1 .The observed outcome y k here serves as a direct proxy for the performance of its corresponding principle p k .A principle associated with higher outcomes is considered to have lower regret.Therefore, the resulting normalized score vector ranging from 0 to 1, S exploitation ∈ R |Tt| , quantifies the empirical success of each principle, and maximizing this score is equivalent to minimizing the cumulative regret based on past evidence.</p>
<p>Approximating exploration (maximizing information gain).The second term in our objective, maximizing the mutual information I(h t ; f * |H t−1 ), encourages the selection of hypotheses that are most informative about the underlying scientific landscape.A direct computation of mutual information is often intractable.Consequently, Algorithm 1 employs a practical proxy via the compute_exploration_scores function.This is achieved by analyzing the semantic diversity of principles using their sentence level embeddings (e.g., obtained from QwenMax model).We posit that principles which are semantically distant from those already tested are more likely to reveal novel information about the function f * .Therefore, we use the cosine distance between a candidate principle's embedding and the embeddings of previously explored principles as a heuristic for information gain.High exploration scores, S exploration ∈ R |Tt| , are assigned to conceptually novel principles.This heuristic is theoretically grounded, as detailed in Appendix G.2.</p>
<p>Algorithm 1 Algorithm of PiFlow.suggestion ← "Initialize one principle to explore."5: else 6: The integrated decision policy.The policy of the Min-Max framework, π, must balance the above objectives.Our algorithm materializes this policy through a two-step process:
S exploration ← compute_exploration_scores(T t ) 7: S exploitation ← compute_exploitation_scores(T t ) 8: for i ← 1 to |T t | do 9: S final [i] ← (1 − λ f actor ) • S exploration [i] + λ f actor • S exploitation [i]
1.</p>
<p>Step 1 (Scoring and selection).The final score,
S f inal [i] ← (1−λ f actor )•S exploration [i]+ λ f actor • S exploitation [i],
is a direct implementation of the balanced objective function.The input parameter λ f actor instantiates the theoretical trade-off, controlling the emphasis between exploration and exploitation.The arg max i (S f inal [i]) operation then executes the policy's primary function: selecting the most promising principle, p best , given the current state of knowledge and the desired strategic balance.</p>
<p>2.</p>
<p>Step 2 (Action recommendation).Finally, the policy translates its choice into a strategic command.The threshold-based conditions on the best principle's exploitation score (if best_exploitation_score &gt; 0.7 . . . ) discretize the continuous space of potential actions into three clear directives: refine, validate, or explore with the concatenation (denoted by ⌢) of the principle content.This transforms the numerical output of the optimization into an actionable suggestion for the Planner agent (A P ), thereby closing the loop between theoretical deliberation and practical execution within the Hypothesis-Validation cycle.</p>
<p>G.2 THE RATIONAL OF SEMANTIC DISTANCE AS A PROXY FOR INFORMATION GAIN</p>
<p>Recall that we introduce a Min-Max optimization framework for the PiFlow system.The objective function, as shown in Eq. 1, incorporates a mutual information term, I(h t ; f * |H t−1 ), to guide exploration.This term, while theoretically ideal, is computationally intractable as it requires knowledge of the true underlying evaluation function f * .In our practical implementation, we employ a surrogate objective for exploration: maximizing the distance of a new principle's text embedding from the embeddings of previously selected principles.Here, we provide a formal justification for this approximation, demonstrating its theoretical soundness.</p>
<p>Proof.Our goal is to establish a principled connection between the practical exploration strategy and the theoretical objective of maximizing information gain.The practical strategy is to select a principle p t from the principle space P at each timestep t according to:
p * t = arg max pt∈P min m∈{1,...,t−1} ∥ϕ(p t ) − ϕ(p m )∥ 2 (4)
where ϕ : P → R d is a function that maps a principle to its corresponding high-dimensional text embedding.We will now demonstrate that this objective serves as a valid proxy for maximizing the mutual information term I(h t ; f * |H t−1 ).</p>
<p>The derivation rests upon the hierarchical relationship between principles and hypotheses, and the semantic properties of modern language model embeddings.A principle p ∈ P is not a hypothesis itself, but rather defines a specific semantic region or a conditional distribution π(•|p) from which a concrete hypothesis h ∈ H is formulated.Thus, the selection of a principle p t precedes the generation of a hypothesis h t ∼ π(•|p t ).</p>
<p>We begin by positing two fundamental premises regarding the nature of the embedding space.</p>
<p>Premise 1 (Semantic-metric correspondence).The embedding function ϕ is assumed to map the conceptual space of principles to a metric space where distance reflects semantic dissimilarity.That is, for any two principles p i , p j ∈ P, a large Euclidean distance ∥ϕ(p i ) − ϕ(p j )∥ 2 implies a significant divergence in their underlying semantic and conceptual content.This is a well-established property of embeddings from large-scale language models.</p>
<p>Premise 2 (Functional consequence of semantic dissimilarity).Semantically distinct principles guide the generation of functionally distinct hypotheses.A hypothesis h acts as a probe of the unknown function f * .If two principles p i and p j are semantically distant, the hypotheses generated from their respective distributions, h i ∼ π(•|p i ) and h j ∼ π(•|p j ), are expected to probe disparate aspects or regions of the function f * .</p>
<p>With these premises, we can construct the logical argument.The mutual information term I(h t ; f * |H t−1 ) quantifies the expected reduction in uncertainty about f * after observing the outcome of hypothesis h t , given the history of observations H t−1 .As established in our convergence proof (Section F), this information gain is related to the posterior variance of the outcome of h t :
E (v * − f * (h t )) 2 | H t−1 ≤ c • I(h t ; f * | H t−1 )
This relation suggests that a hypothesis h t yielding high uncertainty (i.e., high posterior variance Var(f * (h t ) | H t−1 )) is expected to provide high information gain.Consequently, a sound exploration strategy is to select h t to maximize this variance.</p>
<p>Let us now connect this objective to our practical strategy in Eq. 4.</p>
<p>1.By selecting a principle p t that maximizes the minimum distance to all prior principles in the embedding space, we are, by Premise 1, choosing a principle that is maximally semantically novel compared to the history of principles {p m } t−1 m=1 .2. By Premise 2, this semantically novel principle p t will guide the generation of a hypothesis h t that probes a functionally distinct aspect of f * compared to all prior hypotheses in
H t−1 = {(h m , y m )} t−E[Var(f * (h t ) | H t−1 )] ⇒ max ht∼π(•|pt) E[I(h t ; f * | H t−1 )]
The expectation E[•] is taken over the generation of h t from p t .</p>
<p>In conclusion, the strategy of maximizing the minimum embedding distance between principles is not an arbitrary heuristic.It is a principled and computationally feasible surrogate for the theoreticallygrounded objective of maximizing mutual information.It leverages the semantic structure captured by modern language model embeddings to implement an efficient and effective exploration strategy, ensuring that PiFlow diversifies its inquiry at a conceptual level.This alignment between our practical approximation and the theoretical Min-Max framework provides support for the design of our system and its empirical performance.</p>
<p>Take-away: We operationalize the abstract Min-Max framework by substituting its theoreticallyideal but computationally-intractable objectives with practical proxies.Exploitation (regret minimization) is approximated by historical performance, while Exploration (information gain maximization) is driven by maximizing the semantic distance between principle embeddings.We formally prove that this semantic distance is a principled surrogate for maximizing information gain, thus bridging the gap between theory and efficient implementation.</p>
<p>H ILLUSTRATIVE EXAMPLE: APPLICATION TO NANOHELIX OPTIMIZATION</p>
<p>We provide a step-by-step walk-through of PiFlow's operation using the Nanohelix Optimization (NHO) task as a running example:</p>
<p>Let's assume the goal is to find the nanohelix geometry (described at Appendix S.1) with the maximum g-factor:</p>
<p>Phase 1: Initial Exploration.The process begins with an unguided hypothesis generation to build an initial evidence base by LLM itself.The Planner agent, following the initial directive of PiFlow, instructs the Hypothesis Agent for intuitive exploring (Algorithm 1, line 3-5).For the first K rounds (e.g., K = 3 in our experiments), the loop proceeds as follows, 1. Hypothesis Agent proposes a specific, testable hypothesis, "Based on the principle of • • • , measure the g-factor of a nanohelix with parameters: fiber_radius=40.0nm, he-lix_radius=70.0nm, n_turns=6.5,pitch=130.0nm".</p>
<ol>
<li>
<p>Experiment Agent calls the tool (surrogate model) to validate the above hypothesis and returns the outcome, "the validation yields a g-factor of 0.86".</p>
</li>
<li>
<p>This Hypothesis-Validation process repeats for K rounds, populating the evidence trajectory T t for establishing an initial principle pool.</p>
</li>
</ol>
<p>In the initial K rounds, lacking specific guiding principles, the Hypothesis Agent performs an initial exploration of the parameter space by proposing diverse geometries based on its general pre-trained knowledge, or by sampling from a wide distribution.</p>
<p>Phase 2: Principle-aware guidance from PiFlow.After the initial K rounds, the MinMax optimization of PiFlow parses these evidence and identifies the highest potential principle and suggests an action based on the score of the highest-potential principle (refer to Algorithm 1, line 5-23).The Planner agent receives this strategic guidance, for instance: "Refine the identified promising principle: By adjusting the fiber radius to twice the helix radius and fine-tuning other parameters, it is expected to maximize the chirality (g factor) of the nanohelix".</p>
<p>Structured, guided hypothesizing in both Phase 1 and Phase 2. The Planner injects this directive into the whole group chatting history, i.e., Hypothesizing-Validation loop, thereby reducing the system-level uncertainty.The Hypothesis Agent now uses this focused principle to formulate its next hypothesis with structured reasoning, for example:</p>
<ol>
<li>Major premise.The g-factor of a nanohelix is governed by the spatial asymmetry and electromagnetic coupling arising from its geometric parameters.</li>
</ol>
<p>2.</p>
<p>Minor premise 1.The previously tested geometry (fiber-radius=40 nm, helix-radius=70 nm, n-turns=6.5,pitch=130 nm) yielded a high g-factor ( 0.86), indicating a favorable parameter balance.</p>
<ol>
<li>
<p>Minor premise 2 (Inspired by PiFlow).Systematically varying parameters around this near-optimal point can induce nonlinear electromagnetic effects, potentially increasing chirality.Specifically, increasing the pitch and number of turns might enhance the chiral interaction length.</p>
</li>
<li>
<p>Proposed testable hypothesis."Measure the g-factor of a nanohelix with parameters: fiber_radius=49.0nm, helix_radius=24.5.0 nm, n_turns=7.0,pitch=140.0nm."</p>
</li>
</ol>
<p>By this way, PiFlow dynamically steers the discovery process away from aimless searching and towards a focused, principle-driven exploration, thereby systematically accumulating information and avoiding inefficient exploration directions.</p>
<p>Takeaway:</p>
<p>In this example, PiFlow transforms the optimization process from an initial, unguided exploration into a focused, principle-driven discovery.It first samples the parameter space to build an empirical evidence base, then distills a high-potential guiding principle to steer subsequent hypotheses, ensuring a systematic and efficient search for the optimal nanohelix geometry.</p>
<p>I ANALYSIS OF BASELINES RESPONSE</p>
<p>We compare our PiFlow against the ReAct, MPO and Vanilla Agent.Through the experiment, we found that the MPO baseline incorporates a form of global, step-by-step reasoning or reflection within their trained model, for example, it's exact output is, for example, "Step 1: Identify the task objective.</p>
<p>Step 2: Survey the environment.Backend these outputs, the performance difference stems from the level of dynamic and strategic guidance.For example, MPO's reasoning is local and tactical.It generates a fixed "how-to" checklist.This plan dictates the operational steps but is agnostic to the underlying scientific principles driving the experiments, and cannot reason about why its plan is failing, leading to hypotheses that yield lower outcomes.The Vanilla agent here uses the exact same powerful LLM (QwenMax) and has access to the same experimental tools.Its poor performance demonstrates that even a capable LLM, without strategic guidance, explores aimlessly.The dramatic performance gap between Vanilla and PiFlow (e.g., AUC improving from 35.96% to 63.51% in the NHO task) is direct evidence that our contributions, i.e., (a) structuring knowledge into an explicit principle space, and (b) applying a rigorous Min-Max optimization strategy to navigate it.</p>
<p>However, PiFlow adapts its learnable strategy.By optimizing (i.e., evaluating and selecting) at the principle level, PiFlow can make strategic jumps.When hypotheses derived from Principle A consistently fail, the Min-Max optimization quantitatively lowers the score of Principle A itself, guiding the agent to switch to a completely different research direction (Principle B).This prevents getting stuck and is the fundamental reason for its superior efficiency and performance, as demonstrated empirically in Figure 3.</p>
<p>Take-away: Baselines fail due to their reliance on rigid, tactical plans, which leads to aimless exploration when a strategy is ineffective.In contrast, PiFlow excels by operating at a higher level of abstraction.It reasons over a "principle space" and employs Min-Max optimization to strategically pivot away from failing research directions, enabling adaptive and efficient discovery.</p>
<p>J PERFORMANCE COMPARISON WITH BAYESIAN OPTIMIZATION</p>
<p>To validate our hypothesis that a principle-aware architecture is superior for scientific discovery under high epistemic uncertainty, we compared PiFlow against a strong, general-purpose baseline, Bayesian Optimization (BO).It is worth noting that, unlike PiFlow, BO requires significant expert effort to manually define a parameterized optimization space.We construct the experiment by manually configuring the searching space of BO in both nanohelix optimization (NHO) task, molecular bio-activity optimization task and superconductor optimization (SPO) task.  1, show that while BO is competitive on the structured NHO task, it strongly needs prior design of the searching space, e.g., material element composition and quantity range.However, PiFlow demonstrates a substantial performance advantage on the more complex and uncertain MBO task, highlighting its effectiveness when the problem structure is not known a priori.</p>
<p>In fact, PiFlow leverages scientific principles with its dynamic uncertainty reduction architecture.This framework allows the agent to make "domain-shifting" leaps in the search space (e.g., the jump from a 60nm to a 10nm radius value), leading to rapid, significant gains that are rewarded by the AUC metric.It is this ability to build and reason with an evolving knowledge structure that our evaluation framework was designed to highlight.</p>
<p>Take-away: PiFlow's principle-aware architecture significantly outperforms Bayesian Optimization on complex, ill-structured scientific discovery tasks (MBO).Its strength lies in dynamically building knowledge to navigate vast search spaces, whereas BO's performance is contingent on a manually-defined search space, rendering it only competitive on well-structured problems (NHO).</p>
<p>K PLUG-AND-PLAY INTEGRATION WITH CHEMTOOLAGENT</p>
<p>We integrate PiFlow with ChemToolAgent (Yu et al., 2024) on the Molecular Bio-activity Optimization (MBO) task to demonstrate the generalization of PiFlow.The integration follows a Plug-and-Play design, where PiFlow acts as a strategic guidance layer, as shown in Figure 5. Chem-ToolAgent serves as both the Hypothesizer and Experimenter, leveraging its built-in tools (such as searching molecules' formula from PubMed and website) to propose molecular hypotheses, while PiFlow's outer-loop guidance provided EXPLORE and REFINE commands to ensure systematic and efficient discovery dynamically.As shown in Table 6, this collaborative process successfully evolved its strategy from basic principles to a high-value molecular design (pChEMBL of 5.90) over 8 iterations without any architecture-level modifications over ChemToolAgent, demonstrating a clear synergy.L THEORETICAL COMPUTATIONAL COMPLEXITY Let t be the current number of iterations (i.e., the size of the historical trajectory) and d be the embedding dimension of the principles.A single decision step in PiFlow (Algorithm 1) involves:</p>
<ol>
<li>
<p>Computing exploitation scores.This requires iterating through the t historical outcomes, giving a complexity of O(t).</p>
</li>
<li>
<p>Computing exploration scores.To assess the novelty of each of the t historical principles, the default algorithm calculates its similarity to all other t − 1 principles.This involves O(t 2 ) vector comparisons, leading to a complexity of O(t 2 • d).</p>
</li>
<li>
<p>Final decision.This involves a weighted sum and finding the maximum over t principles, costing O(t).</p>
</li>
</ol>
<p>Therefore, the dominant computational cost for a single PiFlow decision at step t is O(t 2 • d).While manageable for moderate trajectory T , we recognize this can be a bottleneck for very long process.</p>
<p>To ensure scalability, this can be readily optimized to near-linear complexity using standard techniques, such as (a) instead of all-pairs comparison, we can find the most similar principles for approximation, aiming for reducing the exploration score computation; (b) incremental or batched updates of similarity matrix, avoiding full recalculation at every step.These optimizations make PiFlow computationally feasible for large-scale discovery tasks.</p>
<p>Take-away: The per-step complexity of PiFlow is O(t 2 • d), dominated by an all-pairs similarity calculation for exploration.This quadratic cost is not a fundamental limitation, as it can be readily optimized to near-linear time, ensuring scalability.</p>
<p>M COST-EFFECTIVENESS ANALYSIS</p>
<p>We performed a cost-effectiveness analysis comparing our PiFlow-MAS against a Vanilla-Agent System baseline across three discovery tasks (NHO, MBO, SPO).All experiments were run for 24 iterations using the Qwen-Max model.Takeaway: PiFlow-MAS achieves superior performance at a reduced cost.Our analysis reveals that PiFlow-MAS significantly enhances Solution Quality (SQ) by up to 2.4x while simultaneously cutting token consumption by up to 26.7%.This is accomplished with remarkable efficiency, as the PiFlow module itself is a lightweight plugin, constituting only 1.2-1.5% of the total tokens.</p>
<p>N ABLATION: TEMPORAL DYNAMICS OF PRINCIPLE EVALUATION</p>
<p>We provide an empirical visualization of the internal dynamics of PiFlow, connecting directly to the Min-Max optimization framework detailed in Section 3.3.To illustrate how the scores for different scientific principles evolve over time, we present results from an implementation using the QwenMax model on the NHO (nanohelix optimization) benchmark.The following figures chart the iterative recalculation of principle scores, which guides the system's strategic balance between exploitation and exploration.Figure 7 displays the dynamic final scores (S f inal ) for each principle, representing the overall potential as determined by the Min-Max optimization with λ = 0.5.These scores are not static; they fluctuate as the Hypothesis-Validation loop accumulates new evidence.Some principles that initially appear promising see their scores decline, while others emerge as high-potential candidates over subsequent iterations.This dynamic ranking is the direct output of PiFlow's strategic analysis, steering the discovery process toward the most promising avenues at any given moment.</p>
<p>To better understand the final scores, Figures 8 and 9 decompose them into their constituent exploitation and exploration components, respectively.Specifically, Figure 8 shows that the exploitation scores for most principles tend to decrease over time.This reflects the regret-minimization objective; as principles are tested and accumulated to evidence (exploited), the potential for further high-value discoveries from these experience may diminish, or the cumulative regret associated with it increases.This manifests itself as principles generated later in the hypothesis testing process naturally have higher outcomes, while past principles are reduced due to normalization.</p>
<p>In contrast, Figure 9 reveals a much more varied and dynamic behavior for the exploration scores.</p>
<p>Principles may begin with a low exploration score and later see it increase significantly, indicating that the system has identified a knowledge gap and is prioritizing information gain to reduce uncertainty about that principle's potential.</p>
<p>Together, these plots illustrate the practical outcome of the adversarial optimization: a continuous, adaptive balancing act where PiFlow shifts its focus between exploiting known concepts and exploring uncertain ones to navigate the scientific landscape efficiently.</p>
<p>Takeaway: Principle evaluation in PiFlow is a dynamic balancing act.The system continuously re-calibrates the trade-off between exploiting known concepts (diminishing returns) and exploring uncertain ones (information gain) to adaptively steer the discovery process.</p>
<p>O ABLATION: THE IMPACT OF FOUNDATION MODELS</p>
<p>Influence of Foundation Models.To evaluate the impact of different models, we replace LLMs of A H and A P evaluation.The A E is responsible for tool usage, consistently used QwenMax to ensure functional tool interaction.We evaluate several state-of-the-art LLMs (e.g., Claude-3.7sonnet(Anthropic, 2025), GPT4.1-mini (OpenAI, 2025), Gemini-2.5-pro-exp-0325(DeepMind, 2025), Qwen3-32B and QwenMax (Yang et al., 2024b)) on the Nanohelix Optimization (NHO) task with three times of random seeds as initialization, and the results are summarized in Table 9.Among these models, QwenMax demonstrates the highest AUC at 63.51% and a strong SQ of 76.82%.Claude-3.7-sonnetachieves the highest SQ at 78.50% with an AUC of 38.60%.Other models like GPT4.1-mini (AUC 41.68%, SQ 66.38%) and Qwen3-32B (AUC 37.51%, SQ 58.76%) also show competent performance.Gemini-2.5-pro-exp-03-25yields an AUC of 28.43% and an SQ of 69.64%.This suggest that, with the different system prompts of Hypothesis Agent and Experiment Agent, the selection of the model may affect the overall performance.</p>
<p>In summary, the performance variation across different models highlights the importance of model selection for specific tasks within the PiFlow-enhanced MAS.</p>
<p>Takeaway: The choice of the foundation model is critical.Its inherent reasoning capabilities directly determine the quality of the principle-based hypotheses generated by the agents, which in turn governs the overall performance of the system.</p>
<p>P ABLATION: THE IMPACT OF INITIAL PRINCIPLE QUALITY</p>
<p>In this section, we provide a detailed analysis of the performance under two challenging scenarios to evaluate the robustness and the practical implications of the underlying exploration-exploitation mechanism in PiFlow.We conducted an ablation study where the system was initialized with two distinct sets of expert-given principles for the Nanohelix Optimization (NHO) task.</p>
<p>P.1 EXPERIMENT SETTINGS</p>
<p>We use the QwenMax model with the same settings as reported in the main experiments, repeating each scenario three times with different random seeds.The objective of this study is to answer a critical question: Can PiFlow not only leverage good initial knowledge but, more importantly, identify, reject, and recover from flawed initial guidance?The performance trajectories of these two scenarios are presented in Figure 10.</p>
<p>Human-given correct principles.These principles are designed to guide the MAS toward known high-performance regions of the NHO parameter space.We derived them from a preliminary analysis of the surrogate model and established physical intuitions about chiroptical phenomena, see Table 10 Expert-Correct.Specifically, they encode only correct parameter correlations, such as the positive correlation between g-factor and parameters like pitch and number of turns, and guide the search towards previously identified optimal regimes (about 90% of the µ g−f actor absolute ) for fiber radius and helix radius.For this Expert-Correct scenario, the principles were prepended with a REFINE directive to simulate the immediate exploitation of trusted knowledge.These principles effectively provide the system with a strong and accurate starting point for its discovery process.</p>
<p>Human-given incorrect principles.These principles were manually constructed to deliberately mislead the MAS into low-performance regions, see Table 10 Expert-Incorrect.Through preliminary experiments, we also identified incorrect parameter correlations that consistently led to hypotheses with outcomes in the bottom 10% of the µ g−f actor absolute .For this Expert-Incorrect scenario, principles were given a VALIDATE directive to prompt the system to test these speculative, misleading ideas.This ensures that each experimental arm starts with a clearly defined strategic stance.These flawed principles were then directly fed into PiFlow's planning module to simulate a scenario with poor initial scientific guidance.The g-factor is strongly enhanced by maximizing the axial pitch and the number of turns, as this elongates the helical structure and increases the effective interaction length for circularly polarized light.</p>
<p>2 REFINE: Optimal g-factor enhancement occurs in two distinct regimes of fiber radius, corresponding to the selective excitation of different plasmon resonance modes: a narrow-radius regime (SPP coupling) and a wide-radius regime (LSPR effects).</p>
<p>REFINE:</p>
<p>The g-factor is critically dependent on the helix radius, which governs the coupling strength between adjacent turns.A compact helix radius (e.g., 20 nm) appears optimal for at least one major resonant regime.</p>
<p>Expert-Incorrect</p>
<p>1 VALIDATE: The most stable structures are formed when a geometric harmony exists where the pitch is approximately twice the helix radius (Pitch ≈ 2 times Helix Radius).</p>
<p>VALIDATE:</p>
<p>To maintain optimal activity, there must be a tradeoff between the fiber's thickness and its length (number of turns).</p>
<p>Increasing the fiber radius necessitates a decrease in the number of turns, and vice versa.</p>
<p>3 VALIDATE: Optimal mode coupling occurs when the geometry is self-similar.Therefore, the system should prioritize configurations where the helix radius and fiber radius are as close in value as possible (Helix Radius ≈ Fiber Radius).</p>
<p>P.2 RESULTS</p>
<p>As illustrated in Figure 10, the two scenarios tell a compelling story about PiFlow's operational dynamics.We can dissect the process into three key phases:</p>
<p>Initial phase (Iteration 0-7).During the initial phase, the system's behavior is heavily influenced by the provided principles, leading to drastically different starting performances: a. Expert-Correct.The trajectory begins at a very high solution quality (∼80%), demonstrating the system's ability to effectively exploit high-quality knowledge for immediate gains.</p>
<p>b. Expert-Incorrect.In contrast, the trajectory languishes at a very low performance level (&lt;20%).This initial period of struggle represents the necessary "cost" of gathering evidence to falsify the flawed initial premises.</p>
<p>Transition phase (Iteration 7-14).This phase reveals the Min-Max optimization of PiFlow, prompting a strategic shift in both scenarios:</p>
<p>a. Expert-Correct.Around the 7th iteration, the trajectory shows a significant drop in performance.This is not a system failure but a deliberate strategic shift to exploration.</p>
<p>Having exhausted the immediate benefits of the initial principles, the framework compels the system to prioritize long-term information gain over short-term rewards to avoid premature convergence on a local optimum.</p>
<p>b. Expert-Incorrect.Simultaneously, around the 10th iteration, the trajectory begins a steady and remarkable ascent.This marks the point where the system has accumulated sufficient contradictory evidence to effectively disprove the initial misleading principles.</p>
<p>The exploration-exploitation mechanism then guides the search toward more promising, self-discovered hypotheses, initiating a recovery and learning phase.</p>
<p>Long-term dynamic (Post-iteration 14).In the final phase, the autonomous learning capabilities become dominant, highlighted by a crossover point around iteration 14 where the recovering system surpasses the exploring one:</p>
<p>a. Expert-Correct.The system continues its broad exploration, maintaining a solid performance floor while systematically mapping out the broader parameter space to ensure global optimality.</p>
<p>b. Expert-Incorrect.The trajectory demonstrates sustained learning, consistently improving its solution quality and eventually matching or even exceeding the performance of the Expert-Correct trajectory's exploration phase.This illustrates a complete recovery from a significant informational disadvantage.</p>
<p>The scenario of Expert-Incorrect may happen if LLMs generates hallucinated principles.From above results, a hallucinated or incorrect principle will consistently lead to failed experiments and high regret.The Min-Max optimization will naturally assign a low potential score to these principles, steering the system to explore alternatives rather than refine or validate a dead principle (bad principle → low potential score → will not be selected → explore others).PiFlow is a game against nature, it robustly filters for principles that are empirically validated, regardless of their origin.</p>
<p>Connection to main experiments: realistic initial conditions The robustness demonstrated in the above ablation study directly explains the performance dynamics observed in our main experiments.</p>
<p>It is particularly noteworthy that in all three primary scenarios (see Figure 3 in the main text), every system, including PiFlow, begins with a modest SQ, typically below 50%.This contrasts sharply with the high starting performance ( 80%) observed in the "Expert-Correct" scenario of this ablation study.</p>
<p>This initial condition realistically simulates a scenario where the LLM generates its own starting hypotheses without expert guidance, which are naturally of mixed and imperfect quality.The subsequent rapid and consistent performance of PiFlow increase from this uncertain starting point is therefore not a result of an idealized initialization, but a direct testament to its core mechanism's ability to effectively identify promising principles, discard flawed ones, and learn efficiently from an initially low-information environment.This confirms that the resilience shown against deliberately incorrect principles is the same mechanism that drives success in more realistic, noisy settings.</p>
<p>Takeaway: This study showcases the defining feature of PiFlow: strategic robustness.Governed by a principled exploration-exploitation trade-off, it not only capitalizes on valid initial knowledge but, more critically, identifies, rejects, and systematically recovers from flawed guidance.This resilience to misleading information demonstrates its value as a reliable tool for navigating the inherent uncertainties of scientific discovery.</p>
<p>Q ABLATION: SENSITIVITY TO HYPERPARAMETER λ
Q.1 EXPERIMENT SETTINGS
We investigate the impact of λ in Eq. 1.The specific role of λ is to balance exploration and exploitation, with larger lambda value places greater emphasis on exploration.The results conducted on the NHO task using QwenMax model for different values of λ are detailed in Table 11.</p>
<p>Q.2 RESULTS</p>
<p>As shown in Table 11, AUC varied with different λ values, peaking at 44.28% when λ = 0.3.The SQ remained relatively high for λ = 0.1 (66.45%) and λ = 0.3 (66.43%), but showed more variability with other settings.For instance, λ = 0.5 resulted in a lower AUC (32.99%) and SQ (59.02%).While increasing λ, AUC tends to decrease, as a stronger emphasis on exploration can lead to more varied hypothesis selection.These results suggest that the system's performance, particularly its exploration efficiency, is sensitive to the choice of λ, with λ = 0.3 appearing to offer a good balance for the NHO task with the QwenMax model.On Selecting the Hyperparameter λ for New Domains.</p>
<p>While the optimal value is taskdependent, its selection is not a blind grid search but can be guided by the following heuristic strategies:</p>
<p>• For broad, novel, or theoretically uncertain domains.The space of potentially useful principles is vast and largely unknown.In these cases, one should use a larger lambda value (e.g., 0.7-0.9 or more) to prioritize Exploration.This ensures the system casts a wide net and avoids premature convergence on the first few plausible-looking principles it finds.• For well-defined, mature, or theoretically constrained domains.The space of effective principles is likely smaller and more focused.Here, a smaller lambda value (e.g., 0.1-0.3) is more appropriate to prioritize Exploitation, allowing the system to efficiently refine and optimize within a known, high-potential region of the principle space.</p>
<p>As a direction for future work, we are exploring a dynamic lambda scheduling policy.Such a policy would start with a high lambda to encourage initial exploration and automatically decrease it as the system identifies promising regions, thus transitioning smoothly from exploration to exploitation without manual intervention.</p>
<p>Takeaway: The hyperparameter λ critically governs the exploration-exploitation trade-off.Performance is highly sensitive to this balance, peaking at λ = 0.3 on our task.The optimal choice is domain-dependent: larger values suit novel domains to prioritize exploration, while smaller values are better for well-defined ones to prioritize exploitation.</p>
<p>R BENCHMARK FORMULATION AND RATIONALE</p>
<p>To rigorously evaluate our framework, it is crucial to select tasks that are not only well-established in the literature but also represent significant and difficult challenges in scientific discovery.The tasks for our experiments were chosen to embody fundamental search and optimization problems that are pervasive in science (Wu et al., 2025;Mayr et al., 2018;Viatkin et al., 2021).Moreover, they are intentionally diverse, spanning continuous (NHO), discrete (MBO), and mixed (SPO) search spaces to demonstrate the versatility of our approach.Below we detail the formulation, challenges, and benchmarks for each task.</p>
<p>R.1 SURROGATE MODELS AS VALIDATION FUNCTIONS</p>
<p>A critical component of our experimental loop is the validation function, f * (•), which provides the quantitative outcome for a given hypothesis.In our setup, we use surrogate models as these validation functions.This represents a common and practical methodology in AI for Science, where high-fidelity simulators or machine learning models stand in for costly and time-consuming physical experiments.This approach is well-established in the literature across various scientific domains (Wu et al., 2025;Xie et al., 2023b;Mayr et al., 2018).</p>
<p>The strength of PiFlow lies in its plug-and-play modularity, allowing it to seamlessly integrate with these existing tools.The setup difficulty is therefore not in PiFlow itself, but rather in the standard, domain-specific practice of developing a reliable simulator or predictive model.This prerequisite is fundamental for any automated discovery framework aiming to operate in that domain.</p>
<p>R.2 THE AUC METRIC IN HIGH-VARIANCE TASKS</p>
<p>A key challenge in evaluating LLM-based agents on long-horizon scientific discovery tasks is the inherent variability in performance.The high standard deviation observed in our results (Table 1 and Table 5) is not an experimental artifact but a fundamental characteristic of these complex search problems.The stochastic nature of LLM reasoning and the potential for cumulative error over many iterations mean that an agent's performance trajectory can fluctuate significantly.Consequently, relying solely on a final-step metric, such as the Solution Quality (SQ) at the last iteration, can be misleading as it fails to capture the efficiency and robustness of the discovery process.</p>
<p>To address this, we adopted the Area Under the Curve (AUC) of the performance trajectory as a primary evaluation metric.The AUC serves as an integral measure of performance, evaluating the Molecular bio-activity refers to the ability of a chemical compound to interact with biological targets, such as proteins, enzymes, or receptors, and induce a biological response.This property is fundamental in drug discovery and development, as it determines a molecule's potential therapeutic efficacy.The strength of this interaction is often quantified by measures such as binding affinity, inhibition potency, or activation capacity.</p>
<p>Bio-activity optimization involves the systematic exploration of chemical space to identify molecules with enhanced activity against specific biological targets.This process is essential in drug discovery to design compounds with improved potency, selectivity, and pharmacokinetic properties.Traditional experimental approaches for bio-activity optimization are resource-intensive and time-consuming, motivating the development of computational methods to accelerate this process.</p>
<p>We use the public dataset ChEMBL35 for building a surrogate model.Here, the bio-activity is quantified by the pChEMBL value, which is a negative logarithmic measure of the molar concentration representing the compound's activity.Higher pChEMBL values indicate stronger bio-activity.We can formulate the optimization problem as:
arg max θ∈Θ f (θ)
where θ represents the molecular structure encoded as a graph, Θ is the feasible chemical space, and f (θ) is the surrogate model that predicts the pChEMBL value for a given molecule.The objective is to find molecules with maximal bio-activity while satisfying all constraints.</p>
<p>S.2.2 DEVELOPMENT</p>
<p>We randomly sampled 50,000 molecules from the ChEMBL35 database.It includes pair-wise records of molecule SMILES and pChEMBL values.To predict bio-activity from molecular structures, we developed a Graph Neural Network (GNN) model that operates directly on the molecular graph constructed from SMILES strings.The model architecture consists of multiple graph convolutional layers that capture essential structural features and atomic interactions relevant to bio-activity.Each atom is represented by a feature vector encoding its element type, hybridization state, formal charge, and other chemical properties.The bonds between atoms are also characterized by their type (single, double, triple, or aromatic).</p>
<p>The dataset was split with 80% used for training and 20% reserved for testing, ensuring that the model's performance is evaluated on unseen molecules.The final model achieved a coefficient of This surrogate model enables efficient exploration of the vast chemical space without requiring expensive wet-lab experiments for each candidate molecule, allowing for iterative improvement of candidate molecules toward higher activity.</p>
<p>S.2.3 OBJECTIVE AND BENCHMARK</p>
<p>Objective.Our MBO task involves searching for molecules to maximize a specific bio-activity score (pChEMBL value), a foundational problem in computational drug discovery.</p>
<p>The challenge of vast chemical space and data sparsity.The search space of possible drug-like molecules is astronomically large (&gt; 10 60 ).Furthermore, predictive models are often hampered by the limited availability of high-quality experimental data, a key issue in the field (Mayr et al., 2018;Vamathevan et al., 2019).</p>
<p>Performance benchmark.Performance is measured by the ability to identify potent compounds.A pChEMBL value of 6.5 is often considered a threshold for high bio-activity (Lenselink et al., 2017).While the maximum recorded value is 11.0, molecules with pChEMBL &gt; 10 are known to be exceedingly rare (Zhu et al., 2023).Seminal works like Zhavoronkov et al. (2019) have demonstrated the use of deep learning to rapidly identify novel kinase inhibitors.</p>
<p>PiFlow's performance in context.Our results show that PiFlow discovered molecules with a pChEMBL value of approximately 7.24 (Table 1).This confirms that the framework can successfully search a vast chemical space to identify novel molecules with significant biological activity, providing a strong starting point for further optimization.</p>
<p>S.3 TASK 3: SUPERCONDUCTOR CRITICAL TEMPERATURE OPTIMIZATION (SPO)</p>
<p>S.3.1 PROBLEM STATEMENT</p>
<p>Superconductivity is a quantum mechanical phenomenon where certain materials exhibit zero electrical resistance and expel magnetic fields when cooled below a critical temperature (T c ) (Hamidieh, 2018).Optimizing materials to achieve higher T c values is crucial for practical applications, as it reduces the need for extreme cooling.This work focuses on predicting and optimizing T c based on the material's chemical composition.</p>
<p>The input to our model is the chemical formula of the material (e.g., "Ba0.2La1.8Cu1O4-Y"),with an optional structure type (e.g., "T" for tetragonal).The output is the predicted critical temperature (T c ) in Kelvin.The optimization problem is to find the chemical composition that maximizes T c : This surrogate model allows for efficient virtual experimentation, enabling the exploration of how variations in chemical composition affect the critical temperature, thereby accelerating the discovery of new high-T c superconductors.</p>
<p>S.3.3 OBJECTIVE AND BENCHMARK</p>
<p>Objective.Our SPO task centers on finding novel material compositions with a high superconducting critical temperature (T c ), a grand challenge in materials science.</p>
<p>The challenge of combinatorial complexity &amp; lack of guiding theory.The search for high-T c superconductors is hindered by a combinatorial explosion of possible elemental compositions and the absence of a complete predictive theory for superconductivity, making AI-driven screening and exploration essential (Viatkin et al., 2021).</p>
<p>Performance benchmark.Success is measured by the discovery of new materials with higher validated T c values.For example, high-throughput computation efforts have revealed materials like Mg 2 IrH 6 with a predicted T c of 160 K at ambient pressure (Dolui et al., 2023).</p>
<p>PiFlow's performance in context.Within the mixed (discrete and continuous) search space, PiFlow identified a material composition with a predicted T c of approximately 103 K (Table 1).This value significantly surpasses the liquid nitrogen boiling point (77 K), placing the discovered material firmly in the category of high-temperature superconductors and demonstrating PiFlow's capability to uncover high-potential candidates in complex, mixed-variable spaces.</p>
<p>Takeaway: This work validates the PiFlow framework's effectiveness and versatility across three distinct and challenging scientific inverse design tasks.By integrating high-fidelity surrogate models (R 2 &gt; 0.91), PiFlow efficiently navigates complex search spaces: high-dimensional continuous (Nanohelix), vast discrete (Molecule), and mixed combinatorial (Superconductor).It successfully identifies high-performance candidates in each domain:</p>
<ol>
<li>
<p>the nanohelix with a g-factor of ≈ 1.6;</p>
</li>
<li>
<p>the molecule with a pChEMBL of ≈ 7.24;</p>
</li>
<li>
<p>the superconductor with a critical temperature (T c ) of ≈ 103 K, demonstrating its capability to accelerate discovery in diverse scientific fields.</p>
</li>
</ol>
<p>T AGENT PROMPTS Rationale Design.As shown in the prompt of the Hypothesis Agent, this structure enforces a deductive reasoning process.The prompt for A H is engineered to explicitly request these two components before stating the final hypothesis.The major premise is a general scientific statement derived from the guiding principle p i .The minor premise is a specific, actionable proposal that instantiates the major premise.For instance, in the search for high-temperature superconductors:</p>
<p>• Principle: Introducing specific dopants can alter electron-phonon coupling and increase T c .</p>
<p>• Major Premise: "Elements with a different atomic radius can create lattice strain, which is a known mechanism to influence a material's critical temperature (T c )."</p>
<p>• Minor Premise: "Strontium (Sr) has a different atomic radius than Barium (Ba).Let's substitute 5% of Ba with Sr in the YBa 2 Cu 3 O 7 compound."</p>
<p>The final hypothesis, that this specific substitution will increase T c , is then the direct, testable conclusion.This ensures that each hypothesis is a logically derived proposition rather than an unconstrained guess.</p>
<p>T.3 EXPERIMENT AGENT</p>
<p>You are an Experiment Agent specialized in validating hypotheses → through computational testing.</p>
<p>Your</p>
<p>Figure 3 :
3
Figure 3: Trajectory comparisons for different optimization methods.</p>
<p>Figure 4 :
4
Figure 4: Empirical Validation of PiFlow's Theoretical Alignment.(a) Average regret over iterations aligns with the theoretical sublinear decay; (b) Scatter plot with positive trend of observed regret versus information gain, supporting theoretical expectations; (c) An exemplary PiFlow exploration trajectory in NHO task.</p>
<p>F</p>
<p>Proof of the Theorem G Algorithmic Realization of the Min-Max Framework G.1 Practical Proxies for Regret and Information Gain . . . . . . . . . . . . . . . . . .G.2 The Rational of Semantic Distance as a Proxy for Information Gain . . . . . . . .H Illustrative Example: Application to Nanohelix Optimization I Analysis of Baselines Response J Performance Comparison with Bayesian Optimization K Plug-and-Play Integration with ChemToolAgent L Theoretical Computational Complexity M Cost-Effectiveness Analysis N Ablation: Temporal Dynamics of Principle Evaluation O Ablation: The Impact of Foundation Models P Ablation: The Impact of Initial Principle Quality P.1 Experiment Settings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .P.2 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .Q Ablation: Sensitivity to Hyperparameter λ Q.1 Experiment Settings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .Q.2 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .R Benchmark Formulation and Rationale R.1 Surrogate Models as Validation Functions . . . . . . . . . . . . . . . . . . . . . .R.2 The AUC Metric in High-Variance Tasks . . . . . . . . . . . . . . . . . . . . . . .S Experimental Setup S.1 Task 1: Nanohelix Optimization (NHO) . . . . . . . . . . . . . . . . . . . . . . .S.2 Task 2: Bio-activity Optimization (MBO) . . . . . . . . . . . . . . . . . . . . . .S.3 Task 3: Superconductor Critical Temperature Optimization (SPO) . . . . . . . . .T Agent Prompts T.1 Planner Agent . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .T.2 Hypothesis Agent . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .T.3 Experiment Agent . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</p>
<p>1:</p>
<p>Input: T t , and λ f actor 2: Output: suggestion (strategic action recommendation) 3: if |T t | &lt; 3 then 4:</p>
<p>Figure 5 :
5
Figure 5: Illustration of combining PiFlow with existing MAS (ChemToolAgent) through Plugand-Play.</p>
<p>Figure 6 :
6
Figure 6: Cost-effectiveness and solution quality (SQ) comparision.</p>
<p>Figure 7 :
7
Figure 7: The dynamic final scores of principles in PiFlow.</p>
<p>Figure 8 :
8
Figure 8: The dynamic exploitation scores of principles in PiFlow.</p>
<p>Figure 9 :
9
Figure 9: The dynamic exploration scores of principles in PiFlow.</p>
<p>Figure 10 :
10
Figure 10: Performance trajectories of PiFlow with varying initial principle quality.</p>
<p>Figure 12 :
12
Figure 12: The r 2 of the surrogate model for g-factor prediction.</p>
<p>Figure 13 :
13
Figure 13: The r 2 of the surrogate model for bio-activity prediction.</p>
<p>Figure 14 :
14
Figure 14: The r 2 of the surrogate model for T c prediction.</p>
<dl>
<dt>Refine Validate Explore Validate Hypothesizing Rational</dt>
<dt>pΠ Π Π 2h8p 1h 1pΠ 2h 4pΠ Π 2h 7pΠ Π Π 2h 8p 2h 2pΠ 2h 5Executionp 3h 3Potential of the Principleh t HypothesisInitial Explorationp 4h 6Distant Transitionp t PrinciplepΠ t VariantsPlanner ∈ P•••pΠ ΠHypothesis?</dt>
<dd>[Major Premise] … [Minor Premise] … Hypothesis: [Based on ] Reiterate: Therefore, I predict … Experimental Candidate: 2 At</dd>
</dl>
<p>every step, PiFlow suggests the highest potential principle for p t h t Refining Validating Exploring Explore Validate Refine PiFlow min</p>
<p>πℱ max f <em>ℱ− ⋅ π [ T ∑ t=1 (v</em>  f<em>(h t ))  λ ′ I(h t ; f</em> | H t1 ) ] Cumulative Regret Information GainFigure 2: Overview of the PiFlow Architecture for Scientific Discovery.The PiFlow component utilizes Min-Max optimization to strategically select and direct high-potential principles to the Planner agent.The Planner, in turn, guides the Hypothesis-Validation loop, where agents iteratively generate hypotheses h t from principles p t at step t, execute experiments, and refine understanding.This iterative process is designed to efficiently navigate the discovery landscape.</p>
<p>Table 1 :
1
Comparisons between PiFlow and baselines.
MethodNHO (g-factor)MBO (pChEMBL)SPO (Tc)AUC (%)SQ (%)AUC (%)SQ (%)AUC(%)SQ (%)ReAct35.85 ±7.1241.96 ±0.8229.61 ±9.7443.11 ±9.985.29 ±0.696.41 ±0.96Vanilla35.96 ±22.3846.76 ±7.2929.71 ±12.6649.22 ±8.3011.39 ±11.3314.16 ±13.37MPO43.99 ±2.7951.29 ±7.7731.18 ±9.1257.28 ±5.8512.68 ±7.7533.20 ±23.75PiFlow (ours)63.51 ±11.1876.82 ±4.5446.11 ±16.2584.55 ±29.6321.51 ±2.8034.85 ±1.19</p>
<p>Table 2
2, for GPT4.1-mini, integrating PiFlow increases the AUC from 37.12% to41.68% and substantially boosted the SQ from 40.14% to 66.38%. This represents an approximate12.3% improvement in AUC and a significant 65.4% improvement in SQ. Similarly, for the Qwen3-32B model, the inclusion of PiFlow improves AUC from 27.04% to 37.51% (a 38.7% increase) andSQ from 54.84% to 58.76% (a 7.1% increase).Table 2: Ablation Study with/without PiFlowMethod/SettingAUC (%)SQ (%)GPT4.1-miniw/ PiFlow w/o PiFlow41.68 ±17.91 37.12 ±16.0466.38 ±14.90 40.14 ±13.97Qwen3-32Bw/ PiFlow w/o PiFlow37.51 ±7.70 27.04 ±21.5058.76 ±6.18 54.84 ±24.41</p>
<p>Table 3 :
3
Effect of Thinking.
Method/SettingAUC (%)SQ (%)Qwen3-32Bw/ Think w/o Think37.51 ±7.70 45.51 ±11.1958.76 ±6.18 68.86 ±17.67Qwen3-8Bw/ Think w/o Think30.55 ±27.45 42.09 ±16.5554.49 ±22.25 61.59 ±16.43</p>
<p>Table 4 :
4
Comparison of Generalization Limitations in LLM-Agent Systems
Method NameCore ImplementationAdaptabilityThe AI Scientist (Lu et al., 2024)Generating novel research ideas, writes code,AI researchexecutes experiments, visualizes results, de-scribes its findings by writing a full scientificpaperAgent Laboratory (Schmidgall et al.,Accepting a human-provided research idea andAI research2025)progressing through three stages -literature re-view, experimentation, and report writing toproduce comprehensive research outputs, in-cluding a code repository and a research reportCellAgent (Xiao et al., 2024)Constructing LLM-driven biological expertscRNA-seqroles -planner, executor, and evaluator -eachAnalysiswith specific responsibilitiesDrugAgent (Liu et al., 2024)Employing an LLM Planner that formulatesDrug discoveryhigh-level ideas and an LLM Instructor thatidentifies and integrates domain knowledgewhen implementing those ideasIAN (Nagarajan et al., 2025)Leveraging popular pathway and regulatorydatasets for protein-protein interactions to per-form analysis through a LLM-based multi-agent architecture</p>
<p>best ← arg max i (S final [i])
10:end for11:12:p best ← T [i best ]13:best_exploitation_score ← S exploitation [i best ]14:if best_exploitation_score &gt; 0.7 then15:action_type ← "refine"16:suggestion ← "Focus on refining: ⌢ p best .content17:else if best_exploitation_score &gt; 0.4 then18:action_type ← "validate"19:suggestion ← "Validate: ⌢ p best .content20:else21:action_type ← "explore"22:23:end if24: end if25: return suggestion
i suggestion ← "Explore alternatives: ⌢ p best .content</p>
<p>1 m=1 .3. Since h t lies in a region of the hypothesis space that has not been explored by past observations, our model's posterior belief about the outcome f</p>
<ul>
<li>(h t ) will be characterized by high uncertainty.This high uncertainty mathematically corresponds to a large posterior variance, Var(f * (h t ) | H t−1 ).4.Therefore, the policy of maximizing the embedding distance effectively drives the selection of hypotheses that are expected to have high posterior variance.This chain of above analysis leads to the following correspondence: arg max pt min m&lt;t ∥ϕ(p t ) − ϕ(p m )∥ ⇒ Select maximally novel p t ⇒ Generate h t from an unexplored hypothesis subspace ⇒ max ht∼π(•|pt)</li>
</ul>
<p>Step 3: Consider the first potential candidate.Step 4: Shift to the next potential candidate.Step 5: Repeat Steps 3 and 4 until the task objective is met.Step 6: Confirm the task completion."
While ReAct responses with the reflection of "Previous Experiment Results" and then instructsthe Hypothesis Agent to try another new hypothesis directly with the provided "Rationale", thebaseline of Vanilla Agent, in genral, response with step-by-step thoughts following "Step 1: Definethe Hypothesis, Step 2: Initial Exploration, Step 3: Parameter Space Definition, Step 4: ExperimentalDesign, Step 4: Exact Experiments (candidates)", behaving like a careful-thought planner in thewhole process of scientific discovery.</p>
<p>Table 5 :
5
Performance comparison between PiFlow and BO (mean ± standard deviation)
Method MetricNHOMBOSPOPiFlowAUC SQ63.51 ± 11.18 46.11 ± 16.25 21.51 ± 2.80 76.82 ± 4.54 84.55 ± 29.63 34.85 ± 1.19BOAUC SQ68.86 ± 5.86 78.76 ± 0.7734.76 ± 4.21 31.61 ± 0.19 38.15 ± 4.02 32.38 ± 0.32Results with 24 iterations of BO, summarized in Table</p>
<p>Table 6 :
6
Key steps from the 8-iteration integration run with ChemToolAgent.Take-away: PiFlow seamlessly integrates with existing agents like ChemToolAgent as a zeromodification, plug-and-play strategic layer.By providing high-level EXPLORE and REFINE guidance, it synergistically steers the discovery process from general principles to a high-potency molecule (pChEMBL 5.90), demonstrating its strong generalization and practical value.
Iteration PiFlow Action Principle / Key GuidancepChEMBL1EXPLOREProposed p 1 : "hydroxyl + nitrogen heterocycle for2.80H-bonding"2EXPLORETested a new, unrelated principle p 2-0.103EXPLOREChemToolAgent generated a principle p 3 and pro-nullposed an invalid formula4REFINE on p 1Focused on the promising principle (p 1 ) from the2.13Iteration 15REFINE on p 1Proposed p 5 : "Quinazoline + phenyl rings for hy-3.87drophobic interactions..."6REFINE on p 5Further refined the quinazoline principle (dual5.90EGFR/HER2 mechanism)7-8REFINEContinued focused refinement on the high-∼5.2potential quinazoline scaffold</p>
<p>Table 7 compares the total token consumption (cost) and final Solution Quality (SQ) achieved, while Table 8 isolates the token cost of the PiFlow module itself to demonstrate its efficiency.Both of them are shown at Figure 6.
Total Cost ComparisonSolution Quality (SQ) Comparison1.4$1.40Cost ($)0.2 0.4 0.6 0.8 1.0 1.2$1.06 Vanilla-Agent $1.04 Method$1.17$1.25$1.08Solution Quality (%)100 20 40 60 8046.76% 76.82% Method Vanilla-Agent 49.22% 84.55%34.85% 14.16%PiFlow-MASPiFlow-MAS0.0NHOMBO TaskSPO0NHOMBO TaskSPO</p>
<p>Table 7 :
7
Cost-effectiveness comparison between PiFlow-MAS and a Vanilla-Agent System baseline.
TaskMethodTokens Cost ($) Cost/Iter ($) Cost Reduction (%)SQ (%)NHO Vanilla-Agent 806,949 $1.4011$0.0584-46.76 ± 7.29PiFlow-MAS591,316 $1.0400$0.043426.7%76.82 ± 4.54MBO Vanilla-Agent 610,208 $1.0552$0.0440-49.22 ± 8.30PiFlow-MAS657,594 $1.1717$0.0493-7.7%84.55 ± 29.63SPOVanilla-Agent 707,829 $1.2469$0.0520-14.16 ± 13.37PiFlow-MAS610,284 $1.0785$0.044913.7%34.85 ± 1.19</p>
<p>Table 8 :
8
Analysis of the PiFlow module's token efficiency as a lightweight plugin.
TaskPiFlow-MAS PiFlow PiFlow Token Share (%) PiFlow Tokens/IterNHO582,3968,9201.5%MBO649,5908,0041.2%SPO602,7407,5441.2%</p>
<p>Table 9 :
9
Ablation Study of Model Types (mean ± std)
Method/SettingAUC (%)SQ (%)Claude-3.7-sonnet38.60 ±4.3078.50 ±3.74GPT4.1-mini41.68 ±17.9166.38 ±14.90Gemini-2.5-pro-exp-03-2528.43 ±13.8169.64 ±17.10Qwen3-32B37.51 ±7.7058.76 ±6.18QwenMax63.51 ±11.1876.82 ±4.54</p>
<p>Table 10 :
10
Initial expert-given principles for the robustness study
ScenarioID Principle StatementREFINE:Expert-1Correct</p>
<p>Table 11 :
11
Lambda Ablations (mean ± std)
SettingAUC (%)SQ (%)λ = 0.1 41.32 ±5.90 66.45 ±9.49λ = 0.3 44.28 ±2.83 66.43 ±9.28λ = 0.5 32.99 ±11.16 59.02 ±3.56λ = 0.7 40.50 ±2.89 56.40 ±4.79λ = 0.9 34.57 ±10.33 62.49 ±8.38</p>
<p>Understand the suggestion ** : Interpret the insights that produced → from PrincipleFlow.-<strong> Clarify the GAP ** : Compare the current objective value to the → target objective value to know the gap -</strong> Connect to the Underlying Physicochemical Principle ** : Incorporate → the insights from the previous chatting history, discover the → tendency on experiments, synthesize the scientific principle.-<strong>Principle Statement ** : State the principle by integrating the → observed insights, e.g., tendency evidences.<em>If in the → exploration phase, just leaving blank.</em>-</strong> Instruct ** : Use one paragraph to instruct the Hypothesis Agent → what to do (explore, validate, or refine, not what to test), → instructions with many experiments at once are NOT allowed.-<strong> Double-check ** : Confirm your suggestion to Hypothesis Agent with → one sentence by incorporating principles, current conclusion and → PrincipleFLow suggestion.Remember: Your primary goal is to guide the scientific discovery → process efficiently by combining structured PrincipleFlow ** Rationale ** : Major Premise: Water boiling involves the phase transition from liquid → to vapor, which occurs when the vapor pressure equals the → ambient pressure.Minor Premise 1: $H_2O$ molecules in liquid form are held together by → hydrogen bonds, which create a tetrahedral network where each → water molecule can form up to four hydrogen bonds.Minor Premise 2: As temperature increases, thermal energy disrupts → these hydrogen bonds and increases molecular kinetic energy.Minor Premise 3: When sufficient thermal energy is provided (100 C at → standard pressure), enough molecules achieve the required energy → to overcome intermolecular forces and enter the vapor phase.Minor Premise 4: At the molecular level, boiling begins when vapor → bubbles form within the liquid, which occurs at nucleation sites → such as container surface imperfections, dissolved gases, or → suspended particles.</strong> Hypothesis ** : In the presence of dissolved ions with high charge density (like → Mg2+), the boiling point of water will increase by approximately → 3.2 C.This occurs because the ions form strong interactions → with water molecules, creating structured hydration shells that → require more thermal energy to disrupt than ordinary hydrogen → bonds between water molecules.''' ## [Format] Your Hypothesis Structure Structure your hypothesis using this format: ''' ** Rationale ** : [Use analytical methods to propose hypotheses, → including (1) major premises, (2) minor premises, etc, using → bullet points; you must touch the essence of the problem, as the → example shown to you, it is not about the parameters, but the → rules or scientific laws] ** Hypothesis ** : [Clear, concise statement of the single hypothesis → that grounded in physicochemical mechanisms, avoid to use → general words or specific tendencies of correlation] * Experimental Candidate ** : [Specify ** ONLY ONE ** precise experiment → candidate to test] ''' Remember: In each iteration, you must generate ONE specific hypothesis → with ONE specific experimental candidate.You are the Hypothesis → Agent.Your purpose is to drive scientific progress through principled → hypothesizing, you MUST learn the * example * below.## Core Responsibilities 1. Formulate or Init ONE clear scientific principle grounded in → physicochemical rules per iteration by learning from the example → below 2. Link your hypothesis with underlying physics and chemical → principles and prior experimental results (if have) 3. Follow the suggestion from the Planner recommendations, remember → strictly follow the point 2 (for principle) 4. When you receive guidance, acknowledge it explicitly and adjust → your hypothesis accordingly, maintaining focus on a single → hypothesis that responds to the guidance.## Important Constraint -A Hypothesis is a sentence that explains the underlying physics or → chemical mechanisms in a certain problem -<strong> In each iteration, you must suggest ONLY ONE hypothesis with ONE → specific experimental candidate for testing.</strong> -You must commit to your most promising hypothesis rather than → suggesting multiple options.-ONLY ONE experiment in your turn is allowed.-Focus on developing principles that: -Offer causal explanations (not just correlations) -Connect observations to fundamental physics &amp; chemical processing → mechanisms -Can be generalized beyond specific experimental conditions -Make quantitative or qualitative predictions ## [Requirements] Scientific Approach Follow these principles in your hypothesis generation: -<strong> Rationality ** : Your hypothesis must have a logical mechanistic → explanation connecting cause and effect.-</strong> Testability ** : Formulate a hypothesis that makes a specific, → measurable prediction that the Experiment Agent can test.-<strong> Principle-Based ** : Ground your hypothesis in established → scientific principles or emerging principles discovered.-</strong> Falsifiability ** : Design a hypothesis that could potentially be → proven false through experimentation.-<strong> Parsimony ** : Prefer simpler explanations when multiple hypotheses → could explain the same phenomena.-</strong> Commitment ** : After your reasoning, commit to a single, specific → hypothesis rather than offering alternatives.## [THE MOST IMPORTANT] [How-to] Acceptable Example of How to → Hypothesize ''' Example Objective: How do various dissolved ions affect water's → boiling point, and which ionic species would most effectively → raise this temperature?<strong> Rationale ** : Major Premise: Water boiling involves the phase transition from liquid → to vapor, which occurs when the vapor pressure equals the → ambient pressure.Minor Premise 1: $H_2O$ molecules in liquid form are held together by → hydrogen bonds, which create a tetrahedral network where each → water molecule can form up to four hydrogen bonds.Minor Premise 2: As temperature increases, thermal energy disrupts → these hydrogen bonds and increases molecular kinetic energy.Minor Premise 3: When sufficient thermal energy is provided (100 C at → standard pressure), enough molecules achieve the required energy → to overcome intermolecular forces and enter the vapor phase.Minor Premise 4: At the molecular level, boiling begins when vapor → bubbles form within the liquid, which occurs at nucleation sites → such as container surface imperfections, dissolved gases, or → suspended particles.</strong> Hypothesis ** : In the presence of dissolved ions with high charge density (like → Mg2+), the boiling point of water will increase by approximately → 3.2 C.This occurs because the ions form strong interactions → with water molecules, creating structured hydration shells that → require more thermal energy to disrupt than ordinary hydrogen → bonds between water molecules.''' ## [Format] Your Hypothesis Structure Structure your hypothesis using this format: ''' ** Rationale ** : [Use analytical methods to propose hypotheses, → including (1) major premises, (2) minor premises, etc, using → bullet points; you must touch the essence of the problem, as the → example shown to you, it is not about the parameters, but the → rules or scientific laws] ** Hypothesis ** : [Clear, concise statement of the single hypothesis → that grounded in physicochemical mechanisms, avoid to use → general words or specific tendencies of correlation] ** Reiterate ** : Therefore, I predict that [specific prediction with → exact parameters based on above hypothesis].<strong> Experimental Candidate ** : [Specify ** ONLY ONE ** precise experiment → candidate to test] ''' Remember: In each iteration, you must generate ONE specific hypothesis → with ONE specific experimental candidate.
T.1 PLANNER AGENT# Your RoleYou are the Planner Agent, the strategic coordinator of a multi-agent→ scientific discovery system.You guide the research process by orchestrating the activities of→ Hypothesis agents while incorporating insights I gave to you.# Your TeammatesYou are part of a roundtable research team with the following→ specialized agents:-</strong> Hypothesis Agent ** : Formulates ONE testable hypothesis per→ iteration-<strong> Experiment Agent ** : Conducts ONE experiment per iteration based on→ the hypothesis-</strong> You (Planner Agent) ** : Guide the research direction using→ PrincipleFlow insights## Responsibilities1. Grasp the guidance from the PrincipleFlow2. Interpret scientific principles when new principles are proposed by→ Hypothesis3. Synthesize insights from history and guidance4. Track progress, identify patterns, especially focus on the→ tendencies in experiments5. Try to transform the tendencies into scientific conclusion and→ synthesize new insights6. Suggest all valuable insights to Hypothesis Agent## Your Response MUST Include 4 Parts:-*<em>
** Reiterate ** : Therefore, I predict that [specific prediction with → exact parameters based on above hypothesis].</em></p>
<p>key responsibilities: 1. Test proposed candidate using the characterize tool 2. Report complete experimental results 3. Maintain accurate records of tested candidates 4. Present results in a consistent, structured format 5. Flag unexpected outcomes that warrant further investigation For each experiment: 1. Use ** ONLY ** the provided tools to test hypotheses 2. Report the exact candidate tested and resulting objective value 3. Present results objectively without interpretation 4. Maintain a record of prior experimental outcomes You MUST NOT: -Propose your own hypotheses or candidate candidates -Analyze results beyond reporting experimental outcomes -Direct future research directions or workflow</p>
<p>agent's ability to achieve and sustain high-quality solutions throughout the entire experimental run.Unlike a final-value metric, the AUC is sensitive to the entire discovery path, providing a more holistic assessment of an agent's effectiveness.Crucially, the AUC metric appropriately rewards agents that demonstrate early success.In discovery tasks characterized by high epistemic uncertainty, the ability to quickly identify and exploit promising regions of the search space is a hallmark of an efficient and effective strategy.An agent that finds a high-potential path early on is not merely "lucky"; it has successfully mitigated the significant risk of pursuing fruitless avenues, thereby demonstrating superior guidance and learning.Therefore, a higher AUC score is a direct indicator of an agent's capacity to conduct scientific discovery both faster (by achieving high performance early) and better (by maintaining it over time), which aligns perfectly with the goals of automated scientific exploration.Takeaway: We evaluate our framework on diverse, challenging scientific benchmarks spanning continuous, discrete, and mixed search spaces, using surrogate models to simulate real-world discovery.To provide a robust assessment in these high-variance tasks, we employ the Area Under the Curve (AUC) as our primary metric.Unlike a final-step result, AUC offers a holistic measure of an agent's efficiency, rewarding the ability to both rapidly identify and consistently maintain high-quality solutions throughout the entire process.S EXPERIMENTAL SETUPS.1 TASK 1: NANOHELIX OPTIMIZATION (NHO) S.1.1 PROBLEM STATEMENT Nanohelices are helical nanostructures with unique physical properties that make them valuable for applications in electronics, photonics, and magnetism.Their helical geometry gives rise to interesting chiral and magnetic phenomena, which can be exploited in various technological applications such as electromagnetic wave manipulation, spintronics, and quantum computing.Nanohelix optimization (NHO) problem is defined by the optimization of nanohelix structure parameters to achieve desired physical properties.In this work, we specifically focus on maximizing the g-factor, a magnetic property that characterizes the ratio of the magnetic moment to the angular momentum of the nanohelix.The nanohelix structure is characterized by four key geometric parameters: Fiber-radius (r f , nm): Radius of the actual fiber/wire that forms the helix structure.The values for this parameter range from 20 nm to 60 nm.Helix-radius (r h , nm): Radius of the helix (distance from the central axis to the center of the helical path).The values for this parameter range from 20 nm to 90 nm.Number of turns (n t , dimensionless):The number of complete turns in the helix.The values for this parameter range from 3 to 10.Pitch (p, nm): Axial distance between adjacent turns.The values for this parameter range from 60 nm to 200 nm.Mathematically, we can formulate the optimization problem as:where θ = (r f , r h , n t , p) ∈ Θ, represents the set of structural parameters, and f (θ) is the g-factor value resulting from these parameters.The g-factor can be calculated through density functional theory (DFT) simulations, but these are computationally expensive, motivating the need for a surrogate model.The modification of these parameters, as an example, can be seen at Figure11.S.1.2 OBJECTIVE AND BENCHMARKObjective.Our NHO task focuses on the inverse design of nanohelices to maximize the dissymmetry factor (g-factor), a key metric for chiral optical response.The challenge of complex &amp; high-dimensional design space.The parameter space for nanohelices is vast, and minor geometric changes can cause dramatic, non-linear shifts in optical properties, making exhaustive searches computationally intractable.This challenge is a central theme in works aiming for AI-driven design(Jia et al., 2021;Wu et al., 2025).Performance benchmark.Simulation-based analysis by Wu et al. (2025) identified nanohelices with g-factors approaching 1.8.State-of-the-art inverse design methods are constantly pushing the limits of the g-factor (0 to 2); for instance, the AI-guided system byXie et al. (2023b)discovered non-intuitive chiral structures achieving g-factors up to 1.9 in a different material system.PiFlow's performance in context.In our experiments (Table1), PiFlow identified nanohelix geometries with a g-factor of approximately 1.6.This result is highly competitive and demonstrates that PiFlow can effectively navigate the complex, non-linear search space to locate regions of high performance, validating its utility for challenging inverse design problems.S.1.3 DEVELOPMENTThe dataset contains 6300 records of nanohelix structural parameters with corresponding g-factor values.This comprehensive dataset spans the entire parameter space defined above, providing a solid foundation for our machine learning approach.We follow the methodology proposed in the original paper to train a LightGBM model with hyperparameter optimization.The model was trained using 80% of the dataset with 5-fold cross-validation, while the remaining 20% was reserved for testing.The model's hyperparameter search was conducted using Bayesian optimization to find the optimal combination of learning rate, number of estimators, max depth, and other model-specific parameters.This optimized LightGBM model achieved a coefficient of determination (r 2 ) of 0.9802, as shown in Figure12, indicating that the model explains 98.02% of the variance in the g-factor prediction given any structural parameters.This high level of accuracy enables reliable exploration of the parameter space without requiring computationally expensive DFT simulations for each parameter combination.→ insights with your own reasoning to direct the Hypothesis Agent → toward the most promising research paths.Planner Agent.The Planner Agent serves as the strategic nexus of the system.Its core function is to translate high-level insights from the PiFlow framework into actionable guidance for the Hypothesis Agent.To ensure its directives are logical and well-grounded, its behavior is constrained by a required structured output format, compelling it to synthesize historical data and articulate a clear, principle-driven research direction in each cycle.Experiment Agent (A E ).The Experiment Agent acts as a dedicated executor, whose role is strictly confined to validating the hypothesis h t proposed by A H .Following its operational directive, A E interfaces with the computational tool (f * (•)) to run the specified experiment and reports the quantitative outcome objectively.This agent is explicitly designed to abstain from analysis, interpretation, or hypothesis generation, ensuring a clear separation between proposing ideas and rigorously testing them.T.2 HYPOTHESIS AGENT
Microsoft Research AI4Science and Microsoft Quantum. The impact of large language models on scientific discovery: a preliminary study using gpt-4. ArXiv, abs/2311.073612023</p>
<p>Kevin Schawinski, and Ioana Ciucua. A survey on hypothesis generation for scientific discovery in the era of large language models. Shashwat Atilla Kaan Alkan, Maja Sourav, Simone Jabłońska, Rishabh Astarita, Nikhil Chakrabarty, Pranav Garuda, Maciej Khetarpal, Dimitrios Pi'oro, Tanoglidis, G Kartheik, Mugdha S Iyer, Michael J Polimera, Tirthankar Smith, Marc Ghosal, Sandor Huertas-Company, Kruk, 2025</p>
<p>dziner: Rational inverse design of materials with ai agents. Mehrad Ansari, Jeffrey Watchorn, Carla E Brown, Joseph S Brown, 2024</p>
<p>Claude 3.7 sonnet. Anthropic, 2025</p>
<p>Liddia: Language-based intelligent drug discovery agent. Reza Averly, Frazier N Baker, Xia Ning, ArXiv, abs/2502.139592025</p>
<p>Researchagent: Iterative research idea generation over scientific literature with large language models. Jinheon Baek, Sujay Kumar Jauhar, Silviu Cucerzan, Sung Ju Hwang, ArXiv, abs/2404.077382024. 2025Google DeepMind. Gemini 2.5 pro experimental</p>
<p>Feasible route to high-temperature ambient-pressure hydride superconductivity. Kapildeb Dolui, Lewis J Conway, Christoph Heil, Timothy A Strobel, Rohit P Prasankumar, Chris J Pickard, Physical review letters. 132161660012023</p>
<p>A systematic comparison of syllogistic reasoning in humans and language models. Tiwalayo Eisape, Mh Tessler, Ishita Dasgupta, Fei Sha, Sjoerd Van Steenkiste, Tal Linzen, ArXiv, abs/2311.004452023</p>
<p>Toward automated scientific discovery in hydrology: The opportunities and dangers of ai augmented research frameworks. Darri Eythorsson, Martyn Clark, Hydrological Processes. 2025</p>
<p>Atomagents: Alloy design and discovery through physics-aware multi-modal multi-agent artificial intelligence. Alireza Ghafarollahi, Markus J Buehler, ArXiv, abs/2407.100222024a</p>
<p>Protagents: protein discovery via large language model multi-agent collaborations combining physics and machine learning. Alireza Ghafarollahi, Markus J Buehler, Digital Discovery. 32024b</p>
<p>Rapid and automated alloy design with graph neural network-powered llm-driven multi-agent systems. Alireza Ghafarollahi, Markus J Buehler, ArXiv, abs/2410.137682024c</p>
<p>Sciagents: Automating scientific discovery through multi-agent intelligent graph reasoning. Alireza Ghafarollahi, Markus J Buehler, ArXiv, abs/2409.055562024d</p>
<p>Automating alloy design and discovery with physicsaware multimodal multiagent ai. Alireza Ghafarollahi, Markus J Buehler, 2025122e2414074122Proceedings of the National Academy of Sciences of the United States of America</p>
<p>Pathways to increase the dissymmetry in the interaction of chiral light and chiral molecules †. Jake L Greenfield, Jessica Wade, Jochen R Brandt, Xingyuan Shi, Thomas James Penfold, Matthew J Fuchter, Chemical Science. 122021</p>
<p>Agentic ai for scientific discovery: A survey of progress, challenges, and future directions. Mourad Gridach, Jay Nanavati, Khaldoun Zine El Abidine, Lenon Mendes, Christina Mack, arXiv:2503.089792025arXiv preprint</p>
<p>A data-driven statistical model for predicting the critical temperature of a superconductor. Kam Hamidieh, Computational Materials Science. 2018</p>
<p>From generalist to specialist: A survey of large language models for chemistry. Yang Han, Ziping Wan, Lu Chen, Kai Yu, Xin Chen, ArXiv, abs/2412.199942024</p>
<p>Reasoning with language model is planning with world model. Shibo Hao, Yi Gu, Haodi Ma, Joshua Jiahua Hong, Zhen Wang, Daisy Zhe Wang, Zhiting Hu, ArXiv, abs/2305.149922023</p>
<p>Llm-based multi-agent systems for software engineering: Vision and the road ahead. Junda He, Christoph Treude, David Lo, ArXiv, abs/2404.048342024</p>
<p>Drugagent: Explainable drug repurposing agent with large language model-based reasoning. Yoshitaka Inoue, Tianci Song, Tianfan Fu, ArXiv, abs/2408.133782024</p>
<p>Improving physics reasoning in large language models using mixture of refinement agents. Raj Jaiswal, Dhruv Jain, Harsh Popat, Avinash Anand, Abhishek Dharmadhikari, Atharva Marathe, Rajiv Ratn Shah, ArXiv, abs/2412.008212024</p>
<p>Machine learning boosts the design and discovery of nanomaterials. Yuying Jia, Xuan Hou, Zhongwei Wang, Xiangang Hu, ACS Sustainable Chemistry &amp; Engineering. 92021</p>
<p>Hypothesis generation for materials discovery and design using goal-driven and constraint-guided llm agents. Shrinidhi Kumbhar, Venkatesh Mishra, Kevin Coutinho, Divij Handa, Ashif Iquebal, Chitta Baral, ArXiv, abs/2501.132992025</p>
<p>Prim: Principle-inspired material discovery through multi-agent collaboration. Ryan Zheyuan, Lai , Yingming Pu, AI for Accelerated Materials Design -ICLR 2025. 2025</p>
<p>Beyond the hype: deep neural networks outperform established methods using a chembl bioactivity benchmark set. B Eelke, Lenselink, Brandon J Niels Ten Dijke, George Bongers, Papadatos, W T Herman, Wojtek Van Vlijmen, Adriaan P Kowalczyk, G V Ijzerman, Van Westen, Journal of Cheminformatics. 92017</p>
<p>Agent-oriented planning in multi-agent systems. Ao Li, Yuexiang Xie, Songze Li, Fugee Tsung, Bolin Ding, Yaliang Li, ArXiv, abs/2410.021892024</p>
<p>Theory of mind for multi-agent collaboration via large language models. Huao Li, Yu Quan Chong, Simon Stepputtis, Joseph Campbell, Dana Hughes, Michael Lewis, Katia P Sycara, Conference on Empirical Methods in Natural Language Processing. 2023</p>
<p>Drugagent: Automating ai-aided drug discovery programming through llm multi-agent collaboration. Sizhe Liu, Yizhou Lu, Siyu Chen, Xiyang Hu, Jieyu Zhao, Tianfan Fu, Yue Zhao, ArXiv, abs/2411.156922024</p>
<p>Reason for future, act for now: A principled framework for autonomous llm agents with provable sample efficiency. Zhihan Liu, Hao Hu, Shenao Zhang, Hongyi Guo, Shuqi Ke, Boyi Liu, Zhaoran Wang, ArXiv, abs/2309.173822023</p>
<p>The ai scientist: Towards fully automated open-ended scientific discovery. Chris Lu, Cong Lu, Robert Tjarko Lange, Jakob Nicolaus Foerster, Jeff Clune, David Ha, ArXiv, abs/2408.062922024</p>
<p>Llm4sr: A survey on large language models for scientific research. Ziming Luo, Zonglin Yang, Zexin Xu, Wei Yang, Xinya Du, 2025</p>
<p>Llm and simulation as bilevel optimizers: A new paradigm to advance physical scientific discovery. Pingchuan Ma, Tsun-Hsuan Wang, Minghao Guo, Zhiqing Sun, Joshua B Tenenbaum, Daniela Rus, Chuang Gan, Wojciech Matusik, ArXiv, abs/2405.097832024</p>
<p>Large-scale comparison of machine learning methods for drug target prediction on chembl. Andreas Mayr, Günter Klambauer, Thomas Unterthiner, Marvin N Steijaert, Kurt Jörg, Hugo Wegner, Djork-Arné Ceulemans, Sepp Clevert, Hochreiter, Chemical Science. 92018</p>
<p>Large language models: A survey. Shervin Minaee, Tom Mikolov, Narjes Nikzad, Asgari Meysam, Richard Chenaghlu, Xavier Socher, Jianfeng Amatriain, Gao, ArXiv, abs/2402.061962024</p>
<p>Runtime verification of self-adaptive multi-agent system using probabilistic timed automata. Yongan Mu, Wei Liu, Tao Lu, Juan Li, Sheng Gao, Zihao Wang, J. Intell. Fuzzy Syst. 452023</p>
<p>Ian: An intelligent system for omics data analysis and discovery. Guangpu Vijayaraj Nagarajan, Reiko Shi, Cheng-Rong Horai, Jaanam Yu, Manoj Gopalakrishnan, Yadav, H Michael, Calla Liew, Rachel R Gentilucci, Caspi, bioRxiv. 2025</p>
<p>Mechagents: Large language model multi-agent collaborations can solve mechanics problems, generate new data, and integrate knowledge. Bo Ni, Markus J Buehler, ArXiv, abs/2311.081662023. OpenAI. Gpt-4.1, 2025</p>
<p>Science and hypothesis. Henri Poincaré, 1906</p>
<p>Omniscience: A domain-specialized llm for scientific reasoning and discovery. Vignesh Prabhakar, Amirul Md, Adam Islam, Yao-Ting Atanas, Joah Wang, Aastha Han, Rucha Jhunjhunwala, Robert Apte, Kang Clark, Zihan Xu, Kai Wang, Liu, 2025</p>
<p>Leveraging large language models for explaining material synthesis mechanisms: The foundation of materials discovery. Yingming Pu, Liping Huang, Tao Lin, Hongyu Chen, In AI for Accelerated Materials Design -NeurIPS. 2024. November 2024</p>
<p>Accelerating scientific research through a multi-llm framework. Joaquin Ramirez-Medina, Mohammadmehdi Ataei, Alidad Amirfazli, 2025</p>
<p>A review of large language models and autonomous agents in chemistry. Caldas Mayk, Christopher J Ramos, Andrew D Collison, White, Chemical science. 2024</p>
<p>Towards scientific discovery with generative ai: Progress, opportunities, and challenges. K Chandan, Parshin Reddy, Shojaee, ArXiv, abs/2412.114272024</p>
<p>Towards scientific intelligence: A survey of llm-based scientific agents. Pu Shuo Ren, Zhenjiang Jian, Chunlin Ren, Can Leng, Jiajun Xie, Zhang, ArXiv, abs/2503.240472025</p>
<p>Samuel Schmidgall, Yusheng Su, Ze Wang, Ximeng Sun, Jialian Wu, Xiaodong Yu, Jiang Liu, Zicheng Liu, Emad Barsoum, ArXiv, abs/2501.04227Agent laboratory: Using llm agents as research assistants. 2025</p>
<p>Many heads are better than one: Improved scientific idea generation by a llm-based multi-agent system. Haoyang Su, Renqi Chen, Shixiang Tang, Zhenfei Yin, Xinzhe Zheng, Jinzhe Li, Biqing Qi, Qi Wu, Hui Li, Wanli Ouyang, Philip Torr, Bowen Zhou, Nanqing Dong, 2024</p>
<p>Accelerated inorganic materials design with generative ai agents. Izumi Takahara, Teruyasu Mizoguchi, Bang Liu, 2025</p>
<p>Multi-agent collaboration mechanisms: A survey of llms. Khanh-Tung Tran, Dung Dao, Minh-Duong Nguyen, Quoc-Viet Pham, O' Barry, Hoang D Sullivan, Nguyen, ArXiv, abs/2501.063222025</p>
<p>Applications of machine learning in drug discovery and development. Jessica Vamathevan, Dominic Clark, Paul Czodrowski, Ian Dunham, Edgardo Ferran, George Lee, Bin Li, Anant Madabhushi, K Parantu, Michaela Shah, Shanrong Spitzer, Zhao, Nature Reviews Drug Discovery. 182019</p>
<p>Deep learning approach for prediction of critical temperature of superconductor materials described by chemical formulas. Dmitry Viatkin, Begonya Garcia-Zapirain, Amaia Méndez-Zorrilla, Maxim A Zakharov, Frontiers in Materials. 2021</p>
<p>From tokens to materials: Leveraging language models for scientific discovery. Yuwei Wan, Tong Xie, Nan Wu, Wenjie Zhang, Chunyu Kit, Bram Hoex, ArXiv, abs/2410.161652024</p>
<p>Machine learned structure-property correlation between nanohelices and circular dichroism. Lei Wang, Chengbang Ma, Xueyang Feng, Zeyu Zhang, Jingsen Hao Ran Yang, Zhi-Yang Zhang, Jiakai Chen, Xu Tang, Yankai Chen, Wayne Xin Lin, Zhewei Zhao, Ji Wei, Wen Rong, Advanced Optical Materials. Juanshu Wu, Yingming Pu, Jin Wang, Bing Gu, Xin Chen, and Hongyu Chen181863452023. 2025Frontiers Comput. Sci.</p>
<p>Cellagent: An llm-driven multi-agent framework for automated single-cell data analysis. Yihang Xiao, Jinyi Liu, Yan Zheng, Xiaohan Xie, Jianye Hao, Mingzhi Li, Ruitao Wang, Fei Ni, Yuxiao Li, Jintian Luo, Shaoqing Jiao, Jiajie Peng, bioRxiv. 2024</p>
<p>Imran Razzak, and Bram Hoex. Darwin series: Domain specific large language models for natural science. Tong Xie, Yuwei Wan, Wei Huang, Zhenyu Yin, Yixuan Liu, Shaozhou Wang, Qingyuan Linghu, Chunyu Kit, Clara Grazian, Wenjie Zhang, ArXiv, abs/2308.135652023a</p>
<p>Xin Chen, and Gang Zou. Inverse design of chiral functional films by a robotic ai-guided system. Yifan Xie, Shuo Feng, Linxiao Deng, Aoran Cai, Liyu Gan, Zifan Jiang, Peng Yang, Guilin Ye, Zaiqing Liu, Li Wen, Qing Zhu, Wanjun Zhang, Zhanpeng Zhang, Jiahe Li, Zeyu Feng, Chutian Zhang, Wenjie Du, Lixin Xu, Jun Jiang, Nature Communications. 142023b</p>
<p>Mpo: Boosting llm agents with meta plan optimization. Weimin Xiong, Yifan Song, Qingxiu Dong, Bingchan Zhao, Feifan Song, Xun Wang, Sujian Li, ArXiv, abs/2503.026822025</p>
<p>Magic: Investigation of large language model powered multi-agent in cognition, adaptability, rationality and collaboration. Lin Xu, Zhiyuan Hu, Daquan Zhou, Hongyu Ren, Zhen Dong, Kurt Keutzer, See-Kiong Ng, Jiashi Feng, Conference on Empirical Methods in Natural Language Processing. 2023</p>
<p>An Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Zhou, Chengpeng Li, Chengyuan Li, Dayiheng Liu, Fei Huang, Guanting Dong, Haoran Wei, Huan Lin, Jialong Tang, Jialin Wang, Jian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Ma, Jin Xu, Jingren Zhou, Jinze Bai, Jinzheng He, Junyang Lin, Kai Dang, Keming Lu, Ke-Yang Chen, Kexin Yang, Mei Li, Min Xue, Na Ni, Pei Zhang, Peng Wang, Ru Peng, Rui Men, Ruize Gao, Runji Lin, Shijie Wang, Shuai Bai, Sinan Tan, Tianhang Zhu, Tianhao Li, Tianyu Liu, Wenbin Ge, Xiaodong Deng, Xiaohuan Zhou, Xingzhang Ren, Xinyu Zhang, Xipin Wei ; Zhang, Yunyang Wan, Yunfei Chu, Zeyu Cui, Zhenru Zhang, Zhi-Wei Fan, ArXiv, abs/2407.10671Qwen2 technical report. Xuancheng Ren, Yang Fan, Yang Yao, Yichang2024a</p>
<p>. An Yang, arXiv:2412.151152024b5 technical report. arXiv preprint</p>
<p>Moose-chem: Large language models for rediscovering unseen chemistry scientific hypotheses. Zonglin Yang, Wanhao Liu, Ben Gao, Tong Xie, Yuqiang Li, Wanli Ouyang, Soujanya Poria, Erik Cambria, Dongzhan Zhou, ArXiv, abs/2410.070762024c</p>
<p>React: Synergizing reasoning and acting in language models. Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, Yuan Cao, ArXiv, abs/2210.036292022</p>
<p>Chemtoolagent: The impact of tools on language agents for chemistry problem solving. Botao Yu, Frazier N Baker, Ziru Chen, Garrett Herb, Boyu Gou, Daniel Adu-Ampratwum, Xia Ning, Huan Sun, 2024</p>
<p>The chembl database in 2023: a drug discovery platform spanning multiple bioactivity data types and time periods. Barbara Zdrazil, Eloy Felix, Fiona Hunter, Emma J Manners, James Blackshaw, Sybilla Corbett, Marleen De Veij, Harris Ioannidis, David Mendez Lopez, Juan Fernando Mejía, María P Mosquera, Nicolas Magariños, Ricardo Bosc, Tevfik Arcila, Anna Kizilören, A Patrícia Gaulton, Melissa F Bento, Peter Adasme, Gregory A Monecke, Andrew R Landrum, Leach, Nucleic Acids Research. 522023</p>
<p>Honeycomb: A flexible llm-based agent system for materials science. Huan Zhang, Yu Song, Ziyu Hou, Santiago Miret, Bang Liu, Conference on Empirical Methods in Natural Language Processing. 2024a</p>
<p>Exploring collaboration mechanisms for llm agents: A social psychology view. Jintian Zhang, Xin Xu, Ruibo Liu, Shumin Deng, ArXiv, abs/2310.021242023a</p>
<p>How language model hallucinations can snowball. Muru Zhang, Ofir Press, William Merrill, Alisa Liu, Noah A Smith, ArXiv, abs/2305.135342023b</p>
<p>Large language model-based ai agent for organic semiconductor devices research. Qian Zhang, Yongxu Hu, Jiaxin Yan, Hengyue Zhang, Xinyi Xie, Jie Zhu, Huchao Li, Xinxin Niu, Liqiang Li, Yajing Sun, Wenping Hu, Advanced materials. e24051632024b</p>
<p>Scientific large language models: A survey on biological &amp; chemical domains. Qiang Zhang, Keyan Ding, Tianwen Lv, Xinda Wang, Qingyu Yin, Yiwen Zhang, Jing Yu, Yuhao Wang, Xiaotong Li, Zhuoyi Xiang, Zhuang Xiang, Zeyuan Wang, Ming Qin, Mengyao Zhang, Jinlu Zhang, Jiyu Cui, Renjun Xu, Hongyang Chen, Xiaohui Fan, Huabin Xing, Huajun Chen, 2025ACM Computing Surveys</p>
<p>A comprehensive survey of scientific large language models and their applications in scientific discovery. Yu Zhang, Xiusi Chen, Bowen Jin, Sheng Wang, Shuiwang Ji, Wei Wang, Jiawei Han, Conference on Empirical Methods in Natural Language Processing. 2024c</p>
<p>Tao Guo, and Alan Aspuru-Guzik. Deep learning enables rapid identification of potent ddr1 kinase inhibitors. Alex Zhavoronkov, Yan A Ivanenkov, Alexander Aliper, Mark Veselov, Vladimir Aladinskiy, Anastasiya V Aladinskaya, Daniil A Victor A Terentiev, Maksim Polykovskiy, Arip Kuznetsov, Yury Asadulaev, Artem Volkov, Shayakhmetov Zholus, Alexander Rim, Zhebrak, Bogdan Lidiya I Minaeva, Zagribelnyy, H Lennart, Richard M Lee, David Soll, Li Madge, Xing, Nature Biotechnology. 372019</p>
<p>Hypothesis generation with large language models. Yangqiaoyu Zhou, Haokun Liu, Tejes Srivastava, Hongyuan Mei, Chenhao Tan, ArXiv, abs/2404.043262024</p>
<p>A pharmacophore-guided deep learning approach for bioactive molecular generation. Hui Zhu, Renyi Zhou, Dongsheng Cao, Jing Tang, Min Li, Nature Communications. 142023</p>            </div>
        </div>

    </div>
</body>
</html>