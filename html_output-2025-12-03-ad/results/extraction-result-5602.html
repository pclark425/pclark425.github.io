<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-5602 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-5602</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-5602</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-115.html">extraction-schema-115</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <p><strong>Paper ID:</strong> paper-610902</p>
                <p><strong>Paper Title:</strong> <a href="https://arxiv.org/pdf/1712.00557v1.pdf" target="_blank">Recurrent Neural Network Language Models for Open Vocabulary Event-Level Cyber Anomaly Detection</a></p>
                <p><strong>Paper Abstract:</strong> Automated analysis methods are crucial aids for monitoring and defending a network to protect the sensitive or confidential data it hosts. This work introduces a flexible, powerful, and unsupervised approach to detecting anomalous behavior in computer and network logs, one that largely eliminates domain-dependent feature engineering employed by existing methods. By treating system logs as threads of interleaved"sentences"(event log lines) to train online unsupervised neural network language models, our approach provides an adaptive model of normal network behavior. We compare the effectiveness of both standard and bidirectional recurrent neural network language models at detecting malicious activity within network log data. Extending these models, we introduce a tiered recurrent architecture, which provides context by modeling sequences of users' actions over time. Compared to Isolation Forest and Principal Components Analysis, two popular anomaly detection algorithms, we observe superior performance on the Los Alamos National Laboratory Cyber Security dataset. For log-line-level red team detection, our best performing character-based model provides test set area under the receiver operator characteristic curve of 0.98, demonstrating the strong fine-grained anomaly detection performance of this approach on open vocabulary logging sources.</p>
                <p><strong>Cost:</strong> 0.012</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e5602.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e5602.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>EM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Event Model (forward LSTM language model)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A per-log-line recurrent neural network language model using a forward LSTM to predict next-token distributions; anomaly score is the cross-entropy (negative log-probability) assigned to tokens/events.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LSTM RNN language model (forward/unidirectional)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>A token-level Long Short-Term Memory (LSTM) recurrent neural network trained as a language model over individual log-line token sequences (word- or character-level). Inputs are token embeddings (or one-hot/character inputs); outputs are softmax next-token distributions. Trained online/day-by-day using cross-entropy loss and mini-batch BPTT.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_method</strong></td>
                            <td>Scoring: per-token/per-log-line negative log-likelihood (cross-entropy) from the LSTM LM is used as the anomaly score; optionally aggregated per-user-day via max or normalized-diff.</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Structured/semi-structured log lines represented as token sequences (word-level or character-level sequences); sequential per-log-line data</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Outliers / rare/unexpected events (event-level anomalies indicating malicious red-team activity); syntactic/unexpected token sequences in log lines</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>Los Alamos National Laboratory (LANL) Cyber Security Dataset (authentication logs)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Area Under ROC (AUC) and Average Percentile (AP) reported. EM (forward LSTM) achieved comparable performance to aggregated-feature baselines on user-day granularity for character tokenization and outperformed baselines with word tokenization; exact AUCs per variant reported in paper tables/figures (best log-line models outperform day-aggregated).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared to PCA-based anomaly detection and Isolation Forest on 108-dim per-user-day aggregate features, the EM matched or exceeded performance depending on tokenization (word EM > baselines; char EM comparable), though bidirectional models showed larger gains.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Limited to context within a single log-line (no explicit inter-log-line context); performance sensitive to tokenization and normalization choices (word tokenization benefited more from 'diff' normalization); event-level EM generally inferior to bidirectional variants; interpretability lower for character tokenization.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Recurrent Neural Network Language Models for Open Vocabulary Event-Level Cyber Anomaly Detection', 'publication_date_yy_mm': '2017-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5602.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e5602.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BEM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Bidirectional Event Model (bidirectional LSTM language model)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A bidirectional LSTM language model over tokens in a log-line that uses both forward and backward LSTMs to predict token probabilities; per-log-line cross-entropy is used as the anomaly score.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Bidirectional LSTM language model</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>A bidirectional recurrent neural network where forward and backward LSTMs are run over each log-line; token prediction at position t conditions on forward hidden state up to t-1 and backward hidden state from t+1, combined via affine transforms into a softmax. Implemented for both character- and word-level tokenizations and trained online with cross-entropy loss.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_method</strong></td>
                            <td>Scoring: per-token/per-log-line negative log-likelihood (cross-entropy) from the bidirectional LM used as anomaly score; supports event-level alerts and aggregation (max, diff) to user-day scores.</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Structured/semi-structured log lines as token sequences (sequences of characters or words); operates at log-line (sequence) granularity</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Outliers / rare or unexpected sequences within log lines indicating malicious activity (red-team events); syntactic and token-sequence anomalies detected at fine granularity</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>Los Alamos National Laboratory (LANL) Cyber Security Dataset (authentication logs)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Reported metrics: AUC and Average Percentile (AP). The best reported model overall was a bidirectional character-level model at log-line granularity achieving AUC = 0.98 on the test set; event-level bidirectional models substantially outperformed day-level aggregate baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Bidirectional language models significantly outperformed PCA and Isolation Forest baselines on day-level detection; at event/log-line granularity the bidirectional character model substantially outperformed both the best day-level language model and the aggregate baselines (e.g., 100% recall at 12% of data for the char event model vs near-all-data for baselines).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Although highly effective, character-level bidirectional models reduce interpretability versus word-level models; performance depends on normalization (diff vs max) and tokenization; model size/compute not detailed and robustness to adversarial tampering not evaluated.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Recurrent Neural Network Language Models for Open Vocabulary Event-Level Cyber Anomaly Detection', 'publication_date_yy_mm': '2017-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5602.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e5602.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>T-EM / T-BEM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Tiered Event Models (tiered LSTM architectures: T-EM and T-BEM)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A two-tier recurrent architecture where a lower-tier LSTM models tokens within each log-line and an upper-tier LSTM models sequences of users' log-lines over time, passing context vectors from upper to lower tier.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Tiered LSTM language model (hierarchical RNN)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>A hierarchical model: lower-tier is an event-level LSTM (EM or BEM) producing hidden states per token; for each log-line the lower-tier final and averaged hidden states are fed sequentially into an upper-tier LSTM that models user behavior across log-lines and produces context vectors concatenated into lower-tier inputs for subsequent log-lines. Jointly trained to minimize lower-tier cross-entropy loss.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_method</strong></td>
                            <td>Scoring: lower-tier cross-entropy loss (per-token/per-log-line) used as anomaly score; upper tier provides contextual conditioning across a user's sequence of events but no direct loss is computed on upper-tier outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Structured/semi-structured log lines organized into sequences per user (sequence-of-sequences: tokens within log-lines and sequences of log-lines per user)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Temporal/contextual anomalies across sequences of user actions (anomalous transitions/behavior over time), as well as rare/unlikely individual log-line events</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>Los Alamos National Laboratory (LANL) Cyber Security Dataset (authentication logs)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Evaluated with AUC and Average Percentile (AP). Tiered models performed comparably to event-level models but did not show consistent improvement over the best event-level (EM/BEM) models in these experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Tiered models did not outperform single-log-line event models or the bidirectional event models; event-level bidirectional LMs still yielded better detection performance than classic aggregate baselines (PCA, Isolation Forest).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Minibatching/implementation complexity due to variable numbers of log-lines per user; potential inefficiency from truncating users' log-lines; in experiments tiered models did not improve detection (suggesting event-level models captured sufficient context in weights), and authors note tiered models might be more beneficial when modeling PCs rather than users or using richer log sources.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Recurrent Neural Network Language Models for Open Vocabulary Event-Level Cyber Anomaly Detection', 'publication_date_yy_mm': '2017-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5602.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e5602.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Tokenization variants</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Character-level and Word-level tokenization strategies</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Two tokenization granularities used as model inputs: character-level (printable ASCII alphabet including delimiters) and word-level (space-delimited tokens with fixed vocabulary and <oov> token), each affecting open-vocabulary handling, interpretability, and detection latency.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Character-level tokenization; Word-level tokenization</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Character-level: uses printable ASCII characters (including delimiters) as tokens, eliminating open-vocab issues and representing any log entry; supports immediate scoring without per-day vocabulary stats. Word-level: splits on delimiters to create a vocabulary of frequent tokens and uses an <oov> token for unseen words; yields more interpretable per-field anomaly attributions.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_method</strong></td>
                            <td>Used as input representation to the LSTM language models; anomaly scoring unchanged (cross-entropy) but tokenization affects modeling granularity, adaptability to unseen tokens, and normalization requirements.</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Structured/semi-structured log lines tokenized into sequences (either character sequences or word/token sequences)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Character-level captures fine-grained syntactic anomalies and novel token strings (e.g., new IPs, usernames); word-level detects anomalies in field-level token patterns and is more interpretable for field contributions.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>Los Alamos National Laboratory (LANL) Cyber Security Dataset (authentication logs)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Both AUC and AP reported. Word tokenization generally performed better with diff normalization at day-level; however, the best event/log-line-level performance was achieved by a bidirectional character-level model with AUC = 0.98. Character-level models achieved very high percentiles for red-team events (many above 95th/99th percentile).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Character-level models provided faster response (less dependence on day-level statistics) and matched/exceeded baseline performance at event granularity; word-level models provided decomposability and sometimes better day-level performance after normalization.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Word-level requires vocabulary management and <oov> handling; sensitive to normalization (diff) and may need periodic vocabulary updates in online settings. Character-level models reduce interpretability of which log-line fields caused the anomaly and may need additional tooling for analyst context. Both were tuned on diff mode (word models reliant on diff).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Recurrent Neural Network Language Models for Open Vocabulary Event-Level Cyber Anomaly Detection', 'publication_date_yy_mm': '2017-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5602.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e5602.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Overall approach</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>RNN language models for open-vocabulary event-level cyber anomaly detection</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Unsupervised online anomaly detection by treating log lines as token sequences and training recurrent neural network language models (unidirectional, bidirectional, and tiered) to assign probabilities to events; low-probability events are flagged as anomalies.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Recurrent Neural Network Language Models for Open Vocabulary Event-Level Cyber Anomaly Detection</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>RNN-based language modeling (LSTM/BiLSTM, tiered LSTM)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>An online system that trains LSTM-based language models each day on previous activity, assigns per-token/per-log-line cross-entropy as anomaly scores, and optionally aggregates to per-user-day scores (max or diff normalization). Implemented in TensorFlow and evaluated on authentication logs.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_method</strong></td>
                            <td>Unsupervised scoring: language model log-likelihood (cross-entropy) used as anomaly measure; online incremental training (for each day produce scores then update model on that day's data). Supports event-level and aggregated per-user-day alerts.</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Structured/semi-structured event logs (authentication log lines) represented as token sequences; modeling both intra-log-line sequences and sequences of log-lines per user (tiered)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Operational anomalies manifested as unexpected or rare log-line token sequences and unusual sequences of user actions over time (red-team compromise events); effectively outliers/rare behavior detection</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>Los Alamos National Laboratory (LANL) Cyber Security Dataset (authentication logs)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Primary metrics: Area Under ROC (AUC) and Average Percentile (AP). Best reported: bidirectional character-level event model achieved AUC = 0.98 at log-line granularity. Character event model: 100% recall at 12% of data flagged; 80% recall at 3% flagged (compared to 14% and 55% for other models/baselines respectively).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Language-model approach (especially bidirectional and event-level char models) outperformed typical aggregated-feature unsupervised baselines (Isolation Forest, PCA) on LANL authentication logs, providing superior detection at much lower analyst review budgets.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Does not evaluate adversarial robustness; tiered architectures did not improve performance in current experiments; weekends/holidays excluded because distributions differ and separate models would be needed; interpretability challenges for character models; hyperparameters tuned on dev set (diff) so some variants may need further tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Recurrent Neural Network Language Models for Open Vocabulary Event-Level Cyber Anomaly Detection', 'publication_date_yy_mm': '2017-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>A neural network component for an intrusion detection system <em>(Rating: 2)</em></li>
                <li>Bidirectional recurrent neural networks <em>(Rating: 2)</em></li>
                <li>Pascanu, R.; Stokes, J. W.; Sanossian, H.; Marinescu, M.; and Thomas, A. 2015. Malware classification with recurrent networks <em>(Rating: 2)</em></li>
                <li>Turcotte, M.; Moore, J.; Heard, N.; and McPhall, A. 2016. Poisson factorization for peer-based anomaly detection <em>(Rating: 2)</em></li>
                <li>Tuor, A.; Kaplan, S.; Hutchinson, B.; Nichols, N.; and Robinson, S. 2017. Deep learning for unsupervised insider threat detection in structured cybersecurity data streams <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-5602",
    "paper_id": "paper-610902",
    "extraction_schema_id": "extraction-schema-115",
    "extracted_data": [
        {
            "name_short": "EM",
            "name_full": "Event Model (forward LSTM language model)",
            "brief_description": "A per-log-line recurrent neural network language model using a forward LSTM to predict next-token distributions; anomaly score is the cross-entropy (negative log-probability) assigned to tokens/events.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "LSTM RNN language model (forward/unidirectional)",
            "model_description": "A token-level Long Short-Term Memory (LSTM) recurrent neural network trained as a language model over individual log-line token sequences (word- or character-level). Inputs are token embeddings (or one-hot/character inputs); outputs are softmax next-token distributions. Trained online/day-by-day using cross-entropy loss and mini-batch BPTT.",
            "model_size": null,
            "anomaly_detection_method": "Scoring: per-token/per-log-line negative log-likelihood (cross-entropy) from the LSTM LM is used as the anomaly score; optionally aggregated per-user-day via max or normalized-diff.",
            "data_type": "Structured/semi-structured log lines represented as token sequences (word-level or character-level sequences); sequential per-log-line data",
            "anomaly_type": "Outliers / rare/unexpected events (event-level anomalies indicating malicious red-team activity); syntactic/unexpected token sequences in log lines",
            "dataset_name": "Los Alamos National Laboratory (LANL) Cyber Security Dataset (authentication logs)",
            "performance_metrics": "Area Under ROC (AUC) and Average Percentile (AP) reported. EM (forward LSTM) achieved comparable performance to aggregated-feature baselines on user-day granularity for character tokenization and outperformed baselines with word tokenization; exact AUCs per variant reported in paper tables/figures (best log-line models outperform day-aggregated).",
            "baseline_comparison": "Compared to PCA-based anomaly detection and Isolation Forest on 108-dim per-user-day aggregate features, the EM matched or exceeded performance depending on tokenization (word EM &gt; baselines; char EM comparable), though bidirectional models showed larger gains.",
            "limitations_or_failure_cases": "Limited to context within a single log-line (no explicit inter-log-line context); performance sensitive to tokenization and normalization choices (word tokenization benefited more from 'diff' normalization); event-level EM generally inferior to bidirectional variants; interpretability lower for character tokenization.",
            "uuid": "e5602.0",
            "source_info": {
                "paper_title": "Recurrent Neural Network Language Models for Open Vocabulary Event-Level Cyber Anomaly Detection",
                "publication_date_yy_mm": "2017-12"
            }
        },
        {
            "name_short": "BEM",
            "name_full": "Bidirectional Event Model (bidirectional LSTM language model)",
            "brief_description": "A bidirectional LSTM language model over tokens in a log-line that uses both forward and backward LSTMs to predict token probabilities; per-log-line cross-entropy is used as the anomaly score.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Bidirectional LSTM language model",
            "model_description": "A bidirectional recurrent neural network where forward and backward LSTMs are run over each log-line; token prediction at position t conditions on forward hidden state up to t-1 and backward hidden state from t+1, combined via affine transforms into a softmax. Implemented for both character- and word-level tokenizations and trained online with cross-entropy loss.",
            "model_size": null,
            "anomaly_detection_method": "Scoring: per-token/per-log-line negative log-likelihood (cross-entropy) from the bidirectional LM used as anomaly score; supports event-level alerts and aggregation (max, diff) to user-day scores.",
            "data_type": "Structured/semi-structured log lines as token sequences (sequences of characters or words); operates at log-line (sequence) granularity",
            "anomaly_type": "Outliers / rare or unexpected sequences within log lines indicating malicious activity (red-team events); syntactic and token-sequence anomalies detected at fine granularity",
            "dataset_name": "Los Alamos National Laboratory (LANL) Cyber Security Dataset (authentication logs)",
            "performance_metrics": "Reported metrics: AUC and Average Percentile (AP). The best reported model overall was a bidirectional character-level model at log-line granularity achieving AUC = 0.98 on the test set; event-level bidirectional models substantially outperformed day-level aggregate baselines.",
            "baseline_comparison": "Bidirectional language models significantly outperformed PCA and Isolation Forest baselines on day-level detection; at event/log-line granularity the bidirectional character model substantially outperformed both the best day-level language model and the aggregate baselines (e.g., 100% recall at 12% of data for the char event model vs near-all-data for baselines).",
            "limitations_or_failure_cases": "Although highly effective, character-level bidirectional models reduce interpretability versus word-level models; performance depends on normalization (diff vs max) and tokenization; model size/compute not detailed and robustness to adversarial tampering not evaluated.",
            "uuid": "e5602.1",
            "source_info": {
                "paper_title": "Recurrent Neural Network Language Models for Open Vocabulary Event-Level Cyber Anomaly Detection",
                "publication_date_yy_mm": "2017-12"
            }
        },
        {
            "name_short": "T-EM / T-BEM",
            "name_full": "Tiered Event Models (tiered LSTM architectures: T-EM and T-BEM)",
            "brief_description": "A two-tier recurrent architecture where a lower-tier LSTM models tokens within each log-line and an upper-tier LSTM models sequences of users' log-lines over time, passing context vectors from upper to lower tier.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Tiered LSTM language model (hierarchical RNN)",
            "model_description": "A hierarchical model: lower-tier is an event-level LSTM (EM or BEM) producing hidden states per token; for each log-line the lower-tier final and averaged hidden states are fed sequentially into an upper-tier LSTM that models user behavior across log-lines and produces context vectors concatenated into lower-tier inputs for subsequent log-lines. Jointly trained to minimize lower-tier cross-entropy loss.",
            "model_size": null,
            "anomaly_detection_method": "Scoring: lower-tier cross-entropy loss (per-token/per-log-line) used as anomaly score; upper tier provides contextual conditioning across a user's sequence of events but no direct loss is computed on upper-tier outputs.",
            "data_type": "Structured/semi-structured log lines organized into sequences per user (sequence-of-sequences: tokens within log-lines and sequences of log-lines per user)",
            "anomaly_type": "Temporal/contextual anomalies across sequences of user actions (anomalous transitions/behavior over time), as well as rare/unlikely individual log-line events",
            "dataset_name": "Los Alamos National Laboratory (LANL) Cyber Security Dataset (authentication logs)",
            "performance_metrics": "Evaluated with AUC and Average Percentile (AP). Tiered models performed comparably to event-level models but did not show consistent improvement over the best event-level (EM/BEM) models in these experiments.",
            "baseline_comparison": "Tiered models did not outperform single-log-line event models or the bidirectional event models; event-level bidirectional LMs still yielded better detection performance than classic aggregate baselines (PCA, Isolation Forest).",
            "limitations_or_failure_cases": "Minibatching/implementation complexity due to variable numbers of log-lines per user; potential inefficiency from truncating users' log-lines; in experiments tiered models did not improve detection (suggesting event-level models captured sufficient context in weights), and authors note tiered models might be more beneficial when modeling PCs rather than users or using richer log sources.",
            "uuid": "e5602.2",
            "source_info": {
                "paper_title": "Recurrent Neural Network Language Models for Open Vocabulary Event-Level Cyber Anomaly Detection",
                "publication_date_yy_mm": "2017-12"
            }
        },
        {
            "name_short": "Tokenization variants",
            "name_full": "Character-level and Word-level tokenization strategies",
            "brief_description": "Two tokenization granularities used as model inputs: character-level (printable ASCII alphabet including delimiters) and word-level (space-delimited tokens with fixed vocabulary and &lt;oov&gt; token), each affecting open-vocabulary handling, interpretability, and detection latency.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Character-level tokenization; Word-level tokenization",
            "model_description": "Character-level: uses printable ASCII characters (including delimiters) as tokens, eliminating open-vocab issues and representing any log entry; supports immediate scoring without per-day vocabulary stats. Word-level: splits on delimiters to create a vocabulary of frequent tokens and uses an &lt;oov&gt; token for unseen words; yields more interpretable per-field anomaly attributions.",
            "model_size": null,
            "anomaly_detection_method": "Used as input representation to the LSTM language models; anomaly scoring unchanged (cross-entropy) but tokenization affects modeling granularity, adaptability to unseen tokens, and normalization requirements.",
            "data_type": "Structured/semi-structured log lines tokenized into sequences (either character sequences or word/token sequences)",
            "anomaly_type": "Character-level captures fine-grained syntactic anomalies and novel token strings (e.g., new IPs, usernames); word-level detects anomalies in field-level token patterns and is more interpretable for field contributions.",
            "dataset_name": "Los Alamos National Laboratory (LANL) Cyber Security Dataset (authentication logs)",
            "performance_metrics": "Both AUC and AP reported. Word tokenization generally performed better with diff normalization at day-level; however, the best event/log-line-level performance was achieved by a bidirectional character-level model with AUC = 0.98. Character-level models achieved very high percentiles for red-team events (many above 95th/99th percentile).",
            "baseline_comparison": "Character-level models provided faster response (less dependence on day-level statistics) and matched/exceeded baseline performance at event granularity; word-level models provided decomposability and sometimes better day-level performance after normalization.",
            "limitations_or_failure_cases": "Word-level requires vocabulary management and &lt;oov&gt; handling; sensitive to normalization (diff) and may need periodic vocabulary updates in online settings. Character-level models reduce interpretability of which log-line fields caused the anomaly and may need additional tooling for analyst context. Both were tuned on diff mode (word models reliant on diff).",
            "uuid": "e5602.3",
            "source_info": {
                "paper_title": "Recurrent Neural Network Language Models for Open Vocabulary Event-Level Cyber Anomaly Detection",
                "publication_date_yy_mm": "2017-12"
            }
        },
        {
            "name_short": "Overall approach",
            "name_full": "RNN language models for open-vocabulary event-level cyber anomaly detection",
            "brief_description": "Unsupervised online anomaly detection by treating log lines as token sequences and training recurrent neural network language models (unidirectional, bidirectional, and tiered) to assign probabilities to events; low-probability events are flagged as anomalies.",
            "citation_title": "Recurrent Neural Network Language Models for Open Vocabulary Event-Level Cyber Anomaly Detection",
            "mention_or_use": "use",
            "model_name": "RNN-based language modeling (LSTM/BiLSTM, tiered LSTM)",
            "model_description": "An online system that trains LSTM-based language models each day on previous activity, assigns per-token/per-log-line cross-entropy as anomaly scores, and optionally aggregates to per-user-day scores (max or diff normalization). Implemented in TensorFlow and evaluated on authentication logs.",
            "model_size": null,
            "anomaly_detection_method": "Unsupervised scoring: language model log-likelihood (cross-entropy) used as anomaly measure; online incremental training (for each day produce scores then update model on that day's data). Supports event-level and aggregated per-user-day alerts.",
            "data_type": "Structured/semi-structured event logs (authentication log lines) represented as token sequences; modeling both intra-log-line sequences and sequences of log-lines per user (tiered)",
            "anomaly_type": "Operational anomalies manifested as unexpected or rare log-line token sequences and unusual sequences of user actions over time (red-team compromise events); effectively outliers/rare behavior detection",
            "dataset_name": "Los Alamos National Laboratory (LANL) Cyber Security Dataset (authentication logs)",
            "performance_metrics": "Primary metrics: Area Under ROC (AUC) and Average Percentile (AP). Best reported: bidirectional character-level event model achieved AUC = 0.98 at log-line granularity. Character event model: 100% recall at 12% of data flagged; 80% recall at 3% flagged (compared to 14% and 55% for other models/baselines respectively).",
            "baseline_comparison": "Language-model approach (especially bidirectional and event-level char models) outperformed typical aggregated-feature unsupervised baselines (Isolation Forest, PCA) on LANL authentication logs, providing superior detection at much lower analyst review budgets.",
            "limitations_or_failure_cases": "Does not evaluate adversarial robustness; tiered architectures did not improve performance in current experiments; weekends/holidays excluded because distributions differ and separate models would be needed; interpretability challenges for character models; hyperparameters tuned on dev set (diff) so some variants may need further tuning.",
            "uuid": "e5602.4",
            "source_info": {
                "paper_title": "Recurrent Neural Network Language Models for Open Vocabulary Event-Level Cyber Anomaly Detection",
                "publication_date_yy_mm": "2017-12"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "A neural network component for an intrusion detection system",
            "rating": 2,
            "sanitized_title": "a_neural_network_component_for_an_intrusion_detection_system"
        },
        {
            "paper_title": "Bidirectional recurrent neural networks",
            "rating": 2,
            "sanitized_title": "bidirectional_recurrent_neural_networks"
        },
        {
            "paper_title": "Pascanu, R.; Stokes, J. W.; Sanossian, H.; Marinescu, M.; and Thomas, A. 2015. Malware classification with recurrent networks",
            "rating": 2,
            "sanitized_title": "pascanu_r_stokes_j_w_sanossian_h_marinescu_m_and_thomas_a_2015_malware_classification_with_recurrent_networks"
        },
        {
            "paper_title": "Turcotte, M.; Moore, J.; Heard, N.; and McPhall, A. 2016. Poisson factorization for peer-based anomaly detection",
            "rating": 2,
            "sanitized_title": "turcotte_m_moore_j_heard_n_and_mcphall_a_2016_poisson_factorization_for_peerbased_anomaly_detection"
        },
        {
            "paper_title": "Tuor, A.; Kaplan, S.; Hutchinson, B.; Nichols, N.; and Robinson, S. 2017. Deep learning for unsupervised insider threat detection in structured cybersecurity data streams",
            "rating": 2,
            "sanitized_title": "tuor_a_kaplan_s_hutchinson_b_nichols_n_and_robinson_s_2017_deep_learning_for_unsupervised_insider_threat_detection_in_structured_cybersecurity_data_streams"
        }
    ],
    "cost": 0.012108,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Recurrent Neural Network Language Models for Open Vocabulary Event-Level Cyber Anomaly Detection</p>
<p>Aaron Tuor 
Pacific Northwest National Laboratory Richland
Washington</p>
<p>Ryan Baerwolf 
Western Washington University Bellingham
Washington</p>
<p>Nicolas Knowles 
Western Washington University Bellingham
Washington</p>
<p>Brian Hutchinson 
Pacific Northwest National Laboratory Richland
Washington</p>
<p>Western Washington University Bellingham
Washington</p>
<p>Nicole Nichols 
Pacific Northwest National Laboratory Richland
Washington</p>
<p>Robert Jasper 
Pacific Northwest National Laboratory Richland
Washington</p>
<p>Recurrent Neural Network Language Models for Open Vocabulary Event-Level Cyber Anomaly Detection</p>
<p>Automated analysis methods are crucial aids for monitoring and defending a network to protect the sensitive or confidential data it hosts. This work introduces a flexible, powerful, and unsupervised approach to detecting anomalous behavior in computer and network logs; one that largely eliminates domain-dependent feature engineering employed by existing methods. By treating system logs as threads of interleaved "sentences" (event log lines) to train online unsupervised neural network language models, our approach provides an adaptive model of normal network behavior. We compare the effectiveness of both standard and bidirectional recurrent neural network language models at detecting malicious activity within network log data. Extending these models, we introduce a tiered recurrent architecture, which provides context by modeling sequences of users' actions over time. Compared to Isolation Forest and Principal Components Analysis, two popular anomaly detection algorithms, we observe superior performance on the Los Alamos National Laboratory Cyber Security dataset. For log-line-level red team detection, our best performing character-based model provides test set area under the receiver operator characteristic curve of 0.98, demonstrating the strong fine-grained anomaly detection performance of this approach on open vocabulary logging sources.</p>
<p>Introduction</p>
<p>To minimize cyber security risks, it is essential that organizations be able to rapidly detect and mitigate malicious activity on their computer networks. These threats can originate from a variety of sources including malware, phishing, port scanning, etc. Attacks can lead to unauthorized network access to perpetrate further damage such as theft of credentials, intellectual property, and other business sensitive information. In a typical scenario, cyber defenders and network administrators are tasked with sifting through vast amounts of data from various logging sources to assess potential security risks. Unfortunately, the amount of data for even a modestly-sized network can quickly grow beyond the ability of a single person or team to assess, leading to delayed response. The desire for automated assistance has and continues to encourage inter-domain research in cyber security and machine learning.</p>
<p>Signature-based approaches for automated detection can be highly effective for characterizing individual threats. De-spite their high precision, they suffer from low recall and may fail to detect subtle mutations or novel attacks. Alternatively, given an unlabeled training set of typically benign activity logs, one can build a model of "normal behavior". During online joint training and evaluation of this model, patterns of normal usage will be reinforced and atypical malicious activity will stand out as anomalous. The features used to identify unusual behavior are typically statistical feature vectors associated with time slices, e.g., vectors of counts for types of activities taking place in a 24-hour window. Such systems developed in research have been criticized as brittle to differences in site-specific properties of real-world operational networks such as security constraints and variable usage patterns (Sommer and Paxson 2010).</p>
<p>The approach we introduce aims to minimize site-specific assumptions implicit in feature engineering, and effectively model variability in network usage by direct online learning of language models over log lines. Language models assign probabilities to sequences of tokens and are a core component of speech recognition, machine translation, and other language processing systems. Specifically, we explore the effectiveness of several recurrent neural network (RNN) language models for use in a network anomaly detection system. Our system dynamically updates the network language model each day based on the previous day's events. When the language model assigns a low probability to a log-line it is flagged as anomalous. There are several advantages to this approach:</p>
<ol>
<li>
<p>Reduced feature engineering: Our model acts directly on raw string tokens, rather than hand-designed domainspecific statistics. This dramatically reduces the time to deployment, and makes it agnostic to the specific network or logging source configuration. It also removes the "blind spots" introduced when tens of thousands of log-lines are distilled down to a single aggregated feature vector, allowing our model to capture patterns that would have otherwise been lost.</p>
</li>
<li>
<p>Fine grained assessment: The response time for analysts can be improved by providing more specific and relevant events of interest. Baseline systems that alert to a user's day aggregate require sifting through tens of thousands of actions. Our approach can provide log-line-level or even token-level scores to the analyst, helping them quickly lo-cate the suspicious activity.</p>
</li>
<li>
<p>Real time processing: With the ability to process events in real time and fixed bounds on memory usage which do not grow over time, our approach is suitable for the common scenario in which log-line events are appearing in a high-volume, high-velocity log stream.</p>
</li>
</ol>
<p>We assess our models using the publicly available Los Alamos National Laboratory (LANL) Cyber Security Dataset, which contains real (de-identified) data with ground truth red team attacks, and demonstrate language models definitively outperforming standard unsupervised anomaly detection approaches.</p>
<p>Prior work</p>
<p>Machine learning has been widely explored for network anomaly detection, with techniques such as isolation forest (Gavai et al. 2015;Liu, Ting, and Zhou 2008) and principal component analysis (Novakov et al. 2013;Ringberg et al. 2007) attracting significant interest. Machine learning classifiers ranging from decision trees to Nave Bayes have been used for cyber security tasks such as malware detection, network intrusion, and insider threat detection. Extensive discussion of machine learning applications in cyber security is presented in (Bhattacharyya and Kalita 2013; Buczak and Guven 2016;Dua and Du 2016;Kumar, Kumar, and Sachdeva 2010;Zuech, Khoshgoftaar, and Wald 2015;Rubin-Delanchy, Lawson, and Heard 2016).</p>
<p>Deep learning approaches are also gaining adoption for specialized cyber defense tasks. In an early use of recurrent neural networks, Debar, Becker, and Siboni (1992) model sequences of Unix shell commands for network intrusion detection. Anomaly detection has been demonstrated using deep belief networks on the KDD Cup 1999 dataset (Alrawashdeh and Purdy 2016), and Bivens et al. (2002) use multi-layer perceptrons for the DARPA 1999 dataset. Both approaches use aggregated features and synthetic network data. Tuor et al. (2017) andVeeramachaneni et al. (2016) both employ deep neural network autoencoders for unsupervised network anomaly detection using time aggregated statistics as features.</p>
<p>Some works of note have been previously published on the LANL data. Turcotte, Heard and Kent (2016) develop an online statistical model for anomaly detection in network activity using Multinomial-Dirichlet models. Similarly, Turcotte et al. (2016) use Poission Factorization (Gopalan, Hofman, and Blei 2013) on the LANL authentication logs. A user/computer authentication count matrix is constructed by assuming each count comes from a Poisson distribution parameterized by latent factors for users and computers. The learned distributions are then used to predict unlikely authentication behavior.</p>
<p>Several variants of tiered recurrent networks have been explored in the machine learning and natural language processing communities (Koutnik et al. 2014;Ling et al. 2015b;Ling et al. 2015a;Chung et al. 2015). They are often realized by a lower tier pre-processing network, whose output is fed to an upper tier network and the separate tiers are jointly trained. Ling et al. (2015b) use a character-level convolutional neural network to feed a word level long short-term memory (LSTM) RNN for machine translation, with predictions made at the word-level. Both Hwang and Sung (2016) and Ling et al. (2015a) use a character-based LSTM to feed a second word or utterance-based LSTM for language modeling. Pascanu et al. (2015) create activity models from real world data on a per-event (command) basis and sequences of system calls are then modeled using RNN and echo state networks. The learned features are used to independently train neural network and logistic regression classifiers. Max pooling is applied to hidden layers of the unsupervised RNN for each time step in a session and the result is concatenated to the final hidden state to produce feature vectors for the classifier. This is similar to our tiered approach, in which we use the average of all hidden states concatenated with the final hidden state as input to the upper-tier RNN. In contrast, our model is completely unsupervised and all components are jointly trained.</p>
<p>Approach</p>
<p>Our approach learns normal behavior for users, processing a stream of computer and network log-lines as follows: 1. Initialize model weights randomly 2. For each day k in chronological order:</p>
<p>(a) Given model M k1 , produce log-line-level anomaly scores for all events in day k (b) Optionally, produce an aggregated anomaly score each user for day k (from the log-line-level scores) (c) Send per-user-day or per-user-event anomaly scores in rank order to analysts for inspection (d) Update model weights to minimize loss on all log-lines in day k, yielding model M k</p>
<p>This methodology interleaves detection and training in an online fashion. In this section we detail the components of our approach.</p>
<p>Log-Line Tokenization</p>
<p>To work directly from arbitrary log formats, we treat loglines as sequences of tokens. For this work, we consider two tokenization granularities: word-level and character-level.</p>
<p>For word tokenization, we assume that tokens in the logline are delimited by a known character (e.g., space or comma). After splitting the log-lines on this delimiter, we define a shared vocabulary of "words" over all log fields, consisting of the sufficiently-frequent tokens appearing in the training set. To allow our model to handle previously unseen tokens, we add an "out of vocbulary" token to our vocabulary, <oov>. (For instance, not every IP address will be represented in a training set; likewise, new PCs and users are continually being added to large networks.) To ensure that <oov> has non-zero probability, we replace sufficiently infrequent tokens in the training data with <oov>. During evaluation, tokens not seen before are labeled <oov>. In order to accommodate shifting word distributions in an online environment, a fixed size vocabulary could be periodically updated using a sliding window of word frequency statistics. For simplicity, we assume we have a fixed training set from which we produce a fixed vocabulary.</p>
<p>To avoid the challenges of managing a word-level vocabulary, we also develop language models using a characterlevel tokenization. In this case our primitive vocabulary, the alphabet of printable ASCII characters, circumvents the open vocabulary issue by its ability to represent any log entry irrespective of the network, logging source, or log field. With character-level tokenization, we keep the delimiter token in the sequence, to provide our models with cues to transitions between log-line fields.</p>
<p>Recurrent Neural Network Language Models</p>
<p>To produce log-line-level anomaly scores, we use recurrent neural networks in two ways: 1) as a language model over individual log-lines, and 2) to model the state of a user over time. We first present two recurrent models that focus only on (1), and then a tiered model that accomplishes both (1) and (2). Both were implemented 1 for our experiments using TensorFlow (Abadi et al. 2015).</p>
<p>Event Model (EM). First we consider a simple RNN model that operates on the token (e.g., word) sequences of individual log-lines (events). Specifically, we consider a Long Short-Term Memory (LSTM) (Hochreiter and Schmidhuber 1997) network whose inputs are token embeddings and from whose output we predict distributions over the next token.</p>
<p>For a log-line with K tokens, each drawn from a shared vocabulary of size C, let X (1:K) = x (1) , x (2) , . . . , x (K) denote a sequence of one-hot representations of the tokens (each x (t)  R C ).</p>
<p>In this model, the hidden representation at token t, h (t) , from which we make our predictions, is a function of x (1) , x (2) , . . . , x (t) according to the usual LSTM equations:
h (t) = o (t)  tanh(c (t) ) (1) c (t) = f (t)  c (t1) + i (t)  g (t)
(2)
g (t) = tanh x (t) W (g,x) + h (t1) W (g,h) + b (g) (3) f (t) =  x (t) W (f,x) + h (t1) W (f,h) + b (f ) (4) i (t) =  x (t) W (i,x) + h (t1) W (i,h) + b (i)(5)o (t) =  x (t) W (o,x) + h (t1) W (o,h) + b (o) ,(6)
where the initial hidden and cell states, c (0) and h (0) , are set to zero vectors, and  and  denote element-wise multiplication and logistic sigmoid, respectively. Vector g (t) is a hidden representation based on the current input and previous hidden state, while vectors f (t) , i (t) , and o (t) , are the standard LSTM gates. The matrices (W) and bias vectors (b) are the model parameters. We use each h (t1) to produce a probability distribution p (t) over the token at time t, as follows:
p (t) = softmax h (t1) W (p) + b (p)(7)
1 Code will soon be available at https://github.com/pnnl/safekit We use cross-entropy loss,
LSTM LSTM  softmax softmax LSTM x (K-1) softmax p (2) p (K) LSTM LSTM LSTM x (1) x (3) x (2) <eos> LSTM softmax p (K-1) LSTM x (K-2) x (K) p(1 K K t=1 H(x (t) , p (t) ),(8)
for two important purposes: first, as per-log-line anomaly score and second, as the training objective to update model weights. We train this model using stochastic mini-batch (non-truncated) back-propagation through time.</p>
<p>Bidirectional Event Model (BEM). Following the language model formulation suggested in (Schuster and Paliwal 1997), we alternatively model the structure of log lines with a bidirectional LSTM. We define a new set of hidden vec-
tors h b (K+1) , h b (K) , . . . , h b
(1) by running the LSTM equations backwards in time (starting with initial zero cell and hidden states at time K + 1 set to zero). The weights W and biases b for the backward LSTM are denoted with superscript b.</p>
<p>The probability distribution p (t) over the token at time t is then:
p (t) = softmax h (t1) W (p) + h b (t+1) W b (p) + b (p) (9)
Tiered Event Models (T-EM, T-BEM). To incorporate inter-log-line context, we propose a two-tiered recurrent neural network. The lower-tier can be either event model (EM or BEM), but with the additional input of a context vector (generated by the upper-tier) concatenated to the token embedding at each time step. The input to the upper-tier model is the hidden states of the lower-tier model. This upper tier models the dynamics of user behavior over time, producing the context vectors provided to the lower-tier RNN. This model is illustrated in Fig. 2. In this model, x (u,j) denotes user u's jth log line, which consists of a sequence of tokens as described in the previous subsections. The upper-tier models a sequence of user log lines, x (u,1) , x (u,2) , . . . , x (u,Tu) , using an LSTM. For each user u and each log line j in the user's log line sequence, a lower-tier LSTM is applied to the tokens of x (u,j) . The input to the upper-tier model at log-line j is the concatenation of: 1) the final lower-tier hidden state(s) and 2) the average of the lower-tier hidden states. In the case of a lower-tier EM, (1) refers to the hidden state at time K; for the BEM, (1) is the concatenation of the forward hidden state at time K and the backward hidden state at time 1. For (2), we average over hidden states primarily to provide many short-cut connections in the LSTM, which aids trainability. The output of the upper-tier LSTM at log-line j is a hidden stat h (u,j) . This hidden vector serves to provide context for the lower-tier model at the next time step: specifically, (u,j1) is concatenated to each of the inputs of the lower-tier model operating on the jth log-line. Note that the upper-tier model serves only to propagate context information across individual log-lines; no loss is computed directly on the values produced by the upper-tier model. The upper-and lower-tier models are trained jointly to minimize the cross-entropy loss of the lower-tier model. We unroll the two-tier model for a fixed number of log-lines, fully unrolling each of the lower-tier models within that window. The lower-tier model's cross-entropy loss is also used to detect anomalous behavior, as is described further in Section 4.2.</p>
<p>Minibatching becomes more challenging for the tiered model, as the number of log-lines per day can vary dramatically between users. This poses two problems: first, it introduces the possibility that the most active users may have a disproportionate impact on model weights; second, it means that toward the end of the day, there may not be enough users to fill the minibatch. To counteract the first problem, we fix the number of log-lines per user per day that the model will train on. The remaining log-lines are not used in any gradient updates. We leave compensating for the inefficiency that results from the second to future work.</p>
<p>Baselines</p>
<p>Anomaly detection in streaming network logs often relies upon computing statistics over windows of time and applying anomaly detection techniques to those vectors. Below we describe the aggregate features and two anomaly detection techniques that are typical of prior work.</p>
<p>Aggregate Features</p>
<p>We first define the set of per-userday features, which summarize users' activities in the day. To aggregate the features that have a small number of distinct values (e.g. success/failure, logon orientation) we count the number of occurrences for each distinct value for the user-day. For fields that have a larger number of distinct values (pcs, users, domains), we count the number of common and uncommon events that occurred, rather than the number of occurrences of each distinct value (this approach avoids high dimensional sparse features). Furthermore, we define two categories of common/uncommon; to the individual entity/user, and relative to all users. A value is defined as uncommon for the user if it accounts for fewer than 5% of the values observed in that field (up to that point in time), and common otherwise. A value is defined as uncommon for all users if it occurs fewer times than the average value for the field, and common otherwise.</p>
<p>For the LANL dataset, the prior featurization strategy yields a 108-dimensional aggregate feature vector per userday. These feature vectors then serve as the input to the baseline models described next.</p>
<p>Models We consider two baseline models. The first uses Principal Components Analysis (pca) to learn a low dimensional representation of the aggregate features; the anomaly score is proportional to the reconstruction error after mapping the compressed representation back into the original dimension (Shyu et al. 2003). The second is an isolation forest (iso) based approach (Liu, Ting, and Zhou 2008) as implemented in scikit-learn's outlier detection tools (Pedregosa et al. 2011). This was noted as the best performing anomaly detection algorithm in the recent DARPA insider threat detection program, (Gavai et al. 2015).</p>
<p>Experiments</p>
<p>In this section we describe experiments to evaluate the effectiveness of the proposed event modeling algorithms.</p>
<p>Data</p>
<p>The Los Alamos National Laboratory (LANL) Cyber Security Dataset (Kent 2016) consists of event logs from LANL's internal computer network collected over a period of 58 consecutive days. The data set contains over one billion loglines from authentication, process, network flow, and DNS logging sources. Identifying fields (e.g., users, computers, and processes) have been anonymized.</p>
<p>The recorded network activities included both normal operational network activity as well as a series of red team activities that compromised account credentials over the first 30 days of data. Information about known red team attack events is used only for evaluation; our approach is strictly unsupervised.</p>
<p>For the experiments presented in this paper, we rely only on the authentication event logs, whose fields and statistics are summarized in Figure 3a. We filter these events to only those log-lines linked to an actual user, removing computercomputer interaction events. Events on weekends and holidays contain drastically different frequencies and distributions of activities. In a real deployment a separate model would be trained for use on those days, but because no malicious events were in that data it was also withheld. Table 3b has statistics of our data split; the first 12 days serve as the development set, while the remaining 18 days are the independent test set.</p>
<p>Assessment Granularity</p>
<p>Our model learns normal behavior and assigns relatively high loss to events that are unexpected. A principal advantage of our approach is this ability to score the anomaly of  individual events, allowing us to flag at the event-level or aggregate anomalies over any larger timescale. For this work, we consider two timescales. First, we assess based on individual events; a list of events would be presented to the analyst, sorted descending by anomaly score. Second, to facilitate comparison with traditional aggregation methods, we aggregate anomaly scores over all of a user's events for the day (specifically, taking the max), producing a single anomaly score per-user, per-day. In this scenario, a list of user-days would be provided to the analyst, sorted descending by anomaly score. We refer to this approach as max, because the anomaly scores provided to the analyst are produced by taking the maximum score over the event scores in the window for that user (where event-level scoring is just taking the max over a singleton set of one event).</p>
<p>In order to counter systematic offsets in users' anomaly scores for a day we also consider a simple normalization strategy, which we refer to as diff, by which every raw score is first normalized by subtracting the user's average event-level anomaly score for the day.</p>
<p>Metrics</p>
<p>We consider two performance metrics. First, we assess results using the standard area under the receiver operator characteristic curve (AUC) which characterizes the trade-off in model detection performance between true positives and false positives, effectively sweeping through all possible analyst budgets. False positives are detections that are not truly red team events, while true positives are detections that are.</p>
<p>To quantify the proportion of the data the analyst must sift through to diagnose malicious behavior on the network, we use the Average Percentile (AP) metric. Specifically, for each red team event or user-day, we note the percentile of its anomaly amongst all anomaly scores for the day. We then average these percentiles for all of the malicious events or  user-days. Note that if all true malicious events or user-days are flagged as the most anomalous on the respective days, then AP  100, while if all malicious events or user-days are ranked as the least anomalous on their respective days, AP  0. For both AUC and AP, a higher score is better.</p>
<p>Our model hyperparameters were manually tuned to maximize AP for day-level diff scores on the development set. No separate training set is needed as our approach is unsupervised and trained online.</p>
<p>Results and Analysis</p>
<p>We begin by exploring the user-day granularity performance. Table 1 summarizes model detection performance at this granularity on the test set for the AUC and AP metrics using the diff method to produce day level scores from the language models. A few trends are evident from these results. First, the aggregate feature baselines have nearequivalent performance by both metrics, with the isolation forest approach having a slight edge. We hypothesize the feature representation, which is common to these methods, could be a bottleneck in performance. This highlights the "blind spot" issue feature engineering introduces. Second, despite having only the context of a single log-line at a time, as opposed to features aggregated over an entire day, the event model (EM) performs comparably to the baseline models when a forward pass LSTM network is used with  a character tokenization and outperforms the baselines with word tokenization. The most pronounced performance gain results from using bidirectional models. Finally, word-level tokenization performs better than character-level; however, even the bidirectional character models perform appreciably better than the baselines. It is clear from these results that the tiered models perform comparably to, but not better than, the event-level models. This suggests that the event level model is able to characterize normal user behavior from information stored in the model weights of the network, which are trained each day to model user activity. Given the context of the past day's activity stored in the model weights, the categorical variables represented by the fields in an individual log line may eliminate the need for explicit event context modeling. We leave tracking the state of individual computers, rather than users, to future work, but hypothesize that it may make the tiered approach more effective.</p>
<p>Next, we broaden our analysis of language modeling approaches, comparing performance across all language models, tokenization strategies, anomaly granularity, and normalization techniques. Figure 4 plots AUC for all language model types using word tokenization, contrasting max and diff normalization modes. Figure 5 compares the same variations for character tokenization. Table 2 presents these results in tabular form. With few exceptions, log-line-level granularity vastly outperforms day-level; this is true for both the character-level and word-level tokenization strategies, with an average gain of 0.1 AUC. The most interesting outcome of these comparisons is that word tokenization performance gains are heavily reliant on the diff normalization, whereas for character tokenization the diff normalization has a minor detrimental effect for some models. This suggests that the character-level model could be used to provide a more immediate response time, not having to wait until the day is done to obtain the day statistics used in diff mode. The two tokenization strategies may in fact be complementary as the versatility and response time gains of a character tokenization come at the expense of easy interpretibility of a word tokenization: the word tokenization allows anomaly scores to be decomposed into individual log-line fields, enabling analysts to pinpoint features of the event that most contributed to it being flagged. Since we tuned hyperparameters using diff mode, the character-level model has potential to do better with additional tuning.</p>
<p>Next, Figures 6 and 7 visualize the average percentiles of red team detections for the subset of the test set with the most red-team activity. Anomaly scores for both word and character tokenizations are computed without average userday offset normalization. Red team log-line-level scores are plotted as purple x's with the x coordinate being the second in time at which the event occurred and y coordinate the anomaly score for that event. Percentile ranges are colored to provide context for the red-team anomaly scores against the backdrop of other network activity. The spread of non-normalized anomaly scores is much greater for the word-level tokenizations (Fig. 7) than character-level (Fig.  6), which could explain the different sensitivity of word level tokenization to normalization. Also notice that there is an expected bump in percentiles for windows of frequent redteam activity. Curiously, at the end of day 14 there are massive bumps for the 99th percentile, which suggest unplanned and un-annotated anomalous events on the LANL network for those hours. Notice that for the character tokenization almost all non-normalized red team anomaly scores are above the 95th percentile, with a large proportion above the 99th percentile.</p>
<p>Finally, Figure 8 plots the ROC curves for the best aggregate baseline (iso), the best user-day granularity language model (word BEM), and the best event-level granularity model (character BEM). It illustrates the qualitatively different curves obtained with the baselines, the user-day granularity, and the event-level granularity.</p>
<p>Since the proportion of red-team to normal events is vanishingly low in the data-set (&lt; 0.001%), the false-positive rate is effectively the proportion of data flagged to achieve a particular recall. From this observation, Figure 8 shows the character event model can achieve 100% recall from only 12% of the data whereas the other models considered only achieve 100% recall when nearly all of the data has been  Figure 6: Character-level red-team log-line anomaly scores in relation to percentiles over time. Figure 7: Word-level red-team log-line anomaly scores in relation to percentiles over time. handed to the analyst. Further, the character event model can achieve 80% recall by flagging only 3% of the data whereas the word day language model needs 14% of the data and the aggregate isolation forest model needs 55% of the data to achieve the same result.</p>
<p>Conclusion</p>
<p>This work builds upon advances in language modeling to address computer security log analysis, proposing an unsupervised, online anomaly detection approach. We eliminate the usual effort-intensive feature engineering stage, making our approach fast to deploy and agnostic to the system configuration and monitoring tools. It further confers the key advantage of event-level detection which allows for a near immediate alert response following anomalous activity.</p>
<p>In experiments using the Los Alamos National Laboratory Cyber Security Dataset, bidirectional language models significantly outperformed standard methods at day-level detection. The best log-line-level detection performance was achieved with a bidirectional character-based language model, obtaining a 0.98 area under the ROC curve, showing that for the constrained language domain of network logs, character based language modeling can achieve comparable accuracy to word based modeling for event level detection. We have therefore demonstrated a simple and effective approach to modeling dynamic networks with open vocabulary logs (e.g. with new users, PCs, or IP addresses).</p>
<p>We propose to extend this work in several ways. First, potential modeling advantages of tiered architectures merit further investigation. The use of tiered architectures to track PCs instead of network users, or from a richer set of logging sources other than simply authentication logs may take better advantage of their modeling power. Next, we anticipate interpretability can become lost with such detailed granularity provided by log-line-level detection from a characterbased model, therefore future work will explore alternate methods of providing context to an analyst. Finally, we are interested in exploring the robustness of this approach to adversarial tampering. Similarly performing models could have different levels of resilience that would lead to selection of one over another.</p>
<p>Figure 1 :
1Event Models. Set of black bordered nodes and connections illustrate the EM model while set of all nodes and connections illustrate the BEM model.</p>
<p>Figure 2 :
2Tiered Event Model (T-EM)</p>
<p>Figure 3 :
3Dataset statistics: (a) Authentication log fields and statistics and (b) dataset splits.</p>
<p>of AUC for day-level and log-line-level analysis with and without user-day normalization. Figures 4 and 5 provide a visualization of these results.</p>
<p>Figure 4 :Figure 5 :
45Word model comparison of AUC at day-level and log-line-level granularities. Character model comparison of AUC at day-level and log-line-level granularities.</p>
<p>Figure 8 :
8ROC curves for best performing baseline, word language model evaluated at day-granularity, and character language model evaluated at log-line-granularity.
Acknowledgments The research described in this paper is part of the Analysis in Motion Initiative at Pacific Northwest National Laboratory. It was conducted under the Laboratory Directed Research and Development Program at PNNL, a multi-program national laboratory operated by Battelle for the U.S. Department of Energy. The authors would also like to thank the Nvidia corporation for their donations of Titan X and Titan Xp GPUs used in this research.
. [ References, Abadi, References [Abadi et al. 2015] Abadi, M.; Agarwal, A.; Barham, P.; Brevdo, E.; Chen, Z.; Citro, C.; Corrado, G. S.; Davis, A.; Dean, J.; Devin, M.; Ghemawat, S.; Goodfellow, I.; Harp, A.; Irving, G.; Isard, M.; Jia, Y.; Jozefowicz, R.; Kaiser, L.; Kudlur, M.; Levenberg, J.; Man, D.; Monga, R.; Moore, S.;</p>
<p>TensorFlow: Largescale machine learning on heterogeneous systems. Software available from tensorflow.org. D Murray, C Olah, M Schuster, J Shlens, B Steiner, I Sutskever, K Talwar, P Tucker, V Vanhoucke, V Vasudevan, F Vigas, O Vinyals, P Warden, M Wattenberg, M Wicke, Y Yu, X Zheng, K Alrawashdeh, C Purdy, D K Bhattacharyya, J K Kalita, Network anomaly detection: A machine learning perspective. CRC PressMachine Learning and Applications (ICMLA)Murray, D.; Olah, C.; Schuster, M.; Shlens, J.; Steiner, B.; Sutskever, I.; Talwar, K.; Tucker, P.; Vanhoucke, V.; Vasude- van, V.; Vigas, F.; Vinyals, O.; Warden, P.; Wattenberg, M.; Wicke, M.; Yu, Y.; and Zheng, X. 2015. TensorFlow: Large- scale machine learning on heterogeneous systems. Software available from tensorflow.org. [Alrawashdeh and Purdy 2016] Alrawashdeh, K., and Purdy, C. 2016. Toward an online anomaly intrusion detection system based on deep learning. In Machine Learning and Applications (ICMLA), 2016 15th IEEE International Con- ference on, 195-200. IEEE. [Bhattacharyya and Kalita 2013] Bhattacharyya, D. K., and Kalita, J. K. 2013. Network anomaly detection: A machine learning perspective. CRC Press.</p>
<p>Networkbased intrusion detection using neural networks. Bivens, Intelligent Engineering Systems through Artificial Neural Networks. 121[Bivens et al. 2002] Bivens, A.; Palagiri, C.; Smith, R.; Szy- manski, B.; Embrechts, M.; et al. 2002. Network- based intrusion detection using neural networks. Intelli- gent Engineering Systems through Artificial Neural Net- works 12(1):579-584.</p>
<p>A survey of data mining and machine learning methods for cyber security intrusion detection. A L Buczak, E Guven, Chung, Gated feedback recurrent neural networks. In International Conference on Machine Learning. 18Proc. IEEE Symposium on Research in Security and Privacy[Buczak and Guven 2016] Buczak, A. L., and Guven, E. 2016. A survey of data mining and machine learning meth- ods for cyber security intrusion detection. IEEE Communi- cations Surveys &amp; Tutorials 18(2):1153-1176. [Chung et al. 2015] Chung, J.; Gulcehre, C.; Cho, K.; and Bengio, Y. 2015. Gated feedback recurrent neural networks. In International Conference on Machine Learning, 2067- 2075. [Debar, Becker, and Siboni 1992] Debar, H.; Becker, M.; and Siboni, D. 1992. A neural network component for an intrusion detection system. In Proc. IEEE Symposium on Research in Security and Privacy, 240-250.</p>
<p>Supervised and unsupervised methods to detect insider threat from enterprise social and online activity data. S Dua, X Du, G Gavai, K Sricharan, D Gunning, J Hanley, M Singhal, R Rolleston, Journal of Wireless Mobile Networks, Ubiquitous Computing, and Dependable Applications. 64CRC pressData mining and machine learning in cybersecurityand Du 2016] Dua, S., and Du, X. 2016. Data mining and machine learning in cybersecurity. CRC press. [Gavai et al. 2015] Gavai, G.; Sricharan, K.; Gunning, D.; Hanley, J.; Singhal, M.; and Rolleston, R. 2015. Supervised and unsupervised methods to detect insider threat from en- terprise social and online activity data. Journal of Wireless Mobile Networks, Ubiquitous Computing, and Dependable Applications 6(4):47-63.</p>
<p>Character-level language modeling with hierarchical recurrent neural networks. Hofman Gopalan, P Blei ; Gopalan, J M Hofman, D M Blei, S Hochreiter, J Schmidhuber, K Hwang, W Sung, A D Kent, arXiv:1311.1704arXiv:1609.03777Scalable recommendation with Poisson factorization. Kent937arXiv preprintNeural computation[Gopalan, Hofman, and Blei 2013] Gopalan, P.; Hofman, J. M.; and Blei, D. M. 2013. Scalable recommendation with Poisson factorization. arXiv preprint arXiv:1311.1704. [Hochreiter and Schmidhuber 1997] Hochreiter, S., and Schmidhuber, J. 1997. Long short-term memory. Neural computation 9(8):1735-1780. [Hwang and Sung 2016] Hwang, K., and Sung, W. 2016. Character-level language modeling with hierarchical recur- rent neural networks. arXiv preprint arXiv:1609.03777. [Kent 2016] Kent, A. D. 2016. Cyber security data sources for dynamic network research. Dynamic Networks and Cyber-Security 1:37.</p>
<p>. [ Koutnik, arXiv:1402.3511A clockwork RNN. arXiv preprint[Koutnik et al. 2014] Koutnik, J.; Greff, K.; Gomez, F.; and Schmidhuber, J. 2014. A clockwork RNN. arXiv preprint arXiv:1402.3511.</p>
<p>The use of artificial intelligence based techniques for intrusion detection: a review. Kumar Kumar, G Kumar, K Kumar, M Sachdeva, Artificial Intelligence Review. 344Kumar, Kumar, and Sachdeva 2010] Kumar, G.; Kumar, K.; and Sachdeva, M. 2010. The use of artificial intelligence based techniques for intrusion detection: a review. Artificial Intelligence Review 34(4):369-387.</p>
<p>Ling, arXiv:1508.02096Finding function in form: Compositional character models for open vocabulary word representation. arXiv preprint[Ling et al. 2015a] Ling, W.; Lus, T.; Marujo, L.; Astudillo, R. F.; Amir, S.; Dyer, C.; Black, A. W.; and Trancoso, I. 2015a. Finding function in form: Compositional charac- ter models for open vocabulary word representation. arXiv preprint arXiv:1508.02096.</p>
<p>arXiv:1511.04586Character-based neural machine translation. arXiv preprintet al. 2015b] Ling, W.; Trancoso, I.; Dyer, C.; and Black, A. W. 2015b. Character-based neural machine trans- lation. arXiv preprint arXiv:1511.04586.</p>
<p>Studies in applying PCA and wavelet algorithms for network traffic anomaly detection. Ting Zhou, F T Liu, K M Ting, Z.-H Zhou, Novakov, Acoustics, Speech and Signal Processing (ICASSP), 2015 IEEE International Conference on. IEEE12High Performance Switching and Routing (HPSR). Pedregosa et al. 2011. Passos, A.; Cournapeau, D.; Brucher, M.; Perrot, M.; and Duchesnay, E. 2011. Scikit-learn: Machine learning in Python, Ting, and Zhou 2008] Liu, F. T.; Ting, K. M.; and Zhou, Z.-H. 2008. Isolation forest. In Proc. ICDM. [Novakov et al. 2013] Novakov, S.; Lung, C.-H.; Lam- badaris, I.; and Seddigh, N. 2013. Studies in applying PCA and wavelet algorithms for network traffic anomaly detection. In High Performance Switching and Routing (HPSR), 2013 IEEE 14th International Conference on, 185- 190. IEEE. [Pascanu et al. 2015] Pascanu, R.; Stokes, J. W.; Sanossian, H.; Marinescu, M.; and Thomas, A. 2015. Malware classi- fication with recurrent networks. In Acoustics, Speech and Signal Processing (ICASSP), 2015 IEEE International Con- ference on, 1916-1920. IEEE. [Pedregosa et al. 2011] Pedregosa, F.; Varoquaux, G.; Gram- fort, A.; Michel, V.; Thirion, B.; Grisel, O.; Blondel, M.; Prettenhofer, P.; Weiss, R.; Dubourg, V.; Vanderplas, J.; Pas- sos, A.; Cournapeau, D.; Brucher, M.; Perrot, M.; and Duch- esnay, E. 2011. Scikit-learn: Machine learning in Python. Journal of Machine Learning Research 12:2825-2830.</p>
<p>Anomaly detection for cyber security applications. Dynamic Networks and Cyber-Security 1:137. Ringberg, SIGMETRICS. 45Bidirectional recurrent neural networks[Ringberg et al. 2007] Ringberg, H.; Soule, A.; Rexford, J.; and Diot, C. 2007. Sensitivity of PCA for traffic anomaly detection. In SIGMETRICS. [Rubin-Delanchy, Lawson, and Heard 2016] Rubin- Delanchy, P.; Lawson, D. J.; and Heard, N. A. 2016. Anomaly detection for cyber security applications. Dy- namic Networks and Cyber-Security 1:137. [Schuster and Paliwal 1997] Schuster, M., and Paliwal, K. K. 1997. Bidirectional recurrent neural networks. IEEE Trans- actions on Signal Processing 45(11):2673-2681.</p>
<p>Outside the closed world: On using machine learning for network intrusion detection. [ Shyu, Proc. Symposium on Security and Privacy. Symposium on Security and PrivacyProc. ICDM[Shyu et al. 2003] Shyu, M.-L.; Chen, S.-C.; Sarinnapakorn, K.; and Chang, L. 2003. A novel anomaly detection scheme based on principal component classifier. In Proc. ICDM. [Sommer and Paxson 2010] Sommer, R., and Paxson, V. 2010. Outside the closed world: On using machine learn- ing for network intrusion detection. In Proc. Symposium on Security and Privacy.</p>
<p>Deep learning for unsupervised insider threat detection in structured cybersecurity data streams. Artificial Intelligence for Cybersecurity Workshop at AAAI. et al. 2017] Tuor, A.; Kaplan, S.; Hutchinson, B.; Nichols, N.; and Robinson, S. 2017. Deep learning for un- supervised insider threat detection in structured cybersecu- rity data streams. In Artificial Intelligence for Cybersecurity Workshop at AAAI.</p>
<p>Poisson factorization for peer-based anomaly detection. Turcotte, Intelligence and Security Informatics (ISI), 2016 IEEE Conference on. IEEETurcotte et al. 2016] Turcotte, M.; Moore, J.; Heard, N.; and McPhall, A. 2016. Poisson factorization for peer-based anomaly detection. In Intelligence and Security Informat- ics (ISI), 2016 IEEE Conference on, 208-210. IEEE.</p>
<p>Modelling user behavior in a network using computer event logs. Dynamic Networks and Cyber-Security 1:67. Heard Turcotte, M J Kent ; Turcotte, N A Heard, A D Kent, K Veeramachaneni, I Arnaldo, V Korrapati, C Bassias, K Li, R Zuech, T M Khoshgoftaar, Wald , R , Proc. HPSC and IDS. [Zuech, Khoshgoftaar, and Wald. HPSC and IDS. [Zuech, Khoshgoftaar, and Wald23Intrusion detection and big heterogeneous data: a surveyTurcotte, Heard, and Kent 2016] Turcotte, M. J.; Heard, N. A.; and Kent, A. D. 2016. Modelling user behavior in a network using computer event logs. Dynamic Networks and Cyber-Security 1:67. [Veeramachaneni et al. 2016] Veeramachaneni, K.; Arnaldo, I.; Korrapati, V.; Bassias, C.; and Li, K. 2016. AI 2 : Training a big data machine to defend. In Proc. HPSC and IDS. [Zuech, Khoshgoftaar, and Wald 2015] Zuech, R.; Khosh- goftaar, T. M.; and Wald, R. 2015. Intrusion detection and big heterogeneous data: a survey. Journal of Big Data 2(1):3.</p>            </div>
        </div>

    </div>
</body>
</html>