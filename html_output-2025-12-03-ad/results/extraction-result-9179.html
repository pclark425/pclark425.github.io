<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-9179 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-9179</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-9179</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-161.html">extraction-schema-161</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs being used as text-based simulators in specific scientific subdomains, including details on the simulation task, the accuracy or evaluation results, and any factors or variables identified as affecting simulation accuracy.</div>
                <p><strong>Paper ID:</strong> paper-265019423</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2311.01918v1.pdf" target="_blank">Large Language Models Illuminate a Progressive Pathway to Artificial Healthcare Assistant: A Review</a></p>
                <p><strong>Paper Abstract:</strong> With the rapid development of artificial intelligence, large language models (LLMs) have shown promising capabilities in mimicking human-level language comprehension and reasoning. This has sparked significant interest in applying LLMs to enhance various aspects of healthcare, ranging from medical education to clinical decision support. However, medicine involves multifaceted data modalities and nuanced reasoning skills, presenting challenges for integrating LLMs. This paper provides a comprehensive review on the applications and implications of LLMs in medicine. It begins by examining the fundamental applications of general-purpose and specialized LLMs, demonstrating their utilities in knowledge retrieval, research support, clinical workflow automation, and diagnostic assistance. Recognizing the inherent multimodality of medicine, the review then focuses on multimodal LLMs, investigating their ability to process diverse data types like medical imaging and EHRs to augment diagnostic accuracy. To address LLMs' limitations regarding personalization and complex clinical reasoning, the paper explores the emerging development of LLM-powered autonomous agents for healthcare. Furthermore, it summarizes the evaluation methodologies for assessing LLMs' reliability and safety in medical contexts. Overall, this review offers an extensive analysis on the transformative potential of LLMs in modern medicine. It also highlights the pivotal need for continuous optimizations and ethical oversight before these models can be effectively integrated into clinical practice. Visit https://github.com/mingze-yuan/Awesome-LLM-Healthcare for an accompanying GitHub repository containing latest papers.</p>
                <p><strong>Cost:</strong> 0.019</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e9179.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e9179.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs being used as text-based simulators in specific scientific subdomains, including details on the simulation task, the accuracy or evaluation results, and any factors or variables identified as affecting simulation accuracy.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLaVA-Med / PathAsst (GPT-4 self-instruction)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLaVA-Med and PathAsst using GPT-4 for self-instruction generation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>GPT-4 is used to generate multi-turn, instruction-following conversational training data (questions and answers) from biomedical image captions, effectively simulating clinician–patient or image–question dialogues to create multimodal instruction datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Llava-med: Training a large language-and-vision assistant for biomedicine in one day.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>GPT-4: OpenAI multimodal-capable large language model (referenced as a state-of-the-art, instruction-following LLM); specific parameter counts and training corpora are not provided in this review.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_subdomain</strong></td>
                            <td>Biomedical imaging / Pathology / Radiology (multimodal medical AI dataset creation)</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task</strong></td>
                            <td>Text-based simulation of multi-turn image-centered conversations and generation of question–answer instruction pairs from image captions to produce training data for multimodal LLMs.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Downstream model performance on biomedical VQA/closed-set benchmarks (datasets cited include VQA-RAD and SLAKE) and qualitative expert assessment of generated instruction-following dialogues; the review reports dataset-level evaluation settings but does not provide numeric scores for the synthetic-data approach itself.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_accuracy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>factors_affecting_accuracy</strong></td>
                            <td>['Quality and representativeness of seed examples used to prompt GPT-4', 'Prompt design and instruction templates used for self-instruction', 'Alignment between generated synthetic dialogues and real-world clinical conversational distribution', 'Potential information loss when converting image content to text captions prior to generation']</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Not explicitly quantified in this review; downstream evaluation was described using held-in/held-out benchmark splits (VQA-RAD, SLAKE) and finetuning comparisons, but no direct numeric baseline comparisons for the synthetic generation method are provided here.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Synthetic conversations may diverge from real clinical dialogue distributions; generated data quality depends on prompt/seed design; possible introduction of noisy or unrealistic examples.</td>
                        </tr>
                        <tr>
                            <td><strong>author_recommendations_or_insights</strong></td>
                            <td>Use curated seed samples and carefully designed instruction pools; expand seed instructions via high-quality LLM prompting (e.g., GPT-4) but combine synthetic data with real annotated data and evaluate on held-out clinical benchmarks.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Large Language Models Illuminate a Progressive Pathway to Artificial Healthcare Assistant: A Review', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9179.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e9179.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs being used as text-based simulators in specific scientific subdomains, including details on the simulation task, the accuracy or evaluation results, and any factors or variables identified as affecting simulation accuracy.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLM-Mini-CEX / patient-simulator evaluation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLM-Mini-CEX (automatic evaluation of diagnostic conversation using a patient simulator and ChatGPT)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An automated evaluation framework that uses a simulated patient and LLMs (e.g., ChatGPT) to run diagnostic conversations for assessing diagnostic abilities, replacing some manual evaluation steps.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Llmmini-cex: Automatic evaluation of large language model for diagnostic conversation.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT (as used in the referenced evaluation pipeline)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>ChatGPT: OpenAI conversational LLM (GPT-3.5-family referenced); exact model variant and training details not enumerated in the review.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_subdomain</strong></td>
                            <td>Clinical diagnostic conversation / Medical education and assessment</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task</strong></td>
                            <td>Simulate patient interactions (patient simulator) and automate diagnostic conversational exchanges to evaluate LLM diagnostic performance and conversational skills.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Automated diagnostic evaluation scores defined by the LLM-tailored criterion in LLM-Mini-CEX; the review notes this is intended to streamline evaluation but does not report numeric values.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_accuracy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>factors_affecting_accuracy</strong></td>
                            <td>['Fidelity of the patient simulator (how realistic the simulated patient responses are)', 'Quality and clarity of evaluation criteria encoded in prompts', 'Transparency and reliability of LLM-based scoring', 'Intrinsic diagnostic limitations of the LLMs used']</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Human expert evaluation (implied as the traditional baseline); the review states LLM-based scoring faces challenges compared to human assessments.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Challenges in transparency and accuracy of automated scoring; sometimes limited diagnostic performance of the automated pipeline compared to human evaluators.</td>
                        </tr>
                        <tr>
                            <td><strong>author_recommendations_or_insights</strong></td>
                            <td>Automated LLM-based evaluators can reduce evaluation cost but require improvements in transparency and diagnostic validity before they can replace human assessment; careful design of patient simulators and scoring criteria is necessary.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Large Language Models Illuminate a Progressive Pathway to Artificial Healthcare Assistant: A Review', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9179.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e9179.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs being used as text-based simulators in specific scientific subdomains, including details on the simulation task, the accuracy or evaluation results, and any factors or variables identified as affecting simulation accuracy.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Med-PaLM / Med-PaLM 2 / Flan-PaLM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Med-PaLM (and Med-PaLM 2) built on Flan-PaLM via instruction tuning for medical QA</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Instruction-tuned LLMs (Flan-PaLM → Med-PaLM → Med-PaLM 2) applied to medical question answering, evaluated on aggregated medical QA benchmarks and USMLE-style questions to simulate expert-level medical question answering.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Flan-PaLM / Med-PaLM 2</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Flan-PaLM: instruction-tuned PaLM; Med-PaLM: Flan-PaLM further tuned on medical instruction data; Med-PaLM 2 is an improved medical instruction-tuned model—the review gives reported downstream performance but not low-level training details in this text.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_subdomain</strong></td>
                            <td>Medical question answering / Medical education (USMLE-style evaluation)</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task</strong></td>
                            <td>Answering USMLE-style medical questions and broader medical QA tasks, effectively simulating clinician-level knowledge retrieval and reasoning on exam-style prompts.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Accuracy on MultiMedQA (aggregation of six medical QA datasets and HealthSearchQA) and USMLE-style question accuracy; human clinician evaluation for qualitative aspects.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_accuracy</strong></td>
                            <td>Med-PaLM 2 reported accuracy: 86.5% on USMLE-style questions (as stated in the review). Flan-PaLM reportedly outperformed the prior leading model by ~17% in accuracy (per review summary).</td>
                        </tr>
                        <tr>
                            <td><strong>factors_affecting_accuracy</strong></td>
                            <td>['Instruction tuning with domain-specific (medical) real-world data', 'Quality and coverage of the medical QA benchmark data', 'Human evaluator preferences and evaluation criteria', 'Model alignment and prompt/instruction design']</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Prior leading models on MultiMedQA / USMLE benchmarks; Flan-PaLM improved over prior best by ~17% and Med-PaLM 2 achieved 86.5% accuracy (comparison to earlier models reported qualitatively in review).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Models remain proprietary (limiting clinical deployment); potential misalignment with clinician preferences despite high benchmark scores; need for human evaluations to assess clinical acceptability.</td>
                        </tr>
                        <tr>
                            <td><strong>author_recommendations_or_insights</strong></td>
                            <td>Instruction tuning on real-world medical data substantially improves accuracy; human-in-the-loop evaluations are necessary as automated metrics can diverge from clinician preferences.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Large Language Models Illuminate a Progressive Pathway to Artificial Healthcare Assistant: A Review', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9179.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e9179.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs being used as text-based simulators in specific scientific subdomains, including details on the simulation task, the accuracy or evaluation results, and any factors or variables identified as affecting simulation accuracy.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-4V evaluation (multimodal diagnostic case studies)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-4V (Vision) case studies for multimodal medical diagnosis</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Case studies evaluated GPT-4V's multimodal diagnostic capabilities across multiple body systems and imaging modalities, assessing tasks like modality/anatomy recognition, disease diagnosis, report generation, and localization.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Can gpt-4v (ision) serve medical applications? case studies on gpt-4v for multimodal medical diagnosis.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4V (GPT-4 with vision)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>GPT-4V: the multimodal variant of GPT-4 capable of processing image inputs (review summarizes an external evaluation study but does not provide model parameter counts here).</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_subdomain</strong></td>
                            <td>Multimodal medical imaging diagnostics (radiology and other imaging specialties)</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task</strong></td>
                            <td>Multimodal diagnostic tasks including imaging modality and anatomy recognition, disease diagnosis, report generation, and disease localization from image inputs (with and without patient history).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Task-specific assessments across 17 body systems and 8 imaging modalities; qualitative and task-level performance (review summarizes strengths/weaknesses but provides no numeric aggregate accuracy).</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_accuracy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>factors_affecting_accuracy</strong></td>
                            <td>['Availability of patient history (performance assessed both with and without it)', 'Type of imaging modality and whether images are 2D snapshots vs native 3D DICOM', "GPT-4V's limitation to processing up to four 2D images at once (necessitating slice selection for 3D studies)", 'Granularity of visual information and need to select key slices or patches for pathology']</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Not explicitly quantified in the review; study contrasted GPT-4V performance across tasks and highlighted gaps relative to clinical needs.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Strong at modality/anatomy recognition but weaker at disease diagnosis and detailed report generation; constrained by handling a small number of 2D images and inability to ingest full 3D DICOM volumes directly.</td>
                        </tr>
                        <tr>
                            <td><strong>author_recommendations_or_insights</strong></td>
                            <td>Significant progress exists, but a performance gap remains before clinical integration; 3D imaging workflows and richer clinical context are critical aspects to address for improved accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Large Language Models Illuminate a Progressive Pathway to Artificial Healthcare Assistant: A Review', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9179.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e9179.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs being used as text-based simulators in specific scientific subdomains, including details on the simulation task, the accuracy or evaluation results, and any factors or variables identified as affecting simulation accuracy.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>TrialGPT / patient-trial matching using LLMs</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>TrialGPT (LLM-assisted system for selecting appropriate clinical trials)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An LLM-based system (TrialGPT) assisting patients and referral physicians to identify suitable clinical trials from a large annotated corpus by interpreting patient attributes and matching them to trial eligibility criteria.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_subdomain</strong></td>
                            <td>Clinical trials / Clinical informatics (patient-trial matching)</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task</strong></td>
                            <td>Simulate the patient–trial matching decision process by parsing patient characteristics and matching them to trial eligibility; produce explanations to support matching decisions.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Validated explanatory capability and matching utility on three public cohorts totaling 184 patients and evaluation across 18,238 annotated clinical trials (as stated in the review); specifics of quantitative accuracy metrics are not provided in the review text.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_accuracy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>factors_affecting_accuracy</strong></td>
                            <td>['Scale and annotation quality of the trial corpus', 'Representation of diverse patient cohorts in evaluation cohorts', "LLM's ability to parse nuanced eligibility criteria and patient notes", 'Prompting/instruction design for explanation generation']</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Not detailed in the review; the system was validated on public cohorts and compared qualitatively in explanatory power.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Review does not report detailed numeric performance; potential limitations include domain-shift between trial descriptions and real-world EHR phrasing and lack of precise numeric accuracy reporting in the review.</td>
                        </tr>
                        <tr>
                            <td><strong>author_recommendations_or_insights</strong></td>
                            <td>LLMs can aid trial selection and explanation generation but require thorough validation on larger, diverse cohorts and careful handling of eligibility nuance.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Large Language Models Illuminate a Progressive Pathway to Artificial Healthcare Assistant: A Review', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9179.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e9179.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs being used as text-based simulators in specific scientific subdomains, including details on the simulation task, the accuracy or evaluation results, and any factors or variables identified as affecting simulation accuracy.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Argyle et al. (LLMs to simulate human samples)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Out of one, many: Using language models to simulate human samples</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Reference to work that uses language models to generate simulated human samples (e.g., synthetic survey/sample responses) to expand or augment human datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Out of one, many: Using language models to simulate human samples.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_subdomain</strong></td>
                            <td>Computational social science / survey research (simulation of human respondents)</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task</strong></td>
                            <td>Generate synthetic human samples (responses) via language models to simulate populations or augment data (only cited in the review's reference list; no task details provided in the review body).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>simulation_accuracy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>factors_affecting_accuracy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>author_recommendations_or_insights</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Large Language Models Illuminate a Progressive Pathway to Artificial Healthcare Assistant: A Review', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Llava-med: Training a large language-and-vision assistant for biomedicine in one day. <em>(Rating: 2)</em></li>
                <li>Pathasst: Redefining pathology through generative foundation ai assistant for pathology. <em>(Rating: 2)</em></li>
                <li>Can gpt-4v (ision) serve medical applications? case studies on gpt-4v for multimodal medical diagnosis. <em>(Rating: 2)</em></li>
                <li>Llmmini-cex: Automatic evaluation of large language model for diagnostic conversation. <em>(Rating: 2)</em></li>
                <li>Out of one, many: Using language models to simulate human samples. <em>(Rating: 2)</em></li>
                <li>Matching patients to clinical trials with large language models. <em>(Rating: 2)</em></li>
                <li>Towards expert-level medical question answering with large language models. <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-9179",
    "paper_id": "paper-265019423",
    "extraction_schema_id": "extraction-schema-161",
    "extracted_data": [
        {
            "name_short": "LLaVA-Med / PathAsst (GPT-4 self-instruction)",
            "name_full": "LLaVA-Med and PathAsst using GPT-4 for self-instruction generation",
            "brief_description": "GPT-4 is used to generate multi-turn, instruction-following conversational training data (questions and answers) from biomedical image captions, effectively simulating clinician–patient or image–question dialogues to create multimodal instruction datasets.",
            "citation_title": "Llava-med: Training a large language-and-vision assistant for biomedicine in one day.",
            "mention_or_use": "mention",
            "model_name": "GPT-4",
            "model_description": "GPT-4: OpenAI multimodal-capable large language model (referenced as a state-of-the-art, instruction-following LLM); specific parameter counts and training corpora are not provided in this review.",
            "scientific_subdomain": "Biomedical imaging / Pathology / Radiology (multimodal medical AI dataset creation)",
            "simulation_task": "Text-based simulation of multi-turn image-centered conversations and generation of question–answer instruction pairs from image captions to produce training data for multimodal LLMs.",
            "evaluation_metric": "Downstream model performance on biomedical VQA/closed-set benchmarks (datasets cited include VQA-RAD and SLAKE) and qualitative expert assessment of generated instruction-following dialogues; the review reports dataset-level evaluation settings but does not provide numeric scores for the synthetic-data approach itself.",
            "simulation_accuracy": null,
            "factors_affecting_accuracy": [
                "Quality and representativeness of seed examples used to prompt GPT-4",
                "Prompt design and instruction templates used for self-instruction",
                "Alignment between generated synthetic dialogues and real-world clinical conversational distribution",
                "Potential information loss when converting image content to text captions prior to generation"
            ],
            "comparison_baseline": "Not explicitly quantified in this review; downstream evaluation was described using held-in/held-out benchmark splits (VQA-RAD, SLAKE) and finetuning comparisons, but no direct numeric baseline comparisons for the synthetic generation method are provided here.",
            "limitations_or_failure_cases": "Synthetic conversations may diverge from real clinical dialogue distributions; generated data quality depends on prompt/seed design; possible introduction of noisy or unrealistic examples.",
            "author_recommendations_or_insights": "Use curated seed samples and carefully designed instruction pools; expand seed instructions via high-quality LLM prompting (e.g., GPT-4) but combine synthetic data with real annotated data and evaluate on held-out clinical benchmarks.",
            "uuid": "e9179.0",
            "source_info": {
                "paper_title": "Large Language Models Illuminate a Progressive Pathway to Artificial Healthcare Assistant: A Review",
                "publication_date_yy_mm": "2023-11"
            }
        },
        {
            "name_short": "LLM-Mini-CEX / patient-simulator evaluation",
            "name_full": "LLM-Mini-CEX (automatic evaluation of diagnostic conversation using a patient simulator and ChatGPT)",
            "brief_description": "An automated evaluation framework that uses a simulated patient and LLMs (e.g., ChatGPT) to run diagnostic conversations for assessing diagnostic abilities, replacing some manual evaluation steps.",
            "citation_title": "Llmmini-cex: Automatic evaluation of large language model for diagnostic conversation.",
            "mention_or_use": "mention",
            "model_name": "ChatGPT (as used in the referenced evaluation pipeline)",
            "model_description": "ChatGPT: OpenAI conversational LLM (GPT-3.5-family referenced); exact model variant and training details not enumerated in the review.",
            "scientific_subdomain": "Clinical diagnostic conversation / Medical education and assessment",
            "simulation_task": "Simulate patient interactions (patient simulator) and automate diagnostic conversational exchanges to evaluate LLM diagnostic performance and conversational skills.",
            "evaluation_metric": "Automated diagnostic evaluation scores defined by the LLM-tailored criterion in LLM-Mini-CEX; the review notes this is intended to streamline evaluation but does not report numeric values.",
            "simulation_accuracy": null,
            "factors_affecting_accuracy": [
                "Fidelity of the patient simulator (how realistic the simulated patient responses are)",
                "Quality and clarity of evaluation criteria encoded in prompts",
                "Transparency and reliability of LLM-based scoring",
                "Intrinsic diagnostic limitations of the LLMs used"
            ],
            "comparison_baseline": "Human expert evaluation (implied as the traditional baseline); the review states LLM-based scoring faces challenges compared to human assessments.",
            "limitations_or_failure_cases": "Challenges in transparency and accuracy of automated scoring; sometimes limited diagnostic performance of the automated pipeline compared to human evaluators.",
            "author_recommendations_or_insights": "Automated LLM-based evaluators can reduce evaluation cost but require improvements in transparency and diagnostic validity before they can replace human assessment; careful design of patient simulators and scoring criteria is necessary.",
            "uuid": "e9179.1",
            "source_info": {
                "paper_title": "Large Language Models Illuminate a Progressive Pathway to Artificial Healthcare Assistant: A Review",
                "publication_date_yy_mm": "2023-11"
            }
        },
        {
            "name_short": "Med-PaLM / Med-PaLM 2 / Flan-PaLM",
            "name_full": "Med-PaLM (and Med-PaLM 2) built on Flan-PaLM via instruction tuning for medical QA",
            "brief_description": "Instruction-tuned LLMs (Flan-PaLM → Med-PaLM → Med-PaLM 2) applied to medical question answering, evaluated on aggregated medical QA benchmarks and USMLE-style questions to simulate expert-level medical question answering.",
            "citation_title": "here",
            "mention_or_use": "mention",
            "model_name": "Flan-PaLM / Med-PaLM 2",
            "model_description": "Flan-PaLM: instruction-tuned PaLM; Med-PaLM: Flan-PaLM further tuned on medical instruction data; Med-PaLM 2 is an improved medical instruction-tuned model—the review gives reported downstream performance but not low-level training details in this text.",
            "scientific_subdomain": "Medical question answering / Medical education (USMLE-style evaluation)",
            "simulation_task": "Answering USMLE-style medical questions and broader medical QA tasks, effectively simulating clinician-level knowledge retrieval and reasoning on exam-style prompts.",
            "evaluation_metric": "Accuracy on MultiMedQA (aggregation of six medical QA datasets and HealthSearchQA) and USMLE-style question accuracy; human clinician evaluation for qualitative aspects.",
            "simulation_accuracy": "Med-PaLM 2 reported accuracy: 86.5% on USMLE-style questions (as stated in the review). Flan-PaLM reportedly outperformed the prior leading model by ~17% in accuracy (per review summary).",
            "factors_affecting_accuracy": [
                "Instruction tuning with domain-specific (medical) real-world data",
                "Quality and coverage of the medical QA benchmark data",
                "Human evaluator preferences and evaluation criteria",
                "Model alignment and prompt/instruction design"
            ],
            "comparison_baseline": "Prior leading models on MultiMedQA / USMLE benchmarks; Flan-PaLM improved over prior best by ~17% and Med-PaLM 2 achieved 86.5% accuracy (comparison to earlier models reported qualitatively in review).",
            "limitations_or_failure_cases": "Models remain proprietary (limiting clinical deployment); potential misalignment with clinician preferences despite high benchmark scores; need for human evaluations to assess clinical acceptability.",
            "author_recommendations_or_insights": "Instruction tuning on real-world medical data substantially improves accuracy; human-in-the-loop evaluations are necessary as automated metrics can diverge from clinician preferences.",
            "uuid": "e9179.2",
            "source_info": {
                "paper_title": "Large Language Models Illuminate a Progressive Pathway to Artificial Healthcare Assistant: A Review",
                "publication_date_yy_mm": "2023-11"
            }
        },
        {
            "name_short": "GPT-4V evaluation (multimodal diagnostic case studies)",
            "name_full": "GPT-4V (Vision) case studies for multimodal medical diagnosis",
            "brief_description": "Case studies evaluated GPT-4V's multimodal diagnostic capabilities across multiple body systems and imaging modalities, assessing tasks like modality/anatomy recognition, disease diagnosis, report generation, and localization.",
            "citation_title": "Can gpt-4v (ision) serve medical applications? case studies on gpt-4v for multimodal medical diagnosis.",
            "mention_or_use": "mention",
            "model_name": "GPT-4V (GPT-4 with vision)",
            "model_description": "GPT-4V: the multimodal variant of GPT-4 capable of processing image inputs (review summarizes an external evaluation study but does not provide model parameter counts here).",
            "scientific_subdomain": "Multimodal medical imaging diagnostics (radiology and other imaging specialties)",
            "simulation_task": "Multimodal diagnostic tasks including imaging modality and anatomy recognition, disease diagnosis, report generation, and disease localization from image inputs (with and without patient history).",
            "evaluation_metric": "Task-specific assessments across 17 body systems and 8 imaging modalities; qualitative and task-level performance (review summarizes strengths/weaknesses but provides no numeric aggregate accuracy).",
            "simulation_accuracy": null,
            "factors_affecting_accuracy": [
                "Availability of patient history (performance assessed both with and without it)",
                "Type of imaging modality and whether images are 2D snapshots vs native 3D DICOM",
                "GPT-4V's limitation to processing up to four 2D images at once (necessitating slice selection for 3D studies)",
                "Granularity of visual information and need to select key slices or patches for pathology"
            ],
            "comparison_baseline": "Not explicitly quantified in the review; study contrasted GPT-4V performance across tasks and highlighted gaps relative to clinical needs.",
            "limitations_or_failure_cases": "Strong at modality/anatomy recognition but weaker at disease diagnosis and detailed report generation; constrained by handling a small number of 2D images and inability to ingest full 3D DICOM volumes directly.",
            "author_recommendations_or_insights": "Significant progress exists, but a performance gap remains before clinical integration; 3D imaging workflows and richer clinical context are critical aspects to address for improved accuracy.",
            "uuid": "e9179.3",
            "source_info": {
                "paper_title": "Large Language Models Illuminate a Progressive Pathway to Artificial Healthcare Assistant: A Review",
                "publication_date_yy_mm": "2023-11"
            }
        },
        {
            "name_short": "TrialGPT / patient-trial matching using LLMs",
            "name_full": "TrialGPT (LLM-assisted system for selecting appropriate clinical trials)",
            "brief_description": "An LLM-based system (TrialGPT) assisting patients and referral physicians to identify suitable clinical trials from a large annotated corpus by interpreting patient attributes and matching them to trial eligibility criteria.",
            "citation_title": "here",
            "mention_or_use": "mention",
            "model_name": null,
            "model_description": null,
            "scientific_subdomain": "Clinical trials / Clinical informatics (patient-trial matching)",
            "simulation_task": "Simulate the patient–trial matching decision process by parsing patient characteristics and matching them to trial eligibility; produce explanations to support matching decisions.",
            "evaluation_metric": "Validated explanatory capability and matching utility on three public cohorts totaling 184 patients and evaluation across 18,238 annotated clinical trials (as stated in the review); specifics of quantitative accuracy metrics are not provided in the review text.",
            "simulation_accuracy": null,
            "factors_affecting_accuracy": [
                "Scale and annotation quality of the trial corpus",
                "Representation of diverse patient cohorts in evaluation cohorts",
                "LLM's ability to parse nuanced eligibility criteria and patient notes",
                "Prompting/instruction design for explanation generation"
            ],
            "comparison_baseline": "Not detailed in the review; the system was validated on public cohorts and compared qualitatively in explanatory power.",
            "limitations_or_failure_cases": "Review does not report detailed numeric performance; potential limitations include domain-shift between trial descriptions and real-world EHR phrasing and lack of precise numeric accuracy reporting in the review.",
            "author_recommendations_or_insights": "LLMs can aid trial selection and explanation generation but require thorough validation on larger, diverse cohorts and careful handling of eligibility nuance.",
            "uuid": "e9179.4",
            "source_info": {
                "paper_title": "Large Language Models Illuminate a Progressive Pathway to Artificial Healthcare Assistant: A Review",
                "publication_date_yy_mm": "2023-11"
            }
        },
        {
            "name_short": "Argyle et al. (LLMs to simulate human samples)",
            "name_full": "Out of one, many: Using language models to simulate human samples",
            "brief_description": "Reference to work that uses language models to generate simulated human samples (e.g., synthetic survey/sample responses) to expand or augment human datasets.",
            "citation_title": "Out of one, many: Using language models to simulate human samples.",
            "mention_or_use": "mention",
            "model_name": null,
            "model_description": null,
            "scientific_subdomain": "Computational social science / survey research (simulation of human respondents)",
            "simulation_task": "Generate synthetic human samples (responses) via language models to simulate populations or augment data (only cited in the review's reference list; no task details provided in the review body).",
            "evaluation_metric": null,
            "simulation_accuracy": null,
            "factors_affecting_accuracy": null,
            "comparison_baseline": null,
            "limitations_or_failure_cases": null,
            "author_recommendations_or_insights": null,
            "uuid": "e9179.5",
            "source_info": {
                "paper_title": "Large Language Models Illuminate a Progressive Pathway to Artificial Healthcare Assistant: A Review",
                "publication_date_yy_mm": "2023-11"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Llava-med: Training a large language-and-vision assistant for biomedicine in one day.",
            "rating": 2,
            "sanitized_title": "llavamed_training_a_large_languageandvision_assistant_for_biomedicine_in_one_day"
        },
        {
            "paper_title": "Pathasst: Redefining pathology through generative foundation ai assistant for pathology.",
            "rating": 2,
            "sanitized_title": "pathasst_redefining_pathology_through_generative_foundation_ai_assistant_for_pathology"
        },
        {
            "paper_title": "Can gpt-4v (ision) serve medical applications? case studies on gpt-4v for multimodal medical diagnosis.",
            "rating": 2,
            "sanitized_title": "can_gpt4v_ision_serve_medical_applications_case_studies_on_gpt4v_for_multimodal_medical_diagnosis"
        },
        {
            "paper_title": "Llmmini-cex: Automatic evaluation of large language model for diagnostic conversation.",
            "rating": 2,
            "sanitized_title": "llmminicex_automatic_evaluation_of_large_language_model_for_diagnostic_conversation"
        },
        {
            "paper_title": "Out of one, many: Using language models to simulate human samples.",
            "rating": 2,
            "sanitized_title": "out_of_one_many_using_language_models_to_simulate_human_samples"
        },
        {
            "paper_title": "Matching patients to clinical trials with large language models.",
            "rating": 2,
            "sanitized_title": "matching_patients_to_clinical_trials_with_large_language_models"
        },
        {
            "paper_title": "Towards expert-level medical question answering with large language models.",
            "rating": 2,
            "sanitized_title": "towards_expertlevel_medical_question_answering_with_large_language_models"
        }
    ],
    "cost": 0.019452249999999997,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Large Language Models Illuminate a Progressive Pathway to Artificial Healthcare Assistant: A Review
3 Nov 2023</p>
<p>Mingze Yuan 
Center for Data Science
Peking University
BeijingChina</p>
<p>Peng Bao 
Center for Data Science
Peking University
BeijingChina</p>
<p>Jiajia Yuan 
Department of Gastrointestinal Oncology
Ministry of Education/Beijing)
Key Laboratory of Carcinogenesis and Translational Research
Peking University Cancer Hospital and Institute
BeijingChina</p>
<p>Yunhao Shen 
Department of Gastrointestinal Oncology
Ministry of Education/Beijing)
Key Laboratory of Carcinogenesis and Translational Research
Peking University Cancer Hospital and Institute
BeijingChina</p>
<p>Zifan Chen 
Center for Data Science
Peking University
BeijingChina</p>
<p>Yi Xie 
Department of Gastrointestinal Oncology
Ministry of Education/Beijing)
Key Laboratory of Carcinogenesis and Translational Research
Peking University Cancer Hospital and Institute
BeijingChina</p>
<p>Jie Zhao 
National Engineering Laboratory for Big Data Analysis and Applications
Peking University
BeijingChina</p>
<p>Peking University Changsha Institute for Computing and Digital Economy
ChangshaChina</p>
<p>Yang Chen 
Department of Gastrointestinal Oncology
Ministry of Education/Beijing)
Key Laboratory of Carcinogenesis and Translational Research
Peking University Cancer Hospital and Institute
BeijingChina</p>
<p>Li Zhang 
Center for Data Science
Peking University
BeijingChina</p>
<p>National Biomedical Imaging Center
Peking University
BeijingChina</p>
<p>Lin Shen 
Department of Gastrointestinal Oncology
Ministry of Education/Beijing)
Key Laboratory of Carcinogenesis and Translational Research
Peking University Cancer Hospital and Institute
BeijingChina</p>
<p>Bin Dong 
Beijing International Center for Mathematical Research
Peking University
BeijingChina</p>
<p>Peking University Changsha Institute for Computing and Digital Economy
ChangshaChina</p>
<p>Center for Machine Learning Research
Peking University
BeijingChina</p>
<p>Large Language Models Illuminate a Progressive Pathway to Artificial Healthcare Assistant: A Review
3 Nov 20235DEA6B3D1FBA5A87C2F739BB687115EDarXiv:2311.01918v1[cs.CL]
With the rapid development of artificial intelligence, large language models (LLMs) have shown promising capabilities in mimicking human-level language comprehension and reasoning.This has sparked significant interest in applying LLMs to enhance various aspects of healthcare, ranging from medical education to clinical decision support.However, medicine involves multifaceted data modalities and nuanced reasoning skills, presenting challenges for integrating LLMs.This paper provides a comprehensive review on the applications and implications of LLMs in medicine.It begins by examining the fundamental applications of general-purpose and specialized LLMs, demonstrating their utilities in knowledge retrieval, research support, clinical workflow automation, and diagnostic assistance.Recognizing the inherent multimodality of medicine, the review then focuses on multimodal LLMs, investigating their ability to process diverse data types like medical imaging and EHRs to augment diagnostic accuracy.To address LLMs' limitations regarding personalization and complex clinical reasoning, the paper explores the emerging development of LLM-powered autonomous agents for healthcare.Furthermore, it summarizes the evaluation methodologies for assessing LLMs' reliability and safety in medical contexts.Overall, this review offers an extensive analysis on the transformative potential of LLMs in modern medicine.It also highlights the pivotal need for continuous optimizations and ethical oversight before these models can be effectively integrated into clinical practice.An accompanying GitHub repository containing latest papers is available at https://github.com/mingze-yuan/Awesome-LLM-Healthcare.</p>
<p>Introduction</p>
<p>With the onset of the 21st century marked by a staggering growth in artificial intelligence capabilities, we have witnessed groundbreaking advancements and transformations across various industries [1,2,3,4,5].Particularly in the medical field, such transformations are even more pronounced [1,5].However, while AI has unveiled countless new opportunities and possibilities for us, it also sheds light on the profound complexity inherent in medical processes.When considering key stages like diagnosis, treatment, and prognosis, the real-world medical data we grapple with is incredibly diverse and intricate.Doctors, when dealing with this data, not only refer to a vast and complicated body of standard medical knowledge but also need to craft individualized treatment plans based on the unique circumstances of each patient.Furthermore, medical examinations are multimodal, encompassing domains like pathology, radiology, and genomics.Faced with such a scenario, integrating this plethora of data and information to form a coherent and comprehensive diagnosis and treatment strategy is undeniably challenging.Most of the current tools are isolated for single tasks, implying that clinical doctors must engage in more holistic analysis and judgment during decision-making.Hence, there's an urgent need for pow-Figure 1: Integration of a Large Language Model (LLM) into advanced healthcare support systems.Multimodal medical data, ranging from pathology, radiology to laboratory sources, funnel into the LLM, symbolized by a digital brain.This LLM interacts seamlessly with AI Agents, distinguished by components including profile, planning, memory, and actions.These agents facilitate a range of healthcare procedures, including diagnosis, prognosis, and surgical assistance, underscoring the pivotal role of the LLM in augmenting AI-empowered healthcare systems.erful intelligent assistance tools to aid these physicians.This is precisely what large language models (LLMs), like GPT-4 [6], offer.Not only can they help doctors consolidate and interpret intricate data, but they also provide insights grounded in extensive knowledge [7], thus ensuring more efficient and precise assistance in pivotal stages like diagnosis, treatment, and prognosis [1,5,8].With the aid of such intelligent tools, we aspire to delve deeper into a patient's genuine situation and make more apt and accurate medical decisions.</p>
<p>In this context, LLMs such as GPT-4 [6], ChatGPT [9], and Claude [10] have gradually made their mark in the medical domain.Taking GPT-4 as an example, its exceptional performance in the United States Medical Licensing Examinations (USMLE) has far exceeded the expectations of many experts.Yet, this is only the tip of the iceberg.While the practical application of LLMs in healthcare is still in its early stages, preliminary research has already unveiled their tremendous potential in specialized medical research and potential clinical decision support [11,12,13,14,15,16,17]. Especially in tasks involving the integration of multimodal medical data from pathology, radiology, and genomics, LLMs have exhibited their unique ability for in-depth interpretation and linkage.Of course, their practical effects and values in real medical environments still require further study and validation.With the introduction of these advanced tools, we not only anticipate efficient consolidation of multisource medical data but also expect AI agents [18] to offer support in predictive analysis and patient management for physicians.For instance, AI agents could assist in analyzing patient histories, laboratory results, and radiological data, subsequently providing data-driven diagnostic suggestion [19,20].Moreover, these tools can further help doctors in choosing the optimal treatment plan from a plethora of options, ensuring patients receive individualized and optimal therapeutic outcomes [21,11].Through this approach, we can look forward to a medical decision-making process that is not only more scientific but also more systematic, ensuring patients receive the best medical care.</p>
<p>Given the outstanding potential of LLMs in medicine, this paper aims to delve deeply into the recent advances achieved by LLMs in this sector, as illustrated in Figure 1.We begin by examining fundamental LLM applications in medicine, spotlighting text-based interactions, and elaborating on both general-purpose and specialized medical LLMs.Subsequently, recognizing the intricate multimodal nature of medicine, we shift our focus to multimodal LLMs, investigating their prowess in inte-grating diverse data types to enhance diagnostic accuracy and efficacy.Despite significant progress in the field, challenges persist, such as achieving genuine personalization, ensuring continual model updates, and empowering AI with the intricate problem-solving skills required in medicine.Against this backdrop, we detail the applications of LLM-driven autonomous agents in the medical domain, presenting a classification of their varied uses.Ultimately, we summarize LLM evaluation methodologies and engage critically on the prevailing limitations and prospective paths forward.</p>
<p>Preliminaries</p>
<p>Before diving deep into the role of LLMs in the medical domain, it's essential to chart the evolution and highlight key technologies underpinning LLMs.This section serves as a foundation, outlining the development trajectory and salient techniques that have characterized the surge of LLMs in recent years.We offer a glossary pertinent to LLMs and their utilization in Table 1.</p>
<p>The emergence of transformer [22] has paved the way for the development of large language models (LLMs) in the field of natural language processing (NLP), exemplified by two significant LLMs, namely GPT [23] and BERT [24].These LLMs [23,24,25,26,9,6] consist of a vast number of learnable parameters, which can easily scale up to billions.They are pre-trained on a large volume of unlabeled corpus using self-supervised learning techniques such as next token prediction [23] and masked language modeling [24].</p>
<p>Recent advancements in LLMs, exemplified by models like ChatGPT [9] and GPT-4 [6], have showcased outstanding performance as zero-shot or few-shot learners, efficiently summarizing, extracting, and generating text with little to no prompting.The introduction of incontext learning [26] has further elevated their capabilities in this domain.Prompt strategies [25,27,28,29,30], often used in conjunction with few-shot or zero-shot learning, enhance the performance of LLMs across diverse tasks by conditioning them on a limited set of examples.Standard prompting techniques [26] often involve presenting the LLM with a succinct prompt, typically a question or statement, steering the model toward the expected outcome.Techniques like chain-of-thought prompting [29,31], which guides LLMs through a sequence of logical steps towards a solution, and least-tomost prompting [28], which systematically breaks down intricate problems into more manageable sub-tasks, exemplify the sophisticated strategies employed to harness and optimize the reasoning prowess of these models.</p>
<p>To enable LLMs to understand natural language instructions and perform real-world tasks, researchers have been exploring methods for instruction-tuning of LLMs [32].Among these methods, reinforcement learning from human feedback (RLHF) [9] has emerged as a crucial technique for training language models to align with human goals.RLHF has been extensively used to fine-tune state-of-the-art LLMs such as GPT-4 [6], Claude [10], Bard [33], and LLaMA-Chat [34].It consists of three interconnected processes: feedback collection, reward modeling, and policy optimization.Specifically, feedback collection involves obtaining evaluations of model outputs from humans and reward modeling aims to train a reward model that mimics these evaluations via supervised learning.Finally, the policy optimization step fine-tunes the language model to produce outputs that garner positive evaluations from the reward model, ensuring alignment with human preferences.A significant challenge with scaling RLHF is the need for copious high-quality human annotations.However, recent research suggests an innovative solution -Reinforcement Learning from AI Feedback (RLAIF) [35].This approach promises performance at par with humanlevel evaluations, potentially circumventing the scalability challenges inherent to RLHF.</p>
<p>The evolution of LLMs has given rise to the concept of foundation models [36,1], which are trained on expansive datasets and demonstrate versatility across diverse downstream applications.Their influence is palpable across various domains, from linguistics [26] and vision [37] to other modalities [38].Intrinsically linked to foundation models is the idea of a generalist model [1], wherein a consistent model structure, devoid of fine-tuning, performs commendably across myriad tasks.The aspiration for a unified multitask model [39] that proficiently addresses an array of challenges has persisted over time [40,41].This ambition is particularly evident in the medical sector [1], where contemporary LLMs underscore the feasibility of crafting medical generalist frameworks [42,43].</p>
<p>Alongside the evolution of LLMs, a plethora of indepth reviews have surfaced.These offer profound understandings of varied facets, encompassing the background, leading-edge technologies, applications, and the inherent challenges in deploying LLMs [44,45,46].Furthermore, pivotal topics such as harmonizing LLMs with human cognition [47], their inherent reasoning capabilities [48], instruction tuning approaches [49], augmentation strategies [50], and evaluation methodologies [51] have been encapsulated in recent reviews.Additionally, the burgeoning fields of multimodal LLMs [52] and LLM-based agents [53,54,18] have been extensively reviewed.</p>
<p>As we transition into the medical realm, a few studies stand out in their exploration of LLMs and their potential impact.Moor et al. [1] have proposed the concept of a generalist medical AI, though without concrete implementations and empirical evaluations.Rajpurkar and Lungren [55] have provided an insightful review on the evolution, impediments, and prospects of radiological AI models in clinical practice, emphasizing the integral role of LLMs.Qiu et al. [56] have examined the potential impact of expansive AI models, particularly LLMs, in Language models with a large number of parameters, capable of performing a wide array of language tasks.</p>
<p>General-purpose LLMs</p>
<p>LLMs designed to handle a wide variety of tasks without task-specific optimization.</p>
<p>Specialized LLMs</p>
<p>LLMs optimized or fine-tuned for a specific task or domain.</p>
<p>Multimodal LLMs</p>
<p>LLMs capable of understanding and generating content across multiple modalities such as text and images.</p>
<p>AI agents</p>
<p>Advanced systems that act autonomously to carry out tasks or make decisions based on data or environment.Reinforcement learning with human feedback (RLHF)</p>
<p>A training approach where human feedback is used to optimize the model's predictions or actions.</p>
<p>Prompt engineering</p>
<p>The practice of crafting and optimizing prompts to effectively instruct a language model.</p>
<p>Zero-shot learning</p>
<p>The ability of a model to generalize to unseen tasks or classes without needing explicit examples during training.</p>
<p>Few-shot learning</p>
<p>The ability of a model to adapt to new tasks or classes with very limited examples.</p>
<p>In-context learning (ICL) Learning or adapting to new tasks by leveraging context or examples provided during inference.</p>
<p>Fine-tuning A process of further training a pre-trained model on a specific task to improve its performance.</p>
<p>Instruction tuning</p>
<p>An approach where LLMs undergo additional training using a dataset of instructionoutput pairs via supervised learning.</p>
<p>Chain-of-thought prompting</p>
<p>Crafting prompts in a way that guides the model through a multi-step reasoning process.Reinforcement Learning from AI Feedback (RLAIF) A reinforcement learning approach where feedback from another AI model is used to guide learning.</p>
<p>Hallucination</p>
<p>The phenomenon where LLMs may fabricate inconsistent or outright false information.</p>
<p>Table 1: This glossary provides concise definitions of crucial terms related to Large Language Models (LLMs) and their applications.It encompasses various types of LLMs, training approaches, learning paradigms, as well as techniques used to optimize and instruct these models.</p>
<p>health informatics, pinpointing seven key areas poised for transformation, including molecular biology and drug development.Liu et al. [57] have highlighted the capacity of artificial general intelligence (AGI) to enhance patient care in radiation oncology through the adept analysis of extensive multimodal clinical data.Moreover, a review by Thirunavukarasu et al. [58] evaluates LLMs' strengths and limitations, emphasizing their potential to enhance clinical, educational, and research activities.Other recent studies [59,60,61,62,63,64] have comprehensively examined the potential applications and challenges of LLMs in healthcare.Notably, He et al. [64] provided an in-depth overview of current specilized LLMs in the healthcare sector, detailing their training data, methodologies, and performance across three benchmarks.</p>
<p>Despite these invaluable insights, the pathway for forging advanced medical AI frameworks harnessing LLMs remains undefined.In the following sections of this survey, we will delve deeper into the manifold applications and implications of LLMs in the medical domain.Specifically, we will explore the broader applications of generalpurpose and specialized LLMs in medicine, focus on the context of multimodal LLMs, and provide an in-depth look into LLM-driven autonomous agents in the medical field.Through this cohesive exploration, our intent is to methodically highlight the transformative potential of LLMs in modern medicine.</p>
<p>LLMs in Medicine</p>
<p>Within the medical field, there is a constant pursuit of AI-driven support systems to enhance healthcare delivery.Prior to the advent of LLMs, Watson for Oncology (WFO) [65] emerged as an AI-assisted decisionmaking tool, collaboratively developed with leading oncologists.This system underwent an extensive training period spanning over four years, drawing upon the National Comprehensive Cancer Network (NCCN) treatment guidelines and amassing over a century's worth of clinical cancer treatment expertise from the United States.WFO was engineered to propose suitable chemotherapy plans tailored to individual cancer patients.Nevertheless, this initial foray into AI-assisted medicine revealed a profound disconnect between traditional machine learning methodologies and the practical workflow of medical practitioners [66], at times resulting in recommendations that were unsafe and incorrect [67].</p>
<p>Large language models, on the other hand, have showcased an enhanced capability for logical reasoning and application of knowledge [68,69,29].In this section, we focus on the application of basic LLMs in medicine that rely solely on textual information for interaction.Our discussion encompasses two main avenues of research: the first explores the direct application of general-purpose LLMs to medical contexts, whereas the second pursues the development of a specialized medical LLM.</p>
<p>Applying General-purpose LLMs to Medicine</p>
<p>The ascendancy of general-purpose LLMs [9,6,33,10,34] has sparked significant interest in the medical field.</p>
<p>Recent literature [59,60,61] has provided a comprehensive review of ChatGPT's applications within healthcare and clinical practice.To gauge the capability of these models, researchers frequently resort to benchmark question-answering datasets spanning various medical disciplines, utilizing metrics such as accuracy, recall, and F1 scores for assessment.OpenAI's pivotal study [6] stands out, showcasing GPT-4's commendable performance on academic and professional tests tailored for an erudite audience.The results pointed to GPT-4's distinguished aptitude in subjects like the Uniform Bar Exam and GRE.Furthermore, Microsoft's independent analysis [70] placed GPT-4 above the USMLE, an exhaustive medical residents' examination, marking a notable improvement from its predecessor, ChatGPT, which merely matched college-level performance on the USMLE [71,72].This progression epitomizes the brisk evolution of LLMs in medical settings.Subsequent research accentuates the adaptability of general-purpose LLMs across diverse medical subspecialties, ranging from oncology [11,12,73] to emergency medicine [13], medical aesthetics [14], radiology [15], ophthalmology [74,75], surgery [76], and nursing [16].These inquiries typically gauge an LLM's domain-specific expertise using carefully curated questions.For example, Hu et al. [75] evaluated GPT-4 by progressively introducing information on select ophthalmic conditions, simulating patient and physician interactions.Experienced ophthalmologists subsequently assessed the model's outputs, underscoring GPT-4's potential utility in both patient referrals and medical training.Additionally, Brin et al. [77] scrutinized both ChatGPT and GPT-4's capabilities in handling USMLE questions centered on communication nuances, ethics, and empathy, finding a noteworthy capacity for empathy and professionalism in AI.</p>
<p>In the realm of knowledge retrieval and dissemination, LLMs emerge as potent instruments, serving not only as invaluable repositories of medical information but also as sophisticated educators.These models afford healthcare professionals immediate access to contemporaneous medical data by meticulously analyzing a plethora of scientific journals, research articles, and clinical protocols.This analysis furnishes pertinent and timely details [78,60] pertaining to disease processes [79,80], therapeutic approaches [81,82,21], and drug interactions [83,84].Such insights can be especially valuable in assisting with the diagnosis of rare diseases [85], which often presents challenges for clini-cians.Furthermore, LLMs have the dexterity to democratize medical knowledge through online medical consultation [7,85,12,86,14,87], ensuring widespread availability while simultaneously offering customization to cater to individual prerequisites, potentially impacting telemedicine [61,88].</p>
<p>The integration of LLMs in medical research and writing, as highlighted in various studies [89,60,17,59,90,91], significantly enhances the efficiency, equity, and applicability of research endeavors.These models streamline experimental design, ensure the preservation of patient confidentiality through effective anonymization of medical records, and augment the available medical text data for training purposes.Notably, they facilitate the swift collection, processing, and sophisticated analysis of disease-specific data, fostering more comprehensive and insightful research initiatives.Clinical trials, an essential component of medical research, benefit immensely from LLMs, as they address challenges related to patient-trial matching and trial planning [92,93,94,95,96,90].A detailed review by Ghim et al. [90] delves into the transformative potential of LLMs within clinical trials, identifying five key areas for imminent implementation: improved patient-trial matching, streamlined clinical planning, advanced free text narrative analysis for coding and classification, assistance in technical trial planning, and the facilitation of informed consent through LLMpowered chatbots.In particular, Jin et al. [94] demonstrated the capability of LLMs, through their proposed TrialGPT system, to aid patients and referral physicians in selecting appropriate clinical trials from a vast array, validating the explanatory prowess and invaluable contribution of LLMs to medical research on three public cohorts encompassing 184 patients and 18,238 annotated clinical trials.</p>
<p>In the context of clinical workflow, LLMs can significantly mitigate the substantial burden shouldered by healthcare professionals by autonomizing the documentation of patient information, clinical observations, and test reports [17].This automation does more than merely streamline the process; it enhances both the accuracy and the thoroughness of the clinical documentation.For example, LLMs have been efficaciously utilized to summarize radiology reports [97], providing a prototype for analogous applications in various domains [11], including using ChatGPT to write patient clinic letters [98].Besides, the deployment of LLMs in clinical decision support is markedly beneficial, offering insightful recommendations pertaining to medication regimens, suggesting suitable imaging services grounded in clinical presentations, and enabling the astute diagnosis of diseases from comprehensive clinical data sets [15].When synergistically integrated with other diagnostic instruments, such as medical imaging tools, LLMs proffer a more holistic perspective of patient health.Moreover, by analytically examining data from analogous cases, LLMs can prog-nosticate patient outcomes, thus assisting both healthcare professionals and patients in navigating toward enlightened treatment decisions.</p>
<p>Beyond such application-oriented evaluations, comparative studies have explored methodological optimizations in LLMs for medical applications, underscoring the critical role of task-adapted prompting for optimal performance.Wang et al. [99] assessed the prowess of state-of-the-art LLMs, including GPT-3.5 [9], GPT-4 [6], and Bard [33], across an array of clinical linguistic tasks, leveraging diverse learning and prompting techniques [29,31,26].Parallel to this, Yuan et al. [21] spotlighted GPT-4's proficiency in intricate clinical assignments, particularly in tumor treatment planning, by employing sophisticated prompting methods.Liu et al.'s study [100] shed light on LLMs' efficiency in radiology, underlining the variance in results depending on specific shot configurations.Moreover, Tang et al. [101] critiqued zero-shot LLMs' abilities in condensing medical evidence, revealing occasional discrepancies in their summaries, thus highlighting the ongoing need for rigorous monitoring and perpetual enhancements.</p>
<p>The potential of general-purpose LLMs is undoubtedly transformative.Yet, when it comes to their integration into the medical sector, numerous challenges arise.Specific tasks and limited question domains can introduce selection bias [75].Furthermore, the model's efficacy often hinges on the design of the prompt, which might not always be intuitive for users [21].Notable commercial LLMs, such as GPT-4 and Claude-2, encounter difficulties when being integrated into clinical workflows.These difficulties range from ensuring HIPAA compliance and safeguarding patient privacy to obtaining necessary IRB approvals, particularly when there's a possibility of patient data being transferred to external servers.From an ethical standpoint, it's worth noting that commercial LLMs like ChatGPT might be restricted from delivering medical diagnoses or drug recommendations [102].Unlike physicians who delve deeper into patients' complaints, models like ChatGPT might provide more generic answers [102].Moreover, they struggle to incorporate the latest health insights, leading to potentially outdated responses.A crucial observation is that some models exhibit deficiencies in specialized medical knowledge, a point emphasized by Antaki et al. [103].One reason for this might be that these LLMs primarily learn from clinical guidelines and research papers-sources that usually reflect controlled environments rather than the nuanced realities of everyday clinical practice.Such challenges amplify the pressing demand for LLMs that are specialized for medical contexts and which are adept at navigating the intricate regulatory landscape [104].</p>
<p>Developing Specialized Medical LLMs</p>
<p>Specialized medical LLMs [102,105,106,69,107,108,109,110,111,112,113,114] are meticulously crafted to address the intricate needs of the healthcare sector, with endeavors centered on either developing entirely new LLMs pre-trained with a healthcare-centric focus or refining existing models to bolster their efficacy within medical contexts.The advent of this category is rooted in research findings that highlight the limitations of generaldomain LLMs, particularly when tasked with healthcarespecific challenges, as they tend to grapple with domain shifts [94,70,75,103].These findings also suggest that merely depending on prompt engineering might not yield substantial enhancements in their performance regarding healthcare-specific applications [21].</p>
<p>One prevalent approach to constructing these specialized medical LLMs involves fine-tuning a base LLM on medical dialogue or datasets tailored to specific instructions.A primary concern with generic LLMs in the realm of medicine is the potential discord between their initial training goals and end-user expectations [102].While LLMs traditionally aim to minimize prediction errors across diverse datasets, users desire models that deliver accurate and safe results.Instruction tuning [32] emerges as a solution, refining LLMs with paired sets of user directives and expected outcomes to better align with users' anticipations.</p>
<p>A noteworthy breakthrough in the field is Google's Med-PaLM [106].This system stands out as the first AI to excel in USMLE-style inquiries, consistently delivering insightful responses to general health queries.To ensure comprehensive evaluations, the researchers introduce MultiMedQA, an all-encompassing benchmark that amalgamates six previous medical QA datasets across different specialties.Furthermore, they introduce a novel dataset, HealthSearchQA.Building on this foundation, Flan-PaLM is derived through instruction tuning on PaLM [115] and subsequently evaluates using MultiMedQA.Impressively, Flan-PaLM outperforms the prior leading model by a margin of 17% in accuracy.This achievement underscores the value of leveraging real-world medical data.Additionally, human evaluators identifies key areas for enhancement.In response to this feedback, researchers develops the "instruction prompt tuning" methodology.This innovation paves the way for the launch of Med-PaLM 2 in March 2023 [69], which boasts an admirable accuracy rate of 86.5% for USMLE-style questions.</p>
<p>However, high-performing models like GPT-4 [6] and Med-PaLM 2 [69] remain proprietary, hampering their private use in this sensitive field.</p>
<p>To circumvent this, efforts have been directed at refining open-source LLMs [100], exemplified by Meta's LLaMA [34].Chat-Doctor [107] stands out in this respect, having fine-tuned LLaMA using extensive patient-doctor dialogues from a popular online medical platform.It further enhances the model with a self-guided information retrieval feature, enabling access to real-time online resources and trusted offline medical databases.This approach markedly amplifies the model's capability to discern patient requirements and offer reliable counsel.Similarly, Radiology-GPT [113] utilizes the Alpaca instruction-tuning framework [116] to create a radiology-centric LLM.The model is tailored to generate diagnostic "Impression" narratives based on provided "Findings" data.While Radiology-GPT performs comparably to ChatGPT in understandability and even surpasses it in coherence, it lags slightly in relevance.Importantly, this underscores the potential for crafting domain-specific LLMs that cater to distinct medical niches, while upholding rigorous privacy standards.</p>
<p>When applied to unstructured textual data, such as Electronic Health Records (EHR), a unique strength of specialized LLMs emerges.Specialized LLMs often outperform traditional structured predictive models due to their inherent flexibility.Jiang et al. [114] demonstrate that unstructured clinical notes from EHRs can facilitate the training of clinical language models.These models can then serve as versatile clinical predictive engines, allowing for streamlined development and deployment.Specifically, their approach, a specialized LLM named NYUTron, is pre-trained on a decade's worth of inpatient clinical notes.It is then fine-tuned for a broad spectrum of clinical and operational predictive tasks, delivering significant enhancements over conventional methods.</p>
<p>Multimodal LLMs in Medicine</p>
<p>Medicine inherently involves multiple data modalities, including text, images, genomics, and more.A recent review on multimodal biomedical AI [142] has explored the opportunities for multimodal datasets in healthcare, and then discussed the key challenges and promising strategies for overcoming them.However, unimodal LLMs still lack the ability to perceive visual modalities such as MRI and handle complex unstructured data (e.g., gene screening status), which limits their utilization for real-world medical scenarios.</p>
<p>In this section, we focus on multimodal LLMs (MLLMs) in medicine [143,117,120,122,124,128,132,42,136,43,144,145], which integrate various modalities into LLMs for diagnostic functions, as listed in Table 2. Here, we specifically examine the taxonomy of utilized data modality, primarily including imaging and intricate unstructured data [146,147,141,139], and proceed with their methodologies for data collection and modality fusion.</p>
<p>A Taxonomy of Data Modality Usage</p>
<p>In the field of medicine, multimodal LLMs can be classified based on the data modality they utilize.They primarily fall into two main categories: imaging, which is the most prominent, and other complex unstructured data types, such as genomic sequences, time-series data, and audio recordings.</p>
<p>Imaging</p>
<p>Existing research on multimodal LLMs in medicine, as evidenced by numerous studies [120,117,122,124,132,42,136,43,148], predominantly focuses on exploiting imaging data.The overarching goal is to devise a universal and adaptive model compatible with various imaging modalities and assignments.BiomedGPT [120] exemplifies this by offering a versatile AI model for medical applications, which integrates diverse modalities, from CT images to clinical notes.Uniquely, BiomedGPT encapsulates information from various input sources into a shared multimodal lexicon suitable for many tasks.It uniformly employs a sequence-to-sequence paradigm throughout both pretraining and finetuning phases.Furthermore, task directives are seamlessly integrated into inputs as plain text, eliminating the need for supplemental parameters.After rigorous testing on multiple biomedical datasets and tasks, BiomedGPT not only demonstrates its ability to effectively disseminate knowledge across tasks but also matches or outperforms dedicated models optimized for specific datasets or modalities.Its strength is most apparent in vision-language assignments like image captioning and visual question answering, where it sets new benchmarks in performance.</p>
<p>The Med-PaLM Multimodal (Med-PaLM M) [42] further exemplifies a cohesive model tailored to interpret a spectrum of biomedical data types, managing diverse tasks using a consistent set of model weights.Addressing the lack of comprehensive multimodal medical benchmarks, it introduced MultiMedBench, an inclusive opensource multimodal medical benchmark.This benchmark covers language, medical imaging, and genomics, encompassing a wide range of tasks.These include question answering, visual question answering, medical image categorization, radiology report creation and summarization, and genomic variant identification.With this foundation, Med-PaLM M introduces a versatile multimodal sequence-to-sequence architecture capable of smoothly integrating diverse biomedical data.The model's universal language decoder provides inherent flexibility, enabling it to handle a variety of biomedical tasks within a unified generative framework.Impressively, even without task-specific fine-tuning, Med-PaLM M matches or surpasses dedicated models across several MultiMedBench tasks.Beyond just performance metrics, the model demonstrates intuitive medical reasoning, adaptability to novel concepts and responsibilities, and effective knowl-  edge transfer.This underscores its vast potential, especially in areas with limited biomedical data."</p>
<p>RadFM [43] serves as a foundational model for radiology.It curates an extensive multimodal dataset, MedMD, boasting roughly 16M medical scans.This dataset includes 15.5M 2D scans and 180K 3D radiological images, each accompanied by textual narratives, such as radiology reports, visual-language instructions, or vital diagnostic labels.Distinctively, RadFM operates as a text-generation model conditions on visual inputs, adeptly merging natural language with 2D or 3D medical imagery.Its output is primarily in the form of natural language, catering to a diverse set of medical tasks.Additionally, RadFM presents a comprehensive radiology benchmark, capturing a spectrum of clinical duties like disease identification, report drafting, and visual question answering across various radiological modalities and anatomical sectors.Also within the field of radiology, ELIXR [148] employs a language-aligned image encoder and skillfully integrates it with a stable LLM, specifically PaLM 2 [149], enabling it to handle a diverse set of tasks.This lightweight adapter architecture is trained on images paired with their corresponding freetext radiology reports, sourced from the MIMIC-CXR dataset [130].This configuration underscores the potential of LLM-aligned multimodal models, demonstrating how the combination of chest X-rays with relevant radiology reports can address numerous medical tasks, including visual question answering and radiology report quality assessment.</p>
<p>The recent advancement in the GPT-4 series, GPT-4V [150], has introduced support for multimodal inputs, garnering immediate attention due to its potential effectiveness.Wu et al. [144] conduct an in-depth evaluation of GPT-4V's performance in multimodal medical diagnostics, encompassing 17 human body systems and employing images from 8 different modalities common in daily clinical practice.The researchers scrutinize GPT-4V's capacity to handle a variety of clinical tasks, assessing its proficiency both with and without patient history, and spanning activities such as imaging modality and anatomy recognition, disease diagnosis, report generation, and disease localization.While the model excels at distinguishing between medical modalities and identifying anatomical structures, it faces challenges in disease diagnosis and producing detailed medical reports.This study underscores that, despite considerable progress in computer vision and natural language processing within large multimodal models, there remains a considerable gap before these tools can be effectively integrated into real-world medical applications and clinical decision-making.However, it is crucial to acknowledge the limitations of this study, as real clinical settings primarily use 3D DICOM formatted radiological images, whereas GPT-4V can process only up to four 2D images simultaneously, necessitating the selection of 2D key slices or small patches for pathology.</p>
<p>Other Unstructured Data</p>
<p>In medical care, clinicians frequently analyze a variety of data types, not limited to medical imaging, but also including clinical notes, lab tests, vital signs, genomics, and other observational metrics.Therefore, effectively deciphering this vast, unstructured data is essential for the integration of multimodal LLMs in healthcare [139,147,141].A recent perspective by Moor et al. [1] underscores the potential of foundational LLMs, which not only incorporate extensive medical knowledge but also adeptly handle intricate unstructured data.Inspired by the transfer learning paradigm of LLMs, Theodoris et al. [146] propose Geneformer.This model is pre-trained on a substantial corpus of approximately 30 million single-cell transcriptomes, allowing for contextspecific predictions in network biology scenarios, especially when data is limited.</p>
<p>In a recent review by Huang et al. [147], the potential applications of multimodal LLMs in dentistry are explored.The authors delineate two primary deployment methodologies: automated dental diagnosis and crossmodal dental diagnosis, elaborating on their prospective utilities.Remarkably, an LLM equipped with a crossmodal encoder can process multi-source data and leverage advanced natural language reasoning for intricate clinical tasks.Beyond the realm of vision-language integration, they underscore the significance of a patient's voice in medical diagnoses, in conjunction with imag-ing and dialogues.They illustrate how waveforms and spectrograms from distinct patients could be ingested by pre-trained LLMs like GPT-4 to diagnose potential ailments and gauge their severity.Here, audio data serves a dual purpose: detecting voice anomalies and comprehending patient narratives.In voice anomaly detection, the system captures patient voice inputs, generates waveforms and spectrograms, and subsequently conducts amplitude and frequency analyses.For narrative understanding, patient accounts are transcribed into text via speech recognition technologies.Essential information, such as described symptoms, can then be distilled and organized into concise reports or bullet points for clinician reference.</p>
<p>Furthermore, HeLM [141] demonstrates the value of multimodal LLMs in delivering personalized healthcare.Designed specifically to process high-dimensional clinical data for disease risk assessment, HeLM employs specialized encoders to convert varied data into the LLM's token embedding space, while simpler tabular data is serialized into textual formats.Impressively, HeLM seamlessly merges both demographic and clinical data, including detailed time-series data, to predict disease risks.Moreover, its exceptional performance in zero-shot and few-shot learning for certain conditions reaffirms the immense foundational knowledge that LLMs can contribute to healthcare.</p>
<p>Notably, though the aforementioned multimodal LLMs show promise in handling multimodal data processing and personal user data, serval challenges remain to be addressed.Initially, a substantial volume of multimodal data, which is currently scarce in healthcare, is essential for training these models.There is also a pressing need for research on converting various modalities into aligned embeddings.</p>
<p>Core Methodologies</p>
<p>Shifting from LLMs to multimodal LLMs (MLLMs) often involves a process termed multimodal instruction tuning [125].Essentially, this method fine-tunes existing LLMs using datasets structured with interwoven text and other data types [151].As the shift from unimodal to multimodal paradigms requires modifications in both dataset structure and model architecture, this section offers an in-depth exploration of the fundamental methodologies for multimodal data acquisition and modality fusion.</p>
<p>Multimodal Data Acquisition</p>
<p>Crafting robust multimodal medical datasets for training MLLMs is a meticulous task that has seen various concerted efforts [117,124].In this context, we spotlight the dominant techniques for data collection, which mainly hinge on modifying established benchmark datasets and employing the innovative method of self-instruction.</p>
<p>Adapting Established Datasets Although existing medical datasets and benchmarks offer a rich source of high-quality data, they often are not formatted for immediate use.Consequently, many studies have undertaken the task of repurposing these datasets into instructionoriented configurations [117,120,128,143,42].One noteworthy example is PathAsst [117], which introduces the PathCap dataset, comprised of image-caption pairs primarily curated from a range of reputable sources, including the PubMed database, medical textbooks, and pathology atlases.A pre-trained classifier sorts out pathological data from PubMed.Subsequently, subfigures and sub-captions are isolated and refined using ChatGPT, leading to a dataset well-suited for multimodal instruction tuning.These image-caption pairs, along with designed instructions, naturally constitute multimodal inputs and responses, where instructions are selected from a pre-established pool.Concurrently, some research initiatives have opted to design a foundational set of instructions [124], expanding them with the aid of GPT-4 for greater diversity and specificity.</p>
<p>Self-Instruction While established datasets are invaluable, they often misalign with real-world scenarios, especially in intricate contexts such as multi-turn conversations.To address this discrepancy, several studies [124,117,43,110] have adopted a self-instruction approach [152].Using this technique, LLMs generate textual data based on a foundational set of handannotated seed samples.For instance, LLaVA-Med [124] leverages GPT-4 [6] to curate instruction-following data with multi-turn conversations around biomedical images.Given an image caption, GPT-4 generates questions and answers, simulating a conversation as if the model could view the image.This interaction is enriched by integrating sentences from the related PubMed articles and by incorporating carefully curated seed examples [152] to guide high-quality conversation generation based on the caption and its context.Similarly, PathAsst [117] prompts GPT-4 to produce conversationbased instruction-following data primarily from image captions.</p>
<p>Modality Fusion</p>
<p>Given that unimodal LLMs predominantly process text, bridging the gap between natural language and various modalities becomes essential.Two primary strategies have emerged to address this: one involves converting external modalities into natural language using expert models before feeding it into the LLM, and the other continuously integrates external modalities into the LLM's embedding space.</p>
<p>Leveraging Expert Models One common approach utilizes expert models, such as image captioning systems, to translate visual data into textual content [153,117].Rather than directly processing multimodal inputs, LLMs interpret the transformed textual representations.Visual Med-Alpaca [153] exemplifies this strategy, utilizing multiple medical visual expert systems, Med-GIT [154] and De-Plot [155], in tandem with an LLM.A classifier discerns which specific captioning model should handle the image data, and the generated text is then integrated with the original textual query, enabling the LLM to craft a pertinent response.However, a notable downside is that such transformations could result in information loss.For instance, the granularity of spatial data in visual content might get oversimplified in the conversion to text, and HeLM [141] has demonstrated that direct text serialization of tabular data does not yield a representation that fully captures the available signal for a complex set of features.</p>
<p>Continuous Injection</p>
<p>Various studies [42,141,136,139,128] have aimed to seamlessly merge multimodal data by continuously injecting it into the embedding space of pre-trained LLMs.For instance, Med-PaLM M [42] integrates visual information using the ViT encoder [138] with PaLM [115], in a manner that sees the continuous integration of visual data.This creates multimodal sentences, where textual data is interspersed with visual embeddings.A representation of such a sentence might look like: Q: What happened between <img 1> and <img 2>?, where <img i> symbolizes an image's embedding.This approach bypasses the discrete token level, allowing for direct mapping of visual observations into the linguistic embedding space.HeLM [141] employs a similar method, converting diverse data types into token embeddings.Nonetheless, a notable challenge with HeLM is the degradation of conversational competence after fine-tuning, a phenomenon observed in other models as well [156].</p>
<p>In more complex scenarios, like with RadFM [43] that deals with 3D images such as MRI or CT scans, the resulting token sequence from visual encoding can be quite lengthy.Here, a perceiver module [157] is used to compactly represent visual data.Leveraging this architecture, diverse image sizes can be uniformly represented, facilitating easier fusion.Similarly, Med-Flamingo [136] uses this perceiver module to efficiently bridge vision encoders and LLMs, translating varying numbers of visual features into a fixed set of outputs, optimizing computational efficiency.</p>
<p>LLM-Powered Autonomous Agents in Medicine</p>
<p>Although LLMs such as ChatGPT, GPT-4 [6], and Med-PaLM M [42] have made strides in the medical domain, they primarily focus on conversational elements and basic information retrieval.In addition, specialized mul-  timodal LLMs demand a vast amount of multimodal data for training, which is scarce in healthcare.Consequently, these models tend to be task-specific, and their conversational capabilities are limited to their training topics.They are not yet fully equipped to serve as comprehensive healthcare agents due to hurdles in personalization, updating knowledge, and engaging in autonomous sequential thinking, strategic planning, and complex problem-solving, all of which are imperative for physicians in clinical practice [19].The development of LLM-driven autonomous agents adept at navigating clinical complexities warrants exploration.</p>
<p>In this section, we offer a concise overview of LLMpowered autonomous agents, outlining their key components and features, as illustrated in Table 3.We proceed to examine existing studies in this domain, classifying them into two primary categories: those focused on developing holistic AI agents for medical applications and those aimed at enhancing individual functionalities of AI agents in healthcare.</p>
<p>Autonomous Agents</p>
<p>Autonomous agents are advanced systems capable of independently accomplishing tasks through self-directed planning and instructions [162].They have emerged as a promising solution for achieving AGI.Traditional approaches have focused on training agents with limited knowledge in isolated environments, failing to achieve human-level proficiency in open-domain settings [163].However, recent breakthroughs in LLMs have exhibited remarkable reasoning capabilities [29], leading to a growing trend in leveraging LLMs as central controllers to empower autonomous agents.This trend holds the potential to develop general problem solvers, as demonstrated by proof-of-concept demos like AutoGPT [164].For a detailed analysis, readers are referred to the comprehensive survey on LLM-based autonomous agents [53,54,18].</p>
<p>In this framework, the LLM acts as the cognitive core of the system, which is further reinforced with various essential capabilities to effectively execute diverse tasks [54].These capabilities are fulfilled through multiple modules: profile, memory, planning, and action [53].Specifically, the profile module aims to determine the role profiles of agents, such as radiologists or programmers, which are typically integrated into the prompt to influence and restrict the behaviors of the LLM [165,166].The memory module stores environmental information and employs recorded memories to facilitate future actions [167].This enables the agent to accumulate experiences, self-evolve, and exhibit more consistent, logical, and effective behavior [168].The planning module empowers the agent to decompose complex tasks into simpler subtasks and solve them sequentially [29,30,28].Additionally, it enables the agent to engage in selfcriticism and self-reflection [169,159], learning from past actions and refining themselves to enhance future performance.The action module translates the agent's decisions into specific outcomes by directly interacting with the environment.The action capability is enriched by the agent's skill in utilizing diverse external tools or knowledge sources [50,170], such as APIs, knowledge bases, and specialized models.These modules are interconnected to establish an LLM-based autonomous agent, where the profiling module influences the memory and planning modules, which, together with the profile, collectively impact the action module [18].</p>
<p>Developing Comprehensive AI Agents in Medicine</p>
<p>Autonomous agents powered by LLM technology, equipped with advanced language comprehension and reasoning abilities, have had a revolutionary impact on various disciplines.They have been successfully employed as assistants in natural science experiments [171,172] and software engineering projects [173,165].However, the potential of autonomous agents in the medical field remains largely unexplored [158,19], due to the complex nature of clinical practice.</p>
<p>AD-AutoGPT [158] has made the first attempt to develop comprehensive AI agents in the medical field, where a specialized AI agent is constructed to autonomously collect, process, and analyze complex health narratives related to Alzheimer's Disease based on textual prompts provided by the user.This agent leverages ChatGPT [9] or GPT-4 [6] for task decomposition and augments it with a library of instructions that includes customized tools such as news search, summarization, and result visualization.Moreover, it incorporates specific prompting mechanisms to enhance the efficiency of retrieving ADrelated information and employs a tailored spatiotemporal information extraction functionality.This pipeline revolutionizes the conventional labor-intensive data analysis approach into a prompt-based automated framework, establishing a solid foundation for subsequent AIassisted public health research.</p>
<p>Abbasian et al. [19] put forth an innovative system, the Conversational Health Agent (CHA), leveraging LLMs to revolutionize personal healthcare services through empathetic dialogue and sophisticated processing of mul-timodal data.This comprehensive system navigates through a series of pivotal steps, initiating the extraction of user queries from conventional multimodal conversations and transforming them into a structured sequence of executable actions to craft the final response.It then demonstrates its problem-solving prowess by tapping into LLMs as a robust knowledge base for a variety of healthcare tasks.Concurrently, it meticulously retrieves the latest and most relevant healthcare information from reputable published sources, aligning it with the user's specific inquiries.The CHA extends its capabilities by forming connections with diverse external health platforms to acquire up-to-date personal user data.When necessary, it delves into multimodal data analysis, utilizing state-of-the-art external machine-learning healthcare tools.Culminating its processes, the system synthesizes all accumulated information to generate responses that are both tailored to the individual user and reflect the most current knowledge, ensuring transparent communication and providing elucidations on the reasoning and reliability of its approach upon user request.The framework proves its mettle by adeptly handling intricate, multi-step health tasks, such as assessing user stress levels, requiring a nuanced blend of personalization, multimodal data analysis, and extensive health knowledge retrieval.</p>
<p>Fulfilling Individual Functions of AI Agents</p>
<p>While comprehensive AI agents tailored for the medical field remain relatively rare, previous research [160,161,20,117,21] that addresses and fulfills individual modules or functions can be considered as initial iterations of AI agents in medicine, illuminating the potential of such agents.</p>
<p>ImpressionGPT [160] introduces the utilization of LLMs for the purpose of summarizing radiology reports.It presents a dynamic prompt approach that employs similarity search techniques to incorporate existing reports that are semantically and clinically similar.These similar reports are then used as demonstrations to assist ChatGPT [9] in learning the text descriptions and summarizations of comparable imaging manifestations within a dynamic context.This enables the model to acquire contextual knowledge from analogous instances in the available data, leveraging the in-context learning capabilities of LLMs [26] in a manner that aligns with the memory module of autonomous agents.Furthermore, an iterative optimization algorithm is devised to automatically evaluate the generated results and formulate corresponding instruction prompts.This iterative process enhances the model by facilitating self-reflection, similar to the self-reflection capability observed in autonomous agents [169,159].In addition, PharmacyGPT [161] extends this framework to address various clinically signif-icant challenges in the pharmacy domain, including patient outcome studies, the generation of AI-based medication prescriptions, and the interpretable clustering analysis of patients, showcasing the versatile potential of autonomous agents in medicine.</p>
<p>Additionally, ChatCAD+ [20], a comprehensive and dependable computer-assisted diagnosis system, is capable of analyzing medical images across a wide range of domains and utilizing up-to-date medical information from reputable sources to offer reliable advice.Specifically, given the input medical image, the system incorporates CLIP [126] as a domain identifier to select an appropriate model to generate textual descriptions that sufficiently characterize image features.Rather than providing diagnostic advice directly, ChatCAD+ first retrieves pertinent knowledge from professional sources such as Mayo Clinic.This curated information bolsters the LLM's knowledge pool, amplifying the reliability of its diagnostic advice.Additionally, ChatCAD+ integrates a template retrieval mechanism, used in ImpressionGPT [160], to further improve the report generation performance.Besides, PathAsst system [117] is fine-tuned to have the capabilities of invoking external pathological models and retrieving relevant information from an extensive paper database, making the system capable of handling more complicated tasks and elevating the precision and thoroughness of the responses.</p>
<p>Evaluation</p>
<p>Given the rapid advancements in the capabilities of LLMs, their integration into critical domains like medicine necessitates a stringent evaluation.These models, while technological marvels, have profound implications on medical decision-making, patient care, and the broader healthcare landscape.As we delve deeper into their technical prowess and applications, the need to ascertain their performance and reliability in medical settings is paramount.</p>
<p>Ensuring the efficacy and safety of LLMs in medicine is vital.An established evaluation framework serves two main purposes: it safeguards against inaccuracies or misjudgments that might have negative consequences in the high-stakes realm of healthcare and provides clear benchmarks and metrics that drive ongoing research and development.Within this framework, evaluating LLMs can be stratified into closed-set and open-set categories based on question types.This distinction is important as it illuminates the model's capabilities in predefined tasks and their adaptability to real-world, unpredictable medical inquiries.</p>
<p>Closed-Set Evaluation</p>
<p>Closed-set questions come with predefined and limited answer options.Their evaluation often uses benchmark-adapted datasets, with performance metrics derived from these standards.For example, LLaVA-Med [124] measures accuracy for closed-set questions using datasets such as VQA-RAD [174] and SLAKE [175].Evaluation settings typically utilize either a zero-shot approach or finetuning.The former takes a range of datasets encompassing various tasks, dividing them into 'held-in' (used for training) and 'held-out' sets (used for testing).</p>
<p>After training on the 'held-in' sets, performance on unseen datasets or tasks is measured.In contrast, finetuning is more common in domain-specific task evaluations, as demonstrated by LLaVA-Med's results on biomedical VQA [174,175].</p>
<p>Despite their usefulness, these evaluations often cover only a limited set of tasks or datasets, lacking a broad quantitative comparison.Recent efforts have sought to bridge this gap, like Med-PaLM's introduction of Mul-tiMedQA [176], which consolidates six medical Q&amp;A datasets, and the addition of another dataset from online medical queries.Another significant contribution is MultiMedBench by Med-PaLM M [42], a comprehensive benchmark for biomedical tasks.RadFM's Rad-Bench [43] caters specifically to radiology.</p>
<p>Open-set Evaluation</p>
<p>Open-set questions allow for a wider range of responses, making LLMs function similarly to chatbots in this context.Given the diverse content, evaluating these responses is multifaceted.Metrics cover standard measures, expert reviews, model scores, and other unique aspects.The model should prioritize clinical relevance, ensuring its information directly influences patient care.Accuracy, safety, interpretability, ethical considerations, and scalability are also of paramount importance, ensuring the model's predictions are trustworthy and widely applicable.</p>
<p>Standard Metrics Standardized metrics established in the NLP community are often employed to evaluate LLM linguistic outputs.These include F1 score [43], accuracy [43], precision [43], recall [124], BLEU [177], METEOR [178], and ROUGE score [179].For instance, BLEU evaluates word and phrase overlaps between a model's output and a reference, while METEOR measures lexical and semantic similarities between the generated summary and the reference.These metrics, which range from 0.0 to 1.0, reflect how closely generated outputs match reference answers.</p>
<p>Expert Evaluation In the healthcare domain, model evaluation goes beyond standard metrics like BLEU and ROUGE, given the evident discrepancies when human evaluations depart from automated benchmarks [21,106,42].Med-PaLM's findings underscored that even topperforming models, such as Flan-PaLM [176], might not always align with clinicians' preferences.The introduction of clinical radiology-tailored metrics, accompanied by expert assessments on aspects like clinical relevance, offers a more grounded evaluation.Both Yuan et al. [21] and Xu et al. [180] have developed metrics based on clinical evaluations to further refine model assessment.The robust evaluation process begins with pilot studies, followed by expert peer reviews, culminating in real-world clinical tests.This comprehensive framework ensures not only the model's accuracy but also its applicability and safety.Once thoroughly vetted, such models can gradually integrate into clinical workflows, aiding professionals in diagnostics, treatment suggestions, and more.</p>
<p>Model Scoring To address the resource-intensive nature of manual assessments, researchers [181,182,183,184,185,102] are exploring LLM-based scoring systems like GPT-Eval [181] and LLM-Mini-CEX [182].These systems employ model-centric strategies, wherein one LLM, usually GPT-4 [6], evaluates another one's medical dialogues.For instance, GPT-Eval [181] provides a methodology where the task and criteria are fed into an LLM, leading to a series of evaluation steps that another LLM uses for assessment.LLM-Mini-CEX [182] offers a unique LLM-tailored criterion, streamlining evaluation of diagnostic abilities by automating interactions using a patient simulator and ChatGPT.However, these methods face challenges related to transparency, accuracy, and sometimes limited diagnostic performance, as noted by Shi et al. [182].</p>
<p>Other Aspects There are also evaluations focusing on unique LLM characteristics [51], such as faithfulness [186], hallucination [187], safety [188], and robustness against adversarial interventions [189].For example, to address the challenges posed by hallucinations in LLMs, particularly in the context of the medical domain, Med-HALT [187] provides a diverse multinational dataset derived from medical examinations across various countries and includes multiple innovative testing modalities, especially reasoning hallucination tests.</p>
<p>In summary, as LLMs show promising advancements in the medical domain, rigorous and comprehensive evaluations are crucial.A combination of automated metrics, expert evaluations, and real-world testing ensures the models' efficacy and safety.As technology and medicine further intertwine, evaluation frameworks must evolve accordingly to ensure the best patient outcomes.Once a model passes this framework, its gradual integration into clinical workflows can commence, starting with tasks like summarizing medical records or aiding in diagnostics, but always under medical professionals' supervision.</p>
<p>Discussion</p>
<p>In this review, we have meticulously navigated through the multifaceted landscape of Large Language Models (LLMs) in the medical domain, illuminating their promising potential.We initiated our exploration by delving into the foundational applications of LLMs in medicine, emphasizing text-based interactions and distinguishing between general-purpose and specialized medical LLMs.Recognizing the inherent multimodality of the medical field, our discussion transitioned to multimodal LLMs, highlighting their capability to integrate diverse data types and thereby augment diagnostic accuracy.Despite these advancements, we acknowledged the persisting challenges such as the need for personalized responses, maintaining currency with the latest medical knowledge, and navigating complex problem-solving scenarios-skills that are indispensable for clinicians in clinical settings.In response to these challenges, we scrutinized the emerging role of LLM-powered autonomous agents in medicine, categorizing their applications and summarizing prevailing evaluation methodologies.</p>
<p>Through this extensive analysis, we aimed to provide a balanced and nuanced perspective on the current state of LLMs in medicine.In the contemporary landscape of LLM development, there is a discernible trend toward harnessing LLMs specifically for the medical domain.While general-purpose LLMs exhibit remarkable proficiency, our observations suggest a strategic advantage in not directly fine-tuning them on specialized, longtailed medical data.Instead, employing highly specialized expert models to handle such nuanced data, followed by storing the processed information in vector databases [20,117], emerges as a promising paradigm.In practice, querying this database can offer accurate and domain-specific insights.This approach not only presents a potential solution to the "hallucination" phenomenon, where the models may fabricate inconsistent or outright false information, but also paves the way for integration within an autonomous agent-based system, hinting at a comprehensive medical support system for the future.Amidst these advancements, we emphasize the potential of LLMs to revolutionize medical practice while underscoring the imperative for ethical vigilance and continuous scrutiny.</p>
<p>The integration of LLMs in the medical field necessitates a nuanced evaluation from both technological and medical standpoints.From a technical perspective, the proficiency of LLMs in parsing and generating complex, nuanced language is crucial, particularly in understanding and formulating medical terminology, patient narratives, and intricate case details.However, the efficacy of these models hinges on their ability to handle sensitive information ethically, maintain patient confidentiality, and navigate the consequences of misinformation, requiring strict accuracy benchmarks.For medical professionals, the assessment revolves around the practical applicability of LLMs: do they enhance diagnostic accuracy, improve patient communication, and aid in advanced research and treatment methodologies without compromising professional responsibilities or patient trust?Ultimately, the symbiotic evaluation seeks to ensure that LLMs not only exhibit technical excellence but also adhere to the rigorous ethical and professional standards indispensable in healthcare.</p>
<p>Although LLMs possess remarkable intellectual abilities, they inherently face certain constraints and are prone to producing inaccurate or possibly damaging content.Their understanding of context is limited, which is particularly problematic in medical settings where precision is crucial.The models' potential to misinterpret or oversimplify complex medical information necessitates rigorous human oversight.Moreover, LLMs' knowledge is constrained to their training data [17,190,89,16], potentially leading to outdated or biased responses, and their inability to ask follow-up questions can be a significant drawback in patient care.</p>
<p>Ethical dilemmas significantly pervade the deployment of LLMs in the medical sphere.These models, by inheriting biases from their vast swathes of training data, are at risk of producing responses that are prejudiced or discriminatory, thereby challenging the principles of fairness and equity in healthcare.The "hallucination" phenomenon pose a substantial risk, particularly in medical settings where accuracy is paramount [15].Moreover, the legal landscape [89] surrounding the use of LLMs in medicine is intricate and fraught with potential pitfalls, necessitating meticulous attention.Issues such as copyright infringement, plagiarism [190], defamation, and breaches of privacy are prominent concerns that must be proactively addressed to safeguard against legal repercussions and uphold ethical standards.Complicating these issues is the models' inherent complexity and the opaqueness of their internal mechanisms.This lack of transparency hinders the ability to decipher how specific outputs are generated, leading to potential trust and accountability issues [190,191].</p>
<p>Despite these challenges, LLMs hold the potential to transform healthcare by enhancing research, improving operational efficiency, and aiding in decision-making.For successful integration and adoption in healthcare, it is imperative to address these limitations and ensure ethical, reliable, and safe applications.Future directions should focus on developing frameworks that recognize and mitigate these constraints, promoting a responsible and informed use of LLMs in medicine.</p>
<p>Conclusion</p>
<p>In conclusion, this review offers a comprehensive analysis of the transformative potential of large language models (LLMs) in modern medicine.It demonstrates the fundamental applications of general-purpose and specialized LLMs in areas like knowledge retrieval, research support, workflow automation, and diagnostic assistance.Recognizing the multimodal nature of medicine, the review explores multimodal LLMs and their ability to process diverse data types including medical imaging and EHRs to enhance diagnostic accuracy.To address limitations of LLMs regarding personalization and complex clinical reasoning, the emerging role of LLM-powered autonomous agents in medicine is discussed.The review also summarizes methodologies for evaluating the reliability and safety of LLMs in medical contexts.</p>
<p>Overall, LLMs hold remarkable promise in medicine but require continuous optimization and ethical oversight before effective integration into clinical practice.Key challenges highlighted include data limitations, reasoning gaps, potential biases, and transparency issues.Future priorities should focus on developing frameworks to identify and mitigate LLM limitations, guiding responsible and informed applications in healthcare.With prudent progress, LLMs can transform modern medicine through enhanced knowledge consolidation, personalized care, accelerated research, and augmented clinical decisionmaking.But ultimately, human expertise, ethics and oversight will remain indispensable in delivering compassionate, high-quality and equitable healthcare.</p>
<p>does chatgpt perform on the united states medical licensing examination?the implications of large language models for medical education and knowledge assessment," JMIR Medical Education, vol.9, no. 1, p. e45312, 2023.</p>
<p>Table 2 :
2
[100]mary of multimodal LLMs in medicine.This table does not include the multitude of open-source projects available on Github[100].The "Sample Size" column denotes the number of training samples, such as image-text pairs."VQA" stands for Visual Question Answering, and "QA" stands for Question Answering.</p>
<p>Table 3 :
3
A summary of LLM-powered autonomous agents in the field of medicine, detailing their specific tasks, planning mechanisms, memory components, and usage of external tools."N/A" denotes components that are not available.</p>
<p>AcknowledgementsThis work was supported by the National Natural Science Foundation of China (91959205 to L.S., U22A20327 to L.S., 82203881 to Y.C., 82272627 to XT.Z., 7232018 to Y.S., 12090022 to B.D., 11831002 to B.D., 81801778 to L.Z.), Beijing Natural Science Foundation (7222021 to Y.C., Z200015 to XT.Z.), Beijing Hospitals Authority Youth Programme (QML20231115 to Y.C.), Clinical Medicine Plus X-Young Scholars Project of Peking University (PKU2023LCXQ041 to Y.C. and L.Z.), Guangdong Provincial Key Laboratory of Precision Medicine for Gastrointestinal Cancer (2020B121201004).
Foundation models for generalist medical artificial intelligence. M Moor, O Banerjee, Z S H Abad, H M Krumholz, J Leskovec, E J Topol, P Rajpurkar, Nature. 61679562023</p>
<p>From artificial intelligence to explainable artificial intelligence in industry 4.0: a survey on what, how, and where. I Ahmed, G Jeon, F Piccialli, IEEE Transactions on Industrial Informatics. 1882022</p>
<p>Redefining creativity in the era of ai? perspectives of computer scientists and new media artists. R Wingström, J Hautala, R Lundman, Creativity Research Journal. 2023</p>
<p>A survey of deep learning for mathematical reasoning. P Lu, L Qiu, W Yu, S Welleck, K.-W Chang, arXiv:2212.105352022arXiv preprint</p>
<p>The AI revolution in medicine: GPT-4 and beyond. P Lee, C Goldberg, I Kohane, 2023Pearson</p>
<p>Openai, abs/2303.08774Gpt-4 technical report. 2023</p>
<p>Ai-generated medical advice-gpt and beyond. C E Haupt, M Marks, Jama. 329162023</p>
<p>Benefits, limits, and risks of gpt-4 as an ai chatbot for medicine. P Lee, S Bubeck, J Petro, New England Journal of Medicine. 388132023</p>
<p>Training language models to follow instructions with human feedback. L Ouyang, J Wu, X Jiang, D Almeida, C Wainwright, P Mishkin, C Zhang, S Agarwal, K Slama, A Ray, Advances in Neural Information Processing Systems. 202235</p>
<p>Y Bai, S Kadavath, S Kundu, A Askell, J Kernion, A Jones, A Chen, A Goldie, A Mirhoseini, C Mckinnon, arXiv:2212.08073Constitutional ai: Harmlessness from ai feedback. 2022arXiv preprint</p>
<p>Appropriateness of breast cancer prevention and screening recommendations provided by chatgpt. H L Haver, E B Ambinder, M Bahl, E T Oluyemi, J Jeudy, P H Yi, Radiology. 3074e2304242023</p>
<p>Can the chatgpt and other large language models with internetconnected database solve the questions and concerns of patient with prostate cancer and help democratize medical knowledge?. L Zhu, W Mou, R Chen, Journal of Translational Medicine. 2112023</p>
<p>chatgpt, can you help me save my child's life?"-diagnostic accuracy and supportive capabilities to lay rescuers by chatgpt in prehospital basic life support and paediatric advanced life support cases-an in-silico analysis. S Bushuven, M Bentele, S Bentele, B Gerber, J Bansbach, J Ganter, M Trifunovic-Koenig, R Ranisch, 2023Research Square</p>
<p>Aesthetic surgery advice and counseling from artificial intelligence: a rhinoplasty consultation with chatgpt. Y Xie, I Seth, D J Hunter-Smith, W M Rozen, R Ross, M Lee, Aesthetic Plastic Surgery. 2023</p>
<p>Chatgpt and other large language models are double-edged swords. Y Shen, L Heacock, J Elias, K D Hentel, B Reig, G Shih, L Moy, 2023</p>
<p>Chatgpt, large language models, and generative ai as future augments of surgical cancer care. A Kothari, Annals of Surgical Oncology. 2023</p>
<p>The promise of large language models in health care. A Arora, A Arora, The Lancet. 401103776412023</p>
<p>Z Xi, W Chen, X Guo, W He, Y Ding, B Hong, M Zhang, J Wang, S Jin, E Zhou, arXiv:2309.07864The rise and potential of large language model based agents: A survey. 2023arXiv preprint</p>
<p>Conversational health agents: A personalized llm-powered agent framework. M Abbasian, I Azimi, A M Rahmani, R Jain, arXiv:2310.023742023arXiv preprint</p>
<p>Chat-cad+: Towards a universal and reliable interactive cad using llms. Z Zhao, S Wang, J Gu, Y Zhu, L Mei, Z Zhuang, Z Cui, Q Wang, D Shen, arXiv:2305.159642023arXiv preprint</p>
<p>Advanced prompting as a catalyst: Empowering large language models in the management of gastrointestinal cancers. J Yuan, P Bao, Z Chen, M Yuan, J Zhao, J Pan, Y Xie, Y Cao, Y Wang, Z Wang, Z Lu, X Zhang, J Li, L Ma, Y Chen, L Zhang, L Shen, B Dong, The Innovation Medicine. 2023</p>
<p>Attention is all you need. A Vaswani, N Shazeer, N Parmar, J Uszkoreit, L Jones, A N Gomez, L Kaiser, I Polosukhin, Advances in neural information processing systems. 201730</p>
<p>Improving language understanding by generative pre-training. A Radford, K Narasimhan, T Salimans, I Sutskever, OpenAI blog. 2018</p>
<p>Bert: Pre-training of deep bidirectional transformers for language understanding. J Devlin, M.-W Chang, K Lee, K Toutanova, arXiv:1810.048052018arXiv preprint</p>
<p>Language models are unsupervised multitask learners. A Radford, J Wu, R Child, D Luan, D Amodei, I Sutskever, OpenAI blog. 1892019</p>
<p>Language models are few-shot learners. T Brown, B Mann, N Ryder, M Subbiah, J D Kaplan, P Dhariwal, A Neelakantan, P Shyam, G Sastry, A Askell, Advances in neural information processing systems. 202033</p>
<p>Retrievalaugmented generation for knowledge-intensive nlp tasks. P Lewis, E Perez, A Piktus, F Petroni, V Karpukhin, N Goyal, H Küttler, M Lewis, W -T. Yih, T Rocktäschel, Advances in Neural Information Processing Systems. 202033</p>
<p>Least-to-most prompting enables complex reasoning in large language models. D Zhou, N Schärli, L Hou, J Wei, N Scales, X Wang, D Schuurmans, O Bousquet, Q Le, E Chi, arXiv:2205.106252022arXiv preprint</p>
<p>Chainof-thought prompting elicits reasoning in large language models. J Wei, X Wang, D Schuurmans, M Bosma, F Xia, E Chi, Q V Le, D Zhou, Advances in Neural Information Processing Systems. 202235</p>
<p>Tree of thoughts: Deliberate problem solving with large language models. S Yao, D Yu, J Zhao, I Shafran, T L Griffiths, Y Cao, K Narasimhan, arXiv:2305.106012023arXiv preprint</p>
<p>Large language models are zero-shot reasoners. T Kojima, S S Gu, M Reid, Y Matsuo, Y Iwasawa, Advances in neural information processing systems. 202235</p>
<p>Instruction tuning with gpt-4. B Peng, C Li, P He, M Galley, J Gao, arXiv:2304.032772023arXiv preprint</p>
<p>. " Google, Bard, 2023</p>
<p>Llama 2: Open foundation and fine-tuned chat models. H Touvron, L Martin, K Stone, P Albert, A Almahairi, Y Babaei, N Bashlykov, S Batra, P Bhargava, S Bhosale, arXiv:2307.092882023arXiv preprint</p>
<p>Rlaif: Scaling reinforcement learning from human feedback with ai feedback. H Lee, S Phatale, H Mansoor, K Lu, T Mesnard, C Bishop, V Carbune, A Rastogi, arXiv:2309.002672023arXiv preprint</p>
<p>On the opportunities and risks of foundation models. R Bommasani, D A Hudson, E Adeli, R Altman, S Arora, S Arx, M S Bernstein, J Bohg, A Bosselut, E Brunskill, arXiv:2108.072582021arXiv preprint</p>
<p>Scaling vision transformers to 22 billion parameters. M Dehghani, J Djolonga, B Mustafa, P Padlewski, J Heek, J Gilmer, A P Steiner, M Caron, R Geirhos, I Alabdulmohsin, International Conference on Machine Learning. PMLR2023</p>
<p>Audiolm: a language modeling approach to audio generation. Z Borsos, R Marinier, D Vincent, E Kharitonov, O Pietquin, M Sharifi, D Roblek, O Teboul, D Grangier, M Tagliasacchi, Speech, and Language Processing. 2023</p>
<p>Multitask learning. R Caruana, Machine learning. 199728</p>
<p>A unified architecture for natural language processing: Deep neural networks with multitask learning. R Collobert, J Weston, Proceedings of the 25th international conference on Machine learning. the 25th international conference on Machine learning2008</p>
<p>An overview of multi-task learning in deep neural networks. S Ruder, arXiv:1706.050982017arXiv preprint</p>
<p>T Tu, S Azizi, D Driess, M Schaekermann, M Amin, P.-C Chang, A Carroll, C Lau, R Tanno, I Ktena, arXiv:2307.14334Towards generalist biomedical ai. 2023arXiv preprint</p>
<p>Towards generalist foundation model for radiology. C Wu, X Zhang, Y Zhang, Y Wang, W Xie, arXiv:2308.024632023arXiv preprint</p>
<p>W X Zhao, K Zhou, J Li, T Tang, X Wang, Y Hou, Y Min, B Zhang, J Zhang, Z Dong, arXiv:2303.18223A survey of large language models. 2023arXiv preprint</p>
<p>Harnessing the power of llms in practice: A survey on chatgpt and beyond. J Yang, H Jin, R Tang, X Han, Q Feng, H Jiang, B Yin, X Hu, arXiv:2304.137122023arXiv preprint</p>
<p>Language model behavior: A comprehensive survey. T A Chang, B K Bergen, arXiv:2303.115042023arXiv preprint</p>
<p>Aligning large language models with human: A survey. Y Wang, W Zhong, L Li, F Mi, X Zeng, W Huang, L Shang, X Jiang, Q Liu, arXiv:2307.129662023arXiv preprint</p>
<p>Towards reasoning in large language models: A survey. J Huang, K C , -C Chang, arXiv:2212.104032022arXiv preprint</p>
<p>Instruction tuning for large language models: A survey. S Zhang, L Dong, X Li, S Zhang, X Sun, S Wang, J Li, R Hu, T Zhang, F Wu, G Wang, abs/2308.10792ArXiv. 2023</p>
<p>Augmented language models: a survey. G Mialon, R Dessì, M Lomeli, C Nalmpantis, R Pasunuru, R Raileanu, B Rozière, T Schick, J Dwivedi-Yu, A Celikyilmaz, arXiv:2302.078422023arXiv preprint</p>
<p>A survey on evaluation of large language models. Y Chang, X Wang, J Wang, Y Wu, K Zhu, H Chen, L Yang, X Yi, C Wang, Y Wang, arXiv:2307.031092023arXiv preprint</p>
<p>A survey on multimodal large language models. S Yin, C Fu, S Zhao, K Li, X Sun, T Xu, E Chen, ArXiv. 2306.13549, 2023</p>
<p>L Wang, C Ma, X Feng, Z Zhang, H Yang, J Zhang, Z Chen, J Tang, X Chen, Y Lin, arXiv:2308.11432A survey on large language model based autonomous agents. 2023arXiv preprint</p>
<p>Llm-powered autonomous agents. L Weng, Jun 2023</p>
<p>The current and future state of ai interpretation of medical images. P Rajpurkar, M P Lungren, New England Journal of Medicine. 388212023</p>
<p>Large ai models in health informatics: Applications, challenges, and the future. J Qiu, L Li, J Sun, J Peng, P Shi, R Zhang, Y Dong, K Lam, F P , .-W Lo, B Xiao, arXiv:2303.115682023arXiv preprint</p>
<p>Artificial general intelligence for radiation oncology. C Liu, Z Liu, J Holmes, L Zhang, L Zhang, Y Ding, P Shu, Z Wu, H Dai, Y Li, arXiv:2309.025902023arXiv preprint</p>
<p>Large language models in medicine. A J Thirunavukarasu, D S J Ting, K Elangovan, L Gutierrez, T F Tan, D S W Ting, Nature Medicine. 2023</p>
<p>Chatgpt in healthcare: A taxonomy and systematic review. J Li, A Dada, J Kleesiek, J Egger, medRxiv. 2023</p>
<p>Chatgpt utility in healthcare education, research, and practice: systematic review on the promising perspectives and valid concerns. M Sallam, Healthcare2023MDPI11887</p>
<p>Utility of chatgpt in clinical practice. J Liu, C Wang, S Liu, Journal of Medical Internet Research. 25e485682023</p>
<p>The future landscape of large language models in medicine. J Clusmann, F R Kolbinger, H S Muti, Z I Carrero, J.-N Eckardt, N G Laleh, C M L Löffler, S.-C Schwarzkopf, M Unger, G P Veldhuizen, Communications Medicine. 311412023</p>
<p>Large language models in medicine: the potentials and pitfalls. J A Omiye, H Gui, S J Rezaei, J Zou, R Daneshjou, arXiv:2309.000872023arXiv preprint</p>
<p>K He, R Mao, Q Lin, Y Ruan, X Lan, M Feng, E Cambria, arXiv:2310.05694A survey of large language models for healthcare: from data, technology, and applications to accountability and ethics. 2023arXiv preprint</p>
<p>A meta-analysis of watson for oncology in clinical application. Z Jie, Z Zhiying, L Li, Scientific reports. 11157922021</p>
<p>Ibm watson, heal thyself: How ibm overpromised and underdelivered on ai health care. E Strickland, IEEE Spectrum. 5642019</p>
<p>Ibm's watson supercomputer recommended 'unsafe and incorrect'cancer treatments, internal documents show. C Ross, I Swetlitz, Stat news. 252018</p>
<p>S Ott, K Hebenstreit, V Liévin, C E Hother, M Moradi, M Mayrhauser, R Praas, O Winther, M Samwald, arXiv:2301.11596Thoughtsource: A central hub for large language model reasoning data. 2023arXiv preprint</p>
<p>Towards expert-level medical question answering with large language models. K Singhal, T Tu, J Gottweis, R Sayres, E Wulczyn, L Hou, K Clark, S Pfohl, H Cole-Lewis, D Neal, arXiv:2305.096172023arXiv preprint</p>
<p>Capabilities of gpt-4 on medical challenge problems. H Nori, N King, S M Mckinney, D Carignan, E Horvitz, arXiv:2303.133752023arXiv preprint</p>
<p>How. A Gilson, C W Safranek, T Huang, V Socrates, L Chi, R A Taylor, D Chartash, </p>
<p>Performance of chatgpt on usmle: Potential for ai-assisted medical education using large language models. T H Kung, M Cheatham, A Medenilla, C Sillos, L De Leon, C Elepaño, M Madriaga, R Aggabao, G Diaz-Candido, J Maningo, PLoS digital health. 22e00001982023</p>
<p>Large language model (chatgpt) as a support tool for breast tumor board. V Sorin, E Klang, M Sklair-Levy, I Cohen, D B Zippel, N Balint Lahat, E Konen, Y Barash, NPJ Breast Cancer. 91442023</p>
<p>Performance of an artificial intelligence chatbot in ophthalmic knowledge assessment. A Mihalache, M M Popovic, R H Muni, JAMA ophthalmology. 2023</p>
<p>What can gpt-4 do for diagnosing rare eye diseases? a pilot study. X Hu, A R Ran, T X Nguyen, S Szeto, J C Yam, C K Chan, C Y Cheung, Ophthalmology and Therapy. 2023</p>
<p>Chatgpt is equivalent to first year plastic surgery residents: evaluation of chatgpt on the plastic surgery in-service exam. P Humar, M Asaad, F B Bengur, V Nguyen, Aesthetic Surgery Journal. 1302023</p>
<p>Comparing chatgpt and gpt-4 performance in usmle soft skill assessments. D Brin, V Sorin, A Vaid, A Soroush, B S Glicksberg, A W Charney, G Nadkarni, E Klang, Scientific Reports. 131164922023</p>
<p>Retrieve, summarize, and verify: How will chatgpt impact information seeking from the medical literature?. Q Jin, R Leaman, Z Lu, 2023Journal of the American Society of Nephrology</p>
<p>Role of chat gpt in public health. S S Biswas, Annals of biomedical engineering. 5152023</p>
<p>How ai responds to common lung cancer questions: Chatgpt vs google bard. A A Rahsepar, N Tavakoli, G H J Kim, C Hassani, F Abtin, A Bedayat, Radiology. 3075e2309222023</p>
<p>Chatgpt/gpt-4: enabling a new era of surgical oncology. K Cheng, H Wu, C Li, International Journal of Surgery. 10982023</p>
<p>A new era in internet interventions: The advent of chat-gpt and ai-assisted therapist guidance. P Carlbring, H Hadjistavropoulos, A Kleiboer, G Andersson, Internet Interventions. 322023</p>
<p>Chat gpt-4 significantly surpasses gpt-3.5 in drug information queries. N He, Y Yan, Z Wu, Y Cheng, F Liu, X Li, S Zhai, Journal of Telemedicine and Telecare. 2023</p>
<p>The role of ai in drug discovery: challenges, opportunities, and strategies. A Blanco-Gonzalez, A Cabezon, A Seco-Gonzalez, D Conde-Torres, P Antelo-Riveiro, A Pineiro, R Garcia-Fandino, Pharmaceuticals. 1668912023</p>
<p>Gpt-4: the future of cosmetic procedure consultation?. Y.-X Sun, Z.-M Li, J.-Z Huang, N.-Z Yu, X Long, Aesthetic Surgery Journal. 1342023</p>
<p>Chatgpt and antimicrobial advice: the end of the consulting infection doctor?. A Howard, W Hope, A Gerada, The Lancet Infectious Diseases. 2342023</p>
<p>Assessing the performance of chatgpt in answering questions regarding cirrhosis and hepatocellular carcinoma. Y H Yeo, J S Samaan, W H Ng, P.-S Ting, H Trivedi, A Vipani, W Ayoub, J D Yang, O Liran, B Spiegel, Clinical and Molecular Hepatology. 2023</p>
<p>Use of gpt-4 to analyze medical records of patients with extensive investigations and delayed diagnosis. Y.-F Shea, C M Y Lee, W C T Ip, D W A Luk, S S W Wong, JAMA Network Open. 682023</p>
<p>Chatgpt and the future of medical writing. S Biswas, 2023</p>
<p>Transforming clinical trials: the emerging roles of large language models. J.-L Ghim, S Ahn, Translational and Clinical Pharmacology. 3131312023</p>
<p>C Peng, X Yang, A Chen, K E Smith, N Pournejatian, A B Costa, C Martin, M G Flores, Y Zhang, T Magoc, arXiv:2305.13523A study of generative large language model for medical research and healthcare. 2023arXiv preprint</p>
<p>An ai boost for clinical trials. M Woo, Nature. 57377752019</p>
<p>Improving patient pre-screening for clinical trials. D M Hamer, P Schoor, T B Polak, D Kapitan, arXiv:2304.07396Assisting physicians with large language models. 2023arXiv preprint</p>
<p>Matching patients to clinical trials with large language models. Q Jin, Z Wang, C S Floudas, J Sun, Z Lu, arXiv:2307.150512023arXiv preprint</p>
<p>Clinidigest: a case study in large language model based large-scale summarization of clinical trial descriptions. R White, T Peng, P Sripitak, A Rosenberg Johansen, M Snyder, Proceedings of the 2023 ACM Conference on Information Technology for Social Good. the 2023 ACM Conference on Information Technology for Social Good2023</p>
<p>Autotrial: Prompting language models for clinical trial design. Z Wang, C Xiao, J Sun, arXiv:2305.113662023arXiv preprint</p>
<p>Potential of chatgpt and gpt-4 for data mining of free-text ct reports on lung cancer. M A Fink, A Bischoff, C A Fink, M Moll, J Kroschke, L Dulz, C P Heußel, H.-U Kauczor, T F Weber, Radiology. 3083e2313622023</p>
<p>Using chatgpt to write patient clinic letters. S R Ali, T D Dobbs, H A Hutchings, I S Whitaker, The Lancet Digital Health. 542023</p>
<p>Are large language models ready for healthcare? a comparative study on clinical language understanding. Y Wang, Y Zhao, L Petzold, arXiv:2304.053682023arXiv preprint</p>
<p>Evaluating large language models for radiology natural language processing. Z Liu, T Zhong, Y Li, Y Zhang, Y Pan, Z Zhao, P Dong, C Cao, Y Liu, P Shu, arXiv:2307.136932023arXiv preprint</p>
<p>Evaluating large language models on medical evidence summarization. L Tang, Z Sun, B Idnay, J G Nestor, A Soroush, P A Elias, Z Xu, Y Ding, G Durrett, J F Rousseau, npj Digital Medicine. 611582023</p>
<p>Huatuogpt, towards taming language model to be a doctor. H Zhang, J Chen, F Jiang, F Yu, Z Chen, J Li, G Chen, X Wu, Z Zhang, Q Xiao, arXiv:2305.150752023arXiv preprint</p>
<p>Evaluating the performance of chatgpt in ophthalmology: An analysis of its successes and shortcomings. F Antaki, S Touma, D Milad, J El-Khoury, R Duval, Ophthalmology Science. 1003242023</p>
<p>R Mao, G Chen, X Zhang, F Guerin, E Cambria, arXiv:2308.12488Gpteval: A survey on assessments of chatgpt and gpt-4. 2023arXiv preprint</p>
<p>A large language model for electronic health records. X Yang, A Chen, N Pournejatian, H C Shin, K E Smith, C Parisien, C Compas, C Martin, A B Costa, M G Flores, NPJ Digital Medicine. 511942022</p>
<p>Large language models encode clinical knowledge. K Singhal, S Azizi, T Tu, S S Mahdavi, J Wei, H W Chung, N Scales, A Tanwani, H Cole-Lewis, S Pfohl, Nature. 2023</p>
<p>Chatdoctor: A medical chat model fine-tuned on a large language model meta-ai (llama) using medical domain knowledge. Y Li, Z Li, K Zhang, R Dan, S Jiang, Y Zhang, Cureus. 1562023</p>
<p>Huatuo: Tuning llama model with chinese medical knowledge. H Wang, C Liu, N Xi, Z Qiang, S Zhao, B Qin, T Liu, arXiv:2304.069752023arXiv preprint</p>
<p>Doctorglm: Fine-tuning your chinese doctor is not a herculean task. H Xiong, S Wang, Y Zhu, Z Zhao, Y Liu, Q Wang, D Shen, arXiv:2304.010972023arXiv preprint</p>
<p>Pmc-llama: Further finetuning llama on medical papers. C Wu, X Zhang, Y Zhang, Y Wang, W Xie, arXiv:2304.144542023arXiv preprint</p>
<p>Bianque: Balancing the questioning and suggestion ability of health llms with multi-turn health conversations polished by chatgpt. Y Chen, Z Wang, X Xing, H Zheng, Z Xu, K Fang, J Wang, S Li, J Wu, Q Liu, X Xu, 2023Github</p>
<p>Clinicalgpt: Large language models finetuned with diverse medical data and comprehensive evaluation. G Wang, G Yang, Z Du, L Fan, X Li, arXiv:2306.099682023arXiv preprint</p>
<p>Z Liu, A Zhong, Y Li, L Yang, C Ju, Z Wu, C Ma, P Shu, C Chen, S Kim, arXiv:2306.08666Radiologygpt: A large language model for radiology. 2023arXiv preprint</p>
<p>Health systemscale language models are all-purpose prediction engines. L Y Jiang, X C Liu, N P Nejatian, M Nasir-Moin, D Wang, A Abidin, K Eaton, H A Riina, I Laufer, P Punjabi, Nature. 2023</p>
<p>Palm: Scaling language modeling with pathways. A Chowdhery, S Narang, J Devlin, M Bosma, G Mishra, A Roberts, P Barham, H W Chung, C Sutton, S Gehrmann, P Schuh, K Shi, S Tsvyashchenko, J Maynez, A Rao, P Barnes, Y Tay, N M Shazeer, V Prabhakaran, E Reif, N Du, B C Hutchinson, R Pope, J Bradbury, J Austin, M Isard, G Gur-Ari, P Yin, T Duke, A Levskaya, S Ghemawat, S Dev, H Michalewski, X García, V Misra, K Robinson, L Fedus, D Zhou, D Ippolito, D Luan, H Lim, B Zoph, A Spiridonov, R Sepassi, D Dohan, S Agrawal, M Omernick, A M Dai, T S Pillai, M Pellat, A Lewkowycz, E Moreira, R Child, O Polozov, K Lee, Z Zhou, X Wang, B Saeta, M Díaz, O Firat, M Catasta, J Wei, K S Meier-Hellstern, D Eck, J Dean, S Petrov, N Fiedel, abs/2204.02311ArXiv. 2022</p>
<p>Stanford alpaca: An instructionfollowing llama model. R Taori, I Gulrajani, T Zhang, Y Dubois, X Li, C Guestrin, P Liang, T B Hashimoto, 2023</p>
<p>Pathasst: Redefining pathology through generative foundation ai assistant for pathology. Y Sun, C Zhu, S Zheng, K Zhang, Z Shui, X Yu, Y.-L Zhao, H Li, Y Zhang, R Zhao, X Lyu, L Yang, ArXiv. 2023</p>
<p>A visual-language foundation model for pathology image analysis using medical twitter. Z Huang, F Bianchi, M Yuksekgonul, T J Montine, J Y Zou, Nature medicine. 2023</p>
<p>Judging llm-as-a-judge with mt-bench and chatbot arena. L Zheng, W.-L Chiang, Y Sheng, S Zhuang, Z Wu, Y Zhuang, Z Lin, Z Li, D Li, E P Xing, H Zhang, J E Gonzalez, I Stoica, 2023</p>
<p>Biomedgpt: A unified and generalist biomedical generative pre-trained transformer for vision, language, and multimodal tasks. K Zhang, J Yu, Z Yan, Y Liu, E Adhikarla, S Fu, X Chen, C Chen, Y Zhou, X Li, arXiv:2305.171002023arXiv preprint</p>
<p>Ofa: Unifying architectures, tasks, and modalities through a simple sequence-to-sequence learning framework. P Wang, A Yang, R Men, J Lin, S Bai, Z Li, J Ma, C Zhou, J Zhou, H Yang, International Conference on Machine Learning. PMLR2022</p>
<p>Pmc-vqa: Visual instruction tuning for medical visual question answering. X Zhang, C Wu, Z Zhao, W Lin, Y Zhang, Y Wang, W Xie, abs/2305.10415ArXiv. 2023</p>
<p>Pmc-clip: Contrastive language-image pre-training using biomedical documents. W Lin, Z Zhao, X Zhang, C Wu, Y Zhang, Y Wang, W Xie, arXiv:2303.072402023arXiv preprint</p>
<p>Llava-med: Training a large language-and-vision assistant for biomedicine in one day. C Li, C Wong, S Zhang, N Usuyama, H Liu, J Yang, T Naumann, H Poon, J Gao, arXiv:2306.008902023arXiv preprint</p>
<p>Visual instruction tuning. H Liu, C Li, Q Wu, Y J Lee, arXiv:2304.084852023arXiv preprint</p>
<p>Learning transferable visual models from natural language supervision. A Radford, J W Kim, C Hallacy, A Ramesh, G Goh, S Agarwal, G Sastry, A Askell, P Mishkin, J Clark, International conference on machine learning. PMLR2021</p>
<p>Large-scale domain-specific pretraining for biomedical vision-language processing. S Zhang, Y Xu, N Usuyama, J Bagga, R Tinn, S Preston, R Rao, M Wei, N Valluri, C Wong, arXiv:2303.009152023arXiv preprint</p>
<p>Xraygpt: Chest radiographs summarization using medical vision-language models. O Thawakar, A M Shaker, S S Mullappilly, H Cholakkal, R M Anwer, S S Khan, J Laaksonen, F S Khan, ArXiv. 2023</p>
<p>Medclip: Contrastive learning from unpaired medical images and text. Z Wang, Z Wu, D Agarwal, J Sun, arXiv:2210.101632022arXiv preprint</p>
<p>Mimic-cxr, a de-identified publicly available database of chest radiographs with free-text reports. A E Johnson, T J Pollard, S J Berkowitz, N R Greenbaum, M P Lungren, C -Y. Deng, R G Mark, S Horng, Scientific data. 20196317</p>
<p>Preparing a collection of radiology examinations for distribution and retrieval. D Demner-Fushman, M D Kohli, M B Rosenman, S E Shooshan, L Rodriguez, S Antani, G R Thoma, C J Mcdonald, Journal of the American Medical Informatics Association. 2322016</p>
<p>Cephgpt-4: An interactive multimodal cephalometric measurement and diagnostic system with visual large language model. L Ma, J Han, Z Wang, D Zhang, abs/2307.07518ArXiv. 2023</p>
<p>Minigpt-4: Enhancing vision-language understanding with advanced large language models. D Zhu, J Chen, X Shen, X Li, M Elhoseiny, arXiv:2304.105922023arXiv preprint</p>
<p>Glm: General language model pretraining with autoregressive blank infilling. Z Du, Y Qian, X Liu, M Ding, J Qiu, Z Yang, J Tang, Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics. Long Papers. the 60th Annual Meeting of the Association for Computational Linguistics20221</p>
<p>Palme: An embodied multimodal language model. D Driess, F Xia, M S M Sajjadi, C Lynch, A Chowdhery, B Ichter, A Wahid, J Tompson, Q H Vuong, T Yu, W Huang, Y Chebotar, P Sermanet, D Duckworth, S Levine, V Vanhoucke, K Hausman, M Toussaint, K Greff, A Zeng, I Mordatch, P R Florence, International Conference on Machine Learning. 2023</p>
<p>Med-flamingo: a multimodal medical few-shot learner. M Moor, Q Huang, S Wu, M Yasunaga, C Zakka, Y Dalmia, E P Reis, P Rajpurkar, J Leskovec, abs/2307.15189ArXiv. 2023</p>
<p>Openflamingo: An open-source framework for training large autoregressive vision-language models. A Awadalla, I Gao, J Gardner, J Hessel, Y Hanafy, W Zhu, K Marathe, Y Bitton, S Y Gadre, S Sagawa, J Jitsev, S Kornblith, P W Koh, G Ilharco, M Wortsman, L Schmidt, abs/2308.01390ArXiv. 2023</p>
<p>An image is worth 16x16 words: Transformers for image recognition at scale. A Dosovitskiy, L Beyer, A Kolesnikov, D Weissenborn, X Zhai, T Unterthiner, M Dehghani, M Minderer, G Heigold, S Gelly, J Uszkoreit, N Houlsby, International Conference on Machine Learning. 2021</p>
<p>Biomedgpt: Open multimodal generative pre-trained transformer for biomedicine. Y Luo, J Zhang, S Fan, K Yang, Y Wu, M Qiao, Z Nie, arXiv:2308.094422023arXiv preprint</p>
<p>S2orc: The semantic scholar open research corpus. K Lo, L L Wang, M Neumann, R Kinney, D S Weld, arXiv:1911.027822019arXiv preprint</p>
<p>Multimodal llms for health grounded in individualspecific data. A Belyaeva, J Cosentino, F Hormozdiari, K Eswaran, S Shetty, G Corrado, A Carroll, C Y Mclean, N A Furlotte, abs/2307.09018ArXiv. 2023</p>
<p>Multimodal biomedical ai. J N Acosta, G J Falcone, P Rajpurkar, E J Topol, Nature Medicine. 2892022</p>
<p>Xrayglm: The first chinese medical multimodal model that chest radiographs summarization. R Wang, Y Duan, J Li, P Pang, T Tan, 2023</p>
<p>Can gpt-4v (ision) serve medical applications? case studies on gpt-4v for multimodal medical diagnosis. C Wu, J Lei, Q Zheng, W Zhao, W Lin, X Zhang, X Zhou, Z Zhao, Y Zhang, Y Wang, arXiv:2310.099092023arXiv preprint</p>
<p>Path to medical agi: Unify domain-specific medical llms with the lowest cost. J Zhou, X Chen, X Gao, arXiv:2306.107652023arXiv preprint</p>
<p>Transfer learning enables predictions in network biology. C V Theodoris, L Xiao, A Chopra, M D Chaffin, Z R A Sayed, M C Hill, H Mantineo, E M Brydon, Z Zeng, X S Liu, P T Ellinor, Nature. 6182023</p>
<p>Chatgpt for shaping the future of dentistry: the potential of multi-modal large language model. H Huang, O Zheng, D Wang, J Yin, Z Wang, S Ding, H Yin, C Xu, R Yang, Q Zheng, International Journal of Oral Science. 151292023</p>
<p>Elixr: Towards a general purpose x-ray artificial intelligence system through alignment of large language models and radiology vision encoders. S Xu, L Yang, C Kelly, M Sieniek, T Kohlberger, M Ma, W.-H Weng, A Kiraly, S Kazemzadeh, Z Melamed, arXiv:2308.013172023arXiv preprint</p>
<p>R Anil, A M Dai, O Firat, M Johnson, D Lepikhin, A Passos, S Shakeri, E Taropa, P Bailey, Z Chen, arXiv:2305.10403Palm 2 technical report. 2023arXiv preprint</p>
<p>The dawn of lmms: Preliminary explorations with gpt-4v (ision). Z Yang, L Li, K Lin, J Wang, C.-C Lin, Z Liu, L Wang, arXiv:2309.174212023arXiv preprint</p>
<p>Finetuned language models are zero-shot learners. J Wei, M Bosma, V Zhao, K Guu, A W Yu, B Lester, N Du, A M Dai, Q V Le, International Conference on Learning Representations. 2021</p>
<p>Self-instruct: Aligning language model with self generated instructions. Y Wang, Y Kordi, S Mishra, A Liu, N A Smith, D Khashabi, H Hajishirzi, arXiv:2212.105602022arXiv preprint</p>
<p>Medalpaca-an open-source collection of medical conversational ai models and training data. T Han, L C Adams, J.-M Papaioannou, P Grundmann, T Oberhauser, A Löser, D Truhn, K K Bressem, arXiv:2304.082472023arXiv preprint</p>
<p>Git: A generative image-to-text transformer for vision and language. J Wang, Z Yang, X Hu, L Li, K Lin, Z Gan, Z Liu, C Liu, L Wang, arXiv:2205.141002022arXiv preprint</p>
<p>Deplot: One-shot visual language reasoning by plot-to-table translation. F Liu, J M Eisenschlos, F Piccinno, S Krichene, C Pang, K Lee, M Joshi, W Chen, N Collier, Y Altun, arXiv:2212.105052022arXiv preprint</p>
<p>Preserving in-context learning ability in large language model fine-tuning. Y Wang, S Si, D Li, M Lukasik, F X Yu, C.-J Hsieh, I S Dhillon, S Kumar, abs/2211.00635ArXiv. 2022</p>
<p>Perceiver: General perception with iterative attention. A Jaegle, F Gimeno, A Brock, O Vinyals, A Zisserman, J Carreira, International conference on machine learning. PMLR2021</p>
<p>Ad-autogpt: An autonomous gpt for alzheimer's disease infodemiology. H Dai, Y Li, Z Liu, L Zhao, Z Wu, S Song, Y Shen, D Zhu, X Li, S Li, arXiv:2306.100952023arXiv preprint</p>
<p>React: Synergizing reasoning and acting in language models. S Yao, J Zhao, D Yu, N Du, I Shafran, K Narasimhan, Y Cao, arXiv:2210.036292022arXiv preprint</p>
<p>Impressiongpt: an iterative optimizing framework for radiology report summarization with chatgpt. C Ma, Z Wu, J Wang, S Xu, Y Wei, Z Liu, L Guo, X Cai, S Zhang, T Zhang, arXiv:2304.084482023arXiv preprint</p>
<p>Pharmacygpt: The ai pharmacist. Z Liu, Z Wu, M Hu, B Zhao, L Zhao, T Zhang, H Dai, X Chen, Y Shen, S Li, arXiv:2307.104322023arXiv preprint</p>
<p>Is it an agent, or just a program?: A taxonomy for autonomous agents. S Franklin, A Graesser, International workshop on agent theories, architectures, and languages. Springer1996</p>
<p>Human-level control through deep reinforcement learning. V Mnih, K Kavukcuoglu, D Silver, A A Rusu, J Veness, M G Bellemare, A Graves, M Riedmiller, A K Fidjeland, G Ostrovski, nature. 51875402015</p>
<p>Autogpt. G Significant, 2023GitHub</p>
<p>Metagpt: Meta programming for multiagent collaborative framework. S Hong, X Zheng, J Chen, Y Cheng, C Zhang, Z Wang, S K S Yau, Z Lin, L Zhou, C Ran, arXiv:2308.003522023arXiv preprint</p>
<p>Out of one, many: Using language models to simulate human samples. L P Argyle, E C Busby, N Fulda, J R Gubler, C Rytting, D Wingate, Political Analysis. 3132023</p>
<p>Chatdb: Augmenting llms with databases as their symbolic memory. C Hu, J Fu, C Du, S Luo, J Zhao, H Zhao, arXiv:2306.039012023arXiv preprint</p>
<p>W Zhong, L Guo, Q Gao, Y Wang, arXiv:2305.10250Memorybank: Enhancing large language models with long-term memory. 2023arXiv preprint</p>
<p>Reflexion: Language agents with verbal reinforcement learning. N Shinn, F Cassano, B Labash, A Gopinath, K Narasimhan, S Yao, arXiv:2303.113662023arXiv preprint</p>
<p>Toolformer: Language models can teach themselves to use tools. T Schick, J Dwivedi-Yu, R Dessì, R Raileanu, M Lomeli, L Zettlemoyer, N Cancedda, T Scialom, arXiv:2302.047612023arXiv preprint</p>
<p>Emergent autonomous scientific research capabilities of large language models. D A Boiko, R Macknight, G Gomes, arXiv:2304.053322023arXiv preprint</p>
<p>Chemcrow: Augmenting largelanguage models with chemistry tools. A M Bran, S Cox, A D White, P Schwaller, arXiv:2304.053762023arXiv preprint</p>
<p>Communicative agents for software development. C Qian, X Cong, C Yang, W Chen, Y Su, J Xu, Z Liu, M Sun, arXiv:2307.079242023arXiv preprint</p>
<p>A dataset of clinically generated visual questions and answers about radiology images. J J Lau, S Gayen, A Ben Abacha, D Demner-Fushman, Scientific data. 512018</p>
<p>Slake: A semantically-labeled knowledgeenhanced dataset for medical visual question answering. B Liu, L.-M Zhan, L Xu, L Ma, Y Yang, X.-M Wu, 2021 IEEE 18th International Symposium on Biomedical Imaging (ISBI). IEEE2021</p>
<p>Large language models encode clinical knowledge. K Singhal, S Azizi, T Tu, S Mahdavi, J Wei, H W Chung, N Scales, A K Tanwani, H J Cole-Lewis, S J Pfohl, P A Payne, M G Seneviratne, P Gamble, C Kelly, N Scharli, A Chowdhery, P A Mansfield, B A Arcas, D R Webster, G S Corrado, Y Matias, K H , .-L Chou, J Gottweis, N Tomavsev, Y Liu, A Rajkomar, J K Barral, C Semturs, A Karthikesalingam, V Natarajan, Nature. 6202022</p>
<p>Bleu: a method for automatic evaluation of machine translation. K Papineni, S Roukos, T Ward, W.-J Zhu, Annual Meeting of the Association for Computational Linguistics. 2002</p>
<p>Meteor: An automatic metric for mt evaluation with improved correlation with human judgments. S Banerjee, A Lavie, Proceedings of the acl workshop on intrinsic and extrinsic evaluation measures for machine translation and/or summarization. the acl workshop on intrinsic and extrinsic evaluation measures for machine translation and/or summarization2005</p>
<p>Rouge: A package for automatic evaluation of summaries. C.-Y Lin, Annual Meeting of the Association for Computational Linguistics. 2004</p>
<p>Medgpteval: A dataset and benchmark to evaluate responses of large language models in medicine. J Xu, L Lu, S Yang, B Liang, X Peng, J Pang, J Ding, X Shi, L Yang, H Song, arXiv:2305.073402023arXiv preprint</p>
<p>Y Liu, D Iter, Y Xu, S Wang, R Xu, C Zhu, arXiv:2303.16634Gpteval: Nlg evaluation using gpt-4 with better human alignment. 2023arXiv preprint</p>
<p>Llmmini-cex: Automatic evaluation of large language model for diagnostic conversation. X Shi, J Xu, J Ding, J Pang, S Liu, S Luo, X Peng, L Lu, H Yang, M Hu, arXiv:2308.076352023arXiv preprint</p>
<p>Gptscore: Evaluate as you desire. J Fu, S.-K Ng, Z Jiang, P Liu, arXiv:2302.041662023arXiv preprint</p>
<p>Exploring the use of large language models for reference-free text quality evaluation: A preliminary empirical study. Y Chen, R Wang, H Jiang, S Shi, R Xu, arXiv:2304.007232023arXiv preprint</p>
<p>Can large language models be an alternative to human evaluations?. C.-H Chiang, H.-Y Lee, arXiv:2305.019372023arXiv preprint</p>
<p>Faithful ai in medicine: A systematic review with large language models and beyond. Q Xie, E J Schenck, H S Yang, Y Chen, Y Peng, F Wang, Medrxiv: the Preprint Server for Health Sciences. 2023</p>
<p>Med-halt: Medical domain hallucination test for large language models. L K Umapathi, A Pal, M Sankarasubbu, arXiv:2307.153432023arXiv preprint</p>
<p>Safetybench: Evaluating the safety of large language models with multiple choice questions. Z Zhang, L Lei, L Wu, R Sun, Y Huang, C Long, X Liu, X Lei, J Tang, M Huang, arXiv:2309.070452023arXiv preprint</p>
<p>Adversarial glue: A multi-task benchmark for robustness evaluation of language models. B Wang, C Xu, S Wang, Z Gan, Y Cheng, J Gao, A H Awadallah, B Li, arXiv:2111.028402021arXiv preprint</p>
<p>The utility of chatgpt as an example of large language models in healthcare education, research and practice: Systematic review on the future perspectives and potential limitations. M Sallam, 2023medRxiv</p>
<p>The role and limitations of large language models such as chatgpt in clinical settings and medical journalism. F Ufuk, Radiology. 3073e2302762023</p>            </div>
        </div>

    </div>
</body>
</html>