<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2278 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2278</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2278</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-64.html">extraction-schema-64</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that automatically generate research hypotheses or research ideas, including how novelty and feasibility are measured, quantified, or traded off against each other.</div>
                <p><strong>Paper ID:</strong> paper-259202505</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2306.11648v1.pdf" target="_blank">Harnessing the Power of Adversarial Prompting and Large Language Models for Robust Hypothesis Generation in Astronomy</a></p>
                <p><strong>Paper Abstract:</strong> This study investigates the application of Large Language Models (LLMs), specifically GPT-4, within Astronomy. We employ in-context prompting, supplying the model with up to 1000 papers from the NASA Astrophysics Data System, to explore the extent to which performance can be improved by immersing the model in domain-specific literature. Our findings point towards a substantial boost in hypothesis generation when using in-context prompting, a benefit that is further accentuated by adversarial prompting. We illustrate how adversarial prompting empowers GPT-4 to extract essential details from a vast knowledge base to produce meaningful hypotheses, signaling an innovative step towards employing LLMs for scientific research in Astronomy.</p>
                <p><strong>Cost:</strong> 0.014</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2278.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2278.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that automatically generate research hypotheses or research ideas, including how novelty and feasibility are measured, quantified, or traded off against each other.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Astro-GPT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Astro-GPT workflow (this paper)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A pipeline that generates scientific hypotheses in Galactic Astronomy by combining retrieval-augmented in-context prompting of GPT-4 with iterative adversarial critique and moderated feedback to refine ideas.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Astro-GPT</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>An end-to-end LLM-based hypothesis-generation pipeline built in this study. Papers (N_k ∈ {1,10,100,1000}) are PDF->text processed, chunked (≈1,000 tokens), embedded with text-ada-002, and stored in a vector DB. Given a query/chat history the pipeline embeds the input, performs similarity search to retrieve relevant chunks, applies 'contextual compression' (filtering of irrelevant detail), and provides the compressed context + prompt to a GPT-4 'Generation' instance. The generation is followed by an 'Adversarial' GPT-4 critic and a third GPT-4 moderator that reformulates feedback into a question for the generator; this iterative adversarial cycle (nF iterations) refines hypotheses. Tools used: LangChain for retrieval and contextual compression, OpenAI embeddings (text-ada-002), GPT-4 for generation, critique, and moderation. Outputs are hypotheses and adversarial critiques; human experts evaluate final outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>research_domain</strong></td>
                            <td>astronomy (Galactic Astronomy)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_type</strong></td>
                            <td>open-ended exploration / interdisciplinary synthesis (generating novel research hypotheses from literature)</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td>Human-expert 'creativity' subscore within a 3-category rubric (scientific accuracy, creativity, feasibility), each scored on a 1–5 scale; final 'quality' is mean of the three subscores. No automated semantic-novelty metric (e.g., distance from literature embeddings) was reported as a numeric metric.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_score</strong></td>
                            <td>Not reported separately for 'creativity' alone; reported aggregate quality (mean of accuracy, creativity, feasibility) improved from 2.5/5 (context=10 papers) to ~4/5 (context=1000 papers with adversarial prompting).</td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_metric</strong></td>
                            <td>Human-expert 'feasibility' subscore from the same 1–5 rubric (part of the 3-category evaluation). No automated feasibility probability or resource-estimate metric reported.</td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_score</strong></td>
                            <td>Not reported separately for 'feasibility' alone; included in the aggregate quality score which improved from 2.5/5 to ~4/5 under larger context + adversarial prompting.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_evidence</strong></td>
                            <td>No explicit quantitative trade-off analysis between novelty and feasibility (e.g., correlations or Pareto front). Qualitatively, human-evaluated 'quality' (which averages creativity and feasibility) increased with adversarial prompting and larger context; the paper notes adversarial improvements tended to add technical detail rather than deep conceptual insight, but does not report a formal novelty-versus-feasibility trade-off metric.</td>
                        </tr>
                        <tr>
                            <td><strong>optimization_strategy</strong></td>
                            <td>Iterative adversarial refinement: generator -> adversarial critic -> moderator -> feedback -> generator; iteration count (nF) varied and shown to improve both quality and consistency. Retrieval of larger context (increasing N_k) is used in combination with adversarial iterations to improve outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation_results</strong></td>
                            <td>Two domain experts scored hypotheses along three categories (scientific accuracy, creativity, feasibility) on a 1–5 scale; reported mean aggregate quality rose from 2.5/5 at N=10 (no/limited adversarial improvement) to ≈4/5 at N=1000 with adversarial prompting. 60 hypotheses and 40 critiques (for N=1000) were evaluated; adversarial prompting substantially improved quality and consistency. No per-category numeric breakdown (creativity vs feasibility) is provided in the paper text.</td>
                        </tr>
                        <tr>
                            <td><strong>comparative_baseline</strong></td>
                            <td>Ablations by context size (N_k = 1,10,100,1000) and by presence/absence of adversarial prompting (nF = 0 vs nF > 0). The implicit baseline is in-context prompting without adversarial critique (nF=0) and/or smaller context sizes.</td>
                        </tr>
                        <tr>
                            <td><strong>comparative_results</strong></td>
                            <td>Without adversarial prompting (nF=0) hypothesis quality was stagnant even with large context. With adversarial prompting and large context (N=1000) mean quality rose to ≈4/5 from 2.5/5 (at N=10). No other baseline (e.g., human-only or different LLM) numerical comparisons provided.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_findings</strong></td>
                            <td>In Galactic Astronomy, access to a broad corpus (1000 papers) plus adversarial prompting enabled GPT-4 to 'connect the dots' across subfields and produce near-expert-level hypotheses; small corpora (10 papers) led to generic, incremental ideas. Adversarial prompting guided expansion of the model's 'knowledge footprint' across diverse subtopics (visualized via embeddings + t-SNE).</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2278.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2278.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that automatically generate research hypotheses or research ideas, including how novelty and feasibility are measured, quantified, or traded off against each other.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Adversarial prompting</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Adversarial in-context prompting (iterative critique-feedback loop)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A method where a generator LLM produces an idea, a separate LLM critic (adversary) critiques it, and a moderator reformulates feedback back to the generator; repeated iteratively to refine outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Adversarial prompting (generator–critic–moderator loop)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>An LLM-based iterative refinement scheme: after initial hypothesis generation, a second LLM acts as an adversarial critic pointing out weaknesses and suggesting improvements; a third LLM moderates and reformulates the critique into constructive feedback/questions, which are returned to the generator. Iterations (nF) of this adversarial loop force the generator to expand scope, address overlooked evidence, and incorporate more specific technical detail.</td>
                        </tr>
                        <tr>
                            <td><strong>research_domain</strong></td>
                            <td>astronomy (demonstrated), general LLM-driven hypothesis generation applicable to other domains</td>
                        </tr>
                        <tr>
                            <td><strong>problem_type</strong></td>
                            <td>open-ended exploration and iterative refinement of ideas</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td>Implicitly measured via human 'creativity' scores in the study's rubric; no automated novelty metric tied specifically to adversarial prompting was reported.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_score</strong></td>
                            <td>Not separately reported for adversarial prompting alone; overall aggregate quality increased with adversarial iterations (no per-iteration numeric series reported in text).</td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_metric</strong></td>
                            <td>Implicitly measured via human 'feasibility' scores in the rubric; adversarial critiques reportedly improved technical detail (which likely affected feasibility scores) but no automatic metric provided.</td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_score</strong></td>
                            <td>Not separately reported.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_evidence</strong></td>
                            <td>No explicit quantitative evidence of a novelty vs feasibility trade-off. The paper notes adversarial prompting mostly improved technical detail (feasibility aspects) rather than deep conceptual novelty in some cases, but no formal trade-off analysis provided.</td>
                        </tr>
                        <tr>
                            <td><strong>optimization_strategy</strong></td>
                            <td>Iterative adversarial refinement (varying nF); combining adversarial iterations with larger retrieval context (N_k) to improve outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation_results</strong></td>
                            <td>Adversarial prompting substantially improved human-judged quality and consistency of hypotheses; it introduced a strong correlation between number of contextual papers and hypothesis quality, and without it quality was stagnant.</td>
                        </tr>
                        <tr>
                            <td><strong>comparative_baseline</strong></td>
                            <td>No-adversary (nF=0) condition; smaller context sizes.</td>
                        </tr>
                        <tr>
                            <td><strong>comparative_results</strong></td>
                            <td>Adversarial prompting produced higher mean quality scores and more consistent critiques/generations compared to nF=0; exact numeric differences by nF are not provided except aggregate examples (2.5→4/5 when increasing context and using adversarial prompting).</td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_findings</strong></td>
                            <td>Adversarial prompting was essential for GPT-4 to effectively use a large corpus in Galactic Astronomy and to produce coherent, well-referenced hypotheses rather than fact-jumbles.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2278.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2278.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that automatically generate research hypotheses or research ideas, including how novelty and feasibility are measured, quantified, or traded off against each other.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>In-context prompting</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>In-context prompting with retrieval-augmented context</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Providing an LLM with task-specific examples or domain documents at inference time to steer its outputs without fine-tuning, here implemented with up to 1000 retrieved document chunks as context.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>In-context prompting (retrieval-augmented)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>An LLM technique where relevant documents are retrieved from a corpus, compressed, and provided inline as context to GPT-4 so it can generate domain-specific hypotheses without fine-tuning. Implemented here with chunking of papers, embedding-based similarity search, and contextual compression to fit the model's input window (GPT-4 ~8k tokens in their setup).</td>
                        </tr>
                        <tr>
                            <td><strong>research_domain</strong></td>
                            <td>astronomy (demonstrated); applicable to domain-specific hypothesis generation generally</td>
                        </tr>
                        <tr>
                            <td><strong>problem_type</strong></td>
                            <td>open-ended hypothesis generation, mitigation of hallucination</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td>Not separately quantified; novelty implicitly assessed via human 'creativity' rubric score.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_score</strong></td>
                            <td>Not separately reported; overall aggregate quality depended weakly on context size without adversarial prompting, but improved strongly with adversarial prompting plus large context.</td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_metric</strong></td>
                            <td>Not separately quantified; feasibility assessed as human rubric subscore.</td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_score</strong></td>
                            <td>Not reported separately.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_evidence</strong></td>
                            <td>No explicit trade-off analysis. Paper reports that in-context prompting alone mitigated hallucination but did not by itself produce substantial quality gains; adversarial prompting was required to leverage large context for improved hypothesis quality.</td>
                        </tr>
                        <tr>
                            <td><strong>optimization_strategy</strong></td>
                            <td>Increasing amount of retrieved context (N_k) combined with contextual compression to fit context into the model, and coupling with adversarial iterations to refine outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation_results</strong></td>
                            <td>Without adversarial prompting, hypothesis quality showed little dependence on the number of papers; with adversarial prompting, quality correlated strongly with number of contextual papers (best at N=1000).</td>
                        </tr>
                        <tr>
                            <td><strong>comparative_baseline</strong></td>
                            <td>Smaller numbers of context papers (N_k) and no-adversary (nF=0).</td>
                        </tr>
                        <tr>
                            <td><strong>comparative_results</strong></td>
                            <td>In-context prompting alone (without adversary) did not substantially increase final human-evaluated quality, whereas in-context + adversarial did.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_findings</strong></td>
                            <td>In Galactic Astronomy, merely exposing GPT-4 to more papers via in-context prompting was insufficient; adversarial prompting was required for the model to synthesize across the broader literature effectively.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2278.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2278.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that automatically generate research hypotheses or research ideas, including how novelty and feasibility are measured, quantified, or traded off against each other.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Retrieval + LangChain</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Retrieval-augmented generation using LangChain + embeddings + contextual compression</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A retrieval pipeline that embeds document chunks, performs similarity search to retrieve relevant context, and compresses it to feed into GPT-4.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Retrieval + LangChain + text-ada-002 embeddings + contextual compression</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Papers are chunked and embedded with OpenAI text-ada-002. Query and chat history are embedded and used to perform similarity search in a vector database. LangChain's contextual compression filters irrelevant information from retrieved chunks to create a compact, relevant prompt for GPT-4. This retrieval augmentation supplies factual grounding to the generator to reduce hallucination and increase domain specificity.</td>
                        </tr>
                        <tr>
                            <td><strong>research_domain</strong></td>
                            <td>astronomy (used here), generalizable to other domains for retrieval-augmented language generation</td>
                        </tr>
                        <tr>
                            <td><strong>problem_type</strong></td>
                            <td>support for open-ended hypothesis generation (grounding, fact retrieval)</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_score</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_score</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_evidence</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimization_strategy</strong></td>
                            <td>Increase number of retrieved papers (N_k), use contextual compression to fit into model context window; combined with adversarial loop for refinement.</td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation_results</strong></td>
                            <td>Indirect: retrieval enabled reduction of hallucination and, when combined with adversarial prompting, contributed to higher human-evaluated hypothesis quality (best results at N=1000). No isolated ablation numeric for retrieval alone provided.</td>
                        </tr>
                        <tr>
                            <td><strong>comparative_baseline</strong></td>
                            <td>Smaller retrieval context sizes (N_k) and no compression; no explicit quantitative baseline beyond N_k ablation.</td>
                        </tr>
                        <tr>
                            <td><strong>comparative_results</strong></td>
                            <td>Larger retrieval context (N=1000) combined with adversarial prompting yielded the best human-evaluated quality; retrieval alone without adversarial prompting did not produce the same improvement.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_findings</strong></td>
                            <td>For Galactic Astronomy the curated ADS literature and good retrieval coverage helped the model avoid hallucination; however, retrieval must be coupled with adversarial prompting to translate raw context into coherent, high-quality hypotheses.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2278.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2278.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that automatically generate research hypotheses or research ideas, including how novelty and feasibility are measured, quantified, or traded off against each other.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-4 (OpenAI)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A large pre-trained transformer-based language model used here as generator, critic, and moderator in the hypothesis-generation pipeline.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A general-purpose LLM employed in three roles: (1) Generation GPT-4 (produces hypotheses from retrieved/compressed context), (2) Adversarial GPT-4 (critiques and identifies weaknesses and overlooked literature), and (3) Moderator GPT-4 (reformats critique into feedback/questions). The model operates with an ≈8,000 token context window in this work.</td>
                        </tr>
                        <tr>
                            <td><strong>research_domain</strong></td>
                            <td>used/demonstrated in astronomy (Galactic Astronomy); broadly applicable</td>
                        </tr>
                        <tr>
                            <td><strong>problem_type</strong></td>
                            <td>open-ended hypothesis generation, critique, and iterative refinement</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_score</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_score</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_evidence</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimization_strategy</strong></td>
                            <td>Used with retrieval-augmented context and adversarial prompting; no model fine-tuning (low-cost in-context approach favored over adapters/LoRA).</td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation_results</strong></td>
                            <td>Outputs from GPT-4 (with retrieval + adversarial prompting) were judged by two human experts; aggregate quality improved with context size + adversarial prompting (2.5→4/5). GPT-4 adversarial critiques were of high quality and occasionally rivaled expert human critique.</td>
                        </tr>
                        <tr>
                            <td><strong>comparative_baseline</strong></td>
                            <td>No-fine-tune baseline (naive LLM usage) and no-adversary (nF=0) condition; the paper contrasts in-context prompting with methods like adapters/LoRA in discussion but did not experimentally fine-tune.</td>
                        </tr>
                        <tr>
                            <td><strong>comparative_results</strong></td>
                            <td>In this setup, GPT-4 with retrieval + adversarial prompting outperformed GPT-4 with retrieval but no adversary; no numeric comparison to human-generated hypotheses was presented beyond the expert scoring rubric reference ('3/5 corresponds to a typical hypothesis by a competent PhD student').</td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_findings</strong></td>
                            <td>GPT-4 benefits markedly from curated domain context and adversarial prompting in producing astronomy hypotheses; adversarial critiques can reach expert-level quality when primed with relevant literature.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2278.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e2278.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that automatically generate research hypotheses or research ideas, including how novelty and feasibility are measured, quantified, or traded off against each other.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>IdeaGPT (repo)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>IdeaGPT (GitHub repository referenced)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A referenced GitHub repository (https://github.com/errai34/IdeaGPT) likely containing code or notebooks related to the hypothesis-generation workflow used in this study.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>IdeaGPT (codebase link)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A public codebase referenced by the authors as containing the full dataset and code used in their analysis, likely implementing parts of the retrieval, prompting, and adversarial pipeline (LangChain wrappers, prompt templates, iteration logic). The repository is mentioned but the paper does not describe its internal details.</td>
                        </tr>
                        <tr>
                            <td><strong>research_domain</strong></td>
                            <td>astronomy (implementation artifact), reproducibility / tooling for LLM-based idea generation</td>
                        </tr>
                        <tr>
                            <td><strong>problem_type</strong></td>
                            <td>tooling and workflow implementation for automated idea/hypothesis generation</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_score</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_score</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_evidence</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimization_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparative_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparative_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_findings</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Language models are few-shot learners <em>(Rating: 2)</em></li>
                <li>Chain of thought prompting elicits reasoning in large language models <em>(Rating: 2)</em></li>
                <li>Automatic chain of thought prompting in large language models <em>(Rating: 2)</em></li>
                <li>An explanation of in-context learning as implicit bayesian inference <em>(Rating: 2)</em></li>
                <li>Gpt-4 technical report <em>(Rating: 2)</em></li>
                <li>A feasibility study of answer-agnostic question generation for education <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2278",
    "paper_id": "paper-259202505",
    "extraction_schema_id": "extraction-schema-64",
    "extracted_data": [
        {
            "name_short": "Astro-GPT",
            "name_full": "Astro-GPT workflow (this paper)",
            "brief_description": "A pipeline that generates scientific hypotheses in Galactic Astronomy by combining retrieval-augmented in-context prompting of GPT-4 with iterative adversarial critique and moderated feedback to refine ideas.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Astro-GPT",
            "system_description": "An end-to-end LLM-based hypothesis-generation pipeline built in this study. Papers (N_k ∈ {1,10,100,1000}) are PDF-&gt;text processed, chunked (≈1,000 tokens), embedded with text-ada-002, and stored in a vector DB. Given a query/chat history the pipeline embeds the input, performs similarity search to retrieve relevant chunks, applies 'contextual compression' (filtering of irrelevant detail), and provides the compressed context + prompt to a GPT-4 'Generation' instance. The generation is followed by an 'Adversarial' GPT-4 critic and a third GPT-4 moderator that reformulates feedback into a question for the generator; this iterative adversarial cycle (nF iterations) refines hypotheses. Tools used: LangChain for retrieval and contextual compression, OpenAI embeddings (text-ada-002), GPT-4 for generation, critique, and moderation. Outputs are hypotheses and adversarial critiques; human experts evaluate final outputs.",
            "research_domain": "astronomy (Galactic Astronomy)",
            "problem_type": "open-ended exploration / interdisciplinary synthesis (generating novel research hypotheses from literature)",
            "novelty_metric": "Human-expert 'creativity' subscore within a 3-category rubric (scientific accuracy, creativity, feasibility), each scored on a 1–5 scale; final 'quality' is mean of the three subscores. No automated semantic-novelty metric (e.g., distance from literature embeddings) was reported as a numeric metric.",
            "novelty_score": "Not reported separately for 'creativity' alone; reported aggregate quality (mean of accuracy, creativity, feasibility) improved from 2.5/5 (context=10 papers) to ~4/5 (context=1000 papers with adversarial prompting).",
            "feasibility_metric": "Human-expert 'feasibility' subscore from the same 1–5 rubric (part of the 3-category evaluation). No automated feasibility probability or resource-estimate metric reported.",
            "feasibility_score": "Not reported separately for 'feasibility' alone; included in the aggregate quality score which improved from 2.5/5 to ~4/5 under larger context + adversarial prompting.",
            "tradeoff_evidence": "No explicit quantitative trade-off analysis between novelty and feasibility (e.g., correlations or Pareto front). Qualitatively, human-evaluated 'quality' (which averages creativity and feasibility) increased with adversarial prompting and larger context; the paper notes adversarial improvements tended to add technical detail rather than deep conceptual insight, but does not report a formal novelty-versus-feasibility trade-off metric.",
            "optimization_strategy": "Iterative adversarial refinement: generator -&gt; adversarial critic -&gt; moderator -&gt; feedback -&gt; generator; iteration count (nF) varied and shown to improve both quality and consistency. Retrieval of larger context (increasing N_k) is used in combination with adversarial iterations to improve outputs.",
            "human_evaluation": true,
            "human_evaluation_results": "Two domain experts scored hypotheses along three categories (scientific accuracy, creativity, feasibility) on a 1–5 scale; reported mean aggregate quality rose from 2.5/5 at N=10 (no/limited adversarial improvement) to ≈4/5 at N=1000 with adversarial prompting. 60 hypotheses and 40 critiques (for N=1000) were evaluated; adversarial prompting substantially improved quality and consistency. No per-category numeric breakdown (creativity vs feasibility) is provided in the paper text.",
            "comparative_baseline": "Ablations by context size (N_k = 1,10,100,1000) and by presence/absence of adversarial prompting (nF = 0 vs nF &gt; 0). The implicit baseline is in-context prompting without adversarial critique (nF=0) and/or smaller context sizes.",
            "comparative_results": "Without adversarial prompting (nF=0) hypothesis quality was stagnant even with large context. With adversarial prompting and large context (N=1000) mean quality rose to ≈4/5 from 2.5/5 (at N=10). No other baseline (e.g., human-only or different LLM) numerical comparisons provided.",
            "domain_specific_findings": "In Galactic Astronomy, access to a broad corpus (1000 papers) plus adversarial prompting enabled GPT-4 to 'connect the dots' across subfields and produce near-expert-level hypotheses; small corpora (10 papers) led to generic, incremental ideas. Adversarial prompting guided expansion of the model's 'knowledge footprint' across diverse subtopics (visualized via embeddings + t-SNE).",
            "uuid": "e2278.0"
        },
        {
            "name_short": "Adversarial prompting",
            "name_full": "Adversarial in-context prompting (iterative critique-feedback loop)",
            "brief_description": "A method where a generator LLM produces an idea, a separate LLM critic (adversary) critiques it, and a moderator reformulates feedback back to the generator; repeated iteratively to refine outputs.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "Adversarial prompting (generator–critic–moderator loop)",
            "system_description": "An LLM-based iterative refinement scheme: after initial hypothesis generation, a second LLM acts as an adversarial critic pointing out weaknesses and suggesting improvements; a third LLM moderates and reformulates the critique into constructive feedback/questions, which are returned to the generator. Iterations (nF) of this adversarial loop force the generator to expand scope, address overlooked evidence, and incorporate more specific technical detail.",
            "research_domain": "astronomy (demonstrated), general LLM-driven hypothesis generation applicable to other domains",
            "problem_type": "open-ended exploration and iterative refinement of ideas",
            "novelty_metric": "Implicitly measured via human 'creativity' scores in the study's rubric; no automated novelty metric tied specifically to adversarial prompting was reported.",
            "novelty_score": "Not separately reported for adversarial prompting alone; overall aggregate quality increased with adversarial iterations (no per-iteration numeric series reported in text).",
            "feasibility_metric": "Implicitly measured via human 'feasibility' scores in the rubric; adversarial critiques reportedly improved technical detail (which likely affected feasibility scores) but no automatic metric provided.",
            "feasibility_score": "Not separately reported.",
            "tradeoff_evidence": "No explicit quantitative evidence of a novelty vs feasibility trade-off. The paper notes adversarial prompting mostly improved technical detail (feasibility aspects) rather than deep conceptual novelty in some cases, but no formal trade-off analysis provided.",
            "optimization_strategy": "Iterative adversarial refinement (varying nF); combining adversarial iterations with larger retrieval context (N_k) to improve outputs.",
            "human_evaluation": true,
            "human_evaluation_results": "Adversarial prompting substantially improved human-judged quality and consistency of hypotheses; it introduced a strong correlation between number of contextual papers and hypothesis quality, and without it quality was stagnant.",
            "comparative_baseline": "No-adversary (nF=0) condition; smaller context sizes.",
            "comparative_results": "Adversarial prompting produced higher mean quality scores and more consistent critiques/generations compared to nF=0; exact numeric differences by nF are not provided except aggregate examples (2.5→4/5 when increasing context and using adversarial prompting).",
            "domain_specific_findings": "Adversarial prompting was essential for GPT-4 to effectively use a large corpus in Galactic Astronomy and to produce coherent, well-referenced hypotheses rather than fact-jumbles.",
            "uuid": "e2278.1"
        },
        {
            "name_short": "In-context prompting",
            "name_full": "In-context prompting with retrieval-augmented context",
            "brief_description": "Providing an LLM with task-specific examples or domain documents at inference time to steer its outputs without fine-tuning, here implemented with up to 1000 retrieved document chunks as context.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "In-context prompting (retrieval-augmented)",
            "system_description": "An LLM technique where relevant documents are retrieved from a corpus, compressed, and provided inline as context to GPT-4 so it can generate domain-specific hypotheses without fine-tuning. Implemented here with chunking of papers, embedding-based similarity search, and contextual compression to fit the model's input window (GPT-4 ~8k tokens in their setup).",
            "research_domain": "astronomy (demonstrated); applicable to domain-specific hypothesis generation generally",
            "problem_type": "open-ended hypothesis generation, mitigation of hallucination",
            "novelty_metric": "Not separately quantified; novelty implicitly assessed via human 'creativity' rubric score.",
            "novelty_score": "Not separately reported; overall aggregate quality depended weakly on context size without adversarial prompting, but improved strongly with adversarial prompting plus large context.",
            "feasibility_metric": "Not separately quantified; feasibility assessed as human rubric subscore.",
            "feasibility_score": "Not reported separately.",
            "tradeoff_evidence": "No explicit trade-off analysis. Paper reports that in-context prompting alone mitigated hallucination but did not by itself produce substantial quality gains; adversarial prompting was required to leverage large context for improved hypothesis quality.",
            "optimization_strategy": "Increasing amount of retrieved context (N_k) combined with contextual compression to fit context into the model, and coupling with adversarial iterations to refine outputs.",
            "human_evaluation": true,
            "human_evaluation_results": "Without adversarial prompting, hypothesis quality showed little dependence on the number of papers; with adversarial prompting, quality correlated strongly with number of contextual papers (best at N=1000).",
            "comparative_baseline": "Smaller numbers of context papers (N_k) and no-adversary (nF=0).",
            "comparative_results": "In-context prompting alone (without adversary) did not substantially increase final human-evaluated quality, whereas in-context + adversarial did.",
            "domain_specific_findings": "In Galactic Astronomy, merely exposing GPT-4 to more papers via in-context prompting was insufficient; adversarial prompting was required for the model to synthesize across the broader literature effectively.",
            "uuid": "e2278.2"
        },
        {
            "name_short": "Retrieval + LangChain",
            "name_full": "Retrieval-augmented generation using LangChain + embeddings + contextual compression",
            "brief_description": "A retrieval pipeline that embeds document chunks, performs similarity search to retrieve relevant context, and compresses it to feed into GPT-4.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "Retrieval + LangChain + text-ada-002 embeddings + contextual compression",
            "system_description": "Papers are chunked and embedded with OpenAI text-ada-002. Query and chat history are embedded and used to perform similarity search in a vector database. LangChain's contextual compression filters irrelevant information from retrieved chunks to create a compact, relevant prompt for GPT-4. This retrieval augmentation supplies factual grounding to the generator to reduce hallucination and increase domain specificity.",
            "research_domain": "astronomy (used here), generalizable to other domains for retrieval-augmented language generation",
            "problem_type": "support for open-ended hypothesis generation (grounding, fact retrieval)",
            "novelty_metric": null,
            "novelty_score": null,
            "feasibility_metric": null,
            "feasibility_score": null,
            "tradeoff_evidence": null,
            "optimization_strategy": "Increase number of retrieved papers (N_k), use contextual compression to fit into model context window; combined with adversarial loop for refinement.",
            "human_evaluation": true,
            "human_evaluation_results": "Indirect: retrieval enabled reduction of hallucination and, when combined with adversarial prompting, contributed to higher human-evaluated hypothesis quality (best results at N=1000). No isolated ablation numeric for retrieval alone provided.",
            "comparative_baseline": "Smaller retrieval context sizes (N_k) and no compression; no explicit quantitative baseline beyond N_k ablation.",
            "comparative_results": "Larger retrieval context (N=1000) combined with adversarial prompting yielded the best human-evaluated quality; retrieval alone without adversarial prompting did not produce the same improvement.",
            "domain_specific_findings": "For Galactic Astronomy the curated ADS literature and good retrieval coverage helped the model avoid hallucination; however, retrieval must be coupled with adversarial prompting to translate raw context into coherent, high-quality hypotheses.",
            "uuid": "e2278.3"
        },
        {
            "name_short": "GPT-4",
            "name_full": "GPT-4 (OpenAI)",
            "brief_description": "A large pre-trained transformer-based language model used here as generator, critic, and moderator in the hypothesis-generation pipeline.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "GPT-4",
            "system_description": "A general-purpose LLM employed in three roles: (1) Generation GPT-4 (produces hypotheses from retrieved/compressed context), (2) Adversarial GPT-4 (critiques and identifies weaknesses and overlooked literature), and (3) Moderator GPT-4 (reformats critique into feedback/questions). The model operates with an ≈8,000 token context window in this work.",
            "research_domain": "used/demonstrated in astronomy (Galactic Astronomy); broadly applicable",
            "problem_type": "open-ended hypothesis generation, critique, and iterative refinement",
            "novelty_metric": null,
            "novelty_score": null,
            "feasibility_metric": null,
            "feasibility_score": null,
            "tradeoff_evidence": null,
            "optimization_strategy": "Used with retrieval-augmented context and adversarial prompting; no model fine-tuning (low-cost in-context approach favored over adapters/LoRA).",
            "human_evaluation": true,
            "human_evaluation_results": "Outputs from GPT-4 (with retrieval + adversarial prompting) were judged by two human experts; aggregate quality improved with context size + adversarial prompting (2.5→4/5). GPT-4 adversarial critiques were of high quality and occasionally rivaled expert human critique.",
            "comparative_baseline": "No-fine-tune baseline (naive LLM usage) and no-adversary (nF=0) condition; the paper contrasts in-context prompting with methods like adapters/LoRA in discussion but did not experimentally fine-tune.",
            "comparative_results": "In this setup, GPT-4 with retrieval + adversarial prompting outperformed GPT-4 with retrieval but no adversary; no numeric comparison to human-generated hypotheses was presented beyond the expert scoring rubric reference ('3/5 corresponds to a typical hypothesis by a competent PhD student').",
            "domain_specific_findings": "GPT-4 benefits markedly from curated domain context and adversarial prompting in producing astronomy hypotheses; adversarial critiques can reach expert-level quality when primed with relevant literature.",
            "uuid": "e2278.4"
        },
        {
            "name_short": "IdeaGPT (repo)",
            "name_full": "IdeaGPT (GitHub repository referenced)",
            "brief_description": "A referenced GitHub repository (https://github.com/errai34/IdeaGPT) likely containing code or notebooks related to the hypothesis-generation workflow used in this study.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "IdeaGPT (codebase link)",
            "system_description": "A public codebase referenced by the authors as containing the full dataset and code used in their analysis, likely implementing parts of the retrieval, prompting, and adversarial pipeline (LangChain wrappers, prompt templates, iteration logic). The repository is mentioned but the paper does not describe its internal details.",
            "research_domain": "astronomy (implementation artifact), reproducibility / tooling for LLM-based idea generation",
            "problem_type": "tooling and workflow implementation for automated idea/hypothesis generation",
            "novelty_metric": null,
            "novelty_score": null,
            "feasibility_metric": null,
            "feasibility_score": null,
            "tradeoff_evidence": null,
            "optimization_strategy": null,
            "human_evaluation": null,
            "human_evaluation_results": null,
            "comparative_baseline": null,
            "comparative_results": null,
            "domain_specific_findings": null,
            "uuid": "e2278.5"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Language models are few-shot learners",
            "rating": 2,
            "sanitized_title": "language_models_are_fewshot_learners"
        },
        {
            "paper_title": "Chain of thought prompting elicits reasoning in large language models",
            "rating": 2,
            "sanitized_title": "chain_of_thought_prompting_elicits_reasoning_in_large_language_models"
        },
        {
            "paper_title": "Automatic chain of thought prompting in large language models",
            "rating": 2,
            "sanitized_title": "automatic_chain_of_thought_prompting_in_large_language_models"
        },
        {
            "paper_title": "An explanation of in-context learning as implicit bayesian inference",
            "rating": 2,
            "sanitized_title": "an_explanation_of_incontext_learning_as_implicit_bayesian_inference"
        },
        {
            "paper_title": "Gpt-4 technical report",
            "rating": 2,
            "sanitized_title": "gpt4_technical_report"
        },
        {
            "paper_title": "A feasibility study of answer-agnostic question generation for education",
            "rating": 1,
            "sanitized_title": "a_feasibility_study_of_answeragnostic_question_generation_for_education"
        }
    ],
    "cost": 0.014474499999999998,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Harnessing the Power of Adversarial Prompting and Large Language Models for Robust Hypothesis Generation in Astronomy</p>
<p>Ioana Ciucȃ 
Yuan-Sen Ting 
Sandor Kruk 
Kartheik Iyer 
Harnessing the Power of Adversarial Prompting and Large Language Models for Robust Hypothesis Generation in Astronomy</p>
<p>This study investigates the application of Large Language Models (LLMs), specifically GPT-4, within Astronomy. We employ in-context prompting, supplying the model with up to 1000 papers from the NASA Astrophysics Data System, to explore the extent to which performance can be improved by immersing the model in domainspecific literature. Our findings point towards a substantial boost in hypothesis generation when using in-context prompting, a benefit that is further accentuated by adversarial prompting. We illustrate how adversarial prompting empowers GPT-4 to extract essential details from a vast knowledge base to produce meaningful hypotheses, signaling an innovative step towards employing LLMs for scientific research in Astronomy.</p>
<p>Introduction</p>
<p>Significant strides in Natural Language Processing (NLP) have been made possible through attention mechanisms and transformer architecture, leading to the development of Large Language Models (LLMs) such as GPT-4 (Vig, 2019;Brown et al., 2020;Ouyang et al., 2022). These models exhibit extraordinary aptitude in understanding, generating, and interacting with human language. They go beyond deciphering complex linguistic patterns to making non-trivial deductions and forming relationships across diverse contexts (e.g., Devlin et al., 2018;Elkins &amp; Chun, 2020).</p>
<p>Two intriguing facets of these models have stirred excite-Proceedings of the 40 th International Conference on Machine Learning, Honolulu, Hawaii, USA. PMLR 202, 2023. Copyright 2023 by the author(s). ment for their potential that surpasses their initial intended applications. Firstly, despite LLMs' propensity to sample posterior means of languages-a factor that can occasionally result in non-trivial hallucination problems-improved performance has been witnessed through in-context prompting Wei et al., 2022;Zhang et al., 2022). This enhancement enables them to handle complex, domain-specific tasks (e.g., Radford &amp; Narasimhan, 2018;Brown et al., 2020;Lu et al., 2022). Secondly, these models, when combined with revolutionary technologies like Langchain 1 to provide extensive context to the LLMs, expand their functionality across a wide range of fields.</p>
<p>While methods like the use of adapters Karimi Mahabadi et al., 2021;Hu et al., 2021) can remarkably augment performance for domain-specific tasks through fine-tuning the LLMs, these approaches often prove challenging for institutions without sufficient resources. In this study, we delve into the application of low-cost incontext prompting Xie et al., 2021) in the realm of astronomy.</p>
<p>Astronomy offers a compelling case study due to three key reasons. Firstly, although the field is rich in literature, the inclusion of such text in the vast corpus used to train GPT models is probably limited. This lack leads to noticeable hallucination problems when employing naive versions of LLMs (Ciucȃ et al., 2023). Secondly, unlike domains that focus more on intensive, detailed studies, advancements in astronomy often stem from "connecting the dots" across different subfields due to the universality of underlying physical processes at various scales. This feature fosters the hypothesis that extensive in-context prompting could significantly enhance hypothesis generation if LLMs are initially exposed to a broad range of literature.</p>
<p>Lastly, astronomy's longstanding "open sky" policy makes it an ideal candidate for in-context prompting research. This policy ensures that most data sets are publicly available immediately or after a short proprietary period (Almeida et al., 2023;Fabricius et al., 2021). Further, the field possesses a comprehensive, well-curated literature database. The internet has enabled the archiving of astronomical knowledge, Figure 1. This figure illustrates the adversarial in-context prompting workflow using OpenAI's GPT-4 model. The procedure begins with the pre-processing and embedding of Galactic Astronomy papers. A similarity search is conducted on the embedded query, and relevant document chunks are retrieved. A further contextual compression is performed to remove irrelevant information from the chunks. These compressed texts serve as input to a GPT-4 instance, which generates an idea. This idea is then critiqued by a second GPT-4 model, and the feedback is moderated by a third GPT-4 model. with NASA's Astrophysics Data System hosting over 15 million resources, effectively covering the entire spectrum of astronomical literature utilized by researchers (Accomazzi et al., 2015;Borgman &amp; Wofford, 2021). This accessibility greatly aids our engagement with the astronomy database.</p>
<p>Literature retrieval and pre-processing</p>
<p>For this study, we focused our exploration on Galactic Astronomy, utilizing our domain expertise to assess the results. We selected Galactic Astronomy as our focal area due to its integrative nature, fusing knowledge from diverse subfields. The study of galaxy evolution not only incorporates the fundamental understanding of stars and stellar populations (Aouad et al., 2020;Sánchez et al., 2022) but it is also influenced by large-scale cosmological environmental factors (Singh et al., 2020;Whitney et al., 2021). Therefore, studying galaxy evolution provides both exciting challenges and abundant possibilities for harnessing implicit knowledge embedded within the vast network of literature.</p>
<p>Our study includes a selection of 1,000 papers related to Galactic Astronomy from the NASA ADS (Accomazzi et al., 2015) Astronomy collection. Our chosen papers were identified through a database query based on criteria such as 'Gaia' appearing in the abstract, publications from the last ten years (since the Gaia launch date), being refereed journal articles, and the inclusion of relevant keywords such as 'galaxy kinematics and dynamics', 'galaxy structure', 'galaxy disk', 'galaxy halo', 'galaxy abundances', and 'galaxy evolution'. Our initial query yielded more than 1,000 papers, leading us to prioritize the most recent publications. Our curated collection contains details such as the ArxivID, Publication Date, Authors, Title, Abstract, Citation, and Key, providing a comprehensive dataset for our analysis. The full dataset as well as the codebase used in our analysis can be found here for reproducibility 2 .</p>
<p>Astro-GPT Workflow</p>
<p>Our exploration capitalizes on the abilities of OpenAI's GPT-4 model (OpenAI, 2023). The first step in in-context prompting involves pre-processing 1,000 papers from the Galactic Astronomy corpus using the langchain library. Each paper, transformed from PDF to text, is subsequently segmented into 'chunks' of 1,000 tokens each. These segmented units are then embedded using OpenAI's text-ada-002 embedding model.</p>
<p>The retrieval phase begins with converting the chat history and input query into a standalone input, which is then embedded. A similarity search is conducted between the embedded query and the vector database. We then use langchain's contextual compression to filter out irrelevant information from the individual chunks. These final texts, combined with the standalone input, form the foundation upon which a GPT-4 model, having a context window of approximately 8,000 tokens, formulates ideas. To scrutinize the model's prowess, we design an adversarial experiment. This involves a secondary GPT-4 model that critiques the idea, highlighting its frailties and suggesting potential enhancements. This feedback is reformulated within a feedback-question structure by a third GPT-4 instance and returned to the initial model. Figure 2. Adversarial prompting and domain-specific context enrichment significantly enhance hypothesis generation quality. 60 hypotheses and 40 critiques generated by the AI were evaluated by two human experts, with the mean scores reported for individual instances. The iterations of adversarial prompting (nF ) was instrumental in driving substantial enhancements in both the quality and consistency of the AI judge and AI generator outputs, particularly when they were supplied with an extensive context (N = 1000 papers). Crucially, in the absence of adversarial prompting (nF = 0), the quality of the hypothesis remained stagnant despite the provision of ample context. This observation underscores the stark contrast and superior effectiveness of adversarial prompting. Implementing our experimental setup, we use N k papers, where k ∈ {1, 10, 100, 1000}. Each sample undergoes hypothesis generation by the 'Generation GPT-4' instance (our in-context prompted model on k papers). An adversarial response from 'Adversarial GPT-4' follows, which is reformulated by a moderator GPT-4 instance and fed back to the generator model. This cycle, yielding three hypotheses and two critiques per experiment, is repeated twice for each N k and replicated five times in total. The same approach is applied to 1,000 papers, without resampling, accumulating a total of 60 hypotheses and 40 critiques.</p>
<p>Results</p>
<p>Human Evaluation</p>
<p>Given the qualitative nature of hypothesis generation, we needed an assessment process that, while inherently subjective, would match the expectations of human experts. For this, we involved two domain experts in the field of Galactic Astronomy to evaluate the quality of the generated hypotheses. These were graded based on the number of papers included within the domain-specific context, and we computed the average score from these dual-human evaluations for each hypothesis. The hypotheses are graded based on a rubric of three categories -scientific accuracy, creativity and feasibility, and the average score of these three domains assumed to be the final score. We also evaluated the critiques provided by the AI judge, which had access to the same contextual information.</p>
<p>As illustrated in the left panel of Fig. 2, adversarial prompting proved to be a critical tool in markedly improving hypothesis generation. The quality of hypothesis generation, without adversarial prompting, showed little dependence on the number of papers, suggesting that in-context prompting alone, while helpful for mitigating hallucination, did not suffice for a comprehensive understanding of the corpus.</p>
<p>The introduction of adversarial prompting considerably altered this outcome. A significant improvement in the quality of hypothesis generation was observed both for the AI generator and the AI judge, even without explicitly aligning the models with human expectations. Notably, adversarial prompting introduced a strong correlation between hypothesis quality and the number of papers reviewed, especially at larger context (N = 1000). It also leads to a much more consistent in term of the quality of the hypotheses (and the critiques). The average quality score rose significantly from 2.5 (when 10 papers were used as context, where a score of 3/5 corresponds to a typical hypothesis by a competent PhD student) to a near-expert level of 4/5 when 1,000 papers were included, emphasizing the potential of adversarial prompting in enhancing the quality of scientific hypothesis generation. We refer to the Appendix for examples.</p>
<p>Exploration of Embeddings</p>
<p>To truly understand the power of adversarial prompting, we first passed the abstracts of our set of 1000 astronomy papers through the text-ada-002 embedding model and arranged them into a 2D TSNE projection. This captured the contextual differences and similarities of these 1000 papers.</p>
<p>For each hypothesis generated, we determined which papers inspired it by querying the GPT model. In Fig. 3, we visualized this 'knowledge footprint' for each hypothesis as black polygons within a green hull representing all the papers GPT-4 had access to. From Fig. 3's top panels, it's clear that as the number of papers grows, GPT broadens its scope, drawing on diverse topics to build interconnected hypotheses. We note that, even with a small training pool of 10 papers, we design our experiment in a way that the corpus still covers a wide range of topics, but GPT-4 lacks the context to connect them in a meaningful way, leading to more general hypotheses (see Appendix).</p>
<p>The bottom panel in Fig. 3, concentrating on the case with 1000 papers, explores how the knowledge footprint evolves with different numbers of adversarial attacks. In the preliminary iteration (bottom left), the judge ingeniously identifies areas of critique based on knowledge overlooked by the original response. This compels the generator to expand its scope further (as shown in the bottom middle and right panels), to appropriately address the criticism. As shown in some of the examples in the Appendix, adversarial prompting allows the GPT-4 model to genuinely benefit from a large number of contextual inputs, guiding the model towards a more coherent understanding of the topic, rather than creating a mere 'fact jumble'. The specific examples of hypotheses and corresponding critiques are shown in the Appendix.</p>
<p>Conclusion and Future Direction</p>
<p>In this research, we delved into a detailed examination of the GPT-4 model's ability to propose novel hypotheses in the domain of Galactic Astronomy using in-context prompting. Our findings confirm that in-context prompting significantly mitigates hallucination, leading to the generation of meaningful hypotheses that can compete with substantive thesis topics, as evaluated by domain experts. Importantly, we found that the inclusion of adversarial prompts enables the model to progressively enhance its performance based on the number of contextual papers. However, a naive implementation of in-context prompting without adversarial judgment fails to replicate this improvement.</p>
<p>While our study marks the inception of a pioneering exploration of in-context prompting for scientific hypothesis generation, it's clear that this dynamic field is rapidly evolving. Thus, we have identified several crucial areas for enhancement. These areas include (a) an improved and automated evaluation method for hypotheses. We have observed that while the AI judge can assist the AI generator, improvements are primarily in technical detail rather than deep insights. We propose leveraging well-curated question-and-answer pairs (e.g. Dugan et al., 2022) to better align the judge with human expectations. (b) Instead of focusing solely on hypothesis generation, integrating other downstream tasks and finite fine-tuning models with smaller adapter models could potentially improve inferences. We have commenced curating metadata from ADS to better design these tasks.</p>
<p>Broader Impact</p>
<p>In this study, our focus on in-context prompting, rather than the more computationally intensive fine-tuning, is inspired by the aim to democratize the utilization of LLMs for scientific inquiry. Current GPT models, due to their immense parameter sets, often render fine-tuning impractical. In the era of Large Language Models, it is crucial to determine whether all academic institutions, regardless of size or available computational resources, can keep pace with these rapidly advancing technologies.</p>
<p>This critical inquiry forms the crux of our study, and our findings present a hopeful outlook. Our study indicates that, with the right strategies and approaches with 'humans in the loop' as domain experts, the barrier to harnessing the full power of these advanced LLMs can be lowered. As a result, we envision a future where all institutions, regardless of size or resources, can contribute to and benefit from the swift advancements in AI, enhancing the collective endeavour of scientific discovery. Our journey into this new frontier of Large Language Models is just beginning, and it promises a thrilling ride full of unexpected insights and revolutionary breakthroughs.</p>
<p>A. Exemplary Hypotheses and Critiques Generated</p>
<p>This section presents three types of hypotheses generated through our in-context prompting and adversarial prompting techniques, along with the associated critiques provided by our adversarial GPT-4 model, which led to substantial improvements in hypothesis generation.</p>
<p>The first example demonstrates a hypothesis generated after subjecting the model to in-context prompting through 1000 papers, followed by two rounds of adversarial attacks.</p>
<p>I propose an investigation into the role of dark matter mini-halos in the formation and evolution of globular clusters (GCs) in the Milky Way. This study would combine the high-precision astrometric data from Gaia EDR3 and DR3 (Gaia Collaboration et al. 2016 with spectroscopic data from large ground-based surveys like APOGEE, GALAH, SDSS SEGUE, and LAMOST to characterize the dynamics of stars in the peripheral regions of GCs. The aim would be to determine whether these GCs are embedded in dark matter mini-halos, which could provide critical insights into their origins (Peebles 1984;Peñarrubia et al. 2017). The proposed research would build upon the probabilistic approach developed by Kuzma et al. (2021) for studying the peripheral regions of GCs, which utilizes a mixture model in spatial and proper motion space to model cluster, extra-tidal, and contaminant stellar populations. By extending this approach to include the effects of dark matter mini-halos on the kinematics of stars in GC outskirts, we can test the hypothesis that dark matter plays a significant role in the formation and evolution of GCs. Furthermore, this study would provide a better understanding of the distribution and properties of dark matter in the Milky Way, contributing to the broader field of near-field cosmology. Integrating this information with the existing knowledge of the hierarchical assembly of the Milky Way (Viswanathan et al. 2023) and the role of rapid gas accretion in the inner Galactic disc (Snaith et al. 2021) would help paint a more comprehensive picture of our Galaxy's formation history and its underlying dark matter distribution.</p>
<p>This hypothesis received high approval from the human jury due to its broad contextual understanding of Galactic Astronomy, a concrete thesis proposal, appropriate references for idea origins, and building upon existing methodologies and studies.</p>
<p>Conversely, the following hypothesis was produced when the in-context prompting was restricted to 10 papers. Hypotheses based on limited exposure to literature often appear generic, lacking substantial insights beyond minor improvements to existing work.</p>
<p>I propose a study investigating the role of intermediate-mass gas-rich mergers in the chemical and kinematic evolution of the Milky Way-like galaxies across a range of redshifts. This research would build upon the findings of Ciucȃ et al. (2023), which suggest that the Gaia-Sausage-Enceladus (GSE) merger significantly impacted the formation of the Galactic disc and the transition from the thick disc to the thin disc. The study could involve a combination of observational data from large spectroscopic surveys such as APOGEE, GALAH, and Gaia-ESO, as well as the utilization of high-resolution cosmological simulations like the Auriga project. Key objectives would include characterizing the chemical abundance patterns and kinematic properties of stars in the disc and halo components during and after the mergers and probing the impact of these mergers on the radial distribution and migration of stars across the Galactic disc. By focusing on intermediate-mass gas-rich mergers, this research would fill a knowledge gap in our understanding of the role these events play in shaping the structure and evolution of Milky Way-like galaxies. The findings would also provide valuable insights for refining galaxy formation models and contribute to a more comprehensive understanding of the complex history of our Galaxy.</p>
<p>Without sufficient context, the model tends to extrapolate based on existing literature, resulting in incremental, less innovative suggestions.</p>
<p>Importantly, despite the exposure to a corpus of 1000 papers, without adversarial attacks, the hypotheses can often seem like a jumble of facts, as shown in the example below: I propose a comprehensive, multi-wavelength exploration of the uncharted regions of the Galactic plane, particularly in the South Galactic cap, including areas below a declination of -65°. This astronomical research initiative can be achieved by combining existing large photometric, spectroscopic, and astrometric surveys, such as Gaia, LAMOST, APOGEE, and GALAH, with new high-resolution surveys aimed at mapping the uncovered areas of the Milky Way. This undertaking should prioritize the detection and characterization of previously undiscovered ultra-faint dwarf galaxies, chemically peculiar stars, and stellar streams, as well as the evaluation of their origins and potential implications for our understanding of the Milky Way's formation and evolution. This research proposal is inspired by the unexplored regions mentioned in Antoja et al. (2015), along with the possibilities for improvement suggested by Gorski and Barmby (2020) and the advancements in large-scale surveys discussed in studies such as Yuan et al. (2014) and An and Beers (2020). Expanding our knowledge of the uncharted regions of the Galactic plane will significantly contribute to our understanding of the structure, formation, and evolution of the Milky Way. Additionally, it will allow astronomers to identify and assess previously unknown populations of stars and their kinematic properties, further refining our knowledge of the various components and phenomena that shape our Galaxy.</p>
<p>Demonstrating adversarial prompting is critical to ensure that the GPT can harness the broad context provided in a meaningful way.</p>
<p>Finally, an example of high-quality critique provided by the adversarial GPT-4 model is showcased. These adversarial critiques, after being primed with 1000 papers, are highly accurate and can rival the quality of expert human critique.</p>
<p>The interdisciplinary approach proposed aims to provide a comprehensive understanding of the Milky Way's gravitational potential by combining photometric data, high-resolution simulations, and novel techniques to analyze phase-space spirals. However, there are several weaknesses and limitations to consider. First, the proposal relies heavily on photometric data, which, although less affected by sampling biases, may still be prone to uncertainties due to dust obscuration and crowding (Rix and Bovy 2013). Additionally, the accuracy of photometric metallicity measurements may be limited compared to spectroscopic data (An and Beers 2021). Second, while high-resolution simulations may enable better modeling of the Milky Way's potential, they are computationally expensive, and current mass and spatial resolutions may not be sufficient for accurate analysis (Darling and Widrow 2018). Furthermore, the complexity of the Milky Way, including its non-steady-state nature and the presence of various structures such as spiral arms and bars, adds challenges to the modeling process (Kipper et al. 2018). Third, novel techniques to analyze phase-space spirals may be subject to different sources of systematic bias (Widmark et al. 2021). The proposal does not fully address how these biases will be accounted for or the potential limitations of these techniques in the context of a complex and evolving galaxy. Lastly, the proposal does not extensively discuss the implications of various selection biases in spectroscopic surveys (Sanders and Das 2018), nor the challenges in incorporating the complexity of our galaxy in large-scale cosmological models (Everall et al. 2021c). In conclusion, while the interdisciplinary approach has merits, further work is needed to address these weaknesses and limitations for a more accurate and comprehensive understanding of the Milky Way's gravitational potential.</p>
<p>Figure 3 .
3Visual representation of each hypothesis's 'knowledge footprint', depicted as black polygons within the TSNE projection of the abstracts of our corpus comprising 1000 papers. As the quantity of papers consumed increases, the model leverages a more diverse array of topics, thus boosting the quality of the hypothesis (as seen in the top panels). The green hull in the top panel shows the overall knowledge base that the model have access through in-context prompting. The lower panel demonstrates how the 'knowledge footprint' evolves with varying quantities nF of adversarial attacks in the case of 1000 papers. The black polygon signifies the footprint of the original response, while the lime indicates the information utilized by the AI judge for critique.
https://python.langchain.com
https://github.com/errai34/IdeaGPT</p>
<p>Open Science at the Frontiers of Librarianship. A Accomazzi, M J Kurtz, E A Henneken, R Chyla, J Luker, C S Grant, D M Thompson, A Holachek, R Dave, S S Murray, 10.48550/arXiv.1503.04194Astronomical Society of the Pacific Conference Series. Holl, A., Lesteven, S., Dietrich, D., and Gasperini, A.492189ADS: The Next Generation Search PlatformAccomazzi, A., Kurtz, M. J., Henneken, E. A., Chyla, R., Luker, J., Grant, C. S., Thompson, D. M., Holachek, A., Dave, R., and Murray, S. S. ADS: The Next Generation Search Platform. In Holl, A., Lesteven, S., Dietrich, D., and Gasperini, A. (eds.), Open Science at the Frontiers of Librarianship, volume 492 of Astronomical Society of the Pacific Conference Series, pp. 189, April 2015. doi: 10.48550/arXiv.1503.04194.</p>
<p>. A Almeida, S F Anderson, M Argudo-Fernández, C Badenes, K Barger, J K Barrera-Ballesteros, C F Bender, E Benitez, F Besser, D Bizyaev, M R Blanton, J Bochanski, J Bovy, W N Brandt, J R Brownstein, J Buchner, E Bulbul, J N Burchett, M C Díaz, J K Carlberg, A R Casey, V Chandra, B Cherinka, C Chiappini, A A Coker, J Comparat, C Conroy, G Contardo, A Cortes, K Covey, J D Crane, K Cunha, C Dabbieri, J W D J Davis, M C Lee, N D Delgado, J E M Demasi, S Mille, F D Donor, J Dow, P Dwelly, T Eracleous, M Eriksen, J Fan, X Farr, E Frederick, S Fries, L Frinchaboy, P Gaensicke, B T Ge, J Ávila, C G Grabowski, K Grier, C Guiglion, G Gupta, P Hall, P Hawkins, K Hayes, C R Hermes, J J Hernández-García, L Hogg, D W Holtzman, J A Ibarra-Medel, H J Ji, A Jofre, P Johnson, J A Jones, A M Kinemuchi, K Kluge, M Koekemoer, A Kollmeier, J A Kounkel, M Krishnarao, D Krumpe, M Lacerna, I Lago, P J A Laporte, C Liu, A Liu, C Liu, X Lopes, A R Macktoobian, M Malanushenko, V Maoz, D Masseron, T Masters, K L Matijevic, G Mcbride, A Medan, I Merloni, A Morrison, S Myers, N Mészáros, S Negrete, C A Nidever, D L Nitschelm, C Oravetz, A Oravetz, D Pan, K Peng, Y Pinsonneault, M H Pogge, R Qiu, D De Andrade Queiroz, A B Ramirez, S V Rix, H.-W Rosso, D F Runnoe, J Salvato, M Sanchez, S F Santana, F A Saydjari, A Sayres, C Schlaufman, K C Schneider, D P Schwope, A Serna, J Shen, Y Sobeck, J Song, Y.-Y Souto, D Spoo, T Stassun, K G Steinmetz, M Straumit, I Stringfellow, G Sánchez-Gallego, J Taghizadeh-Popp, M Tayar, J Thakar, A Tissera, P B Tkachenko, A Toledo, H H Trakhtenbrot, B Trincado, J G F Troup, N Trump, J R Tuttle, S Ulloa, N Vazquez-Mata, J A Alfaro, P V Villanova, S Wachter, S Weijmans, A.-M Wheeler, A Wilson, J Wojno, L Wolf, J Xue, X.-X Ybarra, J E Zari, E Zasowski, G , The eighteenth data release of the sloan digital sky surveys: Targeting and first spectra from sdss-vAlmeida, A., Anderson, S. F., Argudo-Fernández, M., Badenes, C., Barger, K., Barrera-Ballesteros, J. K., Ben- der, C. F., Benitez, E., Besser, F., Bizyaev, D., Blanton, M. R., Bochanski, J., Bovy, J., Brandt, W. N., Brownstein, J. R., Buchner, J., Bulbul, E., Burchett, J. N., Díaz, M. C., Carlberg, J. K., Casey, A. R., Chandra, V., Cherinka, B., Chiappini, C., Coker, A. A., Comparat, J., Conroy, C., Contardo, G., Cortes, A., Covey, K., Crane, J. D., Cunha, K., Dabbieri, C., au2, J. W. D. J., Davis, M. C., Lee, N. D., Delgado, J. E. M., Demasi, S., Mille, F. D., Donor, J., Dow, P., Dwelly, T., Eracleous, M., Eriksen, J., Fan, X., Farr, E., Frederick, S., Fries, L., Frinchaboy, P., Gaensicke, B. T., Ge, J.,Ávila, C. G., Grabowski, K., Grier, C., Guiglion, G., Gupta, P., Hall, P., Hawkins, K., Hayes, C. R., Hermes, J. J., Hernández-García, L., Hogg, D. W., Holtzman, J. A., Ibarra-Medel, H. J., Ji, A., Jofre, P., Johnson, J. A., Jones, A. M., Kinemuchi, K., Kluge, M., Koekemoer, A., Kollmeier, J. A., Kounkel, M., Krishnarao, D., Krumpe, M., Lacerna, I., Lago, P. J. A., Laporte, C., Liu, A., Liu, C., Liu, X., Lopes, A. R., Mack- toobian, M., Malanushenko, V., Maoz, D., Masseron, T., Masters, K. L., Matijevic, G., McBride, A., Medan, I., Merloni, A., Morrison, S., Myers, N., Mészáros, S., Negrete, C. A., Nidever, D. L., Nitschelm, C., Oravetz, A., Oravetz, D., Pan, K., Peng, Y., Pinsonneault, M. H., Pogge, R., Qiu, D., de Andrade Queiroz, A. B., Ramirez, S. V., Rix, H.-W., Rosso, D. F., Runnoe, J., Salvato, M., Sanchez, S. F., Santana, F. A., Saydjari, A., Sayres, C., Schlaufman, K. C., Schneider, D. P., Schwope, A., Serna, J., Shen, Y., Sobeck, J., Song, Y.-Y., Souto, D., Spoo, T., Stassun, K. G., Steinmetz, M., Straumit, I., Stringfellow, G., Sánchez-Gallego, J., Taghizadeh-Popp, M., Tayar, J., Thakar, A., Tissera, P. B., Tkachenko, A., Toledo, H. H., Trakhtenbrot, B., Trincado, J. G. F., Troup, N., Trump, J. R., Tuttle, S., Ulloa, N., Vazquez-Mata, J. A., Alfaro, P. V., Villanova, S., Wachter, S., Weijmans, A.-M., Wheeler, A., Wilson, J., Wojno, L., Wolf, J., Xue, X.-X., Ybarra, J. E., Zari, E., and Zasowski, G. The eighteenth data release of the sloan digital sky surveys: Targeting and first spectra from sdss-v, 2023.</p>
<p>Coupling local to global star formation in spiral galaxies: the effect of differential rotation. C J Aouad, P A James, I V Chilingarian, 10.1093/mnras/staa1945Monthly Notices of the Royal Astronomical Society. 4964Aouad, C. J., James, P. A., and Chilingarian, I. V. Coupling local to global star formation in spiral galaxies: the effect of differential rotation. Monthly Notices of the Royal Astronomical Society, 496(4):5211-5226, jul 2020. doi: 10.1093/mnras/staa1945.</p>
<p>C L Borgman, M F Wofford, 10.48550/arXiv.2109.01707arXiv:2109.01707From Data Processes to Data Products: Knowledge Infrastructures in Astronomy. arXiv e-prints, art. Borgman, C. L. and Wofford, M. F. From Data Processes to Data Products: Knowledge Infrastructures in Astronomy. arXiv e-prints, art. arXiv:2109.01707, September 2021. doi: 10.48550/arXiv.2109.01707.</p>
<p>. T B Brown, B Mann, N Ryder, M Subbiah, J Kaplan, P Dhariwal, A Neelakantan, P Shyam, G Sastry, A Askell, S Agarwal, A Herbert-Voss, G Krueger, T Henighan, R Child, A Ramesh, D M Ziegler, J Wu, C Winter, C Hesse, M Chen, E Sigler, M Litwin, S Gray, B Chess, J Clark, C Berner, S Mccandlish, A Radford, I Sutskever, Amodei , D , Language models are few-shot learnersBrown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert-Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D. M., Wu, J., Winter, C., Hesse, C., Chen, M., Sigler, E., Litwin, M., Gray, S., Chess, B., Clark, J., Berner, C., McCandlish, S., Radford, A., Sutskever, I., and Amodei, D. Language models are few-shot learners, 2020.</p>
<p>Y Chen, R Zhong, S Zha, G Karypis, H He, arXiv:2110.07814Metalearning via language model in-context tuning. arXiv preprintChen, Y., Zhong, R., Zha, S., Karypis, G., and He, H. Meta- learning via language model in-context tuning. arXiv preprint arXiv:2110.07814, 2021.</p>
<p>Chasing the impact of the Gaia-Sausage-Enceladus merger on the formation of the Milky Way thick disc. I Ciucȃ, D Kawata, Y.-S Ting, R J J Grand, A Miglio, M Hayden, J Baba, F Fragkoudi, S Monty, S Buder, Freeman , K , 10.1093/mnrasl/slad033Monthly Notices of the Royal Astronomical Society. Ciucȃ, I., Kawata, D., Ting, Y.-S., Grand, R. J. J., Miglio, A., Hayden, M., Baba, J., Fragkoudi, F., Monty, S., Buder, S., and Freeman, K. Chasing the impact of the Gaia-Sausage- Enceladus merger on the formation of the Milky Way thick disc. Monthly Notices of the Royal Astronomical Society, March 2023. doi: 10.1093/mnrasl/slad033.</p>
<p>J Devlin, M.-W Chang, K Lee, K Toutanova, Bert, 10.48550/arXiv.1810.04805arXiv:1810.04805Pre-training of Deep Bidirectional Transformers for Language Understanding. arXiv e-prints, art. Devlin, J., Chang, M.-W., Lee, K., and Toutanova, K. BERT: Pre-training of Deep Bidirectional Transform- ers for Language Understanding. arXiv e-prints, art. arXiv:1810.04805, October 2018. doi: 10.48550/arXiv. 1810.04805.</p>
<p>A feasibility study of answer-agnostic question generation for education. L Dugan, E Miltsakaki, S Upadhyay, E Ginsberg, H Gonzalez, D Choi, C Yuan, C Callison-Burch, 10.18653/v1/2022.findings-acl.151Findings of the Association for Computational Linguistics: ACL 2022. Dublin, IrelandAssociation for Computational LinguisticsDugan, L., Miltsakaki, E., Upadhyay, S., Ginsberg, E., Gon- zalez, H., Choi, D., Yuan, C., and Callison-Burch, C. A feasibility study of answer-agnostic question generation for education. In Findings of the Association for Compu- tational Linguistics: ACL 2022, pp. 1919-1926, Dublin, Ireland, May 2022. Association for Computational Lin- guistics. doi: 10.18653/v1/2022.findings-acl.151.</p>
<p>Can gpt-3 pass a writer's turing test. K Elkins, J Chun, Journal of Cultural Analytics. 522020Elkins, K. and Chun, J. Can gpt-3 pass a writer's turing test? Journal of Cultural Analytics, 5(2), 2020.</p>
<p>. C Fabricius, X Luri, F Arenou, C Babusiaux, A Helmi, T Muraveva, C Reylé, F Spoto, A Vallenari, T Antoja, E Balbinot, C Barache, N Bauchet, A Bragaglia, D Busonero, T Cantat-Gaudin, J M Carrasco, S Diakité, M Fabrizio, F Figueras, A Garcia-Gutierrez, A Garofalo, C Jordi, P Kervella, S Khanna, N Leclerc, E Licata, S Lambert, P M Marrese, A Masip, P Ramos, N Robichon, A C Robin, M Romero-Gómez, S Rubele, Weiler , 10.1051/0004-6361/202039834Astronomy &amp;amp. 6495AstrophysicsFabricius, C., Luri, X., Arenou, F., Babusiaux, C., Helmi, A., Muraveva, T., Reylé , C., Spoto, F., Vallenari, A., An- toja, T., Balbinot, E., Barache, C., Bauchet, N., Bragaglia, A., Busonero, D., Cantat-Gaudin, T., Carrasco, J. M., Di- akité, S., Fabrizio, M., Figueras, F., Garcia-Gutierrez, A., Garofalo, A., Jordi, C., Kervella, P., Khanna, S., Leclerc, N., Licata, E., Lambert, S., Marrese, P. M., Masip, A., Ramos, P., Robichon, N., Robin, A. C., Romero-Gómez, M., Rubele, S., and Weiler, M. <i>gaia</i>early data release 3. Astronomy &amp; Astrophysics, 649:A5, apr 2021. doi: 10.1051/0004-6361/202039834.</p>
<p>On the effectiveness of adapterbased tuning for pretrained language model adaptation. R He, L Liu, H Ye, Q Tan, B Ding, L Cheng, J.-W Low, L Bing, Si , L , arXiv:2106.03164arXiv preprintHe, R., Liu, L., Ye, H., Tan, Q., Ding, B., Cheng, L., Low, J.-W., Bing, L., and Si, L. On the effectiveness of adapter- based tuning for pretrained language model adaptation. arXiv preprint arXiv:2106.03164, 2021.</p>
<p>E J Hu, Y Shen, P Wallis, Z Allen-Zhu, Y Li, S Wang, L Wang, Chen , W Lora, 10.48550/arXiv.2106.09685arXiv:2106.09685Low-Rank Adaptation of Large Language Models. arXiv e-prints, art. Hu, E. J., Shen, Y., Wallis, P., Allen-Zhu, Z., Li, Y., Wang, S., Wang, L., and Chen, W. LoRA: Low-Rank Adap- tation of Large Language Models. arXiv e-prints, art. arXiv:2106.09685, June 2021. doi: 10.48550/arXiv.2106. 09685.</p>
<p>Compacter: Efficient low-rank hypercomplex adapter layers. R Karimi Mahabadi, J Henderson, S Ruder, Advances in Neural Information Processing Systems. 34Karimi Mahabadi, R., Henderson, J., and Ruder, S. Com- pacter: Efficient low-rank hypercomplex adapter layers. Advances in Neural Information Processing Systems, 34: 1022-1035, 2021.</p>
<p>Learn to explain: Multimodal reasoning via thought chains for science question answering. P Lu, S Mishra, T Xia, L Qiu, K.-W Chang, S.-C Zhu, O Tafjord, P Clark, A Kalyan, Advances in Neural Information Processing Systems. Koyejo, S., Mohamed, S., Agarwal, A., Belgrave, D., Cho, K., and Oh, A.Curran Associates, Inc35Lu, P., Mishra, S., Xia, T., Qiu, L., Chang, K.-W., Zhu, S.-C., Tafjord, O., Clark, P., and Kalyan, A. Learn to explain: Multimodal reasoning via thought chains for science question answering. In Koyejo, S., Mohamed, S., Agarwal, A., Belgrave, D., Cho, K., and Oh, A. (eds.), Advances in Neural Information Processing Systems, vol- ume 35, pp. 2507-2521. Curran Associates, Inc., 2022.</p>
<p>. abs/2303.08774OpenAI. Gpt-4 technical report. ArXiv. OpenAI. Gpt-4 technical report. ArXiv, abs/2303.08774, 2023.</p>
<p>L Ouyang, J Wu, X Jiang, D Almeida, C L Wainwright, P Mishkin, C Zhang, S Agarwal, K Slama, A Ray, J Schulman, J Hilton, F Kelton, L Miller, M Simens, A Askell, P Welinder, P Christiano, J Leike, R Lowe, 10.48550/arXiv.2203.02155arXiv:2203.02155Training language models to follow instructions with human feedback. arXiv e-prints, art. Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C. L., Mishkin, P., Zhang, C., Agarwal, S., Slama, K., Ray, A., Schulman, J., Hilton, J., Kelton, F., Miller, L., Simens, M., Askell, A., Welinder, P., Christiano, P., Leike, J., and Lowe, R. Training language models to follow instructions with human feedback. arXiv e-prints, art. arXiv:2203.02155, March 2022. doi: 10.48550/arXiv. 2203.02155.</p>
<p>Improving language understanding by generative pre-training. A Radford, K Narasimhan, Radford, A. and Narasimhan, K. Improving language un- derstanding by generative pre-training. 2018.</p>
<p>S F Sánchez, D C Medina, J K Barrera-Ballesteros, L Galbany, A Bolatto, T Wong, 10.48550/arXiv.2212.03738arXiv:2212.03738The local and global relations between Σ ⋆ , Σ SFR and Σ mol that regulate star-formation. arXiv e-prints, art. Sánchez, S. F., Gómez Medina, D. C., Barrera-Ballesteros, J. K., Galbany, L., Bolatto, A., and Wong, T. The local and global relations between Σ ⋆ , Σ SFR and Σ mol that regulate star-formation. arXiv e-prints, art. arXiv:2212.03738, December 2022. doi: 10.48550/arXiv. 2212.03738.</p>
<p>Study of galaxies on large-scale filaments in simulations. A Singh, S Mahajan, J S Bagla, 10.1093/mnras/staa1913Monthly Notices of the Royal Astronomical Society. 4972Singh, A., Mahajan, S., and Bagla, J. S. Study of galaxies on large-scale filaments in simulations. Monthly Notices of the Royal Astronomical Society, 497(2):2265-2275, jul 2020. doi: 10.1093/mnras/staa1913.</p>
<p>Visualizing attention in transformer-based language representation models. J Vig, arXiv:1904.02679arXiv preprintVig, J. Visualizing attention in transformer-based language representation models. arXiv preprint arXiv:1904.02679, 2019.</p>
<p>Self-consistency improves chain of thought reasoning in language models. X Wang, J Wei, D Schuurmans, Q Le, E Chi, D Zhou, arXiv:2203.11171arXiv preprintWang, X., Wei, J., Schuurmans, D., Le, Q., Chi, E., and Zhou, D. Self-consistency improves chain of thought reasoning in language models. arXiv preprint arXiv:2203.11171, 2022.</p>
<p>Chain of thought prompting elicits reasoning in large language models. J Wei, X Wang, D Schuurmans, M Bosma, E Chi, Q Le, D Zhou, arXiv:2201.11903arXiv preprintWei, J., Wang, X., Schuurmans, D., Bosma, M., Chi, E., Le, Q., and Zhou, D. Chain of thought prompting elic- its reasoning in large language models. arXiv preprint arXiv:2201.11903, 2022.</p>
<p>Galaxy evolution in all five CANDELS fields and IllustrisTNG: Morphological, structural, and the major merger evolution to z ∼ 3. A Whitney, L Ferreira, C J Conselice, Duncan , K , 10.3847/1538-4357/ac1422The Astrophysical Journal. 9192139Whitney, A., Ferreira, L., Conselice, C. J., and Duncan, K. Galaxy evolution in all five CANDELS fields and IllustrisTNG: Morphological, structural, and the major merger evolution to z ∼ 3. The Astrophysical Journal, 919(2):139, oct 2021. doi: 10.3847/1538-4357/ac1422.</p>
<p>An explanation of in-context learning as implicit bayesian inference. S M Xie, A Raghunathan, P Liang, T Ma, arXiv:2111.02080arXiv preprintXie, S. M., Raghunathan, A., Liang, P., and Ma, T. An explanation of in-context learning as implicit bayesian inference. arXiv preprint arXiv:2111.02080, 2021.</p>
<p>Automatic chain of thought prompting in large language models. Z Zhang, A Zhang, M Li, A Smola, arXiv:2210.03493arXiv preprintZhang, Z., Zhang, A., Li, M., and Smola, A. Automatic chain of thought prompting in large language models. arXiv preprint arXiv:2210.03493, 2022.</p>            </div>
        </div>

    </div>
</body>
</html>