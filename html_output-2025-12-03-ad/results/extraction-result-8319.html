<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-8319 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-8319</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-8319</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-152.html">extraction-schema-152</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models use diverse or similar reasoning methods to solve reasoning problems, including details of the reasoning methods, whether multiple or single methods are used, the tasks or benchmarks, performance results, and any explicit comparisons or ablations between diverse and similar reasoning approaches.</div>
                <p><strong>Paper ID:</strong> paper-278911793</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2505.21354v2.pdf" target="_blank">Leveraging Large Language Models for Bengali Math Word Problem Solving with Chain of Thought Reasoning</a></p>
                <p><strong>Paper Abstract:</strong> Solving Bengali Math Word Problems (MWPs) remains a major challenge in natural language processing (NLP) due to the language's low-resource status and the multi-step reasoning required. Existing models struggle with complex Bengali MWPs, largely because no human-annotated Bengali dataset has previously addressed this task. This gap has limited progress in Bengali mathematical reasoning. To address this, we created SOMADHAN, a dataset of 8792 complex Bengali MWPs with manually written, step-by-step solutions. We designed this dataset to support reasoning-focused evaluation and model development in a linguistically underrepresented context. Using SOMADHAN, we evaluated a range of large language models (LLMs) - including GPT-4o, GPT-3.5 Turbo, LLaMA series models, Deepseek, and Qwen - through both zero-shot and few-shot prompting with and without Chain of Thought (CoT) reasoning. CoT prompting consistently improved performance over standard prompting, especially in tasks requiring multi-step logic. LLaMA-3.3 70B achieved the highest accuracy of 88% with few-shot CoT prompting. We also applied Low-Rank Adaptation (LoRA) to fine-tune models efficiently, enabling them to adapt to Bengali MWPs with minimal computational cost. Our work fills a critical gap in Bengali NLP by providing a high-quality reasoning dataset and a scalable framework for solving complex MWPs. We aim to advance equitable research in low-resource languages and enhance reasoning capabilities in educational and language technologies.</p>
                <p><strong>Cost:</strong> 0.023</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e8319.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e8319.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models use diverse or similar reasoning methods to solve reasoning problems, including details of the reasoning methods, whether multiple or single methods are used, the tasks or benchmarks, performance results, and any explicit comparisons or ablations between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CoT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Chain-of-Thought prompting</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A prompting technique that elicits step-by-step natural language intermediate reasoning from LLMs to improve multi-step problem solving and interpretability.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Chain-of-thought prompting elicits reasoning in large language models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>various (paper-wide)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Applied across multiple evaluated LLMs (GPT-4o, GPT-3.5, LLaMA-3 variants, Deepseek, Qwen), using prompts that include example chains or explicit instructions to produce intermediate reasoning steps.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods</strong></td>
                            <td>['chain-of-thought', 'few-shot CoT', 'zero-shot CoT']</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods_description</strong></td>
                            <td>CoT implemented by (a) zero-shot CoT: system instructions that request step-by-step reasoning; (b) few-shot CoT: inclusion of 5 example QA pairs with explicit chains of thought in the prompt; and (c) fine-tuning with CoT examples during LoRA/standard fine-tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_diversity</strong></td>
                            <td>both</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_diversity_experimental_setup</strong></td>
                            <td>Direct comparisons of Standard prompting (no intermediate steps) vs Chain-of-Thought prompting in zero-shot and few-shot settings; two prompt styles (Prompt-1 and Prompt-2) were evaluated to test CoT effectiveness; CoT also used in fine-tuning and LoRA experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>SOMADHAN (new Bengali GSM8K-derived dataset, 8,792 Bengali MWPs with step-by-step solutions) and PatiGonit (10,000 equation-based Bengali MWPs).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Across models CoT generally improved accuracy versus standard prompting for larger models: GPT-3.5 on SOMADHAN: standard few-shot 24.0% -> CoT few-shot 30.0%; GPT-4o on SOMADHAN: standard few-shot 80.0% -> CoT few-shot 83.0% (Prompt-1) and zero-shot 79.2% -> CoT zero-shot 80.4%; LLaMA-3.3 (70B) achieved 78% standard few-shot -> 87% CoT few-shot (Prompt-1) and 78% -> 88% CoT few-shot (Prompt-2); Qwen-2.5 (32B) Prompt-2: standard few-shot 68% -> CoT few-shot 71%; Deepseek-r1-distill-qwen: standard few-shot 44% -> CoT few-shot 51% (responses sometimes in English).</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_findings</strong></td>
                            <td>CoT yielded large gains on strong, large models (GPT-4o, LLaMA-3.3). Smaller models (LLaMA-3 8B, LLaMA-3.1/3.2 smaller variants) often did not benefit and sometimes lost accuracy with CoT; CoT also affected language of responses (some models produced English outputs rather than Bengali when CoT applied). Prompt style and few-shot exemplars materially affected CoT efficacy. CoT improved interpretability but evaluation only used final-answer accuracy; intermediate steps were not scored.</td>
                        </tr>
                        <tr>
                            <td><strong>explicit_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>key_claims_or_conclusions</strong></td>
                            <td>Chain-of-Thought prompting consistently improved performance over standard prompting, especially for multi-step reasoning tasks and larger models; few-shot CoT produced the best results (LLaMA-3.3 70B reached top accuracy 88% with few-shot CoT).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Leveraging Large Language Models for Bengali Math Word Problem Solving with Chain of Thought Reasoning', 'publication_date_yy_mm': '2025-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8319.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e8319.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models use diverse or similar reasoning methods to solve reasoning problems, including details of the reasoning methods, whether multiple or single methods are used, the tasks or benchmarks, performance results, and any explicit comparisons or ablations between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>StandardPrompt</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Standard prompting (no intermediate steps)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Baseline prompting where the model is given the question and asked for the answer without requesting intermediate reasoning steps.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>various (paper-wide)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Applied as the baseline across evaluated LLMs in zero-shot and few-shot configurations (prompts that do not request CoT).</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods</strong></td>
                            <td>['direct answer prompting (no CoT)']</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods_description</strong></td>
                            <td>Prompting scheme that omits intermediate step examples or instructions; used in zero-shot and few-shot setups to compare against CoT.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_diversity</strong></td>
                            <td>similar</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_diversity_experimental_setup</strong></td>
                            <td>Compared directly to CoT prompting (same models, same few-shot/zero-shot splits) to measure CoT benefit.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>SOMADHAN and PatiGonit</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Examples: GPT-3.5 SOMADHAN standard few-shot 24.0%; GPT-4o standard few-shot 80.0%; LLaMA-3 (70B) standard zero-shot 76% (but in English responses); LLaMA-3 (8B) standard zero-shot 47%.</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_findings</strong></td>
                            <td>Standard prompting sometimes yields higher raw accuracy for certain models/sizes and when responses default to English; lacks interpretability from intermediate steps and is weaker on multi-step reasoning for many large models.</td>
                        </tr>
                        <tr>
                            <td><strong>explicit_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>key_claims_or_conclusions</strong></td>
                            <td>Standard prompting is a weaker baseline for multi-step reasoning tasks compared to CoT for most large models, though some models (and some smaller LLaMA variants) sometimes performed better in standard prompting for certain language/output configurations.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Leveraging Large Language Models for Bengali Math Word Problem Solving with Chain of Thought Reasoning', 'publication_date_yy_mm': '2025-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8319.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e8319.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models use diverse or similar reasoning methods to solve reasoning problems, including details of the reasoning methods, whether multiple or single methods are used, the tasks or benchmarks, performance results, and any explicit comparisons or ablations between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Few-vs-ZeroShot</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Few-shot vs Zero-shot prompting</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Comparison between providing a small number of exemplar QA pairs in-context (few-shot) and providing no examples (zero-shot) for CoT and standard prompts.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>various (paper-wide)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Few-shot used five exemplars with chains of thought; zero-shot used explicit CoT instructions or no instruction depending on condition.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods</strong></td>
                            <td>['few-shot CoT', 'zero-shot CoT', 'few-shot standard', 'zero-shot standard']</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods_description</strong></td>
                            <td>Few-shot: manual inclusion of five chain-of-thought QA examples; Zero-shot: system instruction requesting CoT or plain question for standard prompting.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_diversity</strong></td>
                            <td>both</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_diversity_experimental_setup</strong></td>
                            <td>Evaluated each model in four conditions: standard zero-shot, standard few-shot, CoT zero-shot, CoT few-shot; compared accuracies.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>SOMADHAN (primary), PatiGonit (secondary)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Many models improved from few-shot and from adding CoT. Example: GPT-3.5 SOMADHAN standard 24% -> CoT few-shot 30%; GPT-4o SOMADHAN standard few-shot 80% -> CoT few-shot 83%; LLaMA-3.3 best with CoT few-shot 87-88%.</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_findings</strong></td>
                            <td>Few-shot exemplars with CoT often yield additive gains over zero-shot; effect size depends on model size and prompt style. Some models show diminishing or negative returns in few-shot CoT (notably smaller LLaMA variants).</td>
                        </tr>
                        <tr>
                            <td><strong>explicit_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>key_claims_or_conclusions</strong></td>
                            <td>Few-shot CoT generally outperforms zero-shot CoT and standard prompting, especially for larger-capacity models; prompt design and exemplar selection matter.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Leveraging Large Language Models for Bengali Math Word Problem Solving with Chain of Thought Reasoning', 'publication_date_yy_mm': '2025-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8319.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e8319.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models use diverse or similar reasoning methods to solve reasoning problems, including details of the reasoning methods, whether multiple or single methods are used, the tasks or benchmarks, performance results, and any explicit comparisons or ablations between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DIVERSE</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>DIVERSE (Diverse Verifier on Reasoning Step)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A related-work framework that generates diverse reasoning paths and uses a verifier to score reasoning steps, promoting multiple reasoning trajectories and step-aware verification.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>N/A (related work)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Described in related work as a method to generate diverse reasoning chains and select via weighted voting/verifier over step-level correctness.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods</strong></td>
                            <td>['diverse-path generation', 'step-aware verification']</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods_description</strong></td>
                            <td>Generates multiple reasoning paths per question and uses a verifier to evaluate steps individually and vote for the best final answer.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_diversity</strong></td>
                            <td>diverse</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_diversity_experimental_setup</strong></td>
                            <td>Mentioned as a contrasting/motivating method; not implemented in this paper's experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Mentioned in context of arithmetic/reasoning benchmarks (related work)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_findings</strong></td>
                            <td>Cited as improving reasoning by exploring multiple solution paths and verifying step-level correctness; not evaluated in this study.</td>
                        </tr>
                        <tr>
                            <td><strong>explicit_comparison</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>key_claims_or_conclusions</strong></td>
                            <td>Mentioned as an example of leveraging diverse reasoning paths and verification to improve LLM reasoning; not experimentally compared in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Leveraging Large Language Models for Bengali Math Word Problem Solving with Chain of Thought Reasoning', 'publication_date_yy_mm': '2025-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8319.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e8319.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models use diverse or similar reasoning methods to solve reasoning problems, including details of the reasoning methods, whether multiple or single methods are used, the tasks or benchmarks, performance results, and any explicit comparisons or ablations between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SelfConsistency</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Self-consistency decoding</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A decoding strategy that samples multiple reasoning paths and selects the most consistent final answer across generated chains.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Self-consistency improves chain of thought reasoning in language models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>N/A (related work)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Referenced in related work as a method that improves CoT by sampling many chains-of-thought and choosing the majority/most consistent answer.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods</strong></td>
                            <td>['self-consistency (multiple-chain sampling + majority selection)']</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods_description</strong></td>
                            <td>Produces diverse chains via sampling and aggregates final answers (or uses voting) to increase robustness.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_diversity</strong></td>
                            <td>diverse</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_diversity_experimental_setup</strong></td>
                            <td>Mentioned as an alternative/augmentation to CoT; not used in the paper's experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Referenced with arithmetic reasoning benchmarks (related work)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_findings</strong></td>
                            <td>Cited as valuable for improving CoT reliability; not applied or ablated here.</td>
                        </tr>
                        <tr>
                            <td><strong>explicit_comparison</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>key_claims_or_conclusions</strong></td>
                            <td>Paper cites self-consistency as prior evidence that aggregating diverse reasoning paths can improve answer accuracy, but does not run self-consistency experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Leveraging Large Language Models for Bengali Math Word Problem Solving with Chain of Thought Reasoning', 'publication_date_yy_mm': '2025-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8319.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e8319.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models use diverse or similar reasoning methods to solve reasoning problems, including details of the reasoning methods, whether multiple or single methods are used, the tasks or benchmarks, performance results, and any explicit comparisons or ablations between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LoRA-ablation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LoRA fine-tuning ablations</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Parameter-efficient fine-tuning (Low-Rank Adaptation) applied with multiple configurations (rank, dropout, batch-size) and reported as an ablation study.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLaMA-3 8B (example target for LoRA experiments)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>LoRA applied to adapt models efficiently for Bengali MWPs by training low-rank adapter matrices while freezing base model weights; three LoRA configurations were compared.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods</strong></td>
                            <td>['fine-tuning with CoT supervision (LoRA)']</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods_description</strong></td>
                            <td>LoRA fine-tuning used CoT examples in training data; paper tested three configurations: Baseline (rank 16, no dropout), Higher Rank with Dropout (rank 32, dropout 0.1), and Memory-Efficient with Lower Batch Size (rank 32, lower batch size, gradient accumulation).</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_diversity</strong></td>
                            <td>similar</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_diversity_experimental_setup</strong></td>
                            <td>Ablation study (Table 5) comparing three LoRA configurations on SOMADHAN to measure effects of rank, dropout, batch size on final-answer accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>SOMADHAN</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>LoRA results (Table 5): Baseline (Finetune 1) accuracy 13.0%; Higher Rank with Dropout (Finetune 2) 12.0%; Memory-Efficient with Lower Batch Size (Finetune 3) 17.0% (best LoRA config).</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_findings</strong></td>
                            <td>LoRA yields modest improvements but overall low absolute accuracy compared to prompting with large models; different LoRA hyperparameters substantially change results and risk overfitting; LoRA experiments indicate fine-tuning with few CoT examples is sensitive to config and training dynamics.</td>
                        </tr>
                        <tr>
                            <td><strong>explicit_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>key_claims_or_conclusions</strong></td>
                            <td>LoRA can adapt models efficiently but in this study achieved limited accuracy on SOMADHAN; the memory-efficient lower-batch configuration performed best (17%), while higher rank with dropout underperformed (12%).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Leveraging Large Language Models for Bengali Math Word Problem Solving with Chain of Thought Reasoning', 'publication_date_yy_mm': '2025-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8319.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e8319.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models use diverse or similar reasoning methods to solve reasoning problems, including details of the reasoning methods, whether multiple or single methods are used, the tasks or benchmarks, performance results, and any explicit comparisons or ablations between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-4o</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-4o (OpenAI)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A very large multimodal OpenAI model used as a high-performing baseline for Bengali MWPs with and without CoT prompting.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4o</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Described as having very large parameter count (paper states ~1.3 trillion in one place) and strong generalization, evaluated in zero-shot and few-shot settings with standard and CoT prompting.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods</strong></td>
                            <td>['standard prompting', 'zero-shot CoT', 'few-shot CoT']</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods_description</strong></td>
                            <td>Evaluated with system instructions for CoT, few-shot examples with chains of thought, and standard prompts without intermediate steps; not fine-tuned in study (evaluated as-is).</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_diversity</strong></td>
                            <td>both</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_diversity_experimental_setup</strong></td>
                            <td>Compared standard vs CoT in zero-shot and few-shot; also compared to fine-tuned GPT-3.5 results.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>SOMADHAN (primary) and PatiGonit (secondary)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>SOMADHAN: standard zero-shot 79.0%, standard few-shot 80.0%; CoT zero-shot 80.4%, CoT few-shot 83.0%. PatiGonit few-shot 99.0%. Also reported non-fine-tuned GPT-4o zero-shot 79.2% in Table 6.</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_findings</strong></td>
                            <td>GPT-4o showed strong absolute performance and benefited from CoT (moderate gains), indicating large-capacity models gain from stepwise reasoning; CoT with few-shot gave best results. GPT-4o outperformed fine-tuned GPT-3.5.</td>
                        </tr>
                        <tr>
                            <td><strong>explicit_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>key_claims_or_conclusions</strong></td>
                            <td>GPT-4o handles Bengali MWPs effectively and benefits from CoT prompting, but its high zero-shot competence reduces marginal gains from fine-tuning; CoT few-shot improved accuracy by a few percent.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Leveraging Large Language Models for Bengali Math Word Problem Solving with Chain of Thought Reasoning', 'publication_date_yy_mm': '2025-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8319.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e8319.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models use diverse or similar reasoning methods to solve reasoning problems, including details of the reasoning methods, whether multiple or single methods are used, the tasks or benchmarks, performance results, and any explicit comparisons or ablations between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-3.5</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-3.5 Turbo (OpenAI)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A large OpenAI model (~175B parameters) evaluated with standard prompting, CoT prompting, few-shot examples, and fine-tuning (standard fine-tuning with CoT examples).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5 Turbo-0125 (and turbo variants)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Evaluated in zero-shot and few-shot modes; also fine-tuned with 50 CoT examples (JSONL) with different epoch/lr settings (standard fine-tuning).</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods</strong></td>
                            <td>['standard prompting', 'CoT prompting (zero/few-shot)', 'standard fine-tuning with CoT supervision']</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods_description</strong></td>
                            <td>Few-shot included five CoT exemplars; fine-tuning used 50 CoT examples and varied epochs and learning rates to encourage chain generation.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_diversity</strong></td>
                            <td>both</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_diversity_experimental_setup</strong></td>
                            <td>Compared standard vs CoT in zero/few-shot; ran standard fine-tuning (50 examples) with different epochs and learning rates to observe gains.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>SOMADHAN and PatiGonit</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>SOMADHAN: standard zero-shot 23.0%, standard few-shot 24.0%; CoT zero-shot 24.0%, CoT few-shot 30.0% (Prompt-1). Fine-tuned GPT-3.5 (lr=0.1, 10 epochs) achieved 23.4% (best fine-tune), with other epoch settings showing lower or plateaued performance.</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_findings</strong></td>
                            <td>GPT-3.5 shows modest gains from CoT and few-shot; fine-tuning with small CoT dataset gave limited improvements and was sensitive to epochs (overfitting/diminishing returns beyond 10 epochs). Performance remains far below top large models.</td>
                        </tr>
                        <tr>
                            <td><strong>explicit_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>key_claims_or_conclusions</strong></td>
                            <td>CoT and few-shot help GPT-3.5 but yields modest absolute improvements; fine-tuning with limited CoT examples yields constrained gains and can plateau or degrade with more epochs.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Leveraging Large Language Models for Bengali Math Word Problem Solving with Chain of Thought Reasoning', 'publication_date_yy_mm': '2025-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8319.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e8319.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models use diverse or similar reasoning methods to solve reasoning problems, including details of the reasoning methods, whether multiple or single methods are used, the tasks or benchmarks, performance results, and any explicit comparisons or ablations between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLaMA-3.3-70B</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLaMA-3.3 (70B)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A 70B-parameter LLaMA-3 variant that achieved the highest reported accuracy on SOMADHAN when using few-shot CoT prompting.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLaMA-3.3 70B</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>70B parameter model from the LLaMA-3 family; evaluated with different prompt styles, zero/few-shot, and CoT prompting.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods</strong></td>
                            <td>['standard prompting', 'few-shot CoT', 'zero-shot CoT']</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods_description</strong></td>
                            <td>Used both standard and CoT prompts; best performance achieved with few-shot CoT and Prompt Style 2 (explicit few-shot CoT examples).</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_diversity</strong></td>
                            <td>both</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_diversity_experimental_setup</strong></td>
                            <td>Prompt-style ablation (Prompt-1 vs Prompt-2) and standard vs CoT; zero-shot vs few-shot comparisons reported.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>SOMADHAN</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Achieved highest accuracy on SOMADHAN: 87% with CoT few-shot (Prompt-1) and 88% with CoT few-shot (Prompt-2). Standard few-shot accuracy reported around 78%.</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_findings</strong></td>
                            <td>Large LLaMA variant benefits greatly from few-shot CoT (910% absolute improvement); CoT also improved language alignment to Bengali for this model. Smaller LLaMA variants did not share this benefit.</td>
                        </tr>
                        <tr>
                            <td><strong>explicit_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>key_claims_or_conclusions</strong></td>
                            <td>LLaMA-3.3 (70B) demonstrates that a large but open/model-family LLM can match or exceed GPT-4o on Bengali MWP when combined with few-shot CoT and proper prompt style; CoT with few-shot is the most effective configuration for this model.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Leveraging Large Language Models for Bengali Math Word Problem Solving with Chain of Thought Reasoning', 'publication_date_yy_mm': '2025-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8319.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e8319.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models use diverse or similar reasoning methods to solve reasoning problems, including details of the reasoning methods, whether multiple or single methods are used, the tasks or benchmarks, performance results, and any explicit comparisons or ablations between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLaMA-3-70B</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLaMA-3 (70B)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A 70B-parameter LLaMA-3 base model evaluated with standard and CoT prompting; results indicate mixed CoT benefits depending on prompt style.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLaMA-3 70B</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>70B-parameter LLaMA model; evaluated in zero-shot and few-shot with/without CoT under two prompt styles.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods</strong></td>
                            <td>['standard prompting', 'CoT prompting']</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods_description</strong></td>
                            <td>Standard prompting and CoT tested; Prompt style affected outcomes and language of outputs (English vs Bengali).</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_diversity</strong></td>
                            <td>both</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_diversity_experimental_setup</strong></td>
                            <td>Compared standard vs CoT for Prompt Style 1 and 2, zero-shot vs few-shot.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>SOMADHAN</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Prompt-1: standard zero-shot 76% (but responses in English); CoT zero-shot/few-shot dropped to 65%. Prompt-2: CoT few-shot improved to 73% vs 67% standard prompting (a 6% improvement).</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_findings</strong></td>
                            <td>Performance sensitive to prompt style and language adaptation: Prompt-1 yielded higher standard accuracy but English outputs; Prompt-2 enabled better Bengali outputs and CoT gains. CoT helped in some prompt setups but harmed in others.</td>
                        </tr>
                        <tr>
                            <td><strong>explicit_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>key_claims_or_conclusions</strong></td>
                            <td>Effectiveness of CoT depends on prompt design and language alignment; for LLaMA-3 (70B) Prompt-2+CoT yielded improvements, while Prompt-1 showed opposite trends.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Leveraging Large Language Models for Bengali Math Word Problem Solving with Chain of Thought Reasoning', 'publication_date_yy_mm': '2025-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8319.10">
                <h3 class="extraction-instance">Extracted Data Instance 10 (e8319.10)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models use diverse or similar reasoning methods to solve reasoning problems, including details of the reasoning methods, whether multiple or single methods are used, the tasks or benchmarks, performance results, and any explicit comparisons or ablations between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLaMA-3-8B</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLaMA-3 (8B)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An 8B-parameter LLaMA-3 variant that struggled with CoT prompting on Bengali MWPs and often lost accuracy under CoT.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLaMA-3 8B</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Smaller-capacity LLaMA-3 model evaluated with standard and CoT prompting in zero-shot and few-shot modes.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods</strong></td>
                            <td>['standard prompting', 'CoT prompting']</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods_description</strong></td>
                            <td>Same CoT and standard protocols as larger models; few-shot included five CoT examples.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_diversity</strong></td>
                            <td>both</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_diversity_experimental_setup</strong></td>
                            <td>Direct comparison across prompting conditions; also evaluated for language output mismatch (English vs Bengali).</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>SOMADHAN</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Prompt-1: standard zero-shot 47% (best); CoT decreased to 24% zero-shot and 19% few-shot. Prompt-2: similar pattern of no improvement with CoT; did not generate Bengali reliably in some cases.</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_findings</strong></td>
                            <td>Smaller model capacity limits benefit from CoT; CoT often hurt performance and sometimes caused language/output issues. Indicates that CoT requires sufficient model capacity to be effective.</td>
                        </tr>
                        <tr>
                            <td><strong>explicit_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>key_claims_or_conclusions</strong></td>
                            <td>CoT is not universally beneficial: for smaller LLaMA variants CoT reduced accuracy on Bengali MWPs; model size is a critical factor for CoT efficacy.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Leveraging Large Language Models for Bengali Math Word Problem Solving with Chain of Thought Reasoning', 'publication_date_yy_mm': '2025-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8319.11">
                <h3 class="extraction-instance">Extracted Data Instance 11 (e8319.11)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models use diverse or similar reasoning methods to solve reasoning problems, including details of the reasoning methods, whether multiple or single methods are used, the tasks or benchmarks, performance results, and any explicit comparisons or ablations between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Deepseek-distill-qwen</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Deepseek-r1-distill-qwen-32B</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A distilled 32B Qwen model in Deepseek's family evaluated for CoT and standard prompting; showed moderate gains with CoT but produced English outputs in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Deepseek-r1-distill-qwen-32B</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>A distilled variant of Qwen-32B optimized for efficiency; evaluated in zero/few-shot and CoT/standard prompting.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods</strong></td>
                            <td>['standard prompting', 'few-shot CoT']</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods_description</strong></td>
                            <td>Compared standard few-shot prompting to CoT few-shot; language of response noted as English even when evaluated on Bengali dataset.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_diversity</strong></td>
                            <td>both</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_diversity_experimental_setup</strong></td>
                            <td>Prompt-style comparisons with Prompt-2 reported; measured effect of CoT few-shot vs standard few-shot.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>SOMADHAN</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Prompt-2: standard few-shot 44% -> CoT few-shot 51% (gain +7%), but responses were in English.</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_findings</strong></td>
                            <td>CoT improved numeric accuracy but language mismatch (English outputs) reduces usefulness for Bengali-specific applications; shows CoT gains can exist even when language adaptation fails.</td>
                        </tr>
                        <tr>
                            <td><strong>explicit_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>key_claims_or_conclusions</strong></td>
                            <td>Distilled models can improve with CoT, but achieving language alignment (Bengali output) remains an orthogonal challenge.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Leveraging Large Language Models for Bengali Math Word Problem Solving with Chain of Thought Reasoning', 'publication_date_yy_mm': '2025-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8319.12">
                <h3 class="extraction-instance">Extracted Data Instance 12 (e8319.12)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models use diverse or similar reasoning methods to solve reasoning problems, including details of the reasoning methods, whether multiple or single methods are used, the tasks or benchmarks, performance results, and any explicit comparisons or ablations between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Deepseek-distill-llama</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Deepseek-r1-distill-llama-70B</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A distilled LLaMA-70B variant from Deepseek that showed improved accuracy with CoT few-shot and produced Bengali outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Deepseek-r1-distill-llama-70B</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Distilled LLaMA-70B optimized for efficiency; evaluated with prompt-style variants and CoT few-shot.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods</strong></td>
                            <td>['standard prompting', 'few-shot CoT']</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods_description</strong></td>
                            <td>Evaluated standard vs CoT few-shot (Prompt-2); CoT included step-wise exemplars.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_diversity</strong></td>
                            <td>both</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_diversity_experimental_setup</strong></td>
                            <td>Prompt-2 comparisons; measured language output and accuracy changes due to CoT.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>SOMADHAN</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Prompt-2: standard few-shot 60% -> CoT few-shot 66% (+6%), responses were in Bengali.</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_findings</strong></td>
                            <td>Distilled LLaMA retained Bengali output quality and benefited from CoT; shows distillation does not preclude CoT gains if language alignment maintained.</td>
                        </tr>
                        <tr>
                            <td><strong>explicit_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>key_claims_or_conclusions</strong></td>
                            <td>Distilled large models can benefit from CoT and maintain Bengali output when properly configured; CoT yields clear accuracy gains here.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Leveraging Large Language Models for Bengali Math Word Problem Solving with Chain of Thought Reasoning', 'publication_date_yy_mm': '2025-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8319.13">
                <h3 class="extraction-instance">Extracted Data Instance 13 (e8319.13)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models use diverse or similar reasoning methods to solve reasoning problems, including details of the reasoning methods, whether multiple or single methods are used, the tasks or benchmarks, performance results, and any explicit comparisons or ablations between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Qwen-2.5-32B</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Qwen-2.5 32B</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A 32B-parameter Qwen-family model evaluated with CoT and standard prompting and showing moderate CoT gains.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Qwen-2.5-32B</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Large multi-task Qwen model evaluated on Bengali MWPs with prompt-style ablations; tested with CoT few-shot.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods</strong></td>
                            <td>['standard prompting', 'few-shot CoT']</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods_description</strong></td>
                            <td>Prompt-2 few-shot CoT with five CoT exemplars compared to standard few-shot prompting.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_diversity</strong></td>
                            <td>both</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_diversity_experimental_setup</strong></td>
                            <td>Prompt-style comparison showing CoT advantage for this model.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>SOMADHAN</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Prompt-2: standard few-shot 68% -> CoT few-shot 71% (+3%).</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_findings</strong></td>
                            <td>Qwen-2.5 benefits modestly from CoT; language output alignment achieved for some Qwen variants while others (Qwen-qwq) output English only.</td>
                        </tr>
                        <tr>
                            <td><strong>explicit_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>key_claims_or_conclusions</strong></td>
                            <td>Moderate CoT gains indicate CoT is beneficial across architectures, magnitude depends on model and prompt style.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Leveraging Large Language Models for Bengali Math Word Problem Solving with Chain of Thought Reasoning', 'publication_date_yy_mm': '2025-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8319.14">
                <h3 class="extraction-instance">Extracted Data Instance 14 (e8319.14)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models use diverse or similar reasoning methods to solve reasoning problems, including details of the reasoning methods, whether multiple or single methods are used, the tasks or benchmarks, performance results, and any explicit comparisons or ablations between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SOMADHAN</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>SOMADHAN (Bengali Grade School Math dataset)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A new dataset introduced in this paper: 8,792 Bengali math word problems with human-written step-by-step (CoT) solutions intended to evaluate reasoning in low-resource language settings.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>dataset (task)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Derived from GSM8K via manual translation and annotation into Bengali, includes 4,000 manually annotated CoT examples so far (ongoing annotation) and designed to evaluate multi-step reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods</strong></td>
                            <td>['chain-of-thought supervision (human-provided)', 'equation supervision (for PatiGonit secondary dataset)']</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods_description</strong></td>
                            <td>Each example contains intermediate reasoning steps (s_1...s_k) and a final result r_true; paper evaluates only final-answer correctness but uses the CoT annotations for few-shot and fine-tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_diversity</strong></td>
                            <td>both</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_diversity_experimental_setup</strong></td>
                            <td>Used as primary benchmark to compare standard prompting vs CoT prompting, zero-shot vs few-shot, prompt-style ablations, and LoRA fine-tuning configurations.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>SOMADHAN - 8,792 Bengali MWPs with CoT; PatiGonit used as complementary equation-based dataset.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Top model performance on SOMADHAN: LLaMA-3.3 (70B) CoT few-shot 88% (Prompt-2); GPT-4o CoT few-shot ~83%; many models reported wide spread of accuracies (from single-digit LoRA fine-tuned results up to ~88%).</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_findings</strong></td>
                            <td>Dataset enables direct evaluation of CoT prompting benefits in a low-resource language; models often produce English answers or fail to adapt language even when reasoning improves; only final-answer accuracy was measured despite availability of CoT steps.</td>
                        </tr>
                        <tr>
                            <td><strong>explicit_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>key_claims_or_conclusions</strong></td>
                            <td>Introducing SOMADHAN enabled demonstration that CoT prompting and few-shot exemplars substantially improve large-model performance on Bengali MWPs, highlighting need for CoT supervision and language adaptation.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Leveraging Large Language Models for Bengali Math Word Problem Solving with Chain of Thought Reasoning', 'publication_date_yy_mm': '2025-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Chain-of-thought prompting elicits reasoning in large language models <em>(Rating: 2)</em></li>
                <li>Self-consistency improves chain of thought reasoning in language models <em>(Rating: 2)</em></li>
                <li>Lora: Low-rank adaptation of large language models <em>(Rating: 2)</em></li>
                <li>GSM8K (Grade School Math) dataset <em>(Rating: 2)</em></li>
                <li>On the advance of making language models better reasoners <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-8319",
    "paper_id": "paper-278911793",
    "extraction_schema_id": "extraction-schema-152",
    "extracted_data": [
        {
            "name_short": "CoT",
            "name_full": "Chain-of-Thought prompting",
            "brief_description": "A prompting technique that elicits step-by-step natural language intermediate reasoning from LLMs to improve multi-step problem solving and interpretability.",
            "citation_title": "Chain-of-thought prompting elicits reasoning in large language models",
            "mention_or_use": "use",
            "model_name": "various (paper-wide)",
            "model_description": "Applied across multiple evaluated LLMs (GPT-4o, GPT-3.5, LLaMA-3 variants, Deepseek, Qwen), using prompts that include example chains or explicit instructions to produce intermediate reasoning steps.",
            "reasoning_methods": [
                "chain-of-thought",
                "few-shot CoT",
                "zero-shot CoT"
            ],
            "reasoning_methods_description": "CoT implemented by (a) zero-shot CoT: system instructions that request step-by-step reasoning; (b) few-shot CoT: inclusion of 5 example QA pairs with explicit chains of thought in the prompt; and (c) fine-tuning with CoT examples during LoRA/standard fine-tuning.",
            "reasoning_diversity": "both",
            "reasoning_diversity_experimental_setup": "Direct comparisons of Standard prompting (no intermediate steps) vs Chain-of-Thought prompting in zero-shot and few-shot settings; two prompt styles (Prompt-1 and Prompt-2) were evaluated to test CoT effectiveness; CoT also used in fine-tuning and LoRA experiments.",
            "task_or_benchmark": "SOMADHAN (new Bengali GSM8K-derived dataset, 8,792 Bengali MWPs with step-by-step solutions) and PatiGonit (10,000 equation-based Bengali MWPs).",
            "performance_results": "Across models CoT generally improved accuracy versus standard prompting for larger models: GPT-3.5 on SOMADHAN: standard few-shot 24.0% -&gt; CoT few-shot 30.0%; GPT-4o on SOMADHAN: standard few-shot 80.0% -&gt; CoT few-shot 83.0% (Prompt-1) and zero-shot 79.2% -&gt; CoT zero-shot 80.4%; LLaMA-3.3 (70B) achieved 78% standard few-shot -&gt; 87% CoT few-shot (Prompt-1) and 78% -&gt; 88% CoT few-shot (Prompt-2); Qwen-2.5 (32B) Prompt-2: standard few-shot 68% -&gt; CoT few-shot 71%; Deepseek-r1-distill-qwen: standard few-shot 44% -&gt; CoT few-shot 51% (responses sometimes in English).",
            "qualitative_findings": "CoT yielded large gains on strong, large models (GPT-4o, LLaMA-3.3). Smaller models (LLaMA-3 8B, LLaMA-3.1/3.2 smaller variants) often did not benefit and sometimes lost accuracy with CoT; CoT also affected language of responses (some models produced English outputs rather than Bengali when CoT applied). Prompt style and few-shot exemplars materially affected CoT efficacy. CoT improved interpretability but evaluation only used final-answer accuracy; intermediate steps were not scored.",
            "explicit_comparison": true,
            "key_claims_or_conclusions": "Chain-of-Thought prompting consistently improved performance over standard prompting, especially for multi-step reasoning tasks and larger models; few-shot CoT produced the best results (LLaMA-3.3 70B reached top accuracy 88% with few-shot CoT).",
            "uuid": "e8319.0",
            "source_info": {
                "paper_title": "Leveraging Large Language Models for Bengali Math Word Problem Solving with Chain of Thought Reasoning",
                "publication_date_yy_mm": "2025-05"
            }
        },
        {
            "name_short": "StandardPrompt",
            "name_full": "Standard prompting (no intermediate steps)",
            "brief_description": "Baseline prompting where the model is given the question and asked for the answer without requesting intermediate reasoning steps.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "various (paper-wide)",
            "model_description": "Applied as the baseline across evaluated LLMs in zero-shot and few-shot configurations (prompts that do not request CoT).",
            "reasoning_methods": [
                "direct answer prompting (no CoT)"
            ],
            "reasoning_methods_description": "Prompting scheme that omits intermediate step examples or instructions; used in zero-shot and few-shot setups to compare against CoT.",
            "reasoning_diversity": "similar",
            "reasoning_diversity_experimental_setup": "Compared directly to CoT prompting (same models, same few-shot/zero-shot splits) to measure CoT benefit.",
            "task_or_benchmark": "SOMADHAN and PatiGonit",
            "performance_results": "Examples: GPT-3.5 SOMADHAN standard few-shot 24.0%; GPT-4o standard few-shot 80.0%; LLaMA-3 (70B) standard zero-shot 76% (but in English responses); LLaMA-3 (8B) standard zero-shot 47%.",
            "qualitative_findings": "Standard prompting sometimes yields higher raw accuracy for certain models/sizes and when responses default to English; lacks interpretability from intermediate steps and is weaker on multi-step reasoning for many large models.",
            "explicit_comparison": true,
            "key_claims_or_conclusions": "Standard prompting is a weaker baseline for multi-step reasoning tasks compared to CoT for most large models, though some models (and some smaller LLaMA variants) sometimes performed better in standard prompting for certain language/output configurations.",
            "uuid": "e8319.1",
            "source_info": {
                "paper_title": "Leveraging Large Language Models for Bengali Math Word Problem Solving with Chain of Thought Reasoning",
                "publication_date_yy_mm": "2025-05"
            }
        },
        {
            "name_short": "Few-vs-ZeroShot",
            "name_full": "Few-shot vs Zero-shot prompting",
            "brief_description": "Comparison between providing a small number of exemplar QA pairs in-context (few-shot) and providing no examples (zero-shot) for CoT and standard prompts.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "various (paper-wide)",
            "model_description": "Few-shot used five exemplars with chains of thought; zero-shot used explicit CoT instructions or no instruction depending on condition.",
            "reasoning_methods": [
                "few-shot CoT",
                "zero-shot CoT",
                "few-shot standard",
                "zero-shot standard"
            ],
            "reasoning_methods_description": "Few-shot: manual inclusion of five chain-of-thought QA examples; Zero-shot: system instruction requesting CoT or plain question for standard prompting.",
            "reasoning_diversity": "both",
            "reasoning_diversity_experimental_setup": "Evaluated each model in four conditions: standard zero-shot, standard few-shot, CoT zero-shot, CoT few-shot; compared accuracies.",
            "task_or_benchmark": "SOMADHAN (primary), PatiGonit (secondary)",
            "performance_results": "Many models improved from few-shot and from adding CoT. Example: GPT-3.5 SOMADHAN standard 24% -&gt; CoT few-shot 30%; GPT-4o SOMADHAN standard few-shot 80% -&gt; CoT few-shot 83%; LLaMA-3.3 best with CoT few-shot 87-88%.",
            "qualitative_findings": "Few-shot exemplars with CoT often yield additive gains over zero-shot; effect size depends on model size and prompt style. Some models show diminishing or negative returns in few-shot CoT (notably smaller LLaMA variants).",
            "explicit_comparison": true,
            "key_claims_or_conclusions": "Few-shot CoT generally outperforms zero-shot CoT and standard prompting, especially for larger-capacity models; prompt design and exemplar selection matter.",
            "uuid": "e8319.2",
            "source_info": {
                "paper_title": "Leveraging Large Language Models for Bengali Math Word Problem Solving with Chain of Thought Reasoning",
                "publication_date_yy_mm": "2025-05"
            }
        },
        {
            "name_short": "DIVERSE",
            "name_full": "DIVERSE (Diverse Verifier on Reasoning Step)",
            "brief_description": "A related-work framework that generates diverse reasoning paths and uses a verifier to score reasoning steps, promoting multiple reasoning trajectories and step-aware verification.",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": "N/A (related work)",
            "model_description": "Described in related work as a method to generate diverse reasoning chains and select via weighted voting/verifier over step-level correctness.",
            "reasoning_methods": [
                "diverse-path generation",
                "step-aware verification"
            ],
            "reasoning_methods_description": "Generates multiple reasoning paths per question and uses a verifier to evaluate steps individually and vote for the best final answer.",
            "reasoning_diversity": "diverse",
            "reasoning_diversity_experimental_setup": "Mentioned as a contrasting/motivating method; not implemented in this paper's experiments.",
            "task_or_benchmark": "Mentioned in context of arithmetic/reasoning benchmarks (related work)",
            "performance_results": "",
            "qualitative_findings": "Cited as improving reasoning by exploring multiple solution paths and verifying step-level correctness; not evaluated in this study.",
            "explicit_comparison": false,
            "key_claims_or_conclusions": "Mentioned as an example of leveraging diverse reasoning paths and verification to improve LLM reasoning; not experimentally compared in this paper.",
            "uuid": "e8319.3",
            "source_info": {
                "paper_title": "Leveraging Large Language Models for Bengali Math Word Problem Solving with Chain of Thought Reasoning",
                "publication_date_yy_mm": "2025-05"
            }
        },
        {
            "name_short": "SelfConsistency",
            "name_full": "Self-consistency decoding",
            "brief_description": "A decoding strategy that samples multiple reasoning paths and selects the most consistent final answer across generated chains.",
            "citation_title": "Self-consistency improves chain of thought reasoning in language models",
            "mention_or_use": "mention",
            "model_name": "N/A (related work)",
            "model_description": "Referenced in related work as a method that improves CoT by sampling many chains-of-thought and choosing the majority/most consistent answer.",
            "reasoning_methods": [
                "self-consistency (multiple-chain sampling + majority selection)"
            ],
            "reasoning_methods_description": "Produces diverse chains via sampling and aggregates final answers (or uses voting) to increase robustness.",
            "reasoning_diversity": "diverse",
            "reasoning_diversity_experimental_setup": "Mentioned as an alternative/augmentation to CoT; not used in the paper's experiments.",
            "task_or_benchmark": "Referenced with arithmetic reasoning benchmarks (related work)",
            "performance_results": "",
            "qualitative_findings": "Cited as valuable for improving CoT reliability; not applied or ablated here.",
            "explicit_comparison": false,
            "key_claims_or_conclusions": "Paper cites self-consistency as prior evidence that aggregating diverse reasoning paths can improve answer accuracy, but does not run self-consistency experiments.",
            "uuid": "e8319.4",
            "source_info": {
                "paper_title": "Leveraging Large Language Models for Bengali Math Word Problem Solving with Chain of Thought Reasoning",
                "publication_date_yy_mm": "2025-05"
            }
        },
        {
            "name_short": "LoRA-ablation",
            "name_full": "LoRA fine-tuning ablations",
            "brief_description": "Parameter-efficient fine-tuning (Low-Rank Adaptation) applied with multiple configurations (rank, dropout, batch-size) and reported as an ablation study.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "LLaMA-3 8B (example target for LoRA experiments)",
            "model_description": "LoRA applied to adapt models efficiently for Bengali MWPs by training low-rank adapter matrices while freezing base model weights; three LoRA configurations were compared.",
            "reasoning_methods": [
                "fine-tuning with CoT supervision (LoRA)"
            ],
            "reasoning_methods_description": "LoRA fine-tuning used CoT examples in training data; paper tested three configurations: Baseline (rank 16, no dropout), Higher Rank with Dropout (rank 32, dropout 0.1), and Memory-Efficient with Lower Batch Size (rank 32, lower batch size, gradient accumulation).",
            "reasoning_diversity": "similar",
            "reasoning_diversity_experimental_setup": "Ablation study (Table 5) comparing three LoRA configurations on SOMADHAN to measure effects of rank, dropout, batch size on final-answer accuracy.",
            "task_or_benchmark": "SOMADHAN",
            "performance_results": "LoRA results (Table 5): Baseline (Finetune 1) accuracy 13.0%; Higher Rank with Dropout (Finetune 2) 12.0%; Memory-Efficient with Lower Batch Size (Finetune 3) 17.0% (best LoRA config).",
            "qualitative_findings": "LoRA yields modest improvements but overall low absolute accuracy compared to prompting with large models; different LoRA hyperparameters substantially change results and risk overfitting; LoRA experiments indicate fine-tuning with few CoT examples is sensitive to config and training dynamics.",
            "explicit_comparison": true,
            "key_claims_or_conclusions": "LoRA can adapt models efficiently but in this study achieved limited accuracy on SOMADHAN; the memory-efficient lower-batch configuration performed best (17%), while higher rank with dropout underperformed (12%).",
            "uuid": "e8319.5",
            "source_info": {
                "paper_title": "Leveraging Large Language Models for Bengali Math Word Problem Solving with Chain of Thought Reasoning",
                "publication_date_yy_mm": "2025-05"
            }
        },
        {
            "name_short": "GPT-4o",
            "name_full": "GPT-4o (OpenAI)",
            "brief_description": "A very large multimodal OpenAI model used as a high-performing baseline for Bengali MWPs with and without CoT prompting.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "GPT-4o",
            "model_description": "Described as having very large parameter count (paper states ~1.3 trillion in one place) and strong generalization, evaluated in zero-shot and few-shot settings with standard and CoT prompting.",
            "reasoning_methods": [
                "standard prompting",
                "zero-shot CoT",
                "few-shot CoT"
            ],
            "reasoning_methods_description": "Evaluated with system instructions for CoT, few-shot examples with chains of thought, and standard prompts without intermediate steps; not fine-tuned in study (evaluated as-is).",
            "reasoning_diversity": "both",
            "reasoning_diversity_experimental_setup": "Compared standard vs CoT in zero-shot and few-shot; also compared to fine-tuned GPT-3.5 results.",
            "task_or_benchmark": "SOMADHAN (primary) and PatiGonit (secondary)",
            "performance_results": "SOMADHAN: standard zero-shot 79.0%, standard few-shot 80.0%; CoT zero-shot 80.4%, CoT few-shot 83.0%. PatiGonit few-shot 99.0%. Also reported non-fine-tuned GPT-4o zero-shot 79.2% in Table 6.",
            "qualitative_findings": "GPT-4o showed strong absolute performance and benefited from CoT (moderate gains), indicating large-capacity models gain from stepwise reasoning; CoT with few-shot gave best results. GPT-4o outperformed fine-tuned GPT-3.5.",
            "explicit_comparison": true,
            "key_claims_or_conclusions": "GPT-4o handles Bengali MWPs effectively and benefits from CoT prompting, but its high zero-shot competence reduces marginal gains from fine-tuning; CoT few-shot improved accuracy by a few percent.",
            "uuid": "e8319.6",
            "source_info": {
                "paper_title": "Leveraging Large Language Models for Bengali Math Word Problem Solving with Chain of Thought Reasoning",
                "publication_date_yy_mm": "2025-05"
            }
        },
        {
            "name_short": "GPT-3.5",
            "name_full": "GPT-3.5 Turbo (OpenAI)",
            "brief_description": "A large OpenAI model (~175B parameters) evaluated with standard prompting, CoT prompting, few-shot examples, and fine-tuning (standard fine-tuning with CoT examples).",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "GPT-3.5 Turbo-0125 (and turbo variants)",
            "model_description": "Evaluated in zero-shot and few-shot modes; also fine-tuned with 50 CoT examples (JSONL) with different epoch/lr settings (standard fine-tuning).",
            "reasoning_methods": [
                "standard prompting",
                "CoT prompting (zero/few-shot)",
                "standard fine-tuning with CoT supervision"
            ],
            "reasoning_methods_description": "Few-shot included five CoT exemplars; fine-tuning used 50 CoT examples and varied epochs and learning rates to encourage chain generation.",
            "reasoning_diversity": "both",
            "reasoning_diversity_experimental_setup": "Compared standard vs CoT in zero/few-shot; ran standard fine-tuning (50 examples) with different epochs and learning rates to observe gains.",
            "task_or_benchmark": "SOMADHAN and PatiGonit",
            "performance_results": "SOMADHAN: standard zero-shot 23.0%, standard few-shot 24.0%; CoT zero-shot 24.0%, CoT few-shot 30.0% (Prompt-1). Fine-tuned GPT-3.5 (lr=0.1, 10 epochs) achieved 23.4% (best fine-tune), with other epoch settings showing lower or plateaued performance.",
            "qualitative_findings": "GPT-3.5 shows modest gains from CoT and few-shot; fine-tuning with small CoT dataset gave limited improvements and was sensitive to epochs (overfitting/diminishing returns beyond 10 epochs). Performance remains far below top large models.",
            "explicit_comparison": true,
            "key_claims_or_conclusions": "CoT and few-shot help GPT-3.5 but yields modest absolute improvements; fine-tuning with limited CoT examples yields constrained gains and can plateau or degrade with more epochs.",
            "uuid": "e8319.7",
            "source_info": {
                "paper_title": "Leveraging Large Language Models for Bengali Math Word Problem Solving with Chain of Thought Reasoning",
                "publication_date_yy_mm": "2025-05"
            }
        },
        {
            "name_short": "LLaMA-3.3-70B",
            "name_full": "LLaMA-3.3 (70B)",
            "brief_description": "A 70B-parameter LLaMA-3 variant that achieved the highest reported accuracy on SOMADHAN when using few-shot CoT prompting.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "LLaMA-3.3 70B",
            "model_description": "70B parameter model from the LLaMA-3 family; evaluated with different prompt styles, zero/few-shot, and CoT prompting.",
            "reasoning_methods": [
                "standard prompting",
                "few-shot CoT",
                "zero-shot CoT"
            ],
            "reasoning_methods_description": "Used both standard and CoT prompts; best performance achieved with few-shot CoT and Prompt Style 2 (explicit few-shot CoT examples).",
            "reasoning_diversity": "both",
            "reasoning_diversity_experimental_setup": "Prompt-style ablation (Prompt-1 vs Prompt-2) and standard vs CoT; zero-shot vs few-shot comparisons reported.",
            "task_or_benchmark": "SOMADHAN",
            "performance_results": "Achieved highest accuracy on SOMADHAN: 87% with CoT few-shot (Prompt-1) and 88% with CoT few-shot (Prompt-2). Standard few-shot accuracy reported around 78%.",
            "qualitative_findings": "Large LLaMA variant benefits greatly from few-shot CoT (910% absolute improvement); CoT also improved language alignment to Bengali for this model. Smaller LLaMA variants did not share this benefit.",
            "explicit_comparison": true,
            "key_claims_or_conclusions": "LLaMA-3.3 (70B) demonstrates that a large but open/model-family LLM can match or exceed GPT-4o on Bengali MWP when combined with few-shot CoT and proper prompt style; CoT with few-shot is the most effective configuration for this model.",
            "uuid": "e8319.8",
            "source_info": {
                "paper_title": "Leveraging Large Language Models for Bengali Math Word Problem Solving with Chain of Thought Reasoning",
                "publication_date_yy_mm": "2025-05"
            }
        },
        {
            "name_short": "LLaMA-3-70B",
            "name_full": "LLaMA-3 (70B)",
            "brief_description": "A 70B-parameter LLaMA-3 base model evaluated with standard and CoT prompting; results indicate mixed CoT benefits depending on prompt style.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "LLaMA-3 70B",
            "model_description": "70B-parameter LLaMA model; evaluated in zero-shot and few-shot with/without CoT under two prompt styles.",
            "reasoning_methods": [
                "standard prompting",
                "CoT prompting"
            ],
            "reasoning_methods_description": "Standard prompting and CoT tested; Prompt style affected outcomes and language of outputs (English vs Bengali).",
            "reasoning_diversity": "both",
            "reasoning_diversity_experimental_setup": "Compared standard vs CoT for Prompt Style 1 and 2, zero-shot vs few-shot.",
            "task_or_benchmark": "SOMADHAN",
            "performance_results": "Prompt-1: standard zero-shot 76% (but responses in English); CoT zero-shot/few-shot dropped to 65%. Prompt-2: CoT few-shot improved to 73% vs 67% standard prompting (a 6% improvement).",
            "qualitative_findings": "Performance sensitive to prompt style and language adaptation: Prompt-1 yielded higher standard accuracy but English outputs; Prompt-2 enabled better Bengali outputs and CoT gains. CoT helped in some prompt setups but harmed in others.",
            "explicit_comparison": true,
            "key_claims_or_conclusions": "Effectiveness of CoT depends on prompt design and language alignment; for LLaMA-3 (70B) Prompt-2+CoT yielded improvements, while Prompt-1 showed opposite trends.",
            "uuid": "e8319.9",
            "source_info": {
                "paper_title": "Leveraging Large Language Models for Bengali Math Word Problem Solving with Chain of Thought Reasoning",
                "publication_date_yy_mm": "2025-05"
            }
        },
        {
            "name_short": "LLaMA-3-8B",
            "name_full": "LLaMA-3 (8B)",
            "brief_description": "An 8B-parameter LLaMA-3 variant that struggled with CoT prompting on Bengali MWPs and often lost accuracy under CoT.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "LLaMA-3 8B",
            "model_description": "Smaller-capacity LLaMA-3 model evaluated with standard and CoT prompting in zero-shot and few-shot modes.",
            "reasoning_methods": [
                "standard prompting",
                "CoT prompting"
            ],
            "reasoning_methods_description": "Same CoT and standard protocols as larger models; few-shot included five CoT examples.",
            "reasoning_diversity": "both",
            "reasoning_diversity_experimental_setup": "Direct comparison across prompting conditions; also evaluated for language output mismatch (English vs Bengali).",
            "task_or_benchmark": "SOMADHAN",
            "performance_results": "Prompt-1: standard zero-shot 47% (best); CoT decreased to 24% zero-shot and 19% few-shot. Prompt-2: similar pattern of no improvement with CoT; did not generate Bengali reliably in some cases.",
            "qualitative_findings": "Smaller model capacity limits benefit from CoT; CoT often hurt performance and sometimes caused language/output issues. Indicates that CoT requires sufficient model capacity to be effective.",
            "explicit_comparison": true,
            "key_claims_or_conclusions": "CoT is not universally beneficial: for smaller LLaMA variants CoT reduced accuracy on Bengali MWPs; model size is a critical factor for CoT efficacy.",
            "uuid": "e8319.10",
            "source_info": {
                "paper_title": "Leveraging Large Language Models for Bengali Math Word Problem Solving with Chain of Thought Reasoning",
                "publication_date_yy_mm": "2025-05"
            }
        },
        {
            "name_short": "Deepseek-distill-qwen",
            "name_full": "Deepseek-r1-distill-qwen-32B",
            "brief_description": "A distilled 32B Qwen model in Deepseek's family evaluated for CoT and standard prompting; showed moderate gains with CoT but produced English outputs in experiments.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "Deepseek-r1-distill-qwen-32B",
            "model_description": "A distilled variant of Qwen-32B optimized for efficiency; evaluated in zero/few-shot and CoT/standard prompting.",
            "reasoning_methods": [
                "standard prompting",
                "few-shot CoT"
            ],
            "reasoning_methods_description": "Compared standard few-shot prompting to CoT few-shot; language of response noted as English even when evaluated on Bengali dataset.",
            "reasoning_diversity": "both",
            "reasoning_diversity_experimental_setup": "Prompt-style comparisons with Prompt-2 reported; measured effect of CoT few-shot vs standard few-shot.",
            "task_or_benchmark": "SOMADHAN",
            "performance_results": "Prompt-2: standard few-shot 44% -&gt; CoT few-shot 51% (gain +7%), but responses were in English.",
            "qualitative_findings": "CoT improved numeric accuracy but language mismatch (English outputs) reduces usefulness for Bengali-specific applications; shows CoT gains can exist even when language adaptation fails.",
            "explicit_comparison": true,
            "key_claims_or_conclusions": "Distilled models can improve with CoT, but achieving language alignment (Bengali output) remains an orthogonal challenge.",
            "uuid": "e8319.11",
            "source_info": {
                "paper_title": "Leveraging Large Language Models for Bengali Math Word Problem Solving with Chain of Thought Reasoning",
                "publication_date_yy_mm": "2025-05"
            }
        },
        {
            "name_short": "Deepseek-distill-llama",
            "name_full": "Deepseek-r1-distill-llama-70B",
            "brief_description": "A distilled LLaMA-70B variant from Deepseek that showed improved accuracy with CoT few-shot and produced Bengali outputs.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "Deepseek-r1-distill-llama-70B",
            "model_description": "Distilled LLaMA-70B optimized for efficiency; evaluated with prompt-style variants and CoT few-shot.",
            "reasoning_methods": [
                "standard prompting",
                "few-shot CoT"
            ],
            "reasoning_methods_description": "Evaluated standard vs CoT few-shot (Prompt-2); CoT included step-wise exemplars.",
            "reasoning_diversity": "both",
            "reasoning_diversity_experimental_setup": "Prompt-2 comparisons; measured language output and accuracy changes due to CoT.",
            "task_or_benchmark": "SOMADHAN",
            "performance_results": "Prompt-2: standard few-shot 60% -&gt; CoT few-shot 66% (+6%), responses were in Bengali.",
            "qualitative_findings": "Distilled LLaMA retained Bengali output quality and benefited from CoT; shows distillation does not preclude CoT gains if language alignment maintained.",
            "explicit_comparison": true,
            "key_claims_or_conclusions": "Distilled large models can benefit from CoT and maintain Bengali output when properly configured; CoT yields clear accuracy gains here.",
            "uuid": "e8319.12",
            "source_info": {
                "paper_title": "Leveraging Large Language Models for Bengali Math Word Problem Solving with Chain of Thought Reasoning",
                "publication_date_yy_mm": "2025-05"
            }
        },
        {
            "name_short": "Qwen-2.5-32B",
            "name_full": "Qwen-2.5 32B",
            "brief_description": "A 32B-parameter Qwen-family model evaluated with CoT and standard prompting and showing moderate CoT gains.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "Qwen-2.5-32B",
            "model_description": "Large multi-task Qwen model evaluated on Bengali MWPs with prompt-style ablations; tested with CoT few-shot.",
            "reasoning_methods": [
                "standard prompting",
                "few-shot CoT"
            ],
            "reasoning_methods_description": "Prompt-2 few-shot CoT with five CoT exemplars compared to standard few-shot prompting.",
            "reasoning_diversity": "both",
            "reasoning_diversity_experimental_setup": "Prompt-style comparison showing CoT advantage for this model.",
            "task_or_benchmark": "SOMADHAN",
            "performance_results": "Prompt-2: standard few-shot 68% -&gt; CoT few-shot 71% (+3%).",
            "qualitative_findings": "Qwen-2.5 benefits modestly from CoT; language output alignment achieved for some Qwen variants while others (Qwen-qwq) output English only.",
            "explicit_comparison": true,
            "key_claims_or_conclusions": "Moderate CoT gains indicate CoT is beneficial across architectures, magnitude depends on model and prompt style.",
            "uuid": "e8319.13",
            "source_info": {
                "paper_title": "Leveraging Large Language Models for Bengali Math Word Problem Solving with Chain of Thought Reasoning",
                "publication_date_yy_mm": "2025-05"
            }
        },
        {
            "name_short": "SOMADHAN",
            "name_full": "SOMADHAN (Bengali Grade School Math dataset)",
            "brief_description": "A new dataset introduced in this paper: 8,792 Bengali math word problems with human-written step-by-step (CoT) solutions intended to evaluate reasoning in low-resource language settings.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "dataset (task)",
            "model_description": "Derived from GSM8K via manual translation and annotation into Bengali, includes 4,000 manually annotated CoT examples so far (ongoing annotation) and designed to evaluate multi-step reasoning.",
            "reasoning_methods": [
                "chain-of-thought supervision (human-provided)",
                "equation supervision (for PatiGonit secondary dataset)"
            ],
            "reasoning_methods_description": "Each example contains intermediate reasoning steps (s_1...s_k) and a final result r_true; paper evaluates only final-answer correctness but uses the CoT annotations for few-shot and fine-tuning.",
            "reasoning_diversity": "both",
            "reasoning_diversity_experimental_setup": "Used as primary benchmark to compare standard prompting vs CoT prompting, zero-shot vs few-shot, prompt-style ablations, and LoRA fine-tuning configurations.",
            "task_or_benchmark": "SOMADHAN - 8,792 Bengali MWPs with CoT; PatiGonit used as complementary equation-based dataset.",
            "performance_results": "Top model performance on SOMADHAN: LLaMA-3.3 (70B) CoT few-shot 88% (Prompt-2); GPT-4o CoT few-shot ~83%; many models reported wide spread of accuracies (from single-digit LoRA fine-tuned results up to ~88%).",
            "qualitative_findings": "Dataset enables direct evaluation of CoT prompting benefits in a low-resource language; models often produce English answers or fail to adapt language even when reasoning improves; only final-answer accuracy was measured despite availability of CoT steps.",
            "explicit_comparison": true,
            "key_claims_or_conclusions": "Introducing SOMADHAN enabled demonstration that CoT prompting and few-shot exemplars substantially improve large-model performance on Bengali MWPs, highlighting need for CoT supervision and language adaptation.",
            "uuid": "e8319.14",
            "source_info": {
                "paper_title": "Leveraging Large Language Models for Bengali Math Word Problem Solving with Chain of Thought Reasoning",
                "publication_date_yy_mm": "2025-05"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Chain-of-thought prompting elicits reasoning in large language models",
            "rating": 2,
            "sanitized_title": "chainofthought_prompting_elicits_reasoning_in_large_language_models"
        },
        {
            "paper_title": "Self-consistency improves chain of thought reasoning in language models",
            "rating": 2,
            "sanitized_title": "selfconsistency_improves_chain_of_thought_reasoning_in_language_models"
        },
        {
            "paper_title": "Lora: Low-rank adaptation of large language models",
            "rating": 2,
            "sanitized_title": "lora_lowrank_adaptation_of_large_language_models"
        },
        {
            "paper_title": "GSM8K (Grade School Math) dataset",
            "rating": 2,
            "sanitized_title": "gsm8k_grade_school_math_dataset"
        },
        {
            "paper_title": "On the advance of making language models better reasoners",
            "rating": 1,
            "sanitized_title": "on_the_advance_of_making_language_models_better_reasoners"
        }
    ],
    "cost": 0.02295775,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>LEVERAGING LARGE LANGUAGE MODELS FOR BENGALI MATH WORD PROBLEM SOLVING WITH CHAIN OF THOUGHT REASONING
July 31, 2025</p>
<p>Bidyarthi Paul bidyarthipaul01@gmail.com 
Department of Computer Science and Engineering
Ahsanullah University of Science and Technology Tejgaon
Dhaka</p>
<p>Jalisha Jashim 
Department of Computer Science and Engineering
Ahsanullah University of Science and Technology Tejgaon
Dhaka</p>
<p>Mirazur Rahman Zim 
Department of Computer Science and Engineering
Ahsanullah University of Science and Technology Tejgaon
Dhaka</p>
<p>Sattar Aothoi 
Department of Computer Science and Engineering
Ahsanullah University of Science and Technology Tejgaon
Dhaka</p>
<p>Faisal Muhammad Shah faisal.cse@aust.edu 
Department of Computer Science and Engineering
Ahsanullah University of Science and Technology Tejgaon
Dhaka</p>
<p>LEVERAGING LARGE LANGUAGE MODELS FOR BENGALI MATH WORD PROBLEM SOLVING WITH CHAIN OF THOUGHT REASONING
July 31, 2025AE992444E3D1C4C746F883C538052C10arXiv:2505.21354v2[cs.CL]
Solving Bengali Math Word Problems (MWPs) remains a major challenge in natural language processing (NLP) due to the language's low-resource status and the multi-step reasoning required.Existing models struggle with complex Bengali MWPs, largely because no human-annotated Bengali dataset has previously addressed this task.This gap has limited progress in Bengali mathematical reasoning.To address this, we created SOMADHAN, a dataset of 8792 complex Bengali MWPs with manually written, step-by-step solutions.We designed this dataset to support reasoning-focused evaluation and model development in a linguistically underrepresented context.Using SOMADHAN, we evaluated a range of large language models (LLMs)-including GPT-4o, GPT-3.5 Turbo, LLaMA series models, Deepseek, and Qwen-through both zero-shot and few-shot prompting with and without Chain of Thought (CoT) reasoning.CoT prompting consistently improved performance over standard prompting, especially in tasks requiring multi-step logic.LLaMA-3.3 70B achieved the highest accuracy of 88% with few-shot CoT prompting.We also applied Low-Rank Adaptation (LoRA) to fine-tune models efficiently, enabling them to adapt to Bengali MWPs with minimal computational cost.Our work fills a critical gap in Bengali NLP by providing a high-quality reasoning dataset and a scalable framework for solving complex MWPs.We aim to advance equitable research in low-resource languages and enhance reasoning capabilities in educational and language technologies.</p>
<p>Introduction</p>
<p>In this era, Question Answering (QA) systems are vital in Natural Language Processing (NLP).They are designed to understand and respond to user queries in a human-like manner, crucial for applications like search engines and virtual assistants ( [1], [2]).Improving these systems are essential due to the growing demand for quick and accurate information retrieval.The structure of QA systems varies with the domain and question types ( [3], [4]), with Math Word Problems (MWPs) being a notable subtype.</p>
<p>MWPs pose significant challenges in QA systems ( [5], [6], [7], [8], [9], [10]), requiring more than basic pattern recognition.They involve understanding mathematical operators, quantities, and their relationships to produce a solution equation.This process entails identifying numerical values, selecting appropriate operations, and forming mathematical expressions with unknown variables.Efforts to teach computers to solve MWPs date back to the 1960s, with researchers employing rule-based methods to mimic human problem-solving strategies [11].Recent advancements in NLP and machine learning have significantly improved the ability to tackle MWPs, particularly for simpler problems.</p>
<p>Chain-of-Thought Prompting</p>
<p>While machine learning and transformer-based models excel at solving simpler MWPs ( [12]), they often struggle with problems that require reasoning and multi-step solutions ( [13]).These MWPs demand understanding complex relationships between quantities and applying mathematical principles sequentially, which many models fail to handle effectively.Language models perform well in NLP tasks, but their reasoning abilities are limited, which cannot be solved by increasing model size ( [14]).Prompting-based tools fix this with QA tasks.A study( [15]) introduced CoT (Chain-of-Thought) prompting, which generates short sentences that mimic human problem-solving.</p>
<p>When solving a complex reasoning task, such as a multi-step math word problem, it is natural to break the problem into smaller intermediate steps and solve each one sequentially before arriving at the final answer.For instance: "After Era gives 2 lichies to her mom, she has 10 left.Then, after giving 3 to her dad, she has 7 left.So, the answer is 7." A chain of thought is a series of intermediate natural language reasoning steps that lead to the final output, and we refer to this approach as chain-of-thought prompting ( [15]).Recent advancements on chain-of-thought prompting, have shown promise in enhancing the reasoning capabilities of large language models for solving complex MWPs.Chain-of-thought prompting involves breaking down a problem into intermediate reasoning steps, which are then solved sequentially to reach the final answer.A comparison between Standard Prompting and Chain-of-Thought (CoT) Prompting for solving math word problems (MWPs) using a language model is shown in Figure 1.In Standard Prompting, the model is presented with the question directly, without any reasoning steps, leading to incorrect answers due to a lack of logical breakdown.In contrast, CoT Prompting provides a step-by-step explanation, allowing the model to reason through the problem logically and arrive at the correct solution.By breaking the problem into smaller parts and solving it systematically, CoT significantly improves the model's ability to handle complex reasoning tasks, as demonstrated by the accurate outputs in the CoT example.</p>
<p>Studies ( [15]) have demonstrated that incorporating chain-of-thought reasoning into few-shot prompting significantly improves model performance on tasks such as math word problems, commonsense reasoning, and symbolic manipulation.By leveraging this method, large language models can better handle the intricate reasoning required for complex MWPs.</p>
<p>The challenge is even greater for low-resource languages like Bengali, where limited datasets and linguistic complexities further hinder the development of reasoning-based solutions.Bengali is a low-resource language for Math Word Problem (MWP) solving using Large Language Models, with 272.7 million speakers and seventh worldwide( [16]).Bengali language processing tools and models are difficult to develop due to a lack of datasets, linguistic resources, standardization, and dialectal variations, which hinders LLMs for MWPs solving.</p>
<p>In this study, we introduce a new dataset, SOMADHAN (Solution), which focuses on complex Bengali math word problems and includes intermediate reasoning steps (chain of thought) for each solution.We create this dataset to address the lack of high-quality, human-annotated resources for Bengali MWPs, a gap that severely limits the development and evaluation of reasoning-capable language models in low-resource languages.Unlike existing datasets, which are either automatically translated or limited to final-answer supervision, SOMADHAN provides detailed, step-by-step logical reasoning, enabling models to learn and demonstrate multi-step problem-solving-an essential skill for real-world mathematical understanding.Additionally, we utilized the publicly available "PatiGonit" dataset from a Github repository, which contains equation-based simple MWPs, to analyze models' ability to handle simple MWPs.These two datasets highlight the limitations of large language models, which can only solve straightforward math problems but struggle with complex ones requiring reasoning.Our proposed pipeline for Chain-of-Thought prompting, built on the SOMADHAN dataset, addresses this challenge by enabling large language models to tackle more reasoningintensive tasks.Several large language models, including GPT-4o [17], GPT-3.5 Turbo-16k [18], Llama-3 8B and 70B [19], llama-3.1-70b-versatileand 8b [19],llama-3.2-1b-previewand llama-3.2-3b-preview[19], llama-3.2-90b-textpreview[19], llama-3.3-70b[19], deepseek-r1-distill-qwen-32b, [20], deepseek-r1-distill-llama-70b [20], qwen-2.5-32b,and qwen-qwq-32b [21] were evaluated for their ability to generate intermediate steps and equations.Chain-of-thought (CoT) prompting consistently outperformed standard prompting.Among all the models evaluated, Llama-3.3 with CoT and few-shot prompting achieved the highest accuracy of 88%, outperforming all other models in both zero-shot and few-shot settings.GPT-4o showed strong performance in COT with few-shot learning across both datasets.For further experiments, we introduced LoRA (Low-Rank Adaptation) fine-tuning.LoRA was employed to adapt the models efficiently by modifying only a small subset of parameters, making it computationally and memory efficient.The goal of using LoRA was to see how well it could enhance the performance of large models like Llama-3 (8B) for the specific structure of Bengali math word problems while retaining their versatility for other general tasks.</p>
<p>The following are the main contributions of our study:</p>
<p> Developed SOMADHAN dataset containing 8,792 complex Bengali Math Word Problems with their corresponding step by step solutions.</p>
<p> Introduced a pipeline for applying chain-of-thought prompting using the SOMADHAN dataset, enabling large language models to handle complex reasoning tasks effectively.</p>
<p> Introduced two Prompts to solve Complex Bengali Math Word Problems that requires reasoning steps.</p>
<p> Performed a comparative analysis of GPT-4o, GPT-3.5 Turbo-16k, Llama-3 8B and 70B, llama-3.1-70bversatile,llama-3.1-8b,llama-3.2-1b-preview,llama-3.2-3b-preview,llama-3.2-90b-text-preview,llama-3.3-70b,deepseek-r1-distill-qwen-32b, deepseek-r1-distill-llama-70b, qwen-2.5-32b,and qwen-qwq-32b demonstrating the strengths of zero-shot prompting, few-shot prompting and fine-tuning to solve MWPs.</p>
<p> Employed Low-Rank Adaptation (LoRA) to efficiently fine-tune large language models for Bengali math word problems, optimizing performance with minimal computational overhead.</p>
<p>Related Works</p>
<p>In this section, we discuss works related to our study.During our exploration, we found that no prior work has focused on solving Bengali Math Word Problems (MWPs) with Chain of Thoughts reasoning.However, there have been several studies on solving MWPs in English, which we categorize into six main approaches: Traditional Deep Learning Approaches, Transformer-Based Approaches, Hybrid and Ensemble Models, Methods utilizing intermediate steps, Prompting-based approaches, and Chain-of-Thought (CoT) Reasoning Approaches.Each of these categories is discusses in the following sections.</p>
<p>Traditional Deep Learning Approaches</p>
<p>These methods are increasingly being used to reduce manual effort and to enhance the performance of MWP solvers.One recent study [22] proposed a Bengali Word Problem dataset and set a Benchmark Evaluation for it using transformer and different Neural Machine Translation Models.97.30% accuracy was achieved via mT5.Another notable method involves using Sequence-to-Sequence (Seq2Seq) models to improve MWP solvers.A study by [23] proposed a Seq2Seq RNN model to solve math word problems (MWPs), integrating a GRU-based encoder, LSTM-based decoder, and a similarity-based retrieval mechanism for improved accuracy.While the model achieved 58.1% accuracy on Math23k and 16.1% on Alg514, the hybrid approach boosted performance to 64.7% and 70.1%, respectively.However, it struggled with diverse datasets and failed to generate novel equation templates.To address this, another study by [24] introduced equation normalization and explored Seq2Seq In another approach, [27] introduced the Graph-to-Tree (Graph2Tree) model, using graph-based encoders and tree-based decoders to effectively capture numerical relationships.It achieved accuracies of 83.7% on MAWPS and 77.4% on Math23k, addressing prior gaps in quantity reasoning.Similarly, [28] utilized BiGraphSAGE encoders and tree-based decoders in their Graph2Tree model, achieving 78.8% on MAWPS and 69.65% on MathQA but faced challenges in fully incorporating structural reasoning.</p>
<p>To further enhance MWP solvers, [29] proposed a multi-encoder, multi-decoder framework combining sequence-based and graph-based encoders with sequence and tree decoders.This approach improved equation generation and achieved 78.4% on the Math23k test set but still had gaps in leveraging textual structure.In another advancement, [30] introduced MWP-BERT, a numeracy-augmented pre-trained language model tailored for MWPs, achieving state-of-the-art results of 84.7% on Math23k, 76.2% on MathQA, and 91.2% on Ape-clean.Separately, [31] presented BERT, a bidirectional pre-trained model for language understanding, achieving 93.2% on SQuAD v1.1 and 83.1% on SQuAD v2.0.Building upon BERT, [32] enhanced it with RoBERTa by removing Next Sentence Prediction (NSP), applying dynamic masking, and using larger datasets, achieving state-of-the-art results like 90.2% on MNLI and 96.4</p>
<p>In a generative learning context, [33] introduced GPT-2, a generative pre-trained transformer excelling in zero-shot learning tasks, with notable performance on datasets such as LAMBADA (63.2%).For rule-based reasoning, [34] presented RuleTakers for reasoning over natural language rules, achieving 99% on synthetic datasets and over 90% on hand-authored rules, though paraphrased reasoning remained a challenge.Extending this work, [35] proposed RuleBERT, fine-tuning RoBERTa for probabilistic logic reasoning, achieving up to 99% accuracy on overlapping rules.Finally, [36] introduced EVR, a T5-based model for explainable reasoning, excelling in multi-hop tasks with interpretable steps, achieving 97.0% on DU5 and up to 98.1% on Birds-Electricity tasks.These advancements demonstrate significant progress in NLP for MWPs, reasoning, and language understanding across diverse datasets.</p>
<p>Transformer-Based Approaches</p>
<p>In a recent study, [37]  In another contribution, [38] introduced a novel approach for improving MWP solvers by generating linguistic variants of problem statements using GPT-3.These paraphrased problems were solved using a DeBERTa-based solver, with majority voting employed for final predictions.This approach addressed the lack of robustness in existing models to paraphrased problems.The method achieved accuracies of 91.0% on MAWPS, 79.1% on PARAMAWPS, and 63.5% on SVAMP.The datasets included MAWPS, PARAMAWPS, and SVAMP.</p>
<p>Hybrid and Ensemble Models</p>
<p>Hybrid models that combine different approaches have shown significant improvements.An ensemble model by [39] utilizing BiLSTM and LSTM with equation normalization achieved 69.2% accuracy on the Math23K dataset .In the paper [40] the GTS model, integrating GRU, TreeDecoder, and gated feedforward networks, achieved 74.3% on Math23K and 83.5% on the MAWPS single operation dataset.WARM has been introduced in [41] and it uses a weakly supervised approach with a bidirectional GRU encoder and three fully connected networks as the decoder, achieving 66.9% on All Arith and 56.0% on Math23K .[44] introduced the "Rationalize-Then-Predict" framework, a two-stage method aimed at improving model robustness in adversarial contexts by using rationalizers to extract relevant inputs before prediction.Although models like VIB and SPECTRA showed promise (e.g., 82.6% accuracy on FEVER), they remained vulnerable to strong attacks.In a related effort, [45] proposed BabbleLabble, a weak supervision approach leveraging natural language explanations and semantic parsers, achieving an F1 score of 50.1 on the Spouse dataset but facing challenges with noisy labels and generalization.Similarly, [46] highlighted the utility of intermediate annotations in reading comprehension, reporting 85% accuracy with Random Forest but acknowledging limited dataset diversity.Another study by [47] explored annotator rationales, improving SVM performance to 92.2% on the Polarity Dataset but identified issues with annotation quality and domain applicability.To address explanation integration, [48] developed REMOTE, which incorporated human-provided explanations to enhance language models, achieving 62.0% on HatEval and 92.7% on AmazonMusic, but faced scalability issues with labeled data.Further, [49] evaluated the utility of explanations for improving task performance, achieving 91.41% on e-SNLI while noting inconsistent benefits across tasks.Additionally, [50] introduced DREAM, which refined internal representations in QA models like Macaw, improving accuracy by 4% on CODAH but exposing limitations in coherent scene modeling.In a related context, [51] proposed Learning with Latent Language (L3) to parameterize multitask scenarios, showing promise in structured tasks like ShapeWorld (70% accuracy) but struggling with generalizing to abstract concepts.These studies collectively emphasize advancements in integrating explanations and rationales into AI systems while highlighting persistent challenges in scalability, robustness, and generalization.</p>
<p>In support of explanation-based modeling, [52] introduced the e-SNLI dataset, a natural language inference (NLI) benchmark that incorporates explanations, enabling models to predict decisions and justify them.Models like e-INFERSENT achieved 83.96% accuracy, while EXPLAIN THE PREDICT ATTENTION scored 81.71%, though reliance on spurious correlations in existing models revealed gaps in robustness.Moreover, [53] developed the CoS-E dataset and CAGE framework for commonsense reasoning, which improved model accuracy to 72.6% on the CoS-E dev split but highlighted limitations in explanation generation and dataset availability, underscoring the importance of leveraging annotated explanations for better interpretability.Finally, [54] proposed the Self-Taught Reasoner (STaR), which combines reasoning and rationalization with models like GPT-J and BERT, achieving notable accuracies, such as 72.6% on CommonsenseQA and GSM8K.However, STaR faced challenges in scalability, requiring significant resources for rationale generation and balancing the trade-off between accuracy and explainability.Collectively, these works highlight the potential of explanation-based approaches in enhancing transparency, reasoning, and trust in AI systems while identifying gaps in dataset availability and model generalization.</p>
<p>Prompting-Based Approaches</p>
<p>Recent advancements in prompting techniques have led to significant improvements in the performance of language models.Building on the concept of few-shot prompting introduced by [55], various methods have been explored to refine and optimize how models interact with input data.For example, [56] proposed automatic prompt learning techniques, enabling models to adapt their prompts based on the task at hand, rather than relying solely on predefined prompts.Additionally, studies such as those by [57], [58], and [59] have focused on providing models with task-specific instructions, allowing for better alignment with the desired output.</p>
<p>Another significant development in this area is the use of detailed task instructions, which has been shown to further enhance the performance of language models.In particular, [60], along with works by [57], [59], [58], and [61], emphasize that enriching input-output pairs with clear and specific guidance helps improve model understanding and reasoning, especially in complex tasks like math word problems.This trend of augmenting prompts with additional context and instructions has been pivotal in achieving state-of-the-art results in various natural language processing tasks, demonstrating the importance of prompt design in optimizing model behavior.</p>
<p>Chain-of-Thought (CoT) Reasoning Approaches</p>
<p>Chain of Thought (CoT) prompting has become a widely adopted method for improving the performance of language models, especially in tasks requiring multi-step reasoning.By breaking down a complex problem into smaller, more manageable steps, CoT helps models generate clearer and more accurate answers.For example, [15] demonstrated that CoT prompting significantly outperforms traditional methods for solving math word problems (MWPs), enhancing both the accuracy of the results and the transparency of the model's reasoning process.</p>
<p>Building on this foundation, [42] introduced DIVERSE (Diverse Verifier on Reasoning Step), a framework designed to improve language model reasoning by generating diverse prompts.This approach explores multiple reasoning paths for the same question and uses a verifier to filter out incorrect answers through a weighted voting system.Importantly, DIVERSE focuses on evaluating each reasoning step individually rather than the entire chain, which further refines the model's decision-making process.In a related effort, [43] introduced the concept of self-consistency, a decoding strategy that selects the most consistent answer from multiple reasoning paths, providing another layer of validation.When applied to arithmetic reasoning benchmarks, self-consistency has been shown to enhance CoT prompting, yielding more accurate and reliable results.</p>
<p>Our study explores methods for solving Math Word Problems (MWPs), categorized into Deep Learning, Transformerbased, Hybrid, Prompting, and Chain-of-Thought (CoT) Reasoning approaches.The most significant gap identified in this study is the complete absence of prior work addressing Math Word Problems (MWPs) in the Bengali language.This highlights a critical underrepresentation of Bengali in existing research on mathematical reasoning and natural language processing.In contrast, for English datasets, traditional models like Seq2Seq and Graph2Tree advanced MWP solving but struggled with diverse datasets and reasoning structures.Transformer-based models, including MWP-BERT and GPT-3, achieved state-of-the-art results but faced robustness issues.Prompting and CoT methods improved multi-step reasoning by leveraging task-specific instructions and diverse reasoning paths.A summary of the existing works is given in Table 1.</p>
<p>Problem Description</p>
<p>The problem is best framed as a model's ability to solve complex math word problems by generating intermediate reasoning steps and a final result.Evaluation focuses solely on the correctness of the final result, disregarding intermediate steps.</p>
<p>Let, x denotes the input math word problem, f(x) denotes the output generated by the model, consisting of a sequence of intermediate reasoning steps followed by a final result r pred , and r true denotes the ground truth final result for the problem.</p>
<p>The model's output can be represented as:
f(x) = (s 1 , s 2 , ...... ,s k , r pred )
where s 1 , s 2 , ...... ,s k are the intermediate steps and r pred is the predicted final result.</p>
<p>Corpus Creation</p>
<p>As per our exploration, we found no publicly available dataset addresses complex Bengali Math Word Problems (MWPs) with detailed reasoning steps and human-verified solutions.While a few Bengali MWP datasets exist, they primarily rely on automated translation, which leads to poor linguistic quality and a lack of meaningful reasoning structure.These limitations make them unsuitable for training or evaluating models that aim to perform multi-step mathematical reasoning in Bengali.To address this gap, we developed a new Bengali math word problem dataset, SOMADHAN.This dataset has been meticulously manually annotated by expert annotators, ensuring higher accuracy and contextual relevance in solving complex math problems with reasoning steps and solutions.This dataset focuses on problems that require advanced reasoning and step-by-step solutions, designed to facilitate the evaluation of large language models' reasoning capabilities.Figure 2 illustrates the pipeline we employed to develop the SOMADHAN dataset.required a substantial collection of problems reflecting complex reasoning processes.As a foundation, we utilized the publicly available GSM8K (Grade School Math)1 dataset [13], which contains a diverse set of English grade school math problems.GSM8k has four parts: train, train socratic, test, and test socratic.But specifically, we leveraged the train and test portions, comprising a total of 8,792 questions and solutions.GSM8K was selected for its comprehensive coverage of grade school math concepts, making it an ideal base for developing our dataset.Inspired by GSM8K, we created SOMADHAN (Bengali Grade School Math).Our dataset comprises of 8,792 Bengali Math Word Problems along with their step by step solutions.</p>
<p>GSM8K</p>
<p>PatiGonit Dataset: The second dataset used in this study, PatiGonit, was publicly available and collected from a Github repository.It consists of 10,000 simple Bengali math word problems, each paired with a corresponding equation as the solution.The dataset primarily focuses on elementary school-level problems, encompassing basic arithmetic and some introductory algebraic challenges.The problems are organized into two columns: one for the word problem and the other for the corresponding mathematical equation.PatiGonit serves as a valuable resource for analyzing simple equation-based math word problems.</p>
<p>Data Translation</p>
<p>In this section, we describe the dataset translation process for the SOMADHAN dataset.Manual data translation is inherently challenging as it requires not only linguistic accuracy but also the preservation of contextual meaning, particularly for reasoning-based tasks in math word problems.Any loss of reasoning structure during translation could compromise the dataset's usability for downstream applications like reasoning evaluation and problem-solving.</p>
<p>To ensure the reasoning quality and contextual fidelity of the translated texts, we employed expert human translators for the manual translation process.Comprehensive guidelines were established to provide translators with clear instructions on preserving mathematical and contextual details.These predefined standards, combined with the translators' expertise and judgment, ensured the integrity and consistency of the translated dataset.</p>
<p>Translator Indentity</p>
<p>For the translation process, we engaged professionals with expertise in English-to-Bengali translation to ensure that the translations were accurate, contextually consistent, and aligned with the reasoning requirements of the original texts.A team of five skilled individuals collaboratively worked on the translation task.The entire corpus of the SOMADHAN dataset was evenly distributed among them to ensure efficiency and maintain uniform quality across the translated content.The information regarding their expertise, experiments and other details are presented in Table 2.</p>
<p>Translation guidelines</p>
<p>To ensure accuracy, cultural relevance, and linguistic diversity, the following guidelines were established and provided to the translators:</p>
<p> Translations should retain the original meaning and reasoning of the text, ensuring that mathematical logic and contextual nuances are preserved. The Dollar symbol was consistently replaced with the Bengali Taka symbol to align with regional monetary conventions. English numerals were replaced with their Bengali counterparts to maintain consistency with the Bengali script. Individual names were replaced with culturally appropriate Bengali names.</p>
<p> Similarly, Location names, objects, and food names were substituted with Bengali equivalents to ensure cultural relevance while maintaining the problem's original structure and meaning.</p>
<p>Challenges During Translation</p>
<p>Even with the predefined guidelines, translators encountered several challenges during the translation process, which are summarized in Figure 3.</p>
<p>Dataset Statistics</p>
<p>The SOMADHAN dataset is composed of 8,792 Bengali math word problems with intermediate reasoning steps and their corresponding answers.Currently, the dataset includes 4,000 manually annotated samples, each containing step-by-step reasoning and a final answer.Annotation of the remaining problems is ongoing, and we plan to release the complete version in a future update.Once finalized, we will publish Version 2 of the dataset on Mendeley Data to ensure continued accessibility and reproducibility.A sample is shown in Figure 4.</p>
<p>The PatiGonit dataset on the other hand comprises 10,000 equation-based Bengali math word problems.The dataset contains a variation of simple and complex equations; simple equations are defined as those containing only one mathematical operation, while complex equations involve multiple operations.Sample of the dataset is shown in Figure 5.</p>
<p>Methodology</p>
<p>In this study, our methodology centers on the use of large language models (LLMs) for solving Bengali math word problems.Specifically, we examined the performance of LLMs by constructing tailored prompts, which were then input into the models via API configurations.The outputs were thoroughly analyzed to assess the effectiveness of the models in addressing the challenges posed by Bengali math word problems.This approach allows us to highlight the comparative advantages of using LLMs for these types of tasks.The study utilizes two distinct datasets to evaluate model performance.The primary dataset, SOMADHAN, was specifically designed for Bengali math word problems and incorporated Chain of Thought (CoT) prompting to guide the models through a logical, step-by-step reasoning process.This setup was intended to assess the ability of LLMs to solve more complex problems requiring multi-step reasoning.In contrast, the PatiGonit dataset was employed to investigate the performance of LLMs in solving simpler equation-based problems in compared to Reasoning-based problems.</p>
<p>Evaluation measures</p>
<p>For the SOMADHAN dataset, the evaluation process involved comparing the model's final answer against the correct answer.Only the accuracy of the final solution was considered relevant for assessment.On the other hand, for the PatiGonit dataset, the evaluation was based on matching the predicted equations with the actual equations, which was done manually.In both cases, the evaluation was performed through manual checks to ensure the correctness of the results, guaranteeing the reliability of the accuracy measurements for both datasets.</p>
<p>Proposed Approaches</p>
<p>A methodology was explored for solving Bengali math word problems, leveraging large language models (LLMs) to assess their performance and suitability for this complex task.</p>
<p>Large-Language Models</p>
<p>When using large language models (LLMs), we evaluated their performance through in-context zero-shot and few-shot prompting, emphasizing the Chain of Thought (CoT) approach for reasoning-intensive tasks.This method involved designing prompts that guided the models to provide step-by-step explanations, enhancing clarity and interpretability.Figure 6 illustrates the schematic diagram of our proposed prompting approach.</p>
<p>Additionally, we applied fine-tuning to structure the CoT prompting more effectively.To balance creativity and coherence, we set the temperature to one for all models, enabling them to generate mathematical equations with detailed, logical explanations.This approach fully leveraged the models' potential while ensuring the clarity and precision necessary to solve complex mathematical problems.Gpt-4o and Gpt-3.5 Turbo: GPT models, developed by OpenAI, are state-of-the-art large language models designed for a wide range of natural language processing tasks.Notable examples include GPT-4o [17] with trillions of parameters and GPT-3.5 Turbo [18] with approximately 175 billion parameters.These models are known for their unparalleled ability to understand and generate human-like text, handle complex instructions, and solve intricate tasks with high precision.</p>
<p>Their success stems from extensive training on diverse datasets and leveraging advanced attention mechanisms to capture contextual nuances.In mathematical problem-solving, GPT models excel by employing the Chain of Thought (CoT) approach, generating detailed intermediate reasoning steps that enhance logical accuracy and interpretability.By breaking problems into smaller, manageable parts, CoT ensures systematic reasoning and correct final results.This capability makes GPT models exceptionally effective for tasks requiring deep comprehension, step-by-step execution, and transparent problem-solving processes.</p>
<p>Llama (Large Language Model Meta AI): LLaMA (Large Language Model Meta AI) is a series of advanced language models developed by MetaAI.These models [19], including LLaMA-3 8B, LLaMA-3 70B, LLaMA-3.1 70B, LLaMA-3.1 8B, LLaMA-3.2 1B-preview, LLaMA-3.2 3B-preview, LLaMA-3.2 90B-text-preview, and LLaMA-3.3 70B, represent significant strides in NLP with their efficient scaling and fine-tuning capabilities.Unlike other large models, LLaMA focuses on optimizing performance through parameter-efficient designs, making them particularly effective for specific tasks even with smaller sizes.The LLaMA-3 series introduces improvements in token processing, context understanding, and task adaptability, demonstrating remarkable performance across a variety of benchmarks.</p>
<p>Despite having fewer parameters than GPT-4, LLaMA models excel in tasks like mathematical reasoning by leveraging optimized architectures and structured pre-training to produce accurate, coherent outputs.They effectively apply a structured reasoning approach inspired by the Chain of Thought (CoT) process, enabling step-by-step problem-solving by breaking complex tasks into intermediate steps.This systematic methodology allows LLaMA models to process and solve tasks efficiently while maintaining clarity and precision.Their ability to utilize CoT-style reasoning ensures reliable solutions and highlights their effectiveness in tackling challenges that demand logical progression and detailed analysis.</p>
<p>Deepseek: In addition to the LLaMA series, we also incorporated models from Deepseek and Qwen to further assess their performance in solving complex Bengali Math Word Problems (MWPs).The Deepseek-r1-distill-qwen-32B model [20] is a distilled version of the Qwen-32B model, specifically optimized for efficient performance while reducing computational overhead.This model leverages the distillation process, which involves training a smaller model to mimic the behavior of a larger model.Through this process, the Deepseek-r1-distill-qwen-32B retains the essential capabilities of the Qwen-32B model, allowing it to perform a wide range of natural language processing (NLP) tasks, including complex problem-solving.The distillation technique enhances the model's efficiency by significantly reducing the computational resources required for inference, making it a suitable choice for tasks involving complex mathematical reasoning.</p>
<p>Similarly, the Deepseek-r1-distill-llama-70B model [20] is a distilled variant of the LLaMA-70B model.This model is designed to achieve parameter efficiency while maintaining high levels of performance, particularly in tasks that require multi-step reasoning, such as solving math word problems.By distilling the larger LLaMA-70B model, the Deepseek-r1-distill-llama-70B maintains the essential performance characteristics of its predecessor while optimizing its computational resource usage.This balance between model performance and resource efficiency makes the Deepseek-r1-distill-llama-70B well-suited for handling the complex and computationally intensive nature of solving Bengali Math Word Problems.</p>
<p>Qwen: Additionally, we integrated Qwen models, specifically Qwen-2.5-32B[21] and Qwen-qwq-32B [21], both of which are robust models designed to handle multi-tasking and complex reasoning.The Qwen-2.5-32B model, with its 32 billion parameters, excels in addressing a wide range of natural language processing (NLP) challenges, including multi-step reasoning and complex mathematical computations.It has demonstrated impressive generalization capabilities across various benchmarks, particularly in tasks that require structured problem-solving.This model's architecture is specifically optimized to manage intricate problem-solving tasks, making it well-suited for Bengali Math Word Problems (MWPs).</p>
<p>Meanwhile, the Qwen-qwq-32B model further enhances the performance of the Qwen-2.5 by incorporating advanced optimizations that enhance its efficiency in solving mathematical problems.These optimizations improve the model's ability to handle tasks requiring deep reasoning and multi-step calculations, making it more efficient and accurate in complex problem-solving scenarios.Together, these models represent the latest advancements in large language models, offering significant improvements in the Bengali MWP-solving framework and contributing meaningfully to its effectiveness in solving computationally challenging problems.</p>
<p>Prompting Techniques</p>
<p>While working with large language models (LLMs), we aimed to make our instructions clear and easy to follow so the models could better understand our tasks and give accurate responses.This was important because LLMs often generate different answers depending on how the prompts are designed.Creating these prompts was a step-by-step process with challenges due to the way information is represented differently across models.Our study focused on improving instructions and prompts to guide the models in acting like math instructors and solving math problems with accurate solutions.We also created three sets of instructions and developed unique prompt styles for our proposed dataset.Effective prompting is particularly important for encouraging the models to adopt a Chain of Thought (CoT) approach.Chain-of-thought (CoT) prompting has several key advantages for improving how language models reason:</p>
<ol>
<li>
<p>Helps models break complex problems into smaller, easier steps, allowing them to focus on tasks that need more reasoning.</p>
</li>
<li>
<p>Gives us a clearer view of how the model arrives at an answer, making it easier to spot where the reasoning went wrong (though fully explaining a model's thinking is still challenging).</p>
</li>
<li>
<p>Can be used for various tasks, like solving math problems, understanding everyday situations, and manipulating symbols, and can potentially apply to any task that humans can solve using language.</p>
</li>
<li>
<p>CoT reasoning can be triggered in large language models by simply including examples of reasoning steps in a few-shot prompt.</p>
</li>
</ol>
<p>Zero Shot Prompting</p>
<p>Zero-shot prompting is particularly useful for testing a model's inherent capabilities and adaptability without the need for extra fine-tuning or example-based context.In our approach, we applied zero-shot prompting for both Chain-of-Thought (CoT) and standard prompting.For CoT, we provided clear chain-of-thought instructions that described the task and outlined the expected output, enabling the models to generate intermediate reasoning steps autonomously.This method encourages the LLMs to create their own context and refine their reasoning process, ultimately leading to more accurate and logical results.In contrast, for standard prompting, no prior instructions on solving the problem were given.The model was simply presented with the question, and it was expected to generate the answer without any guidance on breaking down the problem.To enhance the reasoning process, two separate system instructions were incorporated in our prompting techniques.Figure 7 and Figure 8 shows the two types of system instruction (Prompt-1 &amp; Prompt-2) for CoT with zero shot Prompting.Moreover, Figure 12 illustrates the system instruction that we have used for the standard prompting.</p>
<p>Few Shot Prompting</p>
<p>In our approach, we focused on leveraging few-shot learning, which has been shown to outperform zero-shot learning, as demonstrated in studies by [55] and [62].Unlike zero-shot, where no prior examples are provided, few-shot learning uses a small number of example prompts to guide the model's reasoning process.We conducted experiments with GPT-4, GPT-3.5, the LLaMA-3 series, Deepseek, and Qwen models, utilizing training data to enhance their performance.To optimize API costs, we manually included five few-shot prompts.For our two datasets, we designed distinct prompts.Several key steps were taken: we taught the model how to approach and reason through the task, followed by question-and-answer prompts for generating answers.In contrast to zero-shot prompting, which solely relies on the model's pre-existing knowledge without examples, our few-shot approach provides explicit examples of the task, allowing the model to adapt to the specific problem structure.Finally, math problem tests were conducted to assess the model's performance.Our method further augments each few-shot example by incorporating a chain of thought, improving accuracy and clarity in the results.In Figure 9, 10, and 11 we showcase examples of few-shot prompts for both of the datasets.Additionally, Figure 12 illustrates the system instruction that we have used for the standard prompting.</p>
<p>Fine Tuning</p>
<p>To further improve model performance on complex Bengali math word problems, we explore fine-tuning techniques tailored to reasoning-based tasks.In this section, we describe two approaches-standard fine-tuning using OpenAI's GPT-3.5 and parameter-efficient fine-tuning using Low-Rank Adaptation (LoRA)-both enhanced with chain-of-thought supervision.</p>
<p>Gpt-3.5 Standard Tuning</p>
<p>Fine-tuning [63] enhances few-shot learning by training on a larger set of examples, resulting in improved performance across various tasks.In this approach, we integrated chain of thought to encourage models to generate step-by-step reasoning in their solutions.Once a model is fine-tuned, fewer examples are required in the prompt, which reduces costs and enables faster response times.The fine-tuning process consists of the following steps, which differ from few-shot prompting: We chose to fine-tune the recommended model, GPT-3.5-turbo-0125.During this process, we varied only the number of epochs to optimize the model's performance.To build the fine-tuned model, we used 50 examples with appropriate instructions, including explicit chain-of-thought reasoning for complex problems.This ensured the model not only provided answers but also demonstrated the thought process behind solving math problems.The examples followed the JSONL file format as outlined in the OpenAI API documentation. Figure 13 shows an example of how the JSON file was structured to create the fine-tuned model.</p>
<p>Our SOMADHAN dataset required proper chain-of-thought reasoning to produce correct solutions, so fine-tuning was essential.The models were trained to break down complex problems into intermediate steps, ensuring that the reasoning behind the answers was explicit and interpretable.In contrast, the PatiGonit dataset only contains math word problem equations, which require less complex reasoning.For this dataset, GPT-3.5 Turbo and GPT-4 models performed well with few-shot prompting, so extensive fine-tuning was not necessary.</p>
<p>LoRA Fine Tuning</p>
<p>For SOMADHAN dataset, we employed Low-Rank Adaptation (LoRA) [64] for fine-tuning.LoRA improves finetuning by learning two smaller weight-updating matrices, allowing the large model to remain frozen while only the smaller matrices are updated with new data.After training, the updated matrices are recombined with the original weights to create the final model.This method significantly reduces the number of parameters and accelerates the
{"role":"assistant", "content": "                <em> =  |           </em> = &lt;&lt;2*=&gt;&gt; |            / = &lt;&lt;/=&gt;&gt; | ,  ++ = &lt;&lt;++=&gt;&gt;    #### 36"}] 2. . . . .</p>
<p>50.</p>
<p>Figure 13: Structure of JSON file format fine-tuning process while saving storage.As part of this process, we also integrated chain-of-thought examples into the fine-tuning dataset to encourage the model to generate logical, step-by-step reasoning.Figure 14 shows an overview of the process.6 Experimental Setup</p>
<p>To evaluate the performance of large language models on Bengali Math Word Problems, we designed a comprehensive experimental setup.This includes configuring the computational environment, organizing train-test splits for both datasets, and defining evaluation metrics tailored to reasoning-based and equation-based tasks.</p>
<p>Our work was conducted on Google Colab Notebook with Python 3.10.12,PyTorch 2.0.1, a Tesla T4 GPU (15 GB), 12.5 GB of RAM, and 64 GB of disk space.</p>
<p>Train-Test-Validation splits</p>
<p>For our SOMADHAN dataset's prompting and evaluation, we divided the dataset into two parts: 80% for testing and 20% for training.Specifically, 3200 examples were assigned for testing, while 800 examples were reserved for training.</p>
<p>Prompting and fine-tuning samples were taken from the training set, and evaluation was done using the testing set.The same splitting technique was applied for the PatiGonit dataset.However, due to token costs, only 1000 samples from the testing set were considered for evaluation in our experiments for both datasets.This decision allowed us to manage resource constraints effectively while still obtaining valuable insights into model performance.</p>
<p>Evaluation metrics SOMADHAN Dataset Evaluation</p>
<p>The model's output can be represented as:
f(x) = (s 1 , s 2 , ...... ,s k , r pred )
where s 1 , s 2 , ...... ,s k are the intermediate steps and r pred is the predicted final result.</p>
<p>For evaluation, the intermediate reasoning steps s 1 , s 2 , ...... ,s k are not considered.Only the final result r pred is compared with the ground truth r true :
Evaluation(f (x), r true ) = 1 if r pred = r true , 0 if r pred  = r true .(1)
The model is considered to have successfully solved the problem if: r pred = r true If the dataset contains N problems x 1 , x 2 , ...... , x N , the accuracy A is computed as:
A = 1 N N i=1 1(r pred,i = r true,i )
where 1() is the indicator function, which equals 1 if the condition is true and 0 otherwise.</p>
<p>PatiGonit Dataset Evaluation</p>
<p>We used equation accuracy, which compares the predicted equation with the correct equation rather than focusing on the final solution.This metric more effectively measures the model's ability to generate the correct equation, regardless of minor variations in the numerical result.By evaluating the structure of the equation itself, this method ensures that the model is solving the problem with the right logical steps, even if the final solution is not exactly the same.</p>
<p>The model's output can be represented as:
f(x) = (e pred )
where e pred is the equation generated by the model.</p>
<p>Evaluation focuses on comparing the predicted equation e pred with the ground truth equation e true .This approach ensures that the model generates the correct mathematical equation, which is the primary focus of our evaluation.</p>
<p>Result Analysis</p>
<p>The result analysis section provides a detailed evaluation of the model's performance on the SOMADHAN and PatiGonit datasets.We examined the accuracy to evaluate solution correctness to assess the effectiveness of our proposed approaches.</p>
<p>Chain of Thoughts based results</p>
<p>The results in Table 3 and !4 show key distinctions between Standard prompting and Chain of Thought (CoT) prompting, highlighting their respective strengths and weaknesses.In Table 3, the performance of six different large language models (LLMs) is compared across the SOMADHAN and PatiGonit datasets using both Standard prompting and Chain of Thought (CoT) prompting, with evaluations based on Zero-Shot and Few-Shot settings.Prompt Style-1 was used for the experiments in this table.The models include GPT-3.5, GPT-4o, and various versions of the Llama series.</p>
<p>Table 3: Performance comparison of Chain of Thoughts (CoT) prompting (Prompt-1) versus Standard prompting for various large language models on the "SOMADHAN" dataset.A benchmark has been set for the "PatiGonit" dataset using Few Shot prompting (Prompt-3) technique.All metrics are Accuracy (%).(*) represents that the accuracy is correct but the responses of the model was in English.The GPT-3.5 model achieves notable results in both zero-shot and few-shot settings.On the SOMADHAN dataset, it reaches 23.0% accuracy in zero-shot and 24.0% accuracy in few-shot using standard prompting.However, with Chain of Thought (CoT) prompting, GPT-3.5'sperformance improves, reaching 24.0% accuracy in zero-shot and 30.0% in few-shot, which is a significant increase of 6.0%.This indicates the effectiveness of the CoT approach for handling more complex tasks.It also performs decently in the PatiGonit dataset, achieving 86.0% with few-shot prompting.GPT-4o, with approximately 1.3 trillion parameters, demonstrates substantial improvements over GPT-3.5.For SOMADHAN, the model reaches 79.0% in zero-shot and 80.0% in few-shot using standard prompting.With CoT prompting, its performance dramatically improves, achieving 80.4% in zero-shot and 83.0% in few-shot, marking an impressive 3.0% increase in the few-shot setting.This shows that GPT-4o can handle complex reasoning tasks effectively with CoT.In the PatiGonit dataset, GPT-4o achieves 99.0% accuracy in few-shot, nearly perfect, emphasizing its advanced capabilities.</p>
<p>In the case of Llama-3 models with 70B and 8B parameters, the performance differs significantly between standard prompting and Chain of Thought (CoT) prompting.For Llama-3 (70B), the highest accuracy was achieved with standard prompting in the zero-shot setting, reaching 76% accuracy.However, it is important to note that all responses were in English, even though the dataset required responses in Bengali.When CoT prompting was applied, the accuracy dropped slightly to 65% in zero-shot and few-shot settings.Despite the decrease in accuracy, the responses shifted to Bengali, indicating that while CoT improved the language adaptation, it did not significantly improve the accuracy when compared to standard prompting.For Llama-3 (8B), the performance was considerably lower due to the reduced parameter size.The highest accuracy for Llama-3 (8B) was 47% using standard prompting in zero-shot, but when CoT was applied, the accuracy further decreased to 24% in zero-shot and 19% in few-shot.This suggests that smaller models like Llama-3 (8B) do not benefit as much from CoT prompting in case of Bengali as larger models do.In this case, CoT did not help improve accuracy significantly, and the language shift to Bengali did not overcome the challenges posed by the small parameter size.</p>
<p>For Llama-3.1 (70B), the highest accuracy was achieved using Chain of Thought (CoT) prompting with zero-shot, where it reached 80%.This represents a notable improvement of 2% over the standard zero-shot prompting, showcasing the positive impact of CoT on the model's performance.However, when few-shot prompting was applied along with CoT, the performance remained the same as with standard few-shot prompting, indicating that CoT did not contribute additional improvements in the few-shot setting for this model.For Llama-3.2 (90B), the best accuracy was also achieved with Chain of Thought prompting in the zero-shot setting, where it attained 79%.This marked a 4% increase in accuracy compared to standard zero-shot prompting, highlighting the benefit of CoT for this model.However, when few-shot prompting was used in combination with CoT, the accuracy declined by 3% compared to standard few-shot prompting, suggesting that while CoT improved performance in the zero-shot setting, it did not have a similar positive effect in the few-shot setting for this model.For Llama-3.3 (70B), the highest accuracy of 87% was achieved on the Somadhan dataset, outperforming the other models.Without the application of Chain of Thought (CoT), the model achieved its highest accuracy of 78% using standard prompting.However, when CoT was applied with few-shot prompting, the model's performance significantly improved by 9%, reaching the peak accuracy of 87%.This demonstrates the considerable enhancement that CoT along with few shot can provide, especially in tasks involving more complex reasoning, and highlights Llama-3.3 as the top-performing model in this comparison.</p>
<p>In particular, the Llama-3 (70B) and Llama-3 (8B) models exhibited a noticeable drop in performance when using CoT for Bengali language tasks.Despite their strong performance in English, the models struggled to achieve comparable results in Bengali, likely due to the complexity of language-specific reasoning in CoT and their relatively smaller parameter sizes.While CoT improved the performance for larger models like GPT-4o, the benefits for Llama-3 models were more modest, especially in few-shot settings.This disparity highlights the importance of model size and prompt style in achieving optimal performance.To address these challenges, we decided to apply a different prompt style (Prompt Style 2) on the same dataset to investigate whether it could provide a more effective approach, particularly for the Llama models when handling Bengali language tasks.This experiment aims to explore potential improvements and provide better insights into the effectiveness of CoT in multilingual settings.In Table 4, we incorporated Prompt Style 2 to further analyze the performance of various LLM models on the SOMADHAN dataset, comparing standard prompting with Chain of Thoughts (CoT) prompting in both zero-shot and few-shot settings.The aim of this experiment was to determine whether Prompt Style 2 could improve accuracy, particularly for Llama series models and newer models from the Deepseek and Qwen series.</p>
<p>For the Deepseek-r1-distill-qwen model, the highest accuracy of 51% was achieved with CoT and few-shot prompting, showing a significant improvement over the 44% accuracy observed with standard few-shot prompting.However, it is important to note that all responses were in English, which deviates from the desired output in Bengali.Even with Chain of Thought and few-shot prompting, the response language format could not be improved.Similarly, the Deepseek-r1-distill-llama model achieved an impressive 66% accuracy with CoT and few-shot prompting, a 7% increase over the standard few-shot performance of 60%.Unlike the previous Deepseek model, this model's responses were in Bengali, aligning with the intended language output.</p>
<p>For the Qwen-2.5 model with 32 billion parameters, the highest accuracy of 71% was achieved using Chain of Thought with few-shot prompting.This represents a 3% improvement compared to the 68% accuracy observed with standard few-shot prompting.On the other hand, the Qwen-qwq model, despite incorporating Chain of Thought and few-shot prompting, could not generate responses in Bengali.All responses from this model were in English, indicating that the language adaptation was not achieved even with the use of Chain of Thought.</p>
<p>The Llama-3 model with 8 billion parameters did not achieve better results when Chain of Thought (CoT) prompting was introduced.The highest accuracy was achieved with standard prompting in the zero-shot setting, which reached 47%.Instead of increasing accuracy, the use of Chain of Thought actually decreased the accuracy percentage.Furthermore, despite this accuracy, all responses were in English rather than Bengali, which deviates from the intended output.On the other hand, the Llama-3 model with 70 billion parameters performed better, achieving 73% accuracy compared to 67% with standard prompting, reflecting a 6% improvement with the use of CoT.The smaller model (8B) again struggled with Chain of Thought prompting even with a change in Prompt style, possibly due to its limited capacity for processing more intricate tasks or adapting to Bengali.The larger Llama-3 (70B), however, demonstrated a noticeable improvement with the new prompt style.This suggests that parameter size and prompt play a crucial role in the effectiveness of Chain of Thought prompting, especially when dealing with multi-step reasoning and language adaptation.The Llama-3.1 (8B), Llama-3.2 (1B), and Llama-3.2 (3B) models also did not show any improvements with the introduction of Chain of Thought (CoT) prompting.In fact, their accuracy remained below expectations, and in some cases, even decreased.The Llama-3.1 (8B) model, for instance, still achieved its highest accuracy with standard zero-shot prompting (48%), and CoT prompted a decrease in accuracy.Similarly, Llama-3.2 (1B) and Llama-3B also failed to demonstrate any notable improvements with and without CoT prompting, and their performance remained subpar in both zero-shot and few-shot settings.Even with the introduction of Prompt Style 2, Llama-3.3 (70B) continues to achieve the highest accuracy, reaching an impressive 88% on our proposed dataset.This performance was attained with the inclusion of Chain of Thought (CoT) and few-shot prompting, showing a remarkable 10% improvement over the standard few-shot prompting accuracy of 78%.This substantial increase highlights the significant benefits of applying CoT prompting to advanced models like Llama-3.3, demonstrating its effectiveness in handling complex reasoning tasks.The model's ability to achieve the highest accuracy, even with the new prompt style, further underscores the potential of CoT for enhancing model performance, particularly for larger, more capable models like Llama-3.3.</p>
<p>The Chain of Thought (CoT) prompting has proven to be a powerful approach in solving complex reasoning tasks, particularly in the domain of mathematical problems in Bengali.By breaking down intricate problems into smaller, manageable steps, CoT enables the models to better understand the logical structure of the task and produce more accurate solutions.In our experiments, CoT significantly enhanced the performance of larger models like GPT-4o and Llama-3.3, demonstrating its ability to handle multi-step reasoning.Moreover, the introduction of different prompt styles, such as Prompt Style 2, has further improved the efficacy of CoT by better aligning the model's responses with the intended language output.This highlights the importance of fine-tuning both the prompting techniques and the model parameters to optimize performance, particularly in multilingual settings like Bengali, where language-specific nuances can significantly impact the model's ability to reason and generate accurate answers.By strategically incorporating CoT with an appropriate prompt style, we can enhance the model's capacity to tackle more complex tasks with higher accuracy and language adaptation, thus improving overall performance in real-world applications.quicker optimization but also increased the risk of overfitting due to the lack of regularization.The moderate parameters provided a reference point for evaluating more complex setups, showing the limitations of basic fine-tuning without dropout.</p>
<p>LoRA Fintune based results</p>
<p>Higher Rank with Dropout (Finetune 2): Incorporating a higher rank (32) and dropout (0.1), this configuration aimed to increase model capacity and regularization.However, it achieved a slightly lower accuracy of 12%, despite its cautious learning rate of 1e-4.This result suggests that the added complexity and regularization may not align well with the dataset's requirements, possibly due to over-parameterization or insufficient data to fully utilize the additional capacity.</p>
<p>Memory-Efficient with Lower Batch Size (Finetune 3): The third configuration utilized memory-efficient adjustments, including a lower batch size and increased gradient accumulation steps, alongside a higher learning rate of 2e-4.This setup achieved the highest accuracy of 17%.The reduced batch size likely allowed for better gradient updates, while the increased accumulation steps improved learning stability.The higher learning rate might have further facilitated effective convergence by optimizing balancing and learning dynamics.6 presents a performance comparison between the fine-tuned GPT-3.5 (turbo-0125) and GPT-4o, evaluated using standard zero-shot prompting.The results reveal notable differences in accuracy.To build the fine-tuned model, we utilized 50 examples with appropriate instructions, including explicit chain-of-thought reasoning for complex problems.This approach ensured that the model not only provided answers but also demonstrated the reasoning process behind solving math problems.The examples followed the JSONL file format as outlined in the OpenAI API documentation. Figure 13 illustrates an example of how the JSON file was structured to create the fine-tuned model.Fine-tuning GPT-3.5 with a learning rate of 0.1 over 10 epochs achieved the best performance, with an accuracy of 23.4%.However, increasing the number of epochs from 10 to 15 did not yield any further improvements, as the model's performance plateaued at 12.6%, which was equivalent to the performance achieved at 5 epochs.This suggests that fine-tuning for a higher number of epochs may lead to diminishing returns or potential overfitting.</p>
<p>In contrast, GPT-4o, which was not fine-tuned but instead evaluated using its standard zero-shot prompting capability, demonstrated a significantly superior performance of 79.2%.This highlights GPT-4o's inherent ability to generalize across tasks without the need for task-specific fine-tuning, significantly outperforming GPT-3.5, even after fine-tuning.</p>
<p>Appendix A illustrates the OpenAI Playground examples and their outputs and presents the responses of Llama 3.3 on Bengali Math Word Problems, and Appendix B showcases the correct and incorrect responses of GPT models on Bengali Math Word Problems.</p>
<p>Conclusion and Future Work</p>
<p>In this study, we presented a novel approach for solving Bengali Math Word Problems (MWPs) using Large Language Models (LLMs) with Chain of Thought (CoT) prompting.We introduced the SOMADHAN dataset, specifically designed to address Bengali MWPs requiring complex reasoning and multi-step solutions.Our experiments demonstrated that CoT prompting significantly improved the performance of LLMs, particularly for reasoning-intensive tasks in Bengali, a low-resource language.Among the models evaluated, Llama-3.3 outperformed all other models, achieving the highest accuracy of 88% with CoT and few-shot prompting.The GPT-4o model, with its substantial number of parameters, also performed exceptionally well, showing high accuracy in both zero-shot and few-shot settings.Additionally, we leveraged Low-Rank Adaptation (LoRA) fine-tuning techniques to optimize large models for Bengali MWPs.Our findings contribute to advancing the field of Bengali language processing and educational technologies, providing a foundation for future work in multilingual problem-solving tasks.</p>
<p>Q:Figure 1 :
1
Figure 1: Chain-of-Thought (CoT) Prompting enables LLMs (Large Language Model)s to improve complex reasoning of MWPs (Math Word Problems)</p>
<p>Figure 2 :
2
Figure 2: Pipeline for the development of the SOMADHAN dataset</p>
<p>Figure 3 :
3
Figure 3: Challenges faced during the translation of BGSM8K dataset</p>
<p>Question:Figure 4 :Figure 5 :
45
Figure 4: Sample example of SOMADHAN Dataset</p>
<p>Figure 6 :
6
Figure 6: Schematic diagram of our proposed prompting approach</p>
<p>Figure 7 :
7
Figure 7: Instruction (Prompt-1) for SOMADHAN Dataset (Zero Shot Prompting)</p>
<p>Figure 8 :
8
Figure 8: Instruction (Prompt-2) for SOMADHAN Dataset (Zero Shot Prompting)</p>
<p>1 . 3 .
13
Compile and upload the required data for training, ensuring the inclusion of chain-of-thought examples where necessary 2. Develop a new model that is optimized for better performance, focusing on improving reasoning abilities with intermediate steps Analyze the outcomes and make necessary adjustments to ensure that the model produces clear, logical reasoning along with its final answers 4. Utilize the refined and optimized model, leveraging the chain of thought to maintain accurate, interpretable problem-solving</p>
<p>Figure 9 :
9
Figure 9: Instruction (Prompt-1) for SOMADHAN Dataset (Few (5) Shot Prompting)</p>
<p>Figure 10 :
10
Figure 10: Instruction (Prompt-2) for SOMADHAN Dataset (Few (5) Shot Prompting)</p>
<p>content:                            ?, role: assistant content:  =    content:                                    ,         ?(c) User Question</p>
<p>Figure 11 :Figure 12 :
1112
Figure 11: Instruction (Prompt-3) for PatiGonit Dataset (Few (5) Shot) Prompting</p>
<p>Figure 14 :
14
Figure 14: LoRA Fine-Tuning Process: During and After Training (LoRA, 2024)[65]</p>
<ol>
<li>3
3
Gpt-3.5 Finetune result</li>
</ol>
<p>Figure 17 :
17
Figure 17: Response generated by LLaMA 3.3 model on a Bengali Math Word Problem using Chain-of-Thought reasoning.</p>
<p>Figure 18 :
18
Figure 18: Example of correct chains of thought produced by the GPT-3.5 for the SOMADHAN dataset for Few Shot</p>
<p>Figure 19 :
19
Figure 19: Example of correct chains of thought produced by the GPT-4o for the SOMADHAN dataset for Few Shot</p>
<p>Figure 20 :
20
Figure 20: Example of correct chains of thought produced by the GPT-3.5 for the SOMADHAN dataset for Fine Tuning</p>
<p>architectures, including BiLSTM, ConvS2S, and Transformer models.Their ensemble approach achieved 68.4% accuracy on Math23k, outperforming individual models (66.7% for BiLSTM, 64.2% for ConvS2S, and 62.3% for Transformer), emphasizing normalization and model diversity.In</p>
<p>[26]ted work,[25]developed the Variational Neural Machine Translation (VNMT) model with latent variables to enhance semantic understanding, achieving BLEU scores of 32.07 (Chinese-English) and 19.58 (English-German), outperforming traditional models but facing challenges with long sentences.An improvement to Seq2Seq models was proposed by[26], who incorporated Copy and Alignment mechanisms, further optimized via Reinforcement Learning (RL), achieving accuracies of 44.5% on Alg514, 64.0% on NumWord, and 23.3% on Dolphin18KT6.Their hybrid model significantly boosted performance to 82.5%, 65.8%, and 33.2%, respectively.</p>
<p>Table 1 :
1
A Summary of Existing Works in Solving Math Word Problems
Paper TitleApproachModelDatasetAccuracyLanguageEmpoweringTransformerTransformer,PatiGonitPatiGonit:BengaliBengali EducationBasedmT5, BanglaT5,97.30%with AI: SolvingApproach,mBART50Bengali Math WordNeural MachineProblems throughTranslationTransformer(NMT)Models [22]Math word problemEnhanced MaskDeBERTaMAWPS,MAWPS:Englishsolving byDecoder and aPARA-91.0%,generatingVotingMAWPSPARA-linguistic variantsMechanismMAWPS:of problem79.1%statements [38]Chain-of-thoughtChain-of-GPT-3, LaMDA,GSM8KGSM8K:Englishprompting elicitsThoughtPaLM, UL2,63.1%reasoning in largePromptingCodexlanguage models[15]Making LargeDiverse VerifierOpenAI Models:GSM8KGSM8K:EnglishLanguage Modelson Reasoningdavinci,83.2%Better ReasonersSteptext-davinci-002,with Step-Awarecode-davinci-002Verifier [42]Self-consistencySelf-GPT-3:GSM8KGSM8K:Englishimproves chain ofConsistency,code-davinci-001,83.2%thought reasoningChain-of-code-davinci-002,in language modelsThoughtLaMDA-137B,[43]PromptingPaLM-540B(CoT)2.4 Methods Utilizing Intermediate StepsNumerous studies have demonstrated the many benefits of teaching neural networks to produce intermediate stepsthrough fine-tuning or training. Natural language intermediate steps, in particular, have shown promise in enhancingmodel robustness and interpretability. For instance,</p>
<p>Table 2 :
2
Detailed Informations of Translators
DetailsTranslator 1Translator 2Translator 3Translator 4Translator 5RoleGraduateUnder-graduate Under-graduate Under-graduate Under-graduateAge3023242422Research fieldNLPNLPNLPNLPNLPExperience4 years2 years1 years2 years1 years</p>
<p>Table 4 :
4
Performance comparison of Chain of Thoughts (CoT) prompting (Prompt-2) versus Standard prompting for various large language models on the "SOMADHAN" dataset.All metrics are Accuracy (%).(<em>) represents that the accuracy is correct but the responses of the model was in English.
ModelsParametersStandard Zero Shot Few (5) Shot Zero Shot Few (5) Shot Chain of Thoughts (CoT)deepseek-r1-distill-qwen32B39.0</em>44.0*48.0  *  (+9.0)</p>
<p>Table 5 :
5
Ablation Study with three variations of LoRA finetuning on SOMADHAN dataset.All metrics are Accuracy (%).
ParameterBaselineHigher Rank with DropoutMemory Efficient with Lower Batch SizeLoRA Parametersr163216lora alpha163216lora dropout00.10.1target modules{q_proj, k_proj, v_proj, o_proj, gate_proj, up_proj, down_proj}{q_proj, k_proj, v_proj, o_proj}{q_proj, v_proj, o_proj}use gradient checkpointingunslothTrueTrueTraining Argumentslearning rate2e-41e-42e-4per device train batch size241gradient accumulation steps428warmup steps5105max steps6010060Performance13.012.017.0From</p>
<p>Table 5 ,
5
Baseline Configuration (Finetune 1): This setup, characterized by a rank of 16, no dropout, and a moderate learning rate of 2e-4, achieved an accuracy of 13%.The simplicity of this configuration likely facilitated</p>
<p>Table 6 :
6
Performance comparison of finetuned Gpt-3.5 with Gpt-4o.All metrics are Accuracy (%).
ModelsLearning Rate Epochs Performance512.0Gpt-3.5 turbo-01250.11023.01512.0Gpt-4o(Standard Prompting--79.0Zero Shot)Table
https://github.com/openai/grade-school-math/tree/master/grade_school_math/data
While our approach showed promising results, several limitations need to be acknowledged.First, due to resource constraints and token costs, we limited our evaluation to 1000 testing samples from both the SOMADHAN and PatiGonit datasets.This reduced sample size might have impacted the generalizability of the results, and future studies could benefit from evaluating a larger subset of the dataset.Additionally, while CoT prompting improved model performance in many cases, the language adaptation for smaller models, particularly the LLaMA series, was not optimal.Models such as Llama-3 (8B) struggled to effectively solve Bengali MWPs, indicating that smaller models may not perform as well as larger ones when it comes to complex reasoning tasks in low-resource languages.The reliance on English responses for some models, even after incorporating CoT prompting, also highlights the challenge of multilingual task adaptation.For future research, expanding the SOMADHAN dataset to include a larger variety of Bengali Math Word Problems with more diverse reasoning steps could improve model training and evaluation.Future work should also focus on the development of even more efficient fine-tuning strategies, such as further optimizations of Low-Rank Adaptation (LoRA), to handle the increasing complexity of language models without incurring high computational costs.Investigating methods to ensure better language output alignment in multilingual models, such as fine-tuning for Bengali language generation, would be an essential step toward improving the overall effectiveness of LLMs in real-world applications.AcknowledgmentsThis research did not receive any specific grant from funding agencies in the public, commercial, or not-for-profit sectors.
Enhancing multiple-choice question answering through sequential fine-tuning and curriculum learning strategies. Gulsum Yigit, Mehmet Fatih, Amasyali , Knowledge and Information Systems. 65112023</p>
<p>A seq2seq-based approach to question answering over knowledge bases. Linjuan Wu, Peiyun Wu, Xiaowang Zhang, Semantic Technology: 9th Joint International Conference. Hangzhou, ChinaSpringer2019. November 25-27, 2019. 20209</p>
<p>Qa dataset explosion: A taxonomy of nlp resources for question answering and reading comprehension. Anna Rogers, Matt Gardner, Isabelle Augenstein, ACM Computing Surveys. 552021</p>
<p>Ask me: A question answering system via dynamic memory networks. Gulsum Yigit, Mehmet Fatih, Amasyali , Innovations in Intelligent Systems and Applications Conference (ASYU). 2019. 2019</p>
<p>A goal-driven tree-structured neural model for math word problems. Zhipeng Xie, Shichao Sun, International Joint Conference on Artificial Intelligence. 2019</p>
<p>Teacher-student networks with multiple decoders for solving math word problem. Jipeng Zhang, Roy , Ka-Wei Lee, Ee-Peng Lim, Wei Qin, Lei Wang, Jie Shao, Qianru Sun, International Joint Conference on Artificial Intelligence. 2020</p>
<p>Mwp-bert: Numeracy-augmented pre-training for math word problem solving. Zhenwen Liang, Jipeng Zhang, Lei Wang, Wei Qin, Yunshi Lan, Jie Shao, Xiangliang Zhang, NAACL-HLT. 2021</p>
<p>Templatebased math word problem solvers with recursive neural networks. Lei Wang, Dongxiang Zhang, Jipeng Zhang, Xing Xu, Lianli Gao, Bing Tian Dai, Heng Tao Shen, AAAI Conference on Artificial Intelligence. 2019</p>
<p>Graph-to-tree learning for solving math word problems. Jipeng Zhang, Lei Wang, Roy , Ka-Wei Lee, Yi Bin, Yan Wang, Jie Shao, Ee-Peng Lim, Annual Meeting of the Association for Computational Linguistics. 2020</p>
<p>Solving math word problems with multi-encoders and multi-decoders. Yibin Shen, Cheqing Jin, International Conference on Computational Linguistics. 2020</p>
<p>Some challenges and grand challenges for computational intelligence. Edward A Feigenbaum, Journal of the ACM (JACM). 5012003</p>
<p>Mathbot-a deep learning based elementary school math word problem solver. Anish Kumar Nayak, Rajeev Patwari, Viswanathan Subramanian, 807</p>
<p>Training verifiers to solve math word problems. Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, arXiv:2110.141682021arXiv preprint</p>
<p>Scaling language models: Methods, analysis &amp; insights from training gopher. Sebastian Jack W Rae, Trevor Borgeaud, Katie Cai, Jordan Millican, Francis Hoffmann, John Song, Sarah Aslanides, Roman Henderson, Susannah Ring, Young, arXiv:2112.114462021arXiv preprint</p>
<p>Chain-of-thought prompting elicits reasoning in large language models. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Denny Quoc V Le, Zhou, Advances in neural information processing systems. 202235</p>
<p>List of languages by total number of speakers. Wikipedia, 2024</p>
<p>Gpt-4o: A new multimodal ai model. 2024OpenAI</p>
<p>Gpt-3.5 turbo model documentation. 2023OpenAI</p>
<p>Llama 3: Open and efficient foundation language models. A I Meta, 2024</p>
<p>Deepseek platform documentation. Deepseek, 2025</p>
<p>Qwen chat interface. Qwen, 2025</p>
<p>Empowering bengali education with ai: Solving bengali math word problems through transformer models. Jalisha Jashim, Era , Bidyarthi Paul, Tahmid Sattar Aothoi, Mirazur Rahman Zim, Faisal Muhammad Shah, 2024 27th International Conference on Computer and Information Technology (ICCIT). IEEE2024</p>
<p>Deep neural solver for math word problems. Yan Wang, Xiaojiang Liu, Shuming Shi, Proceedings of the 2017 conference on empirical methods in natural language processing. the 2017 conference on empirical methods in natural language processing2017</p>
<p>Translating a math word problem to an expression tree. Lei Wang, Yan Wang, Deng Cai, Dongxiang Zhang, Xiaojiang Liu, arXiv:1811.056322018arXiv preprint</p>
<p>Biao Zhang, Deyi Xiong, Jinsong Su, Hong Duan, Min Zhang, arXiv:1605.07869Variational neural machine translation. 2016arXiv preprint</p>
<p>Neural math word problem solver with reinforcement learning. Danqing Huang, Jing Liu, Chin-Yew Lin, Jian Yin, Proceedings of the 27th International Conference on Computational Linguistics. the 27th International Conference on Computational Linguistics2018</p>
<p>Graph-to-tree learning for solving math word problems. Jipeng Zhang, Lei Wang, Roy , Ka-Wei Lee, Yi Bin, Yan Wang, Jie Shao, Ee-Peng Lim, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. the 58th Annual Meeting of the Association for Computational Linguistics2020</p>
<p>Graph-to-tree neural networks for learning structured input-output translation with applications to semantic parsing and math word problem. Shucheng Li, Lingfei Wu, Shiwei Feng, Fangli Xu, Fengyuan Xu, Sheng Zhong, arXiv:2004.137812020arXiv preprint</p>
<p>Solving math word problems with multi-encoders and multi-decoders. Yibin Shen, Cheqing Jin, Proceedings of the 28th International Conference on Computational Linguistics. the 28th International Conference on Computational Linguistics2020</p>
<p>Zhenwen Liang, Jipeng Zhang, Lei Wang, Wei Qin, Yunshi Lan, Jie Shao, Xiangliang Zhang, arXiv:2107.13435Mwp-bert: Numeracy-augmented pre-training for math word problem solving. 2021arXiv preprint</p>
<p>Bert: Pre-training of deep bidirectional transformers for language understanding. Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, arXiv:1810.048052018arXiv preprint</p>
<p>Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, Veselin Stoyanov, arXiv:1907.11692Roberta: A robustly optimized bert pretraining approach. 2019arXiv preprint</p>
<p>Language models are unsupervised multitask learners. Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, OpenAI blog. 1892019</p>
<p>Peter Clark, Oyvind Tafjord, Kyle Richardson, arXiv:2002.05867Transformers as soft reasoners over language. 2020arXiv preprint</p>
<p>Rulebert: Teaching soft rules to pre-trained language models. Mohammed Saeed, Naser Ahmadi, Preslav Nakov, Paolo Papotti, arXiv:2109.130062021arXiv preprint</p>
<p>Explainable multi-hop verbal reasoning through internal monologue. Zhengzhong Liang, Steven Bethard, Mihai Surdeanu, Proceedings of the 2021 Conference of the North American Chapter. the 2021 Conference of the North American ChapterHuman Language Technologies2021</p>
<p>Zhenwen Liang, Jipeng Zhang, Lei Wang, Wei Qin, Yunshi Lan, Jie Shao, Xiangliang Zhang, arXiv:2107.13435Mwp-bert: Numeracy-augmented pre-training for math word problem solving. 2021arXiv preprint</p>
<p>Math word problem solving by generating linguistic variants of problem statements. Md Syed Rifat Raiyan, Shah Nafis Faiyaz, Jawad Md, Mohsinul Kabir, Kabir, Mahmud Hasan, Md Kamrul Hasan, arXiv:2306.138992023arXiv preprint</p>
<p>Translating a math word problem to an expression tree. Lei Wang, Yan Wang, Deng Cai, Dongxiang Zhang, Xiaojiang Liu, arXiv:1811.056322018arXiv preprint</p>
<p>A goal-driven tree-structured neural model for math word problems. Zhipeng Xie, Shichao Sun, Ijcai. 2019</p>
<p>Warm: A weakly (+ semi) supervised model for solving math word problems. Oishik Chatterjee, Isha Pandey, Aashish Waikar, Vishwajeet Kumar, Ganesh Ramakrishnan, arXiv:2104.067222021arXiv preprint</p>
<p>On the advance of making language models better reasoners. Yifei Li, Zeqi Lin, Shizhuo Zhang, Qiang Fu, Bei Chen, Jian-Guang Lou, Weizhu Chen, 2022b</p>
<p>Self-consistency improves chain of thought reasoning in language models. Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdhery, Denny Zhou, arXiv:2203.111712022arXiv preprint</p>
<p>Howard Chen, Jacqueline He, Karthik Narasimhan, Danqi Chen, arXiv:2204.11790Can rationalization improve robustness?. 2022arXiv preprint</p>
<p>Training classifiers with natural language explanations. Braden Hancock, Martin Bringmann, Paroma Varma, Percy Liang, Stephanie Wang, Christopher R, Proceedings of the conference. the conferenceNIH Public Access201820181884</p>
<p>Benefits of intermediate annotations in reading comprehension. Dheeru Dua, Sameer Singh, Matt Gardner, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. the 58th Annual Meeting of the Association for Computational Linguistics2020</p>
<p>Using "annotator rationales" to improve machine learning for text categorization. Omar Zaidan, Jason Eisner, Christine Piatko, Human language technologies 2007: The conference of the North American chapter of the association for computational linguistics; proceedings of the main conference. 2007</p>
<p>Refining language models with compositional explanations. Huihan Yao, Ying Chen, Qinyuan Ye, Xisen Jin, Xiang Ren, Advances in Neural Information Processing Systems. 202134</p>
<p>When can models learn from explanations? a formal framework for understanding the roles of explanation data. Peter Hase, Mohit Bansal, arXiv:2102.022012021arXiv preprint</p>
<p>Dream: Uncovering mental models behind language models. Yuling Gu, Bhavana Dalvi Mishra, Peter Clark, 2022NAACL</p>
<p>Jacob Andreas, Dan Klein, Sergey Levine, arXiv:1711.00482Learning with latent language. 2017arXiv preprint</p>
<p>e-snli: Natural language inference with natural language explanations. Oana-Maria Camburu, Tim Rocktschel, Thomas Lukasiewicz, Phil Blunsom, Advances in Neural Information Processing Systems. 201831</p>
<p>Explain yourself! leveraging language models for commonsense reasoning. Nazneen Fatema Rajani, Bryan Mccann, Caiming Xiong, Richard Socher, arXiv:1906.023612019arXiv preprint</p>
<p>Star: Bootstrapping reasoning with reasoning. Eric Zelikman, Yuhuai Wu, Jesse Mu, Noah Goodman, Advances in Neural Information Processing Systems. 202235</p>
<p>Language models are few-shot learners. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Advances in neural information processing systems. 202033</p>
<p>The power of scale for parameter-efficient prompt tuning. Brian Lester, Rami Al-Rfou, Noah Constant, arXiv:2104.086912021arXiv preprint</p>
<p>Jason Wei, Maarten Bosma, Y Vincent, Kelvin Zhao, Adams Wei Guu, Brian Yu, Nan Lester, Andrew M Du, Quoc V Dai, Le, arXiv:2109.01652Finetuned language models are zero-shot learners. 2021arXiv preprint</p>
<p>Multitask prompted training enables zero-shot task generalization. Victor Sanh, Albert Webson, Colin Raffel, Stephen H Bach, Lintang Sutawika, Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, Teven Le Scao, Arun Raja, arXiv:2110.082072021arXiv preprint</p>
<p>Training language models to follow instructions with human feedback. Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, Advances in neural information processing systems. 202235</p>
<p>Exploring the limits of transfer learning with a unified text-to-text transformer. Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, Peter J Liu, Journal of machine learning research. 211402020</p>
<p>Super-naturalinstructions. Yizhong Wang, Swaroop Mishra, Pegah Alipoormolabashi, Yeganeh Kordi, Amirreza Mirzaei, Anjana Arunkumar, Arjun Ashok, Arut Selvan Dhanasekaran, Atharva Naik, David Stap, arXiv:2204.07705Generalization via declarative instructions on 1600+ nlp tasks. 2022arXiv preprint</p>
<p>Kabir Ahuja, Harshita Diddee, Rishav Hada, Millicent Ochieng, Krithika Ramesh, Prachi Jain, Akshay Nambi, Tanuja Ganu, Sameer Segal, Maxamed Axmed, arXiv:2303.12528Multilingual evaluation of generative ai. 2023arXiv preprint</p>
<p>Fine-tuning gpt-3.5 models. 2023OpenAI</p>
<p>J Edward, Yelong Hu, Phillip Shen, Zeyuan Wallis, Yuanzhi Allen-Zhu, Shean Li, Lu Wang, Weizhu Wang, Chen, arXiv:2106.09685Lora: Low-rank adaptation of large language models. 2021arXiv preprint</p>
<p>Lora: Low-rank adaptation of large language models. Hugging Face, 2024</p>            </div>
        </div>

    </div>
</body>
</html>