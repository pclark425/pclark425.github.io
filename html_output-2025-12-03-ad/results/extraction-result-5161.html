<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-5161 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-5161</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-5161</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-109.html">extraction-schema-109</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <p><strong>Paper ID:</strong> paper-18253142</p>
                <p><strong>Paper Title:</strong> <a href="https://arxiv.org/pdf/1304.3082v1.pdf" target="_blank">Reasoning With Uncertain Knowledge</a></p>
                <p><strong>Paper Abstract:</strong> A model of knowledge representation is described in which propositional facts and the relationships among them can be supported by other facts. The set of knowledge which can be supported is called the set of cognitive units, each having associated descriptions of their explicit and implicit support structures, summarizing belief and reliability of belief. This summary is precise enough to be useful in a computational model while remaining descriptive of the underlying symbolic support structure. When a fact supports another supportive relationship between facts we call this meta-support. This facilitates reasoning about both the propositional knowledge. and the support structures underlying it.</p>
                <p><strong>Cost:</strong> 0.012</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e5161.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e5161.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Endorsement Network</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Belief-and-Certainty Endorsement Network (Craddock 1986)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A symbolic-structured representational model that encodes propositions as nodes annotated with a belief strength and a certainty value, linked by support (endorsement) arcs whose strengths can be modulated and themselves endorsed; used to compute and maintain belief under uncertainty via heuristics and numeric aggregation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Endorsement network / belief-and-certainty model</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Concepts/propositions are represented as discrete cognitive units (nodes) each carrying two functional values: belief (graded truth in [-1,1]) and certainty (reliability of the belief in [0,1]). Directed support arcs (endorsements) carry signed support weights which can be modulated by other nodes; belief of a target is computed from endorsers' belief, certainty and relative support via weighted aggregation and heuristic rules, while certainty reflects agreement among endorsers.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>symbolic-propositional nodes augmented with numeric qualifiers (hybrid symbolic-numeric representation)</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>Explicit structure of reasons (symbolic support arcs); graded belief values bounded to [-1,1]; separate meta-quantity certainty; support arcs can be excitatory or inhibitory; endorsements themselves can be endorsed (meta-structure); bounded beliefs (no unbounded activation); uses relaxation to propagate beliefs; preserves provenance of numeric values.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>The paper motivates the model with psychological findings about human heuristic reasoning (cites Kahneman & Tversky) and argues the format can capture behaviors such as anchoring, representativeness, availability and adjustments; no original behavioral experiments are reported in this thesis paper, but it is positioned to model known empirical phenomena described in referenced literature.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>No direct empirical tests are reported in the paper; the author acknowledges it is difficult to determine how well the model matches human reasoning and that formulae may not be optimal. Potential challenges noted include choosing aggregation functions and handling cycles, and whether numeric qualifications alone can capture human explanations.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Modeling human reasoning under uncertainty, belief maintenance, decision support where justification/provenance of numeric beliefs is required; contrasted with expert systems and connectionist spreading-activation models.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Explicitly contrasted with connectionist/spreading-activation models (Anderson, McClelland/Rumelhart): differs by (1) representing uncertainty both numerically and symbolically (support structure), (2) bounding belief rather than allowing unbounded activation with decay, and (3) allowing endorsement-of-endorsement enabling representation of dependent evidence; contrasted with MYCIN-style systems which assume conditional independence.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Collection of endorsements guided by heuristics; computation of belief as a weighted sum (endorser belief × support × relative importance × relative certainty) with normalization; certainty computed from agreement/disagreement among endorsers; inhibition among mutually exclusive endorsements via inhibitory supports; relaxation algorithm for propagation; checks for intuitive vs rational contradictions to manage updates and cycles.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>No empirical validation provided; formulae acknowledged as illustratory rather than definitive; scalability and parameter setting (how to assign supports, certainties) left unresolved; handling of large cyclic networks requires partial-network calculation and threshold T for inclusion; extent to which the model matches human cognitive mechanisms remains open.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5161.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e5161.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Spreading Activation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Spreading-activation / Connectionist models (Anderson; McClelland & Rumelhart)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Distributed activation models in which conceptual nodes receive and pass activation through links, and activation levels determine associative relevance and retrieval; widely used as a functional-level account of semantic memory and context effects.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>The architecture of cognition.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Spreading-activation / connectionist interactive-activation models</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Concepts are represented as nodes in a network whose activation values spread to connected nodes; activation is often unbounded but controlled by decay, and retrieval/relevance is a function of activation levels influenced by input and network structure.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>distributed/activation-based (connectionist)</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>Continuous activation levels, spreading dynamics, decay functions for temporal control, associative relevance (higher activation = higher relevance), often subsymbolic and distributed representations with graded effects from multiple inputs.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Cited as accounting for context effects in perception and associative relevance (references to Anderson 1982 and Rumelhart & McClelland 1981/1982), and as influential models for semantic activation and retrieval phenomena.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Paper argues these models often ignore explicit symbolic provenance of uncertainty and that decay-based control can produce counter-intuitive relevance differences when support paths differ in length (example: multi-step support vs shorter paths), suggesting potential mismatches with some belief-maintenance intuitions.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Semantic memory, context effects in perception, associative retrieval, explanation of graded human judgments in many cognitive tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Contrasted with the endorsement network: spreading-activation uses numeric activations without explicit symbolic support structure; endorsement model prefers bounded belief values and explicit provenance; spreading-activation's decay mechanism is argued to be problematic for belief maintenance.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Activation spreading via weighted links; decay over time to prevent unbounded activation; competition/inhibition mechanisms sometimes used to resolve alternatives (e.g., inhibitory clusters).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>Does not explicitly record how numeric activation values were computed (lack of symbolic justification); decay-based relevance heuristics may misrepresent multi-step evidential support; integration of uncertainty provenance is limited in standard formulations.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5161.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e5161.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Fuzzy Propositions</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Fuzzy propositional logic / Fuzzy representation (Zadeh)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Representation of propositions with graded truth values (membership degrees) allowing partial truth; applied to commonsense knowledge representation to capture vagueness.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Commonsense knowledge representation based on Fuzzy Logic</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Fuzzy propositional representation</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Conceptual knowledge is encoded as propositions with degrees of truth/membership (continuous values between false and true), enabling representation of vague predicates and graded beliefs at a functional level.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>graded/continuous propositional (fuzzy)</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>Graded truth values, handles vagueness/partial membership, algebra of fuzzy sets and operators for logical combination, quantitative but not necessarily providing provenance for belief sources.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Mentioned as a quantitative approach to uncertainty with references to Zadeh; paper notes fuzzy values provide expressive gradedness to statements.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Paper argues quantitative assumptions (including fuzzy) can be overly restrictive or lack expressive power for representing provenance and interactions among evidence; fuzzy values alone do not explain how beliefs were derived.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Commonsense knowledge representation, handling vagueness in natural language and decision tasks requiring graded judgments.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Compared to the endorsement model as another numeric scheme; endorsement model augments numeric grades with symbolic endorsement structure to retain reasons-for beliefs, which fuzzy logic formulations typically do not provide.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Use of membership functions and fuzzy combination operators to compute degrees of truth for composed propositions (not elaborated in detail in this paper).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>Lack of explicit representation of evidential provenance and interaction among supports; potential insufficiency to capture heuristic-driven human reasoning processes as described by Kahneman & Tversky.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5161.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e5161.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Heuristics (K&T)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Kahneman & Tversky heuristics (representativeness, availability, anchoring)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A set of decision heuristics describing how people simplify judgment under uncertainty — e.g., representativeness (similarity-based weighting), availability (retrievability-based weighting), and anchoring-and-adjustment (starting from a salient value and adjusting).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Judgment under uncertainty: Heuristics and Biases</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Heuristics and biases framework (Kahneman & Tversky)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Functional-level account that humans rely on a small set of cognitive heuristics to make judgments under uncertainty; these heuristics bias how evidence is selected, weighted and combined, shaping the effective representation and use of conceptual knowledge in decision contexts.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>process-level heuristic-guided sampling/weighting of representations (procedural/algorithmic rather than purely representational type)</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>Selective relevance (availability), similarity-based weighting (representativeness), anchor bias (adjustment from initial values); heuristics constrain which propositions get endorsements and how evidence is aggregated.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Paper cites Kahneman & Tversky's demonstrations of decisions that deviate from normative mathematical theories, and uses their heuristics as guiding principles for which endorsements are collected and how they are weighted in the endorsement model.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Heuristic-based behavior is often non-normative relative to probability theory; the endorsement model attempts to capture these heuristics but the paper notes specifying heuristics formally and validating them remains challenging.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Human judgment and decision-making under uncertainty, modeling biases in probabilistic reasoning, guiding collection/selection of evidence in belief systems.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Used within the endorsement model to constrain evidence collection and weighting, contrasted with pure probabilistic/utility-maximizing frameworks which assume normative computation rather than heuristics.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Heuristics determine which propositions are considered (relevance/availability), how endorsements are weighted (anchoring and adjustment), and how similarity/agreement among evidence affects certainty (representativeness and resolution heuristics).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>Heuristics are descriptive and require formalization for computational models; integrating them with principled aggregation formulas raises questions about parameterization and generality.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5161.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e5161.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Inhibitory Clusters</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Inhibitory clusters (Rumelhart & Zipser)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A competitive organization in connectionist networks where units within a group inhibit each other so that the most strongly activated unit suppresses alternatives, used to implement mutual exclusivity or winner-take-all dynamics.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Feature Discovery by Competitive Learning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Inhibitory cluster / competitive learning mechanism</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Functional mechanism in which nodes are arranged in mutually inhibiting clusters so that the node with the highest activation inhibits others, producing competitive selection among alternatives.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>distributed/competitive (connectionist mechanism)</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>Mutual inhibition, competitive selection (winner-take-all tendencies), supports representation of mutually exclusive alternatives.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Cited as similar in spirit to the endorsement-model's mutual exclusivity mechanism, providing a computational precedent for treating one strong endorsement as inhibiting others.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Connectionist competitive mechanisms may differ in how inhibition is implemented and in whether they preserve symbolic provenance; the endorsement model implements inhibition at the level of support-arcs to preserve evidential structure.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Feature discovery, competitive selection in categorization and representation learning.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Analogous to endorsement-model inhibition of competing supports but implemented at different representational levels (activation competition vs symbolic support inhibition).</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Lateral inhibition among units within a cluster leading to suppression of weaker alternatives; competitive learning algorithms adjust weights to reflect dominance patterns.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>How to reconcile subsymbolic competition with the need for explicit reasons/provenance when explaining beliefs; mapping between inhibitory clusters and symbolic endorsement structures is not one-to-one.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5161.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e5161.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MYCIN CFs</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>MYCIN-style certainty-factor rule systems (Shortliffe)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Rule-based expert systems that attach certainty factors (numeric weights) to rules and conclusions, combining uncertain evidence under assumptions (often conditional independence) to produce graded conclusions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Computer-based medical consultations: MYCIN.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Certainty-factor rule-based representation</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Knowledge represented as symbolic rules augmented with numeric certainty factors; conclusions are derived by combining certainty factors according to system-specific combination rules to yield graded confidence in hypotheses.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>symbolic rule-based with numeric qualifiers</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>Symbolic IF-THEN rules, numeric certainty factors, rule-based chaining; typically assumes conditional independence of evidence and mutual exclusivity among hypotheses in combination procedures.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Historically applied in medical diagnosis (MYCIN) and shown to produce useful expert-like decisions; cited here as a contrast to models that explicitly represent evidence interactions.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Paper criticizes MYCIN-style systems for requiring conditional independence and mutual exclusivity assumptions which limit expressive power regarding interacting or dependent evidence; lacks mechanisms for representing endorsements of endorsements.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Expert systems, rule-based diagnosis (especially medical), decision support where explicit rules are available.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Compared unfavorably (in this paper) to the endorsement model which can represent dependent evidence and endorse supports themselves; MYCIN treated as an example of a quantitative but structurally-limited approach.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Forward/backward chaining of rules with propagation and combination of certainty factors according to ad-hoc combination formulas.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>Assumptions of independence and exclusivity limit applicability when evidence interacts; limited capacity to explain provenance beyond rule firing and numeric CFs.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5161.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e5161.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Non-monotonic Logic / Circumscription</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Non-monotonic reasoning and circumscription (McDermott & Doyle; McCarthy; Reiter)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Symbolic logical formalisms for representing default, defeasible, or context-sensitive knowledge where conclusions can be withdrawn in light of new information (non-monotonicity), e.g., circumscription.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Circumscription -A form of non-monotonic reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Non-monotonic logical formalisms (circumscription, default reasoning)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Conceptual knowledge is represented symbolically with rules and defaults that can be retracted when exceptions arise; reasoning is non-monotonic so adding information can invalidate prior conclusions, modeling common-sense defeasible inference.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>symbolic-logical (non-monotonic)</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>Default rules, defeasible inference, formal mechanisms (e.g., circumscription) to minimize abnormality, retractability of conclusions, explicit symbolic structure supporting explanation.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Cited as traditional logical approach in AI for representing commonsense and defaults; offers principled symbolic mechanisms for defeasible reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Paper argues pure logical schemes do not cope well with graded uncertainty and human use of heuristics; logical formalisms may be poor at modeling the numeric and heuristic aspects of human reasoning under uncertainty.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Common-sense reasoning, knowledge representation in AI, modeling defaults and exceptions.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Presented as one of the classical approaches that the endorsement model seeks to augment/replace in contexts where graded uncertainty and heuristic decision-making are central; lacks natural handling of graded certainties and provenance of evidence strengths.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Symbolic rule application with non-monotonic update policies (e.g., circumscription minimizes abnormal predicates), formal proof-theoretic mechanisms for retracting conclusions.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>Difficulty representing graded uncertainty and human heuristics; integration with numeric uncertainty measures and explanation of how human-like heuristics arise remains open.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Judgment under uncertainty: Heuristics and Biases <em>(Rating: 2)</em></li>
                <li>Variants of uncertainty <em>(Rating: 2)</em></li>
                <li>The architecture of cognition. <em>(Rating: 2)</em></li>
                <li>An interactive activation model of context effects in letter perception: Part 1. An account of basic findings <em>(Rating: 2)</em></li>
                <li>An interactive activation model of context effects in letter perception: Part 2. The contextual enhancement effect and some tests and extensions of the model <em>(Rating: 2)</em></li>
                <li>Feature Discovery by Competitive Learning <em>(Rating: 2)</em></li>
                <li>Commonsense knowledge representation based on Fuzzy Logic <em>(Rating: 2)</em></li>
                <li>Computer-based medical consultations: MYCIN. <em>(Rating: 1)</em></li>
                <li>Circumscription -A form of non-monotonic reasoning. <em>(Rating: 1)</em></li>
                <li>Non-monotonic Logic I <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-5161",
    "paper_id": "paper-18253142",
    "extraction_schema_id": "extraction-schema-109",
    "extracted_data": [
        {
            "name_short": "Endorsement Network",
            "name_full": "Belief-and-Certainty Endorsement Network (Craddock 1986)",
            "brief_description": "A symbolic-structured representational model that encodes propositions as nodes annotated with a belief strength and a certainty value, linked by support (endorsement) arcs whose strengths can be modulated and themselves endorsed; used to compute and maintain belief under uncertainty via heuristics and numeric aggregation.",
            "citation_title": "here",
            "mention_or_use": "use",
            "theory_or_model_name": "Endorsement network / belief-and-certainty model",
            "theory_or_model_description": "Concepts/propositions are represented as discrete cognitive units (nodes) each carrying two functional values: belief (graded truth in [-1,1]) and certainty (reliability of the belief in [0,1]). Directed support arcs (endorsements) carry signed support weights which can be modulated by other nodes; belief of a target is computed from endorsers' belief, certainty and relative support via weighted aggregation and heuristic rules, while certainty reflects agreement among endorsers.",
            "representation_format_type": "symbolic-propositional nodes augmented with numeric qualifiers (hybrid symbolic-numeric representation)",
            "key_properties": "Explicit structure of reasons (symbolic support arcs); graded belief values bounded to [-1,1]; separate meta-quantity certainty; support arcs can be excitatory or inhibitory; endorsements themselves can be endorsed (meta-structure); bounded beliefs (no unbounded activation); uses relaxation to propagate beliefs; preserves provenance of numeric values.",
            "empirical_support": "The paper motivates the model with psychological findings about human heuristic reasoning (cites Kahneman & Tversky) and argues the format can capture behaviors such as anchoring, representativeness, availability and adjustments; no original behavioral experiments are reported in this thesis paper, but it is positioned to model known empirical phenomena described in referenced literature.",
            "empirical_challenges": "No direct empirical tests are reported in the paper; the author acknowledges it is difficult to determine how well the model matches human reasoning and that formulae may not be optimal. Potential challenges noted include choosing aggregation functions and handling cycles, and whether numeric qualifications alone can capture human explanations.",
            "applied_domains_or_tasks": "Modeling human reasoning under uncertainty, belief maintenance, decision support where justification/provenance of numeric beliefs is required; contrasted with expert systems and connectionist spreading-activation models.",
            "comparison_to_other_models": "Explicitly contrasted with connectionist/spreading-activation models (Anderson, McClelland/Rumelhart): differs by (1) representing uncertainty both numerically and symbolically (support structure), (2) bounding belief rather than allowing unbounded activation with decay, and (3) allowing endorsement-of-endorsement enabling representation of dependent evidence; contrasted with MYCIN-style systems which assume conditional independence.",
            "functional_mechanisms": "Collection of endorsements guided by heuristics; computation of belief as a weighted sum (endorser belief × support × relative importance × relative certainty) with normalization; certainty computed from agreement/disagreement among endorsers; inhibition among mutually exclusive endorsements via inhibitory supports; relaxation algorithm for propagation; checks for intuitive vs rational contradictions to manage updates and cycles.",
            "limitations_or_open_questions": "No empirical validation provided; formulae acknowledged as illustratory rather than definitive; scalability and parameter setting (how to assign supports, certainties) left unresolved; handling of large cyclic networks requires partial-network calculation and threshold T for inclusion; extent to which the model matches human cognitive mechanisms remains open.",
            "uuid": "e5161.0"
        },
        {
            "name_short": "Spreading Activation",
            "name_full": "Spreading-activation / Connectionist models (Anderson; McClelland & Rumelhart)",
            "brief_description": "Distributed activation models in which conceptual nodes receive and pass activation through links, and activation levels determine associative relevance and retrieval; widely used as a functional-level account of semantic memory and context effects.",
            "citation_title": "The architecture of cognition.",
            "mention_or_use": "mention",
            "theory_or_model_name": "Spreading-activation / connectionist interactive-activation models",
            "theory_or_model_description": "Concepts are represented as nodes in a network whose activation values spread to connected nodes; activation is often unbounded but controlled by decay, and retrieval/relevance is a function of activation levels influenced by input and network structure.",
            "representation_format_type": "distributed/activation-based (connectionist)",
            "key_properties": "Continuous activation levels, spreading dynamics, decay functions for temporal control, associative relevance (higher activation = higher relevance), often subsymbolic and distributed representations with graded effects from multiple inputs.",
            "empirical_support": "Cited as accounting for context effects in perception and associative relevance (references to Anderson 1982 and Rumelhart & McClelland 1981/1982), and as influential models for semantic activation and retrieval phenomena.",
            "empirical_challenges": "Paper argues these models often ignore explicit symbolic provenance of uncertainty and that decay-based control can produce counter-intuitive relevance differences when support paths differ in length (example: multi-step support vs shorter paths), suggesting potential mismatches with some belief-maintenance intuitions.",
            "applied_domains_or_tasks": "Semantic memory, context effects in perception, associative retrieval, explanation of graded human judgments in many cognitive tasks.",
            "comparison_to_other_models": "Contrasted with the endorsement network: spreading-activation uses numeric activations without explicit symbolic support structure; endorsement model prefers bounded belief values and explicit provenance; spreading-activation's decay mechanism is argued to be problematic for belief maintenance.",
            "functional_mechanisms": "Activation spreading via weighted links; decay over time to prevent unbounded activation; competition/inhibition mechanisms sometimes used to resolve alternatives (e.g., inhibitory clusters).",
            "limitations_or_open_questions": "Does not explicitly record how numeric activation values were computed (lack of symbolic justification); decay-based relevance heuristics may misrepresent multi-step evidential support; integration of uncertainty provenance is limited in standard formulations.",
            "uuid": "e5161.1"
        },
        {
            "name_short": "Fuzzy Propositions",
            "name_full": "Fuzzy propositional logic / Fuzzy representation (Zadeh)",
            "brief_description": "Representation of propositions with graded truth values (membership degrees) allowing partial truth; applied to commonsense knowledge representation to capture vagueness.",
            "citation_title": "Commonsense knowledge representation based on Fuzzy Logic",
            "mention_or_use": "mention",
            "theory_or_model_name": "Fuzzy propositional representation",
            "theory_or_model_description": "Conceptual knowledge is encoded as propositions with degrees of truth/membership (continuous values between false and true), enabling representation of vague predicates and graded beliefs at a functional level.",
            "representation_format_type": "graded/continuous propositional (fuzzy)",
            "key_properties": "Graded truth values, handles vagueness/partial membership, algebra of fuzzy sets and operators for logical combination, quantitative but not necessarily providing provenance for belief sources.",
            "empirical_support": "Mentioned as a quantitative approach to uncertainty with references to Zadeh; paper notes fuzzy values provide expressive gradedness to statements.",
            "empirical_challenges": "Paper argues quantitative assumptions (including fuzzy) can be overly restrictive or lack expressive power for representing provenance and interactions among evidence; fuzzy values alone do not explain how beliefs were derived.",
            "applied_domains_or_tasks": "Commonsense knowledge representation, handling vagueness in natural language and decision tasks requiring graded judgments.",
            "comparison_to_other_models": "Compared to the endorsement model as another numeric scheme; endorsement model augments numeric grades with symbolic endorsement structure to retain reasons-for beliefs, which fuzzy logic formulations typically do not provide.",
            "functional_mechanisms": "Use of membership functions and fuzzy combination operators to compute degrees of truth for composed propositions (not elaborated in detail in this paper).",
            "limitations_or_open_questions": "Lack of explicit representation of evidential provenance and interaction among supports; potential insufficiency to capture heuristic-driven human reasoning processes as described by Kahneman & Tversky.",
            "uuid": "e5161.2"
        },
        {
            "name_short": "Heuristics (K&T)",
            "name_full": "Kahneman & Tversky heuristics (representativeness, availability, anchoring)",
            "brief_description": "A set of decision heuristics describing how people simplify judgment under uncertainty — e.g., representativeness (similarity-based weighting), availability (retrievability-based weighting), and anchoring-and-adjustment (starting from a salient value and adjusting).",
            "citation_title": "Judgment under uncertainty: Heuristics and Biases",
            "mention_or_use": "mention",
            "theory_or_model_name": "Heuristics and biases framework (Kahneman & Tversky)",
            "theory_or_model_description": "Functional-level account that humans rely on a small set of cognitive heuristics to make judgments under uncertainty; these heuristics bias how evidence is selected, weighted and combined, shaping the effective representation and use of conceptual knowledge in decision contexts.",
            "representation_format_type": "process-level heuristic-guided sampling/weighting of representations (procedural/algorithmic rather than purely representational type)",
            "key_properties": "Selective relevance (availability), similarity-based weighting (representativeness), anchor bias (adjustment from initial values); heuristics constrain which propositions get endorsements and how evidence is aggregated.",
            "empirical_support": "Paper cites Kahneman & Tversky's demonstrations of decisions that deviate from normative mathematical theories, and uses their heuristics as guiding principles for which endorsements are collected and how they are weighted in the endorsement model.",
            "empirical_challenges": "Heuristic-based behavior is often non-normative relative to probability theory; the endorsement model attempts to capture these heuristics but the paper notes specifying heuristics formally and validating them remains challenging.",
            "applied_domains_or_tasks": "Human judgment and decision-making under uncertainty, modeling biases in probabilistic reasoning, guiding collection/selection of evidence in belief systems.",
            "comparison_to_other_models": "Used within the endorsement model to constrain evidence collection and weighting, contrasted with pure probabilistic/utility-maximizing frameworks which assume normative computation rather than heuristics.",
            "functional_mechanisms": "Heuristics determine which propositions are considered (relevance/availability), how endorsements are weighted (anchoring and adjustment), and how similarity/agreement among evidence affects certainty (representativeness and resolution heuristics).",
            "limitations_or_open_questions": "Heuristics are descriptive and require formalization for computational models; integrating them with principled aggregation formulas raises questions about parameterization and generality.",
            "uuid": "e5161.3"
        },
        {
            "name_short": "Inhibitory Clusters",
            "name_full": "Inhibitory clusters (Rumelhart & Zipser)",
            "brief_description": "A competitive organization in connectionist networks where units within a group inhibit each other so that the most strongly activated unit suppresses alternatives, used to implement mutual exclusivity or winner-take-all dynamics.",
            "citation_title": "Feature Discovery by Competitive Learning",
            "mention_or_use": "mention",
            "theory_or_model_name": "Inhibitory cluster / competitive learning mechanism",
            "theory_or_model_description": "Functional mechanism in which nodes are arranged in mutually inhibiting clusters so that the node with the highest activation inhibits others, producing competitive selection among alternatives.",
            "representation_format_type": "distributed/competitive (connectionist mechanism)",
            "key_properties": "Mutual inhibition, competitive selection (winner-take-all tendencies), supports representation of mutually exclusive alternatives.",
            "empirical_support": "Cited as similar in spirit to the endorsement-model's mutual exclusivity mechanism, providing a computational precedent for treating one strong endorsement as inhibiting others.",
            "empirical_challenges": "Connectionist competitive mechanisms may differ in how inhibition is implemented and in whether they preserve symbolic provenance; the endorsement model implements inhibition at the level of support-arcs to preserve evidential structure.",
            "applied_domains_or_tasks": "Feature discovery, competitive selection in categorization and representation learning.",
            "comparison_to_other_models": "Analogous to endorsement-model inhibition of competing supports but implemented at different representational levels (activation competition vs symbolic support inhibition).",
            "functional_mechanisms": "Lateral inhibition among units within a cluster leading to suppression of weaker alternatives; competitive learning algorithms adjust weights to reflect dominance patterns.",
            "limitations_or_open_questions": "How to reconcile subsymbolic competition with the need for explicit reasons/provenance when explaining beliefs; mapping between inhibitory clusters and symbolic endorsement structures is not one-to-one.",
            "uuid": "e5161.4"
        },
        {
            "name_short": "MYCIN CFs",
            "name_full": "MYCIN-style certainty-factor rule systems (Shortliffe)",
            "brief_description": "Rule-based expert systems that attach certainty factors (numeric weights) to rules and conclusions, combining uncertain evidence under assumptions (often conditional independence) to produce graded conclusions.",
            "citation_title": "Computer-based medical consultations: MYCIN.",
            "mention_or_use": "mention",
            "theory_or_model_name": "Certainty-factor rule-based representation",
            "theory_or_model_description": "Knowledge represented as symbolic rules augmented with numeric certainty factors; conclusions are derived by combining certainty factors according to system-specific combination rules to yield graded confidence in hypotheses.",
            "representation_format_type": "symbolic rule-based with numeric qualifiers",
            "key_properties": "Symbolic IF-THEN rules, numeric certainty factors, rule-based chaining; typically assumes conditional independence of evidence and mutual exclusivity among hypotheses in combination procedures.",
            "empirical_support": "Historically applied in medical diagnosis (MYCIN) and shown to produce useful expert-like decisions; cited here as a contrast to models that explicitly represent evidence interactions.",
            "empirical_challenges": "Paper criticizes MYCIN-style systems for requiring conditional independence and mutual exclusivity assumptions which limit expressive power regarding interacting or dependent evidence; lacks mechanisms for representing endorsements of endorsements.",
            "applied_domains_or_tasks": "Expert systems, rule-based diagnosis (especially medical), decision support where explicit rules are available.",
            "comparison_to_other_models": "Compared unfavorably (in this paper) to the endorsement model which can represent dependent evidence and endorse supports themselves; MYCIN treated as an example of a quantitative but structurally-limited approach.",
            "functional_mechanisms": "Forward/backward chaining of rules with propagation and combination of certainty factors according to ad-hoc combination formulas.",
            "limitations_or_open_questions": "Assumptions of independence and exclusivity limit applicability when evidence interacts; limited capacity to explain provenance beyond rule firing and numeric CFs.",
            "uuid": "e5161.5"
        },
        {
            "name_short": "Non-monotonic Logic / Circumscription",
            "name_full": "Non-monotonic reasoning and circumscription (McDermott & Doyle; McCarthy; Reiter)",
            "brief_description": "Symbolic logical formalisms for representing default, defeasible, or context-sensitive knowledge where conclusions can be withdrawn in light of new information (non-monotonicity), e.g., circumscription.",
            "citation_title": "Circumscription -A form of non-monotonic reasoning.",
            "mention_or_use": "mention",
            "theory_or_model_name": "Non-monotonic logical formalisms (circumscription, default reasoning)",
            "theory_or_model_description": "Conceptual knowledge is represented symbolically with rules and defaults that can be retracted when exceptions arise; reasoning is non-monotonic so adding information can invalidate prior conclusions, modeling common-sense defeasible inference.",
            "representation_format_type": "symbolic-logical (non-monotonic)",
            "key_properties": "Default rules, defeasible inference, formal mechanisms (e.g., circumscription) to minimize abnormality, retractability of conclusions, explicit symbolic structure supporting explanation.",
            "empirical_support": "Cited as traditional logical approach in AI for representing commonsense and defaults; offers principled symbolic mechanisms for defeasible reasoning.",
            "empirical_challenges": "Paper argues pure logical schemes do not cope well with graded uncertainty and human use of heuristics; logical formalisms may be poor at modeling the numeric and heuristic aspects of human reasoning under uncertainty.",
            "applied_domains_or_tasks": "Common-sense reasoning, knowledge representation in AI, modeling defaults and exceptions.",
            "comparison_to_other_models": "Presented as one of the classical approaches that the endorsement model seeks to augment/replace in contexts where graded uncertainty and heuristic decision-making are central; lacks natural handling of graded certainties and provenance of evidence strengths.",
            "functional_mechanisms": "Symbolic rule application with non-monotonic update policies (e.g., circumscription minimizes abnormal predicates), formal proof-theoretic mechanisms for retracting conclusions.",
            "limitations_or_open_questions": "Difficulty representing graded uncertainty and human heuristics; integration with numeric uncertainty measures and explanation of how human-like heuristics arise remains open.",
            "uuid": "e5161.6"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Judgment under uncertainty: Heuristics and Biases",
            "rating": 2,
            "sanitized_title": "judgment_under_uncertainty_heuristics_and_biases"
        },
        {
            "paper_title": "Variants of uncertainty",
            "rating": 2,
            "sanitized_title": "variants_of_uncertainty"
        },
        {
            "paper_title": "The architecture of cognition.",
            "rating": 2,
            "sanitized_title": "the_architecture_of_cognition"
        },
        {
            "paper_title": "An interactive activation model of context effects in letter perception: Part 1. An account of basic findings",
            "rating": 2,
            "sanitized_title": "an_interactive_activation_model_of_context_effects_in_letter_perception_part_1_an_account_of_basic_findings"
        },
        {
            "paper_title": "An interactive activation model of context effects in letter perception: Part 2. The contextual enhancement effect and some tests and extensions of the model",
            "rating": 2,
            "sanitized_title": "an_interactive_activation_model_of_context_effects_in_letter_perception_part_2_the_contextual_enhancement_effect_and_some_tests_and_extensions_of_the_model"
        },
        {
            "paper_title": "Feature Discovery by Competitive Learning",
            "rating": 2,
            "sanitized_title": "feature_discovery_by_competitive_learning"
        },
        {
            "paper_title": "Commonsense knowledge representation based on Fuzzy Logic",
            "rating": 2,
            "sanitized_title": "commonsense_knowledge_representation_based_on_fuzzy_logic"
        },
        {
            "paper_title": "Computer-based medical consultations: MYCIN.",
            "rating": 1,
            "sanitized_title": "computerbased_medical_consultations_mycin"
        },
        {
            "paper_title": "Circumscription -A form of non-monotonic reasoning.",
            "rating": 1,
            "sanitized_title": "circumscription_a_form_of_nonmonotonic_reasoning"
        },
        {
            "paper_title": "Non-monotonic Logic I",
            "rating": 1,
            "sanitized_title": "nonmonotonic_logic_i"
        }
    ],
    "cost": 0.01189575,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Department of Computing and Information Science Department of Psychology Queen's University at Kingston Ontario
Canada</p>
<p>INTRODUCTION:</p>
<p>The development of mechanisms for the representation of knowledge has always been a central concern of artificial intelligence. The fundamental criteria for representational schemes have been adapted from criteria mathematics has set up for logical formalisms: (1) that a translation into the representation from natural language statements must be possible, and (2) that deduction and inference of a sort that yields results similar to human conclusions must be possible over the repre sentation. These criteria are not well met by knowledge representation schemes which are based on traditional mathematical logic. In particular human expression is characterized by the use of measures of uncertainty, and human reasoning often appears to not follow the dictates of logic and probability (Lindley, 1971).</p>
<p>There are several solutions for the problems of uncertain information. The first is what Cohen (1983) called· the "engineering solution". This solution is used by many models in artificial intelligence (McDermott and Doyle 1980;McDermott 1980;McCarthy 1979;Reiter 1980). The solution does not deal with uncertainty as a useful source of information and constraints; instead it reduces the problem domain in such a manner as to eliminate uncertainty. Unfortunately eliminating uncertainty results in a reformulated problem that is, at the best, only vaguely related to the original. The second solution is to make quantitative assumptions about uncertainty using probabilities and possibilities (Zadeh 1983(Zadeh , 1984Lee 1969;Edwards 1982;Shortcliffe 1975). The quantitative assumptions often prove to be overly restrictive and lacking in expressive power. The third solution is to use a utility based solution (Nosteller and Nogee 1951;Schoemaker 1980). This solution makes the unpleasant assumption that we can determine subjective utilities for events and manipulate these utilities in a formal manner. Also, there are no clear indications that humans attempt to maximize their expected utilities while reasoning.</p>
<p>A more promising approach to the role of uncertainty in human reasoning is presented by Kahneman and Tversky (1982a b). Their model indicates that humans employ a set of basic heuristics which aid in making decisions in conditions of uncertainty. These heuristics enable humans to constrain problem domains such that the uncertainty becomes manageable but still useful. Once these heuristics are re cognized as a part of human reasoning it no longer appears illogical in the sense of being erratic. but rather more pragmatic and difficult to specify in terms of the logical inference mechanisms of tradi tional logic. Humans simplify decision making situations and use mental shortcuts to reach solutions which are satisfactory within constraints, but not necessarily optimal with respect to formal mathe matical theory. Kahneman and Tversky (ibid) provide numerous examples in which subjects reach decisions which run counter to those reached by mathematical theories.</p>
<p>The research reported in this paper pursues the problem of developing representational and inference mechanisms for talking about human reasoning under conditions of uncertainty . The direction we have taken is based on the belief that methods which model the way people think under uncertainty may be used in the construction of flexible and more understandable computational reasoning svstems. The model developed here involves collecting reasons for believing or disbelieving propositions as Cohen (1983) does in his model of endorsement, and then qualifying these reasons by a measure of belief. In addition the belief measures can have varying degrees of certainty. The belief and certainty values can be used: (1) to determine how supportive a body of evidence for a particular hypothesis is and (2) to represent evidential relationships such as conflicts between decisions (Craddock 1986).</p>
<p>BELIEF AND CERTAINTY:</p>
<p>We shall now proceed with defining a network containing propositions with beliefs and certainties, interconnected by arcs. First, let P be a set of cognitive units p = {nl ... n,.}. Each of these cognitive units may represent a proposition such as I LIKE MATH or rela tionships among objects such as one might employ in descriptions of visual scenes. Each n; has asso ciated with it a belief strength b; , which is a measure of the extent to which the cognitive unit is believable. The believability of n; is a measure of the completeness of the supporting evidence for flj, not a measure of its incidence of occurrence or its possibility of occurrence. As -1 � b; � 1, we may view the cognitive units as statements in a fuzzy propositional logic in which a belief of -1 indicates n; is false and a belief of +1 indicates n; is true.</p>
<p>In addition, each n; has associated with it a certainty, c, of the assignment of the value b, where 0 � c; � 1. The certainty of a belief value is defined as a measure of the reliability of the evidence which was used to calculate a particular belief (Hamburger, 1985). Thus each cognitive unit represents two distinct aspects of the Rational R; = (b;, c;) of n;. To illustrate the distinction between the components, consider I LIKE MATH. This may have, for example b; = 0.4 indicating moderately strong liking for mathematics 1. On the other hand, the certainty c, of this value might be high or low, depending on the person's exposure to mathematics. Thus, it is important to note that the measure of a statement's cer tainty is not closely related to its belief. A statement can be highly believable but still be very uncertain.</p>
<p>In a like fashion, a statement can be unbelievable but its incredibility may be very certain.</p>
<p>Any cognitive unit may endorse another. Each endorsement has associated with it a numeric value corresponding to the extent of the support between the units. If n; endorses n i then the support node s; i is the support for the endorsement where -1 � S; i � 1. If -1 � s; i &lt; 0 then the endorsement n; for n i is said to be inhibitory and if 0 � s; i � 1 then it is said to be excitatory. The support nodes for the endorsement, s; i may be endorsed by other cognitive units. For example: I LIKE PSYCHOLOGY may endorse I LIKE COMPUTING but the support for the endorsement may be contingent on COMPUTATION MAY MODEL COGNmON(see figure 1). If COMPUTATION MAY MODEL COGNITION is false then the support for the endorse ment will decrease (Craddock 1986).</p>
<p>Before going on to consider the mechanisms which permit dynamic evaluations and maintenance of belief based on these assigned values, it is useful to develop a network representation for the belief system. If we consider P = { n1 ... n'"} as the set of propositional nodes of the network, then we can define S' = {sij I n;, n i E P, S; { ,.,= 0} as a subset of support nodes such that n; endorses nj with support si j • and T = {ts;·l s; i E S', n1c E P)' as the other subset of support nodes such that n1c endorses s; i with support fs; • We cari then define the network N = <P, S> where S = S' U T is a finit set of support nodes re pfesenting the arcs and Pis a finit set of propositions._ 3. COMPUTING BELIEF AND CERTAINTY VALUES: We wish to develop ways of computing the values of Rationale R; for a proposition n; on the basis of the endorsements available for that node. The strength of an endorsement between two nodes must be computed with consideration of b,. For example, given the structure as shown in figure 2, if a person likes essays, ie. b; = .8, then a net negative endorsement results for the node representing LIKING COMPUTING sciENCE, but if the value of b, is low, a net positive endorsement would result. We can compute this endorsement strength as e,1 = b;s, i .</p>
<p>In this system, the belief strength· of a node may be computed from the beliefs and certainties of its endorsements. We note, however, that it is not possible to compute this for all nodes in the network because to do so would require every node to have endorsements. Any node in the system, can be provided with an Intuition represented as I, = (b',c',). This structure appears much the same as the 
I I sij I LIKE PSYCHOLOGY 1----------1•�1 1 LIKE COMPUTING �-------------------� R; = (b;. C;) Ri = (bi, C) COMPUTATION MAY MODEL COGNITION R k = -(b k, ck) Figure 1.
An example of an endorsement which influences the strength of endorsement between two other nodes.</p>
<p>Rationale structure except that its values are never computed, but they remain available to take part in the computation of other beliefs. As we shall see later on, if a node has both a Rationale, and an In tuition, the system will check to verify that the values do not become inconsistent.</p>
<p>The computation of a belief value for a node is a function of the summary of the evidence and argu ments. In such instances belief depends on: (1)  c i rei=-.</p>
<p>[2] ·C where c· is max {ci ... c,.}. In this manner we can define a measure of belief using a formula such as m bi = I:rck X 'ki X b k k-1</p>
<p>(3]</p>
<p>Allowing the support of an endorsement to be endorsed enables us to deal with situations in which the endorsements {!11 .. . nm} for n1 are mutually exclusive. n 1 will be given an endorsement of b·sk i where b' = max {b1 ... bm}· The node nk will inhibit all the other endorsements by giving an inhibitory endorsement to their respective supports for the endorsement. This mutual exclusivity is somewhat similar to Rumelhart and Zipser's (1985) "Inhibitory Clusters" where nodes were arranged in groups in which the node with the highest activation inhibits the activations of all the other nodes. The certainty of a belief is calculated as a function of the agreement of the individual endorsement strengths with the final belief value calculated from them. Thus, belief must be calculated before cer tainty. The importance of the agreement is once again measured as a function of the relative support of the individual endorsements and their relative certainties. As these values increase so does the un certainty associated with disagreement. Where {n1 ... n,.} are the endorsing nodes for n1, this effect can be modelled in formulas such as:
�... ..- 1 _ LI _ K _ E_ E _ S _ S _ A _ Y _ s __ ----ll----s -ijci = 1-[ i: I (bk-bi) I X rki X rck]
[4] k ,oj, k =O 4. A NETWORK OF BELIEF STRUCTURES The model described so far is similar to many existing connectionist models, particularly the spreading activation models of Anderson {1982), McClelland {1982), andMcClelland andRumelhart (1983). However, because the model is intended to represent belief maintenance with uncertainty it differs in several important respects. First, the un certainty of a proposition is represented numerically, as the values of R;, and non-numerically, as the structure of endorsements. Second, once the endorsements have been collected they are subject to reasoning and natural heuristics to compute numeric values as depicted in formulae [1] to [4]. In con trast, most connectionist models ignore, or do not explicitly deal with the non-numeric representation of uncertainty, depending on numeric values alone which provide no evidence as to how they were calculated, what they actually represent, or how reliable they are.</p>
<p>Third, many recent spreading activation models (Anderson, 1982) propose that no limit be placed on the numeric "activation level" associated with a node. Instead, a decay function, dependent on the elapsed time since activation, is used to stop activation levels from increasing without bound. This al lows the models to use the level of activation as an "associative relevancy" heuristic (Anderson, 1982) which states: The greater the activation of a node, the more relevant and closely associated it is to the problem. However, in this model we are representing belief, not activation, and belief can be bounded by truth, b; = 1, and falsehood, b; = -1. The relative importance of an endorsement, rii• and its relative certainty, rc;, provide a measure similar to the ''associative relevance" heuristic. Using a decay function can provide erroneous results in a belief maintenance system. Consider, for example, that doing WELL IN MATH endorses being a GOOD MATH STUDENT which in turn endorses taking a MATH MAJOR. In a model with a decay function the activation for being a MATRMAJOR will be less if activation has spread from the first endorsement than if it spread only from GOOD MATH sTUDENT. This is because it takes longer for activation to spread through three links as opposed to two. This is counter-intuitive, because if GOOD MATH sTUDENT is unsupported then it is not really as good a source of support. For this reason, this model uses inhibitory endorsements and bounded beliefs along with a relaxation algorithm to control the propagation and level of belief (Craddock 1986).</p>
<p>A further difference is that the proposed model can represent varying degrees of interaction between sources of evidence while models such as MYCIN (Shortcliffe, 1975) must make the assumption that all evidence is conditionally independent and that hypotheses are mutually exclusive. For example, the dynamic strengths of endorsement (see figure 1) allow us to represent evidence which is disjunctive, that is, strong belief may be propagated on the basis of only one of many supports. The endorsement with the greatest combination of relative certainty, belief and support inhibits the strengths of endorsement from the other nodes endorsing the decision so that they are effectively ignored. The amount of inhibition can be varied so that in instances where the endorsements are dependent no inhibition takes place. This is not to be confused with instances in which the proposition's belief is inhibitorly endorsed. To do so would indicate that its supporting evidence had been changed resulting in the unfortunate side-effect of altering the support the effected node would provide in an independent decision (Craddock 1986). The first class of heuristics are influenced by the methods which humans appear to use while con straining and simplifying a problem; making the uncertain knowledge manageable but still useful. Of particular importance are Tversky's (1973, 1982a, b, c) heuristics of relevance and availability, and Anderson's (1982) previously mentioned heuristic of associative relevance. These heuristics make the common statement that the only propositions which will be endorsed are those with endorsements. It is safe to assume that those propositions which are not endorsed are either irrelevant or unavailable to the decision task. As mentioned in section 4 the available information with the greatest combined belief, relative certainty and relative importance is weighted with proportionate strength in the calculation of belief and certainty in formulae [3] and [4].</p>
<p>The second class of heuristics are influenced by the findings that bodies of evidence interact in complex ways. Among those modelled is Kahneman and Tversky's (ibid) heuristic of adjustment and anchoring, used to describe the human characteristic of making estimates from an initial value and then adjusting it to give the final answer. As mentioned in section 4 and formulae (3] and[-+], endorsements with the greatest combined belief, relative certainty, and relative support, are weighted proportionately. The final belief values are thus biased or anchored towards these endorsements to model the phenomenon called adjustment.</p>
<p>In addition, the second class of heuristics attempt . to model Kahneman and Tversky's (ibid) heuristic of representativeness. Kahneman and Tversky discovered that the similarity between data has a dra matic impact on how conclusions are weighted. As agreement between evidence increases so does the certainty of conclusions. As seen in formula [2], an endorsement with absolute uncertainty, rc, = 0, will have no effect on the weighted sum of support in [3] and [4]. This heuristic is called the ignorance heuristic. In a similar fashion the certainty heuristic states that as the overall certainty of a set of endorsements decreases, i.e. as L.rc; approaches 1, so does the resultant certainty, i.e. 1l: I bk-b i I rk;'Ck approaches 0. Finally, in formulae [4], certainty is inversely proportional to the disagreement between an endorsements belief, b;, and the newly calculated belief, b i , of the endorsed node. This allows us to model the range heuristic which states that certainty will be a maximum if all the endorsements agree in their new belief of the node, and the resolution heuristic, which states that as supporting evidence moves closer to the same value, disagreement will decrease and so will uncer tainty. We shall now see what happens when endorsements are in complete disagreement.</p>
<ol>
<li>CONTRADICTION�: Rational contradictions among endorsements are defined as follows: If A is compelling evidence against n; but b is equally compelling evidence for n; then the endorsements for n; are inconsistent. In addition to a rational contraction an intuitive contradiction can also be defined: If the intuitive belief, b'; is not equal to the rational belief, b; then the two beliefs are inconsistent. Intuitive contradictions are useful for recognizing changes in belief through a knowledge base when knowledge is added and removed. In addition they can be used to control cycles which may force more global interpretations on input propositions. When cycles exist within a network N = <P, S>, belief and certainty values will only be calculated for nodes in a partial network N' = P', S', where P'c;;, P , and S'c;;, Sn(PXP'), where there exists a node n; E P -P' such that there is an elementary path between n; to P' and I I; -R; I &gt; T;. CONCLUSIONS: The model discussed in this paper seeks to develop representational and inference mechanisms capable of dealing with incomplete, inaccurate, and uncertain information. To this end, a model is proposed al}� heuristics are developed to collect and evaluate the endorsements for prop ositions in the network of beliefs. At the same time it is intended that the model represent at least some of the processes used in human reasoning. As the downfall of many expert systems with large data bases is that they can not determine which data is relevant to the problem, artificial intelligence may be able to use reasoning methods similar to humans to deal more effectively with uncertainty in decision making.</li>
</ol>
<p>A second conclusion is that heuristics provide a very useful means of guiding the collection and eval uation of information. The constraints that these heuristics place on the decision making not only simplify the task, but allow uncertainty to remain useful. While the heuristics proposed in this paper are by no means exhaustive nor the formulae necessarily optimal, they do illustrate how heuristics might be incorporated into the decision making model in a straight forward fashion (Craddock 1986).</p>
<p>Finally, of major issue is the belief that numerical values, blindly tallied, are an inadequate repre sentation of reasoning. Symbolic structures of support are necessary to specify how and why numeric beliefs are calculated. The incorporation of numerically qualified endorsements allows the model to not only provide numerical information, but it can also describe its reasoning process from start to finish in terms of reasons for and against a decision. The advantages of having a model whose reasoning can be readily understood are numerous if the model is to be used in situations where it is imperative that the justifications for a decision be made clear. In its present prototype form it is difficult to determine the extent to which the model may act as a model of human reasoning. It does, however, offer some attractive directions for further research.</p>
<p>This system does not distinguish between liking most mathematics, or liking all mathematics to some extent.</p>
<p>measuring the varying contributions of the individual endorsements and (2) measuring the effects of interaction among the different endorsements. This interaction among a set of endorsements {n1 ... n,.} for n1 depends on the relative importance of each endorsement defined as and the relative certainty defined as</p>
<p>Figure 2 .
2: An example of an endorsement which may have net positive or net negative sup port.</p>
<p>5 .
5HEURISTICS: Within the model presented, uncertain knowledge is dealt with by using two distinct classes of heuristics. The first class of heuristics are used to determine which information is relevant to a decision. This class of heuristics is used to guide the collecting of endorsements. The second class of heuristics can then be used to evaluate the collected endorsements.</p>
<p>The architecture of cognition. R Anderson, Harvard University PressAnderson, R, The architecture of cognition. Harvard University Press, 1982.</p>
<p>The use of heuristic knowledge in decision theory. R Cohen, A J Craddock, Diss. Stanford University ; Queeen's University at KingstonMSc. ThesisModelling uncertainty in a knowledge baseCohen, R, "The use of heuristic knowledge in decision theory," Diss. Stanford University, 1983. Craddock, A. J., "Modelling uncertainty in a knowledge base," MSc. Thesis, Queeen's University at Kingston, 1986.</p>
<p>Combining uncertain estimates. Uncertainty and Probability in Artificial Intelligence. H Hamburger, Los Angeles, CaliforniaUCLAHamburger, H., Combining uncertain estimates. Uncertainty and Probability in Artificial Intelligence. August 14-16, 1985. UCLA: Los Angeles, California, 1985.</p>
<p>Variants of uncertainty. D Kahneman, Tversky A , Cognition. 11Kahneman D., and Tversky A., "Variants of uncertainty," Cognition, 11 (1982a) pp. 143-157.</p>
<p>D Kahneman, Tversky A , Judgment under uncertainty: Heuristics and Biases. Cambridge University PressKahneman D., and Tversky A., Judgment under uncertainty: Heuristics and Biases. Cambridge University Press, 1982b.</p>
<p>Decision theory and human behaviour. W Lee, D Lindley, Wiley-InterscienceNew York; New YorkMaking DecisionsLee, W., Decision theory and human behaviour. New York: Wiley, 1969. Lindley, D., Making Decisions. New York: Wiley-Interscience, 1971</p>
<p>Circumscription -A form of non-monotonic reasoning. J Mc C Arthy, Artificial Intelligence. 13Mc C arthy, J.. "Circumscription -A form of non-monotonic reasoning." Artificial Intelligence, 13 (1980), pp. 27 -39.</p>
<p>An interactive activation model of context effects in letter perception: Part 1. An account of basic findings. J L Mc C Lelland, D E Rumelhart, Psychological Review. 88Mc C lelland, J. L., and Rumelhart, D. E. , "An interactive activation model of context effects in letter perception: Part 1. An account of basic findings," Psychological Review, 88 ( 1981) pp. 37 5-407.</p>
<p>Non-monotonic Logic I. D Mcdermott, Doyle , J , Artificial Intelligence. 13McDermott, D., and Doyle, J., "Non-monotonic Logic I," Artificial Intelligence, 13 (1980) pp. 41 -72.</p>
<p>Non-monotonic modal theories. D Mcdermott, 174Computer Science Dept., Yale UniversityReportMcDermott, D., "Non-monotonic modal theories," Report No. 174, Computer Science Dept., Yale University, 1980.</p>
<p>An experimental measurement of utility. F Nosteller, P Nogee, Journal of Political Economy. 59Nosteller, F., and Nogee, P., "An experimental measurement of utility," Journal of Political Economy, 59 (1951), pp. 371 -404.</p>
<p>A logic for default reasoning. R Reiter, Artificial Intelligence. 13Reiter, R., "A logic for default reasoning," Artificial Intelligence, 13 (1980), pp. 81-132.</p>
<p>An interactive activation model of context effects in letter perception: Part 2. The contextual enhancement effect and some tests and extensions of the model. D E Rurnelhart, J L Mcclelland, Psychological Review. 89Rurnelhart, D. E., and McClelland, J. L. , "An interactive activation model of context effects in letter perception: Part 2. The contextual enhancement effect and some tests and extensions of the model," Psychological Review, 89 (1982), pp. 60-94.</p>
<p>Feature Discovery by Competitive Learning. D E Rumelhart, D Zipser, Cognitive Science. 975Rumelhart, D. E. and Zipser D., "Feature Discovery by Competitive Learning," Cognitive Science, 9: 1985, pp. 75 -u:.</p>
<p>Experiments on decisions under risk: The expected utility hypothesis. P Schoemaker, Martinus Nijhoff. BostonSchoemaker, P., Experiments on decisions under risk: The expected utility hypothesis. Boston: Martinus Nijhoff, 1980.</p>
<p>Commonsense knowledge representation based on Fuzzy Logic. Shortcliffe, Computer-based medical consultations: MYCI.:'&lt;J. New YorkAmerican Elsevier16Shortcliffe. Computer-based medical consultations: MYCI.:'&lt;J. New York: American Elsevier, 1975. Zadeh L.A:, '"Commonsense knowledge representation based on Fuzzy Logic," Computer, Vol 16, 10 (1983), pp. 6l-66.</p>
<p>Making computers think like people. L A Zadeh, IEEE Spectrum. Zadeh L.A., ' 'Making computers think like people," IEEE Spectrum, Aug. 1984,</p>            </div>
        </div>

    </div>
</body>
</html>