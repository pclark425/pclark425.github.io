<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2449 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2449</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2449</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-66.html">extraction-schema-66</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated research systems, AI scientists, or automated idea generation/implementation systems, including details about what types of research problems they were applied to, the characteristics of those problems, and the success or failure rates of the automated system.</div>
                <p><strong>Paper ID:</strong> paper-272367281</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2409.00102v1.pdf" target="_blank">Collective predictive coding as model of science: formalizing scientific activities towards generative science</a></p>
                <p><strong>Paper Abstract:</strong> This article proposes a new conceptual framework called collective predictive coding as a model of science (CPC-MS) to formalize and understand scientific activities. Building on the idea of CPC originally developed to explain symbol emergence, CPC-MS models science as a decentralized Bayesian inference process carried out by a community of agents. The framework describes how individual scientistsâ€™ partial observations and internal representations are integrated through communication and peer review to produce shared external scientific knowledge. Key aspects of scientific practice like experimentation, hypothesis formation, theory development and paradigm shifts are mapped onto components of the probabilistic graphical model. This article discusses how CPC-MS provides insights into issues like social objectivity in science, scientific progress and the potential impacts of artificial intelligence on research. The generative view of science offers a unified way to analyse scientific activities and could inform efforts to automate aspects of the scientific process. Overall, CPC-MS aims to provide an intuitive yet formal model of science as a collective cognitive activity.</p>
                <p><strong>Cost:</strong> 0.019</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2449.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2449.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated research systems, AI scientists, or automated idea generation/implementation systems, including details about what types of research problems they were applied to, the characteristics of those problems, and the success or failure rates of the automated system.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DENDRAL</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Dendral: a case study of the first expert system for scientific hypothesis formation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An early expert-system research automation effort mentioned as a pioneering example of automating aspects of scientific hypothesis formation using symbolic AI; historically applied to scientific discovery tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Dendral: a case study of the first expert system for scientific hypothesis formation</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>DENDRAL</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Historically seminal expert system that automated parts of scientific hypothesis formation using symbolic/knowledge-based methods; cited in this paper only as a canonical early example of automating scientific tasks (no implementation details provided here).</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>Automated Discovery System / Expert System</td>
                        </tr>
                        <tr>
                            <td><strong>problem_domain</strong></td>
                            <td>Scientific hypothesis formation (historical example often applied to chemistry-related inference tasks)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Automating the generation and evaluation of scientific hypotheses within a constrained domain using encoded symbolic knowledge and rules; cited generically as a pioneering automation system.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Not specified in this paper; historically involved combinatorial search over structured hypothesis spaces but no quantitative measures are provided here.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Not described in this paper; original systems used domain rules and experimental/empirical data available at the time.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_requirements</strong></td>
                            <td>Not specified in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_structure</strong></td>
                            <td>Relatively well-defined and constrained domain (symbolic, discrete hypothesis space) with clear evaluation criteria (consistency with observations); the paper does not provide further structure details.</td>
                        </tr>
                        <tr>
                            <td><strong>success_metric</strong></td>
                            <td>Not specified in this paper (historically assessed by ability to produce scientifically useful hypotheses and match experimental evidence).</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>Not described in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Domain-specific symbolic knowledge and constrained search space (implied historically); not detailed in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>comparative_results</strong></td>
                            <td>No comparative performance details provided in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>human_baseline</strong></td>
                            <td>Not provided in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Collective predictive coding as model of science: formalizing scientific activities towards generative science', 'publication_date_yy_mm': '2025-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2449.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2449.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated research systems, AI scientists, or automated idea generation/implementation systems, including details about what types of research problems they were applied to, the characteristics of those problems, and the success or failure rates of the automated system.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BACON</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>BACON (scientific discovery system)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An early computational system for automating scientific discovery (cited historically); presented as another foundational example of automated scientific reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Scientific discovery: Computational explorations of the creative processes</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>BACON</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A historically influential system cited as an early attempt to automate scientific discovery and induction; in this paper it is referenced only as an archetypal precursor to modern automation efforts.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>Automated Discovery System / Inductive Inference System</td>
                        </tr>
                        <tr>
                            <td><strong>problem_domain</strong></td>
                            <td>General scientific discovery / induction (historical examples across physical and empirical sciences)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Automating the discovery of empirical laws and regularities from data within constrained laboratory settings; this paper only mentions BACON in passing and gives no implementation details.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Not specified in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Not specified in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_requirements</strong></td>
                            <td>Not specified in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_structure</strong></td>
                            <td>Historically targeted relatively well-structured inductive tasks; the current paper does not elaborate.</td>
                        </tr>
                        <tr>
                            <td><strong>success_metric</strong></td>
                            <td>Not specified in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>Not specified in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Not detailed here; historically benefited from narrow domains and explicit rule representations.</td>
                        </tr>
                        <tr>
                            <td><strong>comparative_results</strong></td>
                            <td>No comparative information in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>human_baseline</strong></td>
                            <td>Not provided in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Collective predictive coding as model of science: formalizing scientific activities towards generative science', 'publication_date_yy_mm': '2025-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2449.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2449.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated research systems, AI scientists, or automated idea generation/implementation systems, including details about what types of research problems they were applied to, the characteristics of those problems, and the success or failure rates of the automated system.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ADAM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Adam (robot scientist)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A closed-loop laboratory automation system that combines symbolic AI and robotics to automatically generate hypotheses, perform experiments, and revise hypotheses based on feedback; cited as an example of near end-to-end automation in a single research area.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Functional genomic hypothesis generation and experimentation by a robot scientist</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Adam</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Described in this paper as a closed-loop automation system integrating symbolic AI for hypothesis generation with robotic execution to verify hypotheses experimentally and update its models based on results; the paper cites Adam as an example of partial automation of the full research cycle.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>Automated Experimentation Platform / Robot Scientist / Closed-loop automation system</td>
                        </tr>
                        <tr>
                            <td><strong>problem_domain</strong></td>
                            <td>Functional genomics (experimental molecular biology)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Automating hypothesis generation about gene function and conducting laboratory experiments to test those hypotheses in a loop that refines subsequent hypotheses based on experimental feedback (as cited; no experimental detail given here).</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Experimental biology with combinatorial hypothesis spaces and wet-lab constraints; complexity specifics (dimensionality, search-space size) are not provided in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Data are primarily generated by the automated experimental platform (wet-lab outputs); the paper notes the closed-loop nature but provides no quantitative data availability details.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_requirements</strong></td>
                            <td>Not quantified in this paper; the system combines symbolic AI components with robotics and experimental hardware (implying both compute and instrumentation requirements).</td>
                        </tr>
                        <tr>
                            <td><strong>problem_structure</strong></td>
                            <td>Well-defined experimental loop with clear objective (experimental validation) but subject to stochastic biological noise and constraints of laboratory procedures; domain expertise required for assay design (paper does not enumerate specifics).</td>
                        </tr>
                        <tr>
                            <td><strong>success_metric</strong></td>
                            <td>Implied metrics are successful experimental validation of generated hypotheses and discovery of gene functions; the CPC-MS paper does not report quantitative metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>Paper does not enumerate metrics or failures; general limitations implied include domain restriction to experiments amenable to robotic automation and limited generality beyond those assays.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Tight integration of hypothesis generation, experimental protocol automation, and feedback-driven revision (implied); suitability of the experimental assays to robotic execution.</td>
                        </tr>
                        <tr>
                            <td><strong>comparative_results</strong></td>
                            <td>No comparative performance data are provided in this paper; Adam is listed as a notable example of partial automation.</td>
                        </tr>
                        <tr>
                            <td><strong>human_baseline</strong></td>
                            <td>Not provided in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Collective predictive coding as model of science: formalizing scientific activities towards generative science', 'publication_date_yy_mm': '2025-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2449.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2449.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated research systems, AI scientists, or automated idea generation/implementation systems, including details about what types of research problems they were applied to, the characteristics of those problems, and the success or failure rates of the automated system.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>EVE</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Eve (automated drug-repositioning/robot scientist example)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Mentioned as another closed-loop automation system (like Adam) used in automated discovery workflows; cited here as a historical example of automated experimental pipelines applied to biomedical problems.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Cheaper faster drug development validated by the repositioning of drugs against neglected tropical diseases</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Eve</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Cited in this paper as an example of a closed-loop research automation system used in biomedical/drug-repositioning contexts; the CPC-MS paper does not provide implementation details beyond acknowledging Eve as a notable attempt to automate hypothesis generation and experimental verification.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>Automated Experimentation Platform / Closed-loop automation system</td>
                        </tr>
                        <tr>
                            <td><strong>problem_domain</strong></td>
                            <td>Drug discovery / drug repositioning (biomedical sciences)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Automating aspects of drug-repositioning research including hypothesis generation about candidate compounds and automated experimental validation; specific experimental tasks and setup are not described in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Biomedical experimental complexity with many variables and costly experiments; this paper does not provide quantitative characterizations of complexity.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Not specified in this paper; experiments typically generate wet-lab assay data under resource constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_requirements</strong></td>
                            <td>Not specified in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_structure</strong></td>
                            <td>Experimental, stochastic, multi-factor biological assays with definable validation criteria (e.g., efficacy signals); additional detail not provided here.</td>
                        </tr>
                        <tr>
                            <td><strong>success_metric</strong></td>
                            <td>Not specified in this paper (original literature assesses success by validated repositioned drug candidates and speed/cost improvements).</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>Not discussed here; general limitations likely include assay suitability for automation and biological variability.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Automatable assays, closed-loop integration of hypothesis generation and experimentation; not explicitly enumerated in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>comparative_results</strong></td>
                            <td>None provided in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>human_baseline</strong></td>
                            <td>Not provided in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Collective predictive coding as model of science: formalizing scientific activities towards generative science', 'publication_date_yy_mm': '2025-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2449.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2449.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated research systems, AI scientists, or automated idea generation/implementation systems, including details about what types of research problems they were applied to, the characteristics of those problems, and the success or failure rates of the automated system.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AlphaFold</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>AlphaFold</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A deep learning system for protein structure prediction cited as a landmark example where AI for science produced discoveries that were previously unsolved by humans.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Highly accurate protein structure prediction with alphafold</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>AlphaFold</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Deep-learning based predictive system that maps protein sequence to 3D structure; used here as an example of AI-driven scientific advance that solved previously intractable problems in structural biology (no technical or numerical details given in this CPC-MS paper).</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>AI for Science / Predictive Modeling System</td>
                        </tr>
                        <tr>
                            <td><strong>problem_domain</strong></td>
                            <td>Structural biology / protein structure prediction</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Predicting three-dimensional protein structures from amino-acid sequences, a high-dimensional continuous prediction problem central to molecular biology.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>High-dimensional continuous output space, complex physics and folding landscape; quantitative complexity and computational cost are not described in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Trained on empirically solved protein structures (e.g., PDB) historically, but the CPC-MS paper does not quantify dataset sizes or coverage.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_requirements</strong></td>
                            <td>Not specified in this paper; known to require substantial compute for training in original work, but CPC-MS does not provide numbers.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_structure</strong></td>
                            <td>Supervised prediction problem with well-defined evaluation metrics in the original literature; described here at a conceptual level only.</td>
                        </tr>
                        <tr>
                            <td><strong>success_metric</strong></td>
                            <td>Not specified in this paper (original metrics include structure prediction accuracy measures; CPC-MS cites AlphaFold qualitatively as a success example).</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>Not discussed in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Availability of high-quality structural data and powerful generative/predictive ML methods (implied by citation), but not detailed here.</td>
                        </tr>
                        <tr>
                            <td><strong>comparative_results</strong></td>
                            <td>No comparative details provided in this paper beyond noting AlphaFold's significance.</td>
                        </tr>
                        <tr>
                            <td><strong>human_baseline</strong></td>
                            <td>Not provided in this paper (paper only qualitatively contrasts AI success with prior human limitations).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Collective predictive coding as model of science: formalizing scientific activities towards generative science', 'publication_date_yy_mm': '2025-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2449.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e2449.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated research systems, AI scientists, or automated idea generation/implementation systems, including details about what types of research problems they were applied to, the characteristics of those problems, and the success or failure rates of the automated system.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AI Scientist (Lu et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>The AI Scientist: Towards fully automated open-ended scientific discovery</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A recently proposed system described in the CPC-MS paper as capable of automating a wide range of research tasks end-to-end for machine learning research, including idea generation, experiments, paper writing, and peer review automation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>The ai scientist: Towards fully automated open-ended scientific discovery</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>AI Scientist (Lu et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Described by the CPC-MS paper as an AI system that attempts highly automated, end-to-end scientific research workflows for machine learning: from idea/hypothesis generation to experiment design/execution, result analysis, paper drafting, and (partially) peer-review; the CPC-MS paper highlights it as an advanced example but notes it remains specialized and does not yet automate the entire socially-distributed scientific process.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>AI Scientist / Automated Research System / End-to-end Research Automation</td>
                        </tr>
                        <tr>
                            <td><strong>problem_domain</strong></td>
                            <td>Machine learning research (meta-research / automated ML algorithm/architecture exploration and evaluation)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Automating the process of producing ML research artifacts: generating research questions or ideas, designing and running ML experiments, analyzing outcomes, drafting manuscripts, and automating parts of peer review and dissemination (as characterized by the CPC-MS paper).</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Open-ended research across algorithmic and experimental design spaces; multi-objective (novelty, empirical performance, reproducibility); search spaces include architectures, hyperparameters, datasets and evaluation protocols. The CPC-MS paper does not provide quantitative measures of dimensionality or search size.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Varies by subtask; the system uses ML datasets and simulation/benchmark tasks typical in ML research; the CPC-MS paper does not enumerate dataset sizes or access constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_requirements</strong></td>
                            <td>Implied to be large (training and evaluating many ML models, running experiments, producing manuscripts), but the CPC-MS paper provides no quantitative compute or cost figures.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_structure</strong></td>
                            <td>Highly open-ended and partially ill-posed: mixes discrete (architectures, experimental design choices) and continuous (hyperparameters) search; evaluation combines objective metrics (performance) and subjective/collective metrics (novelty, publishability); degree of domain knowledge required is high. The CPC-MS paper emphasizes that such systems still commonly automate a 'single scientist' workflow rather than community-level social processes.</td>
                        </tr>
                        <tr>
                            <td><strong>success_metric</strong></td>
                            <td>Not specified concretely in the CPC-MS paper; implied metrics include number/quality of publishable findings, empirical performance of proposed methods, and ability to automate writing/review processes.</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>CPC-MS highlights limitations: specialization to particular fields, lack of full social-collective automation (peer review and community consensus), communication/common-ground barriers between AI and human scientists, and potential low acceptance/poor integration when AI proposals diverge strongly from human priors.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Integration across hypothesis generation, experiment execution, and artifact generation; use of generative models and automation of writing/review pipelines; suitability to domains where experiments can be automated (implied).</td>
                        </tr>
                        <tr>
                            <td><strong>comparative_results</strong></td>
                            <td>The CPC-MS paper positions Lu et al.'s work as a significant advance but notes it still falls short of automating the entire social scientific process; no quantitative cross-system comparisons are provided in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>human_baseline</strong></td>
                            <td>Not provided in this paper; CPC-MS discusses conceptual comparisons (e.g., human social processes, peer review) but gives no empirical human-vs-AI performance numbers.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Collective predictive coding as model of science: formalizing scientific activities towards generative science', 'publication_date_yy_mm': '2025-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Functional genomic hypothesis generation and experimentation by a robot scientist <em>(Rating: 2)</em></li>
                <li>The ai scientist: Towards fully automated open-ended scientific discovery <em>(Rating: 2)</em></li>
                <li>Cheaper faster drug development validated by the repositioning of drugs against neglected tropical diseases <em>(Rating: 2)</em></li>
                <li>Highly accurate protein structure prediction with alphafold <em>(Rating: 2)</em></li>
                <li>Dendral: a case study of the first expert system for scientific hypothesis formation <em>(Rating: 2)</em></li>
                <li>The automation of science <em>(Rating: 2)</em></li>
                <li>Scientific discovery: Computational explorations of the creative processes <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2449",
    "paper_id": "paper-272367281",
    "extraction_schema_id": "extraction-schema-66",
    "extracted_data": [
        {
            "name_short": "DENDRAL",
            "name_full": "Dendral: a case study of the first expert system for scientific hypothesis formation",
            "brief_description": "An early expert-system research automation effort mentioned as a pioneering example of automating aspects of scientific hypothesis formation using symbolic AI; historically applied to scientific discovery tasks.",
            "citation_title": "Dendral: a case study of the first expert system for scientific hypothesis formation",
            "mention_or_use": "mention",
            "system_name": "DENDRAL",
            "system_description": "Historically seminal expert system that automated parts of scientific hypothesis formation using symbolic/knowledge-based methods; cited in this paper only as a canonical early example of automating scientific tasks (no implementation details provided here).",
            "system_type": "Automated Discovery System / Expert System",
            "problem_domain": "Scientific hypothesis formation (historical example often applied to chemistry-related inference tasks)",
            "problem_description": "Automating the generation and evaluation of scientific hypotheses within a constrained domain using encoded symbolic knowledge and rules; cited generically as a pioneering automation system.",
            "problem_complexity": "Not specified in this paper; historically involved combinatorial search over structured hypothesis spaces but no quantitative measures are provided here.",
            "data_availability": "Not described in this paper; original systems used domain rules and experimental/empirical data available at the time.",
            "computational_requirements": "Not specified in this paper.",
            "problem_structure": "Relatively well-defined and constrained domain (symbolic, discrete hypothesis space) with clear evaluation criteria (consistency with observations); the paper does not provide further structure details.",
            "success_metric": "Not specified in this paper (historically assessed by ability to produce scientifically useful hypotheses and match experimental evidence).",
            "success_rate": null,
            "failure_modes": "Not described in this paper.",
            "success_factors": "Domain-specific symbolic knowledge and constrained search space (implied historically); not detailed in this paper.",
            "comparative_results": "No comparative performance details provided in this paper.",
            "human_baseline": "Not provided in this paper.",
            "uuid": "e2449.0",
            "source_info": {
                "paper_title": "Collective predictive coding as model of science: formalizing scientific activities towards generative science",
                "publication_date_yy_mm": "2025-06"
            }
        },
        {
            "name_short": "BACON",
            "name_full": "BACON (scientific discovery system)",
            "brief_description": "An early computational system for automating scientific discovery (cited historically); presented as another foundational example of automated scientific reasoning.",
            "citation_title": "Scientific discovery: Computational explorations of the creative processes",
            "mention_or_use": "mention",
            "system_name": "BACON",
            "system_description": "A historically influential system cited as an early attempt to automate scientific discovery and induction; in this paper it is referenced only as an archetypal precursor to modern automation efforts.",
            "system_type": "Automated Discovery System / Inductive Inference System",
            "problem_domain": "General scientific discovery / induction (historical examples across physical and empirical sciences)",
            "problem_description": "Automating the discovery of empirical laws and regularities from data within constrained laboratory settings; this paper only mentions BACON in passing and gives no implementation details.",
            "problem_complexity": "Not specified in this paper.",
            "data_availability": "Not specified in this paper.",
            "computational_requirements": "Not specified in this paper.",
            "problem_structure": "Historically targeted relatively well-structured inductive tasks; the current paper does not elaborate.",
            "success_metric": "Not specified in this paper.",
            "success_rate": null,
            "failure_modes": "Not specified in this paper.",
            "success_factors": "Not detailed here; historically benefited from narrow domains and explicit rule representations.",
            "comparative_results": "No comparative information in this paper.",
            "human_baseline": "Not provided in this paper.",
            "uuid": "e2449.1",
            "source_info": {
                "paper_title": "Collective predictive coding as model of science: formalizing scientific activities towards generative science",
                "publication_date_yy_mm": "2025-06"
            }
        },
        {
            "name_short": "ADAM",
            "name_full": "Adam (robot scientist)",
            "brief_description": "A closed-loop laboratory automation system that combines symbolic AI and robotics to automatically generate hypotheses, perform experiments, and revise hypotheses based on feedback; cited as an example of near end-to-end automation in a single research area.",
            "citation_title": "Functional genomic hypothesis generation and experimentation by a robot scientist",
            "mention_or_use": "mention",
            "system_name": "Adam",
            "system_description": "Described in this paper as a closed-loop automation system integrating symbolic AI for hypothesis generation with robotic execution to verify hypotheses experimentally and update its models based on results; the paper cites Adam as an example of partial automation of the full research cycle.",
            "system_type": "Automated Experimentation Platform / Robot Scientist / Closed-loop automation system",
            "problem_domain": "Functional genomics (experimental molecular biology)",
            "problem_description": "Automating hypothesis generation about gene function and conducting laboratory experiments to test those hypotheses in a loop that refines subsequent hypotheses based on experimental feedback (as cited; no experimental detail given here).",
            "problem_complexity": "Experimental biology with combinatorial hypothesis spaces and wet-lab constraints; complexity specifics (dimensionality, search-space size) are not provided in this paper.",
            "data_availability": "Data are primarily generated by the automated experimental platform (wet-lab outputs); the paper notes the closed-loop nature but provides no quantitative data availability details.",
            "computational_requirements": "Not quantified in this paper; the system combines symbolic AI components with robotics and experimental hardware (implying both compute and instrumentation requirements).",
            "problem_structure": "Well-defined experimental loop with clear objective (experimental validation) but subject to stochastic biological noise and constraints of laboratory procedures; domain expertise required for assay design (paper does not enumerate specifics).",
            "success_metric": "Implied metrics are successful experimental validation of generated hypotheses and discovery of gene functions; the CPC-MS paper does not report quantitative metrics.",
            "success_rate": null,
            "failure_modes": "Paper does not enumerate metrics or failures; general limitations implied include domain restriction to experiments amenable to robotic automation and limited generality beyond those assays.",
            "success_factors": "Tight integration of hypothesis generation, experimental protocol automation, and feedback-driven revision (implied); suitability of the experimental assays to robotic execution.",
            "comparative_results": "No comparative performance data are provided in this paper; Adam is listed as a notable example of partial automation.",
            "human_baseline": "Not provided in this paper.",
            "uuid": "e2449.2",
            "source_info": {
                "paper_title": "Collective predictive coding as model of science: formalizing scientific activities towards generative science",
                "publication_date_yy_mm": "2025-06"
            }
        },
        {
            "name_short": "EVE",
            "name_full": "Eve (automated drug-repositioning/robot scientist example)",
            "brief_description": "Mentioned as another closed-loop automation system (like Adam) used in automated discovery workflows; cited here as a historical example of automated experimental pipelines applied to biomedical problems.",
            "citation_title": "Cheaper faster drug development validated by the repositioning of drugs against neglected tropical diseases",
            "mention_or_use": "mention",
            "system_name": "Eve",
            "system_description": "Cited in this paper as an example of a closed-loop research automation system used in biomedical/drug-repositioning contexts; the CPC-MS paper does not provide implementation details beyond acknowledging Eve as a notable attempt to automate hypothesis generation and experimental verification.",
            "system_type": "Automated Experimentation Platform / Closed-loop automation system",
            "problem_domain": "Drug discovery / drug repositioning (biomedical sciences)",
            "problem_description": "Automating aspects of drug-repositioning research including hypothesis generation about candidate compounds and automated experimental validation; specific experimental tasks and setup are not described in this paper.",
            "problem_complexity": "Biomedical experimental complexity with many variables and costly experiments; this paper does not provide quantitative characterizations of complexity.",
            "data_availability": "Not specified in this paper; experiments typically generate wet-lab assay data under resource constraints.",
            "computational_requirements": "Not specified in this paper.",
            "problem_structure": "Experimental, stochastic, multi-factor biological assays with definable validation criteria (e.g., efficacy signals); additional detail not provided here.",
            "success_metric": "Not specified in this paper (original literature assesses success by validated repositioned drug candidates and speed/cost improvements).",
            "success_rate": null,
            "failure_modes": "Not discussed here; general limitations likely include assay suitability for automation and biological variability.",
            "success_factors": "Automatable assays, closed-loop integration of hypothesis generation and experimentation; not explicitly enumerated in this paper.",
            "comparative_results": "None provided in this paper.",
            "human_baseline": "Not provided in this paper.",
            "uuid": "e2449.3",
            "source_info": {
                "paper_title": "Collective predictive coding as model of science: formalizing scientific activities towards generative science",
                "publication_date_yy_mm": "2025-06"
            }
        },
        {
            "name_short": "AlphaFold",
            "name_full": "AlphaFold",
            "brief_description": "A deep learning system for protein structure prediction cited as a landmark example where AI for science produced discoveries that were previously unsolved by humans.",
            "citation_title": "Highly accurate protein structure prediction with alphafold",
            "mention_or_use": "mention",
            "system_name": "AlphaFold",
            "system_description": "Deep-learning based predictive system that maps protein sequence to 3D structure; used here as an example of AI-driven scientific advance that solved previously intractable problems in structural biology (no technical or numerical details given in this CPC-MS paper).",
            "system_type": "AI for Science / Predictive Modeling System",
            "problem_domain": "Structural biology / protein structure prediction",
            "problem_description": "Predicting three-dimensional protein structures from amino-acid sequences, a high-dimensional continuous prediction problem central to molecular biology.",
            "problem_complexity": "High-dimensional continuous output space, complex physics and folding landscape; quantitative complexity and computational cost are not described in this paper.",
            "data_availability": "Trained on empirically solved protein structures (e.g., PDB) historically, but the CPC-MS paper does not quantify dataset sizes or coverage.",
            "computational_requirements": "Not specified in this paper; known to require substantial compute for training in original work, but CPC-MS does not provide numbers.",
            "problem_structure": "Supervised prediction problem with well-defined evaluation metrics in the original literature; described here at a conceptual level only.",
            "success_metric": "Not specified in this paper (original metrics include structure prediction accuracy measures; CPC-MS cites AlphaFold qualitatively as a success example).",
            "success_rate": null,
            "failure_modes": "Not discussed in this paper.",
            "success_factors": "Availability of high-quality structural data and powerful generative/predictive ML methods (implied by citation), but not detailed here.",
            "comparative_results": "No comparative details provided in this paper beyond noting AlphaFold's significance.",
            "human_baseline": "Not provided in this paper (paper only qualitatively contrasts AI success with prior human limitations).",
            "uuid": "e2449.4",
            "source_info": {
                "paper_title": "Collective predictive coding as model of science: formalizing scientific activities towards generative science",
                "publication_date_yy_mm": "2025-06"
            }
        },
        {
            "name_short": "AI Scientist (Lu et al.)",
            "name_full": "The AI Scientist: Towards fully automated open-ended scientific discovery",
            "brief_description": "A recently proposed system described in the CPC-MS paper as capable of automating a wide range of research tasks end-to-end for machine learning research, including idea generation, experiments, paper writing, and peer review automation.",
            "citation_title": "The ai scientist: Towards fully automated open-ended scientific discovery",
            "mention_or_use": "mention",
            "system_name": "AI Scientist (Lu et al.)",
            "system_description": "Described by the CPC-MS paper as an AI system that attempts highly automated, end-to-end scientific research workflows for machine learning: from idea/hypothesis generation to experiment design/execution, result analysis, paper drafting, and (partially) peer-review; the CPC-MS paper highlights it as an advanced example but notes it remains specialized and does not yet automate the entire socially-distributed scientific process.",
            "system_type": "AI Scientist / Automated Research System / End-to-end Research Automation",
            "problem_domain": "Machine learning research (meta-research / automated ML algorithm/architecture exploration and evaluation)",
            "problem_description": "Automating the process of producing ML research artifacts: generating research questions or ideas, designing and running ML experiments, analyzing outcomes, drafting manuscripts, and automating parts of peer review and dissemination (as characterized by the CPC-MS paper).",
            "problem_complexity": "Open-ended research across algorithmic and experimental design spaces; multi-objective (novelty, empirical performance, reproducibility); search spaces include architectures, hyperparameters, datasets and evaluation protocols. The CPC-MS paper does not provide quantitative measures of dimensionality or search size.",
            "data_availability": "Varies by subtask; the system uses ML datasets and simulation/benchmark tasks typical in ML research; the CPC-MS paper does not enumerate dataset sizes or access constraints.",
            "computational_requirements": "Implied to be large (training and evaluating many ML models, running experiments, producing manuscripts), but the CPC-MS paper provides no quantitative compute or cost figures.",
            "problem_structure": "Highly open-ended and partially ill-posed: mixes discrete (architectures, experimental design choices) and continuous (hyperparameters) search; evaluation combines objective metrics (performance) and subjective/collective metrics (novelty, publishability); degree of domain knowledge required is high. The CPC-MS paper emphasizes that such systems still commonly automate a 'single scientist' workflow rather than community-level social processes.",
            "success_metric": "Not specified concretely in the CPC-MS paper; implied metrics include number/quality of publishable findings, empirical performance of proposed methods, and ability to automate writing/review processes.",
            "success_rate": null,
            "failure_modes": "CPC-MS highlights limitations: specialization to particular fields, lack of full social-collective automation (peer review and community consensus), communication/common-ground barriers between AI and human scientists, and potential low acceptance/poor integration when AI proposals diverge strongly from human priors.",
            "success_factors": "Integration across hypothesis generation, experiment execution, and artifact generation; use of generative models and automation of writing/review pipelines; suitability to domains where experiments can be automated (implied).",
            "comparative_results": "The CPC-MS paper positions Lu et al.'s work as a significant advance but notes it still falls short of automating the entire social scientific process; no quantitative cross-system comparisons are provided in this paper.",
            "human_baseline": "Not provided in this paper; CPC-MS discusses conceptual comparisons (e.g., human social processes, peer review) but gives no empirical human-vs-AI performance numbers.",
            "uuid": "e2449.5",
            "source_info": {
                "paper_title": "Collective predictive coding as model of science: formalizing scientific activities towards generative science",
                "publication_date_yy_mm": "2025-06"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Functional genomic hypothesis generation and experimentation by a robot scientist",
            "rating": 2,
            "sanitized_title": "functional_genomic_hypothesis_generation_and_experimentation_by_a_robot_scientist"
        },
        {
            "paper_title": "The ai scientist: Towards fully automated open-ended scientific discovery",
            "rating": 2,
            "sanitized_title": "the_ai_scientist_towards_fully_automated_openended_scientific_discovery"
        },
        {
            "paper_title": "Cheaper faster drug development validated by the repositioning of drugs against neglected tropical diseases",
            "rating": 2,
            "sanitized_title": "cheaper_faster_drug_development_validated_by_the_repositioning_of_drugs_against_neglected_tropical_diseases"
        },
        {
            "paper_title": "Highly accurate protein structure prediction with alphafold",
            "rating": 2,
            "sanitized_title": "highly_accurate_protein_structure_prediction_with_alphafold"
        },
        {
            "paper_title": "Dendral: a case study of the first expert system for scientific hypothesis formation",
            "rating": 2,
            "sanitized_title": "dendral_a_case_study_of_the_first_expert_system_for_scientific_hypothesis_formation"
        },
        {
            "paper_title": "The automation of science",
            "rating": 2,
            "sanitized_title": "the_automation_of_science"
        },
        {
            "paper_title": "Scientific discovery: Computational explorations of the creative processes",
            "rating": 1,
            "sanitized_title": "scientific_discovery_computational_explorations_of_the_creative_processes"
        }
    ],
    "cost": 0.01902725,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Collective Predictive Coding as Model of Science: Formalizing Scientific Activities Towards Generative Science
27 Aug 2024</p>
<p>Tadahiro Taniguchi taniguchi@i.kyoto-u.ac.jp 
Graduate School of Informatics
Kyoto University</p>
<p>Research Organization of Science and Technology
Ritsumeikan University</p>
<p>Shiro Takagi takagi4646@gmail.com 
Jun Otsuka jotsuka@bun.kyoto-u.ac.jp 
Department of Philosophy
Kyoto University</p>
<p>Data Science and AI Innovation Research Promotion Center
Shiga University</p>
<p>Center for Advanced Intelligence Project
RIKEN
7 AI Alignment Network</p>
<p>Yusuke Hayashi hayashi@aialign.net 
Hiro Taiyo Hamada 
DeSci Tokyo</p>
<p>ARAYA Inc
hamada</p>
<p>Collective Predictive Coding as Model of Science: Formalizing Scientific Activities Towards Generative Science
27 Aug 2024AC51B80582A7AAC23D5540838A67A7C1arXiv:2409.00102v1[physics.soc-ph]
This paper proposes a new conceptual framework called Collective Predictive Coding as a Model of Science (CPC-MS) to formalize and understand scientific activities.Building on the idea of collective predictive coding originally developed to explain symbol emergence, CPC-MS models science as a decentralized Bayesian inference process carried out by a community of agents.The framework describes how individual scientists' partial observations and internal representations are integrated through communication and peer review to produce shared external scientific knowledge.Key aspects of scientific practice like experimentation, hypothesis formation, theory development, and paradigm shifts are mapped onto components of the probabilistic graphical model.This paper discusses how CPC-MS provides insights into issues like social objectivity in science, scientific progress, and the potential impacts of AI on research.The generative view of science offers a unified way to analyze scientific activities and could inform efforts to automate aspects of the scientific process.Overall, CPC-MS aims to provide an intuitive yet formal model of science as a collective cognitive activity.</p>
<p>Introduction</p>
<p>Science is a massive cooperative venture of mankind.Even though each person has limited observations of natural phenomena, their own experience, and perceptions and actions, we can integrate our knowledge through scientific communication and accumulate scientific knowledge throughout the global human community.Science is a collective behavior of humans which explore the world in an active manner.Meanwhile, science has its specific way of communication involving proposing hypotheses, formulating theories, conducting experiments, writing papers, submitting them to journals and conferences, and performing peer reviews.While they have diversity depending on the specific scientific field, most people believe that such scientific activities integrate our knowledge and lead us to better understand the world.However, in what sense do the overall scientific activities bring us a model and better understand the world?How can we improve the rules, regulations, games, and habits in our scientific activities?To understand and improve scientific activity itself, a wide range of studies have been undertaken, including philosophy of science, and science, technology and society (STS), and science of science [Pop59, Kuh62, Lak78, LW79, FBB + 18].Despite these efforts, we have not obtained an intuitive framework that models the total scientific activities.Considering the recent changes in the scientific field, e.g., the introduction of artificial intelligence (AI) technologies [WFD + 23] and huge problems of research ethics in science including the replicability crisis [Bak16] it is highly important for us to have a systemic view of science as a whole.This paper proposes a new conceptual and computational framework of science based on the idea of collective predictive coding (CPC) [Tan24].Scientists conduct experiments and observations, engaging with the target objects, i.e., environment, through their research methodologies.These individual interactions generate data and insights, which are then synthesized and encoded into a shared system of scientific knowledge, analogous to how language emerges in linguistic systems.The diagram depicts a cyclical nature of this process, where internal scientific activities contribute to and are informed by the collective understanding, forming a dynamic feedback loop between personal research and the broader scientific corpus.</p>
<p>The CPC hypothesis was originally proposed to explain the phenomenon of symbol emergence [Tan24, TNN + 16, TUH + 18].Symbol emergence refers to the process by which a shared system of symbols, such as language, arises and evolves within a population of agents through their interactions with each other and the environment.The CPC hypothesis extends the idea of predictive coding (PC) and free-energy principle (FEP) [Fri10, Hoh13, Fri19, FMN + 21, TMS + 23] to a group of people and argues that we, humans, improve prediction capability by updating the symbol system, i.e., external representation systems, we have as a group.In cognitive science and related fields, PC, which can be generalized from a probabilistic viewpoint to the FEP, has become a dominant idea, which regards human cognition as a process of reducing prediction errors [Fri10,Cla13].The PC and FEP provide the generative view of cognition.FEP and PC address not only perceptual aspects of cognition but also operational aspects meaning decision making and active exploration, i.e., actions.However, basically, the idea of PC and FEP are about individual cognitive processes.In contrast, the CPC hypothesis was proposed for symbol emergence, considering language as a representative target symbol system.CPC is a generative model of symbol emergence in human society and provides a generative perspective on the emergence of language.Notably, scientific knowledge we share in our society is also a representative symbol system.Therefore, the authors reached an insight that CPC can be extended to the explanatory theory for formalizing science activities (Figure 1).</p>
<p>Science, including natural, social, and a wide range of sciences, attempts to model and understand the world.Although the quality of theories in science is evaluated in many ways and the values of theories are not monolithic, prediction capability is a central criterion to evaluate scientific theories [Pop59,Lak78].In particular, theories of physics provide generative models of phenomena.For example, Newtonian equations tell us the generative process of the trajectory of a target object [LL82].In contrast, related to PC and FEP, world models are considered to be an internal model which a robot or an AI has and updates to predict their sensory information depending on their actions [HS18, FMN + 21, TMS + 23].In contrast, scientific knowledge we have in our society is an explicit system of knowledge that enables us to predict phenomena happening in the world better.In other words, we can regard scientific knowledge as an external representations of explicit world model which is shared among the people who study science and conduct scientific research.This view allows us to extend the CPC hypothesis to scientific activities.</p>
<p>Building upon these perspectives, this paper aims to introduce a novel conceptual framework called Collective Predictive Coding as a Model of Science (CPC-MS) to formalize and elucidate scientific activities.CPC-MS is a framework that models science as a collective predictive coding activity, as the name suggests.As we find in the later part of this paper, we can find a reasonable correspondence between CPC and scientific activities including experimentation, measurement, proposing hypotheses, testing the hypotheses, writing papers, reviewing papers, and so forth.</p>
<p>The aforementioned view of science presents a vision to model the entirety of scientific activities as a probabilistic generative model [Bis06].We term this perspective generative science.While developing the concept of generative science in relation to CPC, we establish clear correspondences between the probabilistic generative model underlying CPC and concrete, practical scientific activities.Crucially, CPC-MS posits that shared external representations-scientific knowledge in this context-are updated through a form of peer-review process that functions as a decentralized Bayesian inference [Tan24].</p>
<p>The view of generative science proposed in this paper also aims to provide a clear view of the total scientific activities from the viewpoint of generative models and allow people who work on science automation to have a more intuitive roadmap for automated science (see Section 4).Importantly, the theory is totally based on terms of probabilistic modeling and machine learning.This will also allow us to have a clear view of the integration of generative AIs into scientific activities.While there has been intense discussion and significant progress in automating individual research tasks, such as information retrieval [HDW + 23], paper writing [LZW + 24], hypothesis proposition [WFD + 23], paper review [LZC + 24], and experiment execution [KRO + 09], much work remains to be done in automating the entire social scientific process.CPC-MS may provide a new perspective on such automation.</p>
<p>The remainder of this paper is organized as follows.Section 2 introduces CPC as a model for scientific activities, explaining the CPC hypothesis and its application to modeling these activities.This section also includes a detailed explanation of the mathematical framework of CPC-MS, including its formulation based on the theory of active inference.Section 3 applies the CPC model to understanding social objectivity in science, scientific progress, and the shift from confirmatory to generative science.Section 4 explores the implications of CPC for the future of science, including speculations on AI's impact on scientific practices and providing guidelines for implementing automated total scientific activity.Section 5 discusses future research directions.Section 6 concludes this paper.</p>
<p>Scientific Activities as CPC</p>
<p>CPC Hypothesis</p>
<p>The CPC hypothesis proposes that the dynamics of human language can be modeled as a a process of CPC across society [Tan24].This hypothesis is based on the mathematical fact that a certain type of language game played among agents, i.e., Metropolis-Hastings naming game Figure 2, can be acted as a decentralized Bayesian inference of a shared latent variable, sampled instantiation of which can be regarded as an utterance of a name of an object [TYM + 23].The CPC hypothesis extended the idea of PC and FEP to the phenomena of language emergence in human society.If the hypothesis is held, human language is considered to collectively encode information about the world as observed by many agents through their sensory-motor systems.</p>
<p>From a mathematical perspective, CPC can be modeled using probabilistic graphical models (PGMs) where latent variables representing shared external representations are inferred in a decentralized way through agent interactions and communication.Figure 3 represents a general form of CPC, ignoring the temporal and dynamic aspects of agent-environment sensory-motor interactions, and focusing on representation learning perspectives.The computational model for CPC was obtained by extending the PGM for individual representation learning to a social one.We first defined the total PGM by integrating multiple elemental modules representing agents, i.e., people.Each elemental PGM was assumed to involve latent variables z k d representing the internal representation of an agent, and observations o k d corresponding to the k-th agent.A shared latent variable w d is placed as a parent node of {z k d } k .The latent variable w d represents a sign, e.g., a sentence in language, which can be generally The CPC hypothesis assumes that a language game played between agents acts as a decentralized Bayesian inference and the posterior distribution p(w d |{o k d } k ) can be inferred approximately.Inukai et al. showed that recursive MHNG is an example of such a language game.</p>
<p>Mathematically, the inference of q z k | o k corresponds to representation learning by the k-th agent, and q w | {z k } k is assumed to be estimated through a language game within a group.As a whole, symbol emergence by a group is performed to estimate q w, {z k } k | {o k } k in a decentralized manner.We assume that we cannot estimate the true posterior p w, {z k } k | {o k } k , but can only estimate its approximate distribution q w, {z k } k | {o k } k .In MHNG, q(w|â€¢) is considered to be approximated by the sample distribution q(w|â€¢) â‰ˆ 1 I i Î´(w, w [i] ) where {w [i] } i âˆ¼ p(w|â€¢) and I is the number of samples, i.e., a Monte Carlo approximation.</p>
<p>However, if humans could participate in a language game that enables decentralized inference of w d , akin to the MH naming game, a symbolic system like language could develop to unify the sensorimotor information collected by individual agents.Consequently, a symbolic system emerges when agents work together in PC.A more detailed formulation from the perspective of the FEP can be found in Section 2.3.</p>
<p>In summary, the CPC hypothesis proposes that language emerges and evolves as a shared representation system that encodes information about the world in a compressed way, allowing agents to align their models of the world.</p>
<p>CPC as a Model of Science (CPC-MS)</p>
<p>The main argument of this paper is to extend the idea of CPC to a model of science.Assuming that the total goal of science is to build theories that model the world and predict future observations, the framework of CPC seems to be suitable for modeling scientific activities.Especially in science, we need to describe and share theories explicitly, even though insights and thoughts are profoundly internal phenomena in our brains.The explicit theories, which are often described in scientific papers, should be shared among society.We found a clear correspondence between language emergence and scientific activities.We call this framework CPC as a Model of Science (CPC-MS), as introduces in Section 1.In CPC-MS, it is assumed that each agent has partial observations and limited capability for experimentation and measurement.Based on such partial observations of the world, each agent, or scientist, tries to refine their hypothesis to predict their data more accurately.This corresponds to the representation learning of z k d .Based on such a hypothesis, an agent proposes a theory or writes a paper.The paper or theory can be accepted or rejected by reviewers.This is quite similar to the communication in MHNG.</p>
<p>The PGM of CPC (Figure 3) provides a framework for understanding and modeling the process of scientific inquiry.The key components of the PGM, including external representations (w), internal representations (z), and observations (o), correspond to different aspects of scientific activities.The parameter Î¸ is a local parameter for the k-th agent, which represents agent-specific properties such as the agent's bias and internal world model.</p>
<p>We assume that scientific activity aims to reveal the structure of the world and encode it into a system of external representations.We consider a scientific paper to represent explicit knowledge that can be interpreted by everyone, unlike tacit knowledge that only the owner can access.Imagine that scientific knowledge consists of a large number of logical descriptions, e.g., mathematical equations of physical laws, structural formulas of compounds in chemistry, and descriptive theories of social systems.In this sense, w represents a paper or a theoretical argument.We call w global scientific representations in this paper.</p>
<p>In contrast, z corresponds to a personal idea about the world.The internal representation z can be explicit or tacit knowledge, including thoughts, insights, and hypotheses.We call z internal scientific representations in this paper.</p>
<p>Table 1 represents the correspondences between mathematical notations in CPC, phenomena in scientific activities, and language emergence.Assuming the goal of science is to obtain better external representations, i.e., theories, to better predict the world, within the framework of CPC-MS, CPC of {o k d } k and Bayesian inference of w d are the goals of science.</p>
<p>The following is a scenario of two-agent scientific communication, which can be extended to a multiple-agent setting, playing scientific communication possibly corresponding to a decentralized Bayesian inference in the same way as MHNG.The schematic correspondence between MHNG and the scientific communication is depicted in Figure 2 ), scientists update their internal scientific representations, i.e., internal representations, (z * d ) through the inference process P (z|o).This process mirrors how scientists evaluate and refine hypotheses in light of experimental results.Testing hypotheses is represented by the evaluation of the likelihood term P (o|z) in the CPC model, from generative perspectives.Scientists seek hypotheses that maximize the likelihood of the observed data.</p>
<ol>
<li>
<p>Externalization of Scientific Representations: Scientists externalize their ideas mainly by writing papers to communicate their internal representations (z) to the broader scientific community as explicit knowledge.This process can be modeled as a sampling process from the distribution P (w|z), mapping internal representations to external representations (w), which correspond to theories and models described in scientific papers.</p>
</li>
<li>
<p>Judgment of Scientific Representations: When a scientist submits a paper (w) for review, other scientists evaluate it based on their own internal representations (z).Reviewers assess the compatibility of the proposed theory with their understanding and their beliefs.If successful, the distribution of accepted papers can be regarded as samples of q(w | {z k } k ), similar to the MHNG.In other words, when reviewer k â€² makes acceptance decisions based on p(z k â€² |w), the sample distribution of w is influenced by reviewer k â€² 's knowledge, resulting in a sample distribution that approximates p(w|z k , z k â€² ) rather than p(w|z k ).This means that through the judgment process, reviewer k â€² 's knowledge is integrated into the distribution1 .In other words, this scientific communication consisting of sampling, i.e., externalization, and judgment, i.e., peer review process, is considered as the approximate (decentralized) Bayesian inference of P (w|z) in the CPC framework.</p>
</li>
</ol>
<p>the k â€² -th agents, have different observations o k Ì¸ = o k â€² , and the reviewer k â€² judges the paper w written by the k-th agent, i.e., a sample from p(w|o k ), by using q(z k â€² |o k â€² ).However, in this case, if there is a significant difference between the distributions p(o k ) and p(o k â€² ), it may result in an unfairly low acceptance ratio.The other interpretation is that two researchers share the same data o k = o k â€² , i.e., the data is shared publically.In this case, the reviewer uses their knowledge, i.e., the global parameter of p(z k â€² |w) and p(z k â€² |o k â€² = o k ), without being affected by the difference in data distributions.</p>
<p>Iteration:</p>
<p>The process returns to step 1, with scientists designing new experiments based on the updated consensus, continuing the cycle of scientific inquiry.</p>
<p>Through ongoing communication of theories and evidence via papers and discussions, the scientific community, here the group of two agents, updates its shared understanding of the world.This process corresponds to the decentralized Bayesian inference of shared external representations (P (w|o)).In generative science, the ideal scientific consensus corresponds to the inference of the posterior distribution, i.e., p w | {o k } k â‰ˆ q w | {o k } k .Notably, the CPC-MS framework models social scientific activity from the viewpoint of Bayesian inference that aggregates the evidence obtained by agents who have partial capabilities.The CPC-MS framework does not necessarily provide a method enabling the agents to reach the objective "truth," but rather provides a view of scientific communication to better understand, justify, and refine the mechanism of scientific activities played by the multi-agent system, i.e., scientists.</p>
<p>By mapping the components of the CPC framework to specific scientific activities, we can see how the PGM provides a unified view of the scientific process.The interplay between observations, internal representations, and external representations in the CPC model mirrors the way scientists gather evidence, propose hypotheses, test theories, and communicate their findings to the broader community.The CPC framework offers a principled way to understand the emergence of scientific knowledge through the collective efforts of individual scientists.</p>
<p>Active Inference on CPC-MS</p>
<p>In transitioning from a MHNG-based perspective of the CPC model to one grounded in active inference, we open a new dimension of understanding scientific processes.Active inference [TP22], which has been pivotal in explaining cognitive processes through the minimization of prediction errors, offers a robust framework for reinterpreting the CPC model.This approach not only aligns with the principles of active inference but also provides a comprehensive view of scientific inquiry as a collective cognitive process.By adopting this perspective, we can better elucidate how individual scientists' observations and hypotheses are integrated into a cohesive body of scientific knowledge, facilitating a deeper understanding of the dynamics of scientific progress and the role of collective intelligence in scientific discovery.This shift in perspective underscores the potential of CPC-MS to model science as an active, generative process, driven by the continuous interplay between prediction and observation within the scientific community [BfCF + 23, Tan24].</p>
<p>Because the CPC-MS regard the science community as a collective intelligence performing a decentralized Bayesian inference from the viewpoint of generative models, the system as a whole is also viewed as an integrated cognitive system that performs free-energy miniization and active inference.Within the system, each indivisiual is drived to explore based on their individual and collective motivations.Active inference is a theory that explains how living things understand their surroundings, act in the world, and learn.It's based on the idea that organisms try to minimize the difference between what they expect and what they actually experience, both now and in the future.Several studies have demonstrated that active inference can explain how organisms balance exploring new options with exploiting known rewards.This approach offers a clear mathematical solution to a long-standing problem in decision-making research.</p>
<p>Mathematically, the CPC-MS in the simplest case can be described as follows:
Generative model: p (w, z, o | a, C) = p(w)p (o | z, a, C) p (z | w, a)(1)
Inference model:
q (w, z, o | a, C) = q (w | z) q (o | C) q (z | w, o, a)(2)
where w is external (collective) representations, z = {z k } k is the set of representations by the k-th agent, o = {o k } k is the set of observations by the k-th agent, a = {a k } k is the set of sequence of actions taken by the k-th agent, and C = {C k } k is the set of sequence of rewards taken by the k-th agent.</p>
<p>The inference of q (z | w, o, a) corresponds to representation learning by the k-th agent, and q (w | z) is assumed to be estimated through a language game within a group.As a whole, symbol emergence by a group is performed to estimate q (w, z | o, a, C) in a decentralized manner.We assume that we cannot estimate the true posterior p (w, z, o | a, C), but can only estimate its approximate distribution q (w, z | o, a, C).</p>
<p>Based on these premises, the negative variational free energy âˆ’F of the CPC-MS, which exactly corresponds to the model's variational lower bound (ELBO), is defined as follows:
F = D KL [q (w, z, o | a, C) âˆ¥p (w, z, o | a, C)] (3) = q (w, z, o | a, C) ln q (w, z, o | a, C) p (w, z, o | a, C) dwdzdo (4) = âˆ’E q ln p(w) q (w | z) âˆ’ E q ln p (o | z, a, C) q (o | C) âˆ’ E q ln p (z | w, a) q (z | w, o, a) (5) â‰ƒ E q [ln q (w | z)] Collective term âˆ’ E q [ln p (o | z, a, C)] âˆ’ E q ln p (z | w, a) q (z | w, o, a) Individual term (6) = E q ln q w | {z k } k Collective regularization âˆ’ k E q ln p o k | z k , a k , C k Individual prediction error âˆ’ k E q ln p z k | w, a k q (z k | w, o k , a k ) Individual regularization (7)
where the first term E q [ln q (w | z)] represents the collective regularization, which corresponds to the maximization of the log-likelihood concerning the collective latent variable w, and the second term âˆ’E q [ln p (o | z, a, C)] represents the sum of the prediction error for each k-th agent concerning their observation o k , and the third term âˆ’E q ln p(z|w,a) q(z|w,o,a) represents the sum of the regularization for each k-th agent, indicating how useful the generation of the latent variable z k is for estimating the environmental system for each k-th agent.It's important to note that E q [ln p (w)] and E q [ln q (o | C)] are constant terms and therefore do not affect the parameter estimation in the inference model.Additionally, while individual term can be described as the sum of the values for each k-th agent, collective term cannot be expressed as a sum over k.</p>
<p>In Equation 7, the individual prediction error term represents an individual's predictive capability based on their internal scientific representations z k k .In generative science, we take the stance of evaluating theories and hypotheses based on how well they can predict observed values, and this term corresponds to that.The individual regularization term signifies how consistent the inferred z k based on the external and explicit scientific knowledge w is with the inferred z k based on one's own observation o k .This term represents the interaction between top-down and bottom-up information, which is essential for PC and FEP.While the above two terms appear in general FEP, the first term, the collective regularization term, is essential for CPC.The existence of this term gives rise to language and scientific knowledge as external representation systems.This term suggests that it's better for the w represented or inferred by all agents to be as consistent as possible.Notably, both z k and w do not come from the environment but are created by people.The collective regularization term works to adjust latent variables.This means that there is arbitrariness here.In other words, the symbol w representing z k inferred via q(z k |w, o k , a k ) has various degrees of freedom as long as it satisfies social consensus represented by the collective regularization term.This corresponds to the "arbitrariness," which is considered to be a nature of symbols in semiotics [Cha02].We, humans, are adapting to the environment as a group and modeling the world in a generative manner, not only through synaptic plasticity in our nervous system but also by using semantically and structurally flexible symbol systems in society with this plasticity.CPC-MS expresses this quality of scientific theories that enables the group to be an adaptive predictor, i.e., a group of agents attempting to model the world.</p>
<p>The expected free energy G (Ã£) of the CPC-MS for future observational data is defined as follows:
G(Ã£) = E q( w,z,Ãµ|Ã£, C) [ F ] (8) = q( w, z, Ãµ | Ã£, C) F d w dz dÃµ (9) = E q ln q w | zk k Collective epistemic value âˆ’ k E q ln p Ãµk | zk , Ã£k , Ck Individual pragmatic value âˆ’ k E q ln p zk | w, Ã£k q (z k | w, Ãµk , Ã£k ) Individual epistemic value (10)
Scientific progress is exploratory in nature.The CPC theory provides a new perspective on collective exploration in science.Individual scientists explore research fields and reach scientific discoveries through hypothesis generation, experimentation, simulation, etc. Drivers of human exploration including scientific activities can be based on extrinsic and intrinsic motivations [Ber50, KHK + 09, Loe94].Intrinsic motivation of theme selection and scientific discovery is especially described as individual drivers such as curiosity.This individual exploration of science can be supported by theories of information gain.The information gain theory states that the relationship between curiosity and confidence is a inverted U-shape function [SJNK24].Information gain as a proxy of curiosity measures the reduction of uncertainties after samplings.This information-theoretic principle inspired multiple related studies on agents' exploration [OGL16, SPH + 19].</p>
<p>Analogous to the information gain theory, individual scientists attempts to seek novel scientific discovery by rewarding gaining new information based on current situation.The information gain theory of curiosity states that exploratory behaviors are driven by information gain between what an agent knows (internal representation z k ) and what an agent obtains (observation w, o k , a k ).This process can be formulated as refinement of a hypothesis q(z k |w, o k , a k ).However, this view lacks organizational aspects of science since theme selection of scientists are constrained by multiple collective factors such as scientific trends, grant opportunities and collaborators.In other words, individual exploration of science can be biased by global constrains.These global constrains may be interpreted as external (collective) representation w.</p>
<p>The CPC theory can capture collective aspects of scientific discovery and exploration as hypothesis updating and hypothesis testing.We here describe different exploratory patterns and scientific activities.</p>
<p>â€¢ Hypothesis Test: In scientific activities, doing an experiment is crucial for testing hypothesis.</p>
<p>Hypothesis testing can be driven by sampling based on researcher's internal model and theories as global representation.</p>
<p>â€¢ Hypothesis Update: Updating a hypothesis is another important scientific activity.Updating an internal model of a researcher as hypothesis update is driven by the information gain between models given by observation and global representation.</p>
<p>â€¢ Theme Selection: Theme selection is also exploration in scientific activities.This exploration can be driven by comparisons between information gains from multiple targets IG d1,d2,...,dm .Each scientist has preference on which target is more interesting or curious to him or her.Such preference to hypothesis update promotes theme selection of scientific topics in a decentralized manner.</p>
<p>In summary, the CPC theory can describe multiple collective aspects of scientific discovery such as hypothesis test, hypothesis update, and theme selection.</p>
<p>Example</p>
<p>For illustrative purpose, let us explain the case of "verifying whether drug X has a pharmacological effect on disease Y " within the CPC-MS framework.{o k d } d and evaluates whether drug X shows a statistically significant effect on disease Y .Based on this, they update their hypothesis (internal representation) z k d about the effect of drug X.This process is represented as approximate inference of the posterior distribution p(z|w, a).For instance, they refine their hypothesis by evaluating the presence and strength of drug X's effect through statistical analysis.From a generative perspective, the fitness of hypothesis to the data corresponds to evaluating the likelihood term p(o|z, a, C).The reward C k in this context could represent the potential benefits of the drug, such as improved patient outcomes or reduced healthcare costs, which motivate the research.CPC-MS assumes that researchers pursue hypotheses that increase the likelihood of the observational data while being influenced by the top-down effect p(z|w, a) (prior distribution) given by w, which represents prior knowledge in the field.This aligns with Bayesian inference as p(z, o | w, a, C) âˆ p(z|w, a)p(o|z, a, C), appropriately updating one's hypothesis under the influence of prior knowledge w.If the hypothesis (z) is supported, they may plan additional experiments to obtain more data (o) for further verification.If not supported, they consider the reasons and either review the experimental methods to verify the hypothesis or modify the hypothesis (z).</p>
<p>Experimentation and Measurement</p>
<ol>
<li>
<p>Externalization of Scientific Representations: Researchers externalize their internal scientific representations z as papers and communicate them to the scientific community.This can be modeled as a sampling process from the distribution P (w|z).Specifically, they write a paper w on the theory and data analysis results regarding the effect of drug X to convert internal representations into external representations.</p>
</li>
<li>
<p>Judgment of Scientific Representations: When a paper w is submitted, other researchers (i.e., reviewers) evaluate it.Reviewers judge the validity of the proposed theory based on their internal representations z, which are informed by existing knowledge in the world and their own expertise.They evaluate aspects such as the appropriateness of the experimental design, the accuracy of statistical analysis, and the validity of conclusions.</p>
</li>
</ol>
<p>This corresponds to the Listener's acceptance judgment in MHNG, and when done properly, the distribution of accepted papers can be viewed as samples from q(w | {o k d } k ).The scientific activities through this process, i.e., CPC-MS, can be considered as approximate distributed Bayesian inference of p(w | {o k d } k )).</p>
<p>Iteration:</p>
<p>The process returns to step 1.Based on the updated scientific consensus, researchers design new experiments.Now, other research teams k â€² conduct experiments on the same target d.For example, they plan experiments to verify the effect of drug X in different patient groups or to elucidate the detailed mechanism of action, continuing the cycle of scientific inquiry.</p>
<p>In this way, CPC-MS represents scientific inquiry not so much as "the pursuit of true descriptive knowledge w * " but rather as "an overall mechanism for integrating knowledge from limited observations."</p>
<p>Explaining the Scientific Activities with the CPC-MS</p>
<p>This section examines the CPC-MS framework's implications for understanding the social dynamics and progress of scientific inquiry.By emphasizing the collective nature of knowledge formation, it challenges the traditional view of science as an individual, confirmatory process.Instead, the framework highlights how diversity and social interactions among scientists contribute to objective knowledge and drive scientific advancement.Additionally, the Bayesian perspective reframes scientific progress not as the accumulation of truths but as the continuous refinement and generation of new ideas, emphasizing the generative aspects of scientific activity.</p>
<p>Social Objectivity</p>
<p>One salient feature of the CPC-MS is that scientific knowledge emerges through social interactions among individual scientists who have only partial and possibly distorted understanding of the world.Importantly, the establishment of a global scientific understanding does not entail the consensus among individual scientists: they may well disagree each other (q(z k |o) Ì¸ = q(z l |o) for k Ì¸ = l) or have incorrect posterior (q(z k |o) Ì¸ = p(z k |o)) even at the limit where the community as a whole approximately attains the true posterior q w | {o k } k â‰ˆ p w | {o k } k .The holders of scientific knowledge, therefore, are the scientific community as a whole rather than individual scientists.This aligns with the social approach to scientific knowledge [Lon90,Kit93], which frames the objectivity of scientific inquiry as arising from the interplay of social interactions and empirical investigation.In this picture, scientists are depicted not as detached truth seekers who strictly adhere to universal methodologies, but as situated individuals influenced by their backgrounds, beliefs, and values.The individual biases, however, get corrected in critical dialogues including peer reviews and replications of experimental results.</p>
<p>The CPC-MS provides a Bayesian model for such social processes through which objective knowledge emerges from diversity.As described in Section 2, scientists in the CPC-MS model may have their own parameter values Î¸ and thus form different inner representation z based on the same observation o.Thus, their research output w well reflect individual biases.This result, however, will not be integrated into the scientific body unless it is accepted by other scientists (i.e., reviewers), who makes the decision on the basis of their own probability criterion q(w|z).The key observation of the CPC-MS model is that such mutual criticisms can be seen as an essential part of the decentralized Bayesian inference, e.g., MHNG, which realizes the inference to the posterior distribution at the scientific community as a whole.</p>
<p>Moreover, our model predicts the ways in which diversity and heterogeneity even promote objective scientific investigations, by allowing for the inclusion of diverse perspectives and the exploration of varied research paths.First of all, Bayesian inference becomes skewed or biased if data concentrate on a limited range, e.g., if the scientific community conducts experiments and observations only within a specific range of interests and subjects.Second, the asymptotic convergence to the true posterior via the repeated decentralized sampling is conditioned by the sampling process being ergodic, which roughly means that every part of the hypothesis space is eventually explored.This condition is violated if, among others, there is any "blind spot" theory w that has no positive probability of being proposed by any scientist (so that the Markov chain becomes reducible), or if scientific activities are trapped in cycles, with no chance of escaping and exploring new theoretical possibilities (so that the chain is periodic).Moreover, an effective convergence of Metropolis-Hastings algorithm requires that samples are independent of each other, which, in the present context, is translated as that scientists carry out their research according to their own interests and concerns.In contrast, if particular topics or groups become too influential within a research community, scientific explorations can become skewed toward a specific region of the hypothesis space, resulting in slower convergence.These pitfalls may be avoided by increasing the diversity of a scientific community, ensuring a wide range of perspectives and approaches are represented.</p>
<p>Scientific Progress</p>
<p>In this subsection, we explore the crucial role of the model parameter Î¸ = Î¸ k k within our framework.As depicted in Figure 3, Î¸ is a fundamental component of the Bayesian network that underpins the CPC-MS model.It serves as a key determinant of the generative and inference models employed by each agent engaged in active inference.Specifically, Î¸ encapsulates the internal models learned by each agent, influencing how they interpret observations and form hypotheses about their environment.</p>
<p>The parameter Î¸ acts as a bridge between individual internal representations and the shared global scientific representation w d .By modulating the agents' hypothesis formation and revision processes, Î¸ plays a pivotal role in the decentralized Bayesian inference that characterizes scientific communication and progress.Through iterative updates and exchanges among agents, Î¸ helps refine the collective understanding, driving the evolution of scientific knowledge.This dynamic interplay underscores the importance of Î¸ in shaping both local and global scientific representations, ultimately contributing to the advancement of science as a collaborative endeavor.</p>
<p>Science is expected to be progressive as well as objective, continually making solid improvements over past achievements.In the CPC-MS model, scientific progress is understood as the diachronic improvement of the posterior distribution through decentralized Bayesian updating.As scientific inquiry continues and more data o accumulate, the posterior distribution q(w|o) is expected to better approximate the data-generating process.This can be seen as an optimization process in which probability mass is progressively concentrated around the parameters with higher likelihood (Fig. 4).At the same time, this is accompanied by an optimization of the model parameter Î¸ = Î¸ k k , which (i) encapsulates the internal models learned by each agent, influencing how they interpret observations and form hypotheses about their environment (Fig. 3), and (ii) acts as a bridge between individual internal representations and the shared global scientific representation w d .In this sense, Î¸ can be conceived as the scientific understanding of each individual.This perspective allows us to view Bayesian optimization as a form of scientific progress-the process through which scientists' understanding of the world improves over time.</p>
<p>Under this identification, the conventional Bayesian update corresponds to a gradual improvement of the posterior distribution, where the weights of neural connectivity get refined continuously and smoothly on the basis of incoming data (Fig. 4 (a) left).This mode of updating process captures the gradual scientific progress in "normal science," where the scientific community as a whole concentrates on a given vicinity of the parameter space-circumscribed by one paradigm-and seeks to its refinement.</p>
<p>When the parameter space of the model is singular, however, the Bayesian updating process of the posterior distribution may involve jumps from one singular point to another corresponding to a local optimal solution (Fig. 4 (b) right).In singular learning theory, the concept of a singular model refers to a model whose parameter space contains singularities, as opposed to a regular model which lacks such singularities.Developed by Sumio Watanabe, this theory employs theorems from algebraic geometry to rigorously analyze the behavior of Bayesian updating in singular models [Wat09,Wat18].</p>
<p>The key finding is that, in stark contrast to regular models, the Bayesian updating process of the posterior distribution in singular models can exhibit discontinuous jumps from one singularity to another.These jumps correspond to phase transitions between local optima and are a frequently observed phenomenon in the Bayesian updating of posterior distributions in deep learning models.Mathematically, the singularities in the parameter space of these models determine the architecture of the model itself, dictating the presence or absence of edges connecting neurons.Consequently, learning in Bayesian deep models can be interpreted as a process whereby the model architecture is updated discontinuously via Bayesian updating of the posterior distribution.This jump of the posterior distribution from one singularity to another is called a phase transition, a phenomenon frequently observed in the Bayesian updating process of the posterior distribution in deep learning models.In deep learning models, singularities in the parameter space correspond to the architecture of the model and determine the presence or absence of edges connecting one neuron to another.In other words, learning a Bayesian deep learning model can be interpreted as a process in which the architecture of the model is updated discontinuously through Bayesian updating of the posterior distribution.In the context of the CPC framework, this can be viewed as a discontinuous change in the internal representation z of individual scientists, which in turn may lead to a paradigm shift in the distribution of the global latent variable w.</p>
<p>Thomas Kuhn [Kuh62] famously described scientific progress as consisting of two distinct periods: the period of "normal science," in which scientists engage in puzzle-solving activities and piecemeal refinements of a given paradigm, and the period of "extraordinary science," during which accumulated anomalies encourage the critical scrutiny of foundational assumptions and exploration of new theoretical possibilities, eventually leading to a scientific revolution.The CPC-MS framework offers a Bayesian model that accommodates these two periods as distinct modes of Bayesian optimization.Normal science, in this framework, is modeled by the gradual Bayesian update of the posterior distribution toward a given local optimum.During this period, scientists espouse more or less similar local representations, making proposals of external representations that deviate significantly from the shared paradigm (namely, the set of w's constituting a local optimum) rare, and, if made, likely to be rejected.On the other hand, scientific revolutions are represented by phase transitions that leap the posterior distribution from one singularity to another in a discontinuous fashion.Such transitions induce significant reconfigurations in the collective external representations (w) held by the scientific community, such that a set of propositions that enjoyed high probabilities before the transition cease to do so afterward.</p>
<p>Kuhn infamously claimed that the incommensurability between different paradigms makes the comparison and evaluation of competing scientific theories difficult, if not impossible, because the standards of evidence, methods, and the very concepts used in the theories can change so drastically between paradigms.However, within the CPC framework, there is a potential resolution to this problem that acknowledges the incommensurability while still allowing for a form of rational progress.This is because a phase transition between paradigms can still be understood as an improvement in the collective posterior distribution.Since a more refined posterior distribution enhances the explanatory power for observed data and sharpens the predictive accuracy for unobserved phenomena, the transition to a new paradigm can be considered a rational and objectively superior advancement in the scientific community's collective understanding, even if the paradigms themselves are internally incommensurable.In this way, the CPC framework reconciles Kuhn's notion of incommensurability with the idea of scientific progress by proposing a unified model of Bayesian optimization that accommodates both the</p>
<p>From Confirmatory to Generative Science</p>
<p>Finally, the CPC-MS framework prompts us to reconsider the very nature and purpose of the scientific enterprise.The traditional realist perspective in science views its primary goal as the pursuit of true knowledge, placing strong emphasis on the confirmatory role of scientific methods to distinguish valid hypotheses from invalid ones [Car50,Pop59].In the 20th century, statistical tests provided precisely such a universal tool for confirmation, establishing methodological standards across various scientific disciplines [May18,Ots22].The realist picture aligns with the aforementioned image of scientists as "lone truth seekers" who independently collect data, test hypotheses, and publish results, the accumulation of which forms the body of scientific knowledge.</p>
<p>On the other hand, the CPC framework highlights the generative aspect of science, viewing it as a coordinated system for producing new hypotheses, research plans, actions, and predictions.In the CPC-MS model, scientific knowledge is encoded as a posterior distribution q(w|o) that reflects the collective opinions within of the scientific community.The primary function of this distributional knowledge is to induce scientists to take the next step in their inquiry.There are at least two such generative aspects.First, it serves as a key reference point for individual researchers when planning their next studies or experiments.While some researchers may strive to find exceptions to hypotheses with high posterior probability, others may design experiments that prompt a reconsideration of less attended hypotheses.In this way, scientific knowledge serves to streamline research directions that produce further evidence.This leads to a continuous cycle of proposing hypotheses, conducting experiments, and refining theories, much like the iterative updates in a Bayesian model.</p>
<p>The second and more obvious generative role of scientific knowledge is prediction: theories are used to predict unobserved phenomena.In the Bayesian framework, a prediction of new data Ãµ on the basis of past observation o is given by the posterior predictive distribution p(Ãµ | z, a, C)q(z | w, o, a)q(w | z)
p(Ãµ | o, a, C) = p(Ãµ | z, a, C)q(z | w, o, a)q(w | z) dwdz.(11)
Given that an accurate posterior distribution p(Ãµ | o, a, C) leads to better predictions, both in terms of mean squared error and the Kullback-Leibler divergence between the predicted and true distributions, the scientific progress discussed above can also be seen as an improvement in predictive performance.The emphasis on prediction becomes even more apparent in light of the discussion on active inference (Section 2.3), where the scientific community as a whole is viewed as a collective agent aiming to minimize predictive error.The shift from confirmatory to generative approaches induced by the CPC framework is intrinsically linked to its social and progressive visions of science discussed above.From the generative perspective, scientific knowledge is seen as less an end than a means that promotes scientists to pursue new projects.Social exchanges and information sharing accelerate this research cycle, enabling the scientific community as a whole to effectively explore the vast hypothesis space in an efficient manner.The focus on prediction also substantiates the common intuition that science is progressive, an idea that has posed a vexing issue for the confirmatory view of science-precisely because the history of science seemingly presents us with successive scrap-and-build cycles through the refutation of past theories rather than the cumulative build-up of true propositions over time [Lau81].The Bayesian perspective, on the other hand, offers a clear sense of scientific progress in terms of predictive performance, for the diachronic refinement of the posterior distribution, as discussed in the previous section, directly leads to the improvement of the posterior predictive distribution shown in Equation ( 11).This suggests that the aspect of science that can be said to progress, particularly before and after a paradigm shift, is not its stock of confirmed knowledge, but rather its generative capability.</p>
<p>In conclusion, the CPC framework provides a comprehensive view of scientific activities that highlights their social, progressive, and generative nature.This stands in contrast to the traditional view, which portrays science as a predominantly individual, cumulative, and confirmatory procedure.The view of science as a generative process, driven by CPC, provides a new perspective on how scientific knowledge evolves and advances.It emphasizes the importance of diversity in scientific approaches, the value of paradigm-shifting discoveries, and the collective nature of scientific progress.By understanding science through this lens, we can better appreciate the complex dynamics that drive scientific advancement and potentially develop strategies to facilitate more efficient and effective knowledge generation in the scientific community.</p>
<p>AI and Research Automation</p>
<p>As we have repeatedly emphasized throughout previous sections, CPC-MS provides a comprehensive model of scientific activities carried out by scientists.Notably, as discussed earlier, it uses probabilistic generative models to mathematically describe these processes.This unique characteristics of comprehensive modeling and probabilistic approaches enables CPC-MS to offer profound insights into: 1) the potential impact of AI on the future landscape of scientific research, and 2) the development of intuitive guidelines for implementing automated scientific activities.</p>
<p>Speculating AI's Impact on Science for Shaping the Future Science</p>
<p>AI has made remarkable progress, its influence spreading throughout society.Science is no exception to this trend; AI has become an innovative tool in the field, and its applications in science are rapidly expanding [XLC + 21, WFD + 23, ZWH + 23].Furthermore, AI's development isn't limited to its use as a mere tool; scientists are now exploring whether AI can do research on its own as scientist [ZTA + 23, LLL + 24].They're trying to figure out if AI can come up with its own research questions, plan and run experiments, and make sense of the results.The possibility of AI acting as an autonomous scientist points towards a future novel scientific community where both human and AI scientists coexist and contribute to scientific endeavors [KPG + 22, MC24].</p>
<p>Given this rapid advancement of AI for science and its potential to revolutionize scientific practices, there's growing interest in how AI is affecting science.The main feature of CPC-MS is its proposal of a model of science as a CPC activity involving multiple agents.This characteristic allows us to discuss important aspects of how AI might change the nature of science.Specifically, by modeling the scientific community as a hybrid system composed of fundamentally different agents -AI and humans -CPC-MS enables us to explore how this transformation might impact science or even alter the very nature of scientific inquiry.</p>
<p>For instance, the entry of AI into the scientific community might reduce the overall bias of the community.Humans are constrained by biological and cognitive limitations that restrict what they can understand, and their cognition is distorted by cognitive biases and social pressures.In the CPC framework, Î¸ k for each agent k represents these biases and hence their world models, which in turn affect the generation of o k d and z k d .Since bias is prevalent in human agents, its effect on the global scientific representations w d can be proliferated through collective inference in human-only scientific community.Such bias would lead to skewed or biased inferences, the "blind spot" theory, and slower convergence, potentially degrading the social objectivity of science, as we have discussed in Section 3.1.It could also introduce noise and bias in observations or violate the i.i.d.condition, disturbing asymptotic improvement (Section 3.2).</p>
<p>On the other hand, AI would likely have a different Î¸ k than humans', suggesting the possibility of generating different o k d and z k d .Thus, the entry of AI agents into the scientific community might enable the generation of w d that reflects more diverse aspects of target of study d.In other words, the involvement of AI in conducting science suggests that it could introduce greater diversity, which is key for social objectivity in science as discussed in Section 3.1, into the process of scientific knowledge production.Therefore, AI potentially alleviates some of the limitations currently faced by human science, leading to potentially better scientific outcomes.</p>
<p>Simultaneously, the integration of AI also raises concerns about the shared common ground among social members, which is a prerequisite for objectivity as discussed in section 3.1.CPC-MS emphasizes the role of consensus formation through communication among agents in the creation of scientific knowledge.From this perspective, science involving AI can be described as a hybrid system composed of entirely different agents -AI and humans.This bears structural similarities to the AI alignment problem [JQC + 23].In this sense, the CPC-MS framework naturally frames the challenges of AI in science as a specific example of the broader AI alignment issue.</p>
<p>In current science, communication between agents works well because they are all humans who share similar biological bodies and language.However, AI lacks this commonality with us, potentially arising the issue of communication barrier.This suggests that the premise of science as distributed predictive coding, which we explained in Section 3.1, could collapse with the participation of AI as a scientist in the scientific community.</p>
<p>Moreover, a significant increase in the differences between agents could make global scientific representation production inefficient too.In a two-agent MHNG with agent k and l, for example, agent l updates w d by either accepting or rejecting proposals from agent k.If agent k and agent l are an AI and a human, respectively, their internal scientific representations z k d and z l d and then the distributions they follow are expected to be significantly different.Consequently, the generated w k d and w l d will also be very different.Therefore, if the original w d is w l d and the proposal is w k d , the acceptance rate is expected to be quite low (e.g., in MHNG, w k d is accepted with probability min(1,
P (z k d |Î¸ k ,w l d ) P (z k d |Î¸ k ,w k d ) )
, and when w k d and w l d differ significantly, this probability is likely to be small).This could lead to poor convergence efficiency.</p>
<p>As the diversity and heterogeneity among agents increase, the common ground they share tends to decrease.This presents a fundamental trade-off: while greater diversity can enhance social objectivity in science, it also risks undermining the shared basis necessary for effective communication and collaboration.To maximize the potential of AI in expanding new scientific possibilities, it is thus crucial to proactively develop and establish this common ground among diverse constituents, in anticipation of AI scientists' future participation.This involves creating a new scientific framework that maintains the benefits of heterogeneity while ensuring effective collaboration between human and AI agents.</p>
<p>Like this, we can see that the integration of AI scientists into the human scientific community has the potential to significantly impact even the fundamental premises of science.Therefore the emergence of hybrid system of AI and human scientist is creating opportunities to debate and reshape the very nature of science itself, moving beyond simply considering their impact on traditional scientific practices.Humans might have only explored a limited portion of the possible space of science [NQ22], and it has been pointed out that the current scientific system faces many problems.The rise of AI offers us a chance to do more than just passively observe how science is changing.Instead, we can take an active role in reimagining and reshaping science itself.</p>
<p>Guideline for Implementing Automated Total Science Activity</p>
<p>CPC-MS has the potential to provide guidelines for implementing and automating the entire scientific process of a group of scientists as a machine learning model.This could bring a new perspective to the efforts of automating science, which have traditionally focused on automating specific tasks within an individual scientist's research workflow.</p>
<p>The pursuit of automating scientific practices by machines dates back to the early days of computing, with pioneering systems like DENDRAL [LBFL93] and BACON [Lan87].Subsequently, as exemplified by the term fourth paradigm of science, the advancement and proliferation of computational capabilities led to the automation of certain tasks within scientific activities [Hey09].The 2000s saw machine learning techniques like Bayesian optimization applied to scientific processes.However, it was the deep learning revolution of the 2010s that truly accelerated the integration of AI into science, a field now known as AI for Science [WFD + 23, XLC + 21, ZWH + 23].This integration has enabled discoveries previously unsolved by humans, with AlphaFold [JEP + 21] serving as a prime example.</p>
<p>While these activities have brought tremendous progress to humanity, they have largely been limited to the automation and substitution of a specific task in a scientific process.Current research involves activities like formulating questions, conducting experiments, and writing papers.However, attempts to fully automate an entire research cycle, encompassing all of these activities from start to finish, remain few and far between.</p>
<p>There are few examples of attempts to automate an entire research cycle, with systems like Adam [KWJ + 04] and Eve [WBS + 15] being notable exceptions.Adam is a closed-loop automation system that combines traditional symbolic AI with robotics to automatically generate hypotheses, verify them, and modify them based on feedback.More recently, groundbreaking research has proposed an AI system capable of conducting machine learning research in a highly automated, end-to-end manner, handling a wide range of tasks from initial idea generation to paper writing [LLL + 24].</p>
<p>However, even these attempts are specialized, focusing on automating specific areas of scientific research rather than achieving a general automation of science.Furthermore, the automation achieved so far typically replicates the research process of a single scientist.The AI Scientist by Lu et al.</p>
<p>[LLL + 24] represents a significant step forward in automating the social aspects of scientific work, as it not only automates paper writing but also the peer review process.However, even this study still falls short of automating the entire scientific activities.</p>
<p>As this paper emphasizes, science is inherently a collaborative effort.It's common for multiple researchers to work together to understand a single phenomenon, and peer review -the process by which other researchers validate research outcomes -is a crucial aspect of scientific activity.The existing closed-loop research automation systems have not yet managed to incorporate these social aspects, leaving the automation of the entire scientific process, including its collaborative nature, still unrealized.</p>
<p>To achieve this goal, we need a model that captures both the social dimensions of science and the entire process from discovery to knowledge representation and communication by scientists, without being too tied to specific scientific practices.Moreover, to actually automate this model in practice, it needs to be implementable, which means it must be expressible mathematically.CPC-MS offers such a model of science.In essence, CPC-MS could serve as a foundation or starting point for developing a system capable of automatically executing the full spectrum of scientific activities performed by a scientific community.</p>
<p>CPC-MS takes a unique approach by modeling science as a probabilistic generative process.This perspective allows us to view the whole range of scientific activities through the lens of statistical machine learning, enabling us to potentially implement these activities as a machine learning model.Furthermore, by framing science in terms of generative models, CPC-MS can easily incorporate the latest developments in generative AI -a field that has been making waves across society in recent years.To conclude, CPC-MS offers a novel framework for understanding and advancing the future direction of research automation.</p>
<p>Future Work</p>
<p>Network Structure in Scientific Communities The CPC framework can be extended by considering the network structure of multiple agents.Interactions between multiple agents with the CPC framework describe biases and effects in scientific communities.Global scientific representations are often generated by a small scientific community with a few dozen of members.Demographics of such small community may bias or influence scientific activities such as paper citation [TKL + 22], peer-review [LRA18], and recruiting [LAAD18].For example, gendered citation patterns are known in contemporary physics [TKL + 22].This pattern can be described as inferences from smaller number of agents.A small number of agents easily biases collective decision-making.</p>
<p>Another bias can come from whether researchers work with famous or non-famous researchers, notably the Matthew Effect [Mer68,MH18].The difference between famous and less famous researchers may influence range of broadcasting global representations.Less famous researcher may not be able to broadcast global scientific representations to other members effectively while famous researcher can do.A similar pattern also appears in famous and less famous research institutes [ZWLC22].Academic success may also be influenced by structure of social network.For example, diverse intellectual synthesis between mentors and mentees influences success in academic careers [LAAD18].</p>
<p>It is worth to mention relationship with science of science (SciSci) [FBB + 18].SciSci is an emergent interdisciplinary field to uncover mechanisms of doing science using computational methods.Geographical and temporal interactions between scientists are targets of SciSci in addition to conventional citation and co-authorship analyses.The CPC framework is based on interactions between multiple agents, and concurs with SciSci from the perspective of analyzing network structure.</p>
<p>Furthermore, SciSci also aims to influence network structure of agents and scientific activities.One solution is to create open datasets and softwares visualizing biases in scientific activities.Some studies contribute to policy making in scientific commercialization [MH21] and public funding [YDW + 22, RTH23].Ohniwa et al., showed diverse and smaller grants are more effective than centralized and larger grants to generate new fields and promote technology transfer in Japan public funding [RTH23].Such evidence may theoretically support effectiveness of decentralized communities, so called decentralized autonomous organizations (DAOs), to support science projects [SLA24].Recently, there has been a growing momentum around the movement known as decentralized science (DeSci).DeSci are practices of science or related activities, which often are designed with decentralized mechanisms and technologies such as blockchain.In this regards, the CPC theory can be extended by theoretical understanding of social biases and computational frameworks to analyze new forms of science management models including DeSci.Further studies of social network will contribute to the extension of the CPC framework.</p>
<p>Simulation Study of CPC Science Model CPC provides a computational model of science.Therefore, by executing this model on a computer, it is possible to simulate how the scientific community produces knowledge.The advantage of being able to simulate science is that it allows us to conduct pseudo-experiments on science, which is a social activity where actual experiments are not possible.This enables us to discuss how various factors could potentially influence the scientific community and in what ways.For instance, changing the distribution that Î¸ k follows for each k may allow us to study how the diversity among scientists actually influences scientific activity (Sections 3.1 and 4.1).Moreover, if we limit the communication to agents within the same cluster c and restrict inter-cluster communication, we may be able to reveal the impact of clustering on the production of global scientific representations in scientific communities, as discussed above.Additionally, introducing malicious players who make false reports.For example, we may introduce players with an irrational acceptance ratio of w d or players that randomly suggest w k d independent of z k d .Alternatively we may also introduce agents that excessively prioritize individual epistemic value or pragmatic values (Section 2.3) and how these agents affect scientific integrity.</p>
<p>Non-Statioanrity</p>
<p>In the current CPC-MS, for simplicity, it is implicitly assumed that the distribution that w d follows is stationary.However, in reality, the distribution that w d follows may change over time.For example, in fields where claims are difficult to verify and established theories can change significantly when new evidence emerges, the distribution of w d is expected to be non-stationary.Extending CPC-MS to naturally model such non-stationary distributions of w d is one potential direction for expanding the framework.</p>
<p>Incorporating External Players In the current framework, only scientists are considered agents, but in actual science, multiple non-scientist players are essential.These include funders, influencers of scientific direction, and educators.The current CPC-MS framework does not explicitly model these players, limiting discussions of their influence.Incorporating non-scientist players could extend the model.For example, funders influence research themes, indirectly corresponding to selecting certain object d to be studied from this world.This decision-making is closely related to how w d is used and what is required as w d for a society [YDW + 22].The current framework models the inference of w d of target of study but does not address how the target is selected or how w d is used.Modeling such target selection process, as mentioned above, could provide deeper insights into the effect of the society to science.</p>
<p>Utilities and Values</p>
<p>When selecting research topics, the value to society and individuals becomes a crucial factor driving research activities.At first glance, the generative model of CPC (Figure 3) may appear to focus solely on the encoding of observational information, without incorporating elements such as individual values or rewards.However, the PGM of CPC can be naturally extended to include decision-making based on rewards and values.In many cases, decision-making based on rewards and values can be reformulated as Bayesian inference of action sequences to reach a desired state [Lev18,KGO12].Building on this theory, Ebara et al. have proposed a multi-agent reinforcement learning algorithm that extends the MHNG based on CPC to include symbol emergence [ENTT23].</p>
<p>Following the formulation of active inference presented in Section 2.3, pragmatic value can be used to model both utilities and values.</p>
<p>Based on the CPC-MS framework, future challenges include discussing the selection of research topics based on values and the impact of individual agents' (researchers') incentives on scientific exploration as CPC.</p>
<p>Conclusion</p>
<p>The CPC-MS framework presented in this paper offers a novel perspective on scientific activities, viewing them through the lens of collective predictive coding and decentralized Bayesian inference.By modeling science as a generative process carried out by a community of agents-namely, generative science-CPC-MS provides several key insights.</p>
<p>It formalizes the social nature of scientific knowledge production, demonstrating how individual observations and hypotheses are integrated into explicit scientific knowledge, i.e., global scientific representations, through communication and peer review.The CPC-MS framework offers a mathematical foundation for understanding scientific progress, paradigm shifts, and the role of diversity in scientific communities.It bridges the gap between individual cognitive processes and collective knowledge creation in science, offering a unified view of scientific activities, from experimentation to theory development.</p>
<p>The CPC-MS framework aligns with and extends existing ideas in the philosophy of science, such as social objectivity and the generative nature of scientific theories.It encourages us to view science not just as a collection of facts or theories, but as a dynamic, collective cognitive process that continually refines our understanding of the world.</p>
<p>As we move towards an era where AI plays an increasingly significant role in scientific research, the CPC-MS framework provides a valuable tool for understanding and shaping the future of science.Additionally, the mathematical nature of CPC-MS allows us to integrate generative AI-based automated scientific research as a part of the CPC-MS framework.</p>
<p>Future work could focus on refining the mathematical models underlying CPC-MS, conducting empirical studies to test its validity in modeling actual scientific studies, and exploring its implications for science policy, research management, and research ethics.Ultimately, this framework aims to contribute to a more comprehensive understanding of how scientific knowledge is created, validated, and advanced through collective effort.Rewards taken by the k-th agent (e.g., budget for the experiments) F Variational free energy G(a)</p>
<p>Expected free energy for future actions (bold a represents actions of all agents)</p>
<p>Figure 1 :
1
Figure 1: Overview of Collective Predictive Coding as Model of Science.This figure illustrates how scientific knowledge emerges through collective processes.Scientists conduct experiments and observations, engaging with the target objects, i.e., environment, through their research methodologies.These individual interactions generate data and insights, which are then synthesized and encoded into a shared system of scientific knowledge, analogous to how language emerges in linguistic systems.The diagram depicts a cyclical nature of this process, where internal scientific activities contribute to and are informed by the collective understanding, forming a dynamic feedback loop between personal research and the broader scientific corpus.</p>
<p>Figure 2 :
2
Figure 2: Left: Metropolis-Hastings naming game (MHNG) [TYM + 23].In the MHNG, a sign w d representing the d-th object is regarded as a sample from an integrated posterior distribution P (w d |o d A , o d B ) where o d * is the * -th agent's observation.The naming game acts as a distributed Bayesian inference of the posterior distribution over the shared latent variables w d representing shared external representations.Right: scientific activities updating shared explicit knowledge through experiments and communications involving peer-review process.The total systemic dynamics is structurally analogous to the MHNG.</p>
<dl>
<dt>Figure 3: Probabilistic graphical model underlying the CPC-MS framework, which is a variant of that of CPC [Tan24].Left: An integrated model depicting the relationship between individual scientists' observations and a shared global scientific representation.In this framework, the observation o k d of the d-th target by the k-th scientist is conceptualized as being influenced by the d-th global scientific representation w d , mediated by the scientist's internal representation z k d .The parameter Î¸ k encapsulates the k-th scientist's learned internal models.K and D denote the total number of scientists and targets, respectively.Right: A decomposed version of the model, illustrating how the global scientific representation w d evolves through inter-scientist communication, acting as a decentralized Bayesian inference.This process is exemplified by paper submission and peer review.Through this mechanism, w d emerges as a global scientific representation of the d-th target.</dt>
<dd>
<p>A research teams k âˆˆ K designs and conducts an experiment to investigate the effect of drug X on disease Y .For example, they perform clinical trials and collect data o k d on patients' symptom improvement and biomarker changes.The action a k d here corresponds to the specific experimental procedures, such as administering the drug, measuring biomarkers, and recording patient outcomes.Though multiple research teams can obtain their respective o k d (k âˆˆ K), each group can only perform a subset of possible experiments and obtain partial observations due to ethical constraints, experimental design limitations, and limitations, such as constraints on experimental equipment and number of subjects.2. Testing and Refining Hypotheses: Research team k analyzes the observational data o =</p>
</dd>
</dl>
<p>Figure 4 :
4
Figure 4: (a) Left: expected freecal CPC models show gradual, continuous updates of the posterior distribution q(Î¸ | o) as sample size increases.Right: Singular CPC models demonstrate discontinuous jumps in the posterior distribution, representing paradigm shifts in scientific understanding.(b) A network representation of the Singular CPC model, where scientists (Agent 1 and Agent 2) act as neurons.The connections between nodes illustrate how scientific concepts or theories interact and evolve, potentially leading to sudden structural changes in the collective knowledge network.</p>
<p>Table 2 :
2
Nomenclature of CPC-MS Symbol Description w d External representation for the d-th target z k d Internal representation of the k-th agent for the d-th target o k d Observation of the k-th agent for the d-th target d Index for taret objects or phenomena being studied k Index for individual agents (e.g., scientists) Î¸ k Local parameters for the k-th agent (e.g., learned internal models) K Total number of agents D Total number of objects p(w d ) Prior distribution of external representations for the d-th object p(o k d |z k d ) Likelihood of observations given internal representations for the k-th agent and d-th object p(z k d |w d ) Prior distribution of internal representations given external representations q(w d |{z k d } k ) Approximate posterior distribution of external given internal representations q(z k d |o k d ) Approximate posterior distribution of internal representations given observations p(w d |{o k d } k ) True posterior distribution of external representations given observations q(w d |{o k d } k ) Approximated posterior distribution of external representations given observations a k Actions taken by the k-th agent (e.g., conducting experiments) C k</p>
<p>. 1 .
1
Experimentation and Measurement: Each agent (scientist) performs experiments on the d-th target and collects observations, which represent the data o = {o * d } d .Due to limited access
Mathematical notationsScience activitiesLanguage emergenceGlobal scientific representationShared symbolic system(e.g., published papers,(e.g., words,established theories,sentences,External representations wconsensus models)signs)Cognitive representationsInternal scientific representations(e.g., concepts,(e.g., hypotheses, insights,mental images,Internal representations zmental models, intuitions)perceptual state)Empirical dataSensory experiences(e.g., experimental results,(e.g., visual, auditory,Observations ofield observations, measurements)tactile inputs)Hypothesis formation and revisionRepresentation learning(e.g., data analysis,(e.g., categorization,Inference of P (z|o)theory development)concept formation)Scientific communicationLanguage game(e.g., paper writing, peer review,(e.g., speech production,Inference of P (w|z)oral discussion)interpretation)Table 1: Correspondences between mathematical notations in CPC, phenomena in scientific activitiesand language emergenceto the world, scientists can only perform a subset of possible experiments and obtain partialobservations.2. Testing and Refining Hypotheses: Based on the observations (o = {o  *  d } d
Note that there are two types of interpretation of the review process. One is that two researchers, the k-th and
AcknowledgmentThis study is partially supported by JSPS KAKENHI Grant Number JP21H04904, and JST Moonshot R&amp;D Program, Grant Number JPMJMS2033.We also thank Ryuichi Maruyama and the AI Alignment Network (ALIGN), who facilitated our collaboration and provided continuous support.
Monya Baker. 1,500 scientists lift the lid on reproducibility. Nature. 53376042016</p>
<p>Novelty and curiosity as determinants of exploratory behavior. Daniel Berlyne, British Journal of Psychology. 411950</p>
<p>Distributed science-the scientific process as multiscale active inference. + Bfcf, Francesco Balzan-Francesco, John Campbell, Karl Friston, Maxwell James Ramstead, Daniel Friedman, Axel Constant, 2023OSF Preprints</p>
<p>Pattern recognition and machine learning. M Christopher, Bishop, 2006springer</p>
<p>Logical foundations of probability. Rudolf Carnap, 1950University of Chicago Press</p>
<p>Daniel Chandler, Semiotics the Basics. Routledge2002</p>
<p>Whatever next? predictive brains, situated agents, and the future of cognitive science. Andy Clark, Behavioral and brain sciences. 3632013</p>
<p>Multi-agent reinforcement learning with emergent communication using discrete and indifferentiable message. Hiroto Ebara, Tomoaki Nakamura, Akira Taniguchi, Tadahiro Taniguchi, 2023 15th International Congress on Advanced Applied Informatics Winter (IIAI-AAI-Winter). 2023</p>
<p>Santo Fortunato, Carl T Bergstrom, Katy BÃ¶rner, James A Evans, Dirk Helbing, StaÅ¡a MilojeviÄ‡, Alexander M Petersen, Filippo Radicchi, Roberta Sinatra, Brian Uzzi, Alessandro Vespignani, Ludo Waltman, Dashun Wang, Albert-LÃ¡szlÃ³ BarabÃ¡si, FBB + 18. 2018359185Science</p>
<p>World model learning and inference. Rosalyn J Fmn + 21] Karl Friston, Yukie Moran, Tadahiro Nagai, Hiroaki Taniguchi, Josh Gomi, Tenenbaum, Neural Networks. 1442021</p>
<p>The free-energy principle: a unified brain theory?. Karl Friston, Nature reviews neuroscience. 1122010</p>
<p>Karl Friston, arXiv:1906.10184A free energy principle for a particular physics. 2019arXiv preprint</p>
<p>A computational inflection for scientific discovery. Hdw + 23] Tom, Doug Hope, Downey, Oren Daniel S Weld, Eric Etzioni, Horvitz, Communications of the ACM. 6682023</p>
<p>The fourth paradigm. United States of America. Tony Hey, 2009</p>
<p>The predictive mind. Jakob Hohwy, 2013Oxford University Press</p>
<p>. David Ha, JÃ¼rgen Schmidhuber, arXiv:1803.101222018World models. arXiv preprint</p>
<p>Highly accurate protein structure prediction with alphafold. John Jumper, Richard Evans, Alexander Pritzel, Tim Green, Michael Figurnov, Olaf Ronneberger, Kathryn Tunyasuvunakool, Russ Bates, Augustin Å½Ã­dek, Anna Potapenko, JEP + 21. 2021596</p>
<p>Ai alignment: A comprehensive survey. Jiaming Ji, Tianyi Qiu, Boyuan Chen, Borong Zhang, Hantao Lou, Kaile Wang, Yawen Duan, Zhonghao He, Jiayi Zhou, Zhaowei Zhang, arXiv:2310.19852JQC + 23. 2023arXiv preprint</p>
<p>Optimal control as a graphical model inference problem. VicenÃ§ Hilbert J Kappen, Manfred GÃ³mez, Opper, Machine learning. 8722012</p>
<p>The wick in the candle of learning: epistemic curiosity activates reward circuitry and enhances memory. Min Jeong Kang, Ming Hsu, Ian M Krajbich, George Loewenstein, Joseph Samuel M Mcclure, Colin F Tao-Yi Wang, Camerer, KHK + 09Psychological Research. 2092009</p>
<p>Philip Kitcher, The Advancement of Science: Science Without Legend, Objectivity Without Illusions. Oxford University Press1993</p>
<p>On scientific understanding with artificial intelligence. Mario Krenn, Robert Pollice, Si Yue Guo, Matteo Aldeghi, Alba Cervera-Lierta, Pascal Friederich, Gabriel Dos Passos, Florian Gomes, Adrian HÃ¤se, Akshatkumar Jinich, Nigam, KPG + 22Nature Reviews Physics. 4122022</p>
<p>The automation of science. Jem Ross D King, Stephen G Rowland, Michael Oliver, Wayne Young, Emma Aubrey, Maria Byrne, Magdalena Liakata, Pinar Markham, Larisa N Pir, Soldatova, KRO + 09Science. 32459232009</p>
<p>Thomas S Kuhn, The Structure of Scientific Revolutions. University of Chicago Press1962226</p>
<p>Functional genomic hypothesis generation and experimentation by a robot scientist. Ross D King, Ffion M Kenneth E Whelan, Philip Gk Jones, Christopher H Reiser, Stephen H Bryant, Douglas B Muggleton, Stephen G Kell, Oliver, KWJ + 04Nature. 42769712004</p>
<p>Intellectual synthesis in mentorship determines success in academic careers. Jean F LiÃ©nard, Titipat Achakulvisut, Daniel E Acuna, Stephen V David, Nature Communications. 948402018</p>
<p>The methodology of scientific research programmes. Imre Lakatos, 1978Cambridge University Press</p>
<p>Scientific discovery: Computational explorations of the creative processes. Pat Langley, 1987MIT press</p>
<p>A confutation of convergent realism. Larry Laudan, Philos. Sci. 481March 1981</p>
<p>Dendral: a case study of the first expert system for scientific hypothesis formation. Bruce G Robert K Lindsay, Edward A Buchanan, Joshua Feigenbaum, Lederberg, Artificial intelligence. 6121993</p>
<p>Sergey Levine, arXiv:1805.00909Reinforcement learning and control as probabilistic inference: Tutorial and review. 2018arXiv preprint</p>
<p>. L D Landau, E M Lifshitz, Number v. 11982Elsevier Science</p>
<p>The ai scientist: Towards fully automated open-ended scientific discovery. Lll + 24] Chris, Cong Lu, Robert Lu, Jakob N Lange, Jeff Foerster, David Clune, Ha, arXiv:2408.062922024arXiv preprint</p>
<p>The psychology of curiosity: A review and reinterpretation. Psychological. George Loewenstein, Bulletin. 11611994</p>
<p>Science as social knowledge: Values and objectivity in scientific inquiry. Helen E Longino, 1990Princeton University PressPrinceton, NJ</p>
<p>Non-white scientists appear on fewer editorial boards, spend more time under review, and receive fewer citations. Fengyuan Liu, Talal Rahwan, Bedoor Alshebli, Proceedings of the National Academy of Sciences. 948402018</p>
<p>Laboratory life: The construction of scientific facts. Bruno Latour, Steve Woolgar, 1979Sage Publications</p>
<p>Can large language models provide useful feedback on research papers? a large-scale empirical analysis. Weixin Liang, Yuhui Zhang, Hancheng Cao, Binglu Wang, Daisy Yi Ding, Xinyu Yang, Kailas Vodrahalli, Siyu He, Scott Daniel, Yian Smith, Yin, NEJM AI. 24001962024LZC + 24</p>
<p>Mapping the increasing use of llms in scientific papers. Weixin Liang, Yaohui Zhang, Zhengxuan Wu, Haley Lepp, Wenlong Ji, Xuandong Zhao, Hancheng Cao, Sheng Liu, Siyu He, Zhi Huang, arXiv:2404.012682024arXiv preprintLZW + 24</p>
<p>Deborah G Mayo, Statistical Inference as Severe Testing: How to Get Beyond the Statistics Wars. Cambridge, UKCambridge University Press2018</p>
<p>Artificial intelligence and illusions of understanding in scientific research. Lisa Messeri, Crockett, Nature. 62780022024</p>
<p>The matthew effect in science: The reward and communication systems of science are considered. Robert K Merton, Science. 15938101968</p>
<p>The matthew effect in science funding. Matt Marx, David H Hsu, Proceedings of the National Academy of Sciences. 11519. 2018</p>
<p>Revisiting the entrepreneurial commercialization of academic science: Evidence from "twin" discoveries. Matt Marx, David H Hsu, Management Science. 6822021</p>
<p>A Vision of Metascience An Engine of Improvement for the Social Processes of Science. Michael Nielsen, Kanjun Qiu, 2023-05-17</p>
<p>Intrinsic motivation, curiosity, and learning: Theory and applications in educational technologies. Pierre Oudeyer, Jacqueline Gottlieb, Manuel Lopes, Progress in Brain Research. 2292016</p>
<p>Thinking About Statistics: The Philosophical Foundations. Jun Otsuka, December 2022Routledge</p>
<p>The Logic of Scientific Discovery. Raimund Karl, Popper, 1959Hutchinson &amp; Co</p>
<p>The effectiveness of japanese public funding to generate emerging topics in life science and medicine. Kunio Ohniwa L Ryosuke, Aiko Takeyasu, Hibino, PLOS ONE. 188e02900772023</p>
<p>On the interplay of curiosity, confdence, and importance in knowing information. W H Spitzer, Jania Janz, Maohua Nie, Andrea Kiesel, Psychological Research. 882024</p>
<p>The potential of daos for funding and collaborative development in the life sciences. Fantaccini Simone, Grassi Laura, Rampoldi Andrea ; Philipp Schwartenbeck, Johannes Passecker, Tobias U Hauser, Thomas Hb Fitzgerald, Martin Kronbichler, Karl J Friston, Nat Biotechnol. 42e417032024. 2019Computational mechanisms of curiosity and goaldirected exploration</p>
<p>Collective predictive coding hypothesis: Symbol emergence as decentralized Bayesian inference. Tadahiro Taniguchi, Frontiers in Robotics and AI. 1113538702024</p>
<p>Citation inequity and gendered citation practices in contemporary physics. Erin G Teich, TKL + 22Jason Z Kim, TKL + 22Christopher W Lynn, TKL + 22Samantha C Simon, TKL + 22Andrei A Klishin, TKL + 22Karol P Szymula, TKL + 22Pragya Srivastava, TKL + 22Lee C Bassett, TKL + 22Perry Zurn, TKL + 22Jordan D Dworkin, TKL + 22Dani S Bassett, TKL + 22Nature Physics. 6102022</p>
<p>World models and predictive coding for cognitive and developmental robotics: frontiers and challenges. Tadahiro Taniguchi, Shingo Murata, Masahiro Suzuki, Dimitri Ognibene, Pablo Lanillos, Emre Ugur, Lorenzo Jamone, Tomoaki Nakamura, Alejandra Ciria, Bruno Lara, Giovanni Pezzulo, TMS + 23. 202337</p>
<p>Symbol emergence in robotics: a survey. Tnn + 16] Tadahiro, Takayuki Taniguchi, Tomoaki Nagai, Naoto Nakamura, Tetsuya Iwahashi, Hideki Ogata, Asoh, Advanced Robotics. 3011-122016</p>
<p>Active Inference: The Free Energy Principle in Mind, Brain, and Behavior. Karl J Friston, Thomas Parr, Giovanni Pezzulo, 2022The MIT Press</p>
<p>Symbol emergence in cognitive developmental systems: a survey. Tadahiro Taniguchi, Emre Ugur, Matej Hoffmann, Lorenzo Jamone, Takayuki Nagai, Benjamin Rosman, Toshihiko Matsuka, Naoto Iwahashi, Erhan Oztop, Justus Piater, TUH + 18. 201811</p>
<p>Emergent communication through metropolis-hastings naming game with deep generative models. Tadahiro Taniguchi, Yuto Yoshida, Yuta Matsui, Le Nguyen, Akira Hoang, Yoshinobu Taniguchi, Hagiwara, TYM + 23. 202337</p>
<p>Algebraic Geometry and Statistical Learning Theory. Sumio Watanabe, 2009Cambridge University Press</p>
<p>Cheaper faster drug development validated by the repositioning of drugs against neglected tropical diseases. Sumio Watanabe, Kevin Williams, Elizabeth Bilsland, Andrew Sparkes, Wayne Aubrey, Michael Young, Larisa N Soldatova, Kurt De Grave, Jan Ramon, Michaela De Clare, Worachart Sirawaraporn, Mathematical Theory of Bayesian Statistics. Routledge2018. 20151220141289WBS + 15</p>
<p>Scientific discovery in the age of artificial intelligence. Hanchen Wang, Tianfan Fu, Yuanqi Du, Wenhao Gao, Kexin Huang, Ziming Liu, Payal Chandak, Shengchao Liu, Peter Van Katwyk, Andreea Deac, WFD + 23. 2023620</p>
<p>Artificial intelligence: A powerful paradigm for scientific research. Yongjun Xu, Xin Liu, Xin Cao, Changping Huang, Enke Liu, Sen Qian, Xingchen Liu, Yanjun Wu, Fengliang Dong, Cheng-Wei Qiu, XLC + 21. 22021</p>
<p>The future of fundamental science led by generative closed-loop artificial intelligence. Yian Yin, Yuxiao Dong, Kuansan Wang, Dashun Wang, Benjamin F Jones, Hector Zenil, Jesper TegnÃ©r, Felipe S AbrahÃ£o, Alexander Lavin, Vipin Kumar, Jeremy G Frey, Adrian Weller, Larisa Soldatova, Alan R Bundy, Nicholas R Jennings, arXiv:2307.07522Nature human behaviour. 6102022. 2023arXiv preprintPublic use and public funding of science</p>
<p>Artificial intelligence for science in quantum, atomistic, and continuum systems. Xuan Zhang, Limei Wang, Jacob Helwig, Youzhi Luo, Cong Fu, Yaochen Xie, Meng Liu, Yuchao Lin, Zhao Xu, Keqiang Yan, arXiv:2307.08423ZWH + 23. 2023arXiv preprint</p>
<p>Labor advantages drive the greater productivity of faculty at elite universities. Sam Zhang, K Hunter Wapman, Daniel B Larremore, Aaron Clauset, Science Advances. 84670562022</p>            </div>
        </div>

    </div>
</body>
</html>