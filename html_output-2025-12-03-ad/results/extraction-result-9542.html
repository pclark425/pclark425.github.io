<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-9542 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-9542</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-9542</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-166.html">extraction-schema-166</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using LLMs or related models to distill, extract, or discover quantitative laws, equations, or mathematical relationships from large collections of scholarly papers, including methods, results, challenges, and limitations.</div>
                <p><strong>Paper ID:</strong> paper-272881371</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2409.17011v2.pdf" target="_blank">LLM-CARD: Towards a Description and Landscape of Large Language Models</a></p>
                <p><strong>Paper Abstract:</strong> With the rapid growth of the Natural Language Processing (NLP) field, a vast variety of Large Language Models (LLMs) continue to emerge for diverse NLP tasks. As an increasing number of papers are presented, researchers and developers face the challenge of information overload. Thus, it is particularly important to develop a system that can automatically extract and organise key information about LLMs from academic papers (\textbf{LLM model card}). This work is to develop such a pioneer system by using Named Entity Recognition (\textbf{NER}) and Relation Extraction (\textbf{RE}) methods that automatically extract key information about large language models from the papers, helping researchers to efficiently access information about LLMs. These features include model \textit{licence}, model \textit{name}, and model \textit{application}. With these features, we can form a model card for each paper. \textbf{Data-contribution} wise, 106 academic papers were processed by defining three dictionaries - LLMs name, licence, and application. 11,051 sentences were extracted through dictionary lookup, and the dataset was constructed through manual review of the final selection of 129 sentences that have a link between the name and the licence, and 106 sentences that have a link between the model name and the application. Data and code in \textsc{LLM-Card} is openly hosted at \url{https://github.com/shengwei-tian/dependency-parser-visualization}</p>
                <p><strong>Cost:</strong> 0.003</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <p class="empty-note">No extracted data.</p>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <p class="empty-note">No potentially relevant new papers extracted.</p>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-9542",
    "paper_id": "paper-272881371",
    "extraction_schema_id": "extraction-schema-166",
    "extracted_data": [],
    "potentially_relevant_new_papers": [],
    "cost": 0.00326675,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>LLM-CARD: Towards a Description and Landscape of Large Language Models</p>
<p>Shengwei Tian shengwei.tian@postgrad.manchester.ac.uk 
The University of Manchester</p>
<p>Lifeng Han lifeng.han@manchester.ac.uk 
The University of Manchester</p>
<p>Erick Mendez Guzman erick.mendezguzman@manchester.ac.uk 
The University of Manchester</p>
<p>Goran Nenadic g.nenadic@manchester.ac.uk 
The University of Manchester</p>
<p>LLM-CARD: Towards a Description and Landscape of Large Language Models
E745C6E04EF6B9E15766E21A9A73D1E4
With the rapid growth of the Natural Language Processing (NLP) field, a vast variety of Large Language Models (LLMs) continue to emerge for diverse NLP tasks.As more papers are presented, researchers and developers face the challenge of information overload.Thus, it is particularly important to develop a system that can automatically extract and organise key information about LLMs from academic papers (LLM model card).This work is to develop such a pioneer system by using Named Entity Recognition (NER) and Relation Extraction (RE) methods that automatically extract key information about large language models from the papers, helping researchers to access information about LLMs efficiently.These features include model licence, model name, and model application.With these features, we can form a model card for each paper.Data-contribution wise, 106 academic papers were processed by defining three dictionaries -LLMs name, licence, and application.11,051 sentences were extracted through dictionary lookup, and the dataset was constructed through manual review of the final selection of 129 sentences with a link between the name and the licence, and 106 sentences with a link between the model name and the application.Data and code in LLM-CARD is openly hosted at https: //github.com/shengwei-tian/dependency-parser-visualization</p>
<p>Introduction</p>
<p>As a major approach in natural language processing (NLP), language modelling has been widely studied for language understanding and generation in the past two decades, evolving from statistical language models to neural language models.Recently, Pre-trained Language Models (PLMs) have been proposed by pretraining Transformer models over large-scale corpora, showing strong capabilities in solving various NLP tasks.Since researchers have found that model scaling can lead to an improved model capacity, they further investigate the scaling effect by increasing the parameter scale to an even larger size.Interestingly, when the parameter scale exceeds a certain level, these enlarged language models not only achieve a significant performance improvement but also exhibit some special abilities (e.g., in context learning) that are not present in small-scale language models (e.g., BERT).To discriminate the language models in different parameter scales, the research community has coined the term LLMs for the PLMs of significant size e.g., tens or even hundreds of billions of parameters.</p>
<p>In the vast world of computer language processing, a revolutionary entity has emerged, Large Language Models (LLMs).These models possess the remarkable ability to understand intricate linguistic patterns and respond coherently matching the context.LLMs are a type of Artificial Intelligence (AI) that serve as powerful tools for various tasks, including machine translation and question answering.One notable example of LLMs is ChatGPT, developed by OpenAI.Based on the GPT-3.5 architecture, it was trained on a vast corpus of internet-sourced text data, including books, articles, wikis, and websites.ChatGPT excels at generating human-like responses and engaging in conversations with users (Hadi et al., 2023).</p>
<p>In recent years, major research institutes and technology companies have increased their investment in the development of LLMs, resulting in a series of groundbreaking models with the potential for a wide range of applications.Ope-arXiv:2409.17011v2[cs.CL] 28 Sep 2024 nAI is a pioneer in this field.The GPT family (e.g.,  has made significant advances in natural language generation, dialogue systems, and text comprehension, and is widely used in a variety of intelligent assistants, content creation tools, and automated services (Torfi et al., 2020).Meanwhile, the Bidirectional Encoder Representations from Transformers (BERT) (Devlin et al., 2019a) and the subsequent T5 (Textto-Text Transfer Transformer) (Raffel et al., 2020) models developed by Google research department have also made significant progress in tasks such as question-answer systems, text classification and information retrieval.Information Retrieval and BERT is used in the natural language processing of Google's search engine.The Roberta and BlenderBot series of models from Facebook (now Meta) have demonstrated powerful performance in social media data analysis and conversational AI (Liu, 2019).</p>
<p>Motivation</p>
<p>Natural Language Processing (NLP) technologies, driven by Large Language Models (LLMs), have skyrocketed and revolutionised the field of NLP, leading to breakthroughs in various tasks such as machine translation, text summarisation, and dialogue systems.However, these advances have been accompanied by the challenge of navigating the vast array of recent research findings.Each year, thousands of papers on LLMs are published, presenting new models, methods, and innovations.This leads to a phenomenon of information overload that makes it difficult for even the most experienced researchers to keep up with the latest developments.</p>
<p>We need a convenient and efficient tool that enables researchers and developers to quickly sift through and understand large numbers of models and their properties, i.e. the LLM-CARD.Motivated by these needs, this work proposes a novel system that automatically extracts such relationships, as illustrated in Figure 1.Our goal is to simplify the process of understanding key information about licence types, application areas, and more for researchers.By automating this process, researchers can gain a clearer understanding of the latest models, allowing them to save time to focus on innovation rather than tediously sifting through extensive literature.</p>
<p>Research Questions</p>
<p>This work mainly focuses on 3 Research Questions (RQs):</p>
<p>• RQ1: How to identify the target sentences that are related to the description of LLMs?</p>
<p>• RQ2: How to model the relationships between LLMs and their licences, and model relationships between LLMs and their applications.</p>
<p>• RQ3: How to address the issue of data scarcity for tasks where no readily available dataset exists for LLMs descriptions.</p>
<p>Highlights</p>
<p>To answer these Research Questions (RQs), we have the following deliverables and highlights regarding this investigation.</p>
<p>• Define a dictionary look-up method to identify the targeted sentences via key phrases.</p>
<p>• Explore a rule-based method to map the LLMs and their model cards, such as licences and applications.</p>
<p>• Manually construct annotated data on such a task and contribute this as the first public data set in this field.</p>
<p>Paper Structure</p>
<p>The remainder of this paper is structured as follows:</p>
<p>• Section 2: Literature Review -This section provides an in-depth review of the current research and developments in the field of LLMs, highlighting existing key models, architectures, and methodologies.It also discusses the challenges associated with managing the vast amount of information in this rapidly evolving field.</p>
<p>• Section 3: Methodology -This section outlines methodologies employed in developing the automated information extraction system, including data collection, processing techniques, and system design.</p>
<p>• Section 4: Experiment -This section presents the results of our system implementation, including the comparison tables generated by the system, and discusses the implications of these results in the context of current research and industry needs. 2 Literature Review</p>
<p>Large Language Models</p>
<p>Language has always been one of the most important abilities that human beings rely on for survival, and this ability develops in childhood and evolves throughout life.Machines, however, lack this innate language ability.So, how can we enable machines this ability to understand and process human language, so that machines can read, communicate, and write like human beings?This is a long-term challenge that humanity continues to face (Turing, 2009).</p>
<p>Early NLP approaches largely relied on rulebased systems and statistical methods, which, despite their effectiveness, were limited by their dependence on handcrafted features and domainspecific knowledge.The introduction of neural networks in the 1980s began to shift this landscape, but it was the advent of deep learning and the subsequent development of LLMs that truly revolutionised the field.</p>
<p>A pivotal moment in the history of LLMs came with the development of word embeddings, such as word2vec (Mikolov, 2013), which enabled models to learn distributed representations of words in a continuous vector space.This innovation laid the groundwork for more complex architectures like Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM) networks, which were among the first to effectively model sequential data, capturing dependencies across different points in a text sequence.</p>
<p>However, the real breakthrough in LLMs occurred with the introduction of the Transformer architecture (Vaswani, 2017).Unlike RNN, which processed sequences sequentially, Transformers could process all tokens in parallel, thanks to their self-attention mechanism.This innovation dramatically improved the efficiency and scalability of language models, enabling them to handle larger datasets and more complex tasks.The first major success using Transformers was Google's BERT (Bidirectional Encoder Representations from Transformers), which was introduced in 2018.BERT was revolutionary in its bidirectional approach to text encoding, allowing the model to consider the context from both sides of a word, rather than just the preceding text as in traditional models (Devlin et al., 2019b).</p>
<p>Following BERT, the field of NLP has progressed rapidly with a series of more powerful models, notably OpenAI's GPT family.GPT-2, released in 2019, significantly improves AI text generation and closes the gap with human writing.In 2020, GPT-3 set a new benchmark with 175 billion parameters for performing small or no samples for complex tasks such as code writing and dialogue generation (Brown, 2020).In 2022, ChatGPT based on GPT-3.5 further optimises dialogue performance for more natural interactions.GPT-4 in 2023 extends to multi-modal tasks, handling text and image inputs, showing potential for a wide range of applications in fields such as healthcare and law (OpenAI, 2023).</p>
<p>However, as the scale of the models and the range of applications have increased, LLMs have also sparked discussions about interpretability, safety, and ethical issues.While these models drive changes in technology and human interaction, their potential risks and limitations need to be treated with caution to ensure that social fairness and safety are maintained while driving innovation.</p>
<p>Named Entity Recognition</p>
<p>Named Entity Recognition (NER) is a subtask of information extraction in NLP, which is used to classify named entities into predefined categories such as names of people, organisations, places, etc.In the field of NLP, understanding these entities is crucial for many applications because they often contain the most important information in a text.NER is a bridge between unstructured text and structured data, enabling machines to sift through large amounts of textual information and extract valuable data in the form of classification.By precisely locating specific entities in a sea of words, NER changes the way we process and utilise textual data.In text mining, a named entity is a word or a phrase that clearly identifies an entity, an entity with similar properties, from a set of other items with similar properties.In the formulation of named entities, the word named limits the scope of entities that have one or more rigid designators that represent the referent.Typically, rigid designators often include proprietary names, but this depends on the domain of interest, which has reference words for objects as named entities (Sharnagat, 2014).For example, in the sentence: BERT was released under the Apache licence 2.0, the entity of licence is Apache licence and the entity of the model name is BERT.As shown in Figure 2, NER can be broken down into several steps: Tokenisation before identifying entities, the text is split into tokens, which can be words, phrases, or even sentences.For example: BERT was released under the Apache licence 2.0 would be split into word chunks such as 'BERT', 'was', 'released', 'under', 'the', 'Apache', 'licence', '2.0'.Entity identification involves recognising items such as capitalisation in licence ('Apache 2.0') or specific formats.Once entities are identified, they are grouped into predefined categories such as 'model name', 'licence' or 'application'.This is typically achieved by machine learning models trained on annotated datasets.In our example, 'BERT' would be categorised as 'model name', while 'Apache 2.0' would be categorised as 'licence'.The NER system usually considers the surrounding context to improve accuracy.After the initial identification and classification, post-processing may be performed to refine the results, which may involve resolving ambiguities, merging multi-tagged entities, or augmenting the entity data with a knowledge base (Jurafsky, 2000).</p>
<p>Relation Extraction</p>
<p>Rule-based methods</p>
<p>The rule-based relation extraction approach as shown in Figure 3 is one of the early techniques in the field of NLP, which relies on linguists and domain experts to manually write rules to extract relations from text based on an in-depth understanding of linguistic structures (Zhang et al., 2009).The core of this approach lies in the use of predefined linguistic patterns or syntactic structures to accurately match entities and their relationships in a text.While this approach excels in some specific domains and tasks, its scalability and generality are limited.</p>
<p>Pattern-based methods Pattern-based relational extraction methods rely heavily on patterns written by linguistic experts, which are usually constructed from specific linguistic rules or regular expressions to capture fixed relational expressions in the text.This approach is very effective in domain-specific tasks, especially when the expected form of the relationship expression is relatively fixed.However, as the diversity of texts increases, the applicability of the fixed model begins to decline.For example, the sentences 'France's capital is Paris' or 'Paris, the capital of France', which express the same relation, both require different models to be captured (Sarawagi et al., 2008).To cope with this linguistic diversity, pattern-based approaches usually require the design of a large number of rules to cover the possible linguistic variants.These rules can be generated either by hand or by using some semiautomated tools, but either way, writing and maintaining them is very time-consuming and labourintensive.</p>
<p>Advantages:</p>
<p>• High precision: In certain highly structured domains, pattern-based methods can achieve very high precision.It is possible to extract • Easy to interpret: Since the rules are handwritten, each extracted relation has a clear logical basis and is easy for humans to understand and verify.</p>
<p>Disadvantages:</p>
<p>• Limited coverage: Pattern-based rules can often only handle a limited number of sentence types, making it difficult to cope with the diversity and complexity of natural language, complex compound sentences or implicit relations often can not be extracted by simple patterns.</p>
<p>• Poor scalability: Rules need to be redesigned and adapted when confronted with new textual domains or languages, which makes it difficult to scale pattern-based approaches to different domains or large-scale corpora.</p>
<p>• High maintenance cost: Languages and expressions may change over time, which requires constant updating and maintenance of the rule base, increasing the cost of long-term use.</p>
<p>Dependency tree-based methods Dependency Tree Based Relation Extraction method extracts more complex relations from sentences by analysing their dependency trees.The dependency tree is a commonly used syntactic structure representation in NLP, which represents the syntactic dependencies between words in a sentence.The advantage of the dependency tree approach is that it can handle complex grammatical structures, including long-distance dependencies and nested relationships.This ability makes the dependency tree-based approach outperform the simple pattern-based approach in processing complex sentences.Dependency tree-based rules usually involve multiple levels of conditions, e.g., the subject of a certain verb node should be a noun of a particular type, and the object of that verb needs to satisfy specific conditions.This fine-grained rule design allows the dependency treebased approach to capture more complex types of relationships (Sachan et al., 2020).</p>
<p>Advantages:</p>
<p>• Handling Complex Syntactic Structures: Dependency trees are able to capture complex relationships between words in a sentence, allowing the method to handle longdistance dependencies and nested structures, which is useful for relational extraction of complex sentences (Tian et al., 2022).</p>
<p>• High Flexibility: The Dependency Tree method is able to adapt to a wide range of syntactic structures and cover a wide range of topics, allowing it to maintain a high accuracy rate in diverse texts.</p>
<p>Disadvantages:</p>
<p>• The complexity of rule design: Due to the complexity of dependency trees, designing effective rules requires deep linguistic knowledge and a lot of experiments, making rule writing difficult and costly.</p>
<p>• Dependence on the quality of syntactic analysis: The accuracy of the dependency tree depends on the performance of the syntactic analyser; if the syntactic analyser produces wrong dependencies, the result of the relation extraction will also be affected.</p>
<p>• Computational resource consumption:</p>
<p>The construction and parsing of dependency trees usually require high computational resources, which limits their application in large-scale real-time processing tasks.</p>
<p>Deep Learning-based methods</p>
<p>With the rise of deep learning, the field of NLP has experienced a revolutionary change.Deep learning methods, shown in Figure 4, have greatly improved the performance of relation extraction by automatically learning to extract complex features from unlabelled data through neural network models.Compared with traditional rule-based approaches, deep learning is better able to adapt to the diversity of languages and performs particularly well when dealing with large-scale data (Young et al., 2018).</p>
<p>Supervised methods</p>
<p>In a supervised learning framework, deep learning models use large amounts of annotated data to automatically learn features in text through a complex neural network structure.The following are several commonly used deep learning models and their applications for extraction:</p>
<p>Convolutional Neural Network (CNN): The application of CNN in relationship extraction is mainly focused on processing sentence-level tasks.Using the sliding window, CNN can effectively extract local contextual information in a sentence, especially in capturing short-distance dependencies between words.Because CNN can process data in parallel, they are very suitable for training large-scale datasets and therefore have been widely adopted in practical applications (Zeng et al., 2014).</p>
<p>Recurrent Neural Networks (RNNs) and Long Short-Term Memory Networks (LSTMs): RNNs and their variant LSTMs can capture temporal information in sequential data and are especially suitable for dealing with long-distance dependencies.LSTM solves the problem of gradient disappearance that occurs in traditional RNNs when dealing with long sequences through the introduction of memory units and the gating mechanism, which enables it to better remember the previous contextual information, thus improving the accuracy of relationship extraction (Zhang and Wang, 2015).</p>
<p>Attention-based models (e.g., Transformer): The introduction of the attention mechanism further improves the performance of deep learning models.The Transformer model is able to process each word while paying attention to the contextual information of all other words in the sentence through the self-attention mechanism, which makes the model perform much better in capturing complex relationships (Vaswani, 2017).Especially when dealing with long sentences and complex contexts, Transformer shows its advantages and has become one of the most popular deep learning models.</p>
<p>Advantages:</p>
<p>• Automated feature learning: Instead of manually designing features, deep learning models can automatically learn the complex features required for relation extraction from text, which greatly simplifies the process of model development.</p>
<p>• Adaptable: Deep learning models are able to handle a wide range of complex linguistic phenomena, including long-distance dependencies, nested structures, and non-linear relationships, making them particularly good at diverse natural language processing.</p>
<p>• Highly scalable: Since deep learning models can be trained in parallel on large-scale datasets, they are highly scalable and suitable for handling large-scale real-world application scenarios.</p>
<p>Disadvantages:</p>
<p>• High demand for labelled data: The training of deep learning models relies on a large amount of labelled data, which may be difficult to obtain in some domains.If the labelled data is insufficient, the model may suffer from overfitting problems, which may affect its generalisation ability.</p>
<p>• High computational resource requirements:</p>
<p>The training of deep learning models usually requires a large amount of computational resources, especially for complex models (e.g., BERT), where training time and resource consumption may become a bottleneck in the application.</p>
<p>• Poor interpretability: Although deep learning models perform well in terms of performance, their internal working mechanisms are often difficult to explain, which can be a significant drawback for some application scenarios that require a high degree of transparency.</p>
<p>Remote/Distant supervised methods Remote supervised learning is a weakly supervised approach to automatically generate annotated data by aligning text with an existing knowledge base.Remote/distance supervision assumes that if there is a known relationship between two entities in the knowledge base, then any sentence containing both entities may express that relationship.While this assumption simplifies the annotation process, it also introduces a large amount of noisy data, as not all sentences containing these entities express the relevant relationship (Mintz et al., 2009;Yuan et al., 2019).</p>
<p>Advantages:</p>
<p>• Reduced annotation cost: Remote supervision greatly reduces the cost of manual annotation by automatically generating annotated data using an existing knowledge base, making large-scale relational extraction possible.</p>
<p>• Applicable to large-scale data: Remote supervision methods can handle large-scale unlabelled corpora, which makes them valuable in constructing large-scale knowledge graphs.</p>
<p>• Disadvantages:</p>
<p>• Noisy data problem: Since the assumptions of remote supervision tend to be too loose, it leads to a large amount of noise in the generated annotated data, which poses a challenge to the training of the model.</p>
<p>• Dependence on the coverage of the knowledge base: The effectiveness of remote supervision is highly dependent on the coverage and quality of the knowledge base; if the knowledge base is not sufficiently comprehensive or accurate, the extraction results of the model will be limited.</p>
<p>• Increased complexity: While the introduction of deep learning techniques has improved model performance, it has also increased model complexity, making the training and inference process more timeconsuming and labour-intensive.</p>
<p>Methodology</p>
<p>In Figure 5, the names of large language models and the relationships between their applications or licences are extracted using LLM-CARD methodology from academic literature using natural language processing techniques based on the dependency parsing approach.Dependency parsing is a technique that reveals syntactic dependencies between words in a sentence.It can systematically identify and extract key information describing large language models in the literature and convert it into structured relational data for further analysis.</p>
<p>Data Construction</p>
<p>Data collection and pre-processing</p>
<p>The first step of the study was to extract text from PDF documents from multiple sources and to ensure comprehensive coverage of the document's content, including body text, footnotes, and graphical descriptions.The extracted text was subjected to disambiguation and lexical annotation using the spaCy library.Segmentation breaks down sentences into separate word units (tokens), while lexical annotation assigns each token a corresponding lexical tag (POS tag), such as noun (NOUN), verb (VERB), etc.As shown in Figure 10, in the sentence 'BERT was released under the Apache licence 2.0', where 'BERT' is tagged as a proper noun (PROPN), 'was' is tagged as an auxiliary verb (AUX), and 'released' is tagged as a verb (VERB).This process lays the foundation for dependency parsing.</p>
<p>Dependency Tree Construction</p>
<p>Dependency annotation is the process of parsing the grammatical structure of a sentence and labelling each word in the sentence with its grammatical dependency.These dependency tags (e.g., nsubjpass, auxpass, prep, etc.) can help us understand the main stem and modifiers in a sentence.For example, in the sentence: BERT was released under the Apache licence 2.0, where BERT is as the subject (nsubjpass) depends on the verb released.</p>
<p>After the annotation of dependency relations, we can represent the syntactic structure of a sentence as a dependency tree.The root node of a dependency tree is usually the predicate verb of a sentence.By constructing a dependency tree, we can visualise the grammatical structure and logical relationships of a sentence.For example, in the sentence: BERT was released under the Apache licence 2.0, where released is the root node and other words depend on it.</p>
<p>Pipeline</p>
<p>To extract the relationship between LLM names and application scenarios or licences from sentences, a set of rules was developed.These rules identify and extract the relationships between model names, application scenarios, and licences based on the syntactic structure of the sentence.Dependency analysis can not only reveal subject-object relationships but also capture modification relationships and compound structures.As shown in Figure 6, the sentence: GPT-4 enhances Text Generation with more accurate and context-aware outputs, where enhances as a core verb forms the main semantic relationship with the subject GPT-4 and the object Text Generation, while enhances forms the main semantic relationship with GPT-4 and the object Text Generation.Through these parses, we are able to systematically extract and structure this information, providing a basis for more advanced tasks such as information extraction and relational modelling.</p>
<p>Experiment</p>
<p>The implementation process of this work is divided into the following key steps: multi-source data extraction, keyword identification and context capture, data screening and organisation, entity recognition annotation (NER), dependency resolution and relationship extraction, and visualisation and querying of relationship triples.The following is a detailed description of each step and its logical relationship in the overall process.</p>
<p>Settings</p>
<p>Complex data formats require complex logic to parse and understand, the Portable Document Format (PDF) is one of the most demanding formats because it is both a data exchange format and a presentation format and has a particularly rigorous tradition of supporting interoperability and consistent presentation (Anantharaman et al., 2023).This work mainly uses the PyMuPDF python library to extract the text of PDF.106 academic papers were processed by defining three dictionaries-LLMs name, licence, and application.11,051 sentences were extracted through dictionary lookup, and the dataset was constructed through manual review of the final selection of 129 sentences with a link between the name and the licence, and 106 sentences with a link between the model name and the application.</p>
<p>F1 Score is a measure of predictive performance used in this work to evaluate the results of the relation extraction and it is the reconciled mean of Precision and Recall, defined by the formula:
F 1 Score = 2 × P recision × Recall P recision + Recall (1)
Among them: Precision indicates how many of the samples predicted to be in the positive category are truly positive.The formula is:
P recision = T P T P + F P(2)
TP: True Positives, samples that the model correctly predicts as positive.FP: False Positives, samples that the model incorrectly predicts as positive.Recall indicates how many of the samples that are true positives are correctly predicted as positives.The formula is:
Recall = T P T P + F N(3)
In order to cope with document contents of different formats and complexity, a multi-source data extraction strategy is employed.First, we extract text content directly from PDF files using an efficient text parsing tool, which is particularly good at handling documents containing complex structures, such as footnotes and figure illustrations.If the parsing process encounters difficulties or the page cannot be parsed, the system will automatically switch to an alternate text extraction tool.This multi-level extraction method ensures the completeness and accuracy of the document data and lays a solid foundation for subsequent analyses.</p>
<p>After the text extraction was completed, an automated keyword search tool was developed to accurately identify LLM names, licence types and model application scenarios mentioned in the literature.The core functions of the tool include keyword matching and contextual analysis.Firstly, the tool scans the extracted text with a predefined list of keywords (e.g.specific LLM names, licence types, etc.) and marks all matching keywords.Next, by analysing the dependencies and grammatical structure of the sentences in which the keywords are located, the tool is able to automatically extract contextual information related to the keywords, which includes the content of several sentences before and after, ensuring that the actual application scenarios of the keywords are captured, rather than just a single term match.Through this approach, the system is able to identify sentences containing key information in the literature and correlate these sentences with their contexts, providing reliable basic data for subsequent data screening, relationship extraction and structured data construction.This process significantly improves the accuracy and comprehensiveness of information extraction.</p>
<p>When the automated keyword recognition was completed, the extracted sentences were manually screened.Although the automated tool performed well in the initial screening, manual intervention helped to further improve the accuracy and relevance of the data.The manual review enabled the identification and correction of misclassifications or false matches that may have occurred during the automation process.This step lays the foundation for structuring and standardising the data and directly affects the accuracy of the subsequent entity identification annotation.</p>
<p>After multi-source data extraction, keyword recognition, context capture, manual screening, NER annotation, and dependency parsing, the following two datasets are successfully constructed, shown in Table 1 and 2 with examples: Application dataset of big language models: this dataset contains the performance of multiple big language models in different application scenarios, and combines with dependency parsing techniques to reveal the application of each model.Licensing dataset of big language models: this dataset records the types of licences adopted by each model and its legal framework.It clarifies the correspondence between models and licences by parsing the associated sentences.</p>
<p>Rule Formulation</p>
<p>This work performed dependency parsing on sentences using the spaCy library to extract relationships between model names and application scenarios or licences.Dependency parsing reveals the syntactic relationships between words in a sentence, allowing us to extract explicit relational triples (e.g.subject-predicate-object) from complex syntactic structures.By developing a set of rules for dealing with active and passive voice, we can systematically extract relevant relations from sentences with different syntactic structures and transform them into structured data.The generated relation triples provide the core data for subsequent visualisation and query functions.</p>
<p>Active voice processing</p>
<p>Identifying Subjects: for active voice sentences, the sentence's subject is usually the name of a large language model.Dependency parsing enables the identification of the entity that is the subject of the sentence and identifies it as the subject part of the relation.Identifying predicates: the system identifies the predicate verbs of the sentence, which typically describe the behaviour or application of the model.For example, the verb may indicate a release, application, or integration of the model.At this point, the system captures both auxiliary verbs and modifiers associated with the predicate verb to ensure the integrity of the predicate.Identifying objects or prepositional phrases: the system looks for direct ob-Table 2: Example of Relational extraction dataset for large language model and licence jects or prepositional phrases associated with the predicate verb.These components typically describe the application scenario or licence type of the model.By identifying these constituents, the system can associate a model name with its application or licence.As shown in Figure 7, in the sentence RoBERTa improves text classification by fine-tuning on large datasets, the system recognises RoBERTa as the subject, improves as the predicate verb, and text classification as the direct object, which further specifies the application of the model RoBERTa in text classification.In Figure 8, the root is effective, which is an adjective.ERNIE is the subject, is is the auxiliary verb, and in Named Entity Recognition (NER) is a prepositional phrase describing where ERNIE is effective.The phrase particularly in Chinese text further modifies the effectiveness of ERNIE.</p>
<p>Passive voice processing</p>
<p>Identifying passive subjects: For passive sentences, the system first detects passive auxiliary verbs (e.g., was) and identifies the passive subject, which is usually the name of the large language model.</p>
<p>Identifying predicates and prepositional phrases: In passive voice, predicate verbs are usually combined with prepositional phrases to describe the association of the model with a licence or application scenario.The system identifies these prepositional phrases and their objects through dependency parsing to construct a complete relationship.In Figure 9, the root is utilised, which is the main verb.XLNet is the subject, is is the auxiliary verb, and in Text Generation is a prepositional phrase indicating where XLNet is utilised.The phrase providing context-aware sentence completions acts as a participial phrase explaining what XLNet does when utilised.</p>
<p>In Figure 10, the root is released, which is the main verb.BERT is the subject, was is the auxiliary verb, and under the Apache licence 2.0 is a prepositional phrase indicating the condition under which BERT was released.</p>
<p>With these rules, we were able to systematically  extract clear relational triples (subject-predicateobject) from complex sentence structures that accurately reflect the associations between model names and their application scenarios or licences.</p>
<p>The development and implementation of these rules ensured that the system was able to extract relevant information flexibly and accurately when confronted with sentences with different syntactic structures.</p>
<p>Evaluation</p>
<p>In practice, this relationship extraction method based on dependency parsing demonstrated excellent performance in the dataset we constructed.In order to comprehensively evaluate the effectiveness of the method, we used several commonly used evaluation metrics, including Accuracy, Recall, Precision, and F1-Score.</p>
<p>Visualisation</p>
<p>Figure 11 illustrates the output visualisation of extracted relations where users can drag the extracted components.By developing and applying this series of automated data processing tools, we have successfully constructed a structured dataset containing LLM names, licence types, and application scenarios.This dataset not only provides a solid foundation for subsequent relationship extraction and knowledge graph construction but also demonstrates the power of modern automated text processing techniques in academic research.</p>
<p>From the evaluation results, the model performs well in all indicators, especially in identifying relationships in complex syntactic structures.This excellent performance not only verifies the effectiveness of the relationship extraction method based on dependency parsing but also highlights the broad applicability of the method in dealing with diverse literature data.</p>
<p>Following the completion of the extraction of  5 Conclusions and Future Work</p>
<p>Conclusions</p>
<p>As a pilot study, the main goal of this work is to validate the basic feasibility of the proposed method LLM-CARD, i.e., automatically extract LLMs in published literature and their model cards of model details and their affiliated information.We have successfully constructed two core datasets using dependency parsing and relation extraction techniques: one on the application scenarios of big language models, and the other on the types of licences used in these models.These datasets provide a solid foundation for further re-search.</p>
<p>In order to further validate the utility of the method, we also conducted real-world testing of the extracted relations and entities using locally deployed large language models.These big language models performed well in handling natural language tasks, especially in the absence of specialised training data, and were able to accurately identify and predict many complex linguistic relations by virtue of their powerful zero-shot learning capabilities.However, despite the model's good performance in initial tests, there is still room for improvement in its predictions.In order to improve the model's performance in various complex situations, further instruction training is essential (e.g.methods from Cui et al. ( 2023 (2024)).Especially when it comes to literature in specialised areas, the model needs targeted training to enhance its understanding of specific terms and complex grammatical structures, thus ensuring the accuracy and applicability of the prediction results.</p>
<p>Future work</p>
<p>Prospectively, an important direction for this research lies in utilising the experimental results of Figure 11: A visual summary of various large language models, applications, and licences.Blue represents the name of the model, green represents the relationship between the model name and the licence and application entities, and red represents the application and licence of the large language model.this work, i.e., fine-tuning the training of the new model with the relational and entity datasets extracted from this study.These datasets were accurately labelled and processed to provide ideal training material for further optimisation of the model.Future research can design more complex and targeted training tasks to enable the big language model to better grasp domain-specific linguistic features and enhance its performance in real-world applications.In addition, as the amount of data increases, we can explore the use of these relational and entity data to construct more complex knowledge graphs to further enhance the model's reasoning and knowledge management capabilities.Such efforts not only help to enhance the understanding and generative capabilities of the models, but also provide possibilities for a wider range of application scenarios in the future.</p>
<p>Limitations</p>
<p>As proof of concept investigation, the scope of validation in this study is limited, focussing on a small number of literature and specific tasks, and has not yet been fully tested on larger datasets.Although the preliminary results show the effectiveness of the method LLM-CARD, future research needs to expand the size of the validation dataset and apply more stringent evaluation criteria to comprehensively examine the robustness and applicability of the method.</p>
<p>Ethical Statement</p>
<p>We applied the designed algorithms and methods to publically available literature / scientific articles.It does not release/involve any personal data.</p>
<p>Figure 1 :
1
Figure 1: LLM-CARD method demonstration</p>
<p>Figure 2 :
2
Figure 2: The steps for named entities recognition</p>
<p>Figure 4 :
4
Figure 4: Deep learning-based methods</p>
<p>Figure 5 :
5
Figure 5: The pipeline of our LLM-CARD method</p>
<p>Figure 7 :
7
Figure 7: Dependency tree for the active voice processing sentence: RoBERTa improves text classification by fine-tuning on large datasets.</p>
<p>Figure 8 :
8
Figure 8: Dependency tree for the active voice processing sentence: ERNIE is effective in Named Entity Recognition (NER), particularly in Chinese text.</p>
<p>Figure 9 :
9
Figure 9: Dependency tree for the passive voice processing sentence XLNet is utilised in Text Generation, providing context-aware sentence completions.</p>
<p>Figure 10 :
10
Figure 10: Dependency tree for the passive voice processing sentence: BERT was released under the Apache licence 2.0.</p>
<p>); Ren et al. (2024); Micheletti et al. (2024); Belkadi et al.</p>
<p>Table 3 :
3
Evaluation metrics for the test dataset
These metrics arecrucial in measuring the overall performance of arelational extraction model, and can comprehen-sively reflect the performance of the model in dif-ferent dimensions, thus providing a scientific ba-sis for model optimisation and improvement. Theevaluation results on the test dataset are as shownin Table 3. The evaluation results indicate that themethod has a high degree of accuracy and con-sistency in identifying and extracting relationshipsrelated to LLMs, and especially excels in dealingwith complex syntactic structures.
AcknowledgementsLH and GN are grateful to grant support EP/V047949/1 "Integrating hospital outpatient letters into the healthcare data space" (funder: UKRI/EPSRC).Author ContributionsST: experimental work and draft first manuscript, LH: co-supervision and revising the manuscript, EMG: co-supervision, GN: PI and co-supervision.
Polydoc: Surveying pdf files from the polyswarm network. Prashant Anantharaman, Robert Lathrop, Rebecca Shapiro, Michael E Locasto, 2023 IEEE Security and Privacy Workshops (SPW). IEEE2023</p>
<p>Generating synthetic free-text medical records with low reidentification risk using masked language modeling. Samuel Belkadi, Libo Ren, Nicolo Micheletti, Lifeng Han, Goran Nenadic, 2024</p>
<p>Language models are few-shot learners. Tom B Brown, arXiv:2005.141652020arXiv preprint</p>
<p>MedTem2.0: Prompt-based temporal classification of treatment events from discharge summaries. Yang Cui, Lifeng Han, Goran Nenadic, Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics. the 61st Annual Meeting of the Association for Computational LinguisticsToronto, CanadaAssociation for Computational Linguistics20234Student Research Workshop)</p>
<p>BERT: Pre-training of deep bidirectional transformers for language understanding. Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, 10.18653/v1/N19-1423Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. Long and Short Papers. the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesMinneapolis, MinnesotaAssociation for Computational Linguistics2019a1</p>
<p>Bert: Pre-training of deep bidirectional transformers for language understanding. Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, 2019b</p>
<p>A survey on large language models: Applications, challenges, limitations, and practical usage. Rizwan Muhammad Usman Hadi, Abbas Qureshi, Muhammad Shah, Anas Irfan, Muhammad Zafar, Naveed Bilal Shaikh, Jia Akhtar, Seyedali Wu, Mirjalili, 2023Authorea Preprints</p>
<p>Speech and language processing. Daniel Jurafsky, 2000</p>
<p>Yinhan Liu, arXiv:1907.11692Roberta: A robustly optimized bert pretraining approach. 2019arXiv preprint</p>
<p>Exploration of masked and causal language modelling for text generation. Nicolo Micheletti, Samuel Belkadi, Lifeng Han, Goran Nenadic, 2024</p>
<p>Tomas Mikolov, arXiv:1301.3781Efficient estimation of word representations in vector space. 2013arXiv preprint</p>
<p>Distant supervision for relation extraction without labeled data. Mike Mintz, Steven Bills, Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP. the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP2009Rion Snow, and Dan Jurafsky</p>
<p>Exploring the limits of transfer learning with a unified text-to-text transformer. Colin Openai, Noam Raffel, Adam Shazeer, Katherine Roberts, Sharan Lee, Michael Narang, Yanqi Matena, Wei Zhou, Peter J Li, Liu, arxiv 2303.08774Gpt-4 technical report. 2023. 20202View in Article</p>
<p>Synthetic4health: Generating annotated synthetic clinical letters. Libo Ren, Samuel Belkadi, Lifeng Han, Warren Del-Pinto, Goran Nenadic, 2024</p>
<p>Do syntax trees help pretrained transformers extract information?. Devendra Singh Sachan, Yuhao Zhang, Peng Qi, William Hamilton, arXiv:2008.090842020arXiv preprint</p>
<p>Information extraction. Sunita Sarawagi, Foundations and Trends® in Databases. 132008</p>
<p>Named entity recognition: A literature survey. Rahul Sharnagat, Center For Indian Language Technology. 2014</p>
<p>Improving relation extraction through syntax-induced pretraining with dependency masking. Yuanhe Tian, Yan Song, Fei Xia, Findings of the Association for Computational Linguistics: ACL 2022. 2022</p>
<p>Amirsina Torfi, A Rouzbeh, Yaser Shirvani, Nader Keneshloo, Edward A Tavaf, Fox, arXiv:2003.01200Natural language processing advancements by deep learning: A survey. 2020arXiv preprint</p>
<p>Computing machinery and intelligence. Alan M Turing, 2009Springer</p>
<p>Attention is all you need. Vaswani, Advances in Neural Information Processing Systems. 2017</p>
<p>Recent trends in deep learning based natural language processing. Tom Young, Devamanyu Hazarika, Soujanya Poria, Erik Cambria, 10.1109/MCI.2018.2840738IEEE Computational Intelligence Magazine. 1332018review article</p>
<p>Distant supervision for relation extraction with linear attenuation simulation and non-iid relevance embedding. Changsen Yuan, Heyan Huang, Chong Feng, Xiao Liu, Xiaochi Wei, 10.1609/aaai.v33i01.33017418Proceedings of the Thirty-Third AAAI Conference on Artificial Intelligence and Thirty-First Innovative Applications of Artificial Intelligence Conference and Ninth AAAI Symposium on Educational Advances in Artificial Intelligence. the Thirty-Third AAAI Conference on Artificial Intelligence and Thirty-First Innovative Applications of Artificial Intelligence Conference and Ninth AAAI Symposium on Educational Advances in Artificial IntelligenceAAAI Press2019AAAI'19/IAAI'19/EAAI'19</p>
<p>Relation classification via convolutional deep neural network. Daojian Zeng, Kang Liu, Siwei Lai, Guangyou Zhou, Jun Zhao, Proceedings of COLING 2014, the 25th international conference on computational linguistics: technical papers. COLING 2014, the 25th international conference on computational linguistics: technical papers2014</p>
<p>Rule-based extraction of spatial relations in natural language text. Chunju Zhang, Xueying Zhang, Wenming Jiang, Qijun Shen, Shanqi Zhang, 2009 international conference on computational intelligence and software engineering. IEEE2009</p>
<p>Relation classification via recurrent neural network. Dongxu Zhang, Dong Wang, 2015</p>            </div>
        </div>

    </div>
</body>
</html>