<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-4346 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-4346</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-4346</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-99.html">extraction-schema-99</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, systems, or approaches that use LLMs (or other AI models) to extract, distill, or discover quantitative laws, patterns, relationships, or principles from scientific papers or scholarly literature.</div>
                <p><strong>Paper ID:</strong> paper-279402741</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2506.12385v1.pdf" target="_blank">Recent Advances and Future Directions in Literature-Based Discovery</a></p>
                <p><strong>Paper Abstract:</strong> The explosive growth of scientific publications has created an urgent need for automated methods that facilitate knowledge synthesis and hypothesis generation. Literature-based discovery (LBD) addresses this challenge by uncovering previously unknown associations between disparate domains. This article surveys recent methodological advances in LBD, focusing on developments from 2000 to the present. We review progress in three key areas: knowledge graph construction, deep learning approaches, and the integration of pre-trained and large language models (LLMs). While LBD has made notable progress, several fundamental challenges remain unresolved, particularly concerning scalability, reliance on structured data, and the need for extensive manual curation. By examining ongoing advances and outlining promising future directions, this survey underscores the transformative role of LLMs in enhancing LBD and aims to support researchers and practitioners in harnessing these technologies to accelerate scientific innovation.</p>
                <p><strong>Cost:</strong> 0.016</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e4346.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e4346.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, systems, or approaches that use LLMs (or other AI models) to extract, distill, or discover quantitative laws, patterns, relationships, or principles from scientific papers or scholarly literature.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>KGC (BERT + KGC pipeline)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Knowledge Graph Completion via PLM-based Triple Extraction and Link Prediction</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A pipeline that uses a pre-trained language model to extract semantic triples from scientific text to build a knowledge graph, followed by knowledge-graph-completion (link-prediction) algorithms to predict missing edges (e.g., drug-disease relationships) for literature-based discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Drug repurposing for COVID-19 via knowledge graph completion.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>BERT-based semantic triple extraction + Knowledge Graph Completion</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Pipeline: (1) apply a pre-trained language model (described as BERT in the survey) as a preprocessing step to perform entity recognition and semantic triple/predication extraction from articles (produce subject-relation-object triples); (2) assemble extracted triples into a knowledge graph (nodes = concepts, edges = relations); (3) apply knowledge graph completion/link-prediction algorithms (embedding-based or other KGC methods) to predict missing links (e.g., candidate drug -- treats --> disease). The approach treats LBD as a KGC task and uses the PLM to convert unstructured text into structured graph facts that KGC models can consume.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td>BERT (pre-trained language model used for semantic triple extraction) as reported in the survey; the downstream KGC algorithm is unspecified in this paper summary.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Biomedical (drug repurposing / COVID-19)</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>type_of_quantitative_law</strong></td>
                            <td>Predictive relationships/link predictions (drug–disease treatment relationships, semantic predications) rather than explicit mathematical laws</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_output_format</strong></td>
                            <td>Structured semantic triples (subject-relation-object) and predicted graph edges</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td>KGC predictive evaluation on constructed KG (paper reference indicates KGC algorithms applied; exact validation protocol not provided in survey text)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Depends on quality of PLM-based triple extraction and upstream vocabularies; errors in entity normalization and relation extraction propagate to KGC; limitations due to reliance on structured vocabularies and curated knowledge resources.</td>
                        </tr>
                        <tr>
                            <td><strong>requires_human_in_loop</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fully_automated</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Recent Advances and Future Directions in Literature-Based Discovery', 'publication_date_yy_mm': '2025-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4346.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e4346.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, systems, or approaches that use LLMs (or other AI models) to extract, distill, or discover quantitative laws, patterns, relationships, or principles from scientific papers or scholarly literature.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Crichton NN LBD</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Neural Network approaches for open and closed literature-based discovery (Crichton et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Deep learning architectures (MLP/CNN) that take node embeddings of concepts and score A–B and B–C links or entire A–B–C paths to perform closed and open LBD tasks, achieving state-of-the-art performance on benchmark biomedical datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Neural networks for open and closed literature-based discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Embedding-based neural LBD (LINE embeddings + MLP/CNN scoring)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Method: (1) create node embeddings for concepts using LINE (large-scale information network embedding); (2) combine embeddings along discovery paths (A, B, C) using strategies such as aggregation or concatenation to form model inputs; (3) use an MLP to score individual A–B and B–C links and aggregate them to evaluate an A–B–C hypothesis, or combine A,B,C embeddings into a single input for direct path scoring; for open discovery, stack multiple A–B–C path embeddings into a pseudo-image and use a CNN to score A–C candidate pairs across multiple paths. The architecture supports both scoring of candidate triples and end-to-end path evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td>No large language model; uses graph embedding algorithm (LINE) and neural network architectures (MLP, CNN).</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Biomedical literature-based discovery (benchmarked on PubTator and BioGRID datasets)</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>type_of_quantitative_law</strong></td>
                            <td>Inference of semantic/associative relationships (implicit concept link predictions) rather than explicit mathematical laws</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_output_format</strong></td>
                            <td>Scored hypothesis paths and ranked A–C candidate lists (structured embeddings and scores)</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td>Evaluation on PubTator and BioGRID benchmark datasets (closed and open discovery tasks)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Reported as 'state-of-the-art' performance on PubTator and BioGRID in the cited work; no numeric metrics provided in the survey text</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared favorably to prior LBD baselines (details/numeric comparisons not provided in the survey)</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Requires manual construction/enumeration of all possible hypothesis triples prior to evaluation (time-consuming and dependent on domain expertise); interpretability concerns.</td>
                        </tr>
                        <tr>
                            <td><strong>requires_human_in_loop</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>fully_automated</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Recent Advances and Future Directions in Literature-Based Discovery', 'publication_date_yy_mm': '2025-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4346.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e4346.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, systems, or approaches that use LLMs (or other AI models) to extract, distill, or discover quantitative laws, patterns, relationships, or principles from scientific papers or scholarly literature.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Cuffy 2023 closed discovery</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Closed literature-based discovery framework automating ranking of linking terms (Cuffy et al., 2023)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A deep-learning closed-discovery system that ranks candidate bridging concepts B for a given A and C pair by performing a single forward pass through the model, removing the need to pre-generate all A–B–C triples.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Exploring a deep learning neural architecture for closed literature-based discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Single-forward-pass DL ranking for closed discovery</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Method: a neural model is trained to score or rank candidate linking concepts B given a fixed A and C, enabling retrieval of plausible intermediates using a single forward propagation rather than enumerating all possible A–B–C combinations. This reduces precomputation and domain-knowledge dependency in closed discovery workflows.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td>No LLM; a deep neural model (architecture details provided in the cited paper) trained on embedding representations.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Biomedical LBD (general LBD task framing)</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>type_of_quantitative_law</strong></td>
                            <td>Discovery of implicit concept linking relationships (bridging concepts) rather than explicit numerical laws</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_output_format</strong></td>
                            <td>Ranked lists of candidate bridging concepts (concept identifiers and scores)</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td>Task-based evaluation on closed discovery benchmarks (specifics not provided in the survey text)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Described as improving workflow efficiency relative to prior approaches that enumerate triples; no numeric comparisons provided in the survey</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Survey notes prior manual enumeration issues addressed, but overall DL interpretability and domain-generalizability remain concerns</td>
                        </tr>
                        <tr>
                            <td><strong>requires_human_in_loop</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fully_automated</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Recent Advances and Future Directions in Literature-Based Discovery', 'publication_date_yy_mm': '2025-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4346.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e4346.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, systems, or approaches that use LLMs (or other AI models) to extract, distill, or discover quantitative laws, patterns, relationships, or principles from scientific papers or scholarly literature.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Cuffy 2025 embedding prediction</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Predicting implicit concept embeddings for linking-concept discovery (Cuffy & McInnes, 2025)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A model that, given A and C concept embeddings, predicts the embedding of a plausible linking concept B, enabling retrieval of candidate intermediates by nearest-neighbor search in embedding space.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Predicting implicit concept embeddings for singular relationship discovery replication of closed literature-based discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Implicit concept-embedding prediction</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Approach: the model is trained to predict the vector embedding of the bridging concept B from embeddings of A and C. At inference, the predicted B-embedding is compared to stored embeddings of candidate concepts to identify plausible intermediates, converting the discovery task into an embedding regression + retrieval problem.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td>No LLM; uses embedding-based MLP predictive modelling (embedding learning and prediction).</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Bibliomedical LBD (closed discovery replication tasks)</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>type_of_quantitative_law</strong></td>
                            <td>Implicit associative relationships between concepts (concept embeddings representing semantic relationships) rather than explicit quantitative laws</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_output_format</strong></td>
                            <td>Predicted concept embeddings and retrieved candidate concept identifiers (with similarity scores)</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td>Replication experiments and retrieval-based evaluation as described in the cited work (specifics not given in survey)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Shown to be effective for systematic knowledge discovery replication; no numeric comparisons provided in the survey</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Depends on quality and representativeness of embedding space; potential for retrieval errors and semantic drift</td>
                        </tr>
                        <tr>
                            <td><strong>requires_human_in_loop</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fully_automated</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Recent Advances and Future Directions in Literature-Based Discovery', 'publication_date_yy_mm': '2025-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4346.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e4346.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, systems, or approaches that use LLMs (or other AI models) to extract, distill, or discover quantitative laws, patterns, relationships, or principles from scientific papers or scholarly literature.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SciMON</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Scientific Inspiration Machines Optimized for Novelty (SciMON)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An LBD-style framework that grounds hypothesis generation in natural language contexts and iteratively refines generated idea suggestions to optimize novelty, producing full-sentence hypotheses rather than isolated concept links.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>SciMON: Scientific inspiration machines optimized for novelty</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>SciMON (LM-grounded iterative novelty optimization)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>SciMON uses language-model-grounded generation to produce candidate research-idea sentences, then iteratively refines and optimizes those ideas with respect to novelty and conceptual depth until the generated hypotheses meet novelty criteria. Unlike ABC-style methods, SciMON operates in natural language space and constrains the generative hypothesis space with richer contextual signals.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td>Described as an LM-based system; the survey reports that SciMON's outputs were compared against GPT-4 and that SciMON produced ideas judged more original and conceptually deeper than GPT-4, but the precise LM architecture used by SciMON is unspecified in the survey text.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>General scientific literature (cross-domain LBD)</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>type_of_quantitative_law</strong></td>
                            <td>Generative scientific hypotheses and conceptual relationships (not explicitly numerical laws)</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_output_format</strong></td>
                            <td>Natural-language hypotheses (complete sentences) and idea descriptions</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td>Comparative evaluation against GPT-4 (authors report higher originality and conceptual depth); likely human judgment-based evaluation though not fully specified in the survey</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared qualitatively/empirically to GPT-4 (SciMON reported to produce more original and deeper ideas); no numeric metrics provided in the survey</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Emerging method; scalability, validation of novelty, and reproducibility challenges; unspecified evaluation metrics and reliance on language-model quality</td>
                        </tr>
                        <tr>
                            <td><strong>requires_human_in_loop</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fully_automated</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Recent Advances and Future Directions in Literature-Based Discovery', 'publication_date_yy_mm': '2025-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4346.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e4346.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, systems, or approaches that use LLMs (or other AI models) to extract, distill, or discover quantitative laws, patterns, relationships, or principles from scientific papers or scholarly literature.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BioGPT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>BioGPT (Generative pre-trained transformer for biomedical text generation and mining)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A domain-specific large generative transformer trained on biomedical corpora (PubMed, etc.) used for retrieval, summarization, question answering, and domain-targeted text generation to facilitate literature mining and hypothesis discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>BioGPT: Generative pre-trained transformer for biomedical text generation and mining.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>BioGPT for literature retrieval and synthesis</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>BioGPT is a pre-trained generative transformer model trained on biomedical text; in the context of LBD it is used for tasks such as literature retrieval, document summarization, question answering, and extracting/condensing domain-specific insights from corpora to support hypothesis generation. The survey mentions BioGPT as an example of an LLM trained on domain-specific corpora that is particularly effective at literature retrieval and summarization.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td>BioGPT (domain-specific LLM trained on biomedical corpora); specific size/params not provided in the survey</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Biomedical literature</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>type_of_quantitative_law</strong></td>
                            <td>Extraction of domain relationships, factual statements, and summarized insights (not explicit mathematical laws as discussed in the survey)</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_output_format</strong></td>
                            <td>Summaries, retrieved passages, question-answer outputs, and generated text snippets</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td>Not detailed in the survey; used for retrieval/summarization tasks evaluated in original BioGPT work (not reproduced in this survey)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Domain-specific pretraining helps, but survey notes general LBD challenges remain (scalability, validation, reliance on structured resources); specific failure modes not detailed here.</td>
                        </tr>
                        <tr>
                            <td><strong>requires_human_in_loop</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fully_automated</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Recent Advances and Future Directions in Literature-Based Discovery', 'publication_date_yy_mm': '2025-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4346.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e4346.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, systems, or approaches that use LLMs (or other AI models) to extract, distill, or discover quantitative laws, patterns, relationships, or principles from scientific papers or scholarly literature.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SciGLM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>SciGLM (Scientific Language Model trained with self-reflective instruction annotation and tuning)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A scientific language model trained with specialized instruction tuning to improve performance on scientific retrieval, reasoning, and synthesis tasks, supporting literature mining and hypothesis generation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>SciGLM: Training scientific language models with self-reflective instruction annotation and tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>SciGLM for scientific retrieval and reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>SciGLM is a domain-tuned LLM trained on scientific corpora with self-reflective instruction annotation and tuning intended to improve scientific reasoning and downstream tasks such as literature retrieval, summarization, and question answering to support discovery workflows. The survey cites SciGLM as an example of a state-of-the-art domain model for scientific text.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td>SciGLM (model details in cited work; size unspecified in the survey)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>General scientific / cross-domain corpora (e.g., PubMed, arXiv)</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>type_of_quantitative_law</strong></td>
                            <td>Extraction/synthesis of scientific statements and potential relationships; not specifically described as producing symbolic quantitative laws in the survey</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_output_format</strong></td>
                            <td>Retrieved text, summaries, and generated natural-language explanations/answers</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td>Not specified in the survey summary</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Survey notes validation and scalability challenges for LLM-based scientific discovery; specifics for SciGLM not provided in the survey</td>
                        </tr>
                        <tr>
                            <td><strong>requires_human_in_loop</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fully_automated</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Recent Advances and Future Directions in Literature-Based Discovery', 'publication_date_yy_mm': '2025-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4346.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e4346.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, systems, or approaches that use LLMs (or other AI models) to extract, distill, or discover quantitative laws, patterns, relationships, or principles from scientific papers or scholarly literature.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Yang et al. 2024 LLM-hypothesis</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Large language models for automated open-domain scientific hypotheses discovery</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A body of work that explores the use of LLMs (general-purpose and domain-specific) for automated open-domain hypothesis discovery from scholarly literature.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Large language models for automated open-domain scientific hypotheses discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>LLM-driven automated open-domain hypothesis discovery</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Described in the cited ACL findings work: LLMs are applied to open-domain literature to generate candidate hypotheses automatically (retrieval + generation + ranking pipelines). The survey references this work as representative of attempts to use LLMs for open-domain automated hypothesis generation from literature, though implementation details are not provided in the survey summary.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td>LLMs in general (paper title implies the use of large language models; specific model instances not enumerated in the survey summary)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Open-domain scientific literature (cross-disciplinary)</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>type_of_quantitative_law</strong></td>
                            <td>Generated scientific hypotheses and conceptual relationships (open-domain); not explicitly stated to extract symbolic quantitative laws</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_output_format</strong></td>
                            <td>Generated natural-language hypotheses (and possibly candidate evidence passages)</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td>Not detailed in the survey text; likely includes qualitative and human evaluation as typical in such work</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Emerging field; issues with validation, reproducibility, and controlling generative space; survey notes that LLM-based LBD is still developing</td>
                        </tr>
                        <tr>
                            <td><strong>requires_human_in_loop</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fully_automated</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Recent Advances and Future Directions in Literature-Based Discovery', 'publication_date_yy_mm': '2025-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Neural networks for open and closed literature-based discovery. <em>(Rating: 2)</em></li>
                <li>Exploring a deep learning neural architecture for closed literature-based discovery. <em>(Rating: 2)</em></li>
                <li>Predicting implicit concept embeddings for singular relationship discovery replication of closed literature-based discovery. <em>(Rating: 2)</em></li>
                <li>Drug repurposing for COVID-19 via knowledge graph completion. <em>(Rating: 2)</em></li>
                <li>SciMON: Scientific inspiration machines optimized for novelty <em>(Rating: 2)</em></li>
                <li>BioGPT: Generative pre-trained transformer for biomedical text generation and mining. <em>(Rating: 2)</em></li>
                <li>SciGLM: Training scientific language models with self-reflective instruction annotation and tuning. <em>(Rating: 2)</em></li>
                <li>Large language models for automated open-domain scientific hypotheses discovery. <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-4346",
    "paper_id": "paper-279402741",
    "extraction_schema_id": "extraction-schema-99",
    "extracted_data": [
        {
            "name_short": "KGC (BERT + KGC pipeline)",
            "name_full": "Knowledge Graph Completion via PLM-based Triple Extraction and Link Prediction",
            "brief_description": "A pipeline that uses a pre-trained language model to extract semantic triples from scientific text to build a knowledge graph, followed by knowledge-graph-completion (link-prediction) algorithms to predict missing edges (e.g., drug-disease relationships) for literature-based discovery.",
            "citation_title": "Drug repurposing for COVID-19 via knowledge graph completion.",
            "mention_or_use": "use",
            "method_name": "BERT-based semantic triple extraction + Knowledge Graph Completion",
            "method_description": "Pipeline: (1) apply a pre-trained language model (described as BERT in the survey) as a preprocessing step to perform entity recognition and semantic triple/predication extraction from articles (produce subject-relation-object triples); (2) assemble extracted triples into a knowledge graph (nodes = concepts, edges = relations); (3) apply knowledge graph completion/link-prediction algorithms (embedding-based or other KGC methods) to predict missing links (e.g., candidate drug -- treats --&gt; disease). The approach treats LBD as a KGC task and uses the PLM to convert unstructured text into structured graph facts that KGC models can consume.",
            "llm_model_used": "BERT (pre-trained language model used for semantic triple extraction) as reported in the survey; the downstream KGC algorithm is unspecified in this paper summary.",
            "scientific_domain": "Biomedical (drug repurposing / COVID-19)",
            "number_of_papers": null,
            "type_of_quantitative_law": "Predictive relationships/link predictions (drug–disease treatment relationships, semantic predications) rather than explicit mathematical laws",
            "extraction_output_format": "Structured semantic triples (subject-relation-object) and predicted graph edges",
            "validation_method": "KGC predictive evaluation on constructed KG (paper reference indicates KGC algorithms applied; exact validation protocol not provided in survey text)",
            "performance_metrics": null,
            "baseline_comparison": null,
            "challenges_limitations": "Depends on quality of PLM-based triple extraction and upstream vocabularies; errors in entity normalization and relation extraction propagate to KGC; limitations due to reliance on structured vocabularies and curated knowledge resources.",
            "requires_human_in_loop": null,
            "fully_automated": null,
            "uuid": "e4346.0",
            "source_info": {
                "paper_title": "Recent Advances and Future Directions in Literature-Based Discovery",
                "publication_date_yy_mm": "2025-06"
            }
        },
        {
            "name_short": "Crichton NN LBD",
            "name_full": "Neural Network approaches for open and closed literature-based discovery (Crichton et al.)",
            "brief_description": "Deep learning architectures (MLP/CNN) that take node embeddings of concepts and score A–B and B–C links or entire A–B–C paths to perform closed and open LBD tasks, achieving state-of-the-art performance on benchmark biomedical datasets.",
            "citation_title": "Neural networks for open and closed literature-based discovery.",
            "mention_or_use": "mention",
            "method_name": "Embedding-based neural LBD (LINE embeddings + MLP/CNN scoring)",
            "method_description": "Method: (1) create node embeddings for concepts using LINE (large-scale information network embedding); (2) combine embeddings along discovery paths (A, B, C) using strategies such as aggregation or concatenation to form model inputs; (3) use an MLP to score individual A–B and B–C links and aggregate them to evaluate an A–B–C hypothesis, or combine A,B,C embeddings into a single input for direct path scoring; for open discovery, stack multiple A–B–C path embeddings into a pseudo-image and use a CNN to score A–C candidate pairs across multiple paths. The architecture supports both scoring of candidate triples and end-to-end path evaluation.",
            "llm_model_used": "No large language model; uses graph embedding algorithm (LINE) and neural network architectures (MLP, CNN).",
            "scientific_domain": "Biomedical literature-based discovery (benchmarked on PubTator and BioGRID datasets)",
            "number_of_papers": null,
            "type_of_quantitative_law": "Inference of semantic/associative relationships (implicit concept link predictions) rather than explicit mathematical laws",
            "extraction_output_format": "Scored hypothesis paths and ranked A–C candidate lists (structured embeddings and scores)",
            "validation_method": "Evaluation on PubTator and BioGRID benchmark datasets (closed and open discovery tasks)",
            "performance_metrics": "Reported as 'state-of-the-art' performance on PubTator and BioGRID in the cited work; no numeric metrics provided in the survey text",
            "baseline_comparison": "Compared favorably to prior LBD baselines (details/numeric comparisons not provided in the survey)",
            "challenges_limitations": "Requires manual construction/enumeration of all possible hypothesis triples prior to evaluation (time-consuming and dependent on domain expertise); interpretability concerns.",
            "requires_human_in_loop": true,
            "fully_automated": false,
            "uuid": "e4346.1",
            "source_info": {
                "paper_title": "Recent Advances and Future Directions in Literature-Based Discovery",
                "publication_date_yy_mm": "2025-06"
            }
        },
        {
            "name_short": "Cuffy 2023 closed discovery",
            "name_full": "Closed literature-based discovery framework automating ranking of linking terms (Cuffy et al., 2023)",
            "brief_description": "A deep-learning closed-discovery system that ranks candidate bridging concepts B for a given A and C pair by performing a single forward pass through the model, removing the need to pre-generate all A–B–C triples.",
            "citation_title": "Exploring a deep learning neural architecture for closed literature-based discovery.",
            "mention_or_use": "mention",
            "method_name": "Single-forward-pass DL ranking for closed discovery",
            "method_description": "Method: a neural model is trained to score or rank candidate linking concepts B given a fixed A and C, enabling retrieval of plausible intermediates using a single forward propagation rather than enumerating all possible A–B–C combinations. This reduces precomputation and domain-knowledge dependency in closed discovery workflows.",
            "llm_model_used": "No LLM; a deep neural model (architecture details provided in the cited paper) trained on embedding representations.",
            "scientific_domain": "Biomedical LBD (general LBD task framing)",
            "number_of_papers": null,
            "type_of_quantitative_law": "Discovery of implicit concept linking relationships (bridging concepts) rather than explicit numerical laws",
            "extraction_output_format": "Ranked lists of candidate bridging concepts (concept identifiers and scores)",
            "validation_method": "Task-based evaluation on closed discovery benchmarks (specifics not provided in the survey text)",
            "performance_metrics": null,
            "baseline_comparison": "Described as improving workflow efficiency relative to prior approaches that enumerate triples; no numeric comparisons provided in the survey",
            "challenges_limitations": "Survey notes prior manual enumeration issues addressed, but overall DL interpretability and domain-generalizability remain concerns",
            "requires_human_in_loop": null,
            "fully_automated": null,
            "uuid": "e4346.2",
            "source_info": {
                "paper_title": "Recent Advances and Future Directions in Literature-Based Discovery",
                "publication_date_yy_mm": "2025-06"
            }
        },
        {
            "name_short": "Cuffy 2025 embedding prediction",
            "name_full": "Predicting implicit concept embeddings for linking-concept discovery (Cuffy & McInnes, 2025)",
            "brief_description": "A model that, given A and C concept embeddings, predicts the embedding of a plausible linking concept B, enabling retrieval of candidate intermediates by nearest-neighbor search in embedding space.",
            "citation_title": "Predicting implicit concept embeddings for singular relationship discovery replication of closed literature-based discovery.",
            "mention_or_use": "mention",
            "method_name": "Implicit concept-embedding prediction",
            "method_description": "Approach: the model is trained to predict the vector embedding of the bridging concept B from embeddings of A and C. At inference, the predicted B-embedding is compared to stored embeddings of candidate concepts to identify plausible intermediates, converting the discovery task into an embedding regression + retrieval problem.",
            "llm_model_used": "No LLM; uses embedding-based MLP predictive modelling (embedding learning and prediction).",
            "scientific_domain": "Bibliomedical LBD (closed discovery replication tasks)",
            "number_of_papers": null,
            "type_of_quantitative_law": "Implicit associative relationships between concepts (concept embeddings representing semantic relationships) rather than explicit quantitative laws",
            "extraction_output_format": "Predicted concept embeddings and retrieved candidate concept identifiers (with similarity scores)",
            "validation_method": "Replication experiments and retrieval-based evaluation as described in the cited work (specifics not given in survey)",
            "performance_metrics": null,
            "baseline_comparison": "Shown to be effective for systematic knowledge discovery replication; no numeric comparisons provided in the survey",
            "challenges_limitations": "Depends on quality and representativeness of embedding space; potential for retrieval errors and semantic drift",
            "requires_human_in_loop": null,
            "fully_automated": null,
            "uuid": "e4346.3",
            "source_info": {
                "paper_title": "Recent Advances and Future Directions in Literature-Based Discovery",
                "publication_date_yy_mm": "2025-06"
            }
        },
        {
            "name_short": "SciMON",
            "name_full": "Scientific Inspiration Machines Optimized for Novelty (SciMON)",
            "brief_description": "An LBD-style framework that grounds hypothesis generation in natural language contexts and iteratively refines generated idea suggestions to optimize novelty, producing full-sentence hypotheses rather than isolated concept links.",
            "citation_title": "SciMON: Scientific inspiration machines optimized for novelty",
            "mention_or_use": "mention",
            "method_name": "SciMON (LM-grounded iterative novelty optimization)",
            "method_description": "SciMON uses language-model-grounded generation to produce candidate research-idea sentences, then iteratively refines and optimizes those ideas with respect to novelty and conceptual depth until the generated hypotheses meet novelty criteria. Unlike ABC-style methods, SciMON operates in natural language space and constrains the generative hypothesis space with richer contextual signals.",
            "llm_model_used": "Described as an LM-based system; the survey reports that SciMON's outputs were compared against GPT-4 and that SciMON produced ideas judged more original and conceptually deeper than GPT-4, but the precise LM architecture used by SciMON is unspecified in the survey text.",
            "scientific_domain": "General scientific literature (cross-domain LBD)",
            "number_of_papers": null,
            "type_of_quantitative_law": "Generative scientific hypotheses and conceptual relationships (not explicitly numerical laws)",
            "extraction_output_format": "Natural-language hypotheses (complete sentences) and idea descriptions",
            "validation_method": "Comparative evaluation against GPT-4 (authors report higher originality and conceptual depth); likely human judgment-based evaluation though not fully specified in the survey",
            "performance_metrics": null,
            "baseline_comparison": "Compared qualitatively/empirically to GPT-4 (SciMON reported to produce more original and deeper ideas); no numeric metrics provided in the survey",
            "challenges_limitations": "Emerging method; scalability, validation of novelty, and reproducibility challenges; unspecified evaluation metrics and reliance on language-model quality",
            "requires_human_in_loop": null,
            "fully_automated": null,
            "uuid": "e4346.4",
            "source_info": {
                "paper_title": "Recent Advances and Future Directions in Literature-Based Discovery",
                "publication_date_yy_mm": "2025-06"
            }
        },
        {
            "name_short": "BioGPT",
            "name_full": "BioGPT (Generative pre-trained transformer for biomedical text generation and mining)",
            "brief_description": "A domain-specific large generative transformer trained on biomedical corpora (PubMed, etc.) used for retrieval, summarization, question answering, and domain-targeted text generation to facilitate literature mining and hypothesis discovery.",
            "citation_title": "BioGPT: Generative pre-trained transformer for biomedical text generation and mining.",
            "mention_or_use": "mention",
            "method_name": "BioGPT for literature retrieval and synthesis",
            "method_description": "BioGPT is a pre-trained generative transformer model trained on biomedical text; in the context of LBD it is used for tasks such as literature retrieval, document summarization, question answering, and extracting/condensing domain-specific insights from corpora to support hypothesis generation. The survey mentions BioGPT as an example of an LLM trained on domain-specific corpora that is particularly effective at literature retrieval and summarization.",
            "llm_model_used": "BioGPT (domain-specific LLM trained on biomedical corpora); specific size/params not provided in the survey",
            "scientific_domain": "Biomedical literature",
            "number_of_papers": null,
            "type_of_quantitative_law": "Extraction of domain relationships, factual statements, and summarized insights (not explicit mathematical laws as discussed in the survey)",
            "extraction_output_format": "Summaries, retrieved passages, question-answer outputs, and generated text snippets",
            "validation_method": "Not detailed in the survey; used for retrieval/summarization tasks evaluated in original BioGPT work (not reproduced in this survey)",
            "performance_metrics": null,
            "baseline_comparison": null,
            "challenges_limitations": "Domain-specific pretraining helps, but survey notes general LBD challenges remain (scalability, validation, reliance on structured resources); specific failure modes not detailed here.",
            "requires_human_in_loop": null,
            "fully_automated": null,
            "uuid": "e4346.5",
            "source_info": {
                "paper_title": "Recent Advances and Future Directions in Literature-Based Discovery",
                "publication_date_yy_mm": "2025-06"
            }
        },
        {
            "name_short": "SciGLM",
            "name_full": "SciGLM (Scientific Language Model trained with self-reflective instruction annotation and tuning)",
            "brief_description": "A scientific language model trained with specialized instruction tuning to improve performance on scientific retrieval, reasoning, and synthesis tasks, supporting literature mining and hypothesis generation.",
            "citation_title": "SciGLM: Training scientific language models with self-reflective instruction annotation and tuning.",
            "mention_or_use": "mention",
            "method_name": "SciGLM for scientific retrieval and reasoning",
            "method_description": "SciGLM is a domain-tuned LLM trained on scientific corpora with self-reflective instruction annotation and tuning intended to improve scientific reasoning and downstream tasks such as literature retrieval, summarization, and question answering to support discovery workflows. The survey cites SciGLM as an example of a state-of-the-art domain model for scientific text.",
            "llm_model_used": "SciGLM (model details in cited work; size unspecified in the survey)",
            "scientific_domain": "General scientific / cross-domain corpora (e.g., PubMed, arXiv)",
            "number_of_papers": null,
            "type_of_quantitative_law": "Extraction/synthesis of scientific statements and potential relationships; not specifically described as producing symbolic quantitative laws in the survey",
            "extraction_output_format": "Retrieved text, summaries, and generated natural-language explanations/answers",
            "validation_method": "Not specified in the survey summary",
            "performance_metrics": null,
            "baseline_comparison": null,
            "challenges_limitations": "Survey notes validation and scalability challenges for LLM-based scientific discovery; specifics for SciGLM not provided in the survey",
            "requires_human_in_loop": null,
            "fully_automated": null,
            "uuid": "e4346.6",
            "source_info": {
                "paper_title": "Recent Advances and Future Directions in Literature-Based Discovery",
                "publication_date_yy_mm": "2025-06"
            }
        },
        {
            "name_short": "Yang et al. 2024 LLM-hypothesis",
            "name_full": "Large language models for automated open-domain scientific hypotheses discovery",
            "brief_description": "A body of work that explores the use of LLMs (general-purpose and domain-specific) for automated open-domain hypothesis discovery from scholarly literature.",
            "citation_title": "Large language models for automated open-domain scientific hypotheses discovery.",
            "mention_or_use": "mention",
            "method_name": "LLM-driven automated open-domain hypothesis discovery",
            "method_description": "Described in the cited ACL findings work: LLMs are applied to open-domain literature to generate candidate hypotheses automatically (retrieval + generation + ranking pipelines). The survey references this work as representative of attempts to use LLMs for open-domain automated hypothesis generation from literature, though implementation details are not provided in the survey summary.",
            "llm_model_used": "LLMs in general (paper title implies the use of large language models; specific model instances not enumerated in the survey summary)",
            "scientific_domain": "Open-domain scientific literature (cross-disciplinary)",
            "number_of_papers": null,
            "type_of_quantitative_law": "Generated scientific hypotheses and conceptual relationships (open-domain); not explicitly stated to extract symbolic quantitative laws",
            "extraction_output_format": "Generated natural-language hypotheses (and possibly candidate evidence passages)",
            "validation_method": "Not detailed in the survey text; likely includes qualitative and human evaluation as typical in such work",
            "performance_metrics": null,
            "baseline_comparison": null,
            "challenges_limitations": "Emerging field; issues with validation, reproducibility, and controlling generative space; survey notes that LLM-based LBD is still developing",
            "requires_human_in_loop": null,
            "fully_automated": null,
            "uuid": "e4346.7",
            "source_info": {
                "paper_title": "Recent Advances and Future Directions in Literature-Based Discovery",
                "publication_date_yy_mm": "2025-06"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Neural networks for open and closed literature-based discovery.",
            "rating": 2,
            "sanitized_title": "neural_networks_for_open_and_closed_literaturebased_discovery"
        },
        {
            "paper_title": "Exploring a deep learning neural architecture for closed literature-based discovery.",
            "rating": 2,
            "sanitized_title": "exploring_a_deep_learning_neural_architecture_for_closed_literaturebased_discovery"
        },
        {
            "paper_title": "Predicting implicit concept embeddings for singular relationship discovery replication of closed literature-based discovery.",
            "rating": 2,
            "sanitized_title": "predicting_implicit_concept_embeddings_for_singular_relationship_discovery_replication_of_closed_literaturebased_discovery"
        },
        {
            "paper_title": "Drug repurposing for COVID-19 via knowledge graph completion.",
            "rating": 2,
            "sanitized_title": "drug_repurposing_for_covid19_via_knowledge_graph_completion"
        },
        {
            "paper_title": "SciMON: Scientific inspiration machines optimized for novelty",
            "rating": 2,
            "sanitized_title": "scimon_scientific_inspiration_machines_optimized_for_novelty"
        },
        {
            "paper_title": "BioGPT: Generative pre-trained transformer for biomedical text generation and mining.",
            "rating": 2,
            "sanitized_title": "biogpt_generative_pretrained_transformer_for_biomedical_text_generation_and_mining"
        },
        {
            "paper_title": "SciGLM: Training scientific language models with self-reflective instruction annotation and tuning.",
            "rating": 2,
            "sanitized_title": "sciglm_training_scientific_language_models_with_selfreflective_instruction_annotation_and_tuning"
        },
        {
            "paper_title": "Large language models for automated open-domain scientific hypotheses discovery.",
            "rating": 2,
            "sanitized_title": "large_language_models_for_automated_opendomain_scientific_hypotheses_discovery"
        }
    ],
    "cost": 0.01582675,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Recent Advances and Future Directions in Literature-Based Discovery
14 Jun 2025</p>
<p>Andrej Kastrin andrej.kastrin@mf.uni-lj.si 
University of Ljubljana
LjubljanaSlovenia</p>
<p>Bojan Cestnik bojan.cestnik@temida.si 
Jožef Stefan Institute
LjubljanaSlovenia</p>
<p>Temida d
LjubljanaSlovenia</p>
<p>Nada Lavrač nada.lavrac@ijs.si 
Jožef Stefan Institute
LjubljanaSlovenia</p>
<p>Recent Advances and Future Directions in Literature-Based Discovery
14 Jun 2025DBA73BB417A8FE366670E0CC21569698arXiv:2506.12385v1[cs.CL]Artificial intelligenceNatural language processingComputational scientific discoveryLiterature-based discovery
The explosive growth of scientific publications has created an urgent need for automated methods that facilitate knowledge synthesis and hypothesis generation.Literature-based discovery (LBD) addresses this challenge by uncovering previously unknown associations between disparate domains.This article surveys recent methodological advances in LBD, focusing on developments from 2000 to the present.We review progress in three key areas: knowledge graph construction, deep learning approaches, and the integration of pre-trained and large language models (LLMs).While LBD has made notable progress, several fundamental challenges remain unresolved, particularly concerning scalability, reliance on structured data, and the need for extensive manual curation.By examining ongoing advances and outlining promising future directions, this survey underscores the transformative role of LLMs in enhancing LBD and aims to support researchers and practitioners in harnessing these technologies to accelerate scientific innovation.</p>
<p>Introduction</p>
<p>The explosive growth of research publications across various scientific disciplines has led to an overwhelming volume of knowledge, ranging from research articles and monographs to preprints and conference proceedings [4].This proliferation has made it increasingly difficult for researchers to effectively locate, interpret, and synthesize relevant knowledge.As a result, staying current within one's field becomes more challenging, and the risk of missing important findings or inadvertently duplicating existing work rises significantly.Furthermore, the increasing complexity and interdisciplinarity of research further complicate the task of integrating knowledge from multiple sources, and much of the information remains siloed, underutilized, or disconnected.These challenges have led to a rising interest in developing automated methods, particularly those based on natural language processing (NLP), to support hypothesis generation and the discovery of novel scientific insights.</p>
<p>A promising approach to address this problem is literature-based discovery (LBD).LBD, originally introduced by Swanson [29] in the mid-1980s, is an approach designed to generate novel research hypotheses by revealing previously overlooked associations between two complementary and non-interactive sets of scientific literatures.It emerged as a response to the growing difficulty of staying abreast of developments across disparate fields and remains a valuable methodology in the face of ever-expanding scholarly output.</p>
<p>The primary motivation of this article is to provide an overview of current methodological challenges in LBD, survey recent scientific advances, and identify future research directions that align LBD with emerging trends in AI and more broadly computational scientific discovery.We limit the scope to the period between 2000 and early 2025, focusing exclusively on state-of-the-art approaches, as earlier methods have already been comprehensively covered in previous surveys [28,12,32].</p>
<p>The article is organized as follows.Section 2 presents the necessary preliminaries and a concise overview of LBD research.Recent advances in LBD methodologies are examined in Section 3, followed by a discussion of future research directions in Section 4. The article concludes with a synthesis of key findings in Section 5.</p>
<p>Preliminaries and Background</p>
<p>LBD is a subfield of artificial intelligence (AI) at the intersection of information retrieval, NLP and computational scientific discovery, which is dedicated to automating the scientific discovery process.The early Swanson's approach to LBD can be formalized using a generic ABC model (Figure 1) that considers two independent literature sets, A and C [30].In this model, a represents a source concept, c is a target concept, and b serves as a bridge or intermediate concept that connects the two.The key idea is that if a is associated with b in one body of literature and b is associated with c in another-yet a and c have not been directly linked in any publication-there may be a novel, undiscovered relationship between a and c worth exploring.</p>
<p>A seminal example of this model is Swanson's [29] groundbreaking discovery linking dietary fish oil (a) to Raynaud's disease (c).He found that Raynaud's disease was associated with reduced blood viscosity in one set of articles, while another set linked high blood viscosity to fish oil.Although no studies at the time had made a direct connection between Raynaud's disease and fish oil, Swanson's hypothesis suggested a new therapeutic use for fish oil, which was later confirmed by clinical research [8].</p>
<p>In general, LBD encompasses two tasks: hypothesis validation and hypothesis generation, which correspond to closed and open discovery modes, respectively.In closed discovery, the process starts with two known elements-a starting concept (a) and a target concept (c)-and seeks to validate or elaborate the Despite its pivotal importance, the ABC model exhibits critical limitations that severely constrain the broader applicability of LBD.First, scalability remains a pressing challenge.Traditional LBD systems were developed for relatively small, curated datasets and are poorly suited to handle the exponential growth of biomedical publications [32].Effectively managing large-scale, heterogeneous corpora demands advanced computational capabilities and methodological innovations that classical LBD frameworks were not originally designed to support.</p>
<p>Second, the heavy reliance on structured data sources represents a major constraint.LBD approaches have historically depended on controlled vocabularies and ontologies, such as Unified Medical Language System (UMLS) [3], which facilitate computational access but simultaneously narrow the scope of discovery to well-represented areas [12].Consequently, current LBD systems often exhibit limited flexibility when extracting knowledge directly from unstructured or semi-structured texts, which account for a substantial portion of the scientific literature.</p>
<p>Third, the reliance on extensive manual curation and expert intervention remains a substantial barrier to progress in LBD.Traditional LBD workflows necessitate expert involvement at multiple stages, including hypothesis validation, result refinement, and relevance assessment [28].This dependence not only slows the overall discovery process but also poses significant challenges to achieving the scalability and reproducibility required for the broader application of LBD tools.</p>
<p>The landscape of LBD is evolving rapidly, but a comprehensive approach to tackling these challenges is essential for realizing its full potential in biomedical research and beyond.</p>
<p>Recent Advances</p>
<p>The field of LBD has seen notable progress in recent years, driven largely by advancements in machine learning, text mining, and statistical analysis.Research efforts have increasingly harnessed these technologies to develop more effective and sophisticated LBD systems.This section reviews three major directions contributing to the recent evolution of LBD: knowledge graphs (KGs), deep learning (DL), and language models (LMs).</p>
<p>Knowledge Graphs</p>
<p>KGs have emerged as a pivotal technology in NLP, offering a structured and scalable approach to organizing scientific knowledge.By representing information as networks of entities and their relationships, KGs enable graph-based reasoning and facilitate the identification of implicit associations across disparate literature sources.</p>
<p>Formally, KGs are defined as G = (V, E), where V represents the set of vertices (nodes) and E represents edges (links).Relationships in the graph are often modeled as triples (h, r, t), where h (head) and t (tail) are nodes and r is the relation connecting them.</p>
<p>Their construction typically follows two principal methodologies: (i) co-occurrence modeling, where links between entities are established if they co-appear within the same article; and (ii) explicit relation extraction, where semantic relationships are directly identified using specialized NLP tools such as SemRep [26].Co-occurrence models are widely adopted due to their simplicity and scalability, while relation extraction methods provide greater precision and richer semantic information. 4In particular, co-occurrence-based approaches have gained popularity in LBD systems owing to their ease of implementation [28,12].Recent approaches also enable the direct construction of KGs based on predications (subject-relation-object triples) extracted from sources such as PubMed abstracts.Resources such as the UMLS and Open Biomedical Ontologies (OBO) offer rich terminological frameworks that enhance the integration and crossreferencing of knowledge.</p>
<p>We approach LBD by formulating it as a knowledge graph completion (KGC) task.KGC techniques aim to predict missing information in graphs, either by discovering new edges (link prediction) or by identifying missing nodes (node prediction).Depending on the method used to construct the KG, the elements h, r, and t (as previously defined) may differ: in co-occurrence-based graphs, all three components often represent concepts or terms, whereas in relational databases, h and t denote entities and r represents a predicate, such as treats.</p>
<p>Examples include structures like "Fish oil" → "Blood viscosity" → "Raynaud's disease" for co-occurrence graphs, or "Fish oil" → treats → "Raynaud's disease" for relational graphs.</p>
<p>Two main approaches to KGC are usually employed: (i) evaluating the plausibility of candidate triples (h, r, t) by assigning a predictive score, and (ii) inferring missing elements by submitting incomplete triples, such as (h, r), (h, t), or (r, t), and predicting the missing component (i.e., predicting t given (h, r), r given (h, t), or h given (r, t)).</p>
<p>Deep Learning</p>
<p>In contrast to traditional machine learning methods that rely on features explicitly constructed using domain knowledge, DL uses specialized and deep architectures to extract meaningful features from unstructured input, can automatically learn from simple inputs, and extracts task-specific representations of structures.</p>
<p>Crichton et al. [5] provided compelling evidence that neural network models are highly effective for advancing LBD.The authors built upon a multilayer perceptron (MLP) framework designed for both closed and open discovery tasks, achieving state-of-the-art performance on the PubTator and BioGRID datasets.Their approach begins by generating input representations through node embeddings using the Large-scale Information Network Embedding (LINE) algorithm [31], followed by various strategies for combining the embeddings of nodes along a discovery path-structured according to Swanson's ABC model-to construct the input for the neural model.</p>
<p>In closed discovery, the first approach uses a neural model to assign scores to individual A−B and B−C links, which are then aggregated to evaluate the full A−B−C path.The second approach combines the embeddings of A, B, and C into a single input vector, allowing the model to predict a score for the entire path directly, thus removing the need for an explicit aggregation step.In open discovery, the first method similarly scores A−B and B−C links and aggregates them, but additionally uses an accumulator function to integrate multiple paths leading to the same C.The second method employs a convolutional neural network (CNN) that processes stacked embeddings of multiple A−B−C paths, producing a unified score for each A−C pair without relying on separate aggregation or accumulation functions.(Unlike conventional CNN applications where images are used, the input here is a pseudo-image created by stacking vectorized A−B−C paths.)</p>
<p>While Crichton et al. [5] relied on embedding representations for all concepts as model inputs, their method required users to manually construct all possible hypothesis triples prior to evaluation, a process that is both time-consuming and reliant on substantial domain expertise.Addressing this limitation, Cuffy et al. [6] introduced a closed discovery framework that automates the ranking of potential linking B terms for a given A and C pair using a single forward propagation step through the DL model.This approach eliminates the need to generate all A−B−C triples a priori, thereby reducing the dependency on domain-specific knowledge and significantly streamlining the LBD workflow.</p>
<p>Cuffy et al. [7] introduced a further advancement by reformulating the LBD task as the prediction of implicit concept embeddings rather than direct relationship scoring.Instead of classifying triples, their model predicts the embedding of the linking concept (B) given the starting (A) and target (C) concepts.By comparing predicted embeddings against all candidate concepts, the MLP model identifies plausible intermediates, demonstrating its effectiveness in systematic knowledge discovery replication.</p>
<p>Beyond general-purpose LBD tasks, DL has been effectively applied in domainspecific applications, such as drug repurposing.Zhu et al. [39] introduced a BioBERT-based model enhanced with entity-aware attention mechanisms for drug-drug interaction extraction, while Gupta et al. [10] utilized an NSGA-III-based CNN architecture to optimize biomedical search engines.Rather et al. [25] further showcased DL's capacity to uncover latent biomedical relationships through word2vec-based embeddings.Taken together, these studies demonstrate the transformative potential of DL for LBD, facilitating more nuanced knowledge representation and discovery.</p>
<p>Language Models</p>
<p>LMs are nowadays regarded as fundamental components of NLP, tasked with estimating the probability distributions of linguistic units-such as words, phrases, or sentences-based on their contextual surroundings.The evolution of LMs can be delineated into several distinct stages: beginning with statistical language models (SLMs), progressing through neural language models (NLMs), advancing to pre-trained language models (PLMs), and culminating in the emergence of large language models (LLMs).SLMs utilize basic probabilistic frameworks to model word sequences (e.g., n-grams), whereas NLMs employ neural networks to capture complex syntactic and semantic patterns (e.g., RNNs, LSTMs, transformers).PLMs leverage large-scale textual corpora and self-supervised learning to encode general linguistic structures and knowledge (e.g., Bidirectional Encoder Representations from Transformers (BERT), Generative Pretrained Transformer (GPT)).</p>
<p>Here, we focus specifically on how recent developments in PLMs and LLMs have been integrated into LBD pipelines.While both PLMs and LLMs are trained on large corpora using self-supervised methods, LLMs represent a significant advancement in terms of model size, training data scale, and architectural complexity.Building upon the foundation established by PLMs, LLMs offer improved generalization, greater expressivity, enhanced contextual understanding, adaptability, and zero-shot reasoning capabilities-making them particularly well-suited for advanced LBD tasks.A comprehensive overview of the historical development of LMs is provided in recent surveys by Wang et al. [34] and Annepaka et al. [1].</p>
<p>PLMs have elevated the quality and scope of LBD by integrating deep contextual understanding into NLP pipelines.Used both as powerful preprocessing tools and as core components in downstream tasks such as named entity recognition and relation extraction, PLMs have enabled more accurate and scalable discovery workflows.For example, in our LBD approach to drug repurposing for Covid-19 [38], we employed BERT5 as a preprocessing tool to generate an accurate subset of semantic triples, which were then used to construct a KG.KGC algorithms were subsequently applied to this graph to predict potential drug repurposing candidates.</p>
<p>Compared to PLMs, LLMs exhibit remarkable adaptability, with recent empirical results indicating strong potential for their use as a general-purpose tool to support scientific reasoning [13].A growing body of evidence reveals a broad range of promising capabilities of LLM relevant to the scientific process, including the coherent integration of diverse knowledge concepts, the critical evaluation of existing studies, the generation of scientific hypotheses, and the identification of research gaps within scientific literature [21].State-of-the-art LLMs, such as BioGPT [20] and SciGLM [37] are trained on domain-specific corpora like PubMed and arXiv and are particularly effective at literature retrieval, document summarization, and question answering.They facilitate more efficient access to scientific information by identifying relevant publications, extracting key insights, and synthesizing knowledge across documents.</p>
<p>Specifically, building on the improved reasoning capabilities of LMs, the LBD community has begun developing methods that incorporate richer contextual information to address the limitations of traditional approaches, which are primarily based on the ABC model.Classical LBD techniques often fail to capture the nuanced contextual cues considered by human scientists during the ideation process and are largely restricted to predicting pairwise relationships between isolated concepts [13].To overcome these constraints, Wang et al. [33] introduced a novel framework, SciMON, which grounds LBD in natural language contexts, thereby narrowing the generative space in a more controlled and meaningful way.SciMON optimizes novel research hypotheses by iteratively refining idea suggestions derived from published literature until sufficient novelty is achieved.Unlike traditional models that merely predict conceptual links, SciMON generates complete sentences as outputs, offering a more nuanced and contextually rich representation of scientific knowledge.The authors report that it produces ideas that are both more original and exhibit greater conceptual depth than those generated by GPT-4.</p>
<p>A long-standing limitation of LBD has been its restriction to the biomedical domain, primarily due to the widespread availability of the PubMed database and auxiliary knowledge resources (e.g., UMLS vocabularies [3], SemMedDB repository [16], PubTator annotations [35]), which are freely available and optimized for computational access and analysis.However, LLM-powered LBD may have a much broader scope of applicability.In particular, Yang et al. [36] showed that the majority of published hypotheses in the social sciences can be structured in a manner compatible with the LBD framework.</p>
<p>In summary, recent advances in KGs, DL techniques, and LM development have significantly expanded the capabilities of LBD.Table 1 highlights the principal characteristics of the described approaches.Nevertheless, several key challenges remain, which are discussed in the following section.</p>
<p>Future Directions</p>
<p>Although LBD has made significant advances over the past five years, numerous open challenges remain to be addressed.The following discussion outlines several key areas of ongoing work, reflecting the current focus of our research efforts; however, the list is not intended to be exhaustive.</p>
<p>Advancing Interpretability</p>
<p>Interpretability remains one of the principal challenges associated with the application of DL techniques in science [24].Ensuring interpretability in LBD is not simply an auxiliary feature; it is foundational.While DL approaches offer considerable potential for enhancing hypothesis generation from large corpora, their inherent "black-box" nature continues to present significant obstacles for scientific domains where transparent reasoning processes are essential.In particular, many LBD methods, especially those rooted in Swanson's ABC model, focus primarily on hypothesis generation but often lack mechanisms for explaining the reasoning behind the generated hypotheses.While DL systems excel in extracting patterns from literature, they frequently fall short of providing understandable explanations, which symbolic systems have historically offered [2].</p>
<p>Traditional strategies, such as employing attention mechanisms or inspecting model coefficients, offer partial solutions by highlighting feature importance or visualizing internal representations [22].However, these approaches often lack a structured reasoning component and thus fall short of delivering full scientific explanatory power.A promising direction is the integration of neuro-symbolic AI into LBD methodologies.The neuro-symbolic approach aims to combine the pattern recognition capabilities of neural networks with the explicit reasoning structures of symbolic AI [27,2].This integration enables models not only to learn from data but also to reason in ways that are inherently interpretable and grounded in logical principles.Neuro-symbolic approaches have already been successfully applied to various NLP tasks [11].</p>
<p>Augmenting Data Resources</p>
<p>One of the principal limitations of current LBD applications lies in their restricted use of data resources.Most existing approaches rely primarily on Pub-Med, often limiting their textual input to article abstracts rather than utilizing the full texts.While abstracts offer a concise summary of findings, they frequently omit critical contextual relationships that could be valuable for complex hypothesis generation, particularly for LMs.Expanding beyond the biomedical domain to include full-text articles and additional knowledge bases presents a significant opportunity for advancing LBD.In particular, new bibliographic databases such as Semantic Scholar [19] have emerged as valuable resources.These platforms aggregate extensive metadata, citation networks, and, in some cases, full-text content across a wide range of scientific disciplines, offering richer semantic contexts for discovery processes.</p>
<p>In addition, auxiliary knowledge resources, such as the UMLS for the biomedical domain, are of significant importance, particularly during the preprocessing stages of LBD (e.g., guiding the extraction of knowledge concepts and the computation of predicates).Although widely integrated into LBD applications for its standardized vocabularies and extensive concept mappings, the use of UMLS is not without limitations.Issues such as term ambiguity and incomplete concept coverage can substantially impact the performance of downstream tasks.For instance, a significant portion of errors in tools like SemRep stem from difficulties in correctly identifying and normalizing biomedical entities using UMLS, accounting for up to 27% of errors in some evaluations [15].FurthermoreIn addition, auxiliary knowledge resources, such as the UMLS for the biomedical domain, are of significant importance, particularly during the preprocessing stages of LBD (e.g., guiding the extraction of knowledge concepts and the computation of predicates).Although widely integrated into LBD applications for its standardized vocabularies and extensive concept mappings, the use of UMLS is not without limitations.Issues such as term ambiguity and incomplete concept coverage can substantially impact the performance of downstream tasks.For instance, a significant portion of errors in tools like SemRep stem from difficulties in correctly identifying and normalizing biomedical entities using UMLS, accounting for up to 27% of errors in some evaluations [15].Finally, to the best of our knowledge at the time of writing, no comparably well-developed knowledge resource exists outside the life sciences domain.In our experience, the limited adoption of LBD beyond biomedicine is largely due to the greater terminological diversity and, in particular, the absence of standardized ontologies in the humanities and social sciences., to the best of our knowledge at the time of writing, no comparably well-developed knowledge resource exists outside the life sciences domain.In our experience, the limited adoption of LBD beyond biomedicine is largely due to the greater terminological diversity and, in particular, the absence of standardized ontologies in the humanities and social sciences.</p>
<p>Refining Benchmarking Practices</p>
<p>Knuth's [17] concept of literate programming, which emphasizes that computer programs should be readable and understandable by humans, closely aligns with open science initiatives that stress the importance of standardized practices and tools to ensure research outputs are independently verifiable and can support further scientific progress.</p>
<p>Following the principles of open science, we initiated a project aimed at promoting reproducibility within the field of LBD.Existing LBD approaches and results often remain difficult to replicate due to the lack of access to original datasets and unresolved programming dependencies.These limitations pose significant barriers to both the theoretical understanding and practical reuse of previously published methods.To address this gap, we have made publicly available benchmark datasets, replicable LBD case studies, and a collection of interactive Jupyter Notebooks that transparently document each step of the LBD pipeline, including data acquisition, text preprocessing, hypothesis discovery, and evaluation.Furthermore, we provide the LBD community with access to standardized benchmark datasets and prototypical LBD techniques presented through dockerized Jupyter environments, thereby greatly simplifying replication and extension.All associated materials are openly accessible at https: //github.com/akastrin/ida2025lbd.</p>
<p>Conclusion</p>
<p>This survey has reviewed the evolution of LBD over the past five years.We discussed the growing role of KGs, advances in DL methodologies, and the transformative impact of PLMs and LLMs on hypothesis generation and scientific reasoning.</p>
<p>Rapid advances in AI, particularly in the development of LLMs, are reshaping the scientific landscape at an unprecedented pace.These developments open up significant opportunities for treating scientific corpora as dynamic knowledge bases from which novel insights, hypotheses, and ideas can be systematically uncovered.Despite this progress, several fundamental challenges remain unresolved in LBD, notably issues related to scalability, dependence on structured data, the need for extensive manual curation, and the limited interpretability of current DL approaches.</p>
<p>Recent trends in neuro-symbolic AI suggest promising avenues for enhancing both the accuracy and explainability of LBD systems.By combining the strengths of DL with the reasoning capabilities of symbolic methods, these hybrid approaches aim to deliver more transparent and trustworthy discoveries, thereby enabling broader domain applicability of LBD beyond the biomedical sciences.</p>
<p>Fig. 1 .
1
Fig. 1.Swanson's ABC model of discovery.When a is related to b, and b is related to c, it suggests the possibility of an undiscovered indirect relationship between a and c.</p>
<p>Table 1 .
1
Summary of key strengths and limitations of recent approaches in LBD.
Approach StrengthsLimitationsKGsCaptures complex, heterogeneousRequires high-quality semanticassociations; enables context-annotation; extensive filtering of-driven subgraph creation.ten needed.DLOutperforms traditional base-Interpretability remains a chal-lines, especially when input rep-lenge; generalizability may beresentations are well-optimized.constrained by data representa-tion.LMsOffers potential for explainableStill emerging; scalability and val-AI; capable of processing hetero-idation challenges.geneous, cross-domain data.
Co-occurrence refers to the statistical tendency of two terms or concepts to appear together in text (e.g., fever and infection), without implying a specific semantic or causal relationship. In contrast, a semantic relation denotes a defined and meaningful connection between terms, such as a taxonomic link (e.g., influenza as a type of viral infection), regardless of how frequently they co-occur.
Due to its success in general NLP tasks, BERT has been adapted to various specialized domains, including biomedicine, resulting in models such as BioBERT[18], ClinicalBERT[14], PubMedBERT[9], and COVID-Twitter-BERT[23].
Acknowledgments.The authors acknowledge the financial support from the Slovenian Research and Innovation Agency through the Knowledge Technologies (Grant No. P2-0103), and Methodology for Data Analysis in Medical Sciences (Grant No. P3-0154) core research projects, as well as Embeddings-Based Techniques for Media Monitoring Applications (Grant No. L2-50070) research project.Disclosure of Interests.The authors have no competing interests to declare that are relevant to the content of this article.
Large language models: A survey of their development, capabilities, and applications. Y Annepaka, P Pakray, 10.1007/s10115-024-02310-4Knowledge and Information Systems. 6732025</p>
<p>Neuro-symbolic artificial intelligence: A survey. B P Bhuyan, A Ramdane-Cherif, R Tomar, T P Singh, 10.1007/s00521-024-09960-zNeural Computing and Applications. 36212024</p>
<p>The Unified Medical Language System (UMLS): Integrating biomedical terminology. O Bodenreider, 10.1093/nar/gkh061Nucleic Acids Research. 32Database2004</p>
<p>Growth rates of modern science: A latent piecewise growth curve approach to model publication numbers from established and new literature databases. L Bornmann, R Haunschild, R Mutz, 10.1057/s41599-021-00903-wHumanities and Social Sciences Communications. 812242021</p>
<p>Neural networks for open and closed literature-based discovery. G Crichton, S Baker, Y Guo, A Korhonen, 10.1371/journal.pone.0232891PLoS One. 155e02328912020</p>
<p>Exploring a deep learning neural architecture for closed literature-based discovery. C Cuffy, B T Mcinnes, 10.1016/j.jbi.2023.104362Journal of Biomedical Informatics. 1431043622023</p>
<p>Predicting implicit concept embeddings for singular relationship discovery replication of closed literature-based discovery. C Cuffy, B T Mcinnes, 10.3389/frma.2025.1509502Frontiers in Research Metrics and Analytics. 1015095022025</p>
<p>Fish-oil dietary supplementation in patients with Raynaud's phenomenon: A double-blind, controlled, prospective study. R A Digiacomo, J M Kremer, D M Shah, 10.1016/0002-9343(89)90261-1The American Journal of Medicine. 8621989</p>
<p>Domainspecific language model pretraining for biomedical natural language processing. Y Gu, R Tinn, H Cheng, M Lucas, N Usuyama, X Liu, 10.1145/3458754ACM Transactions on Computing for Healthcare. 312021</p>
<p>NSGA-III-based deep-learning model for biomedical search engines. M Gupta, N Kumar, B K Singh, N Gupta, 10.1155/2021/9935862Mathematical Problems in Engineering. 2021199358622021</p>
<p>Is neuro-symbolic AI meeting its promises in natural language processing? A structured review. Nayak Hamilton, A Božić, B Longo, L , 10.3233/SW-223228Semantic Web. 1542024</p>
<p>Literature based discovery: Models, methods, and trends. S Henry, B T Mcinnes, 10.1016/j.jbi.2017.08.011Journal of Biomedical Informatics. 742017</p>
<p>A computational inflection for scientific discovery. T Hope, D Downey, D S Weld, O Etzioni, E Horvitz, 10.1145/3576896Communications of the ACM. 6682023</p>
<p>K Huang, J Altosaar, R Ranganath, 10.48550/arXiv.1904.05342arXivClinicalBERT: Modeling clinical notes and predicting hospital readmission. 2020</p>
<p>Broad-coverage biomedical relation extraction with SemRep. H Kilicoglu, G Rosemblat, M Fiszman, D Shin, 10.1186/s12859-020-3517-7BMC Bioinformatics. 2111882020</p>
<p>SemMedDB: A PubMed-scale repository of biomedical semantic predications. H Kilicoglu, D Shin, M Fiszman, G Rosemblat, T C Rindflesch, 10.1093/bioinformatics/bts591Bioinformatics. 28232012</p>
<p>Literate programming. D E Knuth, The Computer Journal. 2721984</p>
<p>BioBERT: A pre-trained biomedical language representation model for biomedical text mining. J Lee, W Yoon, S Kim, D Kim, S Kim, C H So, 10.1093/bioinformatics/btz682Bioinformatics. 3642020</p>
<p>S2ORC: The Semantic Scholar Open Research Corpus. K Lo, L L Wang, M Neumann, R Kinney, D Weld, 10.18653/v1/2020.acl-main.447Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. D Jurafsky, J Chai, N Schluter, J Tetreault, the 58th Annual Meeting of the Association for Computational LinguisticsAssociation for Computational Linguistics2020</p>
<p>BioGPT: Generative pre-trained transformer for biomedical text generation and mining. R Luo, L Sun, Y Xia, T Qin, S Zhang, H Poon, 10.1093/bib/bbac409Briefings in Bioinformatics. 2364092022</p>
<p>Z Luo, Z Yang, Z Xu, W Yang, X Du, 10.48550/arXiv.2501.04306LLM4SR: A survey on large language models for scientific research. 2025</p>
<p>Explainable artificial intelligence: A survey of needs, techniques, applications, and future direction. M Mersha, K Lam, J Wood, A K Alshami, J Kalita, 10.1016/j.neucom.2024.128111Neurocomputing. 5991281112024</p>
<p>COVID-Twitter-BERT: A natural language processing model to analyse COVID-19 content on Twitter. M Müller, M Salathé, P E Kummervold, 10.3389/frai.2023.1023281Frontiers in Artificial Intelligence. 610232812023</p>
<p>Definitions, methods, and applications in interpretable machine learning. W J Murdoch, C Singh, K Kumbier, R Abbasi-Asl, B Yu, 10.1073/pnas.1900654116Proceedings of the National Academy of Sciences. the National Academy of Sciences2019116</p>
<p>Using deep learning towards biomedical knowledge discovery. N N Rather, C O Patel, S A Khan, 10.5815/ijmsc.2017.02.01International Journal of Mathematical Sciences and Computing. 322017</p>
<p>The interaction of domain knowledge and linguistic structure in natural language processing: Interpreting hypernymic propositions in biomedical text. T C Rindflesch, M Fiszman, 10.1016/j.jbi.2003.11.003Journal of Biomedical Informatics. 3662003</p>
<p>Neuro-symbolic artificial intelligence: Current trends. M K Sarker, L Zhou, A Eberhart, P Hitzler, 10.3233/AIC-210084AI Communications. 3432021</p>
<p>Learning the heterogeneous bibliographic information network for literature-based discovery. Y Sebastian, E G Siew, S O Orimaye, 10.1016/j.knosys.2016.10.015Knowledge-Based Systems. 1152017</p>
<p>Fish oil, Raynaud's syndrome, and undiscovered public knowledge. D R Swanson, 10.1353/pbm.1986.0087Perspectives in Biology and Medicine. 3011986</p>
<p>Undiscovered public knowledge. D R Swanson, 10.1086/601720The Library Quarterly. 5621986</p>
<p>LINE: Large-scale information network embedding. J Tang, M Qu, M Wang, M Zhang, J Yan, Q Mei, 10.1145/2736277.2741093Proceedings of the 24th International Conference on World Wide Web. A Gangemi, S Leonardi, A Panconesi, the 24th International Conference on World Wide Web2015International World Wide Web Conference Committee</p>
<p>A systematic review on literaturebased discovery: General overview, methodology, &amp; statistical analysis. M Thilakaratne, K Falkner, T Atapattu, 10.1145/3365756ACM Computing Surveys. 5261292019</p>
<p>SciMON: Scientific inspiration machines optimized for novelty. Q Wang, D Downey, H Ji, T Hope, 10.18653/v1/2024.acl-long.18Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics. L W Ku, A Martins, V Srikumar, the 62nd Annual Meeting of the Association for Computational LinguisticsAssociation for Computational Linguistics2024</p>
<p>History, development, and principles of large language models: An introductory survey. Z Wang, Z Chu, T V Doan, S Ni, M Yang, W Zhang, 10.1007/s43681-024-00583-7AI and Ethics. 52025</p>
<p>PubTator 3.0: An AI-powered literature resource for unlocking biomedical knowledge. C H Wei, A Allot, P T Lai, R Leaman, S Tian, L Luo, 10.1093/nar/gkae235Nucleic Acids Research. 52W12024</p>
<p>Large language models for automated open-domain scientific hypotheses discovery. Z Yang, X Du, J Li, J Zheng, S Poria, E Cambria, 10.18653/v1/2024.findings-acl.804Findings of the Association for Computational Linguistics: ACL 2024. L W Ku, A Martins, V Srikumar, Association for Computational Linguistics2024</p>
<p>SciGLM: Training scientific language models with self-reflective instruction annotation and tuning. D Zhang, Z Hu, S Zhoubian, Z Du, K Yang, Z Wang, 10.48550/arXiv.1904.05342arXiv2024</p>
<p>Drug repurposing for COVID-19 via knowledge graph completion. R Zhang, D Hristovski, D Schutte, A Kastrin, M Fiszman, H Kilicoglu, 10.1016/j.jbi.2021.103696Journal of Biomedical Informatics. 1151036962021</p>
<p>Extracting drug-drug interactions from texts with BioBERT and multiple entity-aware attentions. Y Zhu, L Li, H Lu, A Zhou, X Qin, 10.1016/j.jbi.2020.103451Journal of Biomedical Informatics. 1061034512020</p>            </div>
        </div>

    </div>
</body>
</html>