<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-473 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-473</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-473</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-17.html">extraction-schema-17</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <p><strong>Paper ID:</strong> paper-258991264</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2306.13150v1.pdf" target="_blank">Rethinking the Physical Symbol Systems Hypothesis</a></p>
                <p><strong>Paper Abstract:</strong> It is now more than a half-century since the Physical Symbol Systems Hypothesis (PSSH) was first articulated as an empirical hypothesis. More recent evidence from work with neural networks and cognitive architectures has weakened it, but it has not yet been replaced in any satisfactory manner. Based on a rethinking of the nature of computational symbols -- as atoms or placeholders -- and thus also of the systems in which they participate, a hybrid approach is introduced that responds to these challenges while also helping to bridge the gap between symbolic and neural approaches, resulting in two new hypotheses, one that is to replace the PSSH and other focused more directly on cognitive architectures.</p>
                <p><strong>Cost:</strong> 0.015</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e473.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e473.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>HSSH</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Hybrid Symbol Systems Hypothesis</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A proposed replacement for the PSSH stating that hybrid symbol systems (symbols combined with numeric/other modalities) are necessary and sufficient for general intelligent action.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Hybrid Symbol Systems (conceptual class)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A class of systems in which computational symbols (reinterpreted as atomic placeholders) optionally support declarative designation, procedural designation, composability, and numeric metadata; these hybrid symbols and structures combine symbolic (declarative) and numeric/procedural components within one system or architecture to support intelligent behavior.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Declarative elements consist of symbols/symbol-structures that can designate objects or relations (classical symbolic representations as used in cognitive architectures and knowledge representations). In the paper this is described at the level of symbol types and symbol structures (e.g., word vectors that externally designate letters/meanings) rather than a single formal logic dialect.</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Imperative elements are numeric metadata and procedures (activations, link weights, procedural designation of links and nodes) including neural processing (feedforward layers, convolutional/transformer composition variants) and other numeric paradigms (probabilities, activations) operating at the same time scale as symbolic processing.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Integration is conceptualized as hybrid symbols/structures that combine symbolic tokens with quantitative metadata; integration can be tight (symbols carry numeric metadata used in-situ during processing) or loose (modular coupling of symbolic and numeric components). The paper exemplifies tight integration in neural networks where nodes and links are treated as hybrid symbols (locations + activations/weights) and vectors as composed hybrid structures; it also mentions both tightly coupled and loosely coupled approaches (e.g., PGMs vs. modular neuro-symbolic systems).</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Enables concurrent symbolic compositionality and rapid numeric/statistical processing on the same time scale; supports grounding (external designation) together with learned procedural mappings; permits behaviors such as flexible vector composition, distributed representation-based designation, and proceduralized numeric operations (e.g., weighted summation) integrated with symbolic structures — capabilities not present when only pure declarative symbol-manipulation (too slow or ill-suited for statistical learning) or only pure numeric systems (lack of explicit compositional symbol structures and declarative designations) are used.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Not evaluated on a single experimental benchmark in this paper; discussed conceptually across cognitive-architecture-level tasks (general intelligent action, cognitive-architecture requirements) and examples such as paired-associates mapping, representation and combinatorial game play contexts referenced in citations.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Argued qualitatively to support both statistical/generalization strengths of numeric methods and compositional/generalization strengths of symbolic methods; paper asserts hybrid systems can restore a stronger empirical sufficiency (relative to PSSH) by enabling numeric processing at cognitive time scales and by reinterpreting neural successes as hybrid-symbolic evidence, but provides no quantitative OOD or compositional generalization measures.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Hybrid symbols with declarative designation can serve as loci for explanation (symbol structures at input/output provide interpretable grounding), while numeric procedural parts (internal activations/weights) remain less directly interpretable; overall interpretability is intermediate — declarative components can enable explanations but substantial procedural elements remain opaque according to the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Paper notes remaining complexities and partial understanding: not all neural networks provide full symbolic compositionality; some tasks (e.g., combinatorial board games) have relied on explicit state-space search in addition to neural methods, indicating limitations of current hybrid/neural approaches alone; potential unaddressed issues include quantum aspects of intelligence that may lie outside hybrid systems.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Presented as an empirical hypothesis grounded in an essential redefinition of 'symbol' (atoms/placeholders with optional properties) and supported by the Common Model of Cognition and analysis of neural networks as instances of hybrid symbols — theoretical rationale is complementarity (symbols + numeric metadata/procedural designation) and the architectural necessity of numeric processing at cognitive time scales.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e473.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e473.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>HCAH</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Hybrid Cognitive Architectures Hypothesis</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A hypothesis that hybrid symbol systems are necessary and sufficient specifically for cognitive architectures (models of fixed structures/processes that yield a mind).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Hybrid Cognitive Architectures (conceptual claim)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>An empirical claim that cognitive architectures must be hybrid: they require symbolic structures plus numeric/statistical processing co-located at cognitive time scales (e.g., architectures like the CMC and Sigma that incorporate numeric metadata and hybrid symbol structures).</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Symbol structures, symbolic memory and symbolic representation components as in cognitive-architecture traditions (compositional symbols, working memory structures, declarative knowledge representations), described at an architectural level rather than a single formal system.</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Numeric/statistical processing integrated into the architecture (activations, probabilities, gradient-based learning, procedural modules) that must operate on the same time scale as symbolic processing; examples include the CMC's quantitative metadata and neural processing modules.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Architectural-level integration where symbolic data structures carry quantitative metadata and numerical processing modules are within the architecture's fixed processes (not merely offloaded to separate systems); the paper emphasizes same-time-scale processing and tight coupling in cognitive architectures rather than sequential or purely modular combinations.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>A cognitive-architecture-level capacity to perform rapid statistical processing (e.g., perceptual/statistical inference) alongside symbolic planning and reasoning within the same architectural time constraints; supports cognitive phenomena requiring both symbolic manipulation and real-time probabilistic/statistical computation.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Conceptual discussion in relation to cognitive-architecture requirements (human-like cognition); no single benchmark or experiment reported in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Argued qualitatively to better meet cognitive time-scale requirements and thus provide more realistic generalization in tasks requiring rapid integration of symbolic and statistical information; no quantitative measures reported.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Because declarative structures are part of the architecture, they can support explanation generation and interpretable state representations, while numeric components may remain less transparent; the architecture-level design can increase interpretability relative to purely procedural systems by exposing symbolic state.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Paper states that the sufficiency of classical physical symbol systems for cognitive architectures fails due to the need for numeric processing within the architecture; it also leaves open whether purely neural/hybrid networks alone (without symbolic architectural scaffolding) will suffice.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Built on the Common Model of Cognition (CMC) and empirical argumentation about time-scale requirements; frames hybrid cognitive architectures as necessary to reconcile symbolic compositionality and in-time numeric processing.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e473.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e473.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CMC</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Common Model of Cognition</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A proposed consensus computational framework of core cognitive components that explicitly allows symbols with quantitative metadata and advocates hybrid processing at cognitive time scales.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>A standard model of the mind: Toward a common computational framework across artificial Intelligence, cognitive science, neuroscience, and robotics.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Common Model of Cognition (CMC)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A cognitive-architecture-level framework identifying core modules (e.g., declarative memory, procedural memory, perception, action) and endorsing hybrid symbols (symbolic structures augmented with quantitative metadata) to support cognitive tasks; used as part of the theoretical basis for the HSSH and HCAH.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Declarative memory and symbolic structures that can represent compositional symbolic information; symbols can designate objects or structures and are used for high-level cognitive representations.</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Procedural modules and numeric metadata associated with symbols (activations, probabilities) enabling statistical processing, learning, and real-time modulation of symbolic processing.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Symbols augmented with quantitative metadata that modulates processing within cognitive modules; tight architectural integration so that statistical/numeric processing operates on the same time scales as symbolic computation.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Combined ability to support cognitive phenomena requiring both symbolic reasoning (planning, problem solving) and rapid statistical/perceptual processing; supports hybrid behaviors like symbol-guided perception influenced by activations/metadata.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Intended as a general cognitive framework for human-like cognition, not evaluated on a single benchmark within this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>CMC is asserted to facilitate architecture-level generalization by ensuring numeric processing is available at cognitive time scales alongside symbolic processing, which should improve performance on tasks mixing perception/statistics and symbolic reasoning; no quantitative evidence in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Declarative modules provide interpretable symbolic representations and potential explanations; quantitative metadata can be inspected but may be less interpretable without mapping to symbolic constructs.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Paper notes that CMC's allowance for numeric metadata complicates the classical PSSH sufficiency claim and that not all details of hybridization/implementation are resolved; empirical validation across all cognitive phenomena remains ongoing.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Presented as a consensus model/framework for integrating symbolic and numeric processing in cognitive architectures; serves as a key theoretical support for HSSH/HCAH.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e473.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e473.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Sigma</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Sigma cognitive architecture</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A cognitive architecture that emphasizes hybrid symbol representations and denies the need for all symbols to support arbitrary composition, aligning with the paper's redefinition of symbols.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>The Sigma cognitive architecture and system: Towards functionally elegant grand unification.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Sigma cognitive architecture</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>An implemented cognitive architecture that integrates symbolic and numeric processing, allowing symbols that do not necessarily support arbitrary composition and incorporating numeric metadata and probabilistic processing within a unifying factor-graph/graphical model-like substrate (as described in the cited Sigma work).</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Symbolic representational elements and symbol structures used for high-level cognitive state and reasoning (the architecture does not require every symbol to support full compositionality).</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Numeric/statistical processing mechanisms embedded in the architecture (belief propagation / probabilistic inference style computations and numeric metadata) that operate within the architecture's processing loop.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Tight architectural integration where symbolic structures coexist with numeric inference mechanisms and metadata; Sigma uses a unifying graphical-model-inspired substrate (factor-graph-like approaches) to blend symbolic/state descriptions with numeric processing (see Sigma citation for implementation details).</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Enables functional unification of classical symbolic cognitive functions with probabilistic/numeric inference, supporting more realistic cognitive-time-scale behaviors and mixed symbolic-statistical reasoning across modules.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Discussed at architecture level; specific Sigma experiments/benchmarks are in the referenced Sigma paper rather than this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Architectural claims suggest improved real-time integration of symbolic and statistical processes and better alignment with human-like cognition; no direct quantitative evidence in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Because Sigma exposes symbolic structures and uses symbolic state representations, it can support interpretability/explanations at the symbolic level while embedding numeric inference internally.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Paper cites Sigma as an example but does not detail limitations; general issues include complexity of integrating inference and symbolic mechanisms and potential limits of composition in specific neural realizations.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Sigma is presented as an architectural instantiation exemplifying the HCAH principles; theoretical rationale is unification of symbolic and numeric processing within a single architecture.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e473.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e473.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PGMs / SRL</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Probabilistic Graphical Models / Statistical Relational Learning</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Hybrid systems that combine symbolic relational structure (relations, logic-like predicates) with probabilistic numeric reasoning, serving as canonical hybrid approaches in AI.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Probabilistic Graphical Models: Principles and Techniques.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Probabilistic Graphical Models / Statistical Relational Systems</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Formalisms that represent dependencies among variables using graphs (Bayesian networks, Markov networks) and that in statistical-relational variants combine logical/relational symbolic structure with probabilities to perform inference and learning under uncertainty.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Relational/logical structure (predicates, relations, symbolic schemas) used to express entities and relationships; in SRL this is formal logic-like structure (e.g., first-order templates) that constrain probabilistic models.</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Probabilistic numeric computation (inference algorithms such as belief propagation, sampling, parameter learning, gradient-based estimation) operating over the symbolic relational scaffold.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Tight formal integration where symbolic relational templates define factorization structure for probabilistic models (e.g., Markov logic networks, probabilistic relational models); numeric inference is performed on graphs grounded from symbolic templates.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Combines structured relational reasoning with robust statistical handling of noise and uncertainty; supports learning and probabilistic inference over rich relational domains that pure symbolic logic (no uncertainty) cannot handle and pure numeric models (no relational structure) cannot compactly represent.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Used in relational probabilistic inference, structured prediction tasks, and domains requiring uncertainty over relational data; paper cites PGMs as a general example rather than giving a specific benchmark.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>SRL/PGMs can generalize by exploiting relational structure and shared parameters across entities; they often generalize better than purely propositional numeric models in relational domains, but this paper does not provide quantitative comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Symbolic relational templates and graph structure provide interpretable structure and explanations for probabilistic inferences; numeric inference details may remain complex but the high-level relational structure aids explainability.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Scalability and inference complexity in large relational domains; requires careful modeling to capture complex compositions that modern deep learning handles more flexibly; paper treats PGMs as already hybrid and not a direct challenge to HSSH.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Grounded in probabilistic graphical model theory and extensions to statistical-relational learning; presented as a canonical example of hybrid symbolic-numeric integration.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e473.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e473.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>FFNN_as_hybrid</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Feedforward Neural Networks interpreted as Hybrid Symbol Systems</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The paper analyzes standard feedforward neural networks (multi-layer perceptrons) and interprets nodes, links, and vectors as hybrid symbols where nodes are symbol-locations with quantitative metadata and links/nodes procedurally designate processes.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Feedforward neural network (interpreted as a hybrid symbol system)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Standard feedforward architectures (input layer, hidden layers, output layer) where input/output vectors are treated as composed hybrid symbol structures (locations+activations), internal nodes and links are hybrid symbols with numeric metadata (activations, weights) that procedurally designate the operations performed (multiplication by weights, summation, nonlinear transformation); encoding/decoding map between external symbolic tokens and vector encodings.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Declarative designation occurs at input (and decoded output) hybrid symbol structures: encoded vectors internally designate words/letters/meanings; these are notated as declarative symbols realized as vector structures rather than explicit logical formulas.</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Imperative procedural components are the per-link multiplication and per-node summation + nonlinear transformation operations, implemented as weighted connections and activation functions (i.e., standard neural computation).</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Tight internal integration: the same neural substrate is interpreted as carrying hybrid symbols (locations) with numeric metadata; symbolic designation resides in the same vectors processed by the imperative computations rather than being a separate module. The paper describes encoding/decoding as external processes that map between symbol tokens and network vectors.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Provides a re-interpretation where distributed vector processing simultaneously implements symbolic designation at I/O and procedural numeric transformations internally; this yields emergent hybrid behavior such as vector-based compositional designation (epiphenomenal 'words' arising from patterns of hybrid symbols) and the ability to perform learned mappings between symbolic tokens via numeric computation.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Illustrated with a conceptual paired-associates example mapping input words to output words via encoding/decoding; no empirical benchmark or numeric evaluation provided.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Paper argues qualitatively that neural networks, when viewed as hybrid symbol systems, inherit statistical generalization properties of neural learning while providing symbolic designation at I/O; no quantitative out-of-distribution or compositional generalization metrics are reported.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Input/output hybrid symbols provide interpretable endpoints (encoded tokens), but internal nodes/weights/procedures are procedural and not declaratively designated, limiting internal interpretability; decoding is required to map internal activations back to symbolic tokens.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Acknowledges that many neural networks do not display full classical symbolic compositionality and that some tasks (e.g., combinatorial board games) have required explicit search/state-space methods in addition to neural components; internal meanings are not fixed, complicating symbolic explanation.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Presents an interpretive framework that treats neural network elements as hybrid symbols (atoms with optional designation/composition/metadata) and uses this to argue that neural networks count as hybrid symbol systems under the HSSH.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e473.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e473.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>NN + search (AlphaZero)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Neural networks combined with explicit state-space search (e.g., AlphaZero)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An example class of hybrid systems where neural networks provide evaluation/policy and explicit search (Monte Carlo tree search / state-space search) provides dynamic composition and combinatorial search capabilities.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Neural network + explicit state-space search hybrid (e.g., AlphaZero style)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Hybrid architectures where learned neural policies/value networks provide fast evaluation and priors, while an external symbolic-like procedural search algorithm (e.g., Monte Carlo tree search / explicit state-space search) supplies dynamic composition and combinatorial planning/search.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>The search/state-space representation and explicit search procedure provide symbolic-like structured search over discrete game states (state representations, legal-move generation, tree structure).</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Deep neural networks (policy/value networks) trained by reinforcement/self-play provide numeric evaluation and move priors; the search algorithm is procedural and algorithmic (MCTS).</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Modular/loosely coupled integration: neural networks supply heuristic evaluations and priors to the search algorithm at each node; the search module uses these numeric signals to guide symbolic/combinatorial exploration (tight coupling during runtime but modular in design).</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Together they achieve high-level combinatorial play that neither component (pure learned network without search, nor pure search with handcrafted evaluation) could match alone at the same efficiency: neural nets provide strong heuristics, search supplies systematic compositional planning over game trees.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Combinatorial board games (chess, shogi, Go) as exemplified by AlphaZero and related systems referenced in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Empirically in cited literature these hybrids generalize across game positions via learned heuristics plus planning, but this paper only references the phenomenon qualitatively and notes that neural networks alone have not solved such combinatorial games without explicit search.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Search traces and explicit state expansions provide interpretable step-by-step rationales for moves (tree of explored continuations), while neural evaluations are less interpretable but can be queried at decision points.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Paper notes reliance on dynamic composition via explicit state-space search for achieving combinatorial game mastery; implies limitations of pure neural composition for such tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Portrays this as an exemplar of modular hybridization where division of labor places statistical evaluation in neural modules and combinatorial planning in algorithmic search modules.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Dimensions of neural-symbolic integration-a structured survey. <em>(Rating: 2)</em></li>
                <li>Probabilistic Graphical Models: Principles and Techniques. <em>(Rating: 2)</em></li>
                <li>The Sigma cognitive architecture and system: Towards functionally elegant grand unification. <em>(Rating: 2)</em></li>
                <li>A standard model of the mind: Toward a common computational framework across artificial Intelligence, cognitive science, neuroscience, and robotics. <em>(Rating: 2)</em></li>
                <li>Deep Learning. <em>(Rating: 2)</em></li>
                <li>The Physical Symbol System Hypothesis: Status and prospects <em>(Rating: 1)</em></li>
                <li>A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play. <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-473",
    "paper_id": "paper-258991264",
    "extraction_schema_id": "extraction-schema-17",
    "extracted_data": [
        {
            "name_short": "HSSH",
            "name_full": "Hybrid Symbol Systems Hypothesis",
            "brief_description": "A proposed replacement for the PSSH stating that hybrid symbol systems (symbols combined with numeric/other modalities) are necessary and sufficient for general intelligent action.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Hybrid Symbol Systems (conceptual class)",
            "system_description": "A class of systems in which computational symbols (reinterpreted as atomic placeholders) optionally support declarative designation, procedural designation, composability, and numeric metadata; these hybrid symbols and structures combine symbolic (declarative) and numeric/procedural components within one system or architecture to support intelligent behavior.",
            "declarative_component": "Declarative elements consist of symbols/symbol-structures that can designate objects or relations (classical symbolic representations as used in cognitive architectures and knowledge representations). In the paper this is described at the level of symbol types and symbol structures (e.g., word vectors that externally designate letters/meanings) rather than a single formal logic dialect.",
            "imperative_component": "Imperative elements are numeric metadata and procedures (activations, link weights, procedural designation of links and nodes) including neural processing (feedforward layers, convolutional/transformer composition variants) and other numeric paradigms (probabilities, activations) operating at the same time scale as symbolic processing.",
            "integration_method": "Integration is conceptualized as hybrid symbols/structures that combine symbolic tokens with quantitative metadata; integration can be tight (symbols carry numeric metadata used in-situ during processing) or loose (modular coupling of symbolic and numeric components). The paper exemplifies tight integration in neural networks where nodes and links are treated as hybrid symbols (locations + activations/weights) and vectors as composed hybrid structures; it also mentions both tightly coupled and loosely coupled approaches (e.g., PGMs vs. modular neuro-symbolic systems).",
            "emergent_properties": "Enables concurrent symbolic compositionality and rapid numeric/statistical processing on the same time scale; supports grounding (external designation) together with learned procedural mappings; permits behaviors such as flexible vector composition, distributed representation-based designation, and proceduralized numeric operations (e.g., weighted summation) integrated with symbolic structures — capabilities not present when only pure declarative symbol-manipulation (too slow or ill-suited for statistical learning) or only pure numeric systems (lack of explicit compositional symbol structures and declarative designations) are used.",
            "task_or_benchmark": "Not evaluated on a single experimental benchmark in this paper; discussed conceptually across cognitive-architecture-level tasks (general intelligent action, cognitive-architecture requirements) and examples such as paired-associates mapping, representation and combinatorial game play contexts referenced in citations.",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Argued qualitatively to support both statistical/generalization strengths of numeric methods and compositional/generalization strengths of symbolic methods; paper asserts hybrid systems can restore a stronger empirical sufficiency (relative to PSSH) by enabling numeric processing at cognitive time scales and by reinterpreting neural successes as hybrid-symbolic evidence, but provides no quantitative OOD or compositional generalization measures.",
            "interpretability_properties": "Hybrid symbols with declarative designation can serve as loci for explanation (symbol structures at input/output provide interpretable grounding), while numeric procedural parts (internal activations/weights) remain less directly interpretable; overall interpretability is intermediate — declarative components can enable explanations but substantial procedural elements remain opaque according to the paper.",
            "limitations_or_failures": "Paper notes remaining complexities and partial understanding: not all neural networks provide full symbolic compositionality; some tasks (e.g., combinatorial board games) have relied on explicit state-space search in addition to neural methods, indicating limitations of current hybrid/neural approaches alone; potential unaddressed issues include quantum aspects of intelligence that may lie outside hybrid systems.",
            "theoretical_framework": "Presented as an empirical hypothesis grounded in an essential redefinition of 'symbol' (atoms/placeholders with optional properties) and supported by the Common Model of Cognition and analysis of neural networks as instances of hybrid symbols — theoretical rationale is complementarity (symbols + numeric metadata/procedural designation) and the architectural necessity of numeric processing at cognitive time scales.",
            "uuid": "e473.0"
        },
        {
            "name_short": "HCAH",
            "name_full": "Hybrid Cognitive Architectures Hypothesis",
            "brief_description": "A hypothesis that hybrid symbol systems are necessary and sufficient specifically for cognitive architectures (models of fixed structures/processes that yield a mind).",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Hybrid Cognitive Architectures (conceptual claim)",
            "system_description": "An empirical claim that cognitive architectures must be hybrid: they require symbolic structures plus numeric/statistical processing co-located at cognitive time scales (e.g., architectures like the CMC and Sigma that incorporate numeric metadata and hybrid symbol structures).",
            "declarative_component": "Symbol structures, symbolic memory and symbolic representation components as in cognitive-architecture traditions (compositional symbols, working memory structures, declarative knowledge representations), described at an architectural level rather than a single formal system.",
            "imperative_component": "Numeric/statistical processing integrated into the architecture (activations, probabilities, gradient-based learning, procedural modules) that must operate on the same time scale as symbolic processing; examples include the CMC's quantitative metadata and neural processing modules.",
            "integration_method": "Architectural-level integration where symbolic data structures carry quantitative metadata and numerical processing modules are within the architecture's fixed processes (not merely offloaded to separate systems); the paper emphasizes same-time-scale processing and tight coupling in cognitive architectures rather than sequential or purely modular combinations.",
            "emergent_properties": "A cognitive-architecture-level capacity to perform rapid statistical processing (e.g., perceptual/statistical inference) alongside symbolic planning and reasoning within the same architectural time constraints; supports cognitive phenomena requiring both symbolic manipulation and real-time probabilistic/statistical computation.",
            "task_or_benchmark": "Conceptual discussion in relation to cognitive-architecture requirements (human-like cognition); no single benchmark or experiment reported in the paper.",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Argued qualitatively to better meet cognitive time-scale requirements and thus provide more realistic generalization in tasks requiring rapid integration of symbolic and statistical information; no quantitative measures reported.",
            "interpretability_properties": "Because declarative structures are part of the architecture, they can support explanation generation and interpretable state representations, while numeric components may remain less transparent; the architecture-level design can increase interpretability relative to purely procedural systems by exposing symbolic state.",
            "limitations_or_failures": "Paper states that the sufficiency of classical physical symbol systems for cognitive architectures fails due to the need for numeric processing within the architecture; it also leaves open whether purely neural/hybrid networks alone (without symbolic architectural scaffolding) will suffice.",
            "theoretical_framework": "Built on the Common Model of Cognition (CMC) and empirical argumentation about time-scale requirements; frames hybrid cognitive architectures as necessary to reconcile symbolic compositionality and in-time numeric processing.",
            "uuid": "e473.1"
        },
        {
            "name_short": "CMC",
            "name_full": "Common Model of Cognition",
            "brief_description": "A proposed consensus computational framework of core cognitive components that explicitly allows symbols with quantitative metadata and advocates hybrid processing at cognitive time scales.",
            "citation_title": "A standard model of the mind: Toward a common computational framework across artificial Intelligence, cognitive science, neuroscience, and robotics.",
            "mention_or_use": "use",
            "system_name": "Common Model of Cognition (CMC)",
            "system_description": "A cognitive-architecture-level framework identifying core modules (e.g., declarative memory, procedural memory, perception, action) and endorsing hybrid symbols (symbolic structures augmented with quantitative metadata) to support cognitive tasks; used as part of the theoretical basis for the HSSH and HCAH.",
            "declarative_component": "Declarative memory and symbolic structures that can represent compositional symbolic information; symbols can designate objects or structures and are used for high-level cognitive representations.",
            "imperative_component": "Procedural modules and numeric metadata associated with symbols (activations, probabilities) enabling statistical processing, learning, and real-time modulation of symbolic processing.",
            "integration_method": "Symbols augmented with quantitative metadata that modulates processing within cognitive modules; tight architectural integration so that statistical/numeric processing operates on the same time scales as symbolic computation.",
            "emergent_properties": "Combined ability to support cognitive phenomena requiring both symbolic reasoning (planning, problem solving) and rapid statistical/perceptual processing; supports hybrid behaviors like symbol-guided perception influenced by activations/metadata.",
            "task_or_benchmark": "Intended as a general cognitive framework for human-like cognition, not evaluated on a single benchmark within this paper.",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "CMC is asserted to facilitate architecture-level generalization by ensuring numeric processing is available at cognitive time scales alongside symbolic processing, which should improve performance on tasks mixing perception/statistics and symbolic reasoning; no quantitative evidence in this paper.",
            "interpretability_properties": "Declarative modules provide interpretable symbolic representations and potential explanations; quantitative metadata can be inspected but may be less interpretable without mapping to symbolic constructs.",
            "limitations_or_failures": "Paper notes that CMC's allowance for numeric metadata complicates the classical PSSH sufficiency claim and that not all details of hybridization/implementation are resolved; empirical validation across all cognitive phenomena remains ongoing.",
            "theoretical_framework": "Presented as a consensus model/framework for integrating symbolic and numeric processing in cognitive architectures; serves as a key theoretical support for HSSH/HCAH.",
            "uuid": "e473.2"
        },
        {
            "name_short": "Sigma",
            "name_full": "Sigma cognitive architecture",
            "brief_description": "A cognitive architecture that emphasizes hybrid symbol representations and denies the need for all symbols to support arbitrary composition, aligning with the paper's redefinition of symbols.",
            "citation_title": "The Sigma cognitive architecture and system: Towards functionally elegant grand unification.",
            "mention_or_use": "use",
            "system_name": "Sigma cognitive architecture",
            "system_description": "An implemented cognitive architecture that integrates symbolic and numeric processing, allowing symbols that do not necessarily support arbitrary composition and incorporating numeric metadata and probabilistic processing within a unifying factor-graph/graphical model-like substrate (as described in the cited Sigma work).",
            "declarative_component": "Symbolic representational elements and symbol structures used for high-level cognitive state and reasoning (the architecture does not require every symbol to support full compositionality).",
            "imperative_component": "Numeric/statistical processing mechanisms embedded in the architecture (belief propagation / probabilistic inference style computations and numeric metadata) that operate within the architecture's processing loop.",
            "integration_method": "Tight architectural integration where symbolic structures coexist with numeric inference mechanisms and metadata; Sigma uses a unifying graphical-model-inspired substrate (factor-graph-like approaches) to blend symbolic/state descriptions with numeric processing (see Sigma citation for implementation details).",
            "emergent_properties": "Enables functional unification of classical symbolic cognitive functions with probabilistic/numeric inference, supporting more realistic cognitive-time-scale behaviors and mixed symbolic-statistical reasoning across modules.",
            "task_or_benchmark": "Discussed at architecture level; specific Sigma experiments/benchmarks are in the referenced Sigma paper rather than this paper.",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Architectural claims suggest improved real-time integration of symbolic and statistical processes and better alignment with human-like cognition; no direct quantitative evidence in this paper.",
            "interpretability_properties": "Because Sigma exposes symbolic structures and uses symbolic state representations, it can support interpretability/explanations at the symbolic level while embedding numeric inference internally.",
            "limitations_or_failures": "Paper cites Sigma as an example but does not detail limitations; general issues include complexity of integrating inference and symbolic mechanisms and potential limits of composition in specific neural realizations.",
            "theoretical_framework": "Sigma is presented as an architectural instantiation exemplifying the HCAH principles; theoretical rationale is unification of symbolic and numeric processing within a single architecture.",
            "uuid": "e473.3"
        },
        {
            "name_short": "PGMs / SRL",
            "name_full": "Probabilistic Graphical Models / Statistical Relational Learning",
            "brief_description": "Hybrid systems that combine symbolic relational structure (relations, logic-like predicates) with probabilistic numeric reasoning, serving as canonical hybrid approaches in AI.",
            "citation_title": "Probabilistic Graphical Models: Principles and Techniques.",
            "mention_or_use": "mention",
            "system_name": "Probabilistic Graphical Models / Statistical Relational Systems",
            "system_description": "Formalisms that represent dependencies among variables using graphs (Bayesian networks, Markov networks) and that in statistical-relational variants combine logical/relational symbolic structure with probabilities to perform inference and learning under uncertainty.",
            "declarative_component": "Relational/logical structure (predicates, relations, symbolic schemas) used to express entities and relationships; in SRL this is formal logic-like structure (e.g., first-order templates) that constrain probabilistic models.",
            "imperative_component": "Probabilistic numeric computation (inference algorithms such as belief propagation, sampling, parameter learning, gradient-based estimation) operating over the symbolic relational scaffold.",
            "integration_method": "Tight formal integration where symbolic relational templates define factorization structure for probabilistic models (e.g., Markov logic networks, probabilistic relational models); numeric inference is performed on graphs grounded from symbolic templates.",
            "emergent_properties": "Combines structured relational reasoning with robust statistical handling of noise and uncertainty; supports learning and probabilistic inference over rich relational domains that pure symbolic logic (no uncertainty) cannot handle and pure numeric models (no relational structure) cannot compactly represent.",
            "task_or_benchmark": "Used in relational probabilistic inference, structured prediction tasks, and domains requiring uncertainty over relational data; paper cites PGMs as a general example rather than giving a specific benchmark.",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "SRL/PGMs can generalize by exploiting relational structure and shared parameters across entities; they often generalize better than purely propositional numeric models in relational domains, but this paper does not provide quantitative comparisons.",
            "interpretability_properties": "Symbolic relational templates and graph structure provide interpretable structure and explanations for probabilistic inferences; numeric inference details may remain complex but the high-level relational structure aids explainability.",
            "limitations_or_failures": "Scalability and inference complexity in large relational domains; requires careful modeling to capture complex compositions that modern deep learning handles more flexibly; paper treats PGMs as already hybrid and not a direct challenge to HSSH.",
            "theoretical_framework": "Grounded in probabilistic graphical model theory and extensions to statistical-relational learning; presented as a canonical example of hybrid symbolic-numeric integration.",
            "uuid": "e473.4"
        },
        {
            "name_short": "FFNN_as_hybrid",
            "name_full": "Feedforward Neural Networks interpreted as Hybrid Symbol Systems",
            "brief_description": "The paper analyzes standard feedforward neural networks (multi-layer perceptrons) and interprets nodes, links, and vectors as hybrid symbols where nodes are symbol-locations with quantitative metadata and links/nodes procedurally designate processes.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "Feedforward neural network (interpreted as a hybrid symbol system)",
            "system_description": "Standard feedforward architectures (input layer, hidden layers, output layer) where input/output vectors are treated as composed hybrid symbol structures (locations+activations), internal nodes and links are hybrid symbols with numeric metadata (activations, weights) that procedurally designate the operations performed (multiplication by weights, summation, nonlinear transformation); encoding/decoding map between external symbolic tokens and vector encodings.",
            "declarative_component": "Declarative designation occurs at input (and decoded output) hybrid symbol structures: encoded vectors internally designate words/letters/meanings; these are notated as declarative symbols realized as vector structures rather than explicit logical formulas.",
            "imperative_component": "Imperative procedural components are the per-link multiplication and per-node summation + nonlinear transformation operations, implemented as weighted connections and activation functions (i.e., standard neural computation).",
            "integration_method": "Tight internal integration: the same neural substrate is interpreted as carrying hybrid symbols (locations) with numeric metadata; symbolic designation resides in the same vectors processed by the imperative computations rather than being a separate module. The paper describes encoding/decoding as external processes that map between symbol tokens and network vectors.",
            "emergent_properties": "Provides a re-interpretation where distributed vector processing simultaneously implements symbolic designation at I/O and procedural numeric transformations internally; this yields emergent hybrid behavior such as vector-based compositional designation (epiphenomenal 'words' arising from patterns of hybrid symbols) and the ability to perform learned mappings between symbolic tokens via numeric computation.",
            "task_or_benchmark": "Illustrated with a conceptual paired-associates example mapping input words to output words via encoding/decoding; no empirical benchmark or numeric evaluation provided.",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Paper argues qualitatively that neural networks, when viewed as hybrid symbol systems, inherit statistical generalization properties of neural learning while providing symbolic designation at I/O; no quantitative out-of-distribution or compositional generalization metrics are reported.",
            "interpretability_properties": "Input/output hybrid symbols provide interpretable endpoints (encoded tokens), but internal nodes/weights/procedures are procedural and not declaratively designated, limiting internal interpretability; decoding is required to map internal activations back to symbolic tokens.",
            "limitations_or_failures": "Acknowledges that many neural networks do not display full classical symbolic compositionality and that some tasks (e.g., combinatorial board games) have required explicit search/state-space methods in addition to neural components; internal meanings are not fixed, complicating symbolic explanation.",
            "theoretical_framework": "Presents an interpretive framework that treats neural network elements as hybrid symbols (atoms with optional designation/composition/metadata) and uses this to argue that neural networks count as hybrid symbol systems under the HSSH.",
            "uuid": "e473.5"
        },
        {
            "name_short": "NN + search (AlphaZero)",
            "name_full": "Neural networks combined with explicit state-space search (e.g., AlphaZero)",
            "brief_description": "An example class of hybrid systems where neural networks provide evaluation/policy and explicit search (Monte Carlo tree search / state-space search) provides dynamic composition and combinatorial search capabilities.",
            "citation_title": "A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play.",
            "mention_or_use": "mention",
            "system_name": "Neural network + explicit state-space search hybrid (e.g., AlphaZero style)",
            "system_description": "Hybrid architectures where learned neural policies/value networks provide fast evaluation and priors, while an external symbolic-like procedural search algorithm (e.g., Monte Carlo tree search / explicit state-space search) supplies dynamic composition and combinatorial planning/search.",
            "declarative_component": "The search/state-space representation and explicit search procedure provide symbolic-like structured search over discrete game states (state representations, legal-move generation, tree structure).",
            "imperative_component": "Deep neural networks (policy/value networks) trained by reinforcement/self-play provide numeric evaluation and move priors; the search algorithm is procedural and algorithmic (MCTS).",
            "integration_method": "Modular/loosely coupled integration: neural networks supply heuristic evaluations and priors to the search algorithm at each node; the search module uses these numeric signals to guide symbolic/combinatorial exploration (tight coupling during runtime but modular in design).",
            "emergent_properties": "Together they achieve high-level combinatorial play that neither component (pure learned network without search, nor pure search with handcrafted evaluation) could match alone at the same efficiency: neural nets provide strong heuristics, search supplies systematic compositional planning over game trees.",
            "task_or_benchmark": "Combinatorial board games (chess, shogi, Go) as exemplified by AlphaZero and related systems referenced in the paper.",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Empirically in cited literature these hybrids generalize across game positions via learned heuristics plus planning, but this paper only references the phenomenon qualitatively and notes that neural networks alone have not solved such combinatorial games without explicit search.",
            "interpretability_properties": "Search traces and explicit state expansions provide interpretable step-by-step rationales for moves (tree of explored continuations), while neural evaluations are less interpretable but can be queried at decision points.",
            "limitations_or_failures": "Paper notes reliance on dynamic composition via explicit state-space search for achieving combinatorial game mastery; implies limitations of pure neural composition for such tasks.",
            "theoretical_framework": "Portrays this as an exemplar of modular hybridization where division of labor places statistical evaluation in neural modules and combinatorial planning in algorithmic search modules.",
            "uuid": "e473.6"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Dimensions of neural-symbolic integration-a structured survey.",
            "rating": 2,
            "sanitized_title": "dimensions_of_neuralsymbolic_integrationa_structured_survey"
        },
        {
            "paper_title": "Probabilistic Graphical Models: Principles and Techniques.",
            "rating": 2,
            "sanitized_title": "probabilistic_graphical_models_principles_and_techniques"
        },
        {
            "paper_title": "The Sigma cognitive architecture and system: Towards functionally elegant grand unification.",
            "rating": 2,
            "sanitized_title": "the_sigma_cognitive_architecture_and_system_towards_functionally_elegant_grand_unification"
        },
        {
            "paper_title": "A standard model of the mind: Toward a common computational framework across artificial Intelligence, cognitive science, neuroscience, and robotics.",
            "rating": 2,
            "sanitized_title": "a_standard_model_of_the_mind_toward_a_common_computational_framework_across_artificial_intelligence_cognitive_science_neuroscience_and_robotics"
        },
        {
            "paper_title": "Deep Learning.",
            "rating": 2,
            "sanitized_title": "deep_learning"
        },
        {
            "paper_title": "The Physical Symbol System Hypothesis: Status and prospects",
            "rating": 1,
            "sanitized_title": "the_physical_symbol_system_hypothesis_status_and_prospects"
        },
        {
            "paper_title": "A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play.",
            "rating": 1,
            "sanitized_title": "a_general_reinforcement_learning_algorithm_that_masters_chess_shogi_and_go_through_selfplay"
        }
    ],
    "cost": 0.01523475,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Rethinking the Physical Symbol Systems Hypothesis</p>
<p>Paul S Rosenbloom rosenbloom@usc.edu 
Department of Computer Science
University of Southern California
90089Los AngelesCAUSA</p>
<p>Rethinking the Physical Symbol Systems Hypothesis
*** Prepublication version of article accepted at AGI 2023. ***Physical Symbol SystemsHybrid Symbol SystemsCognitive ArchitecturesNeural Networks
It is now more than a half-century since the Physical Symbol Systems Hypothesis (PSSH) was first articulated as an empirical hypothesis. More recent evidence from work with neural networks and cognitive architectures has weakened it, but it has not yet been replaced in any satisfactory manner. Based on a rethinking of the nature of computational symbolsas atoms or placeholdersand thus also of the systems in which they participate, a hybrid approach is introduced that responds to these challenges while also helping to bridge the gap between symbolic and neural approaches, resulting in two new hypotheses, one that is to replace the PSSH and other focused more directly on cognitive architectures.</p>
<p>Introduction</p>
<p>Our current understanding of the role of physical symbol systems in artificial intelligence (AI) is grounded in the pioneering work of Newell and Simon [1][2][3], although as they point out the roots go back much further in philosophymost notably in logiccomputer science, linguistics, literature, and the arts. Such systems, and their culmination in the Physical Symbol Systems Hypothesis (PSSH) are reviewed in Section 2.</p>
<p>Many critiques of the PSSH have been proposed since it was first introduced, with some that have easily been refuted and others that have lingered (Section 3). Here, two are taken up that have remained compelling, before hybrid symbol systems of a particular sort are explored as a response to them (Section 4). As part of this, the notion of symbol systems is rethought, starting with a variant definition of what it means to be a computational symbol that is grounded in the Common Model of Cognition (CMC) [4] and the Sigma cognitive architecture [5]. Two new hybrid hypotheses result, one that offers an alternative to the PSSH and the other that focuses more specifically on cognitive architectures.</p>
<p>Demonstrating that neural networks are themselves hybrid symbol systems of this sort (Section 5), rather than being limited to the numeric component of a coarse-grained combination of symbolic and numeric processing, helps to bridge the gap between symbolic and neural approaches while enabling recent successes with neural networks to be weighed in a positive manner in evaluating hypotheses concerning symbol systems, rather than the former necessarily serving as a challenge to the latter.</p>
<p>The overall result, as discussed further in Section 6, is a novel way of thinking about symbol systems and the fundamental hypotheses concerning them; the introduction of a particular form of hybrid symbol system and the appropriate hypotheses concerning it; and an understanding of how neural networks are examples, rather than counterexamples, of this form of symbol system. The hope is that this all helps cut the Gordian Knot that has resulted from past discussions on these topics.</p>
<p>Proposing hybrid or neuro-symbolic systems is certainly nothing new. Many approaches have already been investigatedsee, e.g., [6] and [7] for overviews, and [8] for an earlier discussion of the PSSH and the relevance of hybrid systems. But the point here is to introduce a particular take on hybrid symbol systems that is in service of an appropriate rethinking of the Physical Symbol Systems Hypothesis. The approach is broader than neuro-symbolic, as it also includes hybrid systems that span other numeric paradigms, such as probabilities. In addition, it spans both tightly coupled and loosely coupled approaches to combining symbolic and numeric processing.</p>
<p>Physical Symbol Systems</p>
<p>According to the traditional view, symbols are distinct patterns in the physical world that can be composed into expressions, or symbol structures. Processes are then defined on these symbol structures that can create, modify, reproduce, and destroy them. An expression designates an entity, whether internal or external, if the expression's use depends on the nature of the entity. An expression is interpreted if it designates an internal procedure that is then executed. The physicality of such symbol systems reflects that they are natural, in obeying the laws of physics and being amenable to engineering; and that they aren't limited to what is in human minds, or even necessarily based on the same kinds of symbols that have traditionally been imputed to humans. Given composition, designation, and interpretation, along with the appropriate processes, physical symbol systems provide a form of universal computation. There are certainly more details in the various papers, but this provides the essence of what can now be considered the classical notion of a physical symbol system.</p>
<p>The Physical Symbol Systems Hypothesis (PSSH) then states that: A physical symbol system has the necessary and sufficient means for general intelligent action. This hypothesis was introduced as an empirical generalization rather than a theorem. Evidence for sufficiency stemmed from the universality of symbol systems and the success of such systems built as of then. Evidence for necessity stemmed from noting that the one natural system exhibiting such intelligent behaviorthat is, humansappeared to be such a system, and from the lack of alternative approaches that were nearly as successful. Newell, for example mentions that "These advances far outstrip what has been accomplished by other attempts to build intelligent mechanisms, such as the work in building robots driven directly by circuits; the work in neural nets, or the engineering attempts at pattern recognition using direct circuitry and analogue computation." [3].</p>
<p>He went on to state that "In my own view this hypothesis sets the terms on which we search for a scientific theory of mind." and "The physical symbol system is to our enterprise what the theory of evolution is to all biology, the cell doctrine to cellular biology, the notion of germs to the scientific concept of disease, the notion of tectonic plates to structural geology."</p>
<p>Critiquing the Physical Symbol Systems Hypothesis</p>
<p>It has now been over fifty years since the PSSH was first articulated, with numerous critiques and defenses occurring in the intervening years. Nilsson [8], e.g., lists four general types of critiques with his responses to them (in italics here), which in brief are:</p>
<ol>
<li>
<p>Lack of embodiment/grounding. This is a misunderstanding as the PSSH already includes this.</p>
</li>
<li>
<p>Non-symbolic/analog processing. Include numbers; that is, make the systems hybrid.</p>
</li>
<li>
<p>Brain-style versus computation-style (i.e., brains are not computers). The brain is computational.</p>
</li>
</ol>
<p>The mindlessness of much of what appears to be intelligent behavior.</p>
<p>Mindless constructs only yield mindless behavior.</p>
<p>In this section two particular critiques are considered, based on new empirical evidence in the form of the recent successes of deep learning [9], and to a lesser extent probabilistic graphical models (PGMs) [10], plus work on the CMC. One critique, aligned with Nilsson's second, challenges its sufficiency and the other its necessity.</p>
<p>The sufficiency challenge focuses on the lack of numeric processingi.e., calculations on quantities -in the PSSH. Nilsson's response is to shift to hybrid systems that include both symbols and numbers. In a sense, this isn't logically necessary, as the universality of symbol systems implies that, as with any modern digital computer, they can implement algorithms for numeric processing. However, universality is weaker than what was originally proposed, as it omits grounding sufficiency in the successes of existing symbolic AI systems. Given the range of general intelligent action that has been shown to proceed more effectively with numeric processing, whether in the form of probabilities or activations, the success of purely symbolic systems no longer provides compelling empirical evidence itself for the sufficiency of symbols on their own. Thus, we are left with a weakened form of sufficiency for the PSSH, based solely on universality. Hybrid systems have the potential to restore the stronger sense of sufficiency (Section 4). They also support a more stringent sufficiency hypothesis that arises when the concern is more particularly with cognitive architectures [11]; that is, models of the fixed structures and processes that yield a mind [12].</p>
<p>The necessity challenge is rooted directly in how neural networks now provide a better approach for many problems related to intelligent action. Successes with PGMs can be considered here as well, although they are already hybrid systems that add probabilities to classical symbol systems, particularly in their most general form as statistical relational systems [13], so they do not directly challenge the necessity of physical symbol systems. In contrast, deep learning has the potential to provide an alternative that completely overturns the necessity argument. In Section 5, this challenge is approached via a demonstration that, given the rethinking of symbol systems in Section 4, neural networks are themselves instances of hybrid symbol systems. This approach avoids the need to resolve the contentious question of whether or not neural networks have or need traditional symbols, a question that appears unresolvable, at least to me, without additional evidence.</p>
<p>Rethinking Symbol Systems</p>
<p>This section leverages the four-step methodology of essential analysis [14] to yield a fresh understanding of symbols and symbol systems: (1) strip out many of the elaborations that are normally part of a topic's definition, and which are often a source of dissonance among researchers and communities, to yield its essence; (2) use what has been stripped out, and possibly more, in specifying a definitional space of variations on the topic; (3) populate this space with exemplars that flesh it out; and (4) derive novel implications from the results of the first three steps.</p>
<p>Step three is downplayed here due to lack of space, while step four introduces two new hybrid symbol systems hypotheses.</p>
<p>The focus here is in particular on the notion of symbol as it is used computationally rather than as it is used in the humanities and arts. For example, [15] defines a symbol as "something used for or regarded as representing something else; a material object representing something, often something immaterial; emblem, token, or sign." This focuses on an abstract notion of designation or aboutness, which has elsewhere been considered an important part of the essence of a theory [14]. Computationally, the essence of a symbol is proposed to be an atom that is: (1) indecomposable into other atoms; and (2) distinct from other atoms. McDermott informally introduced the notion of a symbol as a placeholder [16]. Although yielding different connotations, this notion is compatible with that of an atom here.</p>
<p>This essence retains the classical notion of a computational symbol being a primitive element that can be distinguished from other such elements but eschews the need for both physicality and symbols being structured as patterns. There were good reasons at the time to emphasize physicalityto counter both Cartesian dualism and the notion that only humans could use symbolsbut these battles have already been won, at least in my judgement, so this explicit emphasis on physicality is now dispensable.</p>
<p>Pattern comparison is one way to determine whether two atoms are distinct. Yet, such a notion need not be definitional if it is just used to compare symbols. If symbols are considered as types (rather than tokens)a notion implicit in the traditional definitionpatterns are simply intensional definitions of symbols. An extensional alternative defines each symbol in terms of a set of tokens, with each token in a set considered to be indistinct from other tokens in the same set and distinct from tokens in other sets.</p>
<p>The classical notion of symbol also includes composabilityinto symbol structures or expressionsdesignation, and interpretation. The first of these is effectively assumed to be part of the very nature of symbols, whereas the latter two are additional properties necessary to enable the classical form of physical symbol systems. The essential definition of a symbol introduced here includes none of these three notions; that is, all are optional. Therefore, any system that includes even these minimal, atomic forms of symbols can be considered a symbol system of some sort. Fig. 1 structures these optional properties, plus a bit more, into a small tree. According to this perspective, a symbol may be composable into expressions (aka symbol structures). It may also designate; that is, stand in for something else. A designation is procedural if it is about a process. This is the classical notion of interpretation, when combined with the ability to execute the designated process.</p>
<p>A procedural symbol, according to this definition, designates a process rather than being part of the process itself. If the process is itself a symbol structure it will contain symbols, but they themselves may be of any type. A designation is declarative if it is about an objectessentially anything other than a processwhich may be internal to the system or external to it, with the latter relating to grounding. This corresponds to the classical notion of designation when contrasted with interpretation. Beyond this difference in what is designated, there is no intent to impute any other aspects of the classical procedural versus declarative distinction here.</p>
<p>Symbols in a classical symbol system support all of these properties, enabling them to exhibit computational universality. Whether systems in which some or all of the symbols lack some of these properties provide anything like universal computation would necessarily depend on the details of the individual systems.</p>
<p>The CMC, an attempt at developing a consensus on what is needed for human-like cognitioni.e., human cognition and similar forms of artificial cognitiontook a step towards such an essence by dropping the necessity of designation, and thus also of interpretation, stripping symbols down to primitive elements that only support composability into symbol structures. Although designation somewhere in a system seems necessary for it to be either meaningful or operational, it is not necessary for all symbols. The CMC also associated quantitative metadata with such symbols and structureswhich provide the datato modulate how they are processed. Such combinations can be considered as hybrid symbols or structures. 1 Considering hybrid of this sort as a third optional property of symbols leads to Fig. 2.</p>
<p>The CMC went on to argue for a different form of weakening of the sufficiency aspect of the PSSH. While still agreeing that classical symbol systems, as universal computational systems, are sufficient in principle for intelligent behavior, it denied that they are sufficient when time scales are relevant, such as in cognitive architectures. In particular, if statistical processing must occur on the same time scale as symbolic processing in such an architecture, then implementing the former in terms of the latteras the universality argument for sufficiency impliesis insufficient. Thus, the CMC implies the need for numeric and symbolic processing on the same time scale. The Sigma cognitive architecture [5] goes a step further by denying the need for all symbols to support arbitrary forms of composition, thus implicitly yielding the essence made explicit here. Now, given this explicit articulation of the essence of a symbol plus its tree of variations, the Hybrid Symbol Systems Hypothesis (HSSH) can be stated as:</p>
<p>Hybrid symbol systems are necessary and sufficient for general intelligent action.</p>
<p>If the sufficiency clause of the PSSH is valid then so must be the comparable clause in the HSSH, at least for hybrid symbol systems that are universal. However, the HSSH responds to the PSSH sufficiency challenge by including numbers, as suggested in [8]. Necessity of the HSSH is not implied by the corresponding clause in the PSSH. Instead, the HSSH responds to the PSSH necessity challenge by coopting the successes of neural networks (Section 5).</p>
<p>The Hybrid Cognitive Architectures Hypothesis (HCAH) then states:</p>
<p>Hybrid symbol systems are necessary and sufficient for cognitive architectures.</p>
<p>This hypothesis is clearly related to the HSSH, but it matters in itself because the comparable hypothesisperhaps called the Physical Cognitive Architectures Hypothesis (PCAH)fails. Thus, the sufficiency side of the PCAH is invalid irrespective of what might be true with respect to necessity. As with the HSSH, sufficiency for the HCAH need not hold for all hybrid symbol systems, but it must hold for at least some. As with the PSSH and the HSSH, the HCAH is an empirical generalization. Both sides of the argument are now supported by the architectural successes of classical 1 The CMC also allows numeric data, consideration of which is beyond the scope of this paper. symbol systems, neural systems, and traditional hybrid systems such as PGMs. Both sides are further bolstered by how the CMC itself is a hybrid symbol system.</p>
<p>Neural Networks as Hybrid Symbol Systems</p>
<p>What makes neural networks hybrid symbol systems, as defined here, rather than simply the numeric component of a larger system that also includes a symbolic component, such as [17]? To keep things simple, the focus here is limited to standard feedforward neural networks, consisting of multiple layers of nodes and links, where nodes have activations, links connect pairs of nodes across levels and have weights, and processing occurs by multiplying input activations along links by the links' weights and then nonlinearly transforming the sums of these weighted inputs.</p>
<p>To be a bit more specific, let's assume a small network for paired associates that maps an input word to an output word. Fig. 3 exemplifies this via a completely connected network with 6-unit input and output layersyielding a 6-dimensional vector of activations for eachand 2 intermediate layers, each with 3 units. Words map consistently to input and output vectors via encoding and decoding processes that are external to the network. These processes may be based on an arbitrary or random assignment of vectors to words or some form of more sophisticated embedding process, such as in [18].</p>
<p>The focus here, however, is on analyzing the forward processing in the network itself to show how it amounts to a hybrid symbol system. It should be possible to extend such an analysis to encoding and decoding processes, as well as to learning in neural networks, but this simple example is sufficient to establish the precedent.</p>
<p>First consider the nodes in the input layer of the network, now shown at the top of Fig. 4 as locations within a vector of nominal activations. Such nodes can be seen as hybrid symbolssymbolic nodes (i.e., locations) with activations as their quantitative metadatathat exhibit a limited form of composability in yielding the hybrid symbol structure that is the input vector. In contrast to the traditional interpretation of distributed representationswhere nodes are subsymbolic, or microfeatures, with symbols only arising as patterns over these elementshere the individual nodes are themselves hybrid symbols that do not themselves designate, with patterns arising as structures of these hybrid symbols.  This hybrid symbol structure does then internally designate a word structure that has one location per letter (middle of Fig. 4). The metadata in the word structure is not shown as it is irrelevant to this analysis. What does matter is that declarative symbols in this word structure externally designate particular letters of the alphabet, in this case making up Allen Newell's first name (bottom of Fig. 4). The word as whole then externally designates its meaning, iconified to the right of Fig. 4 via an image of him.</p>
<p>Key to this all working is that it isn't just the data aspect of hybrid symbols and structures that can designate, but the entirety of the hybrid symbols and structuresincluding their metadatathat can do so, just as is traditionally assumed for vectors in distributed representations [19]. The word itself is epiphenomenal to the feedforward network processing hereonly the hybrid symbol structure at the top of Fig. 4, as yielded by encoding, actually participates. As put in [20], "the node labels in a Connectionist machine are not part of the causal structure of the machine."</p>
<p>The internal nodes in the network are also hybrid symbols but without declarative designations, fitting the intuition that there are no fixed meanings inside the network. Instead, internal nodesand linksprocedurally designate fixed processes. Consider link in Fig. 3, which points from node 1 to node 2. This link is a hybrid symbol structure composed from these two hybrid symbols, with a weight as its metadata. It procedurally designates a process that multiplies the activation arriving from 1 by this weight. Internal nodes such as 2 then procedurally designate processes that sum all of their inputsin this case, from 1 and any other nodes linked to it from the proceeding layerand then nonlinearly transform the results.</p>
<p>The last part of the analysis concerns the output nodes. Perhaps surprisingly, they too do not declaratively designate anything here. Instead, they procedurally designate the same summation and transformation process as the internal nodes. It is not until postprocessingthat is during decodingthat this reverse mapping occurs.</p>
<p>This analysis demonstrates that a feedforward neural network is a hybrid symbol system, as defined here. As such, it makes the case that the shift from the PSSH to the HSSH enables coopting neural-network successes as evidence for both the sufficiency and necessity of hybrid symbol systems rather than as counterexamples to them.</p>
<p>But what type of hybrid symbol system does this type of neural network yield? It provides limited forms of declarative designation (at input nodes), procedural designation (at all but input nodes), and composition (via vectors within a level and links across levels). Yet, other forms of neural networks do go beyond this. To name just two common examples, both convolutional networks (e.g., [21]) and transformers [22] include additional forms of composition. The flexibility of composition seen in the output of transformer-based generative networks [23] is in fact quite compelling. Some forms of neural networks are also known to support universal computation (see, e.g., [24]). Yet no neural network to date has solved combinatorial board games without the dynamic composition yielded by explicit state-space search (as seen, e.g., in both [25] and [26]). So, the overall story is complex, dependent on the exact nature of the neural networks considered, and still not completely understood.</p>
<p>Conclusion</p>
<p>Leveraging essential analysis, symbols are (re)defined as atoms or placeholders, and a space of variations is defined for symbols, symbol structures, and symbol systems. This includes the classical traits of compositionality and designation, plus hybridness and additional sub-traits under designation (such as interpretation). In response to lingering challenges to the Physical Symbol System Hypothesis (PSSH), two new hypotheses have then been introduced that focus on the resulting hybrid symbol systems:</p>
<p>Hybrid Symbol Systems Hypothesis (HSSH):</p>
<p>Hybrid symbol systems are necessary and sufficient for general intelligent action.</p>
<p>Hybrid Cognitive Architectures Hypothesis (HCAH):</p>
<p>Hybrid symbol systems are necessary and sufficient for cognitive architectures.</p>
<p>The HSSH is intended as a replacement for the PSSH, based on evidence accumulated since the latter was introduced as an empirical hypothesis a half-century ago. Given this recent body of evidence, there is a sense in which the PSSH still holds, but it is a weaker sense. The HSSH recaptures the originally intended strength while adding further to it by reinterpreting neural networks as compatriotsthat is, as hybrid symbol systems themselvesrather than as competitors. The result also helps chip away in a rather fine-grained manner at the overall divide between symbolic and neural systems.</p>
<p>The HCAH is a more stringent claim than either the original PSSH or the HSSH in that it concerns cognitive architectures rather than general intelligent action. Evidence accumulated over the past decades has shown that traditional physical symbol systems fail with respect to sufficiency for cognitive architectures due to the need for numeric processing within the architectures themselves. The necessity of classical physical symbol systems for cognitive architectures remains an open question, as it is not yet clear whether neural networkswhich although as argued here are hybrid symbol systems but which may not be classical symbol systems or even universal computationallywill prove to be a sufficient alternative on their own for such architectures.</p>
<p>One potential chink in the armor of both of these new hypotheses is the possibility of quantum aspects to intelligence that cannot be captured even by hybrid systems [27]. Should it prove necessary, some thought is already being put into what it would mean to have quantum symbol systems (e.g., [28]).</p>
<p>Fig. 1 .
1Optional properties of symbols.</p>
<p>Fig. 2 .
2Optional properties of symbols from Fig. 1, extended with hybrid.</p>
<p>Fig. 4 .
4Designation relationships among input vector, word vector, letters, and word meaning. Dotted lines reflect internal designation and dashed lines external designation.</p>
<p>Fig. 3 .
3Simple network for paired associates.
AcknowledgementsI would like to think John Laird, Christian Lebiere, and Andrea Stocco for helpful comments and discussions on this general topic and this particular paper.
Human Problem Solving. A Newell, H A Simon, Prentice-HallEnglewood Cliffs, NJNewell, A., Simon, H. A.: Human Problem Solving. Prentice-Hall, Englewood Cliffs, NJ (1972).</p>
<p>Computer science as empirical inquiry: Symbols and search. A Newell, H A Simon, Comm. of the ACM. 193Newell, A., Simon, H. A.: Computer science as empirical inquiry: Symbols and search, Comm. of the ACM, 19(3), 113-126 (2017).</p>
<p>Physical symbol systems. A Newell, Cog. Sci. 42Newell, A.: Physical symbol systems, Cog. Sci., 4(2), 135-183 (1980).</p>
<p>A standard model of the mind: Toward a common computational framework across artificial Intelligence, cognitive science, neuroscience, and robotics. J E Laird, C Lebiere, P S Rosenbloom, AI Mag. 384Laird, J. E., Lebiere, C., Rosenbloom, P. S.: A standard model of the mind: Toward a common computational framework across artificial Intelligence, cognitive science, neuroscience, and robotics, AI Mag., 38(4), 13-26 (2017).</p>
<p>The Sigma cognitive architecture and system: Towards functionally elegant grand unification. P S Rosenbloom, A Demski, V Ustun, Journal of Artificial General Intelligence. 71Rosenbloom, P. S., Demski, A., Ustun, V.: The Sigma cognitive architecture and system: Towards functionally elegant grand unification, Journal of Artificial General Intelligence, 7(1), 1-103 (2016)</p>
<p>Integrating symbol-oriented and sub-symbolic reasoning methods into hybrid systems. F J Kurfess, From Synapses to Rules: Disc. Sym. Rules from Neural Proc. Data. Apolloni, B., Kurfess, F.New York, NYKluwerKurfess, F. J.: Integrating symbol-oriented and sub-symbolic reasoning methods into hybrid systems. In: Apolloni, B., Kurfess, F. (eds.) From Synapses to Rules: Disc. Sym. Rules from Neural Proc. Data, pp. 275-292. Kluwer, New York, NY (2002).</p>
<p>Dimensions of neural-symbolic integration-a structured survey. S Bader, P Hitzler, We Will Show Them! Essays in Honour of Dov Gabbay. Artëmov, S. N., Barringer, H., d'Avila Garcez, A. S., Lamb, L. C., Woods J.RickmansworthBader, S., Hitzler, P.: Dimensions of neural-symbolic integration-a structured survey. In: We Will Show Them! Essays in Honour of Dov Gabbay. Artëmov, S. N., Barringer, H., d'Avila Garcez, A. S., Lamb, L. C., Woods J. (eds.), pp. 167-194. Coll. Pubs., Rickmansworth (2005).</p>
<p>Years of AI: Essays Dedicated to the 50 th Anniversary of AI. N Nilsson, Lungarella, M., Iida, F., Bongard, J., Pfeiffer, R.Springer50BerlinThe Physical Symbol System Hypothesis: Status and prospectsNilsson, N.: The Physical Symbol System Hypothesis: Status and prospects. In Lungarella, M., Iida, F., Bongard, J., Pfeiffer, R. (eds.) 50 Years of AI: Essays Dedicated to the 50 th Anniversary of AI. Springer, Berlin (2007).</p>
<p>I J Goodfellow, Y Bengio, A Courville, Deep Learning. Cam., MAMIT PressGoodfellow, I. J., Bengio, Y., Courville, A.: Deep Learning. MIT Press, Cam., MA (2016).</p>
<p>Probabilistic Graphical Models: Principles and Techniques. D Koller, N Friedman, MIT PressCam., MAKoller, D., Friedman, N.: Probabilistic Graphical Models: Principles and Techniques. MIT Press, Cam., MA (2009).</p>
<p>40 years of cognitive architectures: Core cognitive abilities and practical applications. I Kotseruba, J K Tsotsos, AI Rev. 531Kotseruba, I., Tsotsos, J. K.: 40 years of cognitive architectures: Core cognitive abilities and practical applications. AI Rev., 53(1), 17-94 (2020).</p>
<p>Thoughts on architecture. P S Rosenbloom, Proceedings of the 15th Int. Conf. on AGI. the 15th Int. Conf. on AGIChamSpringerRosenbloom, P. S.: Thoughts on architecture. In Proceedings of the 15th Int. Conf. on AGI, pp. 364-373. Springer, Cham (2022).</p>
<p>Statistical relational artificial intelligence: Logic, probability, and computation. L De Raedt, K Kersting, S Natarajan, D Poole, Syn. Lect. on AI and ML. 102de Raedt, L., Kersting, K., Natarajan, S., Poole, D.: Statistical relational artificial intelligence: Logic, probability, and computation, Syn. Lect. on AI and ML, 10(2), 1-189 (2016).</p>
<p>On theories and their implications for cognitive architectures. P S Rosenbloom, In prepRosenbloom, P. S.: On theories and their implications for cognitive architectures. In prep.</p>
<p>. Dictionary.com on Symbol. Dictionary.com on Symbol, https://www.dictionary.com/browse/symbol, last accessed 2023/2/15.</p>
<p>Mind and Mechanism. D V Mcdermott, MIT PressCam., MAMcDermott, D. V.: Mind and Mechanism. MIT Press, Cam., MA (2001).</p>
<p>The CLARION cognitive architecture: Towards a comprehensive theory of the mind. R Sun, The Oxford Handbook of Cognitive Science. Chipman, S.New York, NYOxford Univ. PressSun, R.: The CLARION cognitive architecture: Towards a comprehensive theory of the mind. In: Chipman, S. (ed.) The Oxford Handbook of Cognitive Science, pp. 117-133. Oxford Univ. Press, New York, NY (2017).</p>
<p>Distributed representations of words and phrases and their compositionality. T Mikolov, I Sutskever, K Chen, G S Corrado, J Dean, Advances in Neural Information Processing Systems. 26Mikolov, T., Sutskever, I., Chen, K., Corrado, G. S., Dean, J.: Distributed representations of words and phrases and their compositionality. Advances in Neural Information Processing Systems, 26, 3111-3119 (2013).</p>
<p>Distributed representations. G E Hinton, J L Mcclelland, D E Rumelhart, Parallel Distributed Processing: Explorations in the Microstructure of Cognition. McClelland, J. L., Rumelhart, D. E.Cambridge, MAMIT Press1Hinton, G. E., McClelland, J. L., Rumelhart, D. E.: Distributed representations. In McClelland, J. L., Rumelhart, D. E. (eds.) Parallel Distributed Processing: Explorations in the Microstructure of Cognition, vol. 1, pp. 77-109. MIT Press, Cambridge, MA (1986).</p>
<p>Connectionism and cognitive architecture: A critical analysis. J A Fodor, Z W Pylyshyn, Cog. 281-2Fodor, J. A., Pylyshyn, Z. W.: Connectionism and cognitive architecture: A critical analysis. Cog., 28(1-2), 3-71 (1988).</p>
<p>Convolutional networks for images, speech, and time series. Y Lecun, Y Bengio, The Hand. of Brain Theory and Neural Nets. Arbib, M.Cam., MAMIT PressLeCun, Y., Bengio, Y.: Convolutional networks for images, speech, and time series. In: Arbib, M. (ed.) The Hand. of Brain Theory and Neural Nets. MIT Press, Cam., MA (1995).</p>
<p>Polosukhin, I. Attention is All you Need. A Vaswani, N Shazeer, N Parmar, J Uszkoreit, L Jones, A N Gomez, Ł Kaiser, Proc. of the 31 st Annual Conf. on Neural Info. Proc. Sys. of the 31 st Annual Conf. on Neural Info. . SysVaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, Ł., Polosukhin, I. Attention is All you Need. In Proc. of the 31 st Annual Conf. on Neural Info. Proc. Sys., pp. 5998-6008 (2017).</p>
<p>Language models are few-shot learners. T B Brown, B Mann, N Ryder, M Subbiah, J Kaplan, P Dhariwal, A Neelakantan, P Shyam, G Sastry, A Askell, S Agarwal, A Herbert-Voss, G Krueger, T Henighan, R Child, A Ramesh, D M Ziegler, J Wu, C Winter, C Hesse, M Chen, E Sigler, M Litwin, S Gray, B Chess, J Clark, C Berner, S Mccandlish, A Radford, I Sutskever, D Amodei, Proc. of the 34 th Conf. on Neural Info. Proc. Sys. of the 34 th Conf. on Neural Info. . SysBrown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P. Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert-Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D. M., Wu, J., Winter, C., Hesse, C., Chen, M., Sigler, E., Litwin, M., Gray, S., Chess, B., Clark, J., Berner, C., McCandlish, S., Radford, A., Sutskever, I., Amodei, D. Language models are few-shot learners. In Proc. of the 34 th Conf. on Neural Info. Proc. Sys., pp. 1877-1901)(2020).</p>
<p>Turing computation with neural nets. H T Siegelmann, E D Sontag, Appl. Math. Lett. 46Siegelmann, H. T., Sontag, E. D.: Turing computation with neural nets, Appl. Math. Lett., 4(6), 77-80 (1991).</p>
<p>Temporal difference learning and TD-Gammon. G Tesauro, Comm. of the ACM. 383Tesauro, G.: Temporal difference learning and TD-Gammon. Comm. of the ACM, 38(3), 58-68 (1995).</p>
<p>A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play. D Silver, J Hubert, I Anonoglou, M Lai, A Guez, M Lanctot, L Sifre, D Kumaran, T Graepel, T Lillicrap, K Simonyan, D Hassabis, Science. 3626419Silver, D., Hubert, J., Anonoglou, I., Lai, M., Guez, A., Lanctot, M., Sifre, L., Kumaran, D., Graepel, T., Lillicrap, T., Simonyan, K., Hassabis, D.: A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play. Science, 362(6419), 1140- 1144 (2018).</p>
<p>The Emperor's New Mind: Concerning Computers, Minds, and The Laws of Physics. R Penrose, Oxford Univ. PressOxfordPenrose, R.: The Emperor's New Mind: Concerning Computers, Minds, and The Laws of Physics. Oxford Univ. Press, Oxford (1989).</p>
<p>Quantum Physical Symbol Systems. K B Laskey, Jour. of Log., Lang. and Info. 151-2Laskey, K. B.: Quantum Physical Symbol Systems. Jour. of Log., Lang. and Info., 15(1-2), 109-154 (2006).</p>            </div>
        </div>

    </div>
</body>
</html>