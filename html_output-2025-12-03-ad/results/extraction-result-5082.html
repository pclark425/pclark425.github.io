<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-5082 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-5082</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-5082</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-107.html">extraction-schema-107</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being evaluated or improved for strict logical reasoning, including details of the models, logical reasoning tasks or benchmarks, methods or approaches used, performance results, limitations, and comparisons.</div>
                <p><strong>Paper ID:</strong> paper-257aee73d83a87921fd2d56b524de394dcf6a264</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/257aee73d83a87921fd2d56b524de394dcf6a264" target="_blank">A neural network solves, explains, and generates university math problems by program synthesis and few-shot learning at human level</a></p>
                <p><strong>Paper Venue:</strong> Proceedings of the National Academy of Sciences of the United States of America</p>
                <p><strong>Paper TL;DR:</strong> This work solves university-level mathematics courses and improves upon state-of-the-art, increasing automatic accuracy on randomly sampled questions on a benchmark by order of magnitude.</p>
                <p><strong>Paper Abstract:</strong> Significance We demonstrate that a neural network automatically solves, explains, and generates university-level problems from the largest Massachusetts Institute of Technology (MIT) mathematics courses at a human level. Our methods combine three innovations: 1) using recent neural networks pretrained on text and fine-tuned on code rather than pretrained on text; 2) few-shot learning synthesizing programs that correctly solve course problems automatically; and 3) a pipeline to solve questions, explain solutions, and generate new questions indistinguishable by students from course questions. Our work solves university-level mathematics courses and improves upon state-of-the-art, increasing automatic accuracy on randomly sampled questions on a benchmark by order of magnitude. Implications for higher education include roles of artificial intelligence (AI) in automated course evaluation and content generation.</p>
                <p><strong>Cost:</strong> 0.011</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e5082.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e5082.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being evaluated or improved for strict logical reasoning, including details of the models, logical reasoning tasks or benchmarks, methods or approaches used, performance results, limitations, and comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-3 (text-davinci-002)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>OpenAI GPT-3 (text-davinci-002)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A large autoregressive Transformer language model pre-trained on large text corpora and used here as a baseline for mathematical/logical reasoning; evaluated in zero-shot, few-shot and chain-of-thought prompting settings on university-level math problems and the MATH benchmark.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3 (text-davinci-002)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Autoregressive Transformer language model (GPT-3 family) pre-trained on large-scale text data; used via OpenAI's text-davinci-002 API in zero-shot, few-shot, and chain-of-thought (CoT) prompting setups. No task-specific fine-tuning on code was performed for this model in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>logical_reasoning_task</strong></td>
                            <td>University mathematics course problems (MIT and Columbia) and the MATH benchmark</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Challenging mathematical problem solving requiring symbolic manipulation, multi-step logical reasoning, algebra/calculus/linear algebra/probability problem solving typical of university assignments and high-school competition problems (MATH dataset). Problems include numeric answers, algebraic expressions, plots and vector results; proofs and image-only problems were excluded.</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_approach</strong></td>
                            <td>Evaluated using zero-shot and few-shot prompting; few-shot included adding solved examples and Chain-of-Thought prompting by appending "Let's think step by step." to encourage intermediate reasoning. No program-synthesis or code fine-tuning was used for GPT-3 in these experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>On sampled university course questions: 18.8% automatic solve rate with zero-shot prompting; 30.8% with few-shot + Chain-of-Thought prompting. On sampled MATH benchmark topics: 25.5% zero-shot; 42.2% few-shot + CoT. Evaluations considered a generated solution correct only if program output or answer matched expected solution automatically.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Struggled on university-level and MATH benchmark problems even with CoT; often produced incorrect or incomplete symbolic manipulations, incorrect numeric answers, and incorrect reasoning for multi-step problems. Could not leverage program execution (no code fine-tuning) so could not reliably perform exact symbolic computation or simulations.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison</strong></td>
                            <td>Underperformed substantially versus Codex (code-finetuned transformer) on the same sampled problems: Codex achieved ~71% zero-shot and ~81% few-shot automatic solve rates compared to GPT-3's ~18–42% range. Chain-of-Thought improved GPT-3 but remained far below Codex. Compared to prior state-of-the-art on MATH (8.8%), GPT-3 few-shot+CoT improved but was still much lower than Codex.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_analysis_results</strong></td>
                            <td>Chain-of-Thought prompting improved GPT-3 performance (zero-shot -> few-shot+CoT increases reported), but the paper reports no detailed ablation across GPT-3 sizes. Hyperparameters for GPT-3 CoT experiments were described (CoT implemented by adding the phrase "Let's think step by step.") but no parameter sweeps or model-size analyses were provided for GPT-3 in this work.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A neural network solves, explains, and generates university math problems by program synthesis and few-shot learning at human level', 'publication_date_yy_mm': '2021-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5082.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e5082.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being evaluated or improved for strict logical reasoning, including details of the models, logical reasoning tasks or benchmarks, methods or approaches used, performance results, limitations, and comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Codex (code-davinci-002)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>OpenAI Codex (code-davinci-002)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A Transformer model pre-trained on text and fine-tuned on code that synthesizes executable programs; used to solve, explain, and generate university-level math problems by producing programs whose execution returns/verifies answers.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>OpenAI Codex (code-davinci-002)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Transformer model pre-trained on text then fine-tuned on large corpora of source code; optimized for program synthesis in languages like Python. In this paper Codex is prompted with Python docstring-style prompts, specified libraries (e.g., SymPy, NumPy, Matplotlib), and asked to output executable programs that compute solutions.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>logical_reasoning_task</strong></td>
                            <td>University mathematics course problems (MIT and Columbia) and the MATH benchmark</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Same set of problems as used for GPT-3: multi-step mathematical problems (calculus, differential equations, linear algebra, probability, number theory, etc.) where correct solutions require precise symbolic or numeric computation; program outputs could be numbers, symbolic expressions, vectors, or plots. The MATH benchmark (competition-style problems) was used as an external benchmark.</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_approach</strong></td>
                            <td>Primary approach was program synthesis via few-shot and zero-shot prompting: prompts explicitly ask "write a program" and specify programming language (Python) and libraries (SymPy, NumPy). Automatic contextualization (library and programming context) was added. For unsolved questions, a retrieval-based few-shot pipeline embeds questions (text-similarity-babbage-001) and selects nearest solved question–code pairs as in-context examples (up to 5 examples). Generated code is executed to check answers; explanations are produced by prompting Codex on the question+generated code.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>On sampled university course questions: 71.1% automatic solve rate with zero-shot program-synthesis prompts; 81.1% with few-shot retrieval-based prompting. On sampled MATH benchmark topics: 72.2% zero-shot; 81.1% few-shot. This raised automatic solution accuracy on the MATH benchmark from prior state-of-the-art 8.8% to 81.1% (as reported for their sampled questions and automatic evaluation pipeline).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Unable to handle problems that are image-only, require formal proofs, or are computationally intractable (e.g., factoring very large primes). Approximately 19% of sampled questions required manual prompt tidying or iterative interaction for visualization; some plotted outputs required interactive refinement. Potential for over-reliance on available libraries and inability to solve problems outside of text/code modality constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison</strong></td>
                            <td>Substantially outperformed GPT-3 (text-davinci-002) on the same tasks: Codex zero-shot (71%) vs GPT-3 zero-shot (18.8%) on courses; Codex few-shot (81.1%) vs GPT-3 few-shot+CoT (30.8%). Also markedly improved over previously reported SOTA on the MATH benchmark (8.8% -> 81.1% reported by authors). The paper contrasts program-synthesis approach with expression-tree and verifier approaches used in prior work and argues broader applicability.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_analysis_results</strong></td>
                            <td>Key analytical findings: (1) Fine-tuning on code + explicit program synthesis yields large gains over text-only pretraining. (2) Automatic contextualization ("write a program", specifying Python and libraries like SymPy) materially improves results. (3) Retrieval-based few-shot (embedding nearest solved question–code pair) increased solve rate from ~71% (zero-shot) to ~81% (few-shot); authors used up to 5 in-context examples and measured the jump. (4) Program outputs inherently provide chain-of-thought-like stepwise computation; authors note CoT is inherent in program synthesis. Implementation details fixed Codex hyperparameters to deterministic settings (temperature=0, top_p=0) for solution generation and used slight stochasticity for question generation (temp/top_p=0.1). No detailed parameter ablation over model size was reported.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A neural network solves, explains, and generates university math problems by program synthesis and few-shot learning at human level', 'publication_date_yy_mm': '2021-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Measuring mathematical problem solving with the MATH dataset <em>(Rating: 2)</em></li>
                <li>Large language models are zero-shot reasoners <em>(Rating: 2)</em></li>
                <li>Evaluating large language models trained on code <em>(Rating: 2)</em></li>
                <li>Training verifiers to solve math word problems <em>(Rating: 1)</em></li>
                <li>Generate & rank: A multi-task framework for math word problems <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-5082",
    "paper_id": "paper-257aee73d83a87921fd2d56b524de394dcf6a264",
    "extraction_schema_id": "extraction-schema-107",
    "extracted_data": [
        {
            "name_short": "GPT-3 (text-davinci-002)",
            "name_full": "OpenAI GPT-3 (text-davinci-002)",
            "brief_description": "A large autoregressive Transformer language model pre-trained on large text corpora and used here as a baseline for mathematical/logical reasoning; evaluated in zero-shot, few-shot and chain-of-thought prompting settings on university-level math problems and the MATH benchmark.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "GPT-3 (text-davinci-002)",
            "model_description": "Autoregressive Transformer language model (GPT-3 family) pre-trained on large-scale text data; used via OpenAI's text-davinci-002 API in zero-shot, few-shot, and chain-of-thought (CoT) prompting setups. No task-specific fine-tuning on code was performed for this model in the paper.",
            "model_size": null,
            "logical_reasoning_task": "University mathematics course problems (MIT and Columbia) and the MATH benchmark",
            "task_description": "Challenging mathematical problem solving requiring symbolic manipulation, multi-step logical reasoning, algebra/calculus/linear algebra/probability problem solving typical of university assignments and high-school competition problems (MATH dataset). Problems include numeric answers, algebraic expressions, plots and vector results; proofs and image-only problems were excluded.",
            "method_or_approach": "Evaluated using zero-shot and few-shot prompting; few-shot included adding solved examples and Chain-of-Thought prompting by appending \"Let's think step by step.\" to encourage intermediate reasoning. No program-synthesis or code fine-tuning was used for GPT-3 in these experiments.",
            "performance": "On sampled university course questions: 18.8% automatic solve rate with zero-shot prompting; 30.8% with few-shot + Chain-of-Thought prompting. On sampled MATH benchmark topics: 25.5% zero-shot; 42.2% few-shot + CoT. Evaluations considered a generated solution correct only if program output or answer matched expected solution automatically.",
            "limitations_or_failure_cases": "Struggled on university-level and MATH benchmark problems even with CoT; often produced incorrect or incomplete symbolic manipulations, incorrect numeric answers, and incorrect reasoning for multi-step problems. Could not leverage program execution (no code fine-tuning) so could not reliably perform exact symbolic computation or simulations.",
            "comparison": "Underperformed substantially versus Codex (code-finetuned transformer) on the same sampled problems: Codex achieved ~71% zero-shot and ~81% few-shot automatic solve rates compared to GPT-3's ~18–42% range. Chain-of-Thought improved GPT-3 but remained far below Codex. Compared to prior state-of-the-art on MATH (8.8%), GPT-3 few-shot+CoT improved but was still much lower than Codex.",
            "ablation_or_analysis_results": "Chain-of-Thought prompting improved GPT-3 performance (zero-shot -&gt; few-shot+CoT increases reported), but the paper reports no detailed ablation across GPT-3 sizes. Hyperparameters for GPT-3 CoT experiments were described (CoT implemented by adding the phrase \"Let's think step by step.\") but no parameter sweeps or model-size analyses were provided for GPT-3 in this work.",
            "uuid": "e5082.0",
            "source_info": {
                "paper_title": "A neural network solves, explains, and generates university math problems by program synthesis and few-shot learning at human level",
                "publication_date_yy_mm": "2021-12"
            }
        },
        {
            "name_short": "Codex (code-davinci-002)",
            "name_full": "OpenAI Codex (code-davinci-002)",
            "brief_description": "A Transformer model pre-trained on text and fine-tuned on code that synthesizes executable programs; used to solve, explain, and generate university-level math problems by producing programs whose execution returns/verifies answers.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "OpenAI Codex (code-davinci-002)",
            "model_description": "Transformer model pre-trained on text then fine-tuned on large corpora of source code; optimized for program synthesis in languages like Python. In this paper Codex is prompted with Python docstring-style prompts, specified libraries (e.g., SymPy, NumPy, Matplotlib), and asked to output executable programs that compute solutions.",
            "model_size": null,
            "logical_reasoning_task": "University mathematics course problems (MIT and Columbia) and the MATH benchmark",
            "task_description": "Same set of problems as used for GPT-3: multi-step mathematical problems (calculus, differential equations, linear algebra, probability, number theory, etc.) where correct solutions require precise symbolic or numeric computation; program outputs could be numbers, symbolic expressions, vectors, or plots. The MATH benchmark (competition-style problems) was used as an external benchmark.",
            "method_or_approach": "Primary approach was program synthesis via few-shot and zero-shot prompting: prompts explicitly ask \"write a program\" and specify programming language (Python) and libraries (SymPy, NumPy). Automatic contextualization (library and programming context) was added. For unsolved questions, a retrieval-based few-shot pipeline embeds questions (text-similarity-babbage-001) and selects nearest solved question–code pairs as in-context examples (up to 5 examples). Generated code is executed to check answers; explanations are produced by prompting Codex on the question+generated code.",
            "performance": "On sampled university course questions: 71.1% automatic solve rate with zero-shot program-synthesis prompts; 81.1% with few-shot retrieval-based prompting. On sampled MATH benchmark topics: 72.2% zero-shot; 81.1% few-shot. This raised automatic solution accuracy on the MATH benchmark from prior state-of-the-art 8.8% to 81.1% (as reported for their sampled questions and automatic evaluation pipeline).",
            "limitations_or_failure_cases": "Unable to handle problems that are image-only, require formal proofs, or are computationally intractable (e.g., factoring very large primes). Approximately 19% of sampled questions required manual prompt tidying or iterative interaction for visualization; some plotted outputs required interactive refinement. Potential for over-reliance on available libraries and inability to solve problems outside of text/code modality constraints.",
            "comparison": "Substantially outperformed GPT-3 (text-davinci-002) on the same tasks: Codex zero-shot (71%) vs GPT-3 zero-shot (18.8%) on courses; Codex few-shot (81.1%) vs GPT-3 few-shot+CoT (30.8%). Also markedly improved over previously reported SOTA on the MATH benchmark (8.8% -&gt; 81.1% reported by authors). The paper contrasts program-synthesis approach with expression-tree and verifier approaches used in prior work and argues broader applicability.",
            "ablation_or_analysis_results": "Key analytical findings: (1) Fine-tuning on code + explicit program synthesis yields large gains over text-only pretraining. (2) Automatic contextualization (\"write a program\", specifying Python and libraries like SymPy) materially improves results. (3) Retrieval-based few-shot (embedding nearest solved question–code pair) increased solve rate from ~71% (zero-shot) to ~81% (few-shot); authors used up to 5 in-context examples and measured the jump. (4) Program outputs inherently provide chain-of-thought-like stepwise computation; authors note CoT is inherent in program synthesis. Implementation details fixed Codex hyperparameters to deterministic settings (temperature=0, top_p=0) for solution generation and used slight stochasticity for question generation (temp/top_p=0.1). No detailed parameter ablation over model size was reported.",
            "uuid": "e5082.1",
            "source_info": {
                "paper_title": "A neural network solves, explains, and generates university math problems by program synthesis and few-shot learning at human level",
                "publication_date_yy_mm": "2021-12"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Measuring mathematical problem solving with the MATH dataset",
            "rating": 2
        },
        {
            "paper_title": "Large language models are zero-shot reasoners",
            "rating": 2
        },
        {
            "paper_title": "Evaluating large language models trained on code",
            "rating": 2
        },
        {
            "paper_title": "Training verifiers to solve math word problems",
            "rating": 1
        },
        {
            "paper_title": "Generate & rank: A multi-task framework for math word problems",
            "rating": 1
        }
    ],
    "cost": 0.010870999999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>A Neural Network Solves, Explains, and Generates University Math Problems by Program Synthesis and Few-Shot Learning at Human Level</h1>
<p>Iddo Drori ${ }^{1, a, b}$, Sarah Zhang ${ }^{\text {a }}$, Reece Shuttleworth ${ }^{\text {a }}$, Leonard Tang ${ }^{\circ}$, Albert Lu ${ }^{\text {a }}$, Elizabeth Ke ${ }^{\text {a }}$, Kevin Liu ${ }^{\text {a }}$, Linda Chen ${ }^{\text {a }}$, Sunny Tran ${ }^{\text {a }}$, Newman Cheng ${ }^{\text {b }}$, Roman Wang ${ }^{\text {b }}$, Nikhil Singh ${ }^{\text {a }}$, Taylor L. Patti ${ }^{\circ}$, Jayson Lynch ${ }^{\text {c }}$, Avi Shporer ${ }^{\text {a }}$, Nakul Verma ${ }^{\text {b }}$, Eugene Wu ${ }^{\text {b }}$, and Gilbert Strang ${ }^{\text {a }}$<br>${ }^{a}$ Massachusetts Institute of Technology; ${ }^{\text {b }}$ Columbia University; ${ }^{\circ}$ Harvard University; ${ }^{\text {c }}$ University of Waterloo</p>
<p>This manuscript was compiled on June 1, 2022</p>
<p>We demonstrate that a neural network pre-trained on text and finetuned on code solves mathematics course problems, explains solutions, and generates new questions at a human level. We automatically synthesize programs using few-shot learning and OpenAI's Codex transformer and execute them to solve course problems at $81 \%$ automatic accuracy. We curate a new dataset of questions from MIT's largest mathematics courses (Single Variable and Multivariable Calculus, Differential Equations, Introduction to Probability and Statistics, Linear Algebra, and Mathematics for Computer Science) and Columbia University's Computational Linear Algebra. We solve questions from a MATH dataset (on Prealgebra, Algebra, Counting and Probability, Intermediate Algebra, Number Theory, and Precalculus), the latest benchmark of advanced mathematics problems designed to assess mathematical reasoning. We randomly sample questions and generate solutions with multiple modalities, including numbers, equations, and plots. The latest GPT-3 language model pre-trained on text automatically solves only $18.8 \%$ of these university questions using zero-shot learning and $30.8 \%$ using few-shot learning and the most recent chain of thought prompting. In contrast, program synthesis with few-shot learning using Codex finetuned on code generates programs that automatically solve $81 \%$ of these questions. Our approach improves the previous state-of-theart automatic solution accuracy on the benchmark topics from $8.8 \%$ to $81.1 \%$. We perform a survey to evaluate the quality and difficulty of generated questions. This work is the first to automatically solve university-level mathematics course questions at a human level and the first work to explain and generate university-level mathematics course questions at scale, a milestone for higher education.</p>
<p>Neural networks | Mathematics courses | Answering, explaining, and generating questions</p>
<h2>Introduction</h2>
<p>Until this work; it was widely believed that neural networks could not solve advanced mathematics problems (1). However, the previous unsuccessful studies used only text-based pre-training. We now demonstrate that a neural network, OpenAI Codex, that is pre-trained on text and finetuned on code automatically answers $81 \%$ of university-level mathematics problems by program synthesis using few-shot learning.</p>
<p>Figure 1 illustrates several example problems: computing the volume generated by rotating the graph of a single variable function around an axis, computing the Lorenz attractor and its projection, and computing and demonstrating the geometry of a singular value decomposition (SVD). For the first time, we show that a single machine learning model can solve these
example problems and solve a wide variety of mathematics courses at scale.</p>
<p>Related Work. Transformers are deep learning architectures based only on attention mechanisms (2) that do not use recurrent neural networks or convolutional neural networks. Transformer-based language models have enjoyed tremendous success across various natural language processing (NLP) tasks, including zero-shot and few-shot language tasks (3). However, these models have largely failed to solve math problems (4-6). In particular, previous work using transformers, such as GPT3 (3), has failed to solve mathematics problems because the transformers were pre-trained on text alone. Using few-shot learning and chain of thought (CoT) prompting (7) improves the mathematical reasoning ability of GPT-3; however, without code, GPT-3 with few-shot learning and CoT still fails on university-level mathematics problems and the MATH benchmark.</p>
<p>Pre-training a transformer is computationally expensive and often involves vast amounts of unlabeled data. The most common optimization objectives for pre-training language</p>
<h2>Significance Statement</h2>
<p>We demonstrate that a neural network automatically solves, explains, and generates university-level problems from the largest MIT mathematics courses at a human level. Our methods combine three innovations: (1) using recent neural networks pretrained on text and fine-tuned on code rather than pre-trained on text, (2) few-shot learning synthesizing programs that correctly solve course problems automatically, and (3) a pipeline to solve questions, explain solutions, and generate new questions indistinguishable by students from course questions. Our work is the first to solve university-level mathematics courses and improves upon state-of-the-art increasing automatic accuracy on randomly sampled questions on a benchmark by order of magnitude. Implications for higher education include the new roles of AI in automated course evaluation and content generation.</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Fig. 1. We apply a neural network, OpenAI Codex, to solve, explain, and generate mathematics problems. We randomly sample the input math problems from MIT and Columbia University courses and the MATH dataset (left). We use zero-shot and few-shot learning to automatically generate programs that solve $81 \%$ of the questions. We then use Codex to explain the generated programs. The generated programs can output diverse forms of answers, like printing a numerical answer or generating a plot (right). For example, in Calculus: the volume generated by rotating the finite 2-dimensional region bounded by two 2-dimensional graphs about the plotted axis (top right); in Differential Equations: the Lorenz strange attractor (middle right); In Linear Algebra: the geometry of the singular value decomposition (SVD) (middle right). An example of Codex's ability to produce line-by-line explanations of synthesized programs is demonstrated for a problem from Introduction to Probability and Statistics (bottom right).
models are (1) masked word prediction: predicting a random deleted word in a sentence or predicting the next word, or (2) classifying whether two sentences follow each other. This computationally expensive step is usually done once, followed by a relatively fast fine-tuning step. In fine-tuning, the pretrained model is tuned using a specific dataset or task.</p>
<p>This work demonstrates that OpenAI's Codex (8), a transformer that has been pre-trained on text and then fine-tuned on code, generates programs (i.e., conducts program synthesis) that solve math problems at scale and, with few-shot learning, automatically solves $81 \%$ of the math course problems.</p>
<p>Previous work has seen modest success on simpler or specialized mathematics problem benchmarks. Techniques based on co-training output to verify $(9,10)$ or predict expression trees (11-16), such as MAWPS and Math23k, are able to solve elementary school-level math problems with over $81 \%$ accuracy. However, these approaches do not extend to high-school, math Olympiad, or university-level courses. Co-training paired with graph neural networks (GNNs) to predict arithmetic expression trees is able to solve university-level problems in Machine Learning (17) with up to $95 \%$ accuracy. However, that work is limited to numeric answers and overfits a specific course, which does not generalize to other courses.</p>
<p>Major Contributions. Our main contribution, as shown in Figure 2, is demonstrating that a single neural network model, OpenAI Codex, automatically solves $81 \%$ of randomly selected university-level mathematics problems (from six MIT mathematics courses and one Columbia University course) by using program synthesis and few-shot learning. We also automatically explain the solutions and generate new questions, a process requiring only seconds per problem. The courses are listed in Table 1. We randomly sample 25 questions per course, and the problems are solved as-is or with minor contextual information that is automatically applied. The neural net-
work outputs an executable program that answers the problem when prompted with the question. Furthermore, our method explains the solutions and generates new problems nearly indistinguishable from human-written problems.</p>
<p>This methodology increases the solution accuracy on the MATH benchmark (5) from $8.8 \%$ accuracy using previous state-of-the-art methods to $81.1 \%$ accuracy using automatic few-shot learning. The MATH benchmark measures the mathematical problem-solving ability of neural network models with challenging problems sourced from high school math competitions, such as the AMC $10^{*}$, AMC 12, and AIME ${ }^{1}$.</p>
<p>The methods we propose are simple and broadly applicable. The first is using a transformer model pre-trained on text and fine-tuned on code so that it is adept at synthesizing programmatic solutions. The second is to use zero-shot learning of the questions as-is or automatically added contextual information about the problem or program. The third is to use few-shot learning based on question-code pairs of similar questions that have been solved, found by using the cosine similarity of the question embeddings.</p>
<h2>Methods</h2>
<p>Dataset. We randomly sample 25 questions from each of the seven courses: MIT's 18.01 Single Variable Calculus, 18.02 Multivariable Calculus, 18.03 Differential Equations, 18.05 Introduction to Probability and Statistics, 18.06 Linear Algebra, 6.042 Mathematics for Computer Science, and Columbia University's COMS3251 Computational Linear Algebra. For the MATH dataset, we randomly sample 15 questions from six topics in the dataset (Algebra, Counting \&amp; Probability, Intermediate Algebra, Number Theory, Prealgebra, and Precalculus). We validate that our results are not merely overfitting</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Fig. 2. We select a random sample of questions from each course or topic that do not contain input images or require proofs. A language model pre-trained on text (GPT-3 text-davinci-002) automatically solves only 18% (for courses) and 25.5% (for the MATH benchmark topics) of these questions. In contrast, using zero-shot learning with a network pre-trained on text and fine tuned on code (OpenAI Codex code-davinci-002), we synthesize programs that automatically solve 71% (for courses) and 72.2% (for the MATH benchmark topics) of the questions. Using the same network but using few-shot learning, we automatically solve 81% (for courses) and 81.1% (for the MATH benchmark topics) of the questions. We use the nearest embedded zero-shot questions and their synthesized code for few-shot learning. The remaining 19% of the course questions and 18.9% of MATH benchmark topic questions are manually prompted to solve the question.</p>
<p>Training data by solving questions from a new Computational Linear Algebra course COMS3251 which is unavailable online and was unseen by Codex when trained. We automatically obtain correct answers for 81% of the randomly sampled university math course questions and 81.1% of the MATH benchmark questions. Before this work, the previous state-of-the-art on this benchmark was 8.8% (4).</p>
<p><strong>Workflow.</strong> Our method takes a course problem as input and synthesizes a program that, when run, outputs the solution. Figure 4 compares the percent of automatically solved questions for each course using our zero-shot learning and few-shot learning approaches with the latest GPT-3 (text-davinci-002) and Codex (code-davinci-002) versions. The error bars on the totals are standard errors.</p>
<p>Figures 3 show examples of automatic workflows for solving course questions and generating explanations using Codex. The panels show the original question, the automatic augmentation with context, the resulting synthesized program, the executed output answer that is the solution, and the explanation of the solution program. Questions are given to Codex either as-is or by automatically adding minor context, as described below. The output answer may be of numerous modalities. In the examples featured in Figure 3, the output answers are an equation (18.01), a Boolean value (18.02), a plot (18.03), and a numerical value (18.05), and a vector (18.03 and 18.06).</p>
<h3>Automatic Contextualization</h3>
<p><strong>Programming Language Context.</strong> Best results are obtained when the Codex prompt specifies that a program should be written and specifies which programming language should be used. We add the text "write a program" before the question and focus on the Python programming language by placing the text within Pythonic triple quotes like a docstring.</p>
<p><strong>Library Context.</strong> Likewise, the best results are obtained when the Codex prompt specifies which programming package should be used. For instance, we may add the Python library SymPy as context (see Figure 3 top panel 18.01), specifying that the program synthesized to solve the problem should use this package.</p>
<p>Figure 5 shows the Python programming packages used by each course. Each colored stacked bar represents the number of questions in the class using that package. All courses use NumPy and Sympy. Matplotlib is used in classes with questions that require plotting. Around half of the courses use math, random, and SciPy. The usage patterns of these courses are incorporated automatically in our approach, as we only specify SymPy or plot-related imports; these other package imports are automatically synthesized.</p>
<h3>Automatic Zero-Shot and Few-Shot Learning</h3>
<p>Zero-shot learning synthesizes a program from the original question or the automatically augmented question without examples. This method automatically solves 71% of the questions. Next, we describe the few-shot learning process in detail: If the question is not solved, we do the following: we embed all the questions using OpenAI's text-similarity-babbage-001 embedding engine, which embeds the questions onto a 2,048-dimensional space. Then, we calculate the most similar solved questions to the unsolved question from within its course using the cosine similarity of the embeddings. We take the most similar question and its corresponding code and use these as few-shot examples for the new question. If the generated code does not output the correct answer, we add another solved question–code pair, using the next similar solved question each time. We found that using up to five examples for few-shot learning works well in practice, increasing the total number of questions automat-</p>
<table>
<thead>
<tr>
<th style="text-align: center;">ID</th>
<th style="text-align: center;">Course</th>
<th style="text-align: center;">Question</th>
<th style="text-align: center;">Solution</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">1</td>
<td style="text-align: center;">18.01 <br> Single Variable Calculus</td>
<td style="text-align: center;">A bacteria population is 4000 at time $t=0$ and its rate of growth is $1000 * 2^{t}$ bacteria per hour after $t$ hours. What is the population after one hour?</td>
<td style="text-align: center;">$4000+\frac{1000}{\log (2)}$</td>
</tr>
<tr>
<td style="text-align: center;">2</td>
<td style="text-align: center;">18.02 <br> Multi-variable Calculus</td>
<td style="text-align: center;">Describe the graph of the function $f$ : $f(x, y)=10-\sqrt{x^{2}+y^{2}}$</td>
<td style="text-align: center;"><img alt="img-2.jpeg" src="img-2.jpeg" /></td>
</tr>
<tr>
<td style="text-align: center;">3</td>
<td style="text-align: center;">18.03 <br> Differential Equations</td>
<td style="text-align: center;">Find general solutions of the differential equations. If an initial condition is given, find the corresponding particular solution. Throughout, primes denote derivatives with respect to $x . y^{\prime}+y=2, y(0)=0$</td>
<td style="text-align: center;">$y(x)=2\left(1-e^{-x}\right)$</td>
</tr>
<tr>
<td style="text-align: center;">4</td>
<td style="text-align: center;">18.05 <br> Introduction to Probability and Statistics</td>
<td style="text-align: center;">Calculate the probability of getting a three-of-a-kind poker hand.</td>
<td style="text-align: center;">0.021128</td>
</tr>
<tr>
<td style="text-align: center;">5</td>
<td style="text-align: center;">18.06 <br> Linear Algebra</td>
<td style="text-align: center;">Find a combination $x_{1} w_{1}+x_{2} w_{2}+x_{3} w_{3}$ that gives the zero vector with $x_{1}=1$. $w_{1}$ is the vector $(1 ; 2 ; 3) . w_{2}$ is the vector $(4 ; 5 ; 6) . w_{3}$ is the vector $(7 ; 8 ; 9)$.</td>
<td style="text-align: center;">$x_{1}=1, x_{2}=-2, x_{3}=1$</td>
</tr>
<tr>
<td style="text-align: center;">6</td>
<td style="text-align: center;">6.042 <br> Mathematics for <br> Computer Science</td>
<td style="text-align: center;">Find a number $x \in{0,1, \ldots, 112}$ such that $11 x \equiv 1(\bmod 113)$.</td>
<td style="text-align: center;">72</td>
</tr>
<tr>
<td style="text-align: center;">7</td>
<td style="text-align: center;">COMS3251 <br> Computational <br> Linear Algebra</td>
<td style="text-align: center;">Given a d-dimensional non-zero vector $v$, compute the rank of the matrix $v v^{\prime}$</td>
<td style="text-align: center;">1</td>
</tr>
<tr>
<td style="text-align: center;">8</td>
<td style="text-align: center;">MATH <br> Prealgebra</td>
<td style="text-align: center;">What is the greatest common factor of 84,112 and 210 ?</td>
<td style="text-align: center;">14</td>
</tr>
<tr>
<td style="text-align: center;">9</td>
<td style="text-align: center;">MATH <br> Algebra</td>
<td style="text-align: center;">Let $N, O$ be functions such that $N(x)=2 \sqrt{x}$, and $O(x)=x^{2}$. What is $N(O(N(O(N(O(3))))))$ ?</td>
<td style="text-align: center;">24</td>
</tr>
<tr>
<td style="text-align: center;">10</td>
<td style="text-align: center;">MATH <br> Number Theory</td>
<td style="text-align: center;">How many four-digit numbers whose digits add up to 9 are divisible by 11 ?</td>
<td style="text-align: center;">0</td>
</tr>
<tr>
<td style="text-align: center;">11</td>
<td style="text-align: center;">MATH <br> Counting and Probability</td>
<td style="text-align: center;">A standard six-sided fair die is rolled four times. The probability that the product of all four numbers rolled is a perfect square is $\frac{m}{n}$, where $m$ and $n$ are relatively prime positive integers. Find $m+n$.</td>
<td style="text-align: center;">187</td>
</tr>
<tr>
<td style="text-align: center;">12</td>
<td style="text-align: center;">MATH <br> Intermediate Algebra</td>
<td style="text-align: center;">Given that $x^{2}+y^{2}=14 x+6 y+6$, find the largest possible value of $3 x+4 y$.</td>
<td style="text-align: center;">73</td>
</tr>
<tr>
<td style="text-align: center;">13</td>
<td style="text-align: center;">MATH <br> Precalculus</td>
<td style="text-align: center;">If the six solutions of $x^{6}=-64$ are written in the form $a+b i$, where $a$ and $b$ are real, find the product of those solutions with $a&gt;0$.</td>
<td style="text-align: center;">4</td>
</tr>
</tbody>
</table>
<p>Table 1. Example questions and solutions from six MIT courses (18.01, 18.02, 18.03, 18.05, 18.06, 6.042), one Columbia University course (COMS3251), and six topics from the MATH dataset. The solutions can contain numerical answers, equations, plots, or other modalities.
ically solved from $71 \%$ using zero-shot learning to $81 \%$ using few-shot learning. Figure 3 (18.02) demonstrates few-shot learning.</p>
<p>Simulation. Figure 3 (18.05) shows an example from Probability and Statistics where the question is turned into a probabilistic programming task that generates simulations in order to compute an empirical statistic.</p>
<h2>Manual Prompt Modification.</h2>
<p>Question Tidying. While $81 \%$ of the question is automatically solved by zero-shot and few-shot learning, $19 \%$ of the questions may require manual editing to be solved by Codex. These questions may be vague or contain redundant information (e.g., reference movie characters or current events) and require tidying to extract the essence of the question. Question tidying primarily involves removing redundant information, breaking down long sentence structures into smaller components, and converting prompts into a programming format.</p>
<p>Interaction for Visualization. Another form of manual prompting occurs when an answer involves a plot and requires multiple
steps to generate a visually pleasing and clear plot. These special cases, which are among the remaining $19 \%$ of the questions, require interactively prompting Codex until reaching the desired visualizations.</p>
<p>Automatic Explanation. Explanations are generated automatically using the question, the code generated by Codex when prompted with the question, and a prompt consisting of three quotes followed by the text "Here is what the above code is doing: 1.". This prompt is given after both the question and the generated code since the code may be a lossy representation of the question. The result is a step-by-step explanation of the solution code given to Codex.</p>
<p>Question Generation and their Human Evaluation. We also use Codex to generate new questions for each course. This is done by creating a numbered list of human-written questions from each class. This list is cut off after a random number of questions, and the result is used to prompt Codex to generate the next question. This process is repeated to create many new questions for each course.</p>
<p>To evaluate the generated questions, we survey MIT stu-</p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Fig. 3. Example pipelines automatically solve questions from MIT mathematics courses and explain the solutions. 18.01 Single Variable Calculus Zero-Shot example: Given a question and the automatically generated prefix "using SymPy," Codex is prompted and outputs a program. Running the program results in equations that are the correct answer. The program is then fed to Codex again with an automatic prompt, resulting in a generated code explanation. 18.02 Multivariable Calculus Few-Shot example: Given a question, the prefix "write a program using SymPy" is automatically generated. The question is embedded with the other zero-shot questions in the course. The nearest zero-shot question and its corresponding code are used as a few-shot example. The few-shot example pair and the input question are fed into Codex, which generates a program that solves the question. The question, program, and prompt for explanation are fed into Codex to generate the explanation. 18.03 Differential Equations Zero-Shot example: In this example, the answer is both a vector and a plot. 18.05 Introduction to Probability and Statistics Zero-Shot example: Given the question, a probabilistic program is generated by adding "using simulation" to the prompt. 18.06 Linear Algebra Zero-Shot example: The output answer is the correct vector.
dents who have taken these courses or their equivalents to compare the quality and difficulty of machine-generated questions with human-written questions for each of the courses. ${ }^{1}$</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup>We randomly sampled five original, human-written questions and five generated questions for each of the six MIT courses. Students are asked to read these ten questions per course in the survey, mixed and presented randomly.
tion. For each question, you will be asked (a) whether you think the question is human-written or machine-generated, (b) whether the question is appropriate for the given course, and finally, (c) how you would rate the difficulty of the question. Please carefully read each question and answer to the best of your ability".</p>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Fig. 4. Comparison of the automatic solve rates on (A) MIT math courses and a Columbia University course and on (B) MATH benchmark dataset. The latest OpenAI GPT-3 (text-davinci-002), a transformer pre-trained on text, achieves on the MIT math courses (A) of $18.8 \%$ with zero-shot, and $30.8 \%$ with few-shot and CoT, and on the MATH benchmark (B) $25.5 \%$ with zero-shot, and $42.2 \%$ with few-shot and CoT. In contrast, program synthesis with using the latest OpenAI Codex (code-davinci-002), a transformer pre-trained on text and fine-tuned on code, achieve automatic solve rates on the MIT math courses (A) $71.1 \%$ with zero-shot learning and $81.1 \%$ with few-shot learning, and on the MATH benchmark (B) $72.2 \%$ with zero-shot learning and $81.1 \%$ with few-shot learning.</p>
<p>For each of the 60 questions, the students are asked three survey questions: (1) "Is the question human-written or machine-generated?", (2) "Is the question appropriate or not appropriate for the specific course?", and (3) "What is the question's difficulty level on a scale between 1 (easiest) and 5 (hardest)?" An example of this survey format is given in Figure 6. The students are asked to provide their ratings and not solve the questions. The survey is conducted online and anonymously.</p>
<h2>Results</h2>
<p>Questions Solved. We solve 265 questions, 213 of them automatically, as described in the Supplementary Information. These 265 questions include 25 randomly sampled questions from each of the seven courses (18.01/18.02/18.03/18.05/18.06/6.042/COMS3251) and 15 randomly sampled questions for each of the six topics in the MATH dataset (Prealgebra/Algebra/Number Theory/Count-
<img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Fig. 5. Imported Python programming libraries by course: NumPy is used by nearly all courses. Matplotlib is used in courses with questions that involve plotting. Sympy is used by most of the courses, and SciPy by half of the courses.
ing and Probability/Intermediate Algebra/Precalculus). The breakdown of automatic solve rate by zero-shot and few-shot learning using Codex as compared with GPT-3 and GPT-3 with CoT is shown in Figure 4. Programs involve step-by-step commands; therefore, CoT is inherent in programs.</p>
<p>Visualization of Embedded Questions. We embed the 175 mathematics course questions onto a 2,048-dimensional space using OpenAI's text-similarity-babbage-001 embedding engine, which captures semantic similarity between texts. We then use uniform manifold approximation and projection (UMAP) (18) to reduce the dimensionality of the 175 question embeddings to two. Figure 8, the plot of these two dimensions, shows that the embedded questions are clustered by course topics. We see clusters of questions representing linear algebra from MIT's 18.06 Linear Algebra and Columbia's COMS3251 Computational Linear Algebra on the top right. On the left side, we see a collection of the questions representing calculus from MIT's 18.01 Single Variable Calculus, 18.02 Multivariable Calculus, and 18.03 Differential Equations. On the bottom right, we see a cluster of the questions from MIT's 18.05 Introduction to Probability and Statistics and 6.042 Mathematics for Computer Science, covering probability and statistics.</p>
<p>Automatically Generating New Questions. We generate new questions for each course and topic by prompting Codex with numbered human-written questions to generate the next question automatically. Specifically, we create prompts of 25 randomly selected problems for which Codex generates correct answers, remove the questions after a randomly chosen question in the list, and have Codex complete the next new question. We present 130 new questions generated by Codex in the Supplementary Information to demonstrate this capability. These include ten new questions for each of the seven courses and each of the six MATH topics. Table 2 shows one generated question for each class and MATH topic. Generating a question takes less than a second. We can generate an arbi-</p>
<p>Course Name:
Introduction to Probability and Statistics
For each of the following questions, indicate whether you think the question is Human Written or Machine Generated, whether it is appropriate for the above course, as well as its level of difficulty between 1-5 where 1 is easiest, 2 is below average, 3 is average for the course, 4 is above average, and 5 in hardest.</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: center;">Human vs. Machine <br> Generated</th>
<th style="text-align: center;">Appropriate for Course</th>
<th style="text-align: center;">Difficulty <br> (1=Easiest;5=Hardest)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: center;">Human <br> Written</td>
<td style="text-align: center;">Machine <br> Generated</td>
<td style="text-align: center;">Appropriate Not <br> Appropriate</td>
</tr>
<tr>
<td style="text-align: left;">Boxes of Raisin Bran cereal are 30cm tall. Due to settling, boxes have a <br> higher density of raisins at the bottom ( $h=6$ than at the top $(h=30$ ). <br> Suppose the density (in raisins per cm of height) is given by $\mathrm{f}(\mathrm{h})=40-$ <br> h. What is the probability that a random raisin is in the top third of the <br> box?</td>
<td style="text-align: center;">00</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">00000</td>
</tr>
</tbody>
</table>
<p>Fig. 6. Student survey example question: For each of 60 questions, students are asked if (1) the question is human-written or machine-generated, (2) the question is appropriate or inappropriate for the course, and (3) to rate the difficulty level of each question on a scale between 1 (easiest) and 5 (hardest).
<img alt="img-6.jpeg" src="img-6.jpeg" /></p>
<p>Fig. 7. Student survey results: Panel A compares the level of difficulty of human-written questions and questions generated by our approach for each course based on the student ratings. The plot shows the means of the difficulty ratings between 1 (easiest) and 5 (hardest) and their $95 \%$ confidence intervals. Panel B shows the percentage of human-written and machine-generated questions rated as appropriate and not appropriate for the course. Panel C shows the percentage of human-written questions rated as human-written or machine-generated (left) and the percentage of machine-generated questions rated as human-written or machine-generated (right).
trarily large number of questions, demonstrating that this is a practical and effective method for creating new course content.</p>
<p>Student Survey Results. Fifteen participants completed our survey, answering questions about all 60 questions, taking a median of 40 minutes. Figure 7 summarizes the results of the student survey comparing human-written and machinegenerated questions. Panel A compares the difficulty level of human-written questions and the machine-generated questions for each course based on the student ratings. The plot shows the means of the difficulty ratings between 1 (easiest) and 5 (hardest) and their $95 \%$ confidence intervals. Panel B shows the percentage of human-written and machine-generated questions rated by students as appropriate or not appropriate for the courses. Panel C shows the percentage of human-written questions rated as human-written or machine-generated (left) and the percentage of machine-generated questions rated as human-written or machine-generated (right).</p>
<p>Summarizing the student survey results:</p>
<ul>
<li>Survey participants rated our machine-generated and human-written questions to be similar in difficulty within confidence intervals.</li>
<li>Survey participants rated human-written questions slightly more appropriate for the courses than machinegenerated ones.</li>
<li>Survey participants rated human-written questions more likely to be human-written as shown on the left side of Panel C. Survey participants rated machine-generated questions equally likely to be machine-generated and human-written as shown on the right side of Panel C.</li>
</ul>
<p>Human Level. With our methodology, Codex reaches human performance levels in both the contexts of solving existing questions and generating new content. We achieve $81 \%$ automatic accuracy in solving mathematics course problems at MIT and</p>
<p><img alt="img-7.jpeg" src="img-7.jpeg" /></p>
<p>Fig. 8. Visualization of embeddings of course questions: We embed the course questions into a 2,048-dimensional space using OpenAI's text-similarity-babbage-001 embedding engine, which captures semantic similarity between texts. We then use uniform manifold approximation and projection to reduce the dimensionality to two. This shows distinctive clusters based on topics. We see clusters of questions from MIT's 18.06 Linear Algebra and Columbia's COMS3251 Computational Linear Algebra on the top right. On the left side, we see a cluster of the questions from MIT's 18.01, 18.02, and 18.03. On the bottom right, we see a cluster of the questions from MIT's 18.05 Introduction to Probability and Statistics and 6.042 Mathematics for Computer Science, covering probability and statistics.</p>
<p>Columbia, comparable to typical student performance on these problem sets in our MIT and Columbia University courses. Furthermore, we automatically generate new questions that are indistinguishable to students from human-written course questions.</p>
<p>Implementation Details. We make our data and code publicly available. ${ }^{5}$ We use the latest version of OpenAI's GPT-3 text-davinci-002 and Codex codex-davinci-002 engines for all of our experiments. We fix all Codex's hyperparameters to be the same for all solution and explanation experiments to yield deterministic and reproducible results. Specifically, top P, which controls diversity, is set to 0 and sampling temperature, which controls randomness, is also set to 0 . The frequency and presence penalties are set to 0 , and we do not halt on any stop sequences. We allow diversity and randomness for all new question generation experiments by setting the top P and temperature to 0.1 . Each prompt is structured as a Python documentation comment surrounded by triple quotations and line breaks. We evaluate the solution by running the generated program using a Python interpreter. Evaluations are considered correct if the printed output or the value returned by the generated program is the correct solution.</p>
<p>Few-shot learning prompts are structured as follows: for each question-code examples being used, we insert the question in a docstring on the following available line, have a line break, and then insert the code on the following lines. After all the examples, we insert the target question at the end in the same way as described above and prompt Codex.</p>
<p>Chain of thought (CoT) prompts for GPT-3 are implemented by adding the text "Let's think step by step." (7) after</p>
<p><sup id="fnref4:0"><a class="footnote-ref" href="#fn:0">1</a></sup>the few-shot questions and answers, and the new question.
Types of Problems the Model Cannot Solve. There are a few different types of problems the model is incapable of solving: (1) any problem for which the question is in the form of an image or other non-text modality; (2) questions with solutions that require proofs; and (3) problems that are computationally intractable, such as factoring very large primes. This last category is not expected in any math course assignment, as students themselves would also be unable to answer them. That being said, many questions that students can answer have generalizations that are computationally intractable.</p>
<h2>Conclusion</h2>
<p>We demonstrate that few-shot learning and program synthesis using OpenAI Codex is able to solve, explain, and generate university-level mathematics problems at a human level. In contrast, previous methods using transformers only pre-trained on text, such as GPT-3, fail on these tasks. We verify that our strong results are not overfitting the training data by solving a new course that is not available online. We also generate and analyze new problem sets. The success of this work confirms that programs serve as a good representation and computation environment for solving math problems. Since our approach requires no additional training, it is easily scalable. This work addresses significant pedagogical challenges, bringing substantial benefits to higher education like curriculum design and analysis tools and automatic content generation.</p>
<p>We show that neural network synthesis with modern programming languages is more dynamic and widely applicable than expression trees and likely solves a broader range of problems. Although any finite computation could be expressed as</p>
<table>
<thead>
<tr>
<th style="text-align: center;">ID</th>
<th style="text-align: center;">Course</th>
<th style="text-align: center;">Machine-generated question</th>
<th style="text-align: center;">Most similar human-written question</th>
<th style="text-align: center;">Similarity</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">1</td>
<td style="text-align: center;">18.01 <br> Single-Variable Calculus</td>
<td style="text-align: center;">Find the area of the region bounded by the curve and the $x$-axis. $y=x^{2} \sin (x), 0 \leq x \leq \pi$</td>
<td style="text-align: center;">Find the area of the region under the given curve from 1 to $2 . y=\left(x^{2}+1\right) /\left(3 x-x^{2}\right)$</td>
<td style="text-align: center;">0.61</td>
</tr>
<tr>
<td style="text-align: center;">2</td>
<td style="text-align: center;">18.02 <br> Multi-Variable Calculus</td>
<td style="text-align: center;">Find $a \times b . a=(9,-2,1), b=(-2,1,1)$</td>
<td style="text-align: center;">Find $a \times b . a=(5,-1,-2), b=(-3,2,4)$</td>
<td style="text-align: center;">0.87</td>
</tr>
<tr>
<td style="text-align: center;">3</td>
<td style="text-align: center;">18.03 <br> Differential Equations</td>
<td style="text-align: center;">Use the method of separable variables to solve the initial-value problem $\frac{d x}{d y}=5 e^{x} \cdot y(2)=$ 12 when $x=2$</td>
<td style="text-align: center;">Separate variables and use partial fractions to solve the initial value problems. Use either the exact solution or a computer-generated slope field to sketch the graphs of several solutions of the given differential equation, and highlight the indicated particular solution. $f^{\prime}(x)=3 f(x)(5-f(x)), f(0)=8$</td>
<td style="text-align: center;">0.21</td>
</tr>
<tr>
<td style="text-align: center;">4</td>
<td style="text-align: center;">18.05 <br> Introduction to Probability and Statistics</td>
<td style="text-align: center;">Let $X$ be a uniformly distributed random variable over the interval $[0,1)$. Find $\mathbb{E}\left[X^{2}\right]$</td>
<td style="text-align: center;">Let $X$ be the result of rolling a fair 4 -sided die. Let $Y$ be the result of rolling a fair 6 -sided die. You win $2 X$ dollars if $X&gt;Y$ and lose 1 dollar otherwise. After playing this game 60 times, what is your expected total gain?</td>
<td style="text-align: center;">0.29</td>
</tr>
<tr>
<td style="text-align: center;">5</td>
<td style="text-align: center;">18.06 <br> Linear Algebra</td>
<td style="text-align: center;">Write a Matlab code to determine if the given matrix $A=[1,1 ; 4,4]$ is positive semidefinite and if it is negative semidefinite.</td>
<td style="text-align: center;">Find $A^{\prime} A$ if the columns of $A$ are unit vectors, all mutually perpendicular.</td>
<td style="text-align: center;">0.21</td>
</tr>
<tr>
<td style="text-align: center;">6</td>
<td style="text-align: center;">6.042 <br> Mathematics for <br> Computer Science</td>
<td style="text-align: center;">A student is taking a test consisting of $n$ multiplechoice questions. Each question has five possible answers, and only one is correct. The student knows that the probability that any particular question is answered correctly is $\frac{1}{5}$. Let $X$ be the number of questions answered correctly by the student. What is $\mathbb{E}(X)$ ?</td>
<td style="text-align: center;">MIT students sometimes delay laundry for a few days. Assume all random values described below are mutually independent. A busy student must complete three problem sets before doing laundry. Each problem set requires 1 day with probability $\frac{2}{3}$ and 2 days with probability $\frac{1}{3}$. Let $B$ be the number of days a busy student delays laundry. What is $\mathbb{E}(B)$ ?</td>
<td style="text-align: center;">0.47</td>
</tr>
<tr>
<td style="text-align: center;">7</td>
<td style="text-align: center;">COMS3251 <br> Computational</td>
<td style="text-align: center;">Find a combination of the vectors $\left[\begin{array}{lll}1 &amp; 2 &amp; 3 \ 4 &amp; 5 &amp; 6 \ 7 &amp; 8 &amp; 9\end{array}\right]$ that gives the vector $\left[\begin{array}{lll}1 &amp; 2 &amp; 3 \ 4 &amp; 5 &amp; 6 \ 7 &amp; 8 &amp; 9\end{array}\right]$ that give the zero vector.</td>
<td style="text-align: center;">Find a combination of the vectors $\left[\begin{array}{lll}1 &amp; 2 &amp; 3 \ 4 &amp; 5 &amp; 6 \ 7 &amp; 8 &amp; 9\end{array}\right]$ that give the zero vector.</td>
<td style="text-align: center;">0.90</td>
</tr>
<tr>
<td style="text-align: center;">8</td>
<td style="text-align: center;">MATH <br> Pre-Algebra</td>
<td style="text-align: center;">How many four-digit positive integers are there with hundreds digit 2 ?</td>
<td style="text-align: center;">How many four-digit positive integers are there with thousands digit 2 ?</td>
<td style="text-align: center;">0.90</td>
</tr>
<tr>
<td style="text-align: center;">9</td>
<td style="text-align: center;">MATH <br> Algebra</td>
<td style="text-align: center;">Find the distance between the points $(0,0)$ and $(3,4)$.</td>
<td style="text-align: center;">Find the distance between the points $(0,4)$ and $(3,0)$.</td>
<td style="text-align: center;">0.99</td>
</tr>
<tr>
<td style="text-align: center;">10</td>
<td style="text-align: center;">MATH <br> Number Theory</td>
<td style="text-align: center;">Find the smallest positive integer $n$ such that $n^{2}$ is divisible by $2^{10}$ and $n^{3}$ is divisible by $3^{10}$.</td>
<td style="text-align: center;">How many four-digit numbers whose digits add up to 9 are divisible by 11 ?</td>
<td style="text-align: center;">0.25</td>
</tr>
<tr>
<td style="text-align: center;">11</td>
<td style="text-align: center;">MATH <br> Counting and Probability</td>
<td style="text-align: center;">How many ways are there to divide a set of 10 objects into two sets of equal size?</td>
<td style="text-align: center;">Compute $\binom{8}{4}$.</td>
<td style="text-align: center;">0.12</td>
</tr>
<tr>
<td style="text-align: center;">12</td>
<td style="text-align: center;">MATH <br> Intermediate Algebra</td>
<td style="text-align: center;">Let $x$ and $y$ be positive real numbers such that $x^{2}+$ $y^{2}=1$. Find the maximum value of $x y$.</td>
<td style="text-align: center;">Given that $x^{2}+y^{2}=14 x+6 y+6$, find the largest possible value of $3 x+4 y$.</td>
<td style="text-align: center;">0.59</td>
</tr>
<tr>
<td style="text-align: center;">13</td>
<td style="text-align: center;">MATH <br> Precalculus</td>
<td style="text-align: center;">Let $A$ be the matrix $\left[\begin{array}{lll}1 &amp; 2 &amp; 3 \ 4 &amp; 5 &amp; 6 \ 7 &amp; 8 &amp; 9\end{array}\right]$ <br> minant of $A^{2}+A^{3}$.</td>
<td style="text-align: center;">If $\operatorname{det}(A)=2$ and $\operatorname{det}(B)=12$, then find $\operatorname{det}(A B)$.</td>
<td style="text-align: center;">0.41</td>
</tr>
</tbody>
</table>
<p>Table 2. Examples of new questions generated automatically by Codex for each course and the most similar question from its course.
a sufficiently large expression tree, one may see an arbitrarily large expansion in the size of the expression tree needed, as opposed to a Turing-complete language. This flexibility is bolstered by the massive corpus of existing programs, which eclipses the number of labeled expression trees available. Program outputs are also inherently more human-readable, as the ability to use abstraction, modularity, and high-level logic leads to more explicit illustrations of the path to a solution. Furthermore, program synthesis can convey logical deductions directly through explanatory comments and function and variable names. In particular, we see such descriptive text and derivations in a number of the Codex outputs. The unification of such formal and informal language is an inherent advantage of our methodology. We emphasize that the results may be
complex and multi-modal. For example, by using packages such as Matplotlib, we can produce graphs of equations. This advanced and unique ability is time-consuming for humans and offers a significant pedagogical benefit.</p>
<p>In summary, we automatically solve, explain, and generate university-level mathematics course questions in real-time at a human level. Students rated machine-generated questions as equally likely to have been human-written as machinegenerated. Students also rated machine-generated questions as similarly difficult to human-written questions and most appropriate for their respective courses. Finally, we have succeeded in scaling up this work to over thirty STEM courses across 13 departments in science and engineering schools at MIT and Ivy League universities, with excellent results.</p>
<ol>
<li>CQ Choi, 7 revealing ways AIs fail: Neural networks can be disastrously brittle, forgetful, and surprisingly bad at math. IEEE Spectr. 58, 42-47 (2021).</li>
<li>A Vaswani, et al., Attention is all-you need in Proceedings of Advances in Neural Information Processing Systems. Vol. 30, (2017).</li>
<li>TB Brown, et al., Language models are few-shot learners in Proceedings of Advances in Neural Information Processing Systems. Vol. 33, pp. 1877-1901 (2020).</li>
<li>D Hendrycks, et al., Measuring massive multitask language understanding in Proceedings of the International Conference on Learning Representations. (2021).</li>
<li>D Hendrycks, et al., Measuring mathematical problem solving with the MATH dataset in Proceedings of Advances in Neural Information Processing Systems: Datasets and Benchmarks. (2021).</li>
<li>JW Rae, et al., Scaling language models: Methods, analysis \&amp; insights from training Gopher. arXiv preprint arXiv:2112.11446 (2021).</li>
<li>T Kojima, S Shane Gu, M Reid, Y Matsuo, Y Iwasawa, Large language models are zero-shot reasoners. arXiv preprint arXiv:2205.11916 (2022).</li>
<li>M Chen, , et al., Evaluating large language models trained on code. arXiv preprint arXiv:2107.03374 (2021).</li>
<li>J Shen, et al., Generate \&amp; rank: A multi-task framework for math word problems in Proceedings of the Conference on Empirical Methods in Natural Language Processing. pp. 22692279 (2021).</li>
<li>K Cobbe, et al., Training verifiers to solve math word problems. arXiv preprint arXiv:2110.14168 (2021).</li>
<li>Z Xie, S Sun, A goal-driven tree-structured neural model for math word problems in Proceedings of the International Joint Conference on Artificial Intelligence. pp. 5299-5305 (2019).</li>
<li>Q Wu, Q Zhang, J Fu, XJ Huang, A knowledge-aware sequence-to-tree network for math word problem solving in Proceedings of the Conference on Empirical Methods in Natural Language Processing. pp. 7137-7146 (2020).</li>
<li>J Qin, L Lin, X Liang, R Zhang, L Lin, Semantically-aligned universal tree-structured solver for math word problems in Proceedings of the Conference on Empirical Methods in Natural Language Processing. pp. 3780-3789 (2020).</li>
<li>J Zhang, et al., Graph-to-tree learning for solving math word problems in Proceedings of the Annual Meeting of the Association for Computational Linguistics. pp. 3928-3937 (2020).</li>
<li>S Li, et al., Graph-to-tree neural networks for learning structured input-output translation with applications to semantic parsing and math word problem in Proceedings of the Conference on Empirical Methods in Natural Language Processing. pp. 2841-2852 (2020).</li>
<li>Z Liang, J Zhang, J Shao, X Zhang, MWP-BERT: A strong baseline for math word problems. arXiv preprint arXiv:2107.13435 (2021).</li>
<li>S Tran, et al., Solving machine learning problems in Proceedings of the Asian Conference on Machine Learning. pp. 470-485 (2021).</li>
<li>L McInnes, J Healy, J Melville, Umap: Uniform manifold approximation and projection for dimension reduction. J. Open Source Softw. 3, 861 (2018).</li>
</ol>
<h1>Contents</h1>
<p>A Solutions for MIT 18.01: Single Variable Calculus ..... 11
B Solutions for MIT 18.02: Multivariable Calculus ..... 29
C Solutions for MIT 18.03: Differential Equations ..... 44
D Solutions for MIT 18.05: Introduction to Probability and Statistics ..... 62
E Solutions for MIT 18.06: Introduction to Linear Algebra ..... 79
F Solutions for MIT 6.042: Mathematics for Computer Science ..... 95
G Solutions for Columbia University COMS3251: Computational Linear Algebra ..... 114
H Solutions for MATH: Prealgebra ..... 127
I Solutions for MATH: Algebra ..... 135
J Solutions for MATH: Number Theory ..... 141
K Solutions for MATH: Counting and Probability ..... 149
L Solutions for MATH: Intermediate Algebra ..... 157
M Solutions for MATH: Precalculus ..... 166
N Generation of MIT 18.01: Single-Variable Calculus ..... 174
O Generation of MIT 18.02: Multi-Variable Calculus ..... 174
P Generation of MIT 18.03: Differential Equations ..... 174
Q Generation of MIT 18.05: Introduction to Probability and Statistics ..... 175
R Generation of MIT 18.06: Introduction to Linear Algebra ..... 176
S Generation of MIT 6.042: Mathematics for Computer Science ..... 176
T Generation of Columbia University COMS3251: Computational Linear Algebra ..... 177
U Generation of MATH: Algebra ..... 178
V Generation of MATH: Counting and Probability ..... 178
W Generation of MATH: Intermediate Algebra ..... 179
X Generation of MATH: Number Theory ..... 179
Y Generation of MATH: Prealgebra ..... 180
Z Generation of MATH: Precalculus ..... 180
A. Solutions for MIT 18.01: Single Variable Calculus
Prereq None
Units $\quad 5-0-7$
Syllabus Differentiation and integration of functions of one variable, with applications. Informal treatment of limits and continuity. Differentiation: definition, rules, application to graphing, rates, approximations, and extremum problems. Indefinite integration; separable first-order differential equations. Definite integral; fundamental theorem of calculus. Applications of integration to geometry and science. Elementary functions. Techniques of integration. Polar coordinates. L'Hopital's rule. Improper integrals. Infinite series: geometric, p-harmonic, simple comparison tests, power series for some elementary functions.</p>
<p>Table 3. MIT 18.01, Question 1: Original question, Codex input and code and code explanation, Program solution, Solution type, GPT-3 response and evaluation</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Topic</th>
<th style="text-align: center;">Functions and Models</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Original question</td>
<td style="text-align: center;">Sketch the graph of the function. $f(x)=x+</td>
</tr>
<tr>
<td style="text-align: center;">Codex input</td>
<td style="text-align: center;">Same as original question</td>
</tr>
<tr>
<td style="text-align: center;">Codex code</td>
<td style="text-align: center;"><code>import numpy as np import matplotlib.pyplot as plt x = np.linspace(-10, 10, 100) y = x + np.abs(x) plt.plot(x, y) plt.xlabel('x') plt.ylabel('y') plt.grid() plt.show()</code></td>
</tr>
<tr>
<td style="text-align: center;">Program solution</td>
<td style="text-align: center;"><img alt="img-8.jpeg" src="img-8.jpeg" /></td>
</tr>
<tr>
<td style="text-align: center;">Solution type</td>
<td style="text-align: center;">Automatic Zero-Shot</td>
</tr>
<tr>
<td style="text-align: center;">Codex code explanation</td>
<td style="text-align: center;">1. We import the numpy and matplotlib.pyplot libraries. <br> 2. We create an array of 100 evenly spaced numbers from -10 to 10 . <br> 3. We create an array of the same size as $x$, where each element is the absolute value of the corresponding element in $x$. <br> 4. We plot the graph of $y$ against $x$. <br> 5. We label the $x$-axis and $y$-axis. <br> 6. We display the grid. <br> 7. We display the graph.</td>
</tr>
<tr>
<td style="text-align: center;">GPT-3 response</td>
<td style="text-align: center;">The graph of the function is a line with a slope of 1 and a $y$-intercept of 0 .</td>
</tr>
<tr>
<td style="text-align: center;">GPT-3 evaluation</td>
<td style="text-align: center;">Incorrect</td>
</tr>
</tbody>
</table>
<p>Table 4. MIT 18.01, Question 2: Original question, Codex input and code and code explanation, Program solution, Solution type, GPT-3 response and evaluation</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Topic</th>
<th style="text-align: left;">Functions and Models</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Original question</td>
<td style="text-align: left;">Find $f \circ g \circ h . f(x)=3 x-2, g(x)=\sin (x), h(x)=x^{2}$</td>
</tr>
<tr>
<td style="text-align: left;">Codex input</td>
<td style="text-align: left;">Same as original question</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align: center;">Codex code</th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">import math <br> def $f(x)$ : <br> return $3 * x-2$ <br> def $g(x)$ : <br> return math. $\sin (x)$ <br> def $h(x)$ : <br> return $x * * 2$ <br> def $f g h(x)$ : <br> return $f(g(h(x)))$ <br> print(fgh(2))</td>
</tr>
<tr>
<td style="text-align: center;">Program solution</td>
<td style="text-align: center;">$3 \sin \left(x^{2}\right)-2$</td>
</tr>
<tr>
<td style="text-align: center;">Solution type</td>
<td style="text-align: center;">Automatic Zero-Shot</td>
</tr>
<tr>
<td style="text-align: center;">Codex code explanation</td>
<td style="text-align: center;">1. fgh(2) <br> 2. $h(2)$ <br> 3. $g(4)$ <br> 4. $f(\sin (4))$ <br> 5. $3 \sin 4-2$</td>
</tr>
<tr>
<td style="text-align: center;">GPT-3 response</td>
<td style="text-align: center;">$\mathrm{f}=\mathrm{g}=\mathrm{h}=\mathrm{f}(\mathrm{g}(\mathrm{h}(\mathrm{x})))=\mathrm{f}\left(\mathrm{g}\left(\mathrm{x}^{<em> </em>} 2\right)\right)=\mathrm{f}\left(\sin \left(\mathrm{x}^{<em> </em>} 2\right)\right)=3^{<em>} \sin \left(\mathrm{x}^{</em> *} 2\right)-2$</td>
</tr>
<tr>
<td style="text-align: center;">GPT-3 evaluation</td>
<td style="text-align: center;">Correct</td>
</tr>
</tbody>
</table>
<p>Table 5. MIT 18.01, Question 3: Original question, Codex input and code and code explanation, Program solution, Solution type, GPT-3 response and evaluation</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Topic</th>
<th style="text-align: left;">Functions and Models</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Original question</td>
<td style="text-align: left;">Solve each equation for $x . \ln \left(x^{2}-1\right)=3$</td>
</tr>
<tr>
<td style="text-align: left;">Codex input</td>
<td style="text-align: left;">Same as original question</td>
</tr>
<tr>
<td style="text-align: left;">Codex code</td>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">import sympy</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">$\mathrm{x}=$ sympy. Symbol $\left({ }^{\prime} \mathrm{x}^{\prime}\right)$ <br> eq = sympy.log $(\mathrm{x} * * 2-1)-3$ <br> print(sympy.solve(eq, x))</td>
</tr>
<tr>
<td style="text-align: left;">Program solution</td>
<td style="text-align: left;">$-\sqrt{1+e^{3}} \cdot \sqrt{1+e^{3}}$</td>
</tr>
<tr>
<td style="text-align: left;">Solution type</td>
<td style="text-align: left;">Automatic Zero-Shot</td>
</tr>
<tr>
<td style="text-align: left;">Codex code explanation</td>
<td style="text-align: left;">1. We import the sympy module. <br> 2. We create a symbol $x$. <br> 3. We create an equation. <br> 4. We solve the equation for $x$.</td>
</tr>
<tr>
<td style="text-align: left;">GPT-3 response</td>
<td style="text-align: left;">$x^{<em> </em>} 2-1=e^{<em> </em>} 3$ <br> $x^{<em> </em>} 2=e^{<em> </em>} 3+1$ <br> $x=\operatorname{sqrt}\left(e^{<em> </em>} 3+1\right)$</td>
</tr>
<tr>
<td style="text-align: left;">GPT-3 evaluation</td>
<td style="text-align: left;">Correct</td>
</tr>
</tbody>
</table>
<p>Table 6. MIT 18.01, Question 4: Original question, Codex input and code and code explanation, Program solution, Solution type, GPT-3 response and evaluation</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Topic</th>
<th style="text-align: left;">Limits and Derivatives</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Original question</td>
<td style="text-align: left;">Determine the infinite limit. $\lim _{x \rightarrow 5^{+}}(x+1) /(x-5)$</td>
</tr>
<tr>
<td style="text-align: left;">Codex input</td>
<td style="text-align: left;">Using sympy determine the infinite limit. lim_x_5+ $(x+1) /(x-5)$</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align: left;">Codex code</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">from sympy import limit, Symbol, S</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">$\mathrm{x}=$ Symbol('x')</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">limit $((x+1) /(x-5), x, 5)$</td>
</tr>
<tr>
<td style="text-align: left;">Program solution</td>
<td style="text-align: left;">$\infty$</td>
</tr>
<tr>
<td style="text-align: left;">Solution type</td>
<td style="text-align: left;">Automatic Zero-Shot</td>
</tr>
<tr>
<td style="text-align: left;">Codex code explanation</td>
<td style="text-align: left;">1. We import the limit function from the sympy module. <br> 2. We create a Symbol object called $x$. <br> 3. We call the limit function and pass in the expression $(x+1) /(x-5)$ and the variable $x$. <br> 4. We pass in the point 5 as the third argument.</td>
</tr>
<tr>
<td style="text-align: left;">GPT-3 response</td>
<td style="text-align: left;">The limit does not exist because the function is not defined when $x=5$.</td>
</tr>
<tr>
<td style="text-align: left;">GPT-3 evaluation</td>
<td style="text-align: left;">Incorrect</td>
</tr>
</tbody>
</table>
<p>Table 7. MIT 18.01, Question 5: Original question, Codex input and code and code explanation, Program solution, Solution type, GPT-3 response and evaluation</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Topic</th>
<th style="text-align: center;">Limits and Derivatives</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Original question</td>
<td style="text-align: center;">Find the limits as $x \rightarrow \infty$ and as $x \rightarrow-\infty$. Use this information, together with intercepts, to give a rough sketch of the graph as in Example 12. $y=x^{2}\left(x^{2}-1\right)^{2}(x+2)$</td>
</tr>
<tr>
<td style="text-align: center;">Codex input</td>
<td style="text-align: center;">Same as original question</td>
</tr>
<tr>
<td style="text-align: center;">Codex code</td>
<td style="text-align: center;"><code>import sympy as sym from sympy import Symbol from sympy import pprint sigma = Symbol('sigma') x = Symbol('x') mu = Symbol('mu') pprint(2*sym.pi*sigma) pprint(sym.sqrt(2*sym.pi*sigma)) part_1 = 1/(sym.sqrt(2*sym.pi*sigma)) part_2 = sym.exp(-1*((x-mu)**2)/(2*sigma)) my_gauss_function = part_1*part_2 pprint(my_gauss_function) sym.plot(my_gauss_function.subs({mu:10,sigma:30}),(x,0,100),title='gauss distribution') x_values = [] y_values = [] for value in range(-5,5): y = my_gauss_function.subs({mu:10,sigma:30,x:value}).evalf() y_values.append(y) x_values.append(value) print(value,y) import matplotlib.pyplot as plt plt.plot(x_values,y_values) plt.show()</code></td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align: left;">Program solution</th>
<th style="text-align: left;">$\infty ;-\infty ;$</th>
<th style="text-align: left;"></th>
<th style="text-align: left;"></th>
<th style="text-align: left;"></th>
<th style="text-align: left;"></th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">1.25</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">1.00</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">0.75</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">0.50</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">0.25</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">0.00</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">$-0.25$</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">$-0.50$</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">$-0.75$</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;">Solution type</td>
<td style="text-align: left;">Automatic Zero-Shot</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;">Codex code explanation</td>
<td style="text-align: left;">1. We create a list of $x$ values from -5 to 5. <br> 2. We create an empty list to store the $y$ values. <br> 3. We loop through the $x$ values. <br> 4. For each $x$ value, we calculate the $y$ value. <br> 5. We append the $y$ value to the list of $y$ values. <br> 6. We plot the $x$ values against the $y$ values.</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;">GPT-3 response</td>
<td style="text-align: left;">As $x \rightarrow$ infinity, $y \rightarrow$ infinity. As $x \rightarrow-$ infinity, $y \rightarrow$ infinity. <br> The graph will look like a parabola that opens up.</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;">GPT-3 evaluation</td>
<td style="text-align: left;">Incorrect</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
</tbody>
</table>
<p>Table 8. MIT 18.01, Question 6: Original question, Codex input and code and code explanation, Program solution, Solution type, GPT-3 response and evaluation</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Topic</th>
<th style="text-align: left;">Limits and Derivatives</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Original question</td>
<td style="text-align: left;">Find the derivative of the function using the definition of a derivative. $f(x)=\left(x^{2}-1\right) /(2 x-3)$</td>
</tr>
<tr>
<td style="text-align: left;">Codex input</td>
<td style="text-align: left;">Using Sympy find the derivative of the function using the definition of a derivative. $f(x)=\left(x^{<em> </em>} 2-1\right) /\left(2^{*} x-3\right)$</td>
</tr>
<tr>
<td style="text-align: left;">Codex code</td>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">import sympy as sp</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">$x=\operatorname{sp} . \operatorname{Symbol}\left(' x^{\prime}\right)$</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">$f=(x * * 2-1) /(2 * x-3)$</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">print(sp.diff(f,x))</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">$x=\frac{2 x}{2 x-3}-\frac{2\left(x^{*}-1\right)}{2 x-3}$</td>
</tr>
<tr>
<td style="text-align: left;">Program solution</td>
<td style="text-align: left;">Automatic Zero-Shot</td>
</tr>
<tr>
<td style="text-align: left;">Solution type</td>
<td style="text-align: left;">1. We import sympy as sp <br> 2. We create a symbol $x$ <br> 3. We create a function $f$ <br> 4. We print the derivative of $f$ with respect to $x$</td>
</tr>
<tr>
<td style="text-align: left;">Codex code explanation</td>
<td style="text-align: left;">$2^{<em>}(2 * * 2-1) /\left(2^{</em>} x-3\right)^{* * 2}$</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">Correct</td>
</tr>
</tbody>
</table>
<p>Table 9. MIT 18.01, Question 7: Original question, Codex input and code and code explanation, Program solution, Solution type, GPT-3 response and evaluation</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Topic</th>
<th style="text-align: left;">Differentiation Rules</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Original question</td>
<td style="text-align: left;">Find the limit. $\lim _{x \rightarrow 0} \operatorname{csc}(x) \sin (\sin (x))$</td>
</tr>
<tr>
<td style="text-align: left;">Codex input</td>
<td style="text-align: left;">Same as original question</td>
</tr>
<tr>
<td style="text-align: left;">Codex code</td>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">from sympy import limit, csc, sin, Symbol</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">$x=\operatorname{Symbol}\left(' x^{\prime}\right)$</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">print(limit(csc(x)*sin(sin(x)), x, 0))</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align: left;">Program solution</th>
<th style="text-align: left;">1</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Solution type</td>
<td style="text-align: left;">Automatic Zero-Shot</td>
</tr>
<tr>
<td style="text-align: left;">Codex code explanation</td>
<td style="text-align: left;">1. We are finding the limit of $\mathrm{csc}(\mathrm{x})^{*} \sin (\sin (\mathrm{x}))$ as x approaches 0. <br> 2. We are using the limit function from the sympy library. <br> 3. We are passing in the function $\operatorname{csc}(x)^{\star} \sin (\sin (x))$ as the first argument. <br> 4. We are passing in the variable $x$ as the second argument. <br> 5. We are passing in the number 0 as the third argument.</td>
</tr>
<tr>
<td style="text-align: left;">GPT-3 response</td>
<td style="text-align: left;">The limit does not exist.</td>
</tr>
<tr>
<td style="text-align: left;">GPT-3 evaluation</td>
<td style="text-align: left;">Incorrect</td>
</tr>
</tbody>
</table>
<p>Table 10. MIT 18.01, Question 8: Original question, Codex input and code and code explanation, Program solution, Solution type, GPT-3 response and evaluation</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Topic</th>
<th style="text-align: center;">Differentiation Rules</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Original question</td>
<td style="text-align: center;">The half-life of cesium-137 is 30 years. Suppose we have a 100-mg sample. How much of the sample remains after 100 years?</td>
</tr>
<tr>
<td style="text-align: center;">Codex input</td>
<td style="text-align: center;">Write a program. The half-life of cesium-137 is 30 years. Suppose we have a 100-mg sample. How much of the sample remains after 100 years?</td>
</tr>
<tr>
<td style="text-align: center;">Codex code</td>
<td style="text-align: center;">import math <br> def half_life(t, h): <br> return 100 * math.pow(0.5, t/h) <br> print(half_life(100, 30))</td>
</tr>
<tr>
<td style="text-align: center;">Program solution</td>
<td style="text-align: center;">9.92 mg</td>
</tr>
<tr>
<td style="text-align: center;">Solution type</td>
<td style="text-align: center;">Automatic Zero-Shot</td>
</tr>
<tr>
<td style="text-align: center;">Codex code explanation</td>
<td style="text-align: center;">1. We import the math module. <br> 2. We define a function called half_life that takes two arguments: $t$ and $h$. <br> 3. We return the value of $100 * 0.5^{*} /(t / h)$. <br> 4. We print the result of half_life(100, 30).</td>
</tr>
<tr>
<td style="text-align: center;">GPT-3 response</td>
<td style="text-align: center;">After 100 years, 50 mg of the sample would remain.</td>
</tr>
<tr>
<td style="text-align: center;">GPT-3 evaluation</td>
<td style="text-align: center;">Incorrect</td>
</tr>
</tbody>
</table>
<p>Table 11. MIT 18.01, Question 9: Original question, Codex input and code and code explanation, Program solution, Solution type, GPT-3 response and evaluation</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Topic</th>
<th style="text-align: center;">Differentiation Rules</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Original question</td>
<td style="text-align: center;">The radius of a sphere is increasing at a rate of $4 \mathrm{~mm} / \mathrm{s}$. How fast is the volume increasing when the diameter is 80 mm ?</td>
</tr>
<tr>
<td style="text-align: center;">Codex input</td>
<td style="text-align: center;">Same as original question</td>
</tr>
<tr>
<td style="text-align: center;">Codex code</td>
<td style="text-align: center;">import sympy as sp <br> $r=$ sp.symbols('r') <br> $d=4 * r$ <br> $v=4 / 3 <em>$ sp.pi</em>r**3 <br> $d v _d r=$ sp.diff $(v, r)$ <br> print(dv_dr.subs $(r, 80))$</td>
</tr>
<tr>
<td style="text-align: center;">Program solution</td>
<td style="text-align: center;">25600 r</td>
</tr>
<tr>
<td style="text-align: center;">Solution type</td>
<td style="text-align: center;">Manual</td>
</tr>
<tr>
<td style="text-align: center;">Codex code explanation</td>
<td style="text-align: center;">1. We define the radius as a symbol. <br> 2. We define the diameter as a function of the radius. <br> 3. We define the volume as a function of the radius. <br> 4. We take the derivative of the volume with respect to the radius. <br> 5. We substitute the radius with 80 and print the result.</td>
</tr>
<tr>
<td style="text-align: center;">GPT-3 response</td>
<td style="text-align: center;">The volume of a sphere is increasing at a rate of approximately $201.06 \mathrm{~mm} 3 / \mathrm{s}$.</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align: left;">GPT-3 evaluation</th>
<th style="text-align: left;">Incorrect</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>Table 12. MIT 18.01, Question 10: Original question, Codex input and code and code explanation, Program solution, Solution type, GPT-3 response and evaluation</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Topic</th>
<th style="text-align: center;">Applications of Differentiation</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Original question</td>
<td style="text-align: center;">The water level, measured in feet above mean sea level, of Lake Lanier in Georgia, USA, during 2012 can be modeled by the function $L(t)=0.01441 t^{3}-0.4177 t^{2}+2.703 t+1060.1$ where $t$ is measured in months since January 1, 2012. Estimate when the water level was highest during 2012.</td>
</tr>
<tr>
<td style="text-align: center;">Codex input</td>
<td style="text-align: center;">Same as original question</td>
</tr>
<tr>
<td style="text-align: center;">Codex code</td>
<td style="text-align: center;">import math <br> def $L(t)$ : <br> return $0.01441 * t * * 3-0.4177 * t * * 2+2.703 * t+1060.1$ <br> def $d L(t)$ : <br> return $0.04323 * t * * 2-0.8354 * t+2.703$ <br> def $d d L(t)$ : <br> return $0.08646 * t-0.8354$ <br> def newton(f, df, x0, epsilon): <br> $\mathrm{x}=\mathrm{x} 0$ <br> while True: <br> $\mathrm{x} 1=\mathrm{x}-\mathrm{f}(\mathrm{x}) / \mathrm{df}(\mathrm{x})$ <br> if abs(x1 - x) &lt; epsilon: <br> return x1 <br> $\mathrm{x}=\mathrm{x} 1$ <br> print(newton(dL, ddL, 0, 0.00001))</td>
</tr>
<tr>
<td style="text-align: center;">Program solution</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Solution type</td>
<td style="text-align: center;">Automatic Zero-Shot</td>
</tr>
<tr>
<td style="text-align: center;">Codex code explanation</td>
<td style="text-align: center;">1. We define the function $L(t)$ <br> 2. We define the derivative of $L(t)$ <br> 3. We define the second derivative of $L(t)$ <br> 4. We define a function that uses Newton's method to find the root of a function $f(x)$ <br> 5. We print the result of using Newton's method to find the root of the derivative of $L(t)$</td>
</tr>
<tr>
<td style="text-align: center;">GPT-3 response</td>
<td style="text-align: center;">The water level was maximum at $t=2$.</td>
</tr>
<tr>
<td style="text-align: center;">GPT-3 evaluation</td>
<td style="text-align: center;">Incorrect</td>
</tr>
</tbody>
</table>
<p>Table 13. MIT 18.01, Question 11: Original question, Codex input and code and code explanation, Program solution, Solution type, GPT-3 response and evaluation</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Topic</th>
<th style="text-align: left;">Applications of Differentiation</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Original question</td>
<td style="text-align: left;">If a resistor of $R$ ohms is connected across a battery of $E$ volts with internal resistance $r$ ohms, then the <br> power (in watts) in the external resistor is $P=E^{2} R /(R+r)^{2}$. If $E$ and $r$ are fixed but $R$ varies, what is <br> the maximum value of the power?</td>
</tr>
<tr>
<td style="text-align: left;">Codex input</td>
<td style="text-align: left;">Same as original question</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align: center;">Codex code</th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">import sympy as sym <br> from sympy import Symbol <br> from sympy import pprint <br> $R=$ Symbol('R') <br> $E=$ Symbol('E') <br> $r=$ Symbol('r') <br> $P=E * * 2 * R /(R+r) * * 2$ <br> print(P) <br> $d P=P . d i f f(R)$ <br> print(dP) <br> R_sol = sym.solve(dP,R) <br> print(R_sol) <br> R_max $=$ R_sol[0].evalf() <br> print(R_max) <br> P_max $=$ P.subs({R:R_max}) <br> print(P_max)</td>
</tr>
<tr>
<td style="text-align: center;">Program solution</td>
<td style="text-align: center;">$\frac{E^{<em>}}{R^{</em>}}$</td>
</tr>
<tr>
<td style="text-align: center;">Solution type</td>
<td style="text-align: center;">Automatic Few-Shot (5)</td>
</tr>
<tr>
<td style="text-align: center;">Codex code explanation</td>
<td style="text-align: center;">1. Define the variables <br> 2. Define the function <br> 3. Take the derivative of the function <br> 4. Solve the derivative for $R$ <br> 5. Evaluate the solution <br> 6. Substitute the solution into the original function</td>
</tr>
<tr>
<td style="text-align: center;">GPT-3 response</td>
<td style="text-align: center;">The maximum value of the power is $P=E^{\prime} 2 R \cdot(R+r)^{\prime} 2$ when $R=r$.</td>
</tr>
<tr>
<td style="text-align: center;">GPT-3 evaluation</td>
<td style="text-align: center;">Incorrect</td>
</tr>
</tbody>
</table>
<p>Table 14. MIT 18.01, Question 12: Original question, Codex input and code and code explanation, Program solution, Solution type, GPT-3 response and evaluation</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Topic</th>
<th style="text-align: left;">Applications of Differentiation</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Original question</td>
<td style="text-align: left;">Use Newton's method to find all the solutions of the equation correct to eight decimal places. Start by <br> drawing a graph to find initial approximations. $x^{5}-3 x^{4}+x^{3}-x^{2}-x+6=0$</td>
</tr>
<tr>
<td style="text-align: left;">Codex input</td>
<td style="text-align: left;">Use Newton's method to find all the solutions between -100 and 100 with integer initial values. $x^{<em> </em>} 5-$ <br> $3^{<em>} x^{</em> <em>} 4+x^{</em> <em>} 3-x^{</em> *} 2-x+6=0$. Use initial points between -100 and 100. Round to 8 decimal places.</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align: center;">Codex code</th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">import numpy as np <br> import matplotlib.pyplot as plt <br> def $f(x)$ : <br> return $x * * 5-3 * x * * 4+x * * 3-x * * 2-x+6$ <br> def df(x): <br> return $5 * x * * 4-12 * x * * 3+3 * x * * 2-2 * x-1$ <br> def newton(x, f, df, epsilon=1e-8, max_iter=1000): <br> for i in range(max_iter): <br> $\mathrm{x} _\mathrm{new}=\mathrm{x}-\mathrm{f}(\mathrm{x}) / \mathrm{df}(\mathrm{x})$ <br> if abs(x_new - x) &lt; epsilon: <br> return x_new <br> $\mathrm{x}=\mathrm{x} _\mathrm{new}$ <br> return x_new <br> def main(): <br> $\mathrm{x}=$ np.linspace $(-100,100,1000)$ <br> $\mathrm{y}=\mathrm{f}(\mathrm{x})$ <br> plt.plot(x, y) <br> plt.grid() <br> plt.show() <br> x_sols = [] <br> for i in range $(-100,100)$ : <br> x_sols.append(newton(i, f, df)) <br> print(x_sols) <br> print(np.round(x_sols, 8)) <br> if <strong>name</strong> == '<strong>main</strong>'： <br> main()</td>
</tr>
<tr>
<td style="text-align: center;">Program solution</td>
<td style="text-align: center;">$-1.044503071109637,2.7055120932482875$</td>
</tr>
<tr>
<td style="text-align: center;">Solution type</td>
<td style="text-align: center;">Manual</td>
</tr>
<tr>
<td style="text-align: center;">Codex code explanation</td>
<td style="text-align: center;">1. Plotting the function $f(x)=x^{<em> </em>} 5-3^{<em>} x^{</em> <em>} 4+x^{</em> <em>} 3-x^{</em> *} 2-x+6$ <br> 2. Finding the derivative of $f(x)$ <br> 3. Using Newton's method to find the roots of $f(x)$ <br> 4. Plotting the roots of $f(x)$</td>
</tr>
<tr>
<td style="text-align: center;">GPT-3 response</td>
<td style="text-align: center;">There are five solutions. <br> -1.46557123 <br> -0.53728871 <br> 0.36082474 <br> 1.12403607 <br> 2.09132432</td>
</tr>
<tr>
<td style="text-align: center;">GPT-3 evaluation</td>
<td style="text-align: center;">Incorrect</td>
</tr>
</tbody>
</table>
<p>Table 15. MIT 18.01, Question 13: Original question, Codex input and code and code explanation, Program solution, Solution type, GPT-3 response and evaluation</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Topic</th>
<th style="text-align: left;">Integrals</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Original question</td>
<td style="text-align: left;">Evaluate $\int_{1}^{1} \sqrt{1+x^{4}} d x$.</td>
</tr>
<tr>
<td style="text-align: left;">Codex input</td>
<td style="text-align: left;">Write a program to evaluate the integral from 1 to 1 of $\operatorname{sqrt}\left(1+x^{\prime} 4\right) d x$.</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align: center;">Codex code</th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">from sympy import Symbol, sqrt, Integral, pprint $x=$ Symbol('x') <br> $k=$ Symbol('k') <br> $p=\operatorname{sqrt}(1+x * * 4)$ <br> pprint(Integral(p, (x, 1, 1)).doit())</td>
</tr>
<tr>
<td style="text-align: center;">Program solution</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: center;">Solution type</td>
<td style="text-align: center;">Automatic Zero-Shot</td>
</tr>
<tr>
<td style="text-align: center;">Codex code explanation</td>
<td style="text-align: center;">1. We create a Symbol object called $x$. <br> 2. We create a Symbol object called $k$. <br> 3. We create a symbolic expression called $p$. <br> 4. We create an Integral object called p_integral. <br> 5. We call the doit() method on the Integral object.</td>
</tr>
<tr>
<td style="text-align: center;">GPT-3 response</td>
<td style="text-align: center;">The integral from 1 to 1 of $\operatorname{sqrt}(1+x^{*} 4) \mathrm{dx}$ is equal to 2 .</td>
</tr>
<tr>
<td style="text-align: center;">GPT-3 evaluation</td>
<td style="text-align: center;">Incorrect</td>
</tr>
</tbody>
</table>
<p>Table 16. MIT 18.01, Question 14: Original question, Codex input and code and code explanation, Program solution, Solution type, GPT-3 response and evaluation</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Topic</th>
<th style="text-align: center;">Integrals</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Original question</td>
<td style="text-align: center;">Sketch the region enclosed by the given curves and calculate its area. $y=4-x^{2}, y=0$</td>
</tr>
<tr>
<td style="text-align: center;">Codex input</td>
<td style="text-align: center;">Using numpy, graph the lines $y=0$ and $y=4-x^{<em> </em>} 2$. Use fill_between(). <br> Then using Sympy, find the points of intersection between and $y=0$ and $y=4-x^{<em> </em>} 2$. <br> Integrate between lines $y=4-x^{<em> </em>} 2$ and $y=0$, over the points of intersection to calculate the area of the region. $x$ should go from -5 to 5 .</td>
</tr>
<tr>
<td style="text-align: center;">Codex code</td>
<td style="text-align: center;"><code>import numpy as np import matplotlib.pyplot as plt import sympy as sp x = np.linspace(-5, 5, 100) y1 = 0*x y2 = 4-x**2 plt.plot(x, y1, '-b', label='y=0') plt.plot(x, y2, '-r', label='y=4-x**2') plt.fill_between(x, y1, y2, color='grey', alpha=0.5) plt.legend(loc='best') plt.show() x, y = sp.symbols('x y') f = 4-x**2 g = 0*x sols = sp.solve([f, g], [x, y]) x1 = sols[0][0] y1 = sols[0][1] x2 = sols[1][0] y2 = sols[1][1] area = sp.integrate(f, (x, x1, x2)) + sp.integrate(g, (x, x1, x2)) print(area)</code></td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align: left;">Program solution</th>
<th style="text-align: left;">$\frac{33}{3}$</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">$\frac{1}{4}$</td>
</tr>
<tr>
<td style="text-align: left;">Solution type</td>
<td style="text-align: left;">Manual</td>
</tr>
<tr>
<td style="text-align: left;">Codex code explanation</td>
<td style="text-align: left;">1. We are using numpy to graph the lines $y=0$ and $y=4-x^{<em> </em>} 2$. We are using fill_between() to fill in the area <br> between the two lines. <br> 2. We are using Sympy to find the points of intersection between the two lines. <br> 3. We are using Sympy to integrate between the two lines, over the points of <br> intersection, to calculate the area of the region.</td>
</tr>
<tr>
<td style="text-align: left;">GPT-3 Response</td>
<td style="text-align: left;">The region is enclosed by the curves $y=4-x^{*} 2, y=0$, and $x=2$. Its area is 16.</td>
</tr>
<tr>
<td style="text-align: left;">GPT-3 evaluation</td>
<td style="text-align: left;">Incorrect</td>
</tr>
</tbody>
</table>
<p>Table 17. MIT 18.01, Question 15: Original question, Codex input and code and code explanation, Program solution, Solution type, GPT-3 response and evaluation</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Topic</th>
<th style="text-align: center;">Integrals</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Original question</td>
<td style="text-align: center;">A bacteria population is 4000 at time $t=0$ and its rate of growth is $1000 \cdot 2^{t}$ bacteria per hour after $t$ hours. What is the population after one hour?</td>
</tr>
<tr>
<td style="text-align: center;">Codex input</td>
<td style="text-align: center;">A bacteria population is 4000 at time $t=0$ and its rate of growth is $y=1000 * 2^{*}$ x bacteria per hour after t hours. Write a function to calculate the population after one hour. Use sympy to integrate the symbol $x$ from 0 to 1 . Then add the initial population to the result.</td>
</tr>
<tr>
<td style="text-align: center;">Codex code</td>
<td style="text-align: center;">import sympy as sp <br> $x=$ sp. Symbol('x') <br> def bacteria_population(x): <br> return $1000 * 2 * * x$ <br> print(sp.integrate(bacteria_population(x), (x, 0, 1)) + 4000)</td>
</tr>
<tr>
<td style="text-align: center;">Program solution</td>
<td style="text-align: center;">$\frac{1000}{1000}+4000$</td>
</tr>
<tr>
<td style="text-align: center;">Solution type</td>
<td style="text-align: center;">Manual</td>
</tr>
<tr>
<td style="text-align: center;">Codex code explanation</td>
<td style="text-align: center;">1. We import sympy as sp. <br> 2. We define $x$ as a symbol. <br> 3. We define a function bacteria_population $(x)$ that returns the population of bacteria after $x$ hours. <br> 4. We print the result of integrating the function bacteria_population $(x)$ from 0 to 1 and adding the initial <br> population of 4000 .</td>
</tr>
<tr>
<td style="text-align: center;">GPT-3 response</td>
<td style="text-align: center;">5000</td>
</tr>
<tr>
<td style="text-align: center;">GPT-3 evaluation</td>
<td style="text-align: center;">Incorrect</td>
</tr>
</tbody>
</table>
<p>Table 18. MIT 18.01, Question 16: Original question, Codex input and code and code explanation, Program solution, Solution type, GPT-3 response and evaluation</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Topic</th>
<th style="text-align: left;">Applications of Integration</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Original question</td>
<td style="text-align: left;">Graph the region between the curves and use your calculator to compute the area correct to five decimal <br> places. $y=\tan ^{2}(x), y=\sqrt{x}$</td>
</tr>
<tr>
<td style="text-align: left;">Codex input</td>
<td style="text-align: left;">Graph the region between the curves $y=\tan ^{-} 2(x)$ and $y=\operatorname{sqrt}(x)$ to find the two points where they <br> intersect. Then, write a program to compute the area between the curves where they cross. Use sympy.</td>
</tr>
</tbody>
</table>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{5}$ Data and code: https://github.com/droni/matNQ&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref4:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>