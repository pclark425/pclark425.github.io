<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-6757 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-6757</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-6757</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-130.html">extraction-schema-130</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models solving spatial puzzle games, including details about the model, the puzzle, the reasoning or prompting method, performance metrics, internal representations, use of external tools, and any analysis or limitations reported.</div>
                <p><strong>Paper ID:</strong> paper-62ee2d23968b8ee97c958d75ae2b6ae13c84da1a</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/62ee2d23968b8ee97c958d75ae2b6ae13c84da1a" target="_blank">BRAINTEASER: Lateral Thinking Puzzles for Large Language Models</a></p>
                <p><strong>Paper Venue:</strong> Conference on Empirical Methods in Natural Language Processing</p>
                <p><strong>Paper TL;DR:</strong> A multiple-choice Question Answering task designed to test the model's ability to exhibit lateral thinking and defy default commonsense associations, and enrich BRAINTEASER based on a semantic and contextual reconstruction of its questions to assess the consistency of lateral reasoning by models.</p>
                <p><strong>Paper Abstract:</strong> The success of language models has inspired the NLP community to attend to tasks that require implicit and complex reasoning, relying on human-like commonsense mechanisms. While such vertical thinking tasks have been relatively popular, lateral thinking puzzles have received little attention. To bridge this gap, we devise BRAINTEASER: a multiple-choice Question Answering task designed to test the model's ability to exhibit lateral thinking and defy default commonsense associations. We design a three-step procedure for creating the first lateral thinking benchmark, consisting of data collection, distractor generation, and generation of adversarial examples, leading to 1,100 puzzles with high-quality annotations. To assess the consistency of lateral reasoning by models, we enrich BRAINTEASER based on a semantic and contextual reconstruction of its questions. Our experiments with state-of-the-art instruction- and commonsense language models reveal a significant gap between human and model performance, which is further widened when consistency across adversarial formats is considered. We make all of our code and data available to stimulate work on developing and evaluating lateral thinking models.</p>
                <p><strong>Cost:</strong> 0.005</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <p class="empty-note">No extracted data.</p>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <p class="empty-note">No potentially relevant new papers extracted.</p>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-6757",
    "paper_id": "paper-62ee2d23968b8ee97c958d75ae2b6ae13c84da1a",
    "extraction_schema_id": "extraction-schema-130",
    "extracted_data": [],
    "potentially_relevant_new_papers": [],
    "cost": 0.004994,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>BrainTeaser: Lateral Thinking Puzzles for Large Language Models</h1>
<p>Yifan Jiang ${ }^{1}$, Filip Ilievski ${ }^{1,2}$, Kaixin Ma ${ }^{3 *}$, Zhivar Sourati ${ }^{1}$<br>${ }^{1}$ Information Sciences Institute, Viterbi School of Engineering, University of Southern California<br>${ }^{2}$ Department of Computer Science, Faculty of Science, Vrije Universiteit Amsterdam<br>${ }^{3}$ Tencent AI Lab, Bellevue, WA<br>{yifjia,ilievski, Souratih}@isi.edu, f.ilievski@vu.nl<br>kaixinma@global.tencent.com</p>
<h4>Abstract</h4>
<p>The success of language models has inspired the NLP community to attend to tasks that require implicit and complex reasoning, relying on human-like commonsense mechanisms. While such vertical thinking tasks have been relatively popular, lateral thinking puzzles have received little attention. To bridge this gap, we devise BrainTeaser: a multiple-choice Question Answering task designed to test the model's ability to exhibit lateral thinking and defy default commonsense associations. We design a three-step procedure for creating the first lateral thinking benchmark, consisting of data collection, distractor generation, and generation of reconstruction examples, leading to 1,100 puzzles with high-quality annotations. To assess the consistency of lateral reasoning by models, we enrich BrainTeaser based on a semantic and contextual reconstruction of its questions. Our experiments with state-of-the-art instruction- and commonsense language models reveal a significant gap between human and model performance, which is further widened when consistency across reconstruction formats is considered. We make all of our code and data available to stimulate work on developing and evaluating lateral thinking models.</p>
<h2>1 Introduction</h2>
<p>Human reasoning processes comprise two types of thinking: vertical and lateral (Waks, 1997). Vertical thinking, also known as linear, convergent, or logical thinking, is a sequential analytical process that is based on rationality, logic, and rules, typically associated with the left-brain hemisphere. Vertical thinking, as illustrated in Figure 1 (top), is needed to create a reasoning path from flooding a room to filling it with water for physical reasoning, and from inanimate objects with five fingers to gloves in riddles. Meanwhile, lateral thinking (or "thinking</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: Contrasting existing Vertical Thinking tasks (PIQA (Bisk et al., 2020) and RiddleSense (Lin et al., 2021)) to our novel lateral thinking task called BRAINTEASER. While prior tasks require commonsense to be injected, BrainTeASER's lateral thinking puzzles require default commonsense thinking to be deprecated.
outside the box") is a divergent and creative process that involves looking at a problem from a new perspective and defying preconceptions, associated with the right-brain hemisphere (De Bono, 1970; Waks, 1997). Lateral thinking is required to solve the puzzle in Figure 1 (bottom), by overwriting the commonsense associations of man shaves to he shaves himself, and regarding the man as somebody who shaves others all day (e.g., a barber).</p>
<p>The development of natural language processing (NLP) models and their evaluation has achieved much progress in vertical thinking. In particular, large language models (LLMs) (Devlin et al., 2019; Liu et al., 2019; Brown et al., 2020b) have achieved strong performance across a variety of complex reasoning tasks (Talmor et al., 2019; Bisk et al., 2020;</p>
<p>Sap et al., 2019b), even with the complete absence (zero-shot) (Sanh et al., 2022) or limited provision (few-shot) of training time exemplars (Chung et al., 2022). ${ }^{1}$ To perform well on tasks such as reasoning over physical interactions (Bisk et al., 2020) and social implications (Sap et al., 2019b), LLMs exhibit better vertical thinking capabilities, including commonsense association (Wei et al., 2022) and inference ability (Bosselut et al., 2019). While the extent to which these models possess common sense is heavily discussed (Marcus, 2022; Bubeck et al., 2023; Wei et al., 2023), we note that prior work has not considered the lateral thinking ability of LLMs. Creative thinking problems in benchmarks and knowledge bases are often filtered out as noise during preprocessing (Vajjala and Meurers, 2012; Speer et al., 2017; Sap et al., 2019a), and only kept if their resolution can be supported by commonsense associations, as in the case of riddles (Figure 1) (Lin et al., 2021; Gao et al., 2018). As many situations are novel, we expect that lateral thinking puzzles like those in Figure 1-bottom will be hindered by default commonsense associations and cannot be easily solved by further adaptation and scaling of the existing LLM methods.</p>
<p>To bridge this gap, we propose to study the ability of state-of-the-art LLMs to reason on lateral thinking puzzles. We formulate lateral thinking puzzles as multiple-choice Question Answering (QA) tasks, making them intuitive to answer by humans and easy to evaluate automatically. Following our task definition, we create a novel BrainTeaser benchmark with two tasks of different granularity: Sentence Puzzles and Word Puzzles (cf. Figure 1). To construct the dataset, we design a data collection procedure, which crawls relevant puzzles from several publicly available websites, performs semiautomatic filtering of irrelevant question categories (e.g., pun, dad jokes), and ensures high data quality. To ensure fair and informative questions, we construct distractors semi-automatically by manual annotation of the explicit and implicit (commonsense) premises that arise from each puzzle. To address concerns of possible LLM memorization (Carlini et al., 2022) and their lack of consistency (Goldberg, 2023), we enrich BrainTeaser with two reconstruction strategies: semantic reconstruction and context reconstruction, which create variants of each puzzle without changing its original way of</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup>defying default commonsense associations. This systematic procedure results in a novel BRAINTEASER benchmark with 1.1 K high-quality data points and nearly $100 \%$ human evaluation results. Using BrainTeaser as the benchmark, we conduct comprehensive experiments involving different model structures, model sizes, and prompting strategies. The results reveal a huge gap between human performance and current LLMs, indicating the great need to improve lateral thinking in LLMs.</p>
<p>We summarize our contributions as follows: 1) We introduce lateral thinking puzzles, a multiplechoice QA task designed to test the model's ability to exhibit lateral thinking and defy default commonsense associations. 2) We design a three-step procedure for creating the first lateral thinking benchmark, BrainTeaser, consisting of data collection, distractor generation, and generation of reconstruction examples, leading to 1,100 highquality puzzles. 3) We conduct comprehensive experiments with state-of-the-art LLMs. We make all of our code and data available to stimulate work on developing and evaluating lateral thinking models. ${ }^{2}$</p>
<h2>2 Related work</h2>
<p>We review prior work on computational creativity, commonsense reasoning, and model robustness.</p>
<p>Computational Creativity Computational creativity work includes a broader set of tasks, some of which have been relatively popular, including pun (Zou and Lu, 2019) and humor (Meaney et al., 2021) detection. A particular class of creative challenges, called brain teasers (Draper, 2009; Highhouse et al., 2019), is designed to evaluate a wide range of human intelligence skills, including strategy development, planning, visual-spatial thinking, creativity, and memory (Altun et al., 2016). Most similar to our task, Lin et al. (2021) collects riddles from public websites to challenge current models. While in principle computational creativity puzzles and brain teasers combine vertical and lateral thinking, prior work has focused on the former category. Our BrainTeaser task complements these works with word- and sentence-level lateral thinking puzzles. BrainTeaser can serve as a formal platform to evaluate the creative skills of LLMs, which have been partially explored in recent work</p>
<p><sup id="fnref:1"><a class="footnote-ref" href="#fn:1">2</a></sup></p>
<p>(Franceschelli and Musolesi, 2023; Bubeck et al., 2023; Wang et al., 2023a).</p>
<p>Commonsense Reasoning The task of commonsense reasoning has been popular in recent years (Rajani et al., 2019; Ma et al., 2019; Lourie et al., 2021; Maharana and Bansal, 2022), accompanied by the introduction of numerous challenging benchmarks (Talmor et al., 2019; Sap et al., 2019b; Sakaguchi et al., 2019) and availability of largescale commonsense resources (Speer et al., 2017; Hwang et al., 2021). While each of the existing datasets focuses on different dimensions of commonsense knowledge (Ilievski et al., 2021a), most of them are constructed in the multiple-choice format, due to the ease of evaluation. Some prior works have focused on generative commonsense reasoning (Lin et al., 2020; Boratko et al., 2020). However, due to the vast plausible answer space, the evaluation has been challenging and a large amount of answer annotations have to be collected in order to ensure fairness (Boratko et al., 2020). Curiously, while possession of common sense has been a central goal of AI, its role in our BRAINTEASER task is as a distractor. Namely, successful solutions of the lateral thinking puzzles in BRAINTEASER require the models to defy commonsense associations and linear inference chains.</p>
<p>Robustness Studies As a novel benchmark, BrainTEASER relates to other works that evaluate the performance of LLMs. Since these models are surpassing human performance on some existing benchmarks (Xu et al., 2022), the NLP community has shifted the focus towards robustness evaluation, i.e., whether the model can retain a similar performance to semantically perturbed or adversarially constructed questions (Abdou et al., 2020; Nie et al., 2020). Some recent works have adopted model adversarial approaches to generate datasets that are challenging for models to solve (Zellers et al., 2019; Sakaguchi et al., 2019), while others combine multiple tasks to evaluate the model's behavioral consistency across semantic, logical, and factual categories (Jang et al., 2022). Besides dataset construction, analysis studies have also shown that models easily learn shortcuts to solve the datasets (Branco et al., 2021; Elazar et al., 2021) and their performance heavily depends on the overlap of tokens between training and test data (Ma et al., 2021b). Different from prior works where associative resources are used to finetune the model to improve robustness, we expect that the lateral thinking puzzles in BRAINTEASER require unique associations and creative reasoning paths. In this way, BrainTEASER is designed to minimize the impact of confounding factors like memorization in LLMs (Bang et al., 2023; Guo et al., 2023; Goldberg, 2023).</p>
<h2>3 Construction of BrainTEASER</h2>
<p>In this section, we first provide a definition of lateral thinking puzzles in various granularities. We then present a three-stage pipeline for constructing the multiple-choice puzzles in the BrainTEASER dataset, consisting of data collection, distractor sampling, and reconstruction sample generation. Finally, we present key data statistics and quality validation results.</p>
<h3>3.1 Task Definition</h3>
<p>While lateral thinking puzzles are often presented to humans in an open-ended fashion, these are difficult to evaluate automatically and are difficult to solve by humans. ${ }^{3}$ An additional complication is that there may be multiple independent, yet correct, puzzle explanations. To alleviate these challenges, we pose lateral thinking puzzles as a multiplechoice QA task, a format frequently employed for reasoning tasks. We expect this approach to be both facile for human comprehension and amenable to automated evaluation. In general, each puzzle contains a question $Q$ stating the context, and a lateral explanation $e$ from explanation space $E$ that serves as the correct answer. $Q$ can be decomposed into an atomic premise set $P$, which includes both explicitly stated clauses and implicit clauses derived through default commonsense inferences or associations. For example, in the following puzzle: "How could a cowboy ride into town on Friday, stay two days, and ride out on Wednesday?", the set $P$ includes the following premises:</p>
<ul>
<li>$p_{1}$ : Cowboy rides into town on Friday.</li>
<li>$p_{2}$ : Cowboy stays in town for two days.</li>
<li>$p_{3}$ : Cowboy rides out on Wednesday.</li>
<li>$p_{4}$ : Wednesday is the third day of the week.</li>
<li>$p_{5}$ : Sunday is two days after Friday.</li>
</ul>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>The premises $p_{1}, p_{2}$, and $p_{3}$ are explicitly provided by the context, and the premises $p_{4}$ and $p_{5}$ are implicitly obtained by default commonsense association. The goal of a puzzle is to find an explanation that does not contradict the premise set $P$, $E \cap \neg P=\varnothing$, as the premises are the target to explain and support. With vertical thinking, the question appears impossible to answer because $P$ contains statements that conflict with each other. The premises $p_{3}$ and $p_{4}$ are inconsistent with other premises, leading to an obstacle in explaining the puzzle. The default commonsense inference thus becomes a logic stumper <em>Bar-Hillel et al. (2018)</em>, preventing one from creatively exploring additional explanations in $E$.</p>
<p>Lateral thinking leads to a correct solution to this puzzle: "His horse is named Wednesday.". This creative solution defies the commonsense association of Wednesday as a third day of the week $\left(p_{4}\right)$. Thus, the key point of a lateral thinking puzzle is that some implicit premises generated through default commonsense association incorrectly create an arbitrary "box" that wrongly excludes the possible solution from the explanation space <em>Bar-Hillel et al. (2018)</em>.</p>
<p>Upon careful exploration, we devise two granularity variants of lateral thinking puzzles following our definition (Figure 1): sentence-based, where the puzzle is centered on sentence premises (e.g., Wednesday is the third day of the week), and wordbased, where the answer violates the default meaning of the word and focuses on the letter composition of the target question (e.g., cheese made backwards $\rightarrow$ edam).</p>
<h3>3.2 Data Collection</h3>
<p>We collect over ten thousand lateral thinking puzzles with answers from public websites such as riddles.com and rd.com using web crawlers. We merge the data from different sources and remove (near-)duplicates based on sentence similarity <em>Reimers and Gurevych (2019)</em>. We conduct a semi-automatic process that corrects typos by using an automatic library, Auto Correct, ${ }^{4}$ followed by human verification to ensure that the puzzles preserve their original meaning. We filter the remaining data manually to preserve QA pairs that fit the definition of the sentence- or word-based lateral thinking puzzles. This process yields 373 unique lateral puzzles, formatted as QA pairs.</p>
<p><sup id="fnref4:0"><a class="footnote-ref" href="#fn:0">1</a></sup>Table 1: Example of generated distractors.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Premise</th>
<th style="text-align: left;">Answer/Distractor</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">$\mathbf{p}_{\mathbf{w}}$ : Wednesday is the <br> third day of the week.</td>
<td style="text-align: left;">Answer: His horse is <br> named Wednesday.</td>
</tr>
<tr>
<td style="text-align: left;">$\mathbf{p}_{\mathbf{2}}$ : Cowboy stays in <br> in town for two days.</td>
<td style="text-align: left;">Distractor: While in town, <br> he stays in bed for two days.</td>
</tr>
<tr>
<td style="text-align: left;">$\mathbf{p}_{\mathbf{5}}$ : Sunday is two days <br> past Friday.</td>
<td style="text-align: left;">Distractor: Friday and <br> Saturday are holidays.</td>
</tr>
</tbody>
</table>
<h3>3.3 Distractor Sampling</h3>
<p>We convert each puzzle and its explanation into a multiple-choice QA format to ensure a straightforward evaluation process. A key challenge in creating fair and informative multiple-choice questions is sampling distractors that are simultaneously incorrect and challenging <em>Ma et al. (2021a)</em>. We propose a systematic approach for distractor sampling that directly benefits from our premise-based definition of lateral thinking puzzles.</p>
<p>For sentence puzzles, we list possible premises $P=\left{p_{1}, p_{2}, p_{3}, \ldots\right}$ from the question context manually as the commonsense associations in the data are obvious and straightforward, especially when the answers are provided, like the example in Section 3.1. We know the correct answer $p_{c}^{\prime}$ is an unconventional overwriting of the wrong premise (logic stumper) $p_{w}$ generated by default commonsense association. We generate the distractors by overwriting other premises in $P-p_{w}$. This procedure guarantees that the distractors are incorrect because the misleading premise $p_{w}$ still remains in the premise set and prevents one from reaching the correct explanation. We first use COMET <em>Hwang et al. (2021)</em> to generate the possible premise overwriting candidates for the question as a head combined with inference relations (e.g., happens after, hindered by, cause). Then we pick the COMETgenerated tails that are consistent with the question context as distractors and revise them by manual annotation. Table 1 shows example distractors for our running example puzzle from Section 3.1.</p>
<p>For word puzzles, as we focus on the literal meaning rather than semantic meaning, distractors can share similar semantic meaning as the correct answers and still exhibit similar commonsense associations. We pick distractors from the correct answer's synonyms in WordNet (e.g., mozzarella for edam in Figure 1) and Wikipedia entries that belong to the same category (e.g., both edam and cheddar belong to the semi-hard cheese category).</p>
<p>Since it is generally possible that none of the cre-</p>
<p>Table 2: A sentence-based lateral thinking puzzle and its reconstruction variations. We present an analogous word-level puzzle in the Appendix A.3.</p>
<table>
<thead>
<tr>
<th>Adv Strategy</th>
<th>Question</th>
<th>Answers</th>
</tr>
</thead>
<tbody>
<tr>
<td>-</td>
<td>How could a cowboy ride into town on Friday, stay <br> two days, and ride out on Wednesday?</td>
<td>His horse is named Wednesday. <br> While in town, he stays in bed for two days. <br> Friday and Saturday are holidays. <br> None of the above.</td>
</tr>
<tr>
<td>Semantic Re- <br> construction</td>
<td>How could a cowboy come into town on Friday, <br> stay two days, and then ride away on Wednesday?</td>
<td>His horse is named Wednesday. <br> While in town, he stays in bed for two days. <br> Friday and Saturday are holidays. <br> None of the above.</td>
</tr>
<tr>
<td>Context Re- <br> construction</td>
<td>How can a pilot take off in Los Angeles on Tuesday, <br> fly for 48 hours, and land in Tokyo on Tuesday?</td>
<td>The pilot's airplane is named Tuesday. <br> He flies straight for 24 h and flies quickly for hours left. <br> There was a one-week long holiday. <br> None of the above.</td>
</tr>
</tbody>
</table>
<p>ative solutions will be sensible for some of the questions, we also include the option None of the above in all questions' candidates set. This answer candidate simulates the situation where humans cannot overwrite their commonsense inference and give up on explaining the lateral thinking puzzle. To create puzzles where lateral thinking fails (i.e., with answer None of the above), we replace the correct answer with a distractor in $6 \%$ of the questions. After this procedure, each question in BrainTeaser has four answer candidates.</p>
<h3>3.4 Generating Reconstruction Examples</h3>
<p>Since the latest LLMs are pretrained on massive web snapshots, it is possible that the data sources for BrainTeaser are also included in their training data. Consequently, it is possible for LLMs to memorize the correct answer without performing any reasoning. To ensure that our task evaluates lateral thinking ability rather than memorization, we construct reconstruction versions of the original data in two parallel ways (Table 2): (1) Semantic Reconstruction rephrases the original question without changing its answer, distractor, and any premises in $P$. To do so, we use an open-source rephrasing tool, ${ }^{5}$ after which human annotators refine and validate that all premises remain the same. (2) Context Reconstruction keeps the misleading commonsense premise intact and changes both the question and the answer to a new situational context. For this purpose, we prompt GPT-4 for initial reconstructions, which are then manually refined by human annotators. The new distractors are generated following the same process as in Section 3.3. The premise set and the corresponding distractors also get translated to the new context. Intuitively, a</p>
<p><sup id="fnref5:0"><a class="footnote-ref" href="#fn:0">1</a></sup>Table 3: Key statistics of the BrainTeaser dataset. Choices combine the correct answer with all the distractors. Standard deviation is computed without the None of the above choice, as its token length is fixed and not related to the question context.</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: center;">Sentence</th>
<th style="text-align: center;">Word</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"># Puzzles</td>
<td style="text-align: center;">627</td>
<td style="text-align: center;">492</td>
</tr>
<tr>
<td style="text-align: left;">Average Question Tokens</td>
<td style="text-align: center;">34.88</td>
<td style="text-align: center;">10.65</td>
</tr>
<tr>
<td style="text-align: left;">\% Long Question ( $&gt;30$ tokens)</td>
<td style="text-align: center;">$48.32 \%$</td>
<td style="text-align: center;">$2.23 \%$</td>
</tr>
<tr>
<td style="text-align: left;">Average Answer Tokens</td>
<td style="text-align: center;">9.11</td>
<td style="text-align: center;">3.0</td>
</tr>
<tr>
<td style="text-align: left;">Std of Choice Tokens</td>
<td style="text-align: center;">2.36</td>
<td style="text-align: center;">0.52</td>
</tr>
</tbody>
</table>
<p>model that learns to reason should be able to solve these two reconstruction variants of the questions easily, whereas the model that memorizes the answer would stumble.</p>
<h3>3.5 Data Analysis and Validation</h3>
<p>Key Statistics BrainTeaser includes 1,119 data samples including its reconstruction variants. Table 3 reports key statistics of each subtask of BrainTeaser. The questions in the Sentence Puzzle category are much longer because they are in a narrative story format rather than simple short questions, like those in the Word Puzzle category. The difference between the standard deviation in the number of choice tokens between Sentence Puz$z l e$ and Word Puzzle can be ascribed to the different strategies for generating distractors, i.e., overwriting various premises with new statements versus generating similar words from the synonym set.</p>
<p>We use ChatGPT prompting to extract the context topic from each question and to analyze the major topics in each subtask. The topic distribution shows that both subtasks involve a large range of (more than 80) areas. Sentence Puzzle is denominated by math, physics, and nature while Word Puzzle is denominated particularly by the language</p>
<p>topic. For both tasks, there is a long tail of less common topics. The details of topic extraction and its obtained statistics are given in the Appendix A.1. The data statistics and the topic analysis suggest that, despite its limited size, BrainTEASER can function as a comprehensive benchmark for assessing model performance across diverse topics and varying lengths of context.</p>
<p>Human Validation To ensure the quality of our dataset, we invited three expert annotators to verify the validity of the QA pairs and their reconstruction variants. We sampled 102 examples from BrainTeaser randomly and asked the annotators the following two questions: 1) Does the original puzzle and correct answer make sense? 2) Are the reconstruction variants still consistent with the original questions in terms of the required reasoning process? On average, the human annotators rated $99 \%$ of the original question-answering pairs as valid. $100 \%$ of the semantic reconstructions and $97 \%$ context reconstructions were marked as consistent with the original question-answer pair. The overall Fleiss (1971) kappa inter-annotator agreement is 0.948 , which is an almost perfect score.</p>
<h2>4 Experimental Setup</h2>
<p>We describe the models selected for our experiments and the metrics used to evaluate the reasoning accuracy and consistency of these models.</p>
<h3>4.1 Model selection</h3>
<p>Instruction-Based Models We evaluate the instruction-finetuned LLMs in zero/few-shot setting: 1) ChatGPT, a publicly available state-of-the-art LLM from the GPT (Brown et al., 2020a) series. 2) T0 (Sanh et al., 2022), a LLM trained with multitasking instruction tuning that has strong zero-shot generalization ability. 3) FlanT5 (Chung et al., 2022), an enhanced version of T5 (Raffel et al., 2020) which is instruction-finetuned (Wei et al., 2021) in both zero-shot and few-shot setting. For a fair comparison with humans, while running zero-shot prompting on ChatGPT, we add a description indicating that the question is a brain teaser puzzle that needs creative thinking to solve. For the rest of the models, we use the same instruction templates as found in their training sets (for full details, please refer to Appendix A.2).
Commonsense Models To understand the effect of commonsense knowledge on our task, we evaluate the following models that are enhanced with
common sense: 1) RoBERTa-L (CSKG) (Ma et al., 2021a), a model finetuned on the synthetic QA pairs generated from a diverse set of commonsense knowledge graphs (CSKG) (Ilievski et al., 2021b). 2) CAR (Wang et al., 2023b), a model finetuned in a similar pipeline as Ma et al. (2021a) but with enhanced negative sampling strategy and reportedly superior performance. For reference, we also include the vanilla RoBERTa model (Liu et al., 2019) to understand the impact of commonsense knowledge. We evaluate all of the models in a zero-shot fashion, following the scoring method defined in (Ma et al., 2021a). We select RoBERTa because of its widespread usage of the commonsense task and impressive zero-shot performance. RoBERTa-L (CSKG) achieve SOTA zero-shot result on multiple commonsense tasks, while CAR even outperforms ChatGPT on commonsense tasks.
Human Evaluation To assess the upper bound performance on BrainTeaser, we randomly sample 102 questions from it and invite three experts annotator to solve the test. On average, it takes one hour for an annotator to complete the task.</p>
<h3>4.2 Evaluation Metrics</h3>
<p>As accuracy is a fair evaluation metric for the MCQA format and it has been adopted by many popular commonsense reasoning tasks (Mihaylov et al., 2018; Talmor et al., 2019; Bisk et al., 2020), we evaluate model performance using two accuracy metrics: Instance-based Accuracy considers each (original or reconstruction) question separately. We report instance-based accuracy on the original puzzles, and their semantic and context reconstructions. Group-based Accuracy considers each original puzzle and its variants as a group. The model will score 1 only when it successfully solves all three puzzles in the group, otherwise, its score is 0 .</p>
<h2>5 Results</h2>
<p>Our experiments target five questions: 1) Can LLMs reason on lateral thinking puzzles similar to humans? 2) How do LLMs perform on reconstruction variants? 3) Are model predictions consistent across partitions? 4) Does tuning on commonsense knowledge help to answer BrainTeaser puzzles better? 5) Can LLMs do better in the few-shot setting with more demonstrations?</p>
<p>Overall Performance The main results are shown in Table 4. For both word and sentence BrainTeaser puzzles, the performance of the</p>
<p>Table 4: Main zero-shot results over two BRAINTEASER subtasks across all models in all metrics: Ori = Original, Sem = Semantic, Con = Context. The best performance among all models is in bold, and the best performance in commonsense augmented models is underlined. The human evaluation (*) is computed over 102 randomly sampled data. The random base is average over three different seeds.</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Category</td>
<td>Model</td>
<td>Original</td>
<td>Semantic</td>
<td>Context</td>
<td>Ori \&amp; Sem</td>
<td>Ori \&amp; Sem \&amp; Con</td>
<td>Overall</td>
</tr>
<tr>
<td>Sentence Puzzle</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Random</td>
<td>-</td>
<td>25.52</td>
<td>24.88</td>
<td>22.81</td>
<td>5.58</td>
<td>1.44</td>
<td>24.40</td>
</tr>
<tr>
<td>Instruction</td>
<td>FlanT5(780M)</td>
<td>18.66</td>
<td>16.27</td>
<td>22.01</td>
<td>10.53</td>
<td>4.31</td>
<td>18.98</td>
</tr>
<tr>
<td></td>
<td>FlanT5(3B)</td>
<td>26.79</td>
<td>25.36</td>
<td>35.41</td>
<td>20.10</td>
<td>12.92</td>
<td>29.19</td>
</tr>
<tr>
<td></td>
<td>FlanT5(11B)</td>
<td>33.49</td>
<td>31.58</td>
<td>36.84</td>
<td>22.01</td>
<td>11.00</td>
<td>33.97</td>
</tr>
<tr>
<td></td>
<td>T0(11B)</td>
<td>22.01</td>
<td>22.01</td>
<td>29.67</td>
<td>16.27</td>
<td>11.00</td>
<td>24.56</td>
</tr>
<tr>
<td></td>
<td>T0P(11B)</td>
<td>23.92</td>
<td>22.49</td>
<td>34.93</td>
<td>17.70</td>
<td>11.96</td>
<td>27.11</td>
</tr>
<tr>
<td></td>
<td>TOPP(11B)</td>
<td>26.32</td>
<td>27.27</td>
<td>37.80</td>
<td>19.14</td>
<td>11.96</td>
<td>30.46</td>
</tr>
<tr>
<td></td>
<td>ChatGPT</td>
<td>60.77</td>
<td>59.33</td>
<td>67.94</td>
<td>50.72</td>
<td>39.71</td>
<td>62.68</td>
</tr>
<tr>
<td>Commonsense</td>
<td>RoBERTa-L</td>
<td>43.54</td>
<td>40.19</td>
<td>46.41</td>
<td>33.01</td>
<td>20.10</td>
<td>43.38</td>
</tr>
<tr>
<td></td>
<td>RoBERTa-L(CSKG)</td>
<td>35.41</td>
<td>36.84</td>
<td>44.98</td>
<td>28.71</td>
<td>18.18</td>
<td>39.07</td>
</tr>
<tr>
<td></td>
<td>CAR</td>
<td>10.53</td>
<td>10.53</td>
<td>11.48</td>
<td>5.74</td>
<td>2.39</td>
<td>10.85</td>
</tr>
<tr>
<td>Human*</td>
<td>-</td>
<td>90.74</td>
<td>90.74</td>
<td>94.44</td>
<td>90.74</td>
<td>88.89</td>
<td>91.98</td>
</tr>
<tr>
<td>Word Puzzle</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Random</td>
<td>-</td>
<td>26.02</td>
<td>27.85</td>
<td>22.51</td>
<td>7.32</td>
<td>1.83</td>
<td>25.34</td>
</tr>
<tr>
<td>Instruction</td>
<td>FlanT5(780M)</td>
<td>22.56</td>
<td>17.68</td>
<td>28.66</td>
<td>9.15</td>
<td>3.66</td>
<td>22.97</td>
</tr>
<tr>
<td></td>
<td>FlanT5(3B)</td>
<td>37.80</td>
<td>29.88</td>
<td>42.68</td>
<td>23.17</td>
<td>12.80</td>
<td>36.79</td>
</tr>
<tr>
<td></td>
<td>FlanT5(11B)</td>
<td>42.68</td>
<td>32.93</td>
<td>43.90</td>
<td>28.66</td>
<td>20.12</td>
<td>39.84</td>
</tr>
<tr>
<td></td>
<td>T0(11B)</td>
<td>17.07</td>
<td>14.02</td>
<td>23.17</td>
<td>9.76</td>
<td>6.10</td>
<td>18.09</td>
</tr>
<tr>
<td></td>
<td>T0P(11B)</td>
<td>28.66</td>
<td>26.22</td>
<td>34.15</td>
<td>19.51</td>
<td>12.80</td>
<td>29.67</td>
</tr>
<tr>
<td></td>
<td>TOPP(11B)</td>
<td>33.54</td>
<td>31.10</td>
<td>39.63</td>
<td>20.12</td>
<td>10.98</td>
<td>34.76</td>
</tr>
<tr>
<td></td>
<td>ChatGPT</td>
<td>56.10</td>
<td>52.44</td>
<td>51.83</td>
<td>43.90</td>
<td>29.27</td>
<td>53.46</td>
</tr>
<tr>
<td>Commonsense</td>
<td>RoBERTa-L</td>
<td>19.51</td>
<td>19.51</td>
<td>23.17</td>
<td>14.63</td>
<td>6.10</td>
<td>20.73</td>
</tr>
<tr>
<td></td>
<td>RoBERTa-L(CSKG)</td>
<td>18.90</td>
<td>16.46</td>
<td>30.49</td>
<td>12.80</td>
<td>6.10</td>
<td>21.95</td>
</tr>
<tr>
<td></td>
<td>CAR</td>
<td>38.41</td>
<td>31.10</td>
<td>20.12</td>
<td>26.22</td>
<td>6.10</td>
<td>29.88</td>
</tr>
<tr>
<td>Human*</td>
<td>-</td>
<td>91.67</td>
<td>91.67</td>
<td>91.67</td>
<td>91.67</td>
<td>89.58</td>
<td>91.67</td>
</tr>
</tbody>
</table>
<p>strongest model, ChatGPT (53 and 63\%) is halfway between random ( $25 \%$ ) and human performance ( $92 \%$ ). In general, neither type of model is able to perform consistently well across the two subtasks: instruction-based models perform better on word puzzles, whereas commonsense models perform slightly better on sentence puzzles. The performance of the models is often close to random, with around a third of the models performing equal or worse than random guessing. As it can be expected, we see that scaling up instruction-finetuned models leads to improved performance on both subtasks. Yet, the large gap between human and model performance clearly shows that even the most powerful LLMs are unable to exhibit lateral thinking in multiple-choice puzzles and confirms the challenging nature of our BRAINTEASER dataset.</p>
<p>Original vs Reconstruction Partitions In most cases, all models and humans perform the best on the context reconstruction partition. We hypothesize that this is because original lateral thinking puzzles are designed to mislead humans to a wrong choice based on commonsense associations, often involving rare words and unconventional sentence structures. Meanwhile, we note that our contextual reconstruction mechanism yields puzzles that are more familiar or easier to solve than the original puzzle, possibly because some of the commonsense associations are relatively weaker. An exception to this trend is ChatGPT's performance on word puzzles, where ChatGPT performs the best on the original examples. We believe that this is due to a combination of two factors. First, the word puzzle reconstructions only have a limited impact on the vocabulary domain and sentence structure, because of the much shorter questions. Second, ChatGPT may have memorized some of the word puzzles, e.g., given the question "How do you spell COW in thirteen letters?", its answer begins with "The question seems to be a brain teaser ..." We provide representative examples of the prevalent lateral thinking errors of memorization and commonsense associations in Table 5.</p>
<p>Consistency of Model Predictions We further compare the performance on instance- and groupbased metrics to understand whether the models can solve lateral thinking puzzles by following a consistent reasoning path. A model understand-</p>
<p>Table 5: Error analysis on memorization and commonsense association.</p>
<table>
<thead>
<tr>
<th>Question</th>
<th>Answer</th>
<th>LLM choice</th>
</tr>
</thead>
<tbody>
<tr>
<td>Memorization</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>minimal, given the abstract nature of reasoning pattern in this subtask.</p>
<p>Qualitative Error Analysis We analyze two prevalent lateral thinking errors in the ChatGPT and FlanT5 (11b) LLMs: memorization and commonsense associations, both of which become more apparent with scaling up (Carlini et al., 2022). We show examples in Table 5.</p>
<p>Memorization We find that memorization happens in both subtasks. Given the sentence puzzle "The man calls his dog on the other side of the river, crosses the river without getting wet and using ant tools." the LLMs picked the correct answer "The river was frozen." for both the original and its semantic reconstruction. However, when the question in a new context becomes "The man had to cross the rivers. He can't swim or use any tools. like the bridge. How does the man succeed in the end?", all LLMs failed to answer. Memorization is more frequent in word puzzles. A semantic reconstruction will cause confusion in the model, as is also apparent from the gap between original accuracy and the ori\&amp;sem accuracy in Table 4.</p>
<p>Commonsense association Similarly, we also find that commonsense association often confuses LLMs. For example, for "What animal has no wings, but yet will fly?", the models associate the words "wings" and "fly" with birds and pick the wrong answer "An eagle." despite the contradiction between "eagle" and "no wings". Meanwhile, the correct lateral thinking answer "A caterpillar." is not picked by the models. Interestingly, commonsense associations that mislead models in some examples can be the needed hint in others. For example, in one puzzle, "There is no light on the road and the car's headlight is broken. How can the driver see the black dog?", the answer "It was daytime." is hindered by the commonsense association between mentioning no light and night. However, in another example, "How can Jenny read in a totally no light house at night?", the same commonsense association leads the model to the correct answer: "The book is in Braille.". In the second example, the answer is misled by another commonsense association related to reading.</p>
<h2>6 Conclusions and Outlook</h2>
<p>We defined the task of lateral thinking for LLMs, formulated as a multiple-choice QA with a sentence- and word-level puzzles. We developed BRAINTEASER, a 1.1K lateral thinking benchmark
that combines original puzzles and their reconstruction variants. Our experiments showed that ChatGPT's performance on this task is halfway between random and humans, whereas other models often perform close to random. While scaling up model size improved performance, enriching with common sense or providing few-shot demonstrations yielded limited benefits. Meanwhile, all models tend to solve the variants of the same puzzle inconsistently. Our error analysis showed that the models' lateral thinking is often hindered by memorization and misleading commonsense associations. In the future, we intend to develop lateral thinking models, create additional lateral thinking evaluation tasks (e.g., relating to alteration (De Bono, 1970)), and investigate flexible ways to combine lateral and vertical thinking.</p>
<h2>Limitations</h2>
<p>While our work focuses on both Sentence puzzles and Word puzzles, we intend to develop a comprehensive lateral thinking benchmark according to de Bono's four skills: awareness, random stimulation, alternatives, and alteration (De Bono, 1970). Moreover, while our paper tries to provide a clear distinction between lateral and vertical thinking, it remains an open question to which extent other brain teaser categories, e.g. puns and visual puzzles, require lateral or vertical thinking. As these tasks are not the focus of our present paper, we leave it to future work to comprehensively evaluate models' ability to think out of the box on such tasks and to characterize the complementary and opposing aspects of vertical and lateral thinking.</p>
<p>Also, we opt for constructing the dataset in a multiple-choice QA format to reduce the burden of the evaluation process. However, this inevitably reduces the difficulty of the task and permits the situation where the models solve the questions correctly for the wrong reasons. Future work should also look into better evaluation metrics that are suitable for creative and open-ended generations such that our task can also be adapted to an openended setting. Finally, while our current puzzles are provided in a static manner, future work should also investigate an interactive (multi-step) setup, where the model (or human) may ask clarification questions or receive contextual hints.</p>
<h2>Ethical Considerations</h2>
<p>As our lateral thinking puzzles are "folk knowledge" and are published on a range set of websites, it is hard to check their original licenses comprehensively. Yet, the website owners declare permission to print and download material for noncommercial use without modification on the material's copyright. Therefore, we provide the corresponding copyright statements and website URLs for each original lateral thinking puzzle and its reconstruction version. In addition, we will create a form to ask future dataset users to sign a document claiming that the only aim of the data usage is research before providing them with the data. We note that, despite our best efforts, the task data may still contain bias in terms of gender or politics. We will indicate that future research should use the task data with caution.</p>
<h2>References</h2>
<p>Mostafa Abdou, Vinit Ravishankar, Maria Barrett, Yonatan Belinkov, Desmond Elliott, and Anders Søgaard. 2020. The sensitivity of language models and humans to Winograd schema perturbations. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 75907604, Online. Association for Computational Linguistics.</p>
<p>Meryem Altun, Muhsin Hazar, and Zekihan Hazar. 2016. Investigation of the effects of brain teasers on attention spans of pre-school children. International journal of environmental and science education, 11:81128119.</p>
<p>Yejin Bang, Samuel Cahyawijaya, Nayeon Lee, Wenliang Dai, Dan Su, Bryan Wilie, Holy Lovenia, Ziwei Ji, Tiezheng Yu, Willy Chung, Quyet V. Do, Yan Xu, and Pascale Fung. 2023. A multitask, multilingual, multimodal evaluation of chatgpt on reasoning, hallucination, and interactivity.</p>
<p>Maya Bar-Hillel, Tom Noah, and Shane Frederick. 2018. Learning psychology from riddles: The case of stumpers. Judgment and Decision Making, 13(1):112-122.</p>
<p>Yonatan Bisk, Rowan Zellers, Jianfeng Gao, Yejin Choi, et al. 2020. Piqa: Reasoning about physical commonsense in natural language. In Proceedings of the AAAI conference on artificial intelligence, volume 34, pages 7432-7439.</p>
<p>Michael Boratko, Xiang Li, Tim O’Gorman, Rajarshi Das, Dan Le, and Andrew McCallum. 2020. ProtoQA: A question answering dataset for prototypical common-sense reasoning. In Proceedings of the 2020 Conference on Empirical Methods in Natural</p>
<p>Language Processing (EMNLP), pages 1122-1136, Online. Association for Computational Linguistics.</p>
<p>Antoine Bosselut, Hannah Rashkin, Maarten Sap, Chaitanya Malaviya, Asli Celikyilmaz, and Yejin Choi. 2019. Comet: Commonsense transformers for knowledge graph construction. In Association for Computational Linguistics (ACL).</p>
<p>Ruben Branco, António Branco, João António Rodrigues, and João Ricardo Silva. 2021. Shortcutted commonsense: Data spuriousness in deep learning of commonsense reasoning. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 1504-1521, Online and Punta Cana, Dominican Republic. Association for Computational Linguistics.</p>
<p>Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020a. Language models are few-shot learners. In Advances in Neural Information Processing Systems, volume 33, pages 1877-1901. Curran Associates, Inc.</p>
<p>Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020b. Language models are few-shot learners. Advances in neural information processing systems, 33:1877-1901.</p>
<p>Sébastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg, et al. 2023. Sparks of artificial general intelligence: Early experiments with gpt-4. arXiv preprint arXiv:2303.12712.</p>
<p>Nicholas Carlini, Daphne Ippolito, Matthew Jagielski, Katherine Lee, Florian Tramer, and Chiyuan Zhang. 2022. Quantifying memorization across neural language models. arXiv preprint arXiv:2202.07646.</p>
<p>Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et al. 2022. Scaling instruction-finetuned language models. arXiv preprint arXiv:2210.11416.</p>
<p>Peter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot, Ashish Sabharwal, Carissa Schoenick, and Oyvind Tafjord. 2018. Think you have solved question answering? try arc, the ai2 reasoning challenge. ArXiv, abs/1803.05457.</p>
<p>Edward De Bono. 1970. Lateral thinking. New York.</p>
<p>Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 4171-4186, Minneapolis, Minnesota. Association for Computational Linguistics.</p>
<p>Stephen W Draper. 2009. Catalytic assessment: understanding how mcqs and evs can foster deep learning. British Journal of Educational Technology, 40(2):285-293.</p>
<p>Yanai Elazar, Hongming Zhang, Yoav Goldberg, and Dan Roth. 2021. Back to square one: Artifact detection, training and commonsense disentanglement in the Winograd schema. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 10486-10500, Online and Punta Cana, Dominican Republic. Association for Computational Linguistics.</p>
<p>Joseph L Fleiss. 1971. Measuring nominal scale agreement among many raters. Psychological bulletin, 76(5):378.</p>
<p>Giorgio Franceschelli and Mirco Musolesi. 2023. On the creativity of large language models.</p>
<p>Ge Gao, Eunsol Choi, Yejin Choi, and Luke Zettlemoyer. 2018. Neural metaphor detection in context. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 607-613, Brussels, Belgium. Association for Computational Linguistics.</p>
<p>Yoav Goldberg. 2023. Two kinds of recall. arXiv preprint arXiv:2303.10527.</p>
<p>Biyang Guo, Xin Zhang, Ziyuan Wang, Minqi Jiang, Jinran Nie, Yuxuan Ding, Jianwei Yue, and Yupeng Wu. 2023. How close is chatgpt to human experts? comparison corpus, evaluation, and detection.</p>
<p>Scott Highhouse, Christopher D Nye, and Don C Zhang. 2019. Dark motives and elective use of brainteaser interview questions. Applied Psychology, 68(2):311340 .</p>
<p>Jena D. Hwang, Chandra Bhagavatula, Ronan Le Bras, Jeff Da, Keisuke Sakaguchi, Antoine Bosselut, and Yejin Choi. 2021. Comet-atomic 2020: On symbolic and neural commonsense knowledge graphs. In AAAI.</p>
<p>Filip Ilievski, Alessandro Oltramari, Kaixin Ma, Bin Zhang, Deborah L McGuinness, and Pedro Szekely. 2021a. Dimensions of commonsense knowledge. Knowledge-Based Systems.</p>
<p>Filip Ilievski, Pedro Szekely, and Bin Zhang. 2021b. Cskg: The commonsense knowledge graph. In The Semantic Web: 18th International Conference, ESWC 2021, Virtual Event, June 6-10, 2021, Proceedings 18, pages 680-696. Springer.</p>
<p>Myeongjun Jang, Deuk Sin Kwon, and Thomas Lukasiewicz. 2022. Becel: Benchmark for consistency evaluation of language models. In Proceedings of the 29th International Conference on Computational Linguistics, pages 3680-3696.</p>
<p>Bill Yuchen Lin, Ziyi Wu, Yichi Yang, Dong-Ho Lee, and Xiang Ren. 2021. Riddlesense: Reasoning about riddle questions featuring linguistic creativity and commonsense knowledge. arXiv preprint arXiv:2101.00376.</p>
<p>Bill Yuchen Lin, Wangchunshu Zhou, Ming Shen, Pei Zhou, Chandra Bhagavatula, Yejin Choi, and Xiang Ren. 2020. CommonGen: A constrained text generation challenge for generative commonsense reasoning. In Findings of the Association for Computational Linguistics: EMNLP 2020, pages 1823-1840, Online. Association for Computational Linguistics.</p>
<p>Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019. Roberta: A robustly optimized bert pretraining approach.</p>
<p>Nicholas Lourie, Ronan Le Bras, Chandra Bhagavatula, and Yejin Choi. 2021. Unicorn on rainbow: A universal commonsense reasoning model on a new multitask benchmark. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 35, pages $13480-13488$.</p>
<p>Kaixin Ma, Jonathan Francis, Quanyang Lu, Eric Nyberg, and Alessandro Oltramari. 2019. Towards generalizable neuro-symbolic systems for commonsense question answering. In Proceedings of the First Workshop on Commonsense Inference in Natural Language Processing, pages 22-32, Hong Kong, China. Association for Computational Linguistics.</p>
<p>Kaixin Ma, Filip Ilievski, Jonathan Francis, Yonatan Bisk, Eric Nyberg, and Alessandro Oltramari. 2021a. Knowledge-driven data construction for zero-shot evaluation in commonsense question answering. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 35, pages 13507-13515.</p>
<p>Kaixin Ma, Filip Ilievski, Jonathan Francis, Satoru Ozaki, Eric Nyberg, and Alessandro Oltramari. 2021b. Exploring strategies for generalizable commonsense reasoning with pre-trained models. EMNLP 2021.</p>
<p>Adyasha Maharana and Mohit Bansal. 2022. On curriculum learning for commonsense reasoning. In Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 983-992, Seattle, United States. Association for Computational Linguistics.</p>
<p>Gary Marcus. 2022. Deep learning is hitting a wall. Nautilus, Accessed, pages 03-11.</p>
<p>J. A. Meaney, Steven Wilson, Luis Chiruzzo, Adam Lopez, and Walid Magdy. 2021. SemEval 2021 task 7: HaHackathon, detecting and rating humor and offense. In Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021), pages 105-119, Online. Association for Computational Linguistics.</p>
<p>Todor Mihaylov, Peter Clark, Tushar Khot, and Ashish Sabharwal. 2018. Can a suit of armor conduct electricity? a new dataset for open book question answering. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 2381-2391, Brussels, Belgium. Association for Computational Linguistics.</p>
<p>Yixin Nie, Adina Williams, Emily Dinan, Mohit Bansal, Jason Weston, and Douwe Kiela. 2020. Adversarial NLI: A new benchmark for natural language understanding. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 4885-4901, Online. Association for Computational Linguistics.</p>
<p>Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu. 2020. Exploring the limits of transfer learning with a unified text-to-text transformer. The Journal of Machine Learning Research, 21(1):5485-5551.</p>
<p>Nazneen Fatema Rajani, Bryan McCann, Caiming Xiong, and Richard Socher. 2019. Explain yourself! leveraging language models for commonsense reasoning. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 4932-4942, Florence, Italy. Association for Computational Linguistics.</p>
<p>Nils Reimers and Iryna Gurevych. 2019. SentenceBERT: Sentence embeddings using Siamese BERTnetworks. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 3982-3992, Hong Kong, China. Association for Computational Linguistics.</p>
<p>Keisuke Sakaguchi, Ronan Le Bras, Chandra Bhagavatula, and Yejin Choi. 2019. Winogrande: An adversarial winograd schema challenge at scale.</p>
<p>Victor Sanh, Albert Webson, Colin Raffel, Stephen Bach, Lintang Sutawika, Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, Arun Raja, Manan Dey, et al. 2022. Multitask prompted training enables zero-shot task generalization. In International Conference on Learning Representations.</p>
<p>Maarten Sap, Ronan Le Bras, Emily Allaway, Chandra Bhagavatula, Nicholas Lourie, Hannah Rashkin, Brendan Roof, Noah A. Smith, and Yejin Choi. 2019a. Atomic: An atlas of machine commonsense for if-then reasoning. In AAAI Conference on Artificial Intelligence.</p>
<p>Maarten Sap, Hannah Rashkin, Derek Chen, Ronan Le Bras, and Yejin Choi. 2019b. Social iqa: Commonsense reasoning about social interactions. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 4463-4473.</p>
<p>Robyn Speer, Joshua Chin, and Catherine Havasi. 2017. Conceptnet 5.5: An open multilingual graph of general knowledge. In Proceedings of the AAAI conference on artificial intelligence, volume 31.</p>
<p>Alon Talmor, Jonathan Herzig, Nicholas Lourie, and Jonathan Berant. 2019. Commonsenseqa: A question answering challenge targeting commonsense knowledge. In Proceedings of NAACL-HLT, pages 41494158.</p>
<p>Sowmya Vajjala and Detmar Meurers. 2012. On improving the accuracy of readability classification using insights from second language acquisition. In Proceedings of the seventh workshop on building educational applications using NLP, pages 163-173.</p>
<p>Shlomo Waks. 1997. Lateral thinking and technology education. Journal of Science Education and Technology, 6:245-255.</p>
<p>Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke Zhu, Linxi Fan, and Anima Anandkumar. 2023a. Voyager: An open-ended embodied agent with large language models.</p>
<p>Weiqi Wang, Tianqing Fang, Wenxuan Ding, Baixuan Xu, Xin Liu, Yangqiu Song, and Antoine Bosselut. 2023b. Car: Conceptualization-augmented reasoner for zero-shot commonsense question answering. arXiv preprint arXiv:2305.14869.</p>
<p>Jason Wei, Maarten Bosma, Vincent Y Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M Dai, and Quoc V Le. 2021. Finetuned language models are zero-shot learners. arXiv preprint arXiv:2109.01652.</p>
<p>Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, et al. 2023. Emergent abilities of large language models. Transactions on Machine Learning Research.</p>
<p>Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed Chi, Quoc Le, and Denny Zhou. 2022. Chain-of-thought prompting elicits reasoning in large language models. In Advances in Neural Information Processing Systems.</p>
<p>Yichong Xu, Chenguang Zhu, Shuohang Wang, Siqi Sun, Hao Cheng, Xiaodong Liu, Jianfeng Gao, Pengcheng He, Michael Zeng, and Xuedong Huang. 2022. Human parity on commonsenseqa: Augmenting self-attention with external attention. Proceedings of the Thirty-First International Joint Conference on Artificial Intelligence.</p>
<p>Rowan Zellers, Ari Holtzman, Yonatan Bisk, Ali Farhadi, and Yejin Choi. 2019. HellaSwag: Can a machine really finish your sentence? In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 4791-4800, Florence, Italy. Association for Computational Linguistics.</p>
<p>Yanyan Zou and Wei Lu. 2019. Joint detection and location of English puns. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 2117-2123, Minneapolis, Minnesota. Association for Computational Linguistics.</p>
<h2>A Appendix</h2>
<h2>A. 1 Puzzle topics</h2>
<p>We use few-shot prompting in ChatGPT to extract the context topic for each question. Table 6 shows the top 10 topics for each subtask, for which the prompting template is as follows:
" Can you provide context environment in the following brain teasers? Here are several examples: {examples }"</p>
<p>Table 6: Top-10 topics extracted for both subtasks.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Sentence Puzzle</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Word Puzzle</th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Topic</td>
<td style="text-align: center;">Frequency</td>
<td style="text-align: center;">Topic</td>
<td style="text-align: center;">Frequency</td>
</tr>
<tr>
<td style="text-align: center;">Mathematics</td>
<td style="text-align: center;">45</td>
<td style="text-align: center;">Language</td>
<td style="text-align: center;">79</td>
</tr>
<tr>
<td style="text-align: center;">Physics</td>
<td style="text-align: center;">41</td>
<td style="text-align: center;">Food</td>
<td style="text-align: center;">27</td>
</tr>
<tr>
<td style="text-align: center;">Nature</td>
<td style="text-align: center;">37</td>
<td style="text-align: center;">Mathematics</td>
<td style="text-align: center;">26</td>
</tr>
<tr>
<td style="text-align: center;">Transportation</td>
<td style="text-align: center;">32</td>
<td style="text-align: center;">Animals</td>
<td style="text-align: center;">24</td>
</tr>
<tr>
<td style="text-align: center;">Animals</td>
<td style="text-align: center;">25</td>
<td style="text-align: center;">Science</td>
<td style="text-align: center;">22</td>
</tr>
<tr>
<td style="text-align: center;">Sports</td>
<td style="text-align: center;">24</td>
<td style="text-align: center;">Time</td>
<td style="text-align: center;">18</td>
</tr>
<tr>
<td style="text-align: center;">Family</td>
<td style="text-align: center;">23</td>
<td style="text-align: center;">Geography</td>
<td style="text-align: center;">16</td>
</tr>
<tr>
<td style="text-align: center;">Time</td>
<td style="text-align: center;">19</td>
<td style="text-align: center;">Nature</td>
<td style="text-align: center;">13</td>
</tr>
<tr>
<td style="text-align: center;">Education</td>
<td style="text-align: center;">16</td>
<td style="text-align: center;">Entertainment</td>
<td style="text-align: center;">12</td>
</tr>
<tr>
<td style="text-align: center;">Law</td>
<td style="text-align: center;">16</td>
<td style="text-align: center;">Finance</td>
<td style="text-align: center;">11</td>
</tr>
<tr>
<td style="text-align: center;">Others</td>
<td style="text-align: center;">339</td>
<td style="text-align: center;">Others</td>
<td style="text-align: center;">244</td>
</tr>
</tbody>
</table>
<h2>A. 2 Prompting templates</h2>
<p>ChatGPT We use the following instruction to prompt ChatGPT:
"Please pick the best choice for the brain teaser. Each brain teaser has only one possible solution, including the choice none of the above, answer should only provide the choice:"
FlanT5 We use the instruction template for the AI2 Reasoning Challenge (ARC) (Clark et al., 2018): "Question: {Question}</p>
<p>What is the correct answer to the question from the following choices?
(A) {choice}
(B) {choice}
(C) {choice}
(D) {choice}"
T0PP We use the instruction template for the CommensenseQA task (Talmor et al., 2019):
"{Question}
Choose the most suitable option to answer the above question.
Options:
A. {choice}
B. {choice}
C. {choice}</p>
<h2>D. {choice}</h2>
<h2>A. 3 Word puzzle example</h2>
<p>Table 7 presents a word puzzle with its reconstruction examples.</p>
<h2>A. 4 Few-shot prompting result</h2>
<p>Table 8 shows the few-shot result of ChatGPT and FlanT5 (11B) on the two BrainTeaser subtasks.</p>
<h2>A. 5 Annotation Details</h2>
<p>Human evaluation We give the following instruction to human evaluation participants:
"Hi, welcome to the brain teaser test. Each brain teaser has only one possible solution (none of the above is possible!). Please select the choice in the answer column. Try to Think out of Box :)"
Human validation We give the following instruction:
"Congratulations on passing the brain teaser test. You should notice that some brain teasers are similar to each other :)! Actually, the brain teasers can be divided in groups like the following: In each brain teaser group, we have an original question, semantic reconstruction questions, and context reconstruction questions. Semantic reconstruction question rephrases the original question without changing the correct answer and the distractors. Context reconstruction question keeps the original reasoning path but changes both the question and the answer to describe a new situational context.</p>
<p>Please help with the following three tasks: 1)Whether the original question and its answer make sense. 2)Whether the semantic reconstruction question rephrases the original question. 3)Whether the context reconstruction question keeps the original reasoning path."
Open-ended Human Performance We give the following instruction:
"Please write down the answer of each brain teaser. Anything that makes sense is welcome!! Also, no answer is acceptable!"</p>
<p>We let both humans and ChatGPT write down the most possible answer to 30 context reconstruction questions based on their understanding. Three experts score the answers on a scale of 5, based on the following rubrics:</p>
<ul>
<li>score 0: Fail to answer.</li>
<li>score 1: Try to answer the question, but the answer doesn't make sense.</li>
<li>score 2: The answer is wrong but related to the golden label.</li>
<li>score 3: The answer is wrong, but the reasoning strategy is similar to the golden answer and may lack some keywords.</li>
<li>score 4: The answer is wrong but lacks minor information. Or the answer makes sense but is not the same as the golden answer.</li>
<li>score 5: The answer is correct.</li>
</ul>
<p>Both humans and LLMs cannot perform this task well, scoring 2.64 and 2.62 on a 5-point scale. Humans give up more often ( $18 \%$ ) rather than generating meaningless text like ChatGPT, making the comparison harder if the task is in an open-end format.</p>
<h2>A. 6 Evidence of stronger distractors in the original puzzle</h2>
<p>The barber example in Figure 1, "shaves everyday" and "keep his beard long" triggers a commonsense association that the man shaves himself every day. The contextually reconstructed puzzle of the barber example is "How can a man go to football team every day but doesn't play football at all?". This new question still aims to guide the model to think in the default commonsense way that "He is a football player." but the correct answer "He is a coach." is also highly probable, resulting in an inherent decrease in difficulty.</p>
<h2>A. 7 Fine-tuned on Riddle Sense</h2>
<p>We finetuned RoBERTa-L on RiddleSense (Lin et al., 2021) to analyze whether being aware of linguistic creativity can enhance the model's performance on BrainTeaser. We train RoBERTaL (RS) on the training data of RiddleSense in 3 epochs with a learning rate at $1 e^{-6}$, batch size at 4. RoBERTa-L (RS) reaches 59.95 on the validation set, which is on par with the original paper (60.72). We then adapt Roberta-L (RS) to do the zero-shot evaluation on BrainTeaser. The results are shown in Table 9.</p>
<p>Even though Roberta-L (RS) already gains insight into creative thinking, it is still struggling on BrainTeaser. The better results show that enhancing creative thinking during the training may</p>
<p>Table 7: Overview of a word puzzle example and its reconstruction versions.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Adv Strategy</th>
<th style="text-align: left;">Question</th>
<th style="text-align: left;">Answers</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">-</td>
<td style="text-align: left;">What part of London is in France?</td>
<td style="text-align: left;">The letter N. <br> The letter O. <br> The letter L. <br> None of the above.</td>
</tr>
<tr>
<td style="text-align: left;">Semantic Re- <br> construction</td>
<td style="text-align: left;">Which area of London is inside France?</td>
<td style="text-align: left;">The letter N. <br> The letter O. <br> The letter L. <br> None of the above.</td>
</tr>
<tr>
<td style="text-align: left;">Context Re- <br> construction</td>
<td style="text-align: left;">What part of Korea is in China?</td>
<td style="text-align: left;">The letter A. <br> The letter E. <br> The letter R. <br> None of the above.</td>
</tr>
</tbody>
</table>
<p>Table 8: Main few-shot results of ChatGPT and FlanT5(11B) on two BRAINTEASER subtasks. Ori = Original, Sem $=$ Semantic, Con $=$ Context. The best performance among all models is in bold.</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;">Instance-based</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Group-based</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Overall</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Model</td>
<td style="text-align: center;">Original</td>
<td style="text-align: center;">Semantic</td>
<td style="text-align: center;">Context</td>
<td style="text-align: center;">Ori \&amp; Sem</td>
<td style="text-align: center;">Ori \&amp; Sem \&amp; Con</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Sentence puzzle</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">ChatGPT(zero-shot)</td>
<td style="text-align: center;">60.77</td>
<td style="text-align: center;">59.33</td>
<td style="text-align: center;">67.94</td>
<td style="text-align: center;">50.72</td>
<td style="text-align: center;">39.71</td>
<td style="text-align: center;">62.68</td>
</tr>
<tr>
<td style="text-align: center;">ChatGPT(two-shot)</td>
<td style="text-align: center;">61.72</td>
<td style="text-align: center;">60.77</td>
<td style="text-align: center;">68.90</td>
<td style="text-align: center;">51.67</td>
<td style="text-align: center;">40.67</td>
<td style="text-align: center;">63.80</td>
</tr>
<tr>
<td style="text-align: center;">ChatGPT(four-shot)</td>
<td style="text-align: center;">59.33</td>
<td style="text-align: center;">55.98</td>
<td style="text-align: center;">62.20</td>
<td style="text-align: center;">47.85</td>
<td style="text-align: center;">32.06</td>
<td style="text-align: center;">59.17</td>
</tr>
<tr>
<td style="text-align: center;">ChatGPT(six-shot)</td>
<td style="text-align: center;">60.29</td>
<td style="text-align: center;">59.81</td>
<td style="text-align: center;">66.51</td>
<td style="text-align: center;">51.20</td>
<td style="text-align: center;">40.19</td>
<td style="text-align: center;">62.20</td>
</tr>
<tr>
<td style="text-align: center;">ChatGPT(eight-shot)</td>
<td style="text-align: center;">63.16</td>
<td style="text-align: center;">62.68</td>
<td style="text-align: center;">67.46</td>
<td style="text-align: center;">54.55</td>
<td style="text-align: center;">44.02</td>
<td style="text-align: center;">64.43</td>
</tr>
<tr>
<td style="text-align: center;">FlanT5(zero-shot)</td>
<td style="text-align: center;">33.49</td>
<td style="text-align: center;">31.58</td>
<td style="text-align: center;">36.84</td>
<td style="text-align: center;">22.01</td>
<td style="text-align: center;">11.00</td>
<td style="text-align: center;">33.97</td>
</tr>
<tr>
<td style="text-align: center;">FlanT5(two-shot)</td>
<td style="text-align: center;">37.80</td>
<td style="text-align: center;">33.49</td>
<td style="text-align: center;">38.76</td>
<td style="text-align: center;">26.79</td>
<td style="text-align: center;">13.40</td>
<td style="text-align: center;">36.68</td>
</tr>
<tr>
<td style="text-align: center;">FlanT5(four-shot)</td>
<td style="text-align: center;">38.28</td>
<td style="text-align: center;">34.45</td>
<td style="text-align: center;">41.15</td>
<td style="text-align: center;">26.79</td>
<td style="text-align: center;">13.40</td>
<td style="text-align: center;">37.96</td>
</tr>
<tr>
<td style="text-align: center;">FlanT5(six-shot)</td>
<td style="text-align: center;">38.28</td>
<td style="text-align: center;">34.45</td>
<td style="text-align: center;">41.63</td>
<td style="text-align: center;">27.27</td>
<td style="text-align: center;">13.88</td>
<td style="text-align: center;">38.12</td>
</tr>
<tr>
<td style="text-align: center;">FlanT5(eight-shot)</td>
<td style="text-align: center;">38.76</td>
<td style="text-align: center;">33.01</td>
<td style="text-align: center;">41.63</td>
<td style="text-align: center;">26.79</td>
<td style="text-align: center;">14.35</td>
<td style="text-align: center;">37.80</td>
</tr>
<tr>
<td style="text-align: center;">Word puzzle</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">ChatGPT(zero-shot)</td>
<td style="text-align: center;">56.10</td>
<td style="text-align: center;">52.44</td>
<td style="text-align: center;">51.83</td>
<td style="text-align: center;">43.90</td>
<td style="text-align: center;">29.27</td>
<td style="text-align: center;">53.46</td>
</tr>
<tr>
<td style="text-align: center;">ChatGPT(two-shot)</td>
<td style="text-align: center;">55.49</td>
<td style="text-align: center;">53.66</td>
<td style="text-align: center;">51.22</td>
<td style="text-align: center;">44.51</td>
<td style="text-align: center;">30.49</td>
<td style="text-align: center;">53.46</td>
</tr>
<tr>
<td style="text-align: center;">ChatGPT(four-shot)</td>
<td style="text-align: center;">54.27</td>
<td style="text-align: center;">53.66</td>
<td style="text-align: center;">51.83</td>
<td style="text-align: center;">43.90</td>
<td style="text-align: center;">28.05</td>
<td style="text-align: center;">53.25</td>
</tr>
<tr>
<td style="text-align: center;">ChatGPT(six-shot)</td>
<td style="text-align: center;">56.71</td>
<td style="text-align: center;">51.83</td>
<td style="text-align: center;">54.27</td>
<td style="text-align: center;">45.12</td>
<td style="text-align: center;">28.66</td>
<td style="text-align: center;">54.27</td>
</tr>
<tr>
<td style="text-align: center;">ChatGPT(eight-shot)</td>
<td style="text-align: center;">58.54</td>
<td style="text-align: center;">56.71</td>
<td style="text-align: center;">54.27</td>
<td style="text-align: center;">48.17</td>
<td style="text-align: center;">34.76</td>
<td style="text-align: center;">56.50</td>
</tr>
<tr>
<td style="text-align: center;">FlanT5(zero-shot)</td>
<td style="text-align: center;">42.68</td>
<td style="text-align: center;">32.93</td>
<td style="text-align: center;">43.90</td>
<td style="text-align: center;">28.66</td>
<td style="text-align: center;">20.12</td>
<td style="text-align: center;">39.84</td>
</tr>
<tr>
<td style="text-align: center;">FlanT5(two-shot)</td>
<td style="text-align: center;">44.51</td>
<td style="text-align: center;">34.76</td>
<td style="text-align: center;">45.73</td>
<td style="text-align: center;">30.49</td>
<td style="text-align: center;">18.90</td>
<td style="text-align: center;">41.67</td>
</tr>
<tr>
<td style="text-align: center;">FlanT5(four-shot)</td>
<td style="text-align: center;">43.29</td>
<td style="text-align: center;">35.98</td>
<td style="text-align: center;">47.56</td>
<td style="text-align: center;">30.49</td>
<td style="text-align: center;">20.73</td>
<td style="text-align: center;">42.28</td>
</tr>
<tr>
<td style="text-align: center;">FlanT5(six-shot)</td>
<td style="text-align: center;">44.51</td>
<td style="text-align: center;">36.59</td>
<td style="text-align: center;">47.56</td>
<td style="text-align: center;">29.88</td>
<td style="text-align: center;">17.68</td>
<td style="text-align: center;">42.89</td>
</tr>
<tr>
<td style="text-align: center;">FlanT5(eight-shot)</td>
<td style="text-align: center;">45.73</td>
<td style="text-align: center;">33.54</td>
<td style="text-align: center;">46.95</td>
<td style="text-align: center;">27.44</td>
<td style="text-align: center;">16.46</td>
<td style="text-align: center;">42.07</td>
</tr>
</tbody>
</table>
<p>be a possible solution to defying commonsense. Yet, we note that the performance of this model also declines on the group-based metrics. Moreover, we point out the possible data distribution overlap between BRAINTEASER and RiddleSense, as RiddleSense was collected publicly from similar online websites and contains much more samples (5.7k) than BRAINTEASER.</p>
<h1>A. 8 Human Annotator Information</h1>
<p>Our human annotators major in computer science come from East Asia, Europe and the Middle East. All annotators all fluent in English.</p>
<p>Table 9: RoBERTa-L (RS) zero-shot results over two BRAINTEASER subtasks.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Model</th>
<th style="text-align: center;">Instance-based</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Group-based</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Overall</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Original</td>
<td style="text-align: center;">Semantic</td>
<td style="text-align: center;">Context</td>
<td style="text-align: center;">Ori \&amp; Sem</td>
<td style="text-align: center;">Ori \&amp; Sem \&amp; Con</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Sentence Puzzle</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">RoBERTa-L(RS)</td>
<td style="text-align: center;">42.11</td>
<td style="text-align: center;">45.93</td>
<td style="text-align: center;">54.55</td>
<td style="text-align: center;">37.32</td>
<td style="text-align: center;">27.75</td>
<td style="text-align: center;">47.53</td>
</tr>
<tr>
<td style="text-align: center;">Word Puzzle</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">RoBERTa-L(RS)</td>
<td style="text-align: center;">23.78</td>
<td style="text-align: center;">26.22</td>
<td style="text-align: center;">31.10</td>
<td style="text-align: center;">20.73</td>
<td style="text-align: center;">9.76</td>
<td style="text-align: center;">27.03</td>
</tr>
</tbody>
</table>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{5}$ https://quillbot.com/&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref4:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref5:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
<li id="fn:1">
<p>${ }^{2}$ The code is available at https://github.com/1171jpg/BrainTeaser&#160;<a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 2 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>