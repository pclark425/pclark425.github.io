<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-712 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-712</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-712</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-20.html">extraction-schema-20</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <p><strong>Paper ID:</strong> paper-8a88483bac28e15a86af9e461333fc3e9b68d606</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/8a88483bac28e15a86af9e461333fc3e9b68d606" target="_blank">Active learning for optimal intervention design in causal models</a></p>
                <p><strong>Paper Venue:</strong> Nature Machine Intelligence</p>
                <p><strong>Paper TL;DR:</strong> An active learning approach with theoretical guarantees to discover optimal interventions in causal models, and the framework is demonstrated in the context of genetic perturbation design using single-cell transcriptomic data.</p>
                <p><strong>Paper Abstract:</strong> Sequential experimental design to discover interventions that achieve a desired outcome is a key problem in various domains including science, engineering and public policy. When the space of possible interventions is large, making an exhaustive search infeasible, experimental design strategies are needed. In this context, encoding the causal relationships between the variables, and thus the effect of interventions on the system, is critical for identifying desirable interventions more efficiently. Here we develop a causal active learning strategy to identify interventions that are optimal, as measured by the discrepancy between the post-interventional mean of the distribution and a desired target mean. The approach employs a Bayesian update for the causal model and prioritizes interventions using a carefully designed, causally informed acquisition function. This acquisition function is evaluated in closed form, allowing for fast optimization. The resulting algorithms are theoretically grounded with information-theoretic bounds and provable consistency results for linear causal models with known causal graph. We apply our approach to both synthetic data and single-cell transcriptomic data from Perturb–CITE-sequencing experiments to identify optimal perturbations that induce a specific cell-state transition. The causally informed acquisition function generally outperforms existing criteria, allowing for optimal intervention design with fewer but carefully selected samples. Identifying interventions that can induce a desired effect is challenging owing to the combinatorial number of possible choices in design space. Zhang and colleagues propose an active learning approach with theoretical guarantees to discover optimal interventions in causal models, and demonstrate the framework in the context of genetic perturbation design using single-cell transcriptomic data.</p>
                <p><strong>Cost:</strong> 0.023</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e712.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e712.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CIV</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Causal Integrated Variance</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An acquisition function for active experimental design that integrates posterior uncertainty of the 'optimality gap' g(a) across the intervention space to prioritize interventions that most reduce uncertainty about the optimal intervention.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Causal Integrated Variance (CIV)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>CIV is an acquisition function used in a Bayesian active-learning framework for optimal intervention design. It models the SCM parameters B with a DAG-informed conjugate prior (DAG--BLR), computes the posterior uncertainty Var(g(a) | D_t) where g(a) is a noisy version of the optimality gap ||a - a*||^2, and selects the next intervention a' by minimizing the integrated posterior variance h(a', D_t) = ∫_A Var(g(a) | D_t(a')) dv(a) over a measure v on the feasible intervention set A. CIV uses a plug-in estimator for the hypothetical samples from candidate interventions (using E[B|D_t]) to obtain a tractable, closed-form expression for the variance and acquisition value, enabling gradient-based optimization under constraints (e.g., unit-sphere directions). The method has information-theoretic interpretation (lower bound on mutual information) and asymptotic consistency results for recovering the optimal intervention.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Synthetic linear Gaussian SCMs and Perturb-CITE-seq single-cell perturbation data</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Interactive/experimental environments where the agent can perform interventions and obtain samples: (1) synthetic linear structural causal models defined on DAGs (30-node and other sizes) with continuous shift interventions and (2) a real-world biological 'virtual lab' of perturbational single-cell gene expression (Perturb-CITE-seq) where each interventional experiment corresponds to a genetic perturbation and returns cell-level expression vectors. Both settings allow sequential active experimentation.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>measurement noise (exogenous Gaussian noise), model misspecification / DAG misspecification (examined in supplements), irrelevant interventions (areas of intervention space with little relevance to optimum)</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Posterior uncertainty in g(a) and posterior covariance of B are used to identify regions/interventions with high epistemic uncertainty; mutual-information-lower-bound links uncertainty reduction to information gain.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Indirect: CIV integrates uncertainty across A; when combined with a non-uniform measure v it can emphasize important regions. CIV alone does not use explicit downweighting of distractor variables, but the integrated variance limits attention to model-relevant directions.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Interventional sampling: performing interventions and updating the DAG--BLR posterior reduces Var(B) and Var(g(a)), thereby empirically refuting incorrect parameter estimates and spurious associational signals through active experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td>One-step lookahead acquisition: choose next intervention a' that minimizes the expected posterior integrated variance of g(a) after hypothetically adding plug-in samples from a' (CIV). Optimization uses closed-form variance expressions and gradient-based solvers with constraints (e.g., unit-sphere for direction).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>Qualitative: CIV consistently outperforms correlation-based and naive baselines (random, greedy) and parameter-variance-focused baselines (MaxV, CV) in synthetic experiments (e.g., 30-node DAGs with 10 intervention targets) and in the biological Perturb-CITE-seq dataset (36 genes); yields faster decline in relative distance to target mean and better final approximation to target mean.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td>Baselines (random, greedy, MaxV, CV) show slower improvement and worse final distances to the target mean across the reported synthetic and biological experiments; no single numerical metric (precision/recall/F1) reported — primary metrics are relative distance to target mean and squared distance between estimated and true optimal interventions.</td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>CIV, by explicitly modelling causal structure via a DAG-respecting Bayesian prior and targeting the uncertainty of the optimality gap across interventions, more efficiently identifies optimal interventions than baselines; it admits closed-form variance evaluation enabling fast optimization, has an information-theoretic justification (lower bound on mutual information), and is asymptotically consistent under the assumed model and known DAG.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Active learning for optimal intervention design in causal models', 'publication_date_yy_mm': '2022-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e712.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e712.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CIV-OW</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Causal Integrated Variance — Output-Weighted</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An output-weighted variant of CIV that reweights the integrated variance to place more emphasis on interventions with a small estimated optimality gap, improving focus on promising interventions during active sampling.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>CIV-OW (Causal Output-Weighted Integrated Variance)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>CIV-OW modifies CIV by choosing a non-uniform measure v(a) that upweights interventions likely to be close to the optimal intervention. The measure uses an estimate proportional to the inverse probability of the optimality gap (or practical bimodal von Mises–Fisher density on the sphere) to concentrate mass on interventions with small estimated gap. The acquisition h_OW(a', D_t) integrates Var(g(a) | D_t(a')) against this weighted measure, prioritizing experiments that reduce uncertainty in high-reward regions and thereby improving sample efficiency in finding optimal interventions.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Same interactive environments as CIV (synthetic SCMs; Perturb-CITE-seq)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Sequential experimental settings with active intervention selection; CIV-OW is designed for cases where the feasible intervention magnitude is controlled and we search over directional space (unit sphere) or other constrained intervention sets.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Output-weighting (reweighting intervention space to focus on candidate optimal regions), which indirectly reduces influence of irrelevant regions of the intervention space</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>irrelevant interventions / large-volume regions of A with low chance of being optimal, measurement noise, parameter uncertainty</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Same posterior-variance signals as CIV (Var(g(a)) and Var(B)) flag uncertain or potentially spurious regions; weighting uses estimated optimality gap to detect promising areas.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Explicit downweighting of regions far from the estimated optimum via the non-uniform measure v(a) (inverse optimality-gap probability or bimodal von Mises–Fisher on the sphere), thereby allocating fewer samples to irrelevant interventions.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Active interventions and posterior updates refute incorrect model parameter estimates; output-weighting focuses experiments to quickly disconfirm suboptimal regions.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td>Same one-step lookahead integrated-variance minimization as CIV but integrating against an output-weighted measure that concentrates on interventions with small estimated gap.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>Qualitative: CIV-OW improves over CIV in experiments reported, achieving faster convergence to the target mean and better final approximation in synthetic simulations (30-node DAGs) and shown to improve robustness/efficiency relative to unweighted CIV.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td>CIV (unweighted) — performs well but typically worse than CIV-OW in the same experiments; other baselines (random, greedy, MaxV, CV) perform worse than both CIV variants.</td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Weighting the acquisition by output (estimated proximity to optimum) focuses experiments where they matter and provides measurable gains over uniform-integrated-variance (CIV), improving sample efficiency for finding optimal interventions while still leveraging causal posterior updates.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Active learning for optimal intervention design in causal models', 'publication_date_yy_mm': '2022-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e712.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e712.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DAG-BLR</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>DAG–Bayesian Linear Regression prior (generalization of DAG–Wishart)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A conjugate Bayesian prior on edge weights B and noise variances Σ that respects DAG sparsity (zeros for non-parents) and allows efficient posterior updates in linear Gaussian SCMs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>DAG--BLR prior / posterior update</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>DAG--BLR places independent conjugate priors on each node's linear regression coefficients B_{i,pa(i)} (normal with variance scaled by σ_i^2) and inverse-gamma priors on noise variances σ_i^2, respecting the known DAG sparsity pattern. It generalizes the DAG–Wishart family to the interventional setting and is conjugate for the shift-intervention linear Gaussian model, enabling closed-form posterior hyperparameter updates per node after interventional/observational samples. Posterior means and covariances of rows of B are used in computing Var(g(a)) for CIV/CIV-OW.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Same experimental environments used in the paper (synthetic SCM experiments and Perturb-CITE-seq)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Modeling component used inside an active experimental design pipeline; not an environment itself but a posterior model used to interpret interventional samples obtained from interactive experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>statistical noise and parameter uncertainty; it enforces sparsity according to a known DAG which helps avoid fitting spurious edges absent from the DAG assumption.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Posterior covariance and variance statistics for B reveal which parameters are uncertain and which parent relationships are poorly estimated (high variance flags potential spurious correlations under current data).</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Implicit: known-DAG sparsity sets non-parents to zero, preventing spurious edges from being fitted; posterior variance informs acquisition which nodes/edges to focus on.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Interventional data are used to update the conjugate posterior; as more interventional samples are collected the posterior concentrates (Bernstein–von Mises), thereby empirically refuting incorrect parameter estimates.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td>Used within active-learning loop: after each intervention and sampling step the DAG--BLR posterior is updated and Var(g(a)) recomputed to choose the next intervention via CIV/CIV-OW.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>Provides efficient, closed-form posterior updates that enable CIV/CIV-OW to be computed and optimized; helps the active learner converge faster by respecting known causal sparsity. Empirically, combined with CIV/CIV-OW it yields strong performance in synthetic and biological experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td>Not explicitly benchmarked as an isolated ablation versus other priors in main text; alternative baseline MaxV focuses on minimizing posterior variance of B but performs worse at finding optimal interventions compared with CIV family.</td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Using a DAG-respecting conjugate prior yields tractable posterior updates and meaningful posterior covariances that are central to computing CIV/CIV-OW; enforcing known sparsity (known DAG) prevents many spurious associations from being considered and is a core assumption for the method's strong empirical performance.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Active learning for optimal intervention design in causal models', 'publication_date_yy_mm': '2022-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e712.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e712.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BALD</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Bayesian Active Learning by Disagreement (BALD)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An active learning criterion that selects experiments maximizing information gain (mutual information) about a quantity of interest; cited as related work and interpretative connection for CIV.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Bayesian active learning for classification and preference learning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>BALD (Bayesian Active Learning by Disagreement)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>BALD chooses queries that maximize the mutual information between the model predictions (or a target quantity) and the potential observation, i.e., choose a' to maximize I(Q; x' | a', D_t) where Q is the quantity of interest. Evaluating BALD often requires approximating high-dimensional entropies or sampling (e.g., MCMC) and is computationally heavy; the paper draws a formal connection showing CIV approximately maximizes a lower bound on such mutual information but is computationally cheaper.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>General active-learning and experimental design contexts (cited conceptually, not experimentally used on a virtual lab in this paper)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Not applied in the paper's experiments; referenced as a conceptual alternative that directly maximizes mutual information for active learning.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>general epistemic uncertainty and ambiguous model predictions</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Directly uses information-theoretic gain (mutual information) to prioritize experiments that resolve disagreement, thereby targeting ambiguous/spurious signals in predictions.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Implicit via information gain optimization: regions with low information about Q receive fewer samples.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Experiments that yield high mutual information are used to resolve ambiguities and refute alternative hypotheses; operationally achieved by selecting informative queries and updating the posterior.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td>Mutual information maximization (entropy reduction) per candidate experiment.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Paper positions CIV as an efficient approximation to BALD for the specific optimal-intervention objective: CIV minimizes an integrated-variance objective that lower-bounds mutual information, avoiding BALD's expensive high-dimensional entropy computations while retaining information-theoretic justification.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Active learning for optimal intervention design in causal models', 'publication_date_yy_mm': '2022-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e712.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e712.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Causal Bandits</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Causal Bandits / Structural Causal Bandits</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Bandit formulations that incorporate causal structure to select interventions/arms more effectively than standard bandit algorithms (reduce regret by exploiting causal relationships).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Causal bandits: learning good interventions via causal inference</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Causal bandits / Structural causal bandits</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>These approaches extend multi-armed bandits by embedding arms/interventions within a known causal graph to exploit structural information (e.g., which interventions affect which downstream nodes), enabling improved sample efficiency and regret bounds compared to correlation-only bandits. They typically use causal inference to estimate interventional effects and may select arms that resolve structural uncertainty relevant to decision-making.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Bandit-style sequential decision settings (cited as related work; not directly used in experiments)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Sequential interactive decision-making where each arm corresponds to an intervention and the learner observes outcomes; causal variants leverage the graph structure to inform exploration/exploitation.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>spurious correlations from naive arm-reward associations; can alleviate mistaken correlational signals by leveraging causal structure</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Structural reasoning using the causal graph to avoid attributing downstream effects to irrelevant arms; theoretical analyses on regret characterize behavior under confounding assumptions.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Selects arms guided by causal influence paths, implicitly downweighting arms unlikely to affect the target based on structural knowledge.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Interventional feedback and causal model updates distinguish true causal effects from spurious associations between arms and outcomes.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td>Sequential exploration/exploitation guided by causal structure and regret minimization objectives.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Cited as motivating work showing causal structure can substantially improve sequential intervention selection (bandit regret) compared to purely correlational strategies; motivates the development of CIV which leverages causal structure for active intervention design.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Active learning for optimal intervention design in causal models', 'publication_date_yy_mm': '2022-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e712.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e712.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CausalBO</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Causal Bayesian Optimization</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Bayesian optimization methods that incorporate causal structure to more efficiently search continuous intervention spaces when seeking optima of downstream targets.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Causal Bayesian optimization</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Causal Bayesian Optimization</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Causal Bayesian optimization extends Bayesian optimization by incorporating a causal graph linking inputs (interventions) to outputs (objectives), using structural knowledge to inform the surrogate model and acquisition function, with the aim of reducing queries in high-dimensional/structured intervention spaces. It can handle continuous interventions and exploit causal parent-child relationships to better predict interventional outcomes.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Bayesian optimization settings with continuous intervention spaces (referenced as related literature; not directly run in this paper)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Black-box optimization with ability to perform sequential interventions and observe outcomes; in causal version the surrogate respects causal structure.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>spurious correlations between inputs and outputs that ignore causal paths; causal structure reduces these by modelling direct/indirect influence.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Model-based: using causal graph and surrogate uncertainty estimates to identify where surrogate predictions are unreliable or possibly spurious.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Acquisition functions can be adapted to focus on interventions with plausible causal influence on the target, implicitly downweighting irrelevant regions.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Interventional sampling and surrogate posterior updates refute previously plausible but spurious surrogate predictions.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td>Acquisition-function-driven sequential querying that leverages causal structure (e.g., directed influence) when constructing the surrogate and the acquisition.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Cited as contemporary work that motivates exploiting causal structure in optimization; CIV contributes a tractable integrated-variance acquisition that shares the same motivation but targets distributional mean matching in SCMs with closed-form evaluations.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Active learning for optimal intervention design in causal models', 'publication_date_yy_mm': '2022-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e712.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e712.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MaxV baseline</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Maximum-Variance-parameter (MaxV) baseline</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A baseline acquisition that selects interventions to minimize posterior variance of model parameters B (max over rows' spectral norms), focusing on reducing global model uncertainty rather than the optimality-gap-specific uncertainty.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>MaxV (parameter-variance minimization)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>MaxV computes an acquisition value as the maximum spectral norm over posterior covariance matrices of each row B_i,pa(i) given a candidate intervention, i.e., h_MaxV(a', D_t) = max_i ||Var(B_{i,pa(i)} | a', D_t)||_2. It selects interventions that most reduce the largest-uncertainty parameter block, aiming to reduce global uncertainty about the SCM parameters.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Synthetic SCM experiments and biological dataset used as baselines</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Used as a baseline active strategy inside the same interactive experimental setup; it is not specialized to the target-optimality objective but to parameter estimation.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>parameter estimation uncertainty and measurement noise</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>High posterior covariance identifies uncertain parameters (which may correspond to spurious or underdetermined relationships); MaxV targets those for reduction.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Not focused on downweighting distractors; instead prioritizes experiments reducing overall parameter covariance.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Posterior concentration over B via interventions can refute spurious parameter estimates, but method is not targeted to discriminate spurious-for-decision variables specifically.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td>Greedy minimization of a scalarized posterior-variance metric of model parameters.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>Empirically performs worse than CIV and CIV-OW in the paper's synthetic and biological experiments for the goal of identifying optimal interventions, because it focuses on global parameter uncertainty rather than the optimality gap.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>As a parameter-variance-focused baseline, MaxV is less sample-efficient for finding the optimal intervention than causally targeted acquisition functions (CIV/CIV-OW) because it does not weight parameters by their relevance to the objective.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Active learning for optimal intervention design in causal models', 'publication_date_yy_mm': '2022-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Causal bandits: learning good interventions via causal inference <em>(Rating: 2)</em></li>
                <li>Structural causal bandits: where to intervene? <em>(Rating: 2)</em></li>
                <li>Causal Bayesian optimization <em>(Rating: 2)</em></li>
                <li>Bayesian active learning for classification and preference learning <em>(Rating: 2)</em></li>
                <li>Causal-BALD: deep Bayesian active learning of outcomes to infer treatment-effects from observational data <em>(Rating: 1)</em></li>
                <li>Backshift: learning causal cyclic graphs from unknown shift interventions <em>(Rating: 1)</em></li>
                <li>The interventional Bayesian Gaussian equivalent score for Bayesian causal inference with unknown soft interventions <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-712",
    "paper_id": "paper-8a88483bac28e15a86af9e461333fc3e9b68d606",
    "extraction_schema_id": "extraction-schema-20",
    "extracted_data": [
        {
            "name_short": "CIV",
            "name_full": "Causal Integrated Variance",
            "brief_description": "An acquisition function for active experimental design that integrates posterior uncertainty of the 'optimality gap' g(a) across the intervention space to prioritize interventions that most reduce uncertainty about the optimal intervention.",
            "citation_title": "here",
            "mention_or_use": "use",
            "method_name": "Causal Integrated Variance (CIV)",
            "method_description": "CIV is an acquisition function used in a Bayesian active-learning framework for optimal intervention design. It models the SCM parameters B with a DAG-informed conjugate prior (DAG--BLR), computes the posterior uncertainty Var(g(a) | D_t) where g(a) is a noisy version of the optimality gap ||a - a*||^2, and selects the next intervention a' by minimizing the integrated posterior variance h(a', D_t) = ∫_A Var(g(a) | D_t(a')) dv(a) over a measure v on the feasible intervention set A. CIV uses a plug-in estimator for the hypothetical samples from candidate interventions (using E[B|D_t]) to obtain a tractable, closed-form expression for the variance and acquisition value, enabling gradient-based optimization under constraints (e.g., unit-sphere directions). The method has information-theoretic interpretation (lower bound on mutual information) and asymptotic consistency results for recovering the optimal intervention.",
            "environment_name": "Synthetic linear Gaussian SCMs and Perturb-CITE-seq single-cell perturbation data",
            "environment_description": "Interactive/experimental environments where the agent can perform interventions and obtain samples: (1) synthetic linear structural causal models defined on DAGs (30-node and other sizes) with continuous shift interventions and (2) a real-world biological 'virtual lab' of perturbational single-cell gene expression (Perturb-CITE-seq) where each interventional experiment corresponds to a genetic perturbation and returns cell-level expression vectors. Both settings allow sequential active experimentation.",
            "handles_distractors": false,
            "distractor_handling_technique": null,
            "spurious_signal_types": "measurement noise (exogenous Gaussian noise), model misspecification / DAG misspecification (examined in supplements), irrelevant interventions (areas of intervention space with little relevance to optimum)",
            "detection_method": "Posterior uncertainty in g(a) and posterior covariance of B are used to identify regions/interventions with high epistemic uncertainty; mutual-information-lower-bound links uncertainty reduction to information gain.",
            "downweighting_method": "Indirect: CIV integrates uncertainty across A; when combined with a non-uniform measure v it can emphasize important regions. CIV alone does not use explicit downweighting of distractor variables, but the integrated variance limits attention to model-relevant directions.",
            "refutation_method": "Interventional sampling: performing interventions and updating the DAG--BLR posterior reduces Var(B) and Var(g(a)), thereby empirically refuting incorrect parameter estimates and spurious associational signals through active experiments.",
            "uses_active_learning": true,
            "inquiry_strategy": "One-step lookahead acquisition: choose next intervention a' that minimizes the expected posterior integrated variance of g(a) after hypothetically adding plug-in samples from a' (CIV). Optimization uses closed-form variance expressions and gradient-based solvers with constraints (e.g., unit-sphere for direction).",
            "performance_with_robustness": "Qualitative: CIV consistently outperforms correlation-based and naive baselines (random, greedy) and parameter-variance-focused baselines (MaxV, CV) in synthetic experiments (e.g., 30-node DAGs with 10 intervention targets) and in the biological Perturb-CITE-seq dataset (36 genes); yields faster decline in relative distance to target mean and better final approximation to target mean.",
            "performance_without_robustness": "Baselines (random, greedy, MaxV, CV) show slower improvement and worse final distances to the target mean across the reported synthetic and biological experiments; no single numerical metric (precision/recall/F1) reported — primary metrics are relative distance to target mean and squared distance between estimated and true optimal interventions.",
            "has_ablation_study": true,
            "number_of_distractors": null,
            "key_findings": "CIV, by explicitly modelling causal structure via a DAG-respecting Bayesian prior and targeting the uncertainty of the optimality gap across interventions, more efficiently identifies optimal interventions than baselines; it admits closed-form variance evaluation enabling fast optimization, has an information-theoretic justification (lower bound on mutual information), and is asymptotically consistent under the assumed model and known DAG.",
            "uuid": "e712.0",
            "source_info": {
                "paper_title": "Active learning for optimal intervention design in causal models",
                "publication_date_yy_mm": "2022-09"
            }
        },
        {
            "name_short": "CIV-OW",
            "name_full": "Causal Integrated Variance — Output-Weighted",
            "brief_description": "An output-weighted variant of CIV that reweights the integrated variance to place more emphasis on interventions with a small estimated optimality gap, improving focus on promising interventions during active sampling.",
            "citation_title": "here",
            "mention_or_use": "use",
            "method_name": "CIV-OW (Causal Output-Weighted Integrated Variance)",
            "method_description": "CIV-OW modifies CIV by choosing a non-uniform measure v(a) that upweights interventions likely to be close to the optimal intervention. The measure uses an estimate proportional to the inverse probability of the optimality gap (or practical bimodal von Mises–Fisher density on the sphere) to concentrate mass on interventions with small estimated gap. The acquisition h_OW(a', D_t) integrates Var(g(a) | D_t(a')) against this weighted measure, prioritizing experiments that reduce uncertainty in high-reward regions and thereby improving sample efficiency in finding optimal interventions.",
            "environment_name": "Same interactive environments as CIV (synthetic SCMs; Perturb-CITE-seq)",
            "environment_description": "Sequential experimental settings with active intervention selection; CIV-OW is designed for cases where the feasible intervention magnitude is controlled and we search over directional space (unit sphere) or other constrained intervention sets.",
            "handles_distractors": false,
            "distractor_handling_technique": "Output-weighting (reweighting intervention space to focus on candidate optimal regions), which indirectly reduces influence of irrelevant regions of the intervention space",
            "spurious_signal_types": "irrelevant interventions / large-volume regions of A with low chance of being optimal, measurement noise, parameter uncertainty",
            "detection_method": "Same posterior-variance signals as CIV (Var(g(a)) and Var(B)) flag uncertain or potentially spurious regions; weighting uses estimated optimality gap to detect promising areas.",
            "downweighting_method": "Explicit downweighting of regions far from the estimated optimum via the non-uniform measure v(a) (inverse optimality-gap probability or bimodal von Mises–Fisher on the sphere), thereby allocating fewer samples to irrelevant interventions.",
            "refutation_method": "Active interventions and posterior updates refute incorrect model parameter estimates; output-weighting focuses experiments to quickly disconfirm suboptimal regions.",
            "uses_active_learning": true,
            "inquiry_strategy": "Same one-step lookahead integrated-variance minimization as CIV but integrating against an output-weighted measure that concentrates on interventions with small estimated gap.",
            "performance_with_robustness": "Qualitative: CIV-OW improves over CIV in experiments reported, achieving faster convergence to the target mean and better final approximation in synthetic simulations (30-node DAGs) and shown to improve robustness/efficiency relative to unweighted CIV.",
            "performance_without_robustness": "CIV (unweighted) — performs well but typically worse than CIV-OW in the same experiments; other baselines (random, greedy, MaxV, CV) perform worse than both CIV variants.",
            "has_ablation_study": true,
            "number_of_distractors": null,
            "key_findings": "Weighting the acquisition by output (estimated proximity to optimum) focuses experiments where they matter and provides measurable gains over uniform-integrated-variance (CIV), improving sample efficiency for finding optimal interventions while still leveraging causal posterior updates.",
            "uuid": "e712.1",
            "source_info": {
                "paper_title": "Active learning for optimal intervention design in causal models",
                "publication_date_yy_mm": "2022-09"
            }
        },
        {
            "name_short": "DAG-BLR",
            "name_full": "DAG–Bayesian Linear Regression prior (generalization of DAG–Wishart)",
            "brief_description": "A conjugate Bayesian prior on edge weights B and noise variances Σ that respects DAG sparsity (zeros for non-parents) and allows efficient posterior updates in linear Gaussian SCMs.",
            "citation_title": "here",
            "mention_or_use": "use",
            "method_name": "DAG--BLR prior / posterior update",
            "method_description": "DAG--BLR places independent conjugate priors on each node's linear regression coefficients B_{i,pa(i)} (normal with variance scaled by σ_i^2) and inverse-gamma priors on noise variances σ_i^2, respecting the known DAG sparsity pattern. It generalizes the DAG–Wishart family to the interventional setting and is conjugate for the shift-intervention linear Gaussian model, enabling closed-form posterior hyperparameter updates per node after interventional/observational samples. Posterior means and covariances of rows of B are used in computing Var(g(a)) for CIV/CIV-OW.",
            "environment_name": "Same experimental environments used in the paper (synthetic SCM experiments and Perturb-CITE-seq)",
            "environment_description": "Modeling component used inside an active experimental design pipeline; not an environment itself but a posterior model used to interpret interventional samples obtained from interactive experiments.",
            "handles_distractors": false,
            "distractor_handling_technique": null,
            "spurious_signal_types": "statistical noise and parameter uncertainty; it enforces sparsity according to a known DAG which helps avoid fitting spurious edges absent from the DAG assumption.",
            "detection_method": "Posterior covariance and variance statistics for B reveal which parameters are uncertain and which parent relationships are poorly estimated (high variance flags potential spurious correlations under current data).",
            "downweighting_method": "Implicit: known-DAG sparsity sets non-parents to zero, preventing spurious edges from being fitted; posterior variance informs acquisition which nodes/edges to focus on.",
            "refutation_method": "Interventional data are used to update the conjugate posterior; as more interventional samples are collected the posterior concentrates (Bernstein–von Mises), thereby empirically refuting incorrect parameter estimates.",
            "uses_active_learning": true,
            "inquiry_strategy": "Used within active-learning loop: after each intervention and sampling step the DAG--BLR posterior is updated and Var(g(a)) recomputed to choose the next intervention via CIV/CIV-OW.",
            "performance_with_robustness": "Provides efficient, closed-form posterior updates that enable CIV/CIV-OW to be computed and optimized; helps the active learner converge faster by respecting known causal sparsity. Empirically, combined with CIV/CIV-OW it yields strong performance in synthetic and biological experiments.",
            "performance_without_robustness": "Not explicitly benchmarked as an isolated ablation versus other priors in main text; alternative baseline MaxV focuses on minimizing posterior variance of B but performs worse at finding optimal interventions compared with CIV family.",
            "has_ablation_study": true,
            "number_of_distractors": null,
            "key_findings": "Using a DAG-respecting conjugate prior yields tractable posterior updates and meaningful posterior covariances that are central to computing CIV/CIV-OW; enforcing known sparsity (known DAG) prevents many spurious associations from being considered and is a core assumption for the method's strong empirical performance.",
            "uuid": "e712.2",
            "source_info": {
                "paper_title": "Active learning for optimal intervention design in causal models",
                "publication_date_yy_mm": "2022-09"
            }
        },
        {
            "name_short": "BALD",
            "name_full": "Bayesian Active Learning by Disagreement (BALD)",
            "brief_description": "An active learning criterion that selects experiments maximizing information gain (mutual information) about a quantity of interest; cited as related work and interpretative connection for CIV.",
            "citation_title": "Bayesian active learning for classification and preference learning",
            "mention_or_use": "mention",
            "method_name": "BALD (Bayesian Active Learning by Disagreement)",
            "method_description": "BALD chooses queries that maximize the mutual information between the model predictions (or a target quantity) and the potential observation, i.e., choose a' to maximize I(Q; x' | a', D_t) where Q is the quantity of interest. Evaluating BALD often requires approximating high-dimensional entropies or sampling (e.g., MCMC) and is computationally heavy; the paper draws a formal connection showing CIV approximately maximizes a lower bound on such mutual information but is computationally cheaper.",
            "environment_name": "General active-learning and experimental design contexts (cited conceptually, not experimentally used on a virtual lab in this paper)",
            "environment_description": "Not applied in the paper's experiments; referenced as a conceptual alternative that directly maximizes mutual information for active learning.",
            "handles_distractors": null,
            "distractor_handling_technique": null,
            "spurious_signal_types": "general epistemic uncertainty and ambiguous model predictions",
            "detection_method": "Directly uses information-theoretic gain (mutual information) to prioritize experiments that resolve disagreement, thereby targeting ambiguous/spurious signals in predictions.",
            "downweighting_method": "Implicit via information gain optimization: regions with low information about Q receive fewer samples.",
            "refutation_method": "Experiments that yield high mutual information are used to resolve ambiguities and refute alternative hypotheses; operationally achieved by selecting informative queries and updating the posterior.",
            "uses_active_learning": true,
            "inquiry_strategy": "Mutual information maximization (entropy reduction) per candidate experiment.",
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "Paper positions CIV as an efficient approximation to BALD for the specific optimal-intervention objective: CIV minimizes an integrated-variance objective that lower-bounds mutual information, avoiding BALD's expensive high-dimensional entropy computations while retaining information-theoretic justification.",
            "uuid": "e712.3",
            "source_info": {
                "paper_title": "Active learning for optimal intervention design in causal models",
                "publication_date_yy_mm": "2022-09"
            }
        },
        {
            "name_short": "Causal Bandits",
            "name_full": "Causal Bandits / Structural Causal Bandits",
            "brief_description": "Bandit formulations that incorporate causal structure to select interventions/arms more effectively than standard bandit algorithms (reduce regret by exploiting causal relationships).",
            "citation_title": "Causal bandits: learning good interventions via causal inference",
            "mention_or_use": "mention",
            "method_name": "Causal bandits / Structural causal bandits",
            "method_description": "These approaches extend multi-armed bandits by embedding arms/interventions within a known causal graph to exploit structural information (e.g., which interventions affect which downstream nodes), enabling improved sample efficiency and regret bounds compared to correlation-only bandits. They typically use causal inference to estimate interventional effects and may select arms that resolve structural uncertainty relevant to decision-making.",
            "environment_name": "Bandit-style sequential decision settings (cited as related work; not directly used in experiments)",
            "environment_description": "Sequential interactive decision-making where each arm corresponds to an intervention and the learner observes outcomes; causal variants leverage the graph structure to inform exploration/exploitation.",
            "handles_distractors": null,
            "distractor_handling_technique": null,
            "spurious_signal_types": "spurious correlations from naive arm-reward associations; can alleviate mistaken correlational signals by leveraging causal structure",
            "detection_method": "Structural reasoning using the causal graph to avoid attributing downstream effects to irrelevant arms; theoretical analyses on regret characterize behavior under confounding assumptions.",
            "downweighting_method": "Selects arms guided by causal influence paths, implicitly downweighting arms unlikely to affect the target based on structural knowledge.",
            "refutation_method": "Interventional feedback and causal model updates distinguish true causal effects from spurious associations between arms and outcomes.",
            "uses_active_learning": true,
            "inquiry_strategy": "Sequential exploration/exploitation guided by causal structure and regret minimization objectives.",
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "Cited as motivating work showing causal structure can substantially improve sequential intervention selection (bandit regret) compared to purely correlational strategies; motivates the development of CIV which leverages causal structure for active intervention design.",
            "uuid": "e712.4",
            "source_info": {
                "paper_title": "Active learning for optimal intervention design in causal models",
                "publication_date_yy_mm": "2022-09"
            }
        },
        {
            "name_short": "CausalBO",
            "name_full": "Causal Bayesian Optimization",
            "brief_description": "Bayesian optimization methods that incorporate causal structure to more efficiently search continuous intervention spaces when seeking optima of downstream targets.",
            "citation_title": "Causal Bayesian optimization",
            "mention_or_use": "mention",
            "method_name": "Causal Bayesian Optimization",
            "method_description": "Causal Bayesian optimization extends Bayesian optimization by incorporating a causal graph linking inputs (interventions) to outputs (objectives), using structural knowledge to inform the surrogate model and acquisition function, with the aim of reducing queries in high-dimensional/structured intervention spaces. It can handle continuous interventions and exploit causal parent-child relationships to better predict interventional outcomes.",
            "environment_name": "Bayesian optimization settings with continuous intervention spaces (referenced as related literature; not directly run in this paper)",
            "environment_description": "Black-box optimization with ability to perform sequential interventions and observe outcomes; in causal version the surrogate respects causal structure.",
            "handles_distractors": null,
            "distractor_handling_technique": null,
            "spurious_signal_types": "spurious correlations between inputs and outputs that ignore causal paths; causal structure reduces these by modelling direct/indirect influence.",
            "detection_method": "Model-based: using causal graph and surrogate uncertainty estimates to identify where surrogate predictions are unreliable or possibly spurious.",
            "downweighting_method": "Acquisition functions can be adapted to focus on interventions with plausible causal influence on the target, implicitly downweighting irrelevant regions.",
            "refutation_method": "Interventional sampling and surrogate posterior updates refute previously plausible but spurious surrogate predictions.",
            "uses_active_learning": true,
            "inquiry_strategy": "Acquisition-function-driven sequential querying that leverages causal structure (e.g., directed influence) when constructing the surrogate and the acquisition.",
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "Cited as contemporary work that motivates exploiting causal structure in optimization; CIV contributes a tractable integrated-variance acquisition that shares the same motivation but targets distributional mean matching in SCMs with closed-form evaluations.",
            "uuid": "e712.5",
            "source_info": {
                "paper_title": "Active learning for optimal intervention design in causal models",
                "publication_date_yy_mm": "2022-09"
            }
        },
        {
            "name_short": "MaxV baseline",
            "name_full": "Maximum-Variance-parameter (MaxV) baseline",
            "brief_description": "A baseline acquisition that selects interventions to minimize posterior variance of model parameters B (max over rows' spectral norms), focusing on reducing global model uncertainty rather than the optimality-gap-specific uncertainty.",
            "citation_title": "here",
            "mention_or_use": "use",
            "method_name": "MaxV (parameter-variance minimization)",
            "method_description": "MaxV computes an acquisition value as the maximum spectral norm over posterior covariance matrices of each row B_i,pa(i) given a candidate intervention, i.e., h_MaxV(a', D_t) = max_i ||Var(B_{i,pa(i)} | a', D_t)||_2. It selects interventions that most reduce the largest-uncertainty parameter block, aiming to reduce global uncertainty about the SCM parameters.",
            "environment_name": "Synthetic SCM experiments and biological dataset used as baselines",
            "environment_description": "Used as a baseline active strategy inside the same interactive experimental setup; it is not specialized to the target-optimality objective but to parameter estimation.",
            "handles_distractors": false,
            "distractor_handling_technique": null,
            "spurious_signal_types": "parameter estimation uncertainty and measurement noise",
            "detection_method": "High posterior covariance identifies uncertain parameters (which may correspond to spurious or underdetermined relationships); MaxV targets those for reduction.",
            "downweighting_method": "Not focused on downweighting distractors; instead prioritizes experiments reducing overall parameter covariance.",
            "refutation_method": "Posterior concentration over B via interventions can refute spurious parameter estimates, but method is not targeted to discriminate spurious-for-decision variables specifically.",
            "uses_active_learning": true,
            "inquiry_strategy": "Greedy minimization of a scalarized posterior-variance metric of model parameters.",
            "performance_with_robustness": "Empirically performs worse than CIV and CIV-OW in the paper's synthetic and biological experiments for the goal of identifying optimal interventions, because it focuses on global parameter uncertainty rather than the optimality gap.",
            "performance_without_robustness": null,
            "has_ablation_study": true,
            "number_of_distractors": null,
            "key_findings": "As a parameter-variance-focused baseline, MaxV is less sample-efficient for finding the optimal intervention than causally targeted acquisition functions (CIV/CIV-OW) because it does not weight parameters by their relevance to the objective.",
            "uuid": "e712.6",
            "source_info": {
                "paper_title": "Active learning for optimal intervention design in causal models",
                "publication_date_yy_mm": "2022-09"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Causal bandits: learning good interventions via causal inference",
            "rating": 2,
            "sanitized_title": "causal_bandits_learning_good_interventions_via_causal_inference"
        },
        {
            "paper_title": "Structural causal bandits: where to intervene?",
            "rating": 2,
            "sanitized_title": "structural_causal_bandits_where_to_intervene"
        },
        {
            "paper_title": "Causal Bayesian optimization",
            "rating": 2,
            "sanitized_title": "causal_bayesian_optimization"
        },
        {
            "paper_title": "Bayesian active learning for classification and preference learning",
            "rating": 2,
            "sanitized_title": "bayesian_active_learning_for_classification_and_preference_learning"
        },
        {
            "paper_title": "Causal-BALD: deep Bayesian active learning of outcomes to infer treatment-effects from observational data",
            "rating": 1,
            "sanitized_title": "causalbald_deep_bayesian_active_learning_of_outcomes_to_infer_treatmenteffects_from_observational_data"
        },
        {
            "paper_title": "Backshift: learning causal cyclic graphs from unknown shift interventions",
            "rating": 1,
            "sanitized_title": "backshift_learning_causal_cyclic_graphs_from_unknown_shift_interventions"
        },
        {
            "paper_title": "The interventional Bayesian Gaussian equivalent score for Bayesian causal inference with unknown soft interventions",
            "rating": 1,
            "sanitized_title": "the_interventional_bayesian_gaussian_equivalent_score_for_bayesian_causal_inference_with_unknown_soft_interventions"
        }
    ],
    "cost": 0.022934999999999997,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>MIT <br> Libraries</h1>
<h2>DSpace@MIT</h2>
<h2>MIT Open Access Articles</h2>
<h2>Active learning for optimal intervention design in causal models</h2>
<p>The MIT Faculty has made this article openly available. Please share how this access benefits you. Your story matters.</p>
<p>Citation: Zhang, J., Cammarata, L., Squires, C. et al. Active learning for optimal intervention design in causal models. Nat Mach Intell 5, 1066-1075 (2023).</p>
<p>As Published: 10.1038/s42256-023-00719-0
Publisher: Springer Science and Business Media LLC
Persistent URL: https://hdl.handle.net/1721.1/154216
Version: Final published version: final published article, as it appeared in a journal, conference proceedings, or other formally published context</p>
<p>Terms of Use: Article is made available in accordance with the publisher's policy and may be subject to US copyright law. Please refer to the publisher's site for terms of use.</p>
<h1>Active learning for optimal intervention design in causal models</h1>
<p>Received: 25 November 2022<br>Accepted: 14 August 2023</p>
<p>Published online: 2 October 2023</p>
<h2>A. Check for updates</h2>
<p>Jiaqi Zhang ${ }^{1,2}$, Louis Cammarata ${ }^{2,3,4}$, Chandler Squires ${ }^{1,2,4}$, Themistoklis P. Sapsis ${ }^{1}$ \&amp; Caroline Uhler ${ }^{1,2}$</p>
<p>Sequential experimental design to discover interventions that achieve a desired outcome is a key problem in various domains including science, engineering and public policy. When the space of possible interventions is large, making an exhaustive search infeasible, experimental design strategies are needed. In this context, encoding the causal relationships between the variables, and thus the effect of interventions on the system, is critical for identifying desirable interventions more efficiently. Here we develop a causal active learning strategy to identify interventions that are optimal, as measured by the discrepancy between the post-interventional mean of the distribution and a desired target mean. The approach employs a Bayesian update for the causal model and prioritizes interventions using a carefully designed, causally informed acquisition function. This acquisition function is evaluated in closed form, allowing for fast optimization. The resulting algorithms are theoretically grounded with information-theoretic bounds and provable consistency results for linear causal models with known causal graph. We apply our approach to both synthetic data and single-cell transcriptomic data from Perturb-CITE-sequencing experiments to identify optimal perturbations that induce a specific cell-state transition. The causally informed acquisition function generally outperforms existing criteria, allowing for optimal intervention design with fewer but carefully selected samples.</p>
<p>An important problem across multiple disciplines, ranging from bioengineering to mechanical systems, operations research and environmental regulation, is the discovery of interventions on a system that can produce a desired outcome. With little prior knowledge of the outcome before performing the intervention, one can have a huge number of possible choices for the optimal design. In particular, the interventions in many applications are combinatorial, resulting in an exponential-size design space, making an exhaustive search infeasible. Examples include experimental design of genetic perturbations, such as those for cellular reprogramming in regenerative medicine ${ }^{2}$, optimal feedback control in mechanical systems ${ }^{3}$ as well as turbulent
flows ${ }^{3}$, dynamic pricing strategies in customer networks ${ }^{4}$ and iterative intervention research for climate change adaption ${ }^{5}$.</p>
<p>In this context, 'active learning' has been proposed as a machinelearning strategy to efficiently explore the search space ${ }^{6}$. Such methods sequentially and strategically acquire new interventions, with the goal of discovering an optimal or a close-to-optimal intervention using the fewest number of samples. Although it can be of interest to identify optimal interventions for 'estimating' particular quantities in the model (for example, ref. 7), in this work, we consider the optimality of an intervention with respect to 'optimizing' its effect. Specifically, this is done by successively (I) updating the model belief using samples</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p><strong>Fig. 1: Overview schematic of the active learning framework for optimal intervention design in causal models.</strong> Iterative process of active learning for intervention design in causal models, in which the main design steps are to update the structural causal model using the obtained samples and to select the next intervention based on an acquisition function.</p>
<p>acquired so far from different interventions and (2) selecting the next intervention to obtain samples from by constructing and optimizing an acquisition function, which prioritizes interventions that are more informative for the desired outcomes (Fig. 1).</p>
<p>Standard approaches towards this problem are correlation based. More precisely, the idea is to estimate associational relations between intervention and outcome to update the model belief and make decisions about which samples to acquire next. The two main approaches use either statistical theory, by minimizing the posterior variance of the outcome estimate<sup>5</sup>, or information theory, by maximizing the mutual information between its samples and the quantity of interest<sup>9</sup>. Although these methods are being widely applied, correlation-based approaches are not optimal when the underlying model is causal, as they do not take into account the structural information that can reduce the number of feasible models. Many systems that are relevant for applications are causal, in which an intervention can only have an impact on downstream variables. It is therefore of interest to develop methods that learn what is necessary about the underlying causal mechanisms to identify optimal interventions more quickly.</p>
<p>These limitations of correlation-based approaches have been noted in the related bandit setting, in which the goal is to minimize the cumulative regret by selecting arms iteratively, and causal relations have been used to improve over standard regret bounds<sup>10,11</sup>. Recent works in the related field of Bayesian optimization have also considered exploiting causal structure<sup>12–14</sup>. We provide a detailed review of these works in Supplementary Information I. Our work extends these works in two ways: (1) rather than optimizing a single target node, we optimize the entire distribution mean, and (2) rather than considering discrete or finite interventions, we consider continuous-valued interventions. This is important for various applications, such as optimizing drug dosages or product prices. As a concrete example, consider cellular reprogramming in genomics, a problem of great interest for regenerative medicine<sup>1,15</sup>. The aim in this field is to reprogramme easily accessible cell types into a desired cell type via continuous-valued interventions such as the overexpression of particular transcription factors and genes. Because such interventions act on genes, which regulate each other through different pathways<sup>16</sup>, this problem can be formulated as optimal intervention design in a causal model represented by a directed network on genes.</p>
<p>In particular, we model the underlying causal model in a Bayesian way using a structurally informed prior. We then construct an acquisition function based on this model and show how to efficiently evaluate and optimize it. The acquisition function both enjoys an information-theoretic bound and provably recovers the optimal intervention in the appropriate limit. We demonstrate experimentally that our algorithms outperform baselines on both synthetic data and the design of genetic perturbations in the context of single-cell gene expression data. Finally, we conclude with an outlook to future research directions and discuss other potential applications.</p>
<h2><strong>Problem set-up</strong></h2>
<p>The state of the system of interest is described by a <em>p</em>-dimensional random variable <strong>x</strong> = (<em>x</em><sub>1</sub>, ..., <em>x</em><sub><em>p</em></sub>) ∈ ℝ<sup><em>p</em></sup> sampled from a structural causal model (SCM)<sup>17,18</sup>. Precisely, the 'causal structure' of the system is represented by a directed acyclic graph (DAG), and we assume that the joint distribution <em>P</em> of <em>x</em> factorizes with respect to the DAG; that is, <em>P</em>(<strong>x</strong>) = ∏<sub><em>i</em>=1</sub><sup><em>p</em></sup> <em>P</em>(<em>x</em><sub><em>i</em></sub>|<em>x</em><sub><em>p</em><sub><em>i</em></sub>|)<em>i</em>}, where pa(<em>i</em>) = {<em>j</em> ∈ [<em>p</em>]; <em>j</em> + <em>i</em>} denotes the parents of node <em>i</em> in the DAG. In this formulation, the conditional distributions are the 'causal mechanisms' that generate the variable <em>x</em><sub><em>i</em></sub> from its parents <em>x</em><sub><em>p</em><sub><em>i</em></sub><em>i</em></sub>. Assuming a linear Gaussian model, then</p>
<p>$$
x_i = \sum_{k=1}^{p} B_{ik} x_k + \epsilon_i, \quad \forall i \in [p], \tag{1}
$$</p>
<p>where the real-valued coefficients <em>B</em><sub><em>ik</em></sub> = 0 if <em>k</em> ≠ pa(<em>i</em>) and the exogenous noise variables <em>ε</em><sub><em>i</em></sub> ∼ <em>N</em>(0, σ<sub><em>i</em></sub><sup>2</sup>) with variance σ<sub><em>i</em></sub><sup>2</sup> &gt; 0 are mutually independent. An example of this model is given in Fig. 2. For simplicity, we assume that the system is centred to be mean zero, but intercepts can be easily added to equation (1) and the following approaches still apply.</p>
<p>An intervention, denoted by a vector <strong>a</strong> ∈ ℝ<sup><em>p</em></sup>, modifies the conditional distribution <em>P</em>(<em>x</em><sub><em>i</em></sub>|<em>x</em><sub><em>p</em><sub><em>i</em></sub><em>i</em></sub>) into a new conditional distribution, <em>P</em><sup>0</sup>(<em>x</em><sub><em>i</em></sub>|<em>x</em><sub><em>p</em><sub><em>i</em></sub><em>i</em></sub>). Every <em>i</em> ∈ [<em>p</em>] for which <em>a</em><sub><em>i</em></sub> ≠ 0 is called an 'intervention target'. In this work, we consider shift interventions<sup>19,20</sup> (which are a special class of soft interventions<sup>21</sup>), in which the interventional distribution <em>P</em><sup>0</sup>(<strong>x</strong>) of the modified system under intervention is given by</p>
<p>$$
x_i = \sum_{k=1}^{p} B_{ik} x_k + a_i + \epsilon_i, \quad \forall i \in [p], \tag{2}
$$</p>
<p>where <em>a</em><sub><em>i</em></sub> = 0 for every <em>i</em> that is not an intervention target. This can be written in matrix form as <strong>x</strong> = <strong>Bx</strong> + <strong>a</strong> + <strong>c</strong>, or <strong>x</strong> = (<strong>l</strong>−<em>B</em>)<sup>−1</sup>(<strong>a</strong> + <strong>c</strong>), where <em>l</em> is the <em>p</em>th order identity matrix and <strong>c</strong> ∼ <em>N</em>(0, Σ) with Σ being the diagonal matrix with σ<sub><em>i</em></sub><sup>2</sup>, ..., σ<sub><em>p</em></sub><sup>2</sup> on its diagonal. These interventions can be used to model a broad class of genetic perturbations including clustered regularly interspaced short palindromic repeat (CRISPR) interference and activation<sup>22</sup>, and transcription factor overexpression<sup>23</sup>. Although we consider the case in which all variables can be intervened on, as for example in genetic perturbation experiments<sup>24</sup>, for other applications, it may be of interest to consider extensions in which only a subset of variables can be intervened on. We also note that an extension to hard interventions can be obtained by setting <em>B</em><sub><em>ik</em></sub> to 0 for every <em>i</em> that is an intervention target and subsequently defining the post-interventional mean.</p>
<p>Whether or not an intervention induces the desired outcome is decided through samples obtained in the intervened environment, that is, <strong>x</strong> ∼ <em>P</em><sup>0</sup>. Since <strong>x</strong> is random, it is intuitive to use the average over multiple samples<sup>20,25</sup>, that is, the empirical estimate of the distribution mean, and compare this with the 'target mean' <strong>µ</strong><sup><strong>0</strong></sup>, which is user specified and describes the desired outcome. Formally, we seek an intervention <strong>a</strong> ∈ ℝ<sup><em>p</em></sup> such that, after obtaining <em>n</em> samples <strong>x</strong><sup>(1)</sup>, ..., <strong>x</strong><sup>(<em>n</em>)</sup> ∈ ℝ<sup><em>p</em></sup>, which we denote by <strong>x</strong><sub><em>i</em><sub><em>m</em></sub></sub>, the squared distance between the empirical mean and the target mean, that is, the quantity || ∫<sub><em>n</em></sub><sup><em></sup> </em><em>Σ</em><em><sub></em>m<em><sub></em>m<em></sub><sup></em></sup><strong>x</strong><sup>(<em>m</em>)</sup> − <strong>µ</strong><sup><strong>0</strong></sup> ||<sub><em>n</em></sub><sup><em></sup></em><em>Σ</em><em><sub></em>m<em><sub></em>m<em></sub><sup></em></sup><strong>x</strong><sup>(<em>m</em>)</sup>| is minimized. Denoting by <strong>c</strong><sup>(2)</sup>, ..., <strong>c</strong><sup>(<em>n</em>)</sup> (or short <strong>c</strong><sub><em>i</em><sub><em>m</em></sub></sub>) the exogenous noise vectors independently sampled from <em>N</em>(0, Σ), then the squared distance between the empirical and target mean can be written as</p>
<p>$$
\left| (l - B) ^{−1} \left( \mathbf{a} + \frac{1}{n} \sum_{m=1}^{n} \mathbf{c}^{(m)} \right) - \mathbf{\mu}^n \right|_2^2 \tag{3}
$$</p>
<p>using the matrix form. Here $\frac{1}{n} \sum_{m=1}^n \mathbf{c}^{(m)}$ accounts for the finite number <em>n</em> of interventional samples, where <em>n</em> is user specified based on the available budget. However, as <strong>c</strong><sub><em>i</em><sub><em>m</em></sub></sub> does not depend on the choice of <strong>a</strong>, we can discard this term for the minimization of equation (3) with respect to <strong>a</strong> by considering its infinite-sample version. When the sample size goes to infinity, by the law of large numbers, $\frac{1}{n} \sum_{m=1}^n \mathbf{c}^{(m)} = 0$ almost surely, and thus, the optimal intervention <strong>a</strong><sup><strong>0</strong></sup> achieves the minimum value of zero in equation (3) and has an explicit form <strong>a</strong><sup><strong>0</strong></sup> = (<em>l</em> − <em>B</em>)<strong>µ</strong><sup><strong>0</strong></sup>, which, as expected, depends on the unknown parameter <em>B</em>.</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Fig. 2 | Example causal model. An example of a linear SCM with Gaussian noise on a four-node DAG, in which nodes and edges are labelled with variables and coefficients, respectively.</p>
<p>In what follows, we assume that the DAG structure is given; that is, the sparsity pattern of <em>B</em> is known but not the edge weights <em>B</em><sup><em>B</em></sup> for <em>B</em><sup><em>B</em></sup> × 0. This assumption is natural in many applications including fluid mechanics36 and optimal pricing3, in which there are pre-specified networks given by either known laws or prior information. For applications in which the network cannot be assumed to be known such as problems in biology, the common approach is to use existing data from various sources to learn the DAG first15,27. Further discussions on the implications of an unknown DAG structure are provided in Supplementary Information D.</p>
<p>Let <em>D</em><sup><em>t</em></sup> = {(<em>x</em><sub>(<em>n</em><sub>1</sub>), <em>a</em><sup><em>t</em>(1)</sup>, ..., (<em>x</em><sub><em>D</em>(1), <em>a</em><sup><em>t</em>(1)</sup>)} be the 'current' dataset, consisting of all samples obtained so far by performing interventions <em>a</em><sup><em>t</em>(1)</sup>, ..., <em>a</em><sup><em>t</em>(1)</sup>; here, <em>n</em><sub><em>t</em></sub>, ..., <em>n</em><sub><em>t</em></sub> denotes the number of samples obtained for each of the <em>t</em> interventions. To simplify notation, we will assume <em>n</em><sub><em>t</em></sub> = ... = <em>n</em><sub><em>t</em></sub> = <em>n</em> in the following, but all results still hold when using different sample sizes for each intervention. Given this dataset, the goal is to select the next intervention <em>a</em><sup><em>t</em></sup>(<em>t</em>+1) ∈ ℝ<sup><em>p</em></sup> such that the resulting dataset <em>D</em><sub><em>t</em>+1</sub> = <em>D</em><sub><em>t</em></sub> ∪ (<em>x</em><sub>(<em>n</em>)</sub>, <em>a</em><sup><em>t</em></sup>(<em>t</em>+1)) contains as much information as possible about the underlying optimal intervention <em>a</em><sup><em>t</em></sup>. The overall aim of iteratively picking interventions is to find the optimal intervention <em>a</em><sup><em>t</em></sup> with a minimum number of samples.</p>
<h1>Design of the acquisition function</h1>
<p>To sequentially select the next best intervention, there are two important steps (Fig. 1): (1) updating the posterior of the edge weights in the causal model based on the samples in <em>D</em><sub><em>t</em></sub> collected so far and (2) constructing an 'acquisition function', <em>h</em>(<strong>a</strong>, <em>D</em><sub><em>t</em></sub>), such that the new dataset <em>D</em><sub><em>t</em>+1</sub> after adding samples from <em>a</em><sup><em>t</em></sup>(<em>t</em>+1) = argmin<sub><em>a</em></sub><em>h</em>(<strong>a</strong>, <em>D</em><sub><em>t</em></sub>) is most informative of the optimal intervention <em>a</em><sup><em>t</em></sup> and can be evaluated and optimized efficiently.</p>
<p>For the first step, we generalize the DAG–Wishart distribution28–30 to define a Bayesian model on the parameters <em>B</em>, which can be updated efficiently given a dataset <em>D</em><sub><em>t</em></sub> (Methods). For the second step, we first characterize the uncertainty in estimating the optimality of an arbitrary intervention <strong>a</strong>. Recall that the optimality of <strong>a</strong> is given by the square distance in equation (3), which measures how close the intervention is to achieving the target mean. As <em>B</em> is unknown, we can only estimate this square distance based on the current collected samples in <em>D</em><sub><em>t</em></sub>. The uncertainty of the estimation can be characterized by its variance Var(⊥(<em>I</em> − <em>B</em>)^{-1}(<strong>a</strong> + ⊥∑<sub><em>m</em>=1</sub><sup><em>n</em></sup> <em>ε</em><sub><em>m</em></sub>) −<strong>µ</strong><sup>+</sup><strong>||</strong><sup>2</sup><sub><em>k</em></sub>(<em>D</em><sub><em>k</em></sub>). However, this quantity is typically hard to evaluate as it involves (<em>I</em> − <em>B</em>)<sup>−1</sup>, whose posterior does not have a closed form. We instead multiply the term inside the variance by <em>I</em> − <em>B</em> and characterize the following variance:</p>
<p>$$
\sigma_{g(\mathbf{a} \mid \mathcal{D}_t}^2 : = \text{Var}\left(g(\mathbf{a}) \mid \mathcal{D}_t\right),
$$</p>
<p>where we define</p>
<p>$$
g(\mathbf{a}) := \left|\left(\mathbf{a} + \frac{1}{n} \sum_{m=1}^{n} \epsilon^{(m)}\right) - (I - B) \mathbf{a}^* \right|_2^2. \tag{5}
$$</p>
<p>Interestingly, <em>g</em>(<strong>a</strong>) can be interpreted as a noisy version of the 'optimality gap' by noting that the gap between an arbitrary intervention <strong>a</strong> and the optimal intervention <strong>a</strong><em> = (</em>I<em> − </em>B<em>)</em><em>µ</em><strong> can be written as ||</strong>a<strong> − </strong>a<strong><em>||<sup>2</sup><sub></em>k*</sub> = ||</strong>a<strong> − (<em>I<em> − </em>B<em>)</em>*µ</em></strong>||<sup>2</sup><sub><em>k</em></sub>, which is a version of <em>g</em>(<strong>a</strong>) without noise terms.</p>
<p>Building upon equation (4), the next acquired intervention should be such that after adding its samples to <em>D</em><sub><em>t</em></sub> to obtain <em>D</em><sub><em>t</em>+1</sub>, the uncertainty <em>σ</em><sub><em>g</em>(<em>a</em>)|<em>D</em><sub><em>t</em>+1</sub></sub><sup><em>p</em></sup> conditioned on <em>D</em><sub><em>t</em>+1</sub> is minimized. However, as the samples are unobserved before performing the intervention, we do not have access to <em>D</em><sub><em>t</em>+1</sub> yet. Therefore, when deciding which intervention to perform, we consider the <strong>a</strong><sup><em>t</em></sup>-augmented dataset <em>D</em><sub><em>t</em></sub>(<strong>a</strong><sup><em>t</em></sup>) = <em>D</em><sub><em>t</em></sub> ∪ (<strong>x</strong><sub><em>t</em></sub><sup><em>t</em></sup>)<sup><em>t</em></sup> with 'hypothetical samples' <strong>x</strong><sub><em>t</em></sub><sup><em>t</em></sup> of <strong>a</strong><sup><em>t</em></sup>, which are <em>n</em> repetitions of the plug-in estimator defined as <strong>x</strong><sup><em>t</em></sup> := (<em>I</em> − <em>E</em>(<em>B</em>|<em>D</em><sub><em>t</em></sub>))<sup>−1</sup><strong>a</strong><sup><em>t</em></sup>. This estimator is obtained through <strong>x</strong><sup><em>t</em></sup> = (<em>I</em> − <em>B</em>)<sup>−1</sup>(<strong>a</strong><sup><em>t</em></sup> + <strong>ϵ</strong>) by using the maximum a posteriori estimate <em>E</em>(<em>B</em>|<em>D</em><sub><em>t</em></sub>), which concentrates to <em>B</em> as <em>D</em><sub><em>t</em></sub> grows31, and replacing <strong>ϵ</strong> with its mean 0.</p>
<p>By denoting the feasible set of interventions by <em>A</em>, a reasonable choice is to select <strong>a</strong><sup><em>t</em></sup>32 based on integrating the uncertainty <em>σ</em><sub><em>g</em>(<em>a</em>)|<em>D</em><sub><em>t</em></sub>(<strong>a</strong><sup><em>t</em></sup>) over all <strong>a</strong> ∈ <em>A</em>. Formally, we let</p>
<p>$$
\mathbf{a}^{(t+1)} = \text{argmin}_{\mathbf{a}' \in A} h(\mathbf{a}', \mathcal{D}_t),
$$</p>
<p>and define the causal integrated variance (CIV) acquisition function <em>h</em> as follows.</p>
<h1>Definition 1. The CIV acquisition function evaluated</h1>
<p>at <strong>a</strong><sup><em>t</em></sup> with current dataset <em>D</em><sub><em>t</em></sub> is</p>
<p>$$
h(\mathbf{a}', \mathcal{D}<em _mathcal_A="\mathcal{A">t) = \int</em>),
$$}} \sigma_{g(\mathbf{a})| \mathcal{D}_t(\mathbf{a}'\cdot)}^2 \text{d}\mathbf{v}(\mathbf{a</p>
<p>where <em>v</em> is a non-negative measure on <em>A</em>.</p>
<p>Intuitively, this acquisition function provides a one-step lookahead of the overall uncertainty after acquiring intervention <strong>a</strong><sup><em>t</em></sup>. Minimizing it will prioritize interventions that are most informative towards estimating the optimal intervention. This acquisition function also automatically accounts for the causal model by using a posterior on <em>B</em>.</p>
<p>Note that in this formulation, we can choose the measure <em>v</em>. For example, a uniform measure treats each intervention <strong>a</strong> ∈ <em>A</em> equally and the resulting uncertainty captures how well we can estimate the entire landscape of the optimality gap <em>g</em>. In most cases, an overly concentrated measure (for example, a Dirac measure at a single point) is not preferred, as it can lead to the erroneous estimation of <em>g</em>(<strong>a</strong>) for most <strong>a</strong> ∈ <em>A</em>, which makes minimizing <em>g</em> hard. Inspired by a recent line of work on output-weighted acquisition functions32,33, we describe how to choose a non-uniform measure <em>v</em> in the next section.</p>
<p>We discuss how to optimize CIV to solve for <strong>a</strong><sup><em>t</em></sup>32 in Methods, in which we show that the variance <em>σ</em><sub><em>g</em>(<em>a</em>)|<em>D</em><sub><em>t</em></sub>(<strong>a</strong><sup><em>t</em></sup>) can be computed in closed form. Considering <em>A</em> to be the unit hypersphere and <em>v</em> to be the uniform measure on it, this then leads to an explicit formula for CIV, which enables fast gradient-based optimizers to be used.</p>
<h1>Making the acquisition function output weighted</h1>
<p>Although the use of a uniform measure <em>v</em> places an equal weight on reducing the variance of estimating the optimality gap for all <strong>a</strong> in <em>A</em>, as our goal is to identify the optimal intervention (that is, which minimizes the optimality gap), it is desirable to place more weight on interventions <strong>a</strong> in <em>A</em> with a smaller optimality gap. Note that as the ambient dimension grows, the volume (and thus the probability) of interventions with the optimality gap under a certain threshold shrinks (Supplementary Information C). This motivates the following measure, which uses the inverse of the optimality gap probability to up-weight interventions <strong>a</strong> in <em>A</em> that are closer to the optimal intervention:</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p><strong>Fig. 3</strong> | <strong>Illustration of output-weighted non-negative measure</strong> <strong>v(a) on the space of all possible interventions</strong> <em>A</em><strong>. a</strong>, Values of <strong>da</strong>/dv(<strong>a</strong>) (up to constant multipliers) plotted against values of ||<strong>a</strong> − <strong>b</strong>||<em 2="2">{2}^{2} on the half sphere with ||<strong>a</strong> − <strong>b</strong>||</em> ≤ 2. Solid lines correspond to }^{2<em>f</em>ⱼ_{[<strong>a</strong>−<strong>b</strong>]} in different dimensions; the dashed line is the non-degenerate replacement for <em>p</em> = 3 using the bimodal von Mises–Fisher distribution, which behaves similar to equation (6) in higher dimensions (Fig. 3b and Supplementary Information C). Note that the weighting proposed here is symmetric and also puts more mass on interventions that are closer to −<strong>b</strong>. The reason for this is that the optimal intervention can also be recovered by maximizing the optimality gap ||<strong>a</strong> − <strong>a</strong><em>||_{2} which gives −</em><em>a</em>** (Supplementary Information C).</p>
<p>The corresponding causal output-weighted integrated variance (CIV-OW) acquisition function is given by</p>
<p>$$h_{\text{OW}}(\mathbf{a}'', \mathcal{D}<em _mathcal_A="\mathcal{A">t) = \int</em>}} \sigma_{\mathbf{a}'|\mathcal{D<em _mathbf_a="\mathbf{a">t(\mathbf{a}')}^2 \cdot \frac{f</em>$$}}(\mathbf{a})}{f_{{\mathbf{a} \to \mathbf{b}}_1}^2 (|\mathbf{a} - \mathbf{b}|_2^2)} \mathbf{d\mathbf{a}}.\tag{9</p>
<p>Methods for evaluating and optimizing CIV-OW are given in Supplementary Information C and Supplementary Figs. 1 and 2.</p>
<h4><strong>Theoretical results</strong></h4>
<p>We provide two interpretations of the introduced CIV acquisition function. First, taking an information-theoretic perspective, we show that the proposed uncertainty measure can be lower bounded by the 'negative' mutual information between the variables of interest and the newly acquired samples. Thus, minimizing the uncertainty corresponds to maximizing a lower bound to the mutual information, which means that CIV approximately prioritizes the most informative interventions. Second, taking a graphical perspective, we illustrate how the causal structure is utilized by the CIV acquisition function to identify an intervention that is asymptotically consistent with the optimal intervention. The details underlying these theoretical results are provided in Methods, and Fig. 4 illustrates our consistency results experimentally, showing that a gradient-based optimizer with initialization close to the optimal intervention <strong>a</strong><em> converges to </em><em>a</em><em><em> as </em>t</em> increases.</p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Mises–Fisher distribution. <strong>b</strong>, Visualization of <strong>v(a)</strong> in three dimensions using the bimodal von Mises–Fisher distribution. Here <strong>b</strong> ∈ S^{2} was randomly generated and the points on the sphere are coloured corresponding to the value of dv(<strong>a</strong>)/<strong>d</strong><strong>a</strong>, which is larger for directions that are more aligned with <strong>b</strong>.</p>
<h4><strong>Applications</strong></h4>
<h4><strong>Experiments on the synthetic dataset</strong></h4>
<p>To create a generative model following the linear SCM in equation (1), we first generate a DAG with <em>p</em> nodes (Supplementary Information G and Supplementary Fig. 3). Then, we randomly draw edge weights, namely, <em>B</em><sup><em>a</em></sup> with <em>k</em> ∈ pa(<em>i</em>), from a uniform distribution bounded away from zero. Next, we generate a sparse set of intervention targets and a randomly sampled optimal intervention <strong>a</strong><em> over these targets. Finally, we calculate the target mean </em><em>µ</em><strong> using </strong>a<strong><em> and the ground-truth causal model. These steps construct a synthetic instance of a causal system and optimal intervention </em>*a</strong>* . A more detailed description of the above procedure is given in Methods and Supplementary Information G.</p>
<p>We compare our two acquisition functions, CIV in equation (7) and CIV-OW in equation (9), against four relevant baselines. The 'random' baseline corresponds to a passive setting, in which each intervention is selected at random and no information from the collected samples is used. We also compare against three other active methods. The 'greedy' baseline selects the next intervention <strong>a</strong>^{<em>D</em>} = (<em>I</em> − ⊤(<em>B</em>|<em>D</em><sub><em>t</em></sub>)|<strong>µ</strong><em> purely based on the current estimate of </em><em>a</em><strong> (which is given by ⊤(<em>B<em>|</em>D<em><sub></em>t<em></sub>), where </em>B<em> is estimated from </em>D<em><sub></em>t<em></sub>). The MaxV baseline seeks to select interventions that minimize the posterior variance of the estimate of the model parameters </em>B<em>. It uses as acquisition function a scalar version of this variance, namely, </em>h<em><sub>MaxV</sub>(</em><em>a</em><em><sub></em></sub>, <em>D</em><sub><em>t</em></sub>) = max<sub><em>i</em> ∈ [<em>p</em>]} || Var(<em>B</em><sub><em>i</em>,pa(<em>i</em>)</sub>|<strong>a</strong><sub><em></sub>, </em>D<em><sub></em>t<em></sub>)||<em 2="2">{2}, where ||·||</em> denotes the spectral norm of the covariance matrix of </em>B<em><sub></em>i<em>,pa(</em>i<em>)</sub>. As different rows of </em>B<em> (for example, </em>B<em><sub></em>i<em>,pa(</em>i<em>)</sub> and </em>B<em><sub></em>i<em>,pa(</em>j<em>)</sub> for </em>i<em> ≠ </em>j<em>) are independent (Definition 2), we use the maximum of the spectral norms over </em>i<em> ∈ [</em>p<em>]. Whereas our acquisition functions concentrate on estimating the model parameters that are relevant for </em>*a</em></strong> , this baseline estimates the entire model. Finally, the CV baseline seeks to minimize the posterior variance of estimating <strong>a</strong><em> and uses the spectral norm of its covariance matrix as acquisition function; that is, </em>h<em><sub>CV</sub>(</em><em>a</em><em><sub></em></sub>, <em>D</em><sub><em>t</em></sub>) = || Var((<em>I</em> − <em>B</em>|<strong>µ</strong><em><sub></em></sub><em>|</em><em>a</em><em><sub></em></sub>, <em>D</em><sub><em>t</em></sub>)||_{2}. This is in contrast to our approach that integrates the estimation uncertainty over the entire feasible set of interventions.</p>
<p>To reduce evaluation noise effects, we run each method 20 times over 10 instances of a fixed DAG and optimal intervention <strong>a</strong><em> . Figure 5 shows our results for 30-node DAGs with 10 intervention targets and sample size </em>n<em> = 1 per time step. Denoting the obtained samples at time step </em>t<em> with </em>D<em><sub></em>t<em></sub>, we use the unbiased estimate </em><em>a</em><em><sub></em>t<em></sub></em> = (<em>I</em> − ⊤(<em>B</em>|<em>D</em><sub><em>t</em></sub>)|<strong>µ</strong><em> of </em><em>a</em><strong> to obtain the current estimate of the target mean using the true model parameters, that is, </strong>µ<strong><sub><em>t<em></sub></em> = (<em>I</em> − <em>B</em>)<sup>−1</sup> <strong>a</strong><sub><em>t</em></sub>. Figure 5a shows the decline in the relative distance between current and target mean || <strong>µ</strong><sub><em>t</em></sub><em> − </em>*µ</em></strong>||_{2} / || <strong>µ</strong>* 1/2 across time steps. Figure 5b highlights the statistics of the last time</p>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p><strong>Fig. 4: Convergence of the selected intervention a</strong> <sup>30</sup> <strong>to the optimal intervention a*. a</strong>, DAG showing the targets of the optimal intervention <strong>a*. b</strong>, Minimizing the CIV acquisition function using a sample size of <em>n</em> = 1 at each time step yields interventions <strong>a</strong> for <em>t</em> = 1, ..., 50 that converge to **a*.</p>
<p>step. As is apparent from these experiments, our proposed acquisition functions consistently outperform all baselines, with CIV-OW improving upon CIV by using an output-weighted measure. In Supplementary Information G, we examine the effect of varying different parameters including graph size, number of intervention targets and graph structure, demonstrating the robustness of our results (Extended Data Figs. 1–4). We also include three additional baselines from prior works (522, 34, 35) (Supplementary Information G and I) on a ten-node DAG (Extended Data Fig. 5) and an experiment to examine the effect of misspecifying the underlying causal structure (Supplementary Fig. 4 and Extended Data Fig. 6). These results further demonstrate the effectiveness of our proposed method in terms of both accuracy and efficiency.</p>
<h3>Experiments on the biological dataset</h3>
<p>We next study the performance of our method to identify the optimal intervention for inducing a desired cell-state change in human melanoma cells, thereby mimicking a cellular reprogramming experiment. For this, we use Perturb-CITE-sequencing (Perturb–CITE-seq) data from ref. 36 consisting of single-cell transcriptomic readouts for a large collection of patient-derived melanoma cells. Here an intervention is a genetic perturbation that targets one or multiple genes and drives the expression of these genes towards zero (more precisely, these are knockout interventions). Cell states are measured by the joint distribution of the expression of a collection of genes. Samples from these distributions correspond to gene expression vectors of individual melanoma cells. To avoid dealing with batch effects, we use only one of the screens from ref. 36 (namely, the control screen with no additional treatment), which contains 5,039 cells with no perturbation and 30,486 cells with interventions on subsets of 248 genes associated with immunotherapy resistance (Supplementary Fig. 5). Gene expression of each sampled cell is captured as a vector of log-transformed transcripts per million.</p>
<p>For our optimal intervention design task, we focused on a particular functional context, namely, the <em>p</em> = 36 genes among the 248 interventional targets that are involved in interferon-γ signalling and immune response (Supplementary Information H). As multi-target interventional samples are extremely scarce in this dataset, with most such interventions having no more than one sample (Supplementary Fig. 6), we only consider single-target interventions. We use the observational samples, that is, the cells with no perturbation, to learn a DAG over these 36 genes (Methods, Supplementary Fig. 7 and Extended Data Fig. 7). We model each of the 36 single-target interventions as a down-shift of the target gene by its observational mean; that is, knocking out target gene <em>i</em> ∈ [<em>p</em>] is modelled as a shift intervention <strong>a</strong> with <em>a</em><sup><em>i</em></sup> being the negative of the observed mean of this gene, and all other entries being zero. This model assumes that the perturbations are effective at knocking out their target genes. This assumption is not always met by current technologies: we observe that some interventions do not downregulate their target genes in a statistically significant manner (Supplementary Information H). However, this is only known after performing the experiments, and thus, we use the idealized model. If another dataset or prescreen (usually on a smaller scale) is available to help determine the effectiveness of an intervention to target a specific gene, then we can easily replace the idealized model with this estimate. As we will show, the idealized model still extracts enough signal for our method to aid in finding good interventions.</p>
<p>To evaluate our approach, we use the observational distribution as the source cell state and a particular single-node interventional distribution as the target cell state. The aim is to identify this single-node intervention or an intervention with similar effect using the least number of samples. For benchmarking purposes, we use a setting in which the optimal intervention is contained in the feasible set of interventions, but we note that this is not a requirement and the target cell state can be any desired distribution, the experimental design goal then being to identify an intervention that moves the distribution as close as possible to the target distribution.</p>
<p>Figure 6a shows three representative examples of interventional distributions (targeting <em>CDH19</em>, <em>SOX4</em> and <em>HLA-C</em>), visualized using a 2D projection along the most variable directions obtained using contrastive principal component analysis (PCA) (Methods). These examples highlight that the alterations induced by single-target interventions are subtle (Supplementary Fig. 8), with <em>SOX4</em> being more similar to <em>CDH19</em> than <em>HLA-C</em> as also corroborated by the squared distance between the interventional means (Fig. 6b). This observation is consistent with previous melanoma studies showing that <em>HLA-C</em> is associated with positive immune response (37), whereas <em>CDH19</em> and <em>SOX4</em> are associated with metastasis and immune evasion (38, 39). Figure 6c shows the performance of our results with the optimal intervention targeting gene <em>CDH19</em>. More examples using other target genes are given in Supplementary Information H. Each method is run 50 times, in which each run starts with a warm-up set of 100 observational samples and then <em>n</em> = 10 interventional samples per time step. In Fig. 6c, we present the comparison between three acquisition functions: CIV and the two baselines random and greedy. More implementation details as well as the full results are given in Extended Data Figs. 8–10. Similar to what we observed in the synthetic data experiments, CIV outperforms the benchmarks in terms of distance to target mean across all time steps. This suggests that the proposed approach is beneficial for identifying perturbations to induce a desired cell-state change.</p>
<h3>Discussion</h3>
<p>In this work, we developed an active learning framework for optimal intervention design in causal models. Our method has two main ingredients: (1) modelling and updating the edge weights in the causal model using a Bayesian approach (using the DAG–Bayesian linear regression (BLR) distribution) and (2) optimizing the next intervention from which to obtain samples using a class of causally aware acquisition functions (CIV acquisition functions). The DAG–BLR distribution respects the underlying causal structure and allows for efficient posterior updates. The proposed CIV class of acquisition functions prioritizes the most informative intervention with respect to identifying the optimal intervention for moving the system towards a desired mean by minimizing an uncertainty quantity weighted based on the directions of interest. Importantly, the designed CIV acquisition function allows for efficient optimization by having tractable closed-form evaluations. In addition, we showed that the introduced acquisition function is characterized by attractive theoretical properties, such as by mutual information bounds and consistency. Finally, we demonstrated the developed active learning framework on both synthetic data and a biological dataset. In both cases, the designed acquisition function outperforms empirical analogues, allowing for accurate predictions with fewer experiments.</p>
<p>We made various assumptions that may be limiting for some applications and motivate future research directions. First, we focused on</p>
<p><img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p><strong>Fig. 5 | Comparison of different acquisition functions (random baseline, greedy baseline, MaxV baseline, CV baseline and our proposed CIV and CIV-OW) in a simulation study. a, b.</strong> Simulations on 10 instances of a 30-node DAG in which the optimal intervention <strong>a</strong><em> has 10 targets. Each method is run 20 times and averaged. </em><em>a</em><em>, Relative distance between the target mean </em><em>ρ</em><em> and the best approximation </em><em>μ</em><em> across time step </em>t*. Lines denote the mean over the ten</p>
<p><img alt="img-6.jpeg" src="img-6.jpeg" /></p>
<p><strong>Fig. 6 | Results on perturbational single-cell gene expression dataset. a</strong>, Kernel density estimate plot of the two-dimensional projection of the interventional distributions obtained by targeting three representative genes: <em>CDH19</em>, <em>SOX4</em> and <em>HLA-C</em>. Colors indicate the density of the interventional</p>
<p>the setting with known causal structure. An important future research direction is to consider the case in which the causal structure is partially or entirely unknown. We discuss potential avenues to approach this</p>
<p><strong>b</strong> This is a case study where the best approach is to identify the most important features of the network. The best approach is to identify the most important features of the network that are most likely to be present in the network. The best approach is to identify the most important features of the network that are most likely to be present in the network that are not present in the network.</p>
<p><strong>c</strong> This is a case study where the best approach is to identify the most important features of the network that are most likely to be present in the network that are not present in the network. The best approach is to identify the most important features of the network that are most likely to be present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present in the network that are not present</p>
<p>over the feature space. Similar derivations to our work could be used to evaluate or approximate the CIV acquisition functions in this setting. Third, in our model, we assumed 'causal sufficiency'^{25}, which excludes the existence of latent confounders as well as the possibility of performing interventions only on some nodes. This is violated when some system variables are unobserved and thus cannot be intervened on or specified in the desired state. A possible approach is to use a more agnostic model between interventions and their effects as proposed, for example, in ref. 12; however, this will generally lead to weaker results and a loss of structural information.</p>
<p>Although we discussed our work in the context of applications to cellular reprogramming, we envision our framework to be applicable broadly for sequential design problems arising in complex systems. In Supplementary Information J, we discuss several other applications and how they fit into our proposed framework.</p>
<h2>Methods</h2>
<h3>Posterior update of edge weights</h3>
<p>The current dataset <em>D</em><sup><em>i</em></sup> induces a belief on the model parameters <em>B</em>. We consider the Bayesian setting in which the belief corresponds to a distribution. To account for the known causal structure, we assume a generalization of the DAG--Wishart distribution^{28,29}, which places a prior on <em>B</em> that respects the causal structure and allows for efficient posterior updates (Supplementary Information A). The prior is as follows.</p>
<p><strong>Definition 2.</strong> The DAG--BLR prior models <em>B</em> and the noise variances <em>Σ</em> jointly as <em>P</em>(<em>B</em>, <em>Σ</em>) = ∏_{<em>i</em> = 1}^{<em>p</em>} <em>P</em>(<em>B</em><sub><em>i</em></sub>(<em>α</em>(<em>i</em>), <em>σ</em><sub><em>i</em></sub><sup><em>p</em></sup>), where each <em>P</em>(<em>B</em><sub><em>i</em></sub>(<em>α</em>(<em>i</em>), <em>σ</em><sub><em>i</em></sub><sup><em>p</em></sup>)) is</p>
<p>$$
\sigma_{i}^{2} \sim \mathcal{Эg}(\alpha_i, \beta_i),
$$</p>
<p>$$
B_{i,\text{pa}(i)} | \sigma_{i}^{2} \sim \mathcal{N}(m_i, \sigma_{i}^{2} M_i).
$$</p>
<p>Here <em>Эg</em> denotes the inverse-gamma distribution and {<em>α</em><sub><em>i</em></sub>, <em>β</em><sub><em>i</em></sub>, <em>m</em><sub><em>i</em></sub>, <em>M</em><sub><em>i</em></sub>|<em>i</em><sub><em>i</em>+1</sub><sup><em>p</em></sup> are hyperparameters satisfying certain constraints specified in Supplementary Information A.</p>
<p>This prior is consistent with the DAG structure as it sets <em>B</em><sub><em>i</em><em>t</em></sub> = 0 for all <em>k</em> ∈ pa(<em>i</em>). Although it was developed in the observational setting^{40}, the following lemma shows that it can be extended to the interventional setting and is a conjugate prior for the model in equation (2). Thus, the posterior lies in the same family of distributions.</p>
<p><strong>Lemma 1.</strong> The posterior corresponding to the DAG--BLR prior satisfies <em>P</em>(<em>B</em>, <em>Σ</em>|<em>D</em><sub><em>i</em></sub>) = ∏_{<em>i</em> = 1}^{<em>p</em>} <em>P</em>(<em>B</em><sub><em>i</em></sub>(<em>α</em>(<em>i</em>), <em>σ</em><sub><em>i</em></sub><sup><em>p</em></sup>|<em>D</em><sub><em>i</em></sub>), where <em>P</em>(<em>B</em><sub><em>i</em></sub>(<em>α</em>(<em>i</em>), <em>σ</em><sub><em>i</em></sub><sup><em>p</em></sup>|<em>D</em><sub><em>i</em></sub>) is</p>
<p>$$
\sigma_{i}^{2} | \mathcal{D} \sim \mathcal{Эg}\left(\alpha_i \mathcal{D} \mathcal{D} \right), \beta_i \mathcal{D} \mathcal{D} \right),
$$</p>
<p>$$
B_{i,\text{pa}(i)} | \sigma_{i}^{2}, \mathcal{D} \sim \mathcal{N}\left(m_i \mathcal{D} \mathcal{D} \right), \sigma_{i}^{2} M_i \mathcal{D} \right).
$$</p>
<p>The hyperparameters {<em>α</em>i<sub><em>i</em></sub>(<em>D</em><sub><em>i</em></sub>), <em>β</em>i<sub><em>i</em></sub>(<em>D</em><sub><em>i</em></sub>), <em>m</em>i<sub><em>i</em></sub>(<em>D</em><sub><em>i</em></sub>), <em>M</em>i<sub><em>i</em></sub>(<em>D</em><sub><em>i</em></sub>)|<em>i</em><sub><em>i</em>+1</sub><sup><em>p</em></sup> are specified in Supplementary Information A.</p>
<p>The hyperparameters {<em>α</em>i<sub><em>i</em></sub>(<em>D</em><sub><em>i</em></sub>), <em>β</em>i<sub><em>i</em></sub>(<em>D</em><sub><em>i</em></sub>), <em>m</em>i<sub><em>i</em></sub>(<em>D</em><sub><em>i</em></sub>), <em>M</em>i<sub><em>i</em></sub>(<em>D</em><sub><em>i</em></sub>)|<em>i</em><sub><em>i</em>+1</sub><sup><em>p</em></sup> can be updated easily using the new samples obtained at step <em>t</em>; thus, this choice of a 'conjugate' prior allows for efficient posterior updates.</p>
<p>We make one comment about the DAG--Wishart distribution. In previous literature^{28,29}, this distribution has been extended to model the posterior beliefs of both the edge weights and the DAG structure. The posterior for the DAG structure is known as the Bayesian Gaussian equivalence score. Thus, although we here assume that the DAG is known or prefixed and we only update the posterior on the non-zero entries of <em>B</em>, our framework can be extended to the unknown DAG setting by placing a probability on the DAG structure using the Bayesian Gaussian equivalence score, as discussed in Supplementary Information D.</p>
<h3>Evaluation of CIV in closed form</h3>
<p>We discuss how to optimize CIV to solve for <strong>a</strong>^{<em>i</em> + 1<em>i</em>}. We start by providing a closed form of the variance <em>σ</em><sub><em>g</em><sub><em>i</em></sub>(<strong>a</strong>)|<em>D</em><sub><em>i</em></sub>(<strong>a</strong>')<sup><em>i</em></sup>. For ease of reading, we here provide the formula for the special case in which the exogenous noise variances <em>Σ</em> are known. The general formula, which is similar in flavour but more complicated, including the proof is given in Supplementary Information B.</p>
<p><strong>Proposition 1.</strong> Conditioning on <em>Σ</em>, we have</p>
<p>$$
\sigma_{g(\mathbf{a})| \mathcal{D} \mathcal{i}(\mathbf{a})'}^{2} = \mathcal{I} \sum_{i=1}^{p} \left( v_i^2 + \frac{2}{n} v_i \sigma_i^2 + 2 v_i (a_i - b_i)^2 \right) + c, \tag{12}
$$</p>
<p>where only <em>v</em><sub><em>i</em></sub> := <em>σ</em><sub><em>i</em></sub><sup><em>p</em></sup> <em>μ</em><sub><em>p</em><sub><em>i</em></sub>(<em>i</em>)<em>M</em><sub><em>i</em></sub>(<em>D</em><sub><em>i</em></sub>(<strong>a</strong>'))<em>μ</em><sub><em>p</em><sub><em>i</em></sub>(<em>i</em>)</sub> depends on the augmented dataset <em>D</em><sub><em>i</em></sub>(<strong>a</strong>'), whereas <em>b</em><sub><em>i</em></sub> := <em>μ</em><sub><em>i</em></sub><sup><em>i</em></sup> - <em>m</em><sub><em>i</em></sub>(<em>D</em><sub><em>i</em></sub>)<sup><em>i</em></sup><em> </em>μ<em><sub></em>p<em><sub></em>i<em></sub>(</em>i<em>)</sub> and the constant </em>c<em> do not depend on </em><em>a</em>*'.</p>
<p>We note that the resulting expression is a function of <em>b</em><sub><em>i</em></sub> and <em>v</em><sub><em>i</em></sub>, which can be interpreted as follows: Lemma 1 can be used to rewrite <em>b</em><sub><em>i</em></sub> = {(<em>I</em> - <em>Σ</em>(<em>B</em>|<em>D</em><sub><em>i</em></sub>))<strong>μ</strong><sub><em>i</em></sub><sup><em>i</em></sup>}, as the estimated shift of the optimal intervention at node <em>i</em>, and <em>v</em><sub><em>i</em></sub> = <em>μ</em><sub><em>p</em><sub><em>i</em></sub>(<em>i</em>)<em>Var</em>(<em>B</em><sub><em>i</em></sub>(<em>α</em>(<em>i</em>) | <em>D</em><sub><em>i</em></sub>(<strong>a</strong>'))<em>μ</em><sub><em>p</em><sub><em>i</em></sub>(<em>i</em>)</sub> as the covariance matrix of <em>B</em><sub><em>i</em></sub>(<em>α</em>(<em>i</em>) scaled in the direction of the target mean <strong>μ</strong><sub><em>i</em></sub>.</p>
<p>Next, we discuss how to integrate equation (12) over the space of possible interventions <em>A</em> to evaluate <em>h</em>(<strong>a</strong>', <em>D</em><sub><em>i</em></sub>). Here we consider <em>A</em> to be the hypersphere <em>S</em><sup><em>p</em><sub><em>i</em></sub>1</sup> = {<strong>a</strong> ∈ <em>W</em><sup><em>p</em></sup> : | |<strong>a</strong>|<sub><em>i</em></sub>2 = 1} and <em>v</em> to be the uniform measure on the hypersphere (other types of feasible sets <em>A</em>, for example, with sparsity constraints, can be considered, and similar derivations can be used to identify if a closed-form integration exists). This corresponds to fixing the magnitude of the intervention and only optimizing over its direction. This is suitable for various applications including the biological problem considered below, as the strength of the intervention is often designed separately or prefixed manually by the experimenter. We also note that for many linear problems, the uncertainty is decreased by making the magnitude of the selected point larger^{32}. We show in Supplementary Information B that this is the case also for the problem considered in this paper. Considering the hypersphere allows us to avoid this ambiguity. The following proposition provides the resulting formula when <em>Σ</em> is known; see Supplementary Information B for the general case including the proof.</p>
<p><strong>Proposition 2.</strong> For <em>A</em> = <em>S</em><sup><em>p</em><sub><em>i</em></sub>1</sub> and <em>v</em> being a uniform measure, the CIV acquisition function evaluated at <strong>a</strong>', conditioned on <em>Σ</em>, is</p>
<p>$$
h(\mathbf{a}' , \mathcal{D} \mathcal{i}) = c_1 \sum_{i=1}^{p} \left( v_i^2 + 2 v_i \left(\frac{\sigma_i^2}{n} + b_i^2 + \frac{1}{p}\right)\right) + c_2, \tag{13}
$$</p>
<p>where <em>c</em><sub><em>i</em></sub> &gt; 0 and <em>c</em><sub><em>i</em></sub> are constants that do not depend on <strong>a</strong>'.</p>
<p>The gradient of this objective function can be calculated explicitly also in the general case when <em>Σ</em> is unknown, and thus, we can use gradient-based optimization methods with a ball constraint to solve for <strong>a</strong>^{<em>i</em> + 1<em>i</em>} = argmin<sub><strong>a</strong>'<em>i</em>∈<em>S</em><sup><em>p</em></sup>1</sup> } ∑<sub><em>i</em>=1</sub><sup><em>p</em></sup> (<em>v</em><sub><em>i</em></sub><sup><em>p</em></sup> + 2<em>v</em><sub><em>i</em></sub>(<em>i</em><sub><em>i</em></sub><sup><em>p</em></sup> + <em>b</em><sub><em>i</em></sub><sup><em>p</em></sup> + <em>c</em><sub><em>p</em></sub>)) (see the section Implementations below for details). For other types of feasible sets <em>A</em>, for example, with sparsity constraints or consisting of hard interventions, the appropriate optimization method needs to be adjusted accordingly. We also note that the objective function is not necessarily convex (Supplementary Information B), and gradient-based optimizers may therefore only find a local minimum.</p>
<h3>Mutual information bound</h3>
<p>To provide an information-theoretic interpretation of the CIV acquisition function, we use the 'relative decay' of the uncertainty <em>σ</em><sub><em>g</em><sub><em>i</em></sub>(<strong>a</strong>)|<em>D</em><sub><em>i</em></sub> measured by</p>
<p>$$
\frac{\sigma_{g(\mathbf{a})| \mathcal{D} \mathcal{i}^2}^{2} - \varepsilon_{\mathbf{a}'} \cdot \left(\sigma_{g(\mathbf{a})| \mathcal{D} \mathcal{i}^2}^{2} \mathcal{i}(\mathbf{a}' \cdot \mathbf{a}')\right)}{\sigma_{g(\mathbf{a})| \mathcal{D} \mathcal{i}^2}^{2}}, \tag{14}
$$</p>
<p>where the expectation <em>ε</em><sub><strong>a</strong></sub> is taken with respect to a new sample <strong>x</strong> from <strong>a</strong>' whose distribution is given by <em>P</em>(<strong>x</strong>'|<em>D</em><sub><em>i</em></sub>, <strong>a</strong>'). To simplify the notation, we restrict the discussion in this section to the case of <em>n</em> = 1. Similar</p>
<p>results can easily be derived for sample sizes $n&gt;1$. The following theorem shows that the mutual information between $g(\mathbf{a})$ and a sample $\mathbf{x}^{\prime}$ from $\mathbf{a}^{\prime}$ can be lower bounded by this relative decay up to a multiplicative factor. The proof can be found in Supplementary Information E.
Theorem 1. Conditioning on $\mathcal{D}_{t}$, the following inequality holds for any $\mathbf{a} \in \mathcal{A}$ for the mutual information between $g(\mathbf{a})$ and a sample $\mathbf{x}^{\prime}$ from $P^{\mathbf{a}^{\prime}}$ :</p>
<p>$$
I(g(\mathbf{a}) ; \mathbf{x}^{\prime} \mid \mathbf{a}^{\prime}, \mathcal{D}<em g_mathbf_a="g(\mathbf{a">{t}) \geq \rho^{2} \cdot \frac{\sigma</em>}) \mid \mathcal{D<em _mathbf_x="\mathbf{x">{t}}^{2}-\mathbb{E}</em>}^{\prime}}\left(\sigma_{g(\mathbf{a}) \mid \mathcal{D<em g_mathbf_a="g(\mathbf{a">{t} ; c(\mathbf{x}^{\prime}, \mathbf{a})^{\prime}}\right)}{\sigma</em>
$$}) \mid \mathcal{D}_{t}}^{2}</p>
<p>where $\rho^{2}$ is a constant that does not depend on $\mathbf{a}^{\prime}$.
This result holds in general for any function $g(\mathbf{a})$ and its posterior modelling on $\mathcal{D}_{t}$, but the constant $\rho$ in the bound depends on the specific choice of $g$ and its posterior modelling. For example, for the prominent BLR task, Theorem 1 holds with $\rho^{2}=1 / 2$ (Supplementary Information E).</p>
<p>Note that as $\sigma_{g(\mathbf{a}) \mid \mathcal{D}<em _mathbf_x="\mathbf{x">{t}}^{2}$ does not depend on $\mathbf{a}^{\prime} \in \mathcal{A}$, minimizing the uncertainty $\mathbb{E}</em>}^{\prime}}\left(\sigma_{g(\mathbf{a}) \mid \mathcal{D<em g_mathbf_a="g(\mathbf{a">{t} ; c(\mathbf{x}^{\prime}, \mathbf{a})^{\prime}}\right)$ is equivalent to maximizing its relative decay in equation (14). The uncertainty $\sigma</em>}) \mid \mathcal{D<em _mathbf_x="\mathbf{x">{t}(\mathbf{a})^{\prime}}^{2}$ used by the CIV acquisition function (equation 7) is a computationally efficient estimator of $\mathbb{E}</em>}^{\prime}}\left(\sigma_{g(\mathbf{a}) \mid \mathcal{D<em t="t">{t} ; c(\mathbf{x}^{\prime}, \mathbf{a})^{\prime}}\right)$ in the relative decay (equation 14), where the expectation with respect to $\mathbf{x}^{\prime} \sim \mathcal{D}\left(\mathbf{x}^{\prime} \mid \mathcal{D}</em>$ such that the information gain measured by the entropy decay}, \mathbf{a}^{\prime}\right)$ is replaced by a plug-in estimator $\hat{\mathbf{x}}^{\prime}=\mathbb{E}\left(\mathbf{x}^{\prime} \mid \mathcal{D}_{t}, \mathbf{a}^{\prime}\right)$. It follows from Theorem 1 that minimizing the integrated variance in equation (7) corresponds to selecting an intervention that maximizes a lower bound on the mutual information between the resulting samples and $g(\mathbf{a})$. This perspective shows how the CIV acquisition function connects to a prominent line of previous works, known as Bayesian active learning by disagreement (BALD) ${ }^{3,5,41}$, in which the idea is to select interventions that maximize the information gain at each step. For example, if the quantity of interest is $g(\mathbf{a})$, then BALD seeks to find $\mathbf{a}^{\prime</p>
<p>$$
H(g(\mathbf{a}) \mid \mathcal{D}<em t="t">{t})-H(g(\mathbf{a}) \mid \mathcal{D}</em>\right))
$$} \cup\left(\mathbf{x}^{\prime}, \mathbf{a}^{\prime</p>
<p>is maximized. Note that this term equals $I(g(\mathbf{a}) ; \mathbf{x}^{\prime} \mid \mathbf{a}^{\prime}, \mathcal{D}_{t})$. As a consequence, BALD directly operates on the mutual information, which involves high-dimensional moments of the random variable $g(\mathbf{a})$. This highlights an important drawback of BALD, namely, that it is generally computationally difficult to evaluate and often requires approximation techniques such as Markov chain Monte Carlo ${ }^{9}$. By contrast, our CIV acquisition function only depends on the first and the second moments of $g(\mathbf{a})$, thereby allowing for direct computation and efficient optimization.</p>
<h2>Consistency of CIV for identifying the optimal intervention</h2>
<p>We now provide a graphical interpretation of the proposed CIV acquisition function. For simplicity, we restrict our discussion to the expression developed in Proposition 2 for the case of uniform measure and known variances. The general setting is discussed in Supplementary Information F. As $c_{t}, c_{2}$ in Proposition 2 are constants that do not depend on $\mathbf{a}^{\prime}$, the new intervention is obtained by minimizing $\sum_{i=1}^{p}\left(v_{i}^{2}+2 v_{i}\left(\frac{\partial_{i}^{2}}{n}+b_{i}^{2}+\frac{1}{p}\right)\right)$; with a slight abuse of notation, let</p>
<p>$$
h\left(\mathbf{a}^{\prime}, \mathcal{D}<em i="1">{t}\right)=\sum</em>\right)\right)
$$}^{p}\left(v_{i}^{2}+2 v_{i}\left(\frac{\partial_{i}^{2}}{n}+b_{i}^{2}+\frac{1}{p</p>
<p>The term $v_{i}=p_{\text {pa }(i)}^{<em>} \operatorname{Var}\left(B_{(\text {pa }(i)} \mid \mathcal{D}<em _pa="{pa" _text="\text">{t}\left(\mathbf{a}^{\prime}\right)\right) \mu</em>^{}(i)</em>}$ can be understood as the epistemic uncertainty of node $i$ in the direction of interest, namely, as $x_{i}=B_{(\text {pa }(i)}^{<em>} x_{\text {pa }(i)}+\epsilon_{i}$, the variance of $B_{(\text {pa }(i)}$ characterizes the epistemic uncertainty of estimating $x_{i}$ using its parent nodes; in $v_{i}$, this uncertainty, presented as a covariance matrix, is transformed into a scalar value by scaling it in the direction of the target mean $\boldsymbol{\mu}^{</em>}$. As the number
of time steps $t$ increases, one can show (Supplementary Information E) using the Bernstein--von Mises theorem ${ }^{31}$ that $v_{i}=O(1 / t)$, which implies that the second-order terms $v_{i}^{2}$ are dominated by the first-order terms in equation (17). Note that their coefficients $v_{i}^{2} / n+b_{i}^{2}+1 / p$ are larger for nodes $i$ with larger noise variances and larger estimated optimal shift values $b_{i}=\left[\left(I-\mathbb{E}\left(B \mid \mathcal{D}<em t="t">{t}\right) \mid \boldsymbol{\mu}^{<em>}\right)\right]$. This scaling is intuitive, as it puts emphasis on reducing the variance of nodes in which there is still a high uncertainty (given by $\sigma_{i}^{2}$ ) or that require high shift values (estimated by $b_{i}^{2}$ ). As we show in the following theorem, the combined effect of these terms on acquiring new interventions is that $\mathbf{a}^{</em>}$ will become an approximate local minimizer of equation (17) as $t$ increases as shown in the following theorem, in which we use the conventional asymptotic notation, $o, O$ and $\Theta$, with respect to the time step $t$.
Theorem 2. For all $\mathbf{a}^{\prime} \in \mathcal{A}$, the CIV acquisition function either decays linearly with respect to $t$, that is, $h\left(\mathbf{a}^{\prime}, \mathcal{D}</em>}\right)=\Theta(1 / t)$, or degenerates to the constant zero, that is, $h\left(\mathbf{a}^{\prime}, \mathcal{D<em t="t">{t}\right) \equiv 0$. The optimal intervention $\mathbf{a}^{<em>}$ satisfies $\left|\nabla h\left(\mathbf{a}^{</em>}, \mathcal{D}</em>\right)\right|<em t="t">{2}=O\left(1 / t^{2}\right)$ and $\nabla^{2} h\left(\mathbf{a}^{*}, \mathcal{D}</em>\right) I$.}\right) \geqslant-O\left(1 / t^{2</p>
<p>This theorem shows that as $t$ increases, the gradient at $\mathbf{a}^{<em>}$ vanishes to zero faster than the acquisition function and the Hessian becomes almost positive semi-definite. This suggests that gradient-based optimizers with an initialization close enough to $\mathbf{a}^{</em>}$ converge to the optimal intervention $\mathbf{a}^{*}$ as $t \rightarrow \infty$. In experiments, we observe this to hold even for a moderate number of time steps $t$ as illustrated for a ten-node DAG example in Fig. 4. The proof of Theorem 2 can be found in Supplementary Information F.</p>
<h2>Implementations</h2>
<p>Optimization of the acquisition functions was performed using a gradient-based solver, more precisely, sequential least squares programming with the nonlinear constraint $\left|\mathbf{a}^{(0)}\right|<em 2="2">{2} \leq 1$. As proven in Supplementary Information B, optimizing the proposed acquisition functions with this constraint always outputs a feasible $\mathbf{a}^{(0)}$ such that $\left|\mathbf{a}^{(0)}\right|</em>$.}=1$. For other types of feasible sets, for example, $\mathbf{a}^{(0)} \in[0,1]^{p}$, one can use other solvers such as limited-memory Broyden--Fletcher-Goldfarb--Shanno with box constraints. Sequential least squares programming was implemented using the SciPy package ${ }^{42}$ and initialized in two ways: (1) using the intervention $\mathbf{a}^{(0-1)}$ that was selected in the previous time step and (2) using the current estimate $\left(I-\mathbb{E}\left(B \mid \mathcal{D}_{t}\right) \mid \boldsymbol{\mu}^{*}\right.$ of the optimal intervention. Of the two resulting solutions, we used the one with the better acquisition function value as $\mathbf{a}^{(0)</p>
<p>For the experiments on synthetic data, we generated the DAGs using the NetworkX package ${ }^{43}$ and the CausalDAG package ${ }^{44}$. We used different graph types and sizes, as detailed in Supplementary Information G. The edge weights were uniformly sampled from $[-1,-0.25] \cup[0.25,1]$ to ensure that the parameters were bounded away from zero. The exogenous noise levels were set to 1 , and the resulting linear Gaussian SCM was then rescaled with our implementation of the standardized model as described in Appendix F of ref. 45. For the DAG--BLR prior (equation 10), we set the edge-weight-related hyperparameters as follows: $m_{i}=0$ and $M_{i}$ equal to the identity matrix for all $i \in[p]$. We assumed the variances to be known and used the known-variance formula.</p>
<p>The transcriptomic dataset analysed in the biological application was processed using the Scanpy package ${ }^{46}$. The kernel density estimate plots shown in Fig. 6a share the same coordinate axes and were produced by projecting the high-dimensional dataset along the first two principal components obtained using contrastive PCA ${ }^{47}$, with the unperturbed samples as 'background' and all interventional samples as 'foreground'. The purpose of contrastive PCA is to identify low-dimensional structures in a foreground dataset relative to a background dataset. The greedy sparsest permutation algorithm ${ }^{48}$ was used to learn the DAG structure from the unperturbed data. The parameters used in the greedy sparsest permutation are given in Supplementary Information H and Fig. 7. For the DAG--BLR prior, we set the hyperparameters as follows: $m_{i}=0, M_{i}$ equal to the identity matrix,</p>
<p>$\alpha_{i}=2$ and $\beta_{i}=0$. These hyperparameters were then updated using posterior formula I based on 100 samples from the unperturbed data. Similar warm-up steps are used in the active learning literature ${ }^{135}$. As we usually have access to some observational samples in applications of optimal intervention design, we recommend using these to obtain dataset-informed hyperparameters of the DAG-BLR prior. After this warm-up step using unperturbed data, interventions were acquired based on the known-variance formula, in which we used the estimated mean of the noise variances as a proxy.</p>
<p>The codebase for updating the model posterior and optimizing the causally aware acquisition functions proposed in this work can be obtained via refs. 49. We also provide a notebook to extract and process the Perturb-CITE-seq data from ref. 36. Our codebase can be used to replicate all the main results and figures as well as for other user-defined applications. All methods can be run efficiently on a CPU for a moderate number of variables.</p>
<h2>Data availability</h2>
<p>The Perturb-CITE-seq ${ }^{36}$ data can be obtained from https://doi. org/10.1038/s41588-021-00779-1.</p>
<h2>Code availability</h2>
<p>All code has been deposited at ref. 49.</p>
<h2>References</h2>
<ol>
<li>Cherry, A. B. \&amp; Daley, G. Q. Reprogramming cellular identity for regenerative medicine. Cell 148, 1110-1122 (2012).</li>
<li>Todorov, E. \&amp; Jordan, M. I. Optimal feedback control as a theory of motor coordination. Nat. Neurosci. 5, 1226-1235 (2002).</li>
<li>Blanchard, A. B. et al. Bayesian optimization for active flow control. Acta Mech. Sin. 37, 1786-1798 (2021).</li>
<li>Sunar, N., Birge, J. R. \&amp; Vitavasiri, S. Optimal dynamic product development and launch for a network of customers. Oper. Res. 67, 770-790 (2019).</li>
<li>Serrao-Neumann, S., Di Giulio, G. M., Ferreira, L. C. \&amp; Choy, D. L. Climate change adaptation: is there a role for intervention research? Futures 53, 86-97 (2013).</li>
<li>Fu, Y., Zhu, X. \&amp; Li, B. A survey on instance selection for active learning. Knowl. Inf. Syst. 35, 249-283 (2013).</li>
<li>Jesson, A. et al. Causal-BALD: deep Bayesian active learning of outcomes to infer treatment-effects from observational data. In Adv. Neural Information Processing Systems Vol. 34, 3046530478 (NeurIPS, 2021).</li>
<li>Cohn, D. A., Ghahramani, Z. \&amp; Jordan, M. I. Active learning with statistical models. J. Artif. Intell. Res. 4, 129-145 (1996).</li>
<li>Houlsby, N., Huszár, F., Ghahramani, Z. \&amp; Lengyel, M. Bayesian active learning for classification and preference learning. Preprint at arXiv https://doi.org/10.48550/arXiv.1112.5745 (2011).</li>
<li>Lattimore, F., Lattimore, T. \&amp; Reid, M. D. Causal bandits: learning good interventions via causal inference. In Adv. Neural Information Processing Systems Vol. 29 (2016).</li>
<li>Lee, S. \&amp; Bareinboim, E. Structural causal bandits: where to intervene? In Adv. Neural Information Processing Systems Vol. 31 (2018).</li>
<li>Aglietti, V., Lu, X., Paleyes, A. \&amp; González, J. Causal Bayesian optimization. In Int. Conf. Artificial Intelligence and Statistics 3155-3164 (PMLR, 2020).</li>
<li>Alabed, S. \&amp; Yoneki, E. BoGraph: structured Bayesian optimization from logs for expensive systems with many parameters. In Proc. 2nd European Workshop on Machine Learning and Systems 45-53 (2022).</li>
<li>Branchini, N., Aglietti, V., Dhir, N. \&amp; Damoulas, T. Causal entropy optimization. In Int. Conf. on Artificial Intelligence and Statistics 8586-8605 (PMLR, 2023).</li>
<li>Cahan, P. et al. CellNet: network biology applied to stem cell engineering. Cell 158, 903-915 (2014).</li>
<li>Kemmeren, P. et al. Large-scale genetic perturbations reveal regulatory networks and an abundance of gene-specific repressors. Cell 157, 740-752 (2014).</li>
<li>Spirtes, P., Glymour, C. N., Scheines, R. \&amp; Heckerman, D. Causation, Prediction, and Search (MIT Press, 2000).</li>
<li>Pearl, J. Causality (Cambridge Univ. Press, 2009).</li>
<li>Rothenhäusler, D., Heinze, C., Peters, J. \&amp; Meinshausen, N. Backshift: learning causal cyclic graphs from unknown shift interventions. In Adv. Neural Information Processing Systems Vol. 28 (2015).</li>
<li>Zhang, J., Squires, C. \&amp; Uhler, C. Matching a desired causal state via shift interventions. In Adv. Neural Information Processing Systems Vol. 34 (2021).</li>
<li>Eberhardt, F. \&amp; Scheines, R. Interventions and causal inference. Philos. Sci. 74, 981-995 (2007).</li>
<li>Shalem, O., Sanjana, N. E. \&amp; Zhang, F. High-throughput functional genomics using CRISPR-Cas9. Nat. Rev. Genet. 16, 299-311 (2015).</li>
<li>Joung, J. et al. A transcription factor atlas of directed differentiation. Cell 186, 209-229 (2023).</li>
<li>Replogle, J. M. et al. Mapping information-rich genotypephenotype landscapes with genome-scale Perturb-seq. Cell 185, 2559-2575 (2022).</li>
<li>Sen, R., Shanmugam, K., Dimakis, A. G. \&amp; Shakkottai, S. Identifying best interventions through online importance sampling. In Int. Conf. Machine Learning 3057-3066 (PMLR, 2017).</li>
<li>Koumoutsakos, P. \&amp; Leonard, A. High-resolution simulations of the flow around an impulsively started cylinder using vortex methods. J. Fluid Mech. 296, 1-38 (1995).</li>
<li>Rackham, O. J. et al. A predictive computational framework for direct reprogramming between human cell types. Nat. Genet. 48, 331-335 (2016).</li>
<li>Geiger, D. \&amp; Heckerman, D. Parameter priors for directed acyclic graphical models and the characterization of several probability distributions. Ann. Stat. 30, 1412-1440 (2002).</li>
<li>Kuipers, J. \&amp; Moffa, G. The interventional Bayesian Gaussian equivalent score for Bayesian causal inference with unknown soft interventions. Preprint at arXiv https://doi.org/10.48550/ arXiv.2205.02602 (2022).</li>
<li>Kuipers, J., Moffa, G. \&amp; Heckerman, D. Addendum on the scoring of Gaussian directed acyclic graphical models. Ann. Statist. 42, 1689-1691 (2014).</li>
<li>Kleijn, B. J. \&amp; van der Vaart, A. W. The Bernstein-von-Mises theorem under misspecification. Electron. J. Stat. 6, 354-381 (2012).</li>
<li>Sapsis, T. P. Output-weighted optimal sampling for Bayesian regression and rare event statistics using few samples. Proc. R. Soc. A 476, 20190834 (2020).</li>
<li>Mohamad, M. A. \&amp; Sapsis, T. P. Sequential sampling strategy for extreme event statistics in nonlinear dynamical systems. Proc. Natl Acad. Sci. USA 115, 11138-11143 (2018).</li>
<li>Astudillo, R. \&amp; Frazier, P. Bayesian optimization of function networks. In Adv. Neural Information Processing Systems Vol. 34, 14463-14475 (NeurIPS, 2021).</li>
<li>Bubeck, S. et al. Regret analysis of stochastic and nonstochastic multi-armed bandit problems. Found. Trends Mach. Learn. 5, 1-122 (2012).</li>
<li>Frangieh, C. J. et al. Multimodal pooled Perturb-CITE-seq screens in patient models define mechanisms of cancer immune evasion. Nat. Genet. 53, 332-341 (2021).</li>
<li>Carretero, R. et al. Analysis of HLA class I expression in progressing and regressing metastatic melanoma lesions after immunotherapy. Immunogenetics 60, 439-447 (2008).</li>
<li>
<p>Jaeger, J. et al. Gene expression signatures for tumor progression, tumor subtype, and tumor thickness in laser-microdissected melanoma tissues. Clin. Cancer Res. 13, 806-815 (2007).</p>
</li>
<li>
<p>Cheng, Q. et al. SOX4 promotes melanoma cell migration and invasion though the activation of the NF-кB signaling pathway. Int. J. Mol. Med. 40, 447-453 (2017).</p>
</li>
<li>Cao, X., Khare, K. \&amp; Ghosh, M. Posterior graph selection and estimation consistency for high-dimensional Bayesian DAG models. Ann. Stat. 47, 319-348 (2019).</li>
<li>Kirsch, A., Van Amersfoort, J. \&amp; Gal, Y. BatchBALD: efficient and diverse batch acquisition for deep Bayesian active learning. In Adv. Neural Information Processing Systems Vol. 32 (2019).</li>
<li>Virtanen, P. et al. SciPy 1.0: fundamental algorithms for scientific computing in Python. Nat. Methods 17, 261-272 (2020).</li>
<li>Hagberg, A., Swart, P. \&amp; Schult, D. A. Exploring Network Structure, Dynamics, and Function Using NetworkX (Los Alamos National Lab, 2008).</li>
<li>Squires, C. CausalDAG: creation, manipulation, and learning of causal models. GitHub https://github.com/uhlerlab/causaldag (2018).</li>
<li>Reisach, A., Seiler, C. \&amp; Weichwald, S. Beware of the simulated DAG! Causal discovery benchmarks may be easy to game. In Adv. Neural Information Processing Systems Vol. 34, 27772-27784 (NeurIPS, 2021).</li>
<li>Wolf, F. A., Angerer, P. \&amp; Theis, F. J. SCANPY: large-scale single-cell gene expression data analysis. Genome Biol. 19, $1-5$ (2018).</li>
<li>Abid, A., Zhang, M. J., Bagaria, V. K. \&amp; Zou, J. Exploring patterns enriched in a dataset with contrastive principal component analysis. Nat. Commun. 9, 1-7 (2018).</li>
<li>Solus, L., Wang, Y. \&amp; Uhler, C. Consistency guarantees for greedy permutation-based causal inference algorithms. Biometrika 108, 795-814 (2021).</li>
<li>Zhang, J. uhlerlab/actlearn_optint: v1, July. Zenodo https://doi.org/ 10.5281/zenodo.8170179 (2023).</li>
</ol>
<h2>Acknowledgements</h2>
<p>J.Z., C.S. and C.U. were partially supported by the National Center for Complementary and Integrative Health at the National Institutes of Health (NCCIH/NIH), the Office of Naval Research (N00014-22-12116), the National Science Foundation (DMS-1651995), the MIT-IBM Watson AI Lab, MIT J-Clinic for Machine Learning and Health, the Eric and Wendy Schmidt Center at the Broad Institute and a Simons Investigator Award to C.U. T.P.S. acknowledges support by the Office of Naval Research (N00014-21-1-2357) and the Air Force Office of</p>
<p>Scientific Research (MURI FA9550-21-1-0058). C.S. was partially supported by an NSF Graduate Fellowship.</p>
<h2>Author contributions</h2>
<p>J.Z., L.C., T.P.S. and C.U. conceived the research and designed the method. J.Z. derived the theoretical results and performed the numerical experiments. L.C. and J.Z. processed the biological data. C.S. and J.Z. derived the extension of the DAG-Wishart distribution. All authors interpreted the results and wrote the paper.</p>
<h2>Competing interests</h2>
<p>The authors declare no competing interests.</p>
<h2>Additional information</h2>
<p>Extended data is available for this paper at https://doi.org/10.1038/s42256-023-00719-0.</p>
<p>Supplementary information The online version contains supplementary material available at https://doi.org/10.1038/s42256-023-00719-0.</p>
<p>Correspondence and requests for materials should be addressed to Themistoklis P. Sapsis or Caroline Uhler.</p>
<p>Peer review information Nature Machine Intelligence thanks Virginia Aglietti and the other, anonymous, reviewer(s) for their contribution to the peer review of this work. Primary Handling Editor: Mirko Pieropan, in collaboration with the Nature Machine Intelligence team.</p>
<p>Reprints and permissions information is available at www.nature.com/reprints.</p>
<p>Publisher's note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
<p>Springer Nature or its licensor (e.g. a society or other partner) holds exclusive rights to this article under a publishing agreement with the author(s) or other rightsholder(s); author self-archiving of the accepted manuscript version of this article is solely governed by the terms of such publishing agreement and applicable law.
(c) The Author(s), under exclusive licence to Springer Nature Limited 2023</p>
<p><img alt="img-7.jpeg" src="img-7.jpeg" /></p>
<p>Extended Data Fig. 1: Comparison of different acquisition functions in a simulation study where the underlying causal graph is the complete graph, half of the nodes are selected at random as intervention targets, and we vary the number of nodes $\boldsymbol{p}$. Each plot corresponds to an average of 10 instances and each method is run 20 times and averaged. (A)-(C) Relative distance between the target mean $\boldsymbol{\mu}^{\prime}$ and the best approximation $\boldsymbol{\mu}<em t="t">{t}^{<em>}$ (defined in Fig. 5A in the main text)
up to time step $t$. Lines denote the mean over 10 instances; the shading corresponds to one standard deviation. (D)-(F) Relative distance statistics of each method averaged over 10 instances at the last time step ( $t=50$ ). (G)-(I) Squared distance presented as mean value $+/-$ SEM between the optimal intervention $\mathbf{a}^{</em>}$ and the best approximation $\mathbf{a}</em>^{<em>}$ that is used to obtain $\boldsymbol{\mu}_{t}^{</em>}$ up to time step $t$.</p>
<p><img alt="img-8.jpeg" src="img-8.jpeg" /></p>
<p>Extended Data Fig. 2: Comparison of different acquisition functions in a simulation study where the underlying causal graph is the complete graph, the most downstream half of the nodes are fixed as intervention targets, and we vary the number of nodes $\boldsymbol{p}$. Each plot corresponds to an average of 10 instances and each method is run 20 times and averaged. (A)-(C) Relative distance between the target mean $\boldsymbol{\mu}^{\prime}$ and the best approximation $\boldsymbol{\mu}_{t}^{*}$ (defined in</p>
<p>Fig. 5A in the main text) up to time step $t$. Lines denote the mean over 10 instances; the shading corresponds to one standard deviation. (D)-(F) Relative distance statistic of each method averaged over 10 instances at the last time step $(t=50)$. (G)-(I) Squared distance presented as mean value $+/-$ SEM between the optimal intervention $\mathbf{a}^{\prime}$ and the best approximation $\mathbf{a}_{t}^{<em>}$ that is used to obtain $\boldsymbol{\mu}_{t}^{</em>}$ up to time step $t$.</p>
<p><img alt="img-9.jpeg" src="img-9.jpeg" /></p>
<p>Extended Data Fig. 3: Comparison of different acquisition functions in a simulation study where the underlying causal graph is the complete graph on 30 nodes, the most downstream nodes are fixed as intervention targets, and we vary the number of intervention targets. Each plot corresponds to an average of 10 instances and each method is run 20 times and averaged. (A)-(D) Relative distance between the target mean $\boldsymbol{\mu}$ and the best approximation $\boldsymbol{\mu}_{t}^{*}$
<img alt="img-10.jpeg" src="img-10.jpeg" /></p>
<p><img alt="img-11.jpeg" src="img-11.jpeg" />
(A) Complete graph
(B) Erdös-Rényi graph (0.8)
(C) Erdös-Rényi graph (0.5)
(D) Path graph
<img alt="img-12.jpeg" src="img-12.jpeg" />
(E) Complete graph
(F) Erdös-Rényi graph (0.8)
(G) Erdös-Rényi graph (0.5)
<img alt="img-13.jpeg" src="img-13.jpeg" />
(I) Complete graph
(J) Erdös-Rényi graph (0.8)
(K) Erdös-Rényi graph (0.5)
<img alt="img-14.jpeg" src="img-14.jpeg" />
<img alt="img-15.jpeg" src="img-15.jpeg" />
(H) Path graph
<img alt="img-16.jpeg" src="img-16.jpeg" />
(L) Path graph</p>
<p>Extended Data Fig. 4 | Comparison of different acquisition functions in a simulation study where we vary the underlying causal graph (complete graph, Erdös-Rényi graph with edge probability 0.8, Erdös-Rényi graph with edge probability 0.8 , path graph) and the most downstream half of the nodes are fixed as intervention targets. Each plot corresponds to an average of 10 instances on a 30 -node DAG with 15 perturbation targets. Each method is run 20 times and averaged. (A)-(D) Relative distance between the target mean $\boldsymbol{\mu}$ and the
best approximation $\boldsymbol{\mu}<em t="t">{t}^{<em>}$ (defined in Fig. 5A in the main text) up to time step $t$. Lines denote the mean over 10 instances; the shading corresponds to one standard deviation. (E)-(H) Relative distance statistic of each method averaged over 10 instances at the last time step $(t=50)$. Note that the DAGs become sparser from left to right. (I)-(L) Squared distance presented as mean value +/- SEM between the optimal intervention $\mathbf{a}$ and the best approximation $\mathbf{a}_{t}^{</em>}$ that is used to obtain $\boldsymbol{\mu}</em>$ up to time step $t$.}^{*</p>
<p><img alt="img-17.jpeg" src="img-17.jpeg" />
(A) Relative distance across time steps</p>
<p>Extended Data Fig. 5 | Comparison of our acquisition functions to baseline acquisition functions adapted from prior works (EI-Int: based on Expected Improvement, MI-Int: based on Mutual Information, and UCB-Int: based on Upper Confidence Bound) in a simulation study where the underlying causal graph is the complete graph on 10 nodes and the most downstream 5 nodes are fixed as intervention targets. Each plot corresponds to an average of 10
<img alt="img-18.jpeg" src="img-18.jpeg" />
(B) Last time step
<img alt="img-19.jpeg" src="img-19.jpeg" />
(C) Runtime per iteration
instances and each method is run 20 times and averaged. (A) Relative distance between the target mean $\boldsymbol{\rho}$ ' and the best approximation $\boldsymbol{\rho}_{t}^{*}$ (defined in Fig. 5A in the main text) up to time step $t$. Lines denote the mean over 10 instances; the shading corresponds to one standard deviation. (B) Relative distance statistic of each method averaged over 10 instances at the last time step $(t=50)$. (C) Runtime per iteration of each method in seconds.</p>
<p><img alt="img-20.jpeg" src="img-20.jpeg" /></p>
<p>Extended Data Fig. 6 | Performance of the different acquisition functions under three types of DAG misspecifications where the underlying causal graph is a 5 -node random Erdös-Rényi DAG with edge density 0.5 and 3 intervention targets. Each plot corresponds to an average of the relative
distance at time step 10 across 10 instances. Each method is run 10 times and averaged. SHD denotes the number of misspecified edges. (A)-(C) Three types of DAG misspecifications.</p>
<p><img alt="img-21.jpeg" src="img-21.jpeg" /></p>
<table>
<thead>
<tr>
<th>function/class</th>
<th>parameter</th>
<th>value</th>
</tr>
</thead>
<tbody>
<tr>
<td>GSP</td>
<td>conditional independence tester</td>
<td>MemoizedCI_Tester</td>
</tr>
<tr>
<td></td>
<td>number of runs</td>
<td>1000</td>
</tr>
<tr>
<td>CI Tester</td>
<td>conditional independence test</td>
<td>partial correlation test</td>
</tr>
<tr>
<td></td>
<td>significance level ("α")</td>
<td>1E-03</td>
</tr>
</tbody>
</table>
<p>(B)</p>
<p><img alt="img-22.jpeg" src="img-22.jpeg" /></p>
<h2>Extended Data Fig. 7: Learned linear Gaussian SCM on the 36 genes of interest based on the control cells.</h2>
<p>(A) Learned DAG on the 36 considered genes. Nodes are oriented up-down by their topological order and colored by the module/program they belong to in Supplementary Fig. 7.</p>
<p>(B) Parameters used in GSP</p>
<p>(C) to learn the above DAG.</p>
<p>(C) Pearson r scores of regressing each non-source gene against its parents. Blue: average scores in the learned DAG; grey (with errorbars): average of scores in a random graph (100 samples).</p>
<p><img alt="img-23.jpeg" src="img-23.jpeg" />
(A) CDH19.
<img alt="img-24.jpeg" src="img-24.jpeg" />
(F) CDH19.
<img alt="img-25.jpeg" src="img-25.jpeg" />
(B) SERPINE2.
<img alt="img-26.jpeg" src="img-26.jpeg" />
(C) EIF3K.
<img alt="img-27.jpeg" src="img-27.jpeg" />
(D) HLA-C.
<img alt="img-28.jpeg" src="img-28.jpeg" />
(E) TGFB1.
<img alt="img-29.jpeg" src="img-29.jpeg" />
(F) CDH19.
<img alt="img-30.jpeg" src="img-30.jpeg" />
(G) SERPINE2.
<img alt="img-31.jpeg" src="img-31.jpeg" />
(H) EIF3K.
<img alt="img-32.jpeg" src="img-32.jpeg" />
(I) HLA-C.
<img alt="img-33.jpeg" src="img-33.jpeg" />
(J) TGFB1.</p>
<p>Extended Data Fig. 8 | Comparison of the different acquisition functions for identifying the intervention that matches the target mean for 5 different ground-truth target genes. Square distance presented as mean value $+/-$ SEM between the target mean $\boldsymbol{\mu}$ and the best approximation $\boldsymbol{\mu}_{t}^{\prime}$ across time step $t$ is
reported. (A)-(E) comparison of 6 acquisition functions. (F)-(J) same as top, showing only 3 methods to de-clutter the plots, comparing our CIV acquisition function against the random and greedy baseline. Each plot is captioned with its ground-truth target gene.</p>
<p><img alt="img-34.jpeg" src="img-34.jpeg" />
(A) $M Y C$ expression. Mean: 1.52 (ctrl) v.s. 2.58 (ptb_MYC).
<img alt="img-35.jpeg" src="img-35.jpeg" />
(B) EIF3K expression. Mean: 5.19 (ctrl) v.s. 4.78 (ptb_EIF3K).
<img alt="img-36.jpeg" src="img-36.jpeg" />
(C) HLA-C expression. Mean: 5.98 (ctrl) v.s. 4.16 (ptb_HLA-C).</p>
<p>Extended Data Fig. 9 | Gene expression changes for three examples of different knock-out perturbations. Comparing target-gene expression in the control cell population and the perturbed cell population of the corresponding knock-out experiment. (A)-(C) Included target genes: MYC, EIF3K, and HLA-C. The mean expression of the target gene is given in each subcaption.</p>
<p><img alt="img-37.jpeg" src="img-37.jpeg" />
(A)</p>
<p>Extended Data Fig. 10 | Comparison of acquisition functions for identifying interventions that match the target mean of perturbing MYC. The reported metric is the square distance presented as mean value $+/-$ SEM between the target mean $\boldsymbol{\mu}$ and the best approximation $\boldsymbol{\mu}_{t}^{*}$ across all time steps $t$. (A) All methods. (B) De-cluttered subset of methods.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{1}$ Massachusetts Institute of Technology, Cambridge, MA, USA. ${ }^{2}$ Broad Institute of MIT and Harvard, Cambridge, MA, USA. ${ }^{3}$ Harvard University, Cambridge, MA, USA. ${ }^{4}$ These authors contributed equally: Louis Cammarata, Chandler Squires. $\square$ e-mail: sapsis@mit.edu; culer@mit.edu&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>