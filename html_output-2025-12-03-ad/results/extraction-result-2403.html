<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2403 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2403</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2403</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-64.html">extraction-schema-64</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that automatically generate research hypotheses or research ideas, including how novelty and feasibility are measured, quantified, or traded off against each other.</div>
                <p><strong>Paper ID:</strong> paper-747dff7b9cd0d6feb16c340b684b1923034e8777</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/747dff7b9cd0d6feb16c340b684b1923034e8777" target="_blank">GrEDeL: A Knowledge Graph Embedding Based Method for Drug Discovery From Biomedical Literatures</a></p>
                <p><strong>Paper Venue:</strong> IEEE Access</p>
                <p><strong>Paper TL;DR:</strong> A biomedical knowledge graph embedding-based recurrent neural network method called GrEDeL, which discovers potential drugs for diseases by mining published biomedical literature, which could be a supplementary method for the current traditional drug discovery methods.</p>
                <p><strong>Paper Abstract:</strong> Drug discovery is the process by which new candidate medications are discovered. Developing a new drug is a lengthy, complex, and expensive process. Here, in this paper, we propose a biomedical knowledge graph embedding-based recurrent neural network method called GrEDeL, which discovers potential drugs for diseases by mining published biomedical literature. GrEDeL first builds a biomedical knowledge graph by exploiting the relations extracted from biomedical abstracts. Then, the graph data are converted into a low dimensional space by leveraging the knowledge graph embedding methods. After that, a recurrent neural network model is trained by the known drug therapies which are represented by graph embeddings. Finally, it uses the learned model to discover candidate drugs for diseases of interest from biomedical literature. The experimental results show that our method could not only effectively discover new drugs by mining literature, but also could provide the corresponding mechanism of actions for the candidate drugs. It could be a supplementary method for the current traditional drug discovery methods.</p>
                <p><strong>Cost:</strong> 0.018</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2403.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2403.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that automatically generate research hypotheses or research ideas, including how novelty and feasibility are measured, quantified, or traded off against each other.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GrEDeL</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GrEDeL: A Knowledge Graph Embedding Based Deep Learning method</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A system combining knowledge-graph embeddings (TransE) and an LSTM-based recurrent neural network to generate candidate drug–target–disease hypotheses by scoring and ranking paths extracted from biomedical literature.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>GrEDeL</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Constructs a biomedical knowledge graph from SemRep-extracted predications in PubMed abstracts (entities annotated with UMLS semantic types). Converts the KG into two embedding spaces (Semantic Graph and Type Graph) using TransE; concatenates entity/relation embeddings to form sequential inputs. Trains an LSTM on known drug–target–disease paths (positive examples from TTD and matched negatives) to predict the probability that a candidate drug treats a disease via a target. For discovery, enumerates candidate drug→…→disease paths, scores each path with the trained discriminator D(g(π),θ), and assigns a drug score equal to the maximum path score; ranks drugs by this score.</td>
                        </tr>
                        <tr>
                            <td><strong>research_domain</strong></td>
                            <td>biomedical literature-based drug discovery (biomedicine)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_type</strong></td>
                            <td>targeted hypothesis generation (drug→target→disease associations; literature-based discovery)</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_score</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_score</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_evidence</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimization_strategy</strong></td>
                            <td>scores candidate associations via a learned probabilistic model (cross-entropy trained LSTM) and ranks by maximum path probability; no explicit novelty–feasibility multi-objective optimization is used.</td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparative_baseline</strong></td>
                            <td>Compared against classical ML classifiers (LR, RF, SVM, MLP, vanilla RNN), knowledge-graph methods (Malas, Bakalb, SemaTyP), and graph algorithms (random-walk variants NRWRH, TP-NRWRH, basic RWA).</td>
                        </tr>
                        <tr>
                            <td><strong>comparative_results</strong></td>
                            <td>GrEDeL achieved Precision=0.881, Recall=0.971, F-score=0.924 on 10-fold cross-validation (best among compared models). In drug rediscovery (115 gold cases): Not Found=0, Mean Rank=27.05, Hits@10=33.04%, outperforming Bakalb (Mean Rank 29.44, Hits@10 31.30%), SemaTyP (Mean Rank 29.87, Hits@10 30.58%), NRWRH (Mean Rank 32.17, Hits@10 26.09%) and other baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_findings</strong></td>
                            <td>The paper finds that combining semantic-type embeddings (Type Graph) with entity/relation embeddings (Semantic Graph) improves performance; modeling drug→target→disease as a sequence (LSTM) captures dependencies that improve rediscovery metrics in biomedical drug discovery. No domain-specific novelty vs feasibility analysis was reported.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2403.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2403.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that automatically generate research hypotheses or research ideas, including how novelty and feasibility are measured, quantified, or traded off against each other.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ABC model</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ABC model (Swanson literature-based discovery)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A classic literature-based discovery paradigm that hypothesizes a connection A→C when independent literature shows A→B and B→C (Swanson's Raynaud's–fish oil discovery).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Fish oil, Raynaud's syndrome, and undiscovered public knowledge</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>ABC model (Swanson)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Hypothesis-generation by transitive linking: if the literature supports A implies B and independently B implies C, infer a potential A–C relationship. Typically implemented via co-occurrence and concept linking in corpora to surface candidate novel relationships.</td>
                        </tr>
                        <tr>
                            <td><strong>research_domain</strong></td>
                            <td>literature-based discovery in biomedicine (general LBD)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_type</strong></td>
                            <td>open-ended discovery via transitive inference</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_score</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_score</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_evidence</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimization_strategy</strong></td>
                            <td>not applicable in this paper (historical paradigm); ABC is a generation rule rather than an optimization process.</td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparative_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparative_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_findings</strong></td>
                            <td>Paper cites ABC as foundational LBD approach and notes its limitations (restricted to simple transitive associations).</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2403.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2403.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that automatically generate research hypotheses or research ideas, including how novelty and feasibility are measured, quantified, or traded off against each other.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Co-occurrence methods</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Co-occurrence-based literature mining</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Methods that infer candidate relations/hypotheses by detecting frequent co-occurrence of terms or concepts in text corpora.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Co-occurrence methods</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Directly use term co-occurrence counts in text as evidence of relations; captures many possible relations but often lacks logical explanation and yields false positives (high co-occurrence frequency can be spurious).</td>
                        </tr>
                        <tr>
                            <td><strong>research_domain</strong></td>
                            <td>literature-based discovery / text mining</td>
                        </tr>
                        <tr>
                            <td><strong>problem_type</strong></td>
                            <td>broad screening / hypothesis generation</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_score</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_score</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_evidence</strong></td>
                            <td>Paper notes trade-off qualitatively: co-occurrence yields high recall (many ideas) but low interpretability/precision; no quantitative novelty–feasibility tradeoff reported.</td>
                        </tr>
                        <tr>
                            <td><strong>optimization_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparative_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparative_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_findings</strong></td>
                            <td>Co-occurrence can capture many candidate links quickly but tends to produce relationships lacking mechanistic explanations; subsequent methods aim to improve precision.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2403.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2403.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that automatically generate research hypotheses or research ideas, including how novelty and feasibility are measured, quantified, or traded off against each other.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Semantic models (NLP)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Semantic-model-based literature mining (NLP approaches, e.g., SemRep)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Approaches that apply NLP and semantic parsing to extract predications (subject–relation–object) from text to produce explainable candidate hypotheses.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>The interaction of domain knowledge and linguistic structure in natural language processing: Interpreting hypernymic propositions in biomedical text</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Semantic NLP-based LBD (SemRep)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Uses SemRep to extract semantic predications (subject, relation, object) and UMLS semantic types from biomedical abstracts; these predications are assembled into a knowledge graph that supports hypothesis generation with explicit semantic relations and explanatory paths.</td>
                        </tr>
                        <tr>
                            <td><strong>research_domain</strong></td>
                            <td>biomedical text mining / literature-based discovery</td>
                        </tr>
                        <tr>
                            <td><strong>problem_type</strong></td>
                            <td>explainable hypothesis generation</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_score</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_score</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_evidence</strong></td>
                            <td>Paper qualitatively contrasts semantic models with co-occurrence: semantic models improve precision/explainability but may miss complex associations (i.e., they trade recall/novelty for interpretability/feasibility implicitly). No quantitative tradeoff metrics provided.</td>
                        </tr>
                        <tr>
                            <td><strong>optimization_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparative_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparative_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_findings</strong></td>
                            <td>Semantic predications enable generating mechanistically-explained hypotheses (paths), which are preferable for downstream validation even if some novel associations are missed.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2403.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2403.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that automatically generate research hypotheses or research ideas, including how novelty and feasibility are measured, quantified, or traded off against each other.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Discovery patterns</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Discovery patterns (Hristovski et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A filtering technique that uses semantic patterns (e.g., type and predicate sequences) to reduce false positives and provide explanatory structure for discovered hypotheses.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Discovery patterns</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Apply predefined semantic type/predicate patterns to filter candidate transitive paths (e.g., A→B→C) so that only patterns likely to represent meaningful mechanistic hypotheses are retained; supports interpretability and reduces false positives.</td>
                        </tr>
                        <tr>
                            <td><strong>research_domain</strong></td>
                            <td>biomedical LBD / semantic filtering</td>
                        </tr>
                        <tr>
                            <td><strong>problem_type</strong></td>
                            <td>precision-focused filtering in hypothesis generation</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_score</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_score</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_evidence</strong></td>
                            <td>Described qualitatively: discovery patterns reduce false positives (improve feasibility/interpretability) at the potential cost of missing some novel/complex associations; no numerical tradeoff provided in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>optimization_strategy</strong></td>
                            <td>pattern-based filtering (rule-based constraint on candidate paths)</td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparative_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparative_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_findings</strong></td>
                            <td>Useful as a post-processing step to provide mechanistic explanations for candidate hypotheses in biomedical literature mining.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2403.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e2403.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that automatically generate research hypotheses or research ideas, including how novelty and feasibility are measured, quantified, or traded off against each other.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Cameron subgraph model</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Automatic subgraph model (Cameron et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A KG-based method that clusters semantic paths in a semantic graph to elucidate latent associations between biomedical entities, primarily used for explanation rather than discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Context-driven automatic subgraph creation for literature-based discovery</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Automatic subgraph model (Cameron et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Clusters semantic paths in a semantic graph to create subgraphs that help explain associations between biomedical entities; emphasis on generating explanatory subgraphs rather than directly producing ranked novel hypotheses.</td>
                        </tr>
                        <tr>
                            <td><strong>research_domain</strong></td>
                            <td>biomedical knowledge-graph analysis / literature-based explanation</td>
                        </tr>
                        <tr>
                            <td><strong>problem_type</strong></td>
                            <td>explanatory analysis / association elucidation</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_score</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_score</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_evidence</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimization_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparative_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparative_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_findings</strong></td>
                            <td>Paper notes this method is more focused on explanation of associations than on discovering new drug hypotheses.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2403.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e2403.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that automatically generate research hypotheses or research ideas, including how novelty and feasibility are measured, quantified, or traded off against each other.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Malas's method</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Drug repurposing using a semantic knowledge graph (Malas et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A knowledge-graph feature-based supervised method that uses counts of intermediates, semantic category diversity, and connecting predicates to predict novel drug–disease associations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Drug repurposing using a semantic knowledge graph</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Malas et al. KG-feature classifier</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Extracts features from KG paths between a drug and disease (e.g., total number of intermediate concepts, number of distinct semantic categories, predicates connecting the pair) and trains a predictive model to score drug–disease associations for repurposing hypotheses.</td>
                        </tr>
                        <tr>
                            <td><strong>research_domain</strong></td>
                            <td>biomedical drug repurposing / knowledge graphs</td>
                        </tr>
                        <tr>
                            <td><strong>problem_type</strong></td>
                            <td>targeted hypothesis scoring (repurposing candidates)</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_score</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_score</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_evidence</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimization_strategy</strong></td>
                            <td>feature-based supervised classification (not explicitly optimizing novelty vs feasibility).</td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparative_baseline</strong></td>
                            <td>Compared as a baseline in rediscovery tests (missed 52 of 115 gold drugs; Mean Rank=37.68; Hits@10=24.34%).</td>
                        </tr>
                        <tr>
                            <td><strong>comparative_results</strong></td>
                            <td>Underperforms GrEDeL in rediscovery metrics (GrEDeL Mean Rank 27.05 vs Malas 37.68; GrEDeL Hits@10 33.04% vs Malas 24.34%).</td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_findings</strong></td>
                            <td>Relies on simple KG-derived counts and semantic diversity features; misses cases where more complex path dependencies matter.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2403.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e2403.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that automatically generate research hypotheses or research ideas, including how novelty and feasibility are measured, quantified, or traded off against each other.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Bakalb / Bakal et al.</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Exploiting semantic patterns over biomedical knowledge graphs for predicting treatment and causative relations (Bakal et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Method that uses paths connecting biomedical entities as features in a logistic regression model to discover treatments and causative relations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Exploiting semantic patterns over biomedical knowledge graphs for predicting treatment and causative relations</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Bakal et al. path-feature logistic model</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Uses simple paths (typically all paths up to a length threshold) connecting biomedical entities to construct feature vectors for logistic regression classifiers that predict treatment or causative relations (drug–disease associations).</td>
                        </tr>
                        <tr>
                            <td><strong>research_domain</strong></td>
                            <td>biomedical KG-based relation prediction</td>
                        </tr>
                        <tr>
                            <td><strong>problem_type</strong></td>
                            <td>targeted hypothesis prediction (treatment/causation)</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_score</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_score</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_evidence</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimization_strategy</strong></td>
                            <td>supervised logistic regression on path features; no explicit novelty–feasibility optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparative_baseline</strong></td>
                            <td>Used as baseline: Bakalb's method had Not Found=4, Mean Rank=29.44, Hits@10=31.30% on rediscovery set.</td>
                        </tr>
                        <tr>
                            <td><strong>comparative_results</strong></td>
                            <td>Slightly worse than GrEDeL (Mean Rank 29.44 vs 27.05; Hits@10 31.30% vs 33.04%).</td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_findings</strong></td>
                            <td>Considers multiple path features but lacks sequential modeling of entity order/dependencies, limiting mechanistic detail.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2403.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e2403.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that automatically generate research hypotheses or research ideas, including how novelty and feasibility are measured, quantified, or traded off against each other.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SemaTyP</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>SemaTyP: A knowledge graph based literature mining method for drug discovery</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A KG-based method that scores drug–disease associations by exploiting the distribution of semantic types of entities along connecting paths.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Sematyp: A knowledge graph based literature mining method for drug discovery</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>SemaTyP</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Constructs features based on the distribution and patterns of UMLS semantic types on paths between drugs and diseases in a knowledge graph and uses these to score and rank candidate drug–disease associations.</td>
                        </tr>
                        <tr>
                            <td><strong>research_domain</strong></td>
                            <td>biomedical literature mining / drug discovery</td>
                        </tr>
                        <tr>
                            <td><strong>problem_type</strong></td>
                            <td>targeted hypothesis generation (drug therapies)</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_score</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_score</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_evidence</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimization_strategy</strong></td>
                            <td>semantic-type-distribution scoring (no explicit novelty–feasibility tradeoff optimization).</td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparative_baseline</strong></td>
                            <td>Compared in rediscovery tests: SemaTyP Not Found=0, Mean Rank=29.87, Hits@10=30.58%</td>
                        </tr>
                        <tr>
                            <td><strong>comparative_results</strong></td>
                            <td>GrEDeL outperforms SemaTyP (Mean Rank 27.05 vs 29.87; Hits@10 33.04% vs 30.58%).</td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_findings</strong></td>
                            <td>Type-based features capture semantic patterns useful for discovery but are limited by number of semantic types (133) and cannot fully disambiguate entities.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2403.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e2403.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that automatically generate research hypotheses or research ideas, including how novelty and feasibility are measured, quantified, or traded off against each other.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Random-walk methods (RWA / NRWRH / TP-NRWRH)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Random-walk-based algorithms for candidate scoring (basic RWA, NRWRH, TP-NRWRH)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Graph-based scoring algorithms that estimate the proximity or connectivity between candidate drugs and diseases using random walks (with or without restart) on heterogeneous networks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Drug-target interaction prediction by random walk on the heterogeneous network</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Random-walk based algorithms (RWA, NRWRH, TP-NRWRH)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Basic RWA: simulate random walks from candidate drug nodes for n steps to compute reachability/probability scores to disease nodes (expected number of steps n controls neighborhood breadth). NRWRH: network-based random walk with restart adapted to heterogeneous networks to infer drug–target interactions. TP-NRWRH: two-pass variant improving NRWRH. Scores are used to rank candidate drugs for diseases.</td>
                        </tr>
                        <tr>
                            <td><strong>research_domain</strong></td>
                            <td>network-based drug discovery / graph algorithms</td>
                        </tr>
                        <tr>
                            <td><strong>problem_type</strong></td>
                            <td>targeted scoring and ranking of candidate associations</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_score</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_score</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_evidence</strong></td>
                            <td>Paper reports qualitative behavior: increasing RWA step count increases coverage (reduces Not Found) but can lower ranking quality for gold standards beyond an optimal step due to many additional candidates; no explicit novelty–feasibility tradeoff metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>optimization_strategy</strong></td>
                            <td>tune walk length / restart behavior to balance local specificity vs coverage; NRWRH/TP-NRWRH incorporate semantic types to improve relevance.</td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparative_baseline</strong></td>
                            <td>Used as baselines; basic RWA (steps 1..6), NRWRH and TP-NRWRH.</td>
                        </tr>
                        <tr>
                            <td><strong>comparative_results</strong></td>
                            <td>Basic RWA performance varies with steps (RWA_3 best Mean Rank=30.33, but RWA_2 had best Hits@10 among basics at 24.46%). NRWRH Mean Rank=32.17 Hits@10=26.09%; TP-NRWRH Mean Rank=31.13 Hits@10=27.83%. GrEDeL outperforms these methods.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_findings</strong></td>
                            <td>Random-walk methods can be effective but are sensitive to walk-length hyperparameters; incorporating semantic types improves results.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Fish oil, Raynaud's syndrome, and undiscovered public knowledge <em>(Rating: 2)</em></li>
                <li>Exploiting semantic relations for literature-based discovery <em>(Rating: 2)</em></li>
                <li>Context-driven automatic subgraph creation for literature-based discovery <em>(Rating: 2)</em></li>
                <li>Drug repurposing using a semantic knowledge graph <em>(Rating: 2)</em></li>
                <li>Exploiting semantic patterns over biomedical knowledge graphs for predicting treatment and causative relations <em>(Rating: 2)</em></li>
                <li>Sematyp: A knowledge graph based literature mining method for drug discovery <em>(Rating: 2)</em></li>
                <li>Drug-target interaction prediction by random walk on the heterogeneous network <em>(Rating: 2)</em></li>
                <li>Inferring new indications for approved drugs via random walk on drug-disease heterogenous networks <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2403",
    "paper_id": "paper-747dff7b9cd0d6feb16c340b684b1923034e8777",
    "extraction_schema_id": "extraction-schema-64",
    "extracted_data": [
        {
            "name_short": "GrEDeL",
            "name_full": "GrEDeL: A Knowledge Graph Embedding Based Deep Learning method",
            "brief_description": "A system combining knowledge-graph embeddings (TransE) and an LSTM-based recurrent neural network to generate candidate drug–target–disease hypotheses by scoring and ranking paths extracted from biomedical literature.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "GrEDeL",
            "system_description": "Constructs a biomedical knowledge graph from SemRep-extracted predications in PubMed abstracts (entities annotated with UMLS semantic types). Converts the KG into two embedding spaces (Semantic Graph and Type Graph) using TransE; concatenates entity/relation embeddings to form sequential inputs. Trains an LSTM on known drug–target–disease paths (positive examples from TTD and matched negatives) to predict the probability that a candidate drug treats a disease via a target. For discovery, enumerates candidate drug→…→disease paths, scores each path with the trained discriminator D(g(π),θ), and assigns a drug score equal to the maximum path score; ranks drugs by this score.",
            "research_domain": "biomedical literature-based drug discovery (biomedicine)",
            "problem_type": "targeted hypothesis generation (drug→target→disease associations; literature-based discovery)",
            "novelty_metric": null,
            "novelty_score": null,
            "feasibility_metric": null,
            "feasibility_score": null,
            "tradeoff_evidence": null,
            "optimization_strategy": "scores candidate associations via a learned probabilistic model (cross-entropy trained LSTM) and ranks by maximum path probability; no explicit novelty–feasibility multi-objective optimization is used.",
            "human_evaluation": false,
            "human_evaluation_results": null,
            "comparative_baseline": "Compared against classical ML classifiers (LR, RF, SVM, MLP, vanilla RNN), knowledge-graph methods (Malas, Bakalb, SemaTyP), and graph algorithms (random-walk variants NRWRH, TP-NRWRH, basic RWA).",
            "comparative_results": "GrEDeL achieved Precision=0.881, Recall=0.971, F-score=0.924 on 10-fold cross-validation (best among compared models). In drug rediscovery (115 gold cases): Not Found=0, Mean Rank=27.05, Hits@10=33.04%, outperforming Bakalb (Mean Rank 29.44, Hits@10 31.30%), SemaTyP (Mean Rank 29.87, Hits@10 30.58%), NRWRH (Mean Rank 32.17, Hits@10 26.09%) and other baselines.",
            "domain_specific_findings": "The paper finds that combining semantic-type embeddings (Type Graph) with entity/relation embeddings (Semantic Graph) improves performance; modeling drug→target→disease as a sequence (LSTM) captures dependencies that improve rediscovery metrics in biomedical drug discovery. No domain-specific novelty vs feasibility analysis was reported.",
            "uuid": "e2403.0"
        },
        {
            "name_short": "ABC model",
            "name_full": "ABC model (Swanson literature-based discovery)",
            "brief_description": "A classic literature-based discovery paradigm that hypothesizes a connection A→C when independent literature shows A→B and B→C (Swanson's Raynaud's–fish oil discovery).",
            "citation_title": "Fish oil, Raynaud's syndrome, and undiscovered public knowledge",
            "mention_or_use": "mention",
            "system_name": "ABC model (Swanson)",
            "system_description": "Hypothesis-generation by transitive linking: if the literature supports A implies B and independently B implies C, infer a potential A–C relationship. Typically implemented via co-occurrence and concept linking in corpora to surface candidate novel relationships.",
            "research_domain": "literature-based discovery in biomedicine (general LBD)",
            "problem_type": "open-ended discovery via transitive inference",
            "novelty_metric": null,
            "novelty_score": null,
            "feasibility_metric": null,
            "feasibility_score": null,
            "tradeoff_evidence": null,
            "optimization_strategy": "not applicable in this paper (historical paradigm); ABC is a generation rule rather than an optimization process.",
            "human_evaluation": null,
            "human_evaluation_results": null,
            "comparative_baseline": null,
            "comparative_results": null,
            "domain_specific_findings": "Paper cites ABC as foundational LBD approach and notes its limitations (restricted to simple transitive associations).",
            "uuid": "e2403.1"
        },
        {
            "name_short": "Co-occurrence methods",
            "name_full": "Co-occurrence-based literature mining",
            "brief_description": "Methods that infer candidate relations/hypotheses by detecting frequent co-occurrence of terms or concepts in text corpora.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "Co-occurrence methods",
            "system_description": "Directly use term co-occurrence counts in text as evidence of relations; captures many possible relations but often lacks logical explanation and yields false positives (high co-occurrence frequency can be spurious).",
            "research_domain": "literature-based discovery / text mining",
            "problem_type": "broad screening / hypothesis generation",
            "novelty_metric": null,
            "novelty_score": null,
            "feasibility_metric": null,
            "feasibility_score": null,
            "tradeoff_evidence": "Paper notes trade-off qualitatively: co-occurrence yields high recall (many ideas) but low interpretability/precision; no quantitative novelty–feasibility tradeoff reported.",
            "optimization_strategy": null,
            "human_evaluation": null,
            "human_evaluation_results": null,
            "comparative_baseline": null,
            "comparative_results": null,
            "domain_specific_findings": "Co-occurrence can capture many candidate links quickly but tends to produce relationships lacking mechanistic explanations; subsequent methods aim to improve precision.",
            "uuid": "e2403.2"
        },
        {
            "name_short": "Semantic models (NLP)",
            "name_full": "Semantic-model-based literature mining (NLP approaches, e.g., SemRep)",
            "brief_description": "Approaches that apply NLP and semantic parsing to extract predications (subject–relation–object) from text to produce explainable candidate hypotheses.",
            "citation_title": "The interaction of domain knowledge and linguistic structure in natural language processing: Interpreting hypernymic propositions in biomedical text",
            "mention_or_use": "use",
            "system_name": "Semantic NLP-based LBD (SemRep)",
            "system_description": "Uses SemRep to extract semantic predications (subject, relation, object) and UMLS semantic types from biomedical abstracts; these predications are assembled into a knowledge graph that supports hypothesis generation with explicit semantic relations and explanatory paths.",
            "research_domain": "biomedical text mining / literature-based discovery",
            "problem_type": "explainable hypothesis generation",
            "novelty_metric": null,
            "novelty_score": null,
            "feasibility_metric": null,
            "feasibility_score": null,
            "tradeoff_evidence": "Paper qualitatively contrasts semantic models with co-occurrence: semantic models improve precision/explainability but may miss complex associations (i.e., they trade recall/novelty for interpretability/feasibility implicitly). No quantitative tradeoff metrics provided.",
            "optimization_strategy": null,
            "human_evaluation": null,
            "human_evaluation_results": null,
            "comparative_baseline": null,
            "comparative_results": null,
            "domain_specific_findings": "Semantic predications enable generating mechanistically-explained hypotheses (paths), which are preferable for downstream validation even if some novel associations are missed.",
            "uuid": "e2403.3"
        },
        {
            "name_short": "Discovery patterns",
            "name_full": "Discovery patterns (Hristovski et al.)",
            "brief_description": "A filtering technique that uses semantic patterns (e.g., type and predicate sequences) to reduce false positives and provide explanatory structure for discovered hypotheses.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "Discovery patterns",
            "system_description": "Apply predefined semantic type/predicate patterns to filter candidate transitive paths (e.g., A→B→C) so that only patterns likely to represent meaningful mechanistic hypotheses are retained; supports interpretability and reduces false positives.",
            "research_domain": "biomedical LBD / semantic filtering",
            "problem_type": "precision-focused filtering in hypothesis generation",
            "novelty_metric": null,
            "novelty_score": null,
            "feasibility_metric": null,
            "feasibility_score": null,
            "tradeoff_evidence": "Described qualitatively: discovery patterns reduce false positives (improve feasibility/interpretability) at the potential cost of missing some novel/complex associations; no numerical tradeoff provided in this paper.",
            "optimization_strategy": "pattern-based filtering (rule-based constraint on candidate paths)",
            "human_evaluation": null,
            "human_evaluation_results": null,
            "comparative_baseline": null,
            "comparative_results": null,
            "domain_specific_findings": "Useful as a post-processing step to provide mechanistic explanations for candidate hypotheses in biomedical literature mining.",
            "uuid": "e2403.4"
        },
        {
            "name_short": "Cameron subgraph model",
            "name_full": "Automatic subgraph model (Cameron et al.)",
            "brief_description": "A KG-based method that clusters semantic paths in a semantic graph to elucidate latent associations between biomedical entities, primarily used for explanation rather than discovery.",
            "citation_title": "Context-driven automatic subgraph creation for literature-based discovery",
            "mention_or_use": "mention",
            "system_name": "Automatic subgraph model (Cameron et al.)",
            "system_description": "Clusters semantic paths in a semantic graph to create subgraphs that help explain associations between biomedical entities; emphasis on generating explanatory subgraphs rather than directly producing ranked novel hypotheses.",
            "research_domain": "biomedical knowledge-graph analysis / literature-based explanation",
            "problem_type": "explanatory analysis / association elucidation",
            "novelty_metric": null,
            "novelty_score": null,
            "feasibility_metric": null,
            "feasibility_score": null,
            "tradeoff_evidence": null,
            "optimization_strategy": null,
            "human_evaluation": null,
            "human_evaluation_results": null,
            "comparative_baseline": null,
            "comparative_results": null,
            "domain_specific_findings": "Paper notes this method is more focused on explanation of associations than on discovering new drug hypotheses.",
            "uuid": "e2403.5"
        },
        {
            "name_short": "Malas's method",
            "name_full": "Drug repurposing using a semantic knowledge graph (Malas et al.)",
            "brief_description": "A knowledge-graph feature-based supervised method that uses counts of intermediates, semantic category diversity, and connecting predicates to predict novel drug–disease associations.",
            "citation_title": "Drug repurposing using a semantic knowledge graph",
            "mention_or_use": "use",
            "system_name": "Malas et al. KG-feature classifier",
            "system_description": "Extracts features from KG paths between a drug and disease (e.g., total number of intermediate concepts, number of distinct semantic categories, predicates connecting the pair) and trains a predictive model to score drug–disease associations for repurposing hypotheses.",
            "research_domain": "biomedical drug repurposing / knowledge graphs",
            "problem_type": "targeted hypothesis scoring (repurposing candidates)",
            "novelty_metric": null,
            "novelty_score": null,
            "feasibility_metric": null,
            "feasibility_score": null,
            "tradeoff_evidence": null,
            "optimization_strategy": "feature-based supervised classification (not explicitly optimizing novelty vs feasibility).",
            "human_evaluation": false,
            "human_evaluation_results": null,
            "comparative_baseline": "Compared as a baseline in rediscovery tests (missed 52 of 115 gold drugs; Mean Rank=37.68; Hits@10=24.34%).",
            "comparative_results": "Underperforms GrEDeL in rediscovery metrics (GrEDeL Mean Rank 27.05 vs Malas 37.68; GrEDeL Hits@10 33.04% vs Malas 24.34%).",
            "domain_specific_findings": "Relies on simple KG-derived counts and semantic diversity features; misses cases where more complex path dependencies matter.",
            "uuid": "e2403.6"
        },
        {
            "name_short": "Bakalb / Bakal et al.",
            "name_full": "Exploiting semantic patterns over biomedical knowledge graphs for predicting treatment and causative relations (Bakal et al.)",
            "brief_description": "Method that uses paths connecting biomedical entities as features in a logistic regression model to discover treatments and causative relations.",
            "citation_title": "Exploiting semantic patterns over biomedical knowledge graphs for predicting treatment and causative relations",
            "mention_or_use": "use",
            "system_name": "Bakal et al. path-feature logistic model",
            "system_description": "Uses simple paths (typically all paths up to a length threshold) connecting biomedical entities to construct feature vectors for logistic regression classifiers that predict treatment or causative relations (drug–disease associations).",
            "research_domain": "biomedical KG-based relation prediction",
            "problem_type": "targeted hypothesis prediction (treatment/causation)",
            "novelty_metric": null,
            "novelty_score": null,
            "feasibility_metric": null,
            "feasibility_score": null,
            "tradeoff_evidence": null,
            "optimization_strategy": "supervised logistic regression on path features; no explicit novelty–feasibility optimization.",
            "human_evaluation": false,
            "human_evaluation_results": null,
            "comparative_baseline": "Used as baseline: Bakalb's method had Not Found=4, Mean Rank=29.44, Hits@10=31.30% on rediscovery set.",
            "comparative_results": "Slightly worse than GrEDeL (Mean Rank 29.44 vs 27.05; Hits@10 31.30% vs 33.04%).",
            "domain_specific_findings": "Considers multiple path features but lacks sequential modeling of entity order/dependencies, limiting mechanistic detail.",
            "uuid": "e2403.7"
        },
        {
            "name_short": "SemaTyP",
            "name_full": "SemaTyP: A knowledge graph based literature mining method for drug discovery",
            "brief_description": "A KG-based method that scores drug–disease associations by exploiting the distribution of semantic types of entities along connecting paths.",
            "citation_title": "Sematyp: A knowledge graph based literature mining method for drug discovery",
            "mention_or_use": "use",
            "system_name": "SemaTyP",
            "system_description": "Constructs features based on the distribution and patterns of UMLS semantic types on paths between drugs and diseases in a knowledge graph and uses these to score and rank candidate drug–disease associations.",
            "research_domain": "biomedical literature mining / drug discovery",
            "problem_type": "targeted hypothesis generation (drug therapies)",
            "novelty_metric": null,
            "novelty_score": null,
            "feasibility_metric": null,
            "feasibility_score": null,
            "tradeoff_evidence": null,
            "optimization_strategy": "semantic-type-distribution scoring (no explicit novelty–feasibility tradeoff optimization).",
            "human_evaluation": false,
            "human_evaluation_results": null,
            "comparative_baseline": "Compared in rediscovery tests: SemaTyP Not Found=0, Mean Rank=29.87, Hits@10=30.58%",
            "comparative_results": "GrEDeL outperforms SemaTyP (Mean Rank 27.05 vs 29.87; Hits@10 33.04% vs 30.58%).",
            "domain_specific_findings": "Type-based features capture semantic patterns useful for discovery but are limited by number of semantic types (133) and cannot fully disambiguate entities.",
            "uuid": "e2403.8"
        },
        {
            "name_short": "Random-walk methods (RWA / NRWRH / TP-NRWRH)",
            "name_full": "Random-walk-based algorithms for candidate scoring (basic RWA, NRWRH, TP-NRWRH)",
            "brief_description": "Graph-based scoring algorithms that estimate the proximity or connectivity between candidate drugs and diseases using random walks (with or without restart) on heterogeneous networks.",
            "citation_title": "Drug-target interaction prediction by random walk on the heterogeneous network",
            "mention_or_use": "use",
            "system_name": "Random-walk based algorithms (RWA, NRWRH, TP-NRWRH)",
            "system_description": "Basic RWA: simulate random walks from candidate drug nodes for n steps to compute reachability/probability scores to disease nodes (expected number of steps n controls neighborhood breadth). NRWRH: network-based random walk with restart adapted to heterogeneous networks to infer drug–target interactions. TP-NRWRH: two-pass variant improving NRWRH. Scores are used to rank candidate drugs for diseases.",
            "research_domain": "network-based drug discovery / graph algorithms",
            "problem_type": "targeted scoring and ranking of candidate associations",
            "novelty_metric": null,
            "novelty_score": null,
            "feasibility_metric": null,
            "feasibility_score": null,
            "tradeoff_evidence": "Paper reports qualitative behavior: increasing RWA step count increases coverage (reduces Not Found) but can lower ranking quality for gold standards beyond an optimal step due to many additional candidates; no explicit novelty–feasibility tradeoff metrics.",
            "optimization_strategy": "tune walk length / restart behavior to balance local specificity vs coverage; NRWRH/TP-NRWRH incorporate semantic types to improve relevance.",
            "human_evaluation": false,
            "human_evaluation_results": null,
            "comparative_baseline": "Used as baselines; basic RWA (steps 1..6), NRWRH and TP-NRWRH.",
            "comparative_results": "Basic RWA performance varies with steps (RWA_3 best Mean Rank=30.33, but RWA_2 had best Hits@10 among basics at 24.46%). NRWRH Mean Rank=32.17 Hits@10=26.09%; TP-NRWRH Mean Rank=31.13 Hits@10=27.83%. GrEDeL outperforms these methods.",
            "domain_specific_findings": "Random-walk methods can be effective but are sensitive to walk-length hyperparameters; incorporating semantic types improves results.",
            "uuid": "e2403.9"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Fish oil, Raynaud's syndrome, and undiscovered public knowledge",
            "rating": 2
        },
        {
            "paper_title": "Exploiting semantic relations for literature-based discovery",
            "rating": 2
        },
        {
            "paper_title": "Context-driven automatic subgraph creation for literature-based discovery",
            "rating": 2
        },
        {
            "paper_title": "Drug repurposing using a semantic knowledge graph",
            "rating": 2
        },
        {
            "paper_title": "Exploiting semantic patterns over biomedical knowledge graphs for predicting treatment and causative relations",
            "rating": 2
        },
        {
            "paper_title": "Sematyp: A knowledge graph based literature mining method for drug discovery",
            "rating": 2
        },
        {
            "paper_title": "Drug-target interaction prediction by random walk on the heterogeneous network",
            "rating": 2
        },
        {
            "paper_title": "Inferring new indications for approved drugs via random walk on drug-disease heterogenous networks",
            "rating": 2
        }
    ],
    "cost": 0.0176615,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>GrEDeL: A Knowledge Graph Embedding Based Method for Drug Discovery From Biomedical Literatures</h1>
<p>SHENGTIAN SANG ${ }^{\ominus 1}$, ZHIHAO YANG ${ }^{\ominus 1}$, XIAOXIA LIU ${ }^{1}$, LEI WANG ${ }^{2}$, HONGFEI LIN ${ }^{\ominus 1}$, JIAN WANG ${ }^{1}$, AND MICHEL DUMONTIER ${ }^{3}$<br>${ }^{1}$ College of Computer Science and Technology, Dalian University of Technology, Dalian 116023, China<br>${ }^{2}$ Beijing Institute of Health Administration and Medical Information, Beijing 100191, China<br>${ }^{3}$ Institute of Data Science, Maastricht University, 6229 ER Maastricht, The Netherlands<br>Corresponding authors: Zhihao Yang (yangzh@dlut.edu.cn) and Lei Wang (wangleibihami@gmail.com)</p>
<p>This work was supported in part by the National Key Research and Development Program of China under Grant 2016YFC0901902, in part by the Natural Science Foundation of China under Grant 61272373, Grant 61572102, and Grant 61572098, and in part by the Trans-Century Training Program Foundation for the Talents by the Ministry of Education of China under Grant NCET-13-0084.</p>
<h4>Abstract</h4>
<p>Drug discovery is the process by which new candidate medications are discovered. Developing a new drug is a lengthy, complex, and expensive process. Here, in this paper, we propose a biomedical knowledge graph embedding-based recurrent neural network method called GrEDeL, which discovers potential drugs for diseases by mining published biomedical literature. GrEDeL first builds a biomedical knowledge graph by exploiting the relations extracted from biomedical abstracts. Then, the graph data are converted into a low dimensional space by leveraging the knowledge graph embedding methods. After that, a recurrent neural network model is trained by the known drug therapies which are represented by graph embeddings. Finally, it uses the learned model to discover candidate drugs for diseases of interest from biomedical literature. The experimental results show that our method could not only effectively discover new drugs by mining literature, but also could provide the corresponding mechanism of actions for the candidate drugs. It could be a supplementary method for the current traditional drug discovery methods.</p>
<p>INDEX TERMS Drug discovery, biomedical knowledge graph, recurrent neural network, deep learning.</p>
<h2>I. INTRODUCTION</h2>
<p>Drug discovery is defined as the process whereby a drug candidate or lead compound is identified and partially validated for the treatment of a specific disease [1]. It is a lengthy and expensive process, which is estimated to take 14 years and cost approximately $\$ 1.8$ billion for developing one drug [2]. In contrast, literature based discovery (LBD) is a much less time-consuming and expensive approach to identify new drugs for indications [3]. It has been successfully applied in the field of biomedicine [4]. The LBD was pioneered by Don R. Swanson (1924-2012) who found dietary fish oils (A) might be used to treat Raynaud's disease (C) based on their shared connections to blood viscosity (B) in literature [5]. This hypothesis was clinically confirmed by DiGiacomo et al. two years later [6]. Swanson's method is called the ABC model which hypothesizes the combination of two separately published premises "A implies B" and "B implies C" indicates a relationship between A and C. Since
then, a series of automatic ABC model based methods have been introduced to discover drugs from literature [7]-[9]. Cooccurrence methods are the basic ABC model based literature mining techniques which directly use co-occurrences in text as relationships between terms [9]. Directly using co-occurrences could capture all possible relations in text. However, the main issue of co-occurrence methods is that the extracted relationships lack logical explanations [10]. Furthermore, some extracted pairs of entities with high cooccurrence frequency could be completely uncorrelated actually [11]. In order to solve the problem, many sophisticated semantic models have been developed, which employ natural language processing methods to determine what constitutes a relationship [12], [13]. In addition, Hristovski et al. [14] introduced discovery patterns which serve as an effective filtering method that reduces the number of false positive discoveries and also supports explanation of discoveries. Although semantic models increase the precision of linking,</p>
<p>the major limitation of above semantic models is that more complex associations will go undetected due to semantic models are restricted to the ABC paradigm [3]. More recently, a series of literature mining methods have utilized knowledge graph to discover complex associations. Cameron et al. [15] introduced an automatic subgraph model which first clusters semantic paths in a semantic graph and then elucidates the latent associations between biomedical entities by the corresponding clusters. Malas et al. [16] leverage knowledge graph features such as the total number of intermediate concepts, the number of different semantic categories, and the predicates connecting a drug-disease pair to predict novel drug-disease associations. Bakalb and Talari [17] exploit simple paths connecting biomedical entities as features of logistic regression model to discover drugs. In our previous work, we introduced a biomedical knowledge graph based inference method - SemaTyP - which exploits the distribution of semantic types of entities to discover drug therapies [18]. The limitations of above knowledge graph based methods are: Cameron's method is mainly used to explain the associations between drug and disease, rather than discover new drugs. Malas' method can not find complex associations between drugs and diseases. Bakalb's method and SemaTyP can not capture the dependencies of entities in the drug-targetdisease associations due to the logistic regression model does not consider the order of entities in the associations. In addition, the two methods can not provide the detailed drug mechanism of action. Besides the above methods, recently, significant amount of research attentions have been drawn to leverage various deep learning based approaches in the field of drug discovery [19]-[21]. However, these methods focus on identifying interactions between known drugs and targets from existing biomedical databases without considering the known knowledge contained in the huge amount of biomedical literature. In conclusion, although literaturebased discovery is a powerful paradigm with potential to complement traditional drug discovery methods, there is still considerable room for improvement in mining literature for new drug therapies.</p>
<p>In this paper, we propose a biomedical knowledge Graph Embedding based Deep Learning method - GrEDeL - to discover potential drugs from literature. Firstly, a biomedical knowledge graph was constructed with the relations extracted from PubMed abstracts. Compared with our previous work [18], the biomedical knowledge graph constructed in this work differentiates semantic types of entities. Secondly, we proposed to use the knowledge graph embedding method to convert the knowledge graph into low dimensional vector space. The embeddings of entities and relations could not only preserve the structures of the knowledge graph but also capture the semantic information of entities and relations. After that a Long Short-Term Memory Networks (LSTM) model was trained by known drug therapies from Therapeutic Target Database. Finally, the trained model was used to discover potential drugs from literature. The experimental results show that our method could not only discover
drugs for diseases of interest, but also could provide corresponding potential mechanism of actions for the candidate drugs.</p>
<p>Our contributions are two-fold:</p>
<ul>
<li>We are the first to consider the process of literaturebased discovery as a series analysis problem.</li>
<li>We propose a knowledge graph based deep learning framework for LBD. To the best of our knowledge, this is the first method that employs deep learning method combined with knowledge graph for drug discovery. Additionally, we demonstrate the usefulness of graph embedding-based features for predicting potential drugdisease associations.
The rest of this paper is organized as follows. Section II introduces the related data and tools used in our work. In Section III, we present the details of the proposed method. Subsequently, we describe different evaluation metrics used in this paper and the experimental results in Section IV. Section V is the discussion part and Section VI presents our conclusion.</li>
</ul>
<h2>II. RELATED MATERIALS</h2>
<h2>A. DATABASE</h2>
<p>1) PubMed DATABASE</p>
<p>PubMed comprises citations for biomedical literature from MEDLINE and life science journals. Currently, PubMed contains over 26 million biomedical abstracts, which represents an enormous corpus that could be used for drug discovery [3]. The knowledge graph used in this work was constructed with the relations extracted from the PubMed abstracts.</p>
<h2>2) UMLS SEMANTIC NETWORK</h2>
<p>The Unified Medical Language System (UMLS) semantic network consists of 133 semantic types that provide a consistent categorization of all concepts represented in the UMLS Metathesaurus, and 54 semantic relations that exist between semantic types [22], [23].</p>
<h2>3) THERAPEUTIC TARGET DATABASE</h2>
<p>Therapeutic Target Database (TTD) is a database which provides information about the known and explored therapeutic protein and nucleic acid targets, the targeted disease, pathway information and the corresponding drugs directed at each of these targets [24]. In this work, we constructed the training and test data sets by utilizing the drug-disease associations in TTD.</p>
<h2>B. RELATED TOOLS AND TECHNIQUES</h2>
<p>1) SemRep</p>
<p>SemRep is a program that extracts semantic predications from biomedical free text [25]. Predications consist of a subject argument, an object argument, and the relation that binds them. For example, from the sentence "Hydrocortisone increased slow wave sleep activity.", SemRep extracts a predication:</p>
<ul>
<li>Hydrocortisone|phsu increase|AUGMENTS Sleep, Slow-Wave|phsu</li>
</ul>
<p>SemRep assigns a UMLS semantic type to the entity and relation (the black bold abbreviation on the right of ' $\mid$ '). For example, 'phsu' represents 'Pharmacologic Substance'. In this paper, the abbreviations are used to represent UMLS semantic types.</p>
<h2>2) KNOWLEDGE GRAPH</h2>
<p>Knowledge graphs (KGs) about entities, their properties, and the relationships between entities, have become an important asset for semantic search, analytics, and smart recommendations over Web contents and other kinds of big data. Notable knowledge graph systems include Freebase [26], DBpedia [27], YAGO [28] and many others. In the biomedical domain, KG such as the Gene Ontology and the Disease Ontology are prominent examples of the rich knowledge that are digitally available. In our previous work, we constructed a biomedical knowledge graph SemKG - covering a wide range of terminology in multiple biomedical domains [18]. However, in SemKG, the same entity with different semantic types is considered to be the same one. In this work, we constructed a biomedical knowledge graph which differentiates semantic types of entity and relations.</p>
<h2>3) KNOWLEDGE GRAPH EMBEDDING</h2>
<p>Graph embedding methods convert the graph data into a low dimensional space in which the graph structural information and graph properties are maximally preserved [29]. Let $h$, $r, t$ denote head, tail and relation of one edge in knowledge graph, knowledge graph embedding methods follow a common assumption $\mathbf{h}<em r="r">{r}+\mathbf{r} \approx \mathbf{t}</em>}$, where $\mathbf{h<em r="r">{r}$ and $\mathbf{t}</em>$ are either the original vectors of $h$ and $t$, or the transformed vectors under a certain transformation with respect to $r$. The forerunner TransE [30] is adopted in this work as the knowledge graph embedding method for converting entities and relations of knowledge graph into vectors.</p>
<h2>4) RECURRENT NEURAL NETWORK</h2>
<p>Recurrent Neural Networks (RNNs) are, in general, good at capturing temporal dependencies in data and hence are effective in many time-series analysis applications [31]. However, RNNs have trouble learning time-dependencies more than a few time steps long [32] and suffer from severe overfitting problems [33]. To learn long-term dependencies, an alternative RNN architecture, Long Short Term Memory (LSTM), has been proposed to solve the long term dependency problem [34]. In addition, dropout technique which drops out units (hidden and visible) in a neural network was used to solve the overfitting problems of RNNs [33]. In this paper, we propose a LSTM-based RNN model which incorporates the drug-target-disease sequential data and the structures of knowledge graph to discover drugs from literature.</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>FIGURE 1. An illustration of constructing knowledge graph. There are two relations extracted by SemRep on the top of the figure. The figure shows the same entity (hydrocortisone) with different UMLS semantic types (horm and phsu) is considered as different nodes in the graph.</p>
<h2>III. METHOD</h2>
<p>Here, we consider the process of drug discovery as a drug-target-disease sequential data analysis problem. For example, the process by which chlorpromazine functions to produce a pharmacological effect on cardiac hypertrophy is as follows [35]:
chlorpromazine $\rightarrow$ INHIBITS $\rightarrow$ calmodulin
calmodulin $\rightarrow$ STIMULATES $\rightarrow$ calcineurin
calcineurin $\rightarrow$ CAUSES $\rightarrow$ cardiac hypertrophy
The chlorpromazine acts on cardiac hypertrophy through a series of entities. Since RNNs are well-suited for analyzing sequential data, we proposed a LSTM-based RNN model to predict drug-target-disease associations.</p>
<p>In this section, we first present the biomedical knowledge graph constructed in this study. Then, we introduce a novel approach called GrEDeL which integrates knowledge graph embeddings and LSTM model to score potential associations between drugs and diseases. After that, the trained drug discovery model is implemented to discover potential drugs for diseases.</p>
<h2>A. CONSTRUCTION OF BIOMEDICAL KNOWLEDGE GRAPH</h2>
<p>For constructing a biomedical knowledge graph, we first employed SemRep to extract predications from PubMed abstracts, then the predications were used to build the knowledge graph. Figure 1 is an illustration of constructing the knowledge graph, it shows that the same entity with different semantic types is considered as different nodes in the knowledge graph. In this paper, $E=\left{e_{1}, e_{2}, \ldots, e_{N}\right}$ denotes entities (an entity is a UMLS Metathesaurus concept) of the knowledge graph, $R=\left{r_{1}, r_{2}, \ldots, r_{M}\right}$ denotes the relations between entities and $T=\left{t_{1}, t_{2}, \ldots, t_{K}\right}$ is the set of semantic types of entities and relations. The elements of $T$ are all from the UMLS semantic network.</p>
<h2>B. PREPARATION OF TRAINING DATA</h2>
<p>Given a knowledge graph KG, a path $\pi$ is defined as a sequence of predications $e_{0} r_{0} e_{1} r_{1} e_{2} r_{2} \ldots$. In this work, a gold standard case is represented as drug-target-disease triple, which means the drug can treat the disease by</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>FIGURE 2. The framework of GrEDeL. The blue circle denotes entity and the purple node denotes the entity's corresponding semantic type.
acting on the target. We first employed the path exploring method described in our previous work to construct training data [18]. More concretely, we obtained $\pi^{\ell}=$ $\rho\left(\right.$ drug $<em i="i">{i} \rightarrow$ disease $</em> ;$ target $<em i="i">{i}, \ell$ ), which encodes all the paths of length $\ell$ reaching node disease ${ }</em>$ from source node drug $<em i="i">{i}$ and crossing node target $</em>}$. Then $\pi^{\ell}=\left{\pi_{1}^{\ell}, \pi_{2}^{\ell}, \pi_{3}^{\ell}, \pi_{4}^{\ell} \ldots\right}$ is the set of all $\ell$ length paths. In addition, the paths in $\pi^{\ell}$ containing broad concept entities [10] are discarded. An entity $e_{i}$ is considered as a broad concept entity when the type of $e_{i}$ belongs to broad semantic types, because that the path containing broad concept entities can not express the drug mechanism of action for the particular disease. For example, the type of $e_{i}$ in $\pi=e_{0} r_{0} \ldots e_{i} \ldots r_{\ell-1} e_{\ell}$ is "Animal (anim)" or "Manufactured Object (mnob)", then path is filtered out. After that, all paths in $\boldsymbol{\mathcal { I }}=\left{\pi^{2}, \pi^{3} \ldots \pi^{\ell}\right}$ are considered as positive training data. Similarly, we constructed negative data set by exploring false cases drug ${ <em i="i">{i}^{\prime}$-target $</em>}^{\prime}$-disease ${ <em j="j">{j}^{\prime}$. Each false case denotes that the drug ${ }</em>}^{\prime}$ has no therapeutic effect on the disease ${ <em j="j">{j}^{\prime}$ or the corresponding drug target is not the target $</em>$.}^{\prime</p>
<h2>C. GRAPH EMBEDDING-BASED LSTM DRUG DISCOVERY MODEL</h2>
<p>Given a path $\pi_{i}^{\ell}=e_{0} r_{0} e_{1} r_{1} \ldots r_{\ell-1} e_{\ell}$ where $e_{0}$ indicates a drug and $e_{\ell}$ indicates a disease. The objective of our model is to predict the probability of the association between a potential drug and the disease of interest:</p>
<p>$$
p\left(y \mid \pi_{i}^{\ell}\right)=D\left(g\left(\pi_{i}^{\ell}\right), \theta\right)
$$</p>
<p>where $p\left(y=1 \mid \pi_{i}^{\ell}\right)$ is the probability of the candidate drug for treating the disease and $D($.$) represents any kind of discriminative model with trainable parameter \theta . g($.$) is a function for graph embedding feature extraction. Figure 2 is an illustration of our model.</p>
<h2>1) GRAPH EMBEDDING BASED FEATURE EXTRACTION</h2>
<p>As input $\pi_{i}^{l}$ is represented as a series of entity names, it is difficult to investigate the relation between entities. Thus, we applied TransE to the input $\pi_{i}^{l}$ to learn more dense representations. In TransE, if a relationship ( $e_{\text {head }}, r, e_{\text {tail }}$ ) holds, then the embedding of $e_{\text {tail }}$ should be close to the embedding of $e_{\text {head }}$ plus the embedding of $r$. To obtain both the graph structural information and the relations between semantic types, the biomedical knowledge graph was transformed into two graphs - Semantic Graph ( $S G$ ) and Type Graph ( $T G$ ). Semantic Graph contains entities and relations. Type Graph contains semantic types of entities and relations. In addition, $x_{i}$ represents element of $\pi_{i}^{\ell}=e_{0} r_{0} e_{1} r_{1} \ldots r_{\ell-1} e_{\ell}$ ( $x_{i}$ could be either an entity $e$ or relation $r$ ), then each element $x_{i}$ of $\pi_{i}^{l}$ is embedded as follows:</p>
<p>$$
\mathbf{x}<em i="i">{i}=g\left(x</em>\right)<em i="i">{S G} \bowtie g\left(x</em>
$$}\right)_{T G</p>
<p>where $g($.$) is a function for graph embedding based feature$ extraction and symbol $\bowtie$ is concatenation of two vectors. To learn the vector embeddings of the entities and relations in the Semantic Graph (the process of $g\left(x_{i}\right)<em _left_e__1="\left(e_{1">{S G}$ ), we minimize the loss function $L$ over the training set $S$ and $S^{\prime}$ :
$L=\sum</em>}, r, e_{2}\right) \in S} \sum_{\left(e_{1}^{\prime}, r, e_{2}^{\prime}\right) \in S^{\prime}}\left[\gamma+d\left(\mathbf{e<em _mathbf_2="\mathbf{2">{\mathbf{1}}+\mathbf{r}, \mathbf{e}</em>}}\right)-d\left(\mathbf{e<em _mathbf_2="\mathbf{2">{\mathbf{1}}^{\prime}+\mathbf{r}, \mathbf{e}</em>\right)\right]}}^{\prime<em _mathbf_1="\mathbf{1">{+}$
where bold font indicates vector embedding of the corresponding element (For example, $\mathbf{e}</em>]}}$ is the embedding of $e_{1}$ ). In addition, $[\mathrm{x<em 1="1">{+}$denotes the positive part of $\mathrm{x}, d$ is $L</em>$ does not appear in $S$ ):}$-norm and $\gamma&gt;0$ is a margin hyperparameter. The positive training set $S_{\left(e_{1}, r, e_{2}\right)}$ contains all the triplets $\left(e_{1}, r, e_{2}\right)$ in Semantic Graph, and the negative training set $S^{\prime}$ is constructed by replacing $e_{1}$ or $e_{2}$ of triplets in $S$ with a random entity (each triplet of $S^{\prime</p>
<p>$$
S_{\left(e_{1}, r, e_{2}\right)}^{\prime}=\left{\left(e_{1}^{\prime}, r, e_{2}\right) \mid e_{1}^{\prime} \in E\right} \cup\left{\left(e_{1}+r, e_{2}^{\prime}\right) \mid e_{2}^{\prime} \in E\right}
$$</p>
<p>The optimization procedure is carried out by stochastic gradient descent and the process of embedding the Type Graph $\left(g\left(x_{i}\right)<em i="i">{T G}\right)$ is same as $g\left(x</em>\right)<em e="e">{S G}$. The theoretical number of parameters for training TransE is $O\left(n</em>$ is the number of entities and relations, respectively, and $k$ is the dimension of graph embedding vector.} k+n_{r} k\right)$, where $n_{e}$ and $n_{r</p>
<p>After obtaining embedding $\mathbf{x}<em i="i">{i}$ of $x</em>$ is given as follows:}$, new input matrix $\mathbf{X}$ for $\pi_{i}^{l</p>
<p>$$
\mathbf{X}<em i="i">{\pi</em>
$$}^{l}}=\bigcup_{x_{i} \in \pi_{i}^{l}} \mathbf{x}_{i</p>
<p>The $\pi_{i}^{\ell}$ is converted into a $\left(L_{S G}+L_{T G}\right) * \ell$ matrix, where $L_{S G}$ and $L_{T G}$ are the length of SG and TG embedding vector, respectively. The left part of Figure 2 illustrates the process of graph embedding based feature extraction. We found that concatenation of the embedding vectors of an entity and its semantic type could give a slight improvement of the performance for drug discovery, this will be further discussed in the result section.</p>
<h2>2) MODEL DESCRIPTION</h2>
<p>We employed a recurrent neural network with long short term memory model to capture the dependencies between entities of drug-disease associations. Considering a single hidden layer network in which $x_{t}, h_{t}$ and $y_{t}$ denote the input, hidden and output layer neuron outputs, respectively, a general</p>
<p>recurrent network can be described as:</p>
<p>$$
h_{t}=\sigma\left(W_{x h} x_{t}+W_{h h} h_{t-1}+b_{h}\right)
$$</p>
<p>where, $W_{x h}, W_{h h}$ and $b_{h}$ are the weight matrices across different connections and $\sigma$ is a basic sigmoid function $(\sigma(x)=$ $\left.\frac{1}{1+e^{-x}}\right)$. Note that $h_{0}=e_{0}$ for our task. The dimension of fully connected layer in Figure 2 is $T^{*} 1$, where $T$ is the hidden layer dimension of RNN model. The probability for the $d r u g_{i}$ -target $<em i="i">{i}$-disease $</em>$ is given as follows:}$ association $\pi_{i}^{\ell</p>
<p>$$
p\left(y_{j}=1 \mid \mathbf{X}\right)=\sigma\left(V_{h \ell} h_{\ell}\right)
$$</p>
<p>where $\mathbf{X}$ represents the embeddings of input $\pi_{i}^{\ell} . V_{h \ell}$ is the fully connected output layer, the dimension of $V_{h \ell}$ is $1^{*} H, H$ is the dimension of hidden layer, respectively. Since RNNs have difficulties learning long-range dependencies, we adopted a LSTM as the drug discovery model in our experiment. LSTMs are explicitly designed to avoid the long-term dependency problem. It solves the gradient vanishing and exploding problem by introducing memory cell and forget gate. The LSTM is constructed as follows:</p>
<p>$$
\begin{aligned}
&amp; i_{t}=\sigma\left(W_{x i} x_{t}+W_{h i} h_{t-1}+b_{i}\right) \
&amp; f_{t}=\sigma\left(W_{x f} x_{t}+W_{h f} h_{t-1}+b_{f}\right) \
&amp; o_{t}=\sigma\left(W_{x o} x_{t}+W_{h o} h_{t-1}+b_{o}\right) \
&amp; g_{t}=\tanh \left(W_{x g} x_{t}+W_{h g} h_{t-1}+b_{g}\right) \
&amp; c_{t}=f_{t} \odot c_{t-1}+i_{t} \odot g_{t} \
&amp; h_{t}=o_{t} \odot \tanh \left(c_{t}\right)
\end{aligned}
$$</p>
<p>where $i_{t}, f_{t}$ and $o_{t}$ are input gate, forget gate and output gate, respectively. The current cell state $c_{t}$ will be generated by calculating the weighted sum using both previous cell state and current information generated by the cell. Trainable parameters are the weight matrices $W_{<em>}$ and $b_{</em>} . \odot$ denotes element-wise multiplication. After obtaining the hidden state of LSTM, probability for drug-disease association is calculated as Equation 7.</p>
<p>We added a dropout layer to the non recurrent part of the LSTM to mitigate overfitting problem when training our model. Finally, we defined and optimized a cross entropy loss function $L(\theta)$ as follows:</p>
<p>$$
L(\theta)=-\frac{1}{n} \sum_{i=1}^{n} \gamma \ln \left(p\left(y \mid \mathbf{X}<em i="i">{i}\right)\right)+(1-y) \ln \left(1-p\left(y \mid \mathbf{X}</em>\right)\right)
$$</p>
<p>where y is 1 or 0 . Our model was trained with back propagation through time [36].</p>
<h2>D. IMPLEMENTATION FOR DRUG DISCOVERY</h2>
<p>The trained LSTM model was used for discovering potential drugs for the disease of interest. To evaluate a potential treatment drug ${ }<em _potential="{potential" _text="\text">{\text {potential }}$-target ${ }</em>}}$-disease, first a set of paths $\mathbb{\pi<em _potential="{potential" _text="\text">{\text {potential }}=\left{\rho\left(\right.\right.$ drug $</em> \rightarrow$ disease; target $}<em _potential="{potential" _text="\text">{\text {potential }}, 2 \ldots \ell)}$ were obtained. Then the score of the drug $</em>$ is calculated as:}</p>
<p>$$
\operatorname{score}\left(\text { drug }<em _pi__i="\pi_{i">{\text {potential }}\right)=\max </em>} \in \mathbb{\pi<em i="i">{\text {potential }}} D\left(g\left(\pi</em>\right), \theta\right)
$$</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>FIGURE 3. The features used in the comparing methods is the concatenation of the graph embedding vectors of training case.</p>
<p>Since the treatment of the disease is unknown, all pharmaceuticals could be potential drugs for one specific disease. Then all possible drugs were tested as candidate drugs for treating disease. Finally, we ranked all the candidate drugs by their scores.</p>
<h2>E. BASELINE METHODS</h2>
<p>To evaluate the performance of our method, we conducted ten-fold cross-validation and drug rediscovery test.</p>
<h2>1) BASELINE METHODS FOR CROSS VALIDATION</h2>
<p>Recently, numerous machine learning methods have been applied to predict drug target interactions [37]. The commonly used machine learning methods take drug target pairs as input, and the output of the methods is whether there is an interaction between a drug target pair. The most applied and successful machine learning models are binary classifiers such as logistic regression (LR), random forest (RF) [38] and support vector machine (SVM) [39]. Here, we used the most applied models as our baseline models for cross validation. The baseline models and our model used for the evaluations are as follows:</p>
<ul>
<li>Logistic Regression (LR).</li>
<li>Random Forest (RF).</li>
<li>Support Vector Machine (SVM).</li>
<li>GrEDeL: our proposed graph embedding based LSTM model.
Features for the competitive methods were constructed in the same way as our model. The features of one element in drug-disease association is the concatenation of Semantic Graph embedding and Type Graph embedding. Figure 3 is an illustration of features used in the competitive methods. As shown in Figure 3, the input vector of the methods (LR, RF and SVM) is the concatenation of the graph embedding vectors of the training case.</li>
</ul>
<h2>2) BASELINE METHODS FOR DRUG REDISCOVERY</h2>
<p>In this test, we compared our method with basic random walk method, two graph-based drug repositioning methods NRWRH [40] and TP-NRWRH [41] - and three state-of-theart knowledge graph based drug discovery methods Malas's method [16], Bakalb's method [17] and SemaTyP [18].</p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>FIGURE 4. An illustration of RWA-based methods for drug discovery.</p>
<p>Specifically, NRWRH and TP-NRWRH are both graph-based random walk with restart algorithms [42]. NRWRH is a network-based random walk with restart method for inferring potential drug-target interactions. TP-NRWRH improves NRWRH by introducing a two-pass random walk algorithm. The process of discovering candidate drugs for disease; by RWA-based methods is as follows: First, the RWA algorithm starts from the drug $<em _potential="{potential" _text="\text">{\text {potential }}$ point and the expected number of steps is set to n . Then, the drug $</em>$, RWA-based methods score all drugs for the disease of interest. At last, all candidate drugs could be ranked by their scores. Figure 4 illustrates an example of evaluating "chlorpromazine" to be the treatment of "cardiachypertrophy". The left part of Figure 4 is a weighted semantic graph. The right part of Figure 4 presents the results of basic RWA method with starting point "chlorpromazine". It shows that when the expected number of step is 1 , the score of "chlorpromazine" is 0 due to "chlorpromazine" can not reach "cardiachypertrophy" in one step. Similarly, the score of "chlorpromazine"-"cardiachypertrophy" association is 0.0825 which is assigned by step_2 RWA. As shown in Figure 4, the highest score of "chlorpromazine" for treating "cardiachypertrophy" is 0.697 when the step of RWA is set to 4 .}}$-disease; association could be scored by the RWA-based methods. After that, for each disease $_{i</p>
<p>In addition, Malas's method leverages knowledge graph features such as the total number of intermediate concepts, the number of different semantic categories, and the predicates connecting a drug-disease pair to predict novel drugdisease associations [16]. Bakalb's method exploits all the paths connecting biomedical entities as features of logistic regression model to discover drugs [17]. SemaTyP is a knowledge graph based drug discovery method which exploits the distribution of semantic types of entities to score drug $_{\text {potential }}$-disease; association [18].</p>
<h2>IV. RESULTS</h2>
<p>In this section, we firstly introduce the biomedical knowledge graph and training data. Then we evaluate the performance of graph embedding method on link predication test. After that, our method was evaluated on cross-validation and drug rediscovery test separately. In addition, case studies are conducted to confirm the ability of our model to find potential drugs for diseases.</p>
<p>TABLE 1. The description of biomedical knowledge graph.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Materials</th>
<th style="text-align: center;">Number</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">PubMed abstracts</td>
<td style="text-align: center;">22,769,789</td>
</tr>
<tr>
<td style="text-align: center;">predications</td>
<td style="text-align: center;">$39,133,975$</td>
</tr>
<tr>
<td style="text-align: center;">selected predications</td>
<td style="text-align: center;">$17,651,279$</td>
</tr>
<tr>
<td style="text-align: center;">entities of knowledge graph</td>
<td style="text-align: center;">$1,067,092$</td>
</tr>
<tr>
<td style="text-align: center;">relations of knowledge graph</td>
<td style="text-align: center;">$14,419,744$</td>
</tr>
<tr>
<td style="text-align: center;">entity types</td>
<td style="text-align: center;">133</td>
</tr>
<tr>
<td style="text-align: center;">relation types</td>
<td style="text-align: center;">52</td>
</tr>
</tbody>
</table>
<p>TABLE 2. The broad concept entity list for filtering.</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: left;"></th>
<th style="text-align: left;">Broad concept entities</th>
<th style="text-align: left;"></th>
<th style="text-align: left;"></th>
<th style="text-align: left;"></th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">plnt</td>
<td style="text-align: left;">alga</td>
<td style="text-align: left;">fngs</td>
<td style="text-align: left;">virs</td>
<td style="text-align: left;">rich</td>
<td style="text-align: left;">bact</td>
<td style="text-align: left;">arch</td>
</tr>
<tr>
<td style="text-align: left;">anim</td>
<td style="text-align: left;">imrt</td>
<td style="text-align: left;">vtht</td>
<td style="text-align: left;">amph</td>
<td style="text-align: left;">bird</td>
<td style="text-align: left;">fish</td>
<td style="text-align: left;">rept</td>
</tr>
<tr>
<td style="text-align: left;">mamm</td>
<td style="text-align: left;">hamn</td>
<td style="text-align: left;">anst</td>
<td style="text-align: left;">emst</td>
<td style="text-align: left;">cgab</td>
<td style="text-align: left;">acab</td>
<td style="text-align: left;">ffas</td>
</tr>
<tr>
<td style="text-align: left;">bdsy</td>
<td style="text-align: left;">evnt</td>
<td style="text-align: left;">acty</td>
<td style="text-align: left;">bhvr</td>
<td style="text-align: left;">socb</td>
<td style="text-align: left;">inbe</td>
<td style="text-align: left;">dora</td>
</tr>
<tr>
<td style="text-align: left;">ocac</td>
<td style="text-align: left;">hlca</td>
<td style="text-align: left;">lbpr</td>
<td style="text-align: left;">diap</td>
<td style="text-align: left;">topp</td>
<td style="text-align: left;">resa</td>
<td style="text-align: left;">mbrt</td>
</tr>
<tr>
<td style="text-align: left;">gora</td>
<td style="text-align: left;">edac</td>
<td style="text-align: left;">mcha</td>
<td style="text-align: left;">phpr</td>
<td style="text-align: left;">hcpp</td>
<td style="text-align: left;">eehu</td>
<td style="text-align: left;">npop</td>
</tr>
<tr>
<td style="text-align: left;">phob</td>
<td style="text-align: left;">mnob</td>
<td style="text-align: left;">medd</td>
<td style="text-align: left;">resd</td>
<td style="text-align: left;">cnce</td>
<td style="text-align: left;">idcn</td>
<td style="text-align: left;">tmco</td>
</tr>
<tr>
<td style="text-align: left;">qlco</td>
<td style="text-align: left;">qnco</td>
<td style="text-align: left;">spco</td>
<td style="text-align: left;">geoa</td>
<td style="text-align: left;">ocdi</td>
<td style="text-align: left;">bmod</td>
<td style="text-align: left;">orgt</td>
</tr>
<tr>
<td style="text-align: left;">hcro</td>
<td style="text-align: left;">pros</td>
<td style="text-align: left;">shro</td>
<td style="text-align: left;">grup</td>
<td style="text-align: left;">prog</td>
<td style="text-align: left;">popg</td>
<td style="text-align: left;">famg</td>
</tr>
<tr>
<td style="text-align: left;">aggp</td>
<td style="text-align: left;">podg</td>
<td style="text-align: left;">grpa</td>
<td style="text-align: left;">food</td>
<td style="text-align: left;">sosy</td>
<td style="text-align: left;">anab</td>
<td style="text-align: left;">neop</td>
</tr>
</tbody>
</table>
<h2>A. THE BIOMEIDCAL KNOWLEDGE GRAPH AND TRAINING DATA</h2>
<p>The biomedical knowledge graph is constructed by extracting predications from the abstracts published in PubMed before June 1, 2013. In addition, in order to ensure the accuracy of extracted predication, we filtered out the predications that only appear once. Table 1 presents the details of the biomedical knowledge graph constructed in our work.</p>
<p>For building training set, on one side, we selected 7,144 drug-target-disease triplets from TTD as true cases. Then following the process in Section III-B, we obtained $6,188,265$ positive training data. The $\ell$ was set to 4 as described in our previous work. The broad concept entities used are listed in Table 2. On the other side, we randomly constructed a set of drug $<em _random="{random" _text="\text">{\text {random }}$-target $</em>$-disease $}<em _random="{random" _text="\text">{\text {random }}$ cases for building false training data. Specifically, we kept the drug $</em>$-target $}<em _random="{random" _text="\text">{\text {random }}$-disease $</em>$ triplets that do not exist in TTD as false cases. In order to balance the positive and negative training data, $6,188,265$ negative training data were obtained by the the same process of constructing the positive training data.}</p>
<h2>B. KNOWLEDGE GRAPH EMBEDDING</h2>
<p>For evaluating the performance of knowledge graph embedding, we use the same evaluation protocols as in [30]. We selected subset of 'predications' which constructs the knowledge graph to evaluate graph embedding model. For each subset, $90 \%$ of the data were randomly selected as training data and the other $10 \%$ were test data. For each test triplet $\left(e_{\text {head }}, r, e_{\text {tail }}\right)$, the $e_{\text {tail }}$ is removed and replaced by each of the entities of test set. The dissimilarities of new triplets are first computed and then sorted by ascending order; the rank of the correct entity $e_{\text {tail }}$ is finally stored. Then the mean of those predicted ranks and hits@10 are reported.</p>
<p>TABLE 3. The performance of different models.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Methods</th>
<th style="text-align: left;">Precision</th>
<th style="text-align: left;">Recall</th>
<th style="text-align: left;">F-score</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">LR</td>
<td style="text-align: left;">0.715</td>
<td style="text-align: left;">0.889</td>
<td style="text-align: left;">0.791</td>
</tr>
<tr>
<td style="text-align: left;">RF</td>
<td style="text-align: left;">0.742</td>
<td style="text-align: left;">0.750</td>
<td style="text-align: left;">0.743</td>
</tr>
<tr>
<td style="text-align: left;">SVM</td>
<td style="text-align: left;">0.622</td>
<td style="text-align: left;">0.766</td>
<td style="text-align: left;">0.635</td>
</tr>
<tr>
<td style="text-align: left;">GrEDeL $_{M L P _2}$</td>
<td style="text-align: left;">0.699</td>
<td style="text-align: left;">0.896</td>
<td style="text-align: left;">0.785</td>
</tr>
<tr>
<td style="text-align: left;">GrEDeL $_{M L P _3}$</td>
<td style="text-align: left;">0.707</td>
<td style="text-align: left;">0.901</td>
<td style="text-align: left;">0.792</td>
</tr>
<tr>
<td style="text-align: left;">GrEDeL $_{M L P _4}$</td>
<td style="text-align: left;">0.715</td>
<td style="text-align: left;">0.889</td>
<td style="text-align: left;">0.793</td>
</tr>
<tr>
<td style="text-align: left;">GrEDeL $_{M L P _5}$</td>
<td style="text-align: left;">0.711</td>
<td style="text-align: left;">0.903</td>
<td style="text-align: left;">0.796</td>
</tr>
<tr>
<td style="text-align: left;">GrEDeL $_{R N N}$</td>
<td style="text-align: left;">0.819</td>
<td style="text-align: left;">0.938</td>
<td style="text-align: left;">0.874</td>
</tr>
<tr>
<td style="text-align: left;">GrEDeL</td>
<td style="text-align: left;">$\mathbf{0 . 8 8 1}$</td>
<td style="text-align: left;">$\mathbf{0 . 9 7 1}$</td>
<td style="text-align: left;">$\mathbf{0 . 9 2 4}$</td>
</tr>
</tbody>
</table>
<p>TABLE 4. Performance of knowledge graph embedding method.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Dataset</th>
<th style="text-align: left;">5,000</th>
<th style="text-align: left;">10,000</th>
<th style="text-align: left;">20,000</th>
<th style="text-align: left;">40,000</th>
<th style="text-align: left;">100,000</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Mean Ranks</td>
<td style="text-align: left;">305</td>
<td style="text-align: left;">261</td>
<td style="text-align: left;">176</td>
<td style="text-align: left;">122</td>
<td style="text-align: left;">108</td>
</tr>
<tr>
<td style="text-align: left;">Hits@10 (\%)</td>
<td style="text-align: left;">9.4</td>
<td style="text-align: left;">15.7</td>
<td style="text-align: left;">22.6</td>
<td style="text-align: left;">27.1</td>
<td style="text-align: left;">29.8</td>
</tr>
</tbody>
</table>
<p>TABLE 5. Example of link prediction results.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">INPUT ( $e_{\text {head }}$ and $r$ )</th>
<th style="text-align: left;">PREDICTED $e_{\text {tail }}$</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Cysteine STIMULATE</td>
<td style="text-align: left;">beta-Lactams, bathocuproine disulfonate,</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">hydrogen peroxide, Pheomelanin, N-</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">Methylaspartate, aspartic acid receptor, de-</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">oxyhemoglobin, IL2, Cyclic GMP, Anti-</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">neoplastic Agents</td>
</tr>
<tr>
<td style="text-align: left;">Alteplase INHIBITS</td>
<td style="text-align: left;">Cycloheximide, Urokinase, Plasminogen</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">Activator Inhibitor 1, Thromboxane-A</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">Synthase, Alteplase, alpha 1-Antitrypsin,</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">FASTK Gene, Thromboxane A2 Recep-</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">tor, Plasminogen Inactivators, Antithrom-</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">bin III</td>
</tr>
<tr>
<td style="text-align: left;">Heparin AUGMENTS</td>
<td style="text-align: left;">Megakaryocytopoiesis, thrombin activity,</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">Antiinflammatory Effect, growth factor</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">binding, anti-toxin activity, IgG binding,</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">Hemostatic function, Osteoclastic resorp-</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">tion, Nitrous oxide concentration, Tyro-</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">sine Phosphorylation</td>
</tr>
</tbody>
</table>
<p>The dimension of embedding was set to 100 and $\gamma=1$. Table 4 shows the results of embeddings of Semantic Graph, the 'Dataset' row represents the number of triplets selected from Semantic Graph. Table 5 presents three examples of link predication results: given the entity $e_{\text {head }}$ and the relation $r$, graph embedding method predicts the entity $e_{\text {tail }}$. The 'PREDICATED $e_{\text {tail }}$ ' column shows the top predicated $e_{\text {tail }}$ entities, the entity in bold is the known $e_{\text {tail }}$ entity. The results shows that graph embedding method could capture dependencies between entities and relations.</p>
<h2>C. TEN-FOLD CROSS VALIDATION</h2>
<p>We conducted ten-fold cross validations to evaluate the performance of the proposed GrEDeL against other three baseline methods in terms of commonly used measure: Precision, Recall and F-score. The dataset were split into ten subsets with equal size, and the positive and negative data in each subset is balanced. In particular, each subset does not share the same drug-disease pairs as other subsets in order to avoid overestimation of the training accuracy. Then each subset was taken in turn as a test set and other nine subsets were taken as input to run the methods. The average prediction accuracies</p>
<p>TABLE 6. The performance of GrEDeL with different knowledge graph embedding based features.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Methods</th>
<th style="text-align: left;">Precision</th>
<th style="text-align: left;">Recall</th>
<th style="text-align: left;">F-score</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">GrEDeL $_{\text {random }}$</td>
<td style="text-align: left;">0.608</td>
<td style="text-align: left;">0.759</td>
<td style="text-align: left;">0.68</td>
</tr>
<tr>
<td style="text-align: left;">GrEDeL $_{T G}$</td>
<td style="text-align: left;">0.773</td>
<td style="text-align: left;">0.824</td>
<td style="text-align: left;">0.797</td>
</tr>
<tr>
<td style="text-align: left;">GrEDeL $_{S G}$</td>
<td style="text-align: left;">0.819</td>
<td style="text-align: left;">$\mathbf{0 . 9 9 2}$</td>
<td style="text-align: left;">0.897</td>
</tr>
<tr>
<td style="text-align: left;">GrEDeL $_{S G+O G}$</td>
<td style="text-align: left;">$\mathbf{0 . 8 8 1}$</td>
<td style="text-align: left;">0.971</td>
<td style="text-align: left;">$\mathbf{0 . 9 2 4}$</td>
</tr>
</tbody>
</table>
<p>over the test subsets were regarded as overall performance measures.</p>
<p>Table 3 shows that GrEDeL outperforms LR, RF and SVM models. We argue that our method can effectively capture temporal dependencies in drug-disease sequences. To further investigate the impact of each components in GrEDeL model, performances of GrEDeL with various graph embedding-based features are reported in Table 3. Random embedding (GrEDeL $<em G="G" S="S">{\text {random }}$ ), Semantic Graph embedding only ( $\mathrm{GrEDeL}</em>$ ) and Type Graph embedding only (GrEDeL $<em _random="{random" _text="\text">{T G}$ ) based models were proposed to evaluate the performance of GrEDeL. Specifically, GrEDeL $</em>$ model uses the random embeddings for entities and relations, GrEDeL $}<em G="G" T="T">{S G}$ only uses semantic graph embedding for entities and relations (where the $\mathrm{L}</em>}=0$ ) and similarly, $\mathrm{L<em G="G" T="T">{S G}$ of GrEDeL $</em>$ is 0 . Table 3 shows that although GrEDeL $<em G="G" T="T">{T G}$ model only adopts type graph embeddings for the representation of knowledge graph, it still has reasonable performances. The reason is that the embedding of type graph could learn the rules of relations between entity types. This is similar as defining a semantic type pattern - such as drug-INHIBITES-protein-STIMULATESdisease - which could be used to select drug-disease associations based on their semantic types. However, there are only 133 entity types and 52 relation types in our knowledge graph (Table 1), which results in that GrEDeL $</em>}$ model can not differentiate different entities with the same semantic type. In addition, Table 3 shows that the semantic graph embedding based GrEDeL model ( $\mathrm{GrEDeL<em G="G" G_T="G+T" S="S">{S G}$ ) has significantly boosted the performance. What's more, knowledge graph embedding $\left(\mathrm{GrEDeL}</em>\right)$ outperforms other methods, the reason may be that knowledge graph embedding not only considers structure of knowledge graph but also preserves the information of semantic types. The graph embedding features capture rich information about the graph and entity-entity relations.</p>
<p>In additon, we replaced the LSTM of GrEDeL with other deep learning methods such as MLP (Multi-Layer Perceptron) and vanilla RNN in order to explore the influence of deep learning parts for GrEDeL. Table 3 presents the results and the $N$ in $\operatorname{GrEDeL}_{M L P _N}$ is the number of hidden layers of MLP. The number of parameters of MLP and RNN is $N *$ $n^{2}+n k+n m$ and $n^{2}+n k+n m$, respectively. Where $k, n$ and $m$ is the dimension of input layer, hidden layer and output layer, respectively. Table 7 shows the best performing dimension of hidden layer of MLP and RNN is 100 and 50, respectively. Although the total number of parameters of MLP is more than four times that of RNN, Table 3 shows the vanilla RNN based GrEDeL outperforms MLP based GrEDeL. The reason is that</p>
<p>TABLE 7. Validation hyper parameters. Steps of each range and selected values are shown.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Methods</th>
<th style="text-align: left;">Range</th>
<th style="text-align: left;">Step</th>
<th style="text-align: left;">Optimal</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">LSTM cell dimension</td>
<td style="text-align: left;">$[25-150]$</td>
<td style="text-align: left;">25</td>
<td style="text-align: left;">100</td>
</tr>
<tr>
<td style="text-align: left;">LSTM dropout</td>
<td style="text-align: left;">$[0.3-0.8]$</td>
<td style="text-align: left;">0.05</td>
<td style="text-align: left;">0.5</td>
</tr>
<tr>
<td style="text-align: left;">Hidden layer dimension of GrEDeL</td>
<td style="text-align: left;">$[10-100]$</td>
<td style="text-align: left;">10</td>
<td style="text-align: left;">30</td>
</tr>
<tr>
<td style="text-align: left;">$\mathrm{L}_{S G}$</td>
<td style="text-align: left;">$[25-100]$</td>
<td style="text-align: left;">25</td>
<td style="text-align: left;">100</td>
</tr>
<tr>
<td style="text-align: left;">$\mathrm{L}_{T G}$</td>
<td style="text-align: left;">$[10-50]$</td>
<td style="text-align: left;">10</td>
<td style="text-align: left;">10</td>
</tr>
<tr>
<td style="text-align: left;">Hidden layer dimension of MLP</td>
<td style="text-align: left;">$[10-100]$</td>
<td style="text-align: left;">100</td>
<td style="text-align: left;">100</td>
</tr>
<tr>
<td style="text-align: left;">Hidden layer dimension of RNN</td>
<td style="text-align: left;">$[10-100]$</td>
<td style="text-align: left;">10</td>
<td style="text-align: left;">50</td>
</tr>
</tbody>
</table>
<p>GrEDeL works well not because of deep learning structure but because of sequential characteristic. The performance improvement could come from sequential characteristics of RNN-based methods. In addition, LSTM based GrEDeL achieves better performances than vanilla RNN based method due to LSTM could learn long-term dependent relationships in the drug-target-disease associations.</p>
<p>We validated 5 different hyper parameters of our model (as shown in Table 7). Best performing parameter set on validation phase was used for the GrEDeL model. The Adam optimizer [43] was used for optimizing GrEDeL and the learning rate decay was set to 0.99 for every 100 iterations. Additionally, mini batch of size 500 was used. Implementations of LR, RF and SVM is based on Sklearn library.</p>
<h2>D. DRUG REDISCOVERY TEST</h2>
<p>We conducted drug rediscovery test to evaluate the performance of our method in discovering drugs for diseases of interest. Here, we adopted the same drug-disease relationships as used in our previous work for drug rediscovery test. In particular, in the path obtaining process of this work, we filtered out the paths between drug and disease that containing broad concepts. After the path exploring process, there are only 115 of the 360 standard relationships used in our previous work have paths in the knowledge graph. Then we used the 115 drug-disease relationships as gold standard cases for drug rediscovery test. For each gold standard cases, TTD has reported that the drug could treat the disease, but the corresponding drug targets are not clear. For evaluation, we used the same ranking procedure as described in [18]. Specifically, for each gold standard $d r u g_{i}$-disease $<em i="i">{i}$, we randomly selected other 100 drugs (including chemical entities and new biologic entities) from TTD as potential drugs for treating disease $</em>$. Then drug discovery models scored all the 101 drugs for treating the disease $<em i="i">{i}$. Lastly, the average ranking of standard drugs (mean ranks) among all the standard cases and the proportion of known drugs ranked in the top 10 (Hits@10) were reported to evaluate the performance of the models. For RWA-based methods (NRWRH and TP-NRWRH), if the standard $d r u g</em>$ of disease $<em i="i">{i}$ is not found by the drug discovery model, then the $d r u g</em>$ is scored 0 and the corresponding ranking is 101 . What's more, for SemaTyP and GrEDeL, we selected 5,785 targets from TTD as candidates drug targets for constructing drug $<em _candidate="{candidate" _text="\text">{i}$-target $</em>$ associations.}}$-disease $_{i</p>
<p>TABLE 8. Performance of discovering drugs for disease.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Method</th>
<th style="text-align: left;">Not Found</th>
<th style="text-align: left;">Mean Ranks</th>
<th style="text-align: left;">Hits@10 (\%)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">RWA_1</td>
<td style="text-align: left;">93</td>
<td style="text-align: left;">90.82</td>
<td style="text-align: left;">17.39</td>
</tr>
<tr>
<td style="text-align: left;">RWA_2</td>
<td style="text-align: left;">52</td>
<td style="text-align: left;">44.31</td>
<td style="text-align: left;">24.46</td>
</tr>
<tr>
<td style="text-align: left;">RWA_3</td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">30.33</td>
<td style="text-align: left;">23.48</td>
</tr>
<tr>
<td style="text-align: left;">RWA_4</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">33.84</td>
<td style="text-align: left;">18.26</td>
</tr>
<tr>
<td style="text-align: left;">RWA_5</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">35.27</td>
<td style="text-align: left;">14.78</td>
</tr>
<tr>
<td style="text-align: left;">RWA_6</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">39.14</td>
<td style="text-align: left;">11.30</td>
</tr>
<tr>
<td style="text-align: left;">Malas's Method [16]</td>
<td style="text-align: left;">52</td>
<td style="text-align: left;">37.68</td>
<td style="text-align: left;">24.34</td>
</tr>
<tr>
<td style="text-align: left;">NRWRH [40]</td>
<td style="text-align: left;">26</td>
<td style="text-align: left;">32.17</td>
<td style="text-align: left;">26.09</td>
</tr>
<tr>
<td style="text-align: left;">TP-NRWRH [41]</td>
<td style="text-align: left;">19</td>
<td style="text-align: left;">31.13</td>
<td style="text-align: left;">27.83</td>
</tr>
<tr>
<td style="text-align: left;">Bakalb's Method [17]</td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">29.44</td>
<td style="text-align: left;">31.30</td>
</tr>
<tr>
<td style="text-align: left;">SemaTyP [18]</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">29.87</td>
<td style="text-align: left;">30.58</td>
</tr>
<tr>
<td style="text-align: left;">GrEDeL</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">$\mathbf{2 7 . 0 5}$</td>
<td style="text-align: left;">$\mathbf{3 3 . 0 4}$</td>
</tr>
</tbody>
</table>
<p>In our experiments, all competitive methods (NRWRH, TP-NRWRH, Malas's method, Bakalb's method and SemaTyP) follow the recommended settings reported in their papers and the expected number of step of the basic RWA method was set from 1 to 6 . The overall results of drug rediscovery are presented in Table 8. The "Not Found" denotes the number of gold standard drugs which are not discovered by the corresponding method. "RWA_n" denotes the basic random walk algorithm with $n$ steps.</p>
<p>For "Not found", we find that increasing the number of steps improves the performance of basic RWA method. The reason is that the RWA with more steps could cover more entities. For instance, as shown in Table 8, 93 golden standard drugs are not discovered by RWA_1, this is because there are only 22 (115-93) golden standard drugs directly connect to their corresponding diseases in the knowledge graph. As the number of steps increases, basic RWA method could discover more drugs. Table 8 shows that the basic RWA methods could find all drugs when the number of steps exceeds 3 . It is due to the fact that in the knowledge graph of our experiments, all golden standard drugs and their corresponding diseases can be connected by a path of length 4 . As we can see from Table 8, there are 52 and 4 drugs were missed by Malas's method and Bakalb's method, respectively. This reason is Malas's method considers one intermediate between drug and disease and Bakalb's method just considers all paths of length $\leq 3$. Table 8 shows NRWRH and TP-NRWRH achieve poor performance than some basic RWA methods with respect to "Not found" metric. The primary reason is that, NRWRH and TP-NRWRH are both random walk with restart algorithms, which may result in that some disease nodes can not be reached by the golden standard drugs within desired steps. Moreover, Table 8 shows SemaTyP and GrEDeL rediscover all drugs for the diseases, as both methods could explore all paths of lengths 3 to 6 .</p>
<p>Table 8 shows RWA_1 achieves the worst result (90.82) in terms of "Mean Ranks". For the reason that most of the drugs ( 93 drugs) have not been found by this method. In addition, RWA_2 dramatically improves the performance as RWA with 2 steps could discover more drugs than that of RWA_1 method. As the number of steps increases, the</p>
<p>TABLE 9. Case studies of drug discovery.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Disease</th>
<th style="text-align: center;">Drug</th>
<th style="text-align: center;">Ranking</th>
<th style="text-align: center;">Score</th>
<th style="text-align: center;">Mechanism of Action</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">cardiovascular disease</td>
<td style="text-align: center;">ioxaglate</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0.57</td>
<td style="text-align: center;">ioxaglate DISRUPTS platelet aggregation AFFECTS signal transduction pathway AFFECTS cardiovascular disease</td>
</tr>
<tr>
<td style="text-align: center;">inflammatory disease</td>
<td style="text-align: center;">sb-612111</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0.69</td>
<td style="text-align: center;">sb-612111 NEG_AFFECTS consumption AFFECTS bone metabolism AFFECTS rheumatoid arthritis PROCESS_OF inflammatory disease</td>
</tr>
<tr>
<td style="text-align: center;">dementia</td>
<td style="text-align: center;">rx-77368</td>
<td style="text-align: center;">9</td>
<td style="text-align: center;">0.51</td>
<td style="text-align: center;">rx-77368 NEG_AFFECTS blood flow AFFECTS hsf1 AFFECTS disease COEXISTS_WITH dementia</td>
</tr>
<tr>
<td style="text-align: center;">mood disorder</td>
<td style="text-align: center;">mcpp</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">0.28</td>
<td style="text-align: center;">mcpp COEXISTS_WITH cortisol DISRUPTS telomere LOCATION_OF disease COEXISTS_WITH mood disorder</td>
</tr>
<tr>
<td style="text-align: center;">pain</td>
<td style="text-align: center;">dpi-3290</td>
<td style="text-align: center;">9</td>
<td style="text-align: center;">0.44</td>
<td style="text-align: center;">pi-3290 DISRUPTS tension COEXISTS_WITH pe CAUSES symptom PROCESS_OF pain</td>
</tr>
<tr>
<td style="text-align: center;">cancer</td>
<td style="text-align: center;">$\operatorname{tr}-2$</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">0.13</td>
<td style="text-align: center;">tr-2 INTERACTS_WITH cyclosporine ISA p-glycoprotein AFFECTS tissue LOCATION_OF cancer</td>
</tr>
</tbody>
</table>
<p>performance in terms of "Mean Ranks" can be further improved. For the basic RWA methods, Table 8 shows RWA_3 reaches the best performance (30.33). However, the performance decreases as the number of steps continues to grow. This is because the larger number of steps allows the RWA method to find more candidate drugs, which in turn leads to a lower ranking of the golden standard drugs. Table 8 shows that NRWRH and TP-NRWRH outperform all basic RWA methods. This is because both NRWRH and TP-NRWRH incorporate semantic types of entity besides the graph structure information. Similarly, Table 8 shows SemaTyP further improves the performance by making full use of semantic information of knowledge graph. In addition, Malas's method achieves poor performance (37.68) in terms of "Mean Ranks", this is due to there are 52 drugs were missed by the method.</p>
<p>For "Hits@10", RWA_2 outperforms other basic RWA methods (24.46\%). As shown in Table 8, although the performance decreases slightly when the step increases to 3 ( $23.48 \%$ ), continuously increasing the number of steps of RWA will cause significantly performance degradation. Furthermore, Table 8 shows NRWRH and TP-NRWRH achieve better performances than all basic RWA methods. Compared with the results obtained by RWA-based methods, Bakalb's method and SemaTyP achieve better performance in terms of "Hits@10" metric.</p>
<p>Table 8 shows our method, GrEDeL, outperforms all counterparts on all metrics (The "Mean Ranks" and "Hits@10" is 27.05 and $33.04 \%$, respectively). The main reasons are: 1) GrEDeL makes full use of both semantic information and structure of graph: the graph embedding features capture more information of the biomedical knowledge graph than other competitive methods. 2) GrEDeL considers the process of literature based discovery as a series analysis problem. By using recurrent neural network, GrEDeL can learn the dependencies among entities of drug-disease associations.</p>
<p>We are the first to consider the process of literature based discovery as a series analysis problem.</p>
<h2>E. CASE STUDY</h2>
<p>In this section, we conducted six case studies to show the efficacy of our approach (Table 9). The scores in the table are the probability indicating whether there is a relationship between a drug and a disease. Since the drug mechanism of actions are unknown, the associations obtained by our model was adopted to verify the hypotheses. For each disease of interest, GrEDeL predicts both the potential drugs and the corresponding drug targets simultaneously. For example, TTD has reported that ioxaglate is one known drug for cardiovascular disease, but the drug mechanism is still unknown. GrEDeL ranks ioxaglate as the 1st potential drug for treating cardiovascular disease. What's more, our method also provides corresponding mechanism of action of ioxaglate, Table 9 shows that ioxaglate acts on cardiovascular disease by disrupting platelet aggregation which affects the signal transduction pathway in cardiovascular disease. Other examples: rx-77368 is predicated to treat dementia by acting on hsf. $\operatorname{Tr}-2$ is predicated to treat cancer by acting on p-glycoprotein, etc. The cases in Table 9 show our method has the potential to discover drugs as well as their corresponding drug targets. However, the drug mechanism of actions generated by LBD must then be verified by human judgment and with experimental methods or clinical studies, depending on the nature of the discovery [44].</p>
<h2>F. COMPLEXITY</h2>
<p>Our experiments were conducted on a PC with 4 Intel(R) Xeon(R) CPU E5-2609 of 2.4 GHz and 8GB internal memory, the LSTM was implemented in TensorFlow 1.1.0 with GPU (CUDA 8.0.61) support. The source code of our implementation was released at. ${ }^{1}$ Table 10 shows the time needed</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>TABLE 10. Running time (in hours), the number in left column is the length of graph embedding.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">graph embedding dimension</th>
<th style="text-align: center;">running time</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">$\mathrm{SG}<em 10="10">{25}+T G</em>$</td>
<td style="text-align: center;">4.6</td>
</tr>
<tr>
<td style="text-align: center;">$\mathrm{SG}<em 20="20">{50}+T G</em>$</td>
<td style="text-align: center;">11.2</td>
</tr>
<tr>
<td style="text-align: center;">$\mathrm{SG}<em 30="30">{75}+T G</em>$</td>
<td style="text-align: center;">15.3</td>
</tr>
<tr>
<td style="text-align: center;">$\mathrm{SG}<em 10="10">{100}+T G</em>$</td>
<td style="text-align: center;">16.1</td>
</tr>
<tr>
<td style="text-align: center;">$\mathrm{SG}<em 50="50">{100}+T G</em>$</td>
<td style="text-align: center;">27.3</td>
</tr>
</tbody>
</table>
<p>for training of the GrEDeL in terms of the different graph embedding dimensions (the sum of the length of SG embedding and TG embedding). The first column in Table 10 is the dimension of graph embedding and the second column show the total running time for training GrEDeL. The dimension of hidden layer in LSTM was adopted the optimal setting in Table 7.</p>
<p>The running time for drug discovery depends on the total number of candidate drugs and corresponding drug targets. In this work, 100 candidate drugs and 5,785 targets (a protein, peptide or nucleic acid) extracted from TTD were used to construct candidate drug-target-disease associations for a given disease of interest. The average running time for processing one drug-target-disease association is 12 ms .</p>
<h2>V. DISCUSSION</h2>
<p>As far as we know, this is the first method that incorporates biomedical knowledge graph, knowledge graph embedding, as well as deep learning methods to discover drugs from literature. Our overall approach however, has several limitations: 1) The construction of our biomedical knowledge graph relies heavily on effective natural language processing tool (SemRep). Although we filtered out all isolated predications in order to improve the quality of the biomedical knowledge graph, there are still a large number of false positive relations existing in the knowledge graph, which in turn leads to our method inferring lower-quality results. 2) The positive training data constructed in our work consist of instances corresponding to paths extracted from the KG. However, the instances may correspond to overlapping paths. This could introduce bias to the ten-fold cross validation evaluation as an instance appearing on the training set could be very similar (due to the overlap) to another instance that is used in the test set, and thus lead to an overestimation of the performance. 3) The TransE is adopted in our method for knowledge graph embedding. It only achieves promising results in handling 1-to-1 relations. However, the biomedical knowledge graph also contains some 1-to-n and n-to-n relations.</p>
<p>In future work, we would like to develop high-quality NLP tools, in particular, biomedical NLP tools, to improve the quality of the biomedical knowledge graph. Additionally, other graph embedding methods could be used for capturing multi-mapping relations between entities.</p>
<h2>VI. CONCLUSION</h2>
<p>In this paper we have introduced a framework to jointly utilize knowledge graph and deep learning methods for discovering
drugs from literature. The experimental results show that our method can effectively discover potential drugs and their corresponding mechanism of actions. It could be a supplementary method for current drug discovery methods, which could improve the successfulness in discovering new medicine for currently incurable diseases.</p>
<h2>REFERENCES</h2>
<p>[1] R. Goulding and E. Marden, "An overview of drug discovery and drug development," OHI Del., vol. 1, 2009.
[2] S. Morgan, P. Grootendorst, J. Lexchin, C. Cunningham, and D. Greyson, "The cost of drug development: A systematic review," Health Policy, vol. 100, no. 1, pp. 4-17, 2011.
[3] A. Korhonen et al., "Improving literature-based discovery with advanced text mining," in Computational Intelligence Methods for Bioinformatics and Biostatistics (Lecture Notes in Computer Science), vol. 8623. Springer, 2014, pp. 89-98.
[4] D. Gubiani, I. Petrič, E. Fabbretti, and T. Urbančič, "Mining scientific literature about ageing to support better understanding and treatment of degenerative diseases," Tech. Rep., 2015.
[5] D. R. Swanson, "Fish oil, Raynaud's syndrome, and undiscovered public knowledge," Perspect. Biol. Med., vol. 30, no. 1, pp. 7-18, 1986.
[6] R. A. Digiacomo, J. M. Kremer, and D. M. Shah, "Fish-oil dietary supplementation in patients with Raynaud's phenomenon: A double-blind, controlled, prospective study," Amer. J. Med., vol. 86, no. 2, pp. 158-164, 1989.
[7] R. K. Lindsay and M. D. Gordon, "Literature-based discovery by lexical statistics," J. Assoc. Inf. Sci. Technol., vol. 50, no. 7, pp. 574-587, 1999.
[8] M. D. Gordon and R. K. Lindsay, "Toward discovery support systems: A replication, re-examination, and extension of Swanson's work on literature-based discovery of a connection between Raynaud's and fish oil," J. Assoc. Inf. Sci. Technol., vol. 47, no. 2, pp. 116-128, 1996.
[9] M. Weeber, H. Klein, L. T. W. de Jong-van den Berg, and R. Vos, "Using concepts in literature-based discovery: Simulating Swanson's Raynaudfish oil and migraine-magnesium discoveries," J. Assoc. Inf. Sci. Technol., vol. 52, no. 7, pp. 548-557, 2001.
[10] S. Sang, Z. Yang, Z. Li, and H. Lin, "Supervised learning based hypothesis generation from biomedical literature," BioMed Res. Int., vol. 2015, May 2015, Art. no. 698527.
[11] S. Henry and B. T. Mcinnes, "Literature based discovery: Models, methods, and trends," J. Biomed. Inform., vol. 74, pp. 20-32, Oct. 2017.
[12] D. Hristovski, C. Friedman, T. C. Rindflesch, and B. Peterlin, "Exploiting semantic relations for literature-based discovery," in Proc. Annu. Symp. AMIA. Bethesda, MD, USA: American Medical Informatics Association, 2006, p. 349.
[13] M. Rastegar-Mojarad, R. K. Elayavilli, D. Li, R. Prasad, and H. Liu, "A new method for prioritizing drug repositioning candidates extracted by literature-based discovery," in Proc. IEEE Int. Conf. Bioinf. Biomed., Nov. 2015, pp. 669-674.
[14] C. B. Ahlers, D. Hristovski, H. Kilicoglu, and T. C. Rindflesch, "Using the literature-based discovery paradigm to investigate drug mechanisms," in Proc. AMIA Annu. Symp. Bethesda, MD, USA: American Medical Informatics Association, 2007, pp. 6-10.
[15] D. Cameron, R. Kavuluru, T. C. Rindflesch, A. P. Sheth, K. Thirunarayan, and O. Bodenreider, "Context-driven automatic subgraph creation for literature-based discovery," J. Biomed. Inform., vol. 54, pp. 141-157, Apr. 2015.
[16] T. B. Malas et al., "Drug repurposing using a semantic knowledge graph," Tech. Rep.
[17] G. Bakal, G. Bakal, E. V. Kakani, and R. Kavuluru, "Exploiting semantic patterns over biomedical knowledge graphs for predicting treatment and causative relations," J. Biomed. Inform., vol. 82, pp. 189-199, Jun. 2018.
[18] S. Sang, Z. Yang, L. Wang, X. Liu, H. Lin, and J. Wang, "Sematyp: A knowledge graph based literature mining method for drug discovery," BMC Bioinf., vol. 19, no. 1, p. 193, 2018.
[19] I. I. Baskin, D. Winkler, and I. V. Tetko, "A renaissance of neural networks in drug discovery," Expert Opinion Drug Discovery, vol. 11, no. 8, pp. 785-795, 2016.</p>
<p>[20] P.-W. Keith, C. C. Chan, and Z.-H. You, "Large-scale prediction of drugtarget interactions from deep representations," in Proc. Int. Joint Conf. Neural Netw. (IJCNN), Jul. 2016, pp. 1236-1243.
[21] H. Chen, O. Engkvist, Y. Wang, M. Olivecrona, and T. Blaschke, "The rise of deep learning in drug discovery," Drug Discovery Today, vol. 23, no. 6, pp. 1241-1250, 2018.
[22] D. A. B. Lindberg, B. L. Humphreys, and A. T. McCray, "The unified medical language system," Methods Inf. Med., vol. 32, no. 04, pp. 281-291, 1993.
[23] A. T. McCray, "The UMLS semantic network," in Proc. Annu. Symp. Comput. Appl. Med. Care. Bethesda, MD, USA: American Medical Informatics Association, 1989, pp. 503-507.
[24] X. Chen, Z. L. Ji, and Y. Z. Chen, "TTD: Therapeutic target database," Nucleic Acids Res., vol. 30, no. 1, pp. 412-415, 2002.
[25] T. C. Rindflesch and M. Fiszman, "The interaction of domain knowledge and linguistic structure in natural language processing: Interpreting hypernymic propositions in biomedical text," J. Biomed. Inform., vol. 36, no. 6, pp. 462-477, 2003.
[26] K. Bollacker, C. Evans, P. Paritosh, T. Sturge, and J. Taylor, "Freebase: A collaboratively created graph database for structuring human knowledge," in Proc. ACM SIGMOD Int. Conf. Manage. Data, 2008, pp. 1247-1250.
[27] C. Bizer et al., "DBpedia-A crystallization point for the Web of data," J. Web Semantics, vol. 7, no. 3, pp. 154-165, 2009.
[28] J. Hoffart, F. M. Suchanek, K. Berberich, E. Lewis-Kelham, G. De Melo, and G. Weikum, "Yago2: Exploring and querying world knowledge in time, space, context, and many languages," in Proc. ACM 20th Int. Conf. Companion World Wide Web, 2011, pp. 229-232.
[29] H. Cai, V. W. Zheng, and K. C.-C. Chang. (2017). "A comprehensive survey of graph embedding: Problems, techniques and applications." [Online]. Available: https://arxiv.org/abs/1709.07604
[30] A. Bordes, N. Usunier, A. Garcia-Duran, J. Weston, and O. Yakhnenko, "Translating embeddings for modeling multi-relational data," in Proc. Adv. Neural Inf. Process. Syst., 2013, pp. 2787-2795.
[31] M. Hinken and P. Stagge, "Recurrent neural networks for time series classification," Neurocomputing, vol. 50, pp. 223-235, Jan. 2003.
[32] Y. Bengio, P. Simard, and P. Frasconi, "Learning long-term dependencies with gradient descent is difficult," IEEE Trans. Neural Netw., vol. 5, no. 2, pp. 157-166, Mar. 1994.
[33] W. Zaremba, I. Sutskever, and O. Vinyals. (2014). "Recurrent neural network regularization." [Online]. Available: https://arxiv.org/abs/1409.2329
[34] S. Hochreiter and J. Schmidhuber, "Long short-term memory," Neural Comput., vol. 9, no. 8, pp. 1735-1780, 1997.
[35] J. D. Wren, R. Bekeredjian, J. A. Stewart, R. V. Shohet, and H. R. Garner, "Knowledge discovery by automated identification and ranking of implicit relationships," Bioinformatics, vol. 20, no. 3, pp. 389-398, 2004.
[36] P. J. Werbos, "Backpropagation through time: What it does and how to do it," Proc. IEEE, vol. 78, no. 10, pp. 1550-1560, Oct. 1990.
[37] M. Wen et al., "Deep-learning-based drug-target interaction prediction," J. Proteome Res., vol. 16, no. 4, pp. 1401-1409, 2017.
[38] D.-S. Cao et al., "Computational prediction of drug-target interactions using chemical, biological, and network features," Mol. Inform., vol. 33, no. 10, pp. 669-681, 2014.
[39] E. Byvatov, U. Fechner, J. Sadowski, and G. Schneider, "Comparison of support vector machine and artificial neural network systems for drug/nondrug classification," J. Chem. Inf. Model., vol. 43, no. 6, pp. 1882-1889, 2003.
[40] X. Chen, M.-X. Liu, and G.-Y. Yan, "Drug-target interaction prediction by random walk on the heterogeneous network," Mol. BioSyst., vol. 8, no. 7, pp. 1970-1978, 2012.
[41] H. Liu, Y. Song, J. Guan, L. Luo, and Z. Zhuang, "Inferring new indications for approved drugs via random walk on drug-disease heterogenous networks," BMC Bioinf., vol. 17, no. 17, p. 539, 2016.
[42] M. Gori, A. Pacci, V. Roma, and I. Siena, "ItemRank: A random-walk based scoring algorithm for recommender engines," in Proc. IJCAI, vol. 7, Jan. 2007, pp. 2766-2771.
[43] D. P. Kingma and L. J. Ba, "A method for stochastic optimization," in Proc. Int. Conf. Learn. Represent. (ICLR), 2015, p. 13.
[44] D. Hristovski, T. Rindflesch, and B. Peterlin, "Using literature-based discovery to identify novel therapeutic approaches," Cardiovascular Hematolog. Agents Medicinal Chem. (Formerly Current Medicinal Chem.-Cardiovascular Hematolog. Agents), vol. 11, no. 1, pp. 14-24, 2013.
<img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>SHENGTIAN SANG is currently pursuing the Ph.D. degree with the College of Computer Science and Technology, Dalian University of Technology, Dalian, China. His research interests include literature-based discovery, knowledge graph, and data mining.
<img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>ZHIHAO YANG received the B.Sc., M.Sc., and Ph.D. degrees from the Dalian University of Technology, China, in 1997, 2003, and 2008, respectively. He is currently a Professor with the School of Computer Science and Technology, Dalian University of Technology. He has published over 30 research papers on topics in biomedical literature data mining. His current research interests include biomedical literature data mining, natural language processing, and machine learning. His research projects are funded by the National Natural Science Foundation of China and the Major State Research Development Program of China.
<img alt="img-6.jpeg" src="img-6.jpeg" /></p>
<p>XIAOXIA LIU is currently pursuing the Ph.D. degree with the College of Computer Science and Technology, Dalian University of Technology, Dalian, China. Her research interests include network science, data mining, and bioinformatics.
<img alt="img-7.jpeg" src="img-7.jpeg" /></p>
<p>LEI WANG received the Ph.D. degree from the Beijing Institute of Health Administration and Medical Information, China, in 2006. She is currently a Professor with the Beijing Institute of Health Administration and Medical Information. Her current research interests include biomedical literature data mining, medical science and technology information, and science and technology development strategy. She has published over 20 research papers and four monographs. Her research projects are funded by the National Natural Science Foundation of China and the Major State Research Development Program of China.
<img alt="img-8.jpeg" src="img-8.jpeg" /></p>
<p>HONGFEI LIN received the B.Sc. degree from Northeastern Normal University, in 1983, the M.Sc. degree from the Dalian University of Technology, in 1992, and the Ph.D. degree from Northeastern University, in 2000. He is currently a Professor with the School of Computer Science and Technology, Dalian University of Technology. He has published over 100 research papers in various journals, conferences, and books. His research interests include information retrieval, text mining, natural language processing, and effective computing. In recent years, he has focused on text mining for biomedical literatures.</p>
<p><img alt="img-9.jpeg" src="img-9.jpeg" /></p>
<p>JIAN WANG received the B.Sc., M.Sc., and Ph.D. degrees from the Dalian University of Technology, China, in 1997, 2003, and 2008, respectively. She is currently a Professor with the School of Computer Science and Technology, Dalian University of Technology. She has published over 30 research papers on topics in biomedical literature data mining. Her current research interests include biomedical literature data mining, natural language processing, and machine learning.
<img alt="img-10.jpeg" src="img-10.jpeg" /></p>
<p>MICHEL DUMONTIER was an Associate Professor of medicine (biomedical informatics) with the Stanford University School of Medicine, and also an Associate Professor of bioinformatics with Carleton University. He is currently a Distinguished Professor of data science with Maastricht University. He is best known for his work in biomedical ontologies, linked data, and biomedical knowledge discovery. His research has been funded by the Natural Sciences and Engineering Research Council, the Canada Foundation for Innovation, Mitacs Canada, the Ontario Ministry of Research, Innovation and Science, CANARIE, and the US National Institutes of Health. He has an h-index of over 30 and has authored over 125 scientific publications in journals and conferences. His research focuses on methods to represent knowledge on the web, with applications for drug discovery and personalized medicine.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{1}$ https://github.com/ShengtianSang/GrEDeL&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>