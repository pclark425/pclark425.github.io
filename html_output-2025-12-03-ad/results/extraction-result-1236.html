<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1236 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1236</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1236</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-28.html">extraction-schema-28</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of navigation in text-based games or text worlds, including graph-topology features of the environments (such as diameter, clustering coefficient, dead-ends, door constraints, connectivity), exploration efficiency metrics, and how these relate to agent performance and policy structure.</div>
                <p><strong>Paper ID:</strong> paper-259766368</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2307.04962v4.pdf" target="_blank">Intrinsically Motivated Graph Exploration Using Network Theories of Human Curiosity</a></p>
                <p><strong>Paper Abstract:</strong> Intrinsically motivated exploration has proven useful for reinforcement learning, even without additional extrinsic rewards. When the environment is naturally represented as a graph, how to guide exploration best remains an open question. In this work, we propose a novel approach for exploring graph-structured data motivated by two theories of human curiosity: the information gap theory and the compression progress theory. The theories view curiosity as an intrinsic motivation to optimize for topological features of subgraphs induced by nodes visited in the environment. We use these proposed features as rewards for graph neural-network-based reinforcement learning. On multiple classes of synthetically generated graphs, we find that trained agents generalize to longer exploratory walks and larger environments than are seen during training. Our method computes more efficiently than the greedy evaluation of the relevant topological properties. The proposed intrinsic motivations bear particular relevance for recommender systems. We demonstrate that next-node recommendations considering curiosity are more predictive of human choices than PageRank centrality in several real-world graph environments, including MovieLens, Amazon Books, and Wikipedia.</p>
                <p><strong>Cost:</strong> 0.016</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1236.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1236.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of navigation in text-based games or text worlds, including graph-topology features of the environments (such as diameter, clustering coefficient, dead-ends, door constraints, connectivity), exploration efficiency metrics, and how these relate to agent performance and policy structure.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SyntheticGraphs</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Synthetic graph environments (Random Geometric, Watts-Strogatz, Barabási-Albert, Erdős-Rényi)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A suite of synthetic graph topologies used to evaluate intrinsic curiosity-driven graph exploration agents: Random Geometric (RG), Watts–Strogatz (WS), Barabási–Albert (BA), and Erdős–Rényi (ER). Each topology exposes different clustering and degree characteristics to test how topology affects exploration and policy performance.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Intrinsically Motivated Graph Exploration Using Network Theories of Human Curiosity</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Synthetic graph models (RG, WS, BA, ER)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Graph-structured environments generated by canonical random graph models: RG (spatially embedded, clustered), WS (small-world with tunable clustering), BA (scale-free with hub/core structure), ER (uniform random). Domain: abstract graph exploration.</td>
                        </tr>
                        <tr>
                            <td><strong>graph_diameter</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>clustering_coefficient</strong></td>
                            <td>Not provided numerically; paper reports WS and BA have high clustering (depending on parameters), RG exhibits clustered neighborhoods around high-degree central nodes, and CPT reward is strongly correlated with clustering coefficient.</td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_present</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_count</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_present</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_description</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>graph_connectivity</strong></td>
                            <td>Varies by model: RG/WS/BA show clustered or core-periphery structure; ER is more uniformly random (sparser clustering). Average degree not specified numerically in paper (graphs constructed with N=50 and model-appropriate parameters).</td>
                        </tr>
                        <tr>
                            <td><strong>environment_size</strong></td>
                            <td>Training environments: N = 50 nodes (100 train, 10 val, 10 test per model); episode length T = 10 node visits.</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>GNN (GraphSAGE) trained with DQN; baselines: Greedy (one-step lookahead), Random, MaxDegree, MinDegree</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Value function Q(S_t, v) parameterized by a GraphSAGE GNN taking only local degree-profile node features; trained with DQN (replay buffer, target network, decaying ε-greedy). Actions: move to a neighbor of the most recently visited node (or expand to neighbors of explored subgraph if none). Rewards are intrinsic: F_IGT (β1, number of 1-cycles) or F_CPT (network compressibility).</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_metric</strong></td>
                            <td>Total average return (sum/average of the intrinsic reward over the trajectory); additionally wall-time per forward pass and generalization to longer walks / larger graphs were measured.</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_value</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimal_policy_type</strong></td>
                            <td>Depends on objective: for CPT a greedy one-step-ahead policy often performs best; for IGT the trained GNN policy often outperforms greedy (except on ER graphs).</td>
                        </tr>
                        <tr>
                            <td><strong>topology_performance_relationship</strong></td>
                            <td>Compression-based reward (CPT) is strongly correlated with clustering coefficient, so topologies with high clustering (WS with low rewiring, BA cores, RG central nodes) make CPT easier and cause simple baselines (max-degree, random inside clusters) to perform well; information-gap reward (IGT, β1) is sensitive to single node choices because adding one node can create/close multiple 1-cycles, favoring learned policies (GNN) that consider longer-term structure. ER graphs reduce the advantage of IGT-trained GNN over greedy.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_across_topologies</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>topology_comparison_results</strong></td>
                            <td>Across RG, WS, BA, ER: For IGT (β1 reward) the GNN outperforms greedy in all models except ER; for CPT (compressibility) the greedy one-step policy consistently performs best and the GNN is a close second. Baselines (max degree, min degree, random) perform relatively well on CPT in highly clustered topologies (RG, BA, WS depending on parameters) but worse on IGT. The paper attributes these differences to the differing sensitivity of IGT vs CPT to local neighborhood structure.</td>
                        </tr>
                        <tr>
                            <td><strong>policy_structure_findings</strong></td>
                            <td>IGT requires policies that consider multi-step implications of node choices (single choices can close/create multiple 1-cycles), favoring learned GNN value functions; CPT is less sensitive to individual choices and is well served by a greedy one-step policy. GNN value approximation offers computational scaling advantages and generalizes to longer trajectories and larger graphs.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Intrinsically Motivated Graph Exploration Using Network Theories of Human Curiosity', 'publication_date_yy_mm': '2023-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1236.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e1236.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of navigation in text-based games or text worlds, including graph-topology features of the environments (such as diameter, clustering coefficient, dead-ends, door constraints, connectivity), exploration efficiency metrics, and how these relate to agent performance and policy structure.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GraphExplorationMDP</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Graph exploration Markov decision process and intrinsic rewards (IGT and CPT)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Formal MDP formulation for sequential graph exploration where states are induced subgraphs of visited nodes, actions pick a neighbor to visit next, and intrinsic rewards are topological: IGT reward = β1 (count of 1-cycles) and CPT reward = network compressibility (average reduction in random-walk information rate across scales).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Intrinsically Motivated Graph Exploration Using Network Theories of Human Curiosity</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Graph exploration MDP (general formulation)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Abstract graph-structured exploration task where the agent incrementally builds an induced subgraph by visiting nodes; no extrinsic task reward — exploration itself is the objective.</td>
                        </tr>
                        <tr>
                            <td><strong>graph_diameter</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>clustering_coefficient</strong></td>
                            <td>Used conceptually; compressibility (CPT) is strongly correlated with clustering coefficient but no single numerical coefficient provided globally.</td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_present</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_count</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_present</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_description</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>graph_connectivity</strong></td>
                            <td>General: connectivity determines available actions (neighbors of last visited node). If the immediate neighborhood is exhausted, action set expanded to neighbors of explored subgraph.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_size</strong></td>
                            <td>General (experiments used N=50 synthetic graphs; also larger test graphs up to two orders of magnitude larger were evaluated for generalization).</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>GNN value-function agent (GraphSAGE) trained with DQN</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Q(S_t,v) approximated with a GraphSAGE GNN using local degree-profile (LDP) node features; DQN training (replay buffer, target network). Rewards are intrinsic functions F_IGT = β1(S_t) and F_CPT = C(S_t). Transition dynamics deterministic given selected node.</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_metric</strong></td>
                            <td>Sum (discounted) of intrinsic reward over trajectory (total average return); computational efficiency (wall time for reward computation vs GNN forward pass); generalization to longer trajectories and larger graphs.</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_value</strong></td>
                            <td>GNN generalizes to longer trajectories and to environments up to two orders of magnitude larger than training (qualitative result); exact numeric values depend on experiment and reward type and are reported qualitatively in paper.</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimal_policy_type</strong></td>
                            <td>Objective-dependent: learned GNN policies for IGT; greedy one-step-ahead often optimal for CPT.</td>
                        </tr>
                        <tr>
                            <td><strong>topology_performance_relationship</strong></td>
                            <td>IGT (β1) rewards are topology-sensitive: actions that create/close 1-cycles have high long-term impact, requiring lookahead; CPT rewards depend on clustering, so exploration inside dense clusters yields high compressibility and reduces sensitivity to exact next-node choice.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_across_topologies</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>topology_comparison_results</strong></td>
                            <td>Paper shows different performance rankings of agents across graph models (see SyntheticGraphs entry): GNN best for IGT (except ER), greedy best for CPT; baselines perform differently depending on clustering/degree patterns of the graph model.</td>
                        </tr>
                        <tr>
                            <td><strong>policy_structure_findings</strong></td>
                            <td>Policies for IGT need to encode multi-step structure (learned via GNN); CPT can be effectively optimized with local greedy heuristics due to its correlation with local clustering.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Intrinsically Motivated Graph Exploration Using Network Theories of Human Curiosity', 'publication_date_yy_mm': '2023-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1236.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e1236.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of navigation in text-based games or text worlds, including graph-topology features of the environments (such as diameter, clustering coefficient, dead-ends, door constraints, connectivity), exploration efficiency metrics, and how these relate to agent performance and policy structure.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Wikispeedia</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Wikispeedia (Wikipedia navigation game)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A human navigation dataset/game where players navigate between Wikipedia pages via links to reach a goal page; used here to evaluate whether curiosity-biased centrality (curiosity-biased PageRank) predicts human next-node choices better than standard PageRank.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Intrinsically Motivated Graph Exploration Using Network Theories of Human Curiosity</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Wikispeedia (Wikipedia page link graph, goal-directed navigation game)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Goal-directed human navigation on the Wikipedia hyperlink graph (each node is a Wikipedia page, edges are hyperlinks); domain: semantic information navigation / text-world browsing game.</td>
                        </tr>
                        <tr>
                            <td><strong>graph_diameter</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>clustering_coefficient</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_present</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_count</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_present</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_description</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>graph_connectivity</strong></td>
                            <td>Directed/undirected hyperlink graph structure of Wikipedia (paper treats as graph for random walks); specific connectivity statistics not provided in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Curiosity-biased PageRank walkers (bias via Q-values from GNN trained with IGT or CPT), standard PageRank baseline</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Non-Markovian random walkers whose transition probabilities are biased by ranks of GNN Q-values for candidate next nodes (parameter p_g controls greedy selection). PageRank vector η_F computed by simulating these biased walkers and used to predict human next transitions.</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_metric</strong></td>
                            <td>Predictive power for human next-node transitions measured by percentile rank improvement r_Stest (ratio of ranked-percentile performance of biased PageRank vs standard PageRank on held-out transitions). Also random-walk diffusion distance-from-start was analyzed.</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_value</strong></td>
                            <td>Improvement in predicting human transitions: IGT bias +2.9% ±2.9%; CPT bias +12.2% ±3.2%; combined IGT+CPT +32.2% ±7.7% (these are r_Stest percentage improvements reported for Wikispeedia).</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimal_policy_type</strong></td>
                            <td>For prediction of human transitions, combining standard PageRank with curiosity-biased PageRank (linear combination) produced best predictive performance after parameter tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>topology_performance_relationship</strong></td>
                            <td>CPT-biased walkers tended to remain closer to the initial node (in MovieLens and Wikispeedia), indicating that compressibility bias changes diffusion/locality properties; CPT produced larger predictive improvement in goal-directed Wikispeedia (suggesting compressibility-related topology features matter more in goal-directed navigation).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_across_topologies</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>topology_comparison_results</strong></td>
                            <td>Not directly a topology comparison, but results indicate a larger benefit from CPT bias in the goal-directed Wikispeedia dataset than IGT bias, and substantial further gains when combining IGT and CPT biases.</td>
                        </tr>
                        <tr>
                            <td><strong>policy_structure_findings</strong></td>
                            <td>Biasing random-walk transition probabilities using learned Q-values (non-Markovian, history-dependent) improves alignment with human navigation choices compared to purely Markovian PageRank; CPT bias yields more localized walks (stays closer to start).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Intrinsically Motivated Graph Exploration Using Network Theories of Human Curiosity', 'publication_date_yy_mm': '2023-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1236.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e1236.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of navigation in text-based games or text worlds, including graph-topology features of the environments (such as diameter, clustering coefficient, dead-ends, door constraints, connectivity), exploration efficiency metrics, and how these relate to agent performance and policy structure.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MovieLensGraph</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>MovieLens user–movie graph (user browsing / selection)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A graph representation of the MovieLens dataset (users and movies / item-item or user-item relations) used to test whether curiosity-biased PageRank better predicts human next-item choices than standard PageRank.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Intrinsically Motivated Graph Exploration Using Network Theories of Human Curiosity</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>MovieLens graph (user-item browsing environment)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Recommendation/choice environment where nodes represent movies (and possibly users), and edges encode relations (co-visitation or metadata); used to evaluate next-node recommendation predictive power of curiosity-biased centrality.</td>
                        </tr>
                        <tr>
                            <td><strong>graph_diameter</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>clustering_coefficient</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_present</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_count</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_present</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_description</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>graph_connectivity</strong></td>
                            <td>Not numerically specified in paper; described qualitatively as similar to Amazon Books (non-goal-directed selection with cluster structure influencing compressibility).</td>
                        </tr>
                        <tr>
                            <td><strong>environment_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Curiosity-biased PageRank (IGT and CPT biases) and standard PageRank baseline</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Personalized PageRank with hop vector q set to a user's n burn-in most recently visited nodes; transition probabilities biased using Q-values from GNNs trained with IGT/CPT to produce η_F vectors which are linearly combined with standard PageRank.</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_metric</strong></td>
                            <td>Predictive percentile rank for the actual next transition; reported improvement r_Stest compared to standard PageRank.</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_value</strong></td>
                            <td>Reported improvements: IGT +4.2% ±2.1%; CPT +5.1% ±1.5%; combined IGT+CPT +7.9% ±1.7% (r_Stest percent improvements on MovieLens test set).</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimal_policy_type</strong></td>
                            <td>Combined curiosity-biased PageRank (linear combination of standard PageRank, IGT-biased and CPT-biased scores) after parameter tuning performed best for next-item prediction.</td>
                        </tr>
                        <tr>
                            <td><strong>topology_performance_relationship</strong></td>
                            <td>MovieLens and Amazon Books (non-goal-directed selection) both show improvements when including curiosity biases; CPT bias tends to keep walkers more local which can reflect user browsing patterns in these datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_across_topologies</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>topology_comparison_results</strong></td>
                            <td>N/A (single-dataset evaluation), but paper notes MovieLens and Amazon Books have similar selection mechanisms leading to similar improvements from biases.</td>
                        </tr>
                        <tr>
                            <td><strong>policy_structure_findings</strong></td>
                            <td>In non-goal-directed recommendation environments simple locality/compressibility biases (CPT) and gap-creating biases (IGT) both help; combining them gives the best predictive performance for next-node recommendations.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Intrinsically Motivated Graph Exploration Using Network Theories of Human Curiosity', 'publication_date_yy_mm': '2023-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1236.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e1236.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of navigation in text-based games or text worlds, including graph-topology features of the environments (such as diameter, clustering coefficient, dead-ends, door constraints, connectivity), exploration efficiency metrics, and how these relate to agent performance and policy structure.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AmazonBooksGraph</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Amazon Books co-purchase/selection graph</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Graph derived from Amazon Books dataset representing relationships between books (co-purchase, co-view, or other edges) used to test curiosity-biased PageRank for predicting user next selections.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Intrinsically Motivated Graph Exploration Using Network Theories of Human Curiosity</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Amazon Books graph (user browsing / non-goal-directed selection)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Recommendation/choice environment built from Amazon Books interactions; domain: online product browsing and selection represented as a graph.</td>
                        </tr>
                        <tr>
                            <td><strong>graph_diameter</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>clustering_coefficient</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_present</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_count</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_present</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_description</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>graph_connectivity</strong></td>
                            <td>Not numerically specified; presented qualitatively as similar to MovieLens with cluster structures influencing compressibility.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Curiosity-biased PageRank (IGT and CPT biases) and standard PageRank</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Personalized PageRank with hop vector set to user's recent visited nodes; transition probabilities adjusted with Q-values from GNNs trained for IGT/CPT, producing candidate centrality vectors combined linearly with standard PageRank.</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_metric</strong></td>
                            <td>Predictive percentile rank improvement for held-out next-node transitions (r_Stest).</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_value</strong></td>
                            <td>Reported improvements: IGT +5.4% ±1.9%; CPT +4.6% ±1.6%; combined IGT+CPT +9.6% ±1.9% (r_Stest percent improvements on Amazon Books test set).</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimal_policy_type</strong></td>
                            <td>Combination of standard PageRank and curiosity-biased PageRank vectors after tuning (linear mixture) gave the best predictive performance.</td>
                        </tr>
                        <tr>
                            <td><strong>topology_performance_relationship</strong></td>
                            <td>Non-goal-directed browsing in these datasets benefits from compressibility and gap-creation biases; local clustering patterns likely drive CPT effectiveness, though exact topology statistics are not reported.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_across_topologies</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>topology_comparison_results</strong></td>
                            <td>N/A for cross-topology comparison; dataset-level results show both IGT and CPT provide modest improvements with their combination giving a larger boost.</td>
                        </tr>
                        <tr>
                            <td><strong>policy_structure_findings</strong></td>
                            <td>Biasing random-walk transitions with history-dependent Q-values (from curiosity-trained GNNs) improves human-choice prediction; CPT bias keeps walks more local which aligns with observed browsing patterns in some datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Intrinsically Motivated Graph Exploration Using Network Theories of Human Curiosity', 'publication_date_yy_mm': '2023-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Wikispeedia: An online game for inferring semantic distances between concepts. <em>(Rating: 2)</em></li>
                <li>Human wayfinding in information networks. <em>(Rating: 2)</em></li>
                <li>Quantifying the compressibility of complex networks. <em>(Rating: 2)</em></li>
                <li>PageRank beyond the web. <em>(Rating: 1)</em></li>
                <li>A large-scale characterization of how readers browse Wikipedia. <em>(Rating: 1)</em></li>
                <li>Random walk for generalization in goal-directed human navigation on Wikipedia. <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1236",
    "paper_id": "paper-259766368",
    "extraction_schema_id": "extraction-schema-28",
    "extracted_data": [
        {
            "name_short": "SyntheticGraphs",
            "name_full": "Synthetic graph environments (Random Geometric, Watts-Strogatz, Barabási-Albert, Erdős-Rényi)",
            "brief_description": "A suite of synthetic graph topologies used to evaluate intrinsic curiosity-driven graph exploration agents: Random Geometric (RG), Watts–Strogatz (WS), Barabási–Albert (BA), and Erdős–Rényi (ER). Each topology exposes different clustering and degree characteristics to test how topology affects exploration and policy performance.",
            "citation_title": "Intrinsically Motivated Graph Exploration Using Network Theories of Human Curiosity",
            "mention_or_use": "use",
            "environment_name": "Synthetic graph models (RG, WS, BA, ER)",
            "environment_description": "Graph-structured environments generated by canonical random graph models: RG (spatially embedded, clustered), WS (small-world with tunable clustering), BA (scale-free with hub/core structure), ER (uniform random). Domain: abstract graph exploration.",
            "graph_diameter": null,
            "clustering_coefficient": "Not provided numerically; paper reports WS and BA have high clustering (depending on parameters), RG exhibits clustered neighborhoods around high-degree central nodes, and CPT reward is strongly correlated with clustering coefficient.",
            "dead_ends_present": null,
            "dead_ends_count": null,
            "door_constraints_present": false,
            "door_constraints_description": "",
            "graph_connectivity": "Varies by model: RG/WS/BA show clustered or core-periphery structure; ER is more uniformly random (sparser clustering). Average degree not specified numerically in paper (graphs constructed with N=50 and model-appropriate parameters).",
            "environment_size": "Training environments: N = 50 nodes (100 train, 10 val, 10 test per model); episode length T = 10 node visits.",
            "agent_name": "GNN (GraphSAGE) trained with DQN; baselines: Greedy (one-step lookahead), Random, MaxDegree, MinDegree",
            "agent_description": "Value function Q(S_t, v) parameterized by a GraphSAGE GNN taking only local degree-profile node features; trained with DQN (replay buffer, target network, decaying ε-greedy). Actions: move to a neighbor of the most recently visited node (or expand to neighbors of explored subgraph if none). Rewards are intrinsic: F_IGT (β1, number of 1-cycles) or F_CPT (network compressibility).",
            "exploration_efficiency_metric": "Total average return (sum/average of the intrinsic reward over the trajectory); additionally wall-time per forward pass and generalization to longer walks / larger graphs were measured.",
            "exploration_efficiency_value": null,
            "success_rate": null,
            "optimal_policy_type": "Depends on objective: for CPT a greedy one-step-ahead policy often performs best; for IGT the trained GNN policy often outperforms greedy (except on ER graphs).",
            "topology_performance_relationship": "Compression-based reward (CPT) is strongly correlated with clustering coefficient, so topologies with high clustering (WS with low rewiring, BA cores, RG central nodes) make CPT easier and cause simple baselines (max-degree, random inside clusters) to perform well; information-gap reward (IGT, β1) is sensitive to single node choices because adding one node can create/close multiple 1-cycles, favoring learned policies (GNN) that consider longer-term structure. ER graphs reduce the advantage of IGT-trained GNN over greedy.",
            "comparison_across_topologies": true,
            "topology_comparison_results": "Across RG, WS, BA, ER: For IGT (β1 reward) the GNN outperforms greedy in all models except ER; for CPT (compressibility) the greedy one-step policy consistently performs best and the GNN is a close second. Baselines (max degree, min degree, random) perform relatively well on CPT in highly clustered topologies (RG, BA, WS depending on parameters) but worse on IGT. The paper attributes these differences to the differing sensitivity of IGT vs CPT to local neighborhood structure.",
            "policy_structure_findings": "IGT requires policies that consider multi-step implications of node choices (single choices can close/create multiple 1-cycles), favoring learned GNN value functions; CPT is less sensitive to individual choices and is well served by a greedy one-step policy. GNN value approximation offers computational scaling advantages and generalizes to longer trajectories and larger graphs.",
            "uuid": "e1236.0",
            "source_info": {
                "paper_title": "Intrinsically Motivated Graph Exploration Using Network Theories of Human Curiosity",
                "publication_date_yy_mm": "2023-07"
            }
        },
        {
            "name_short": "GraphExplorationMDP",
            "name_full": "Graph exploration Markov decision process and intrinsic rewards (IGT and CPT)",
            "brief_description": "Formal MDP formulation for sequential graph exploration where states are induced subgraphs of visited nodes, actions pick a neighbor to visit next, and intrinsic rewards are topological: IGT reward = β1 (count of 1-cycles) and CPT reward = network compressibility (average reduction in random-walk information rate across scales).",
            "citation_title": "Intrinsically Motivated Graph Exploration Using Network Theories of Human Curiosity",
            "mention_or_use": "use",
            "environment_name": "Graph exploration MDP (general formulation)",
            "environment_description": "Abstract graph-structured exploration task where the agent incrementally builds an induced subgraph by visiting nodes; no extrinsic task reward — exploration itself is the objective.",
            "graph_diameter": null,
            "clustering_coefficient": "Used conceptually; compressibility (CPT) is strongly correlated with clustering coefficient but no single numerical coefficient provided globally.",
            "dead_ends_present": null,
            "dead_ends_count": null,
            "door_constraints_present": false,
            "door_constraints_description": "",
            "graph_connectivity": "General: connectivity determines available actions (neighbors of last visited node). If the immediate neighborhood is exhausted, action set expanded to neighbors of explored subgraph.",
            "environment_size": "General (experiments used N=50 synthetic graphs; also larger test graphs up to two orders of magnitude larger were evaluated for generalization).",
            "agent_name": "GNN value-function agent (GraphSAGE) trained with DQN",
            "agent_description": "Q(S_t,v) approximated with a GraphSAGE GNN using local degree-profile (LDP) node features; DQN training (replay buffer, target network). Rewards are intrinsic functions F_IGT = β1(S_t) and F_CPT = C(S_t). Transition dynamics deterministic given selected node.",
            "exploration_efficiency_metric": "Sum (discounted) of intrinsic reward over trajectory (total average return); computational efficiency (wall time for reward computation vs GNN forward pass); generalization to longer trajectories and larger graphs.",
            "exploration_efficiency_value": "GNN generalizes to longer trajectories and to environments up to two orders of magnitude larger than training (qualitative result); exact numeric values depend on experiment and reward type and are reported qualitatively in paper.",
            "success_rate": null,
            "optimal_policy_type": "Objective-dependent: learned GNN policies for IGT; greedy one-step-ahead often optimal for CPT.",
            "topology_performance_relationship": "IGT (β1) rewards are topology-sensitive: actions that create/close 1-cycles have high long-term impact, requiring lookahead; CPT rewards depend on clustering, so exploration inside dense clusters yields high compressibility and reduces sensitivity to exact next-node choice.",
            "comparison_across_topologies": true,
            "topology_comparison_results": "Paper shows different performance rankings of agents across graph models (see SyntheticGraphs entry): GNN best for IGT (except ER), greedy best for CPT; baselines perform differently depending on clustering/degree patterns of the graph model.",
            "policy_structure_findings": "Policies for IGT need to encode multi-step structure (learned via GNN); CPT can be effectively optimized with local greedy heuristics due to its correlation with local clustering.",
            "uuid": "e1236.1",
            "source_info": {
                "paper_title": "Intrinsically Motivated Graph Exploration Using Network Theories of Human Curiosity",
                "publication_date_yy_mm": "2023-07"
            }
        },
        {
            "name_short": "Wikispeedia",
            "name_full": "Wikispeedia (Wikipedia navigation game)",
            "brief_description": "A human navigation dataset/game where players navigate between Wikipedia pages via links to reach a goal page; used here to evaluate whether curiosity-biased centrality (curiosity-biased PageRank) predicts human next-node choices better than standard PageRank.",
            "citation_title": "Intrinsically Motivated Graph Exploration Using Network Theories of Human Curiosity",
            "mention_or_use": "use",
            "environment_name": "Wikispeedia (Wikipedia page link graph, goal-directed navigation game)",
            "environment_description": "Goal-directed human navigation on the Wikipedia hyperlink graph (each node is a Wikipedia page, edges are hyperlinks); domain: semantic information navigation / text-world browsing game.",
            "graph_diameter": null,
            "clustering_coefficient": null,
            "dead_ends_present": null,
            "dead_ends_count": null,
            "door_constraints_present": false,
            "door_constraints_description": "",
            "graph_connectivity": "Directed/undirected hyperlink graph structure of Wikipedia (paper treats as graph for random walks); specific connectivity statistics not provided in this paper.",
            "environment_size": null,
            "agent_name": "Curiosity-biased PageRank walkers (bias via Q-values from GNN trained with IGT or CPT), standard PageRank baseline",
            "agent_description": "Non-Markovian random walkers whose transition probabilities are biased by ranks of GNN Q-values for candidate next nodes (parameter p_g controls greedy selection). PageRank vector η_F computed by simulating these biased walkers and used to predict human next transitions.",
            "exploration_efficiency_metric": "Predictive power for human next-node transitions measured by percentile rank improvement r_Stest (ratio of ranked-percentile performance of biased PageRank vs standard PageRank on held-out transitions). Also random-walk diffusion distance-from-start was analyzed.",
            "exploration_efficiency_value": "Improvement in predicting human transitions: IGT bias +2.9% ±2.9%; CPT bias +12.2% ±3.2%; combined IGT+CPT +32.2% ±7.7% (these are r_Stest percentage improvements reported for Wikispeedia).",
            "success_rate": null,
            "optimal_policy_type": "For prediction of human transitions, combining standard PageRank with curiosity-biased PageRank (linear combination) produced best predictive performance after parameter tuning.",
            "topology_performance_relationship": "CPT-biased walkers tended to remain closer to the initial node (in MovieLens and Wikispeedia), indicating that compressibility bias changes diffusion/locality properties; CPT produced larger predictive improvement in goal-directed Wikispeedia (suggesting compressibility-related topology features matter more in goal-directed navigation).",
            "comparison_across_topologies": false,
            "topology_comparison_results": "Not directly a topology comparison, but results indicate a larger benefit from CPT bias in the goal-directed Wikispeedia dataset than IGT bias, and substantial further gains when combining IGT and CPT biases.",
            "policy_structure_findings": "Biasing random-walk transition probabilities using learned Q-values (non-Markovian, history-dependent) improves alignment with human navigation choices compared to purely Markovian PageRank; CPT bias yields more localized walks (stays closer to start).",
            "uuid": "e1236.2",
            "source_info": {
                "paper_title": "Intrinsically Motivated Graph Exploration Using Network Theories of Human Curiosity",
                "publication_date_yy_mm": "2023-07"
            }
        },
        {
            "name_short": "MovieLensGraph",
            "name_full": "MovieLens user–movie graph (user browsing / selection)",
            "brief_description": "A graph representation of the MovieLens dataset (users and movies / item-item or user-item relations) used to test whether curiosity-biased PageRank better predicts human next-item choices than standard PageRank.",
            "citation_title": "Intrinsically Motivated Graph Exploration Using Network Theories of Human Curiosity",
            "mention_or_use": "use",
            "environment_name": "MovieLens graph (user-item browsing environment)",
            "environment_description": "Recommendation/choice environment where nodes represent movies (and possibly users), and edges encode relations (co-visitation or metadata); used to evaluate next-node recommendation predictive power of curiosity-biased centrality.",
            "graph_diameter": null,
            "clustering_coefficient": null,
            "dead_ends_present": null,
            "dead_ends_count": null,
            "door_constraints_present": false,
            "door_constraints_description": "",
            "graph_connectivity": "Not numerically specified in paper; described qualitatively as similar to Amazon Books (non-goal-directed selection with cluster structure influencing compressibility).",
            "environment_size": null,
            "agent_name": "Curiosity-biased PageRank (IGT and CPT biases) and standard PageRank baseline",
            "agent_description": "Personalized PageRank with hop vector q set to a user's n burn-in most recently visited nodes; transition probabilities biased using Q-values from GNNs trained with IGT/CPT to produce η_F vectors which are linearly combined with standard PageRank.",
            "exploration_efficiency_metric": "Predictive percentile rank for the actual next transition; reported improvement r_Stest compared to standard PageRank.",
            "exploration_efficiency_value": "Reported improvements: IGT +4.2% ±2.1%; CPT +5.1% ±1.5%; combined IGT+CPT +7.9% ±1.7% (r_Stest percent improvements on MovieLens test set).",
            "success_rate": null,
            "optimal_policy_type": "Combined curiosity-biased PageRank (linear combination of standard PageRank, IGT-biased and CPT-biased scores) after parameter tuning performed best for next-item prediction.",
            "topology_performance_relationship": "MovieLens and Amazon Books (non-goal-directed selection) both show improvements when including curiosity biases; CPT bias tends to keep walkers more local which can reflect user browsing patterns in these datasets.",
            "comparison_across_topologies": false,
            "topology_comparison_results": "N/A (single-dataset evaluation), but paper notes MovieLens and Amazon Books have similar selection mechanisms leading to similar improvements from biases.",
            "policy_structure_findings": "In non-goal-directed recommendation environments simple locality/compressibility biases (CPT) and gap-creating biases (IGT) both help; combining them gives the best predictive performance for next-node recommendations.",
            "uuid": "e1236.3",
            "source_info": {
                "paper_title": "Intrinsically Motivated Graph Exploration Using Network Theories of Human Curiosity",
                "publication_date_yy_mm": "2023-07"
            }
        },
        {
            "name_short": "AmazonBooksGraph",
            "name_full": "Amazon Books co-purchase/selection graph",
            "brief_description": "Graph derived from Amazon Books dataset representing relationships between books (co-purchase, co-view, or other edges) used to test curiosity-biased PageRank for predicting user next selections.",
            "citation_title": "Intrinsically Motivated Graph Exploration Using Network Theories of Human Curiosity",
            "mention_or_use": "use",
            "environment_name": "Amazon Books graph (user browsing / non-goal-directed selection)",
            "environment_description": "Recommendation/choice environment built from Amazon Books interactions; domain: online product browsing and selection represented as a graph.",
            "graph_diameter": null,
            "clustering_coefficient": null,
            "dead_ends_present": null,
            "dead_ends_count": null,
            "door_constraints_present": false,
            "door_constraints_description": "",
            "graph_connectivity": "Not numerically specified; presented qualitatively as similar to MovieLens with cluster structures influencing compressibility.",
            "environment_size": null,
            "agent_name": "Curiosity-biased PageRank (IGT and CPT biases) and standard PageRank",
            "agent_description": "Personalized PageRank with hop vector set to user's recent visited nodes; transition probabilities adjusted with Q-values from GNNs trained for IGT/CPT, producing candidate centrality vectors combined linearly with standard PageRank.",
            "exploration_efficiency_metric": "Predictive percentile rank improvement for held-out next-node transitions (r_Stest).",
            "exploration_efficiency_value": "Reported improvements: IGT +5.4% ±1.9%; CPT +4.6% ±1.6%; combined IGT+CPT +9.6% ±1.9% (r_Stest percent improvements on Amazon Books test set).",
            "success_rate": null,
            "optimal_policy_type": "Combination of standard PageRank and curiosity-biased PageRank vectors after tuning (linear mixture) gave the best predictive performance.",
            "topology_performance_relationship": "Non-goal-directed browsing in these datasets benefits from compressibility and gap-creation biases; local clustering patterns likely drive CPT effectiveness, though exact topology statistics are not reported.",
            "comparison_across_topologies": false,
            "topology_comparison_results": "N/A for cross-topology comparison; dataset-level results show both IGT and CPT provide modest improvements with their combination giving a larger boost.",
            "policy_structure_findings": "Biasing random-walk transitions with history-dependent Q-values (from curiosity-trained GNNs) improves human-choice prediction; CPT bias keeps walks more local which aligns with observed browsing patterns in some datasets.",
            "uuid": "e1236.4",
            "source_info": {
                "paper_title": "Intrinsically Motivated Graph Exploration Using Network Theories of Human Curiosity",
                "publication_date_yy_mm": "2023-07"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Wikispeedia: An online game for inferring semantic distances between concepts.",
            "rating": 2,
            "sanitized_title": "wikispeedia_an_online_game_for_inferring_semantic_distances_between_concepts"
        },
        {
            "paper_title": "Human wayfinding in information networks.",
            "rating": 2,
            "sanitized_title": "human_wayfinding_in_information_networks"
        },
        {
            "paper_title": "Quantifying the compressibility of complex networks.",
            "rating": 2,
            "sanitized_title": "quantifying_the_compressibility_of_complex_networks"
        },
        {
            "paper_title": "PageRank beyond the web.",
            "rating": 1,
            "sanitized_title": "pagerank_beyond_the_web"
        },
        {
            "paper_title": "A large-scale characterization of how readers browse Wikipedia.",
            "rating": 1,
            "sanitized_title": "a_largescale_characterization_of_how_readers_browse_wikipedia"
        },
        {
            "paper_title": "Random walk for generalization in goal-directed human navigation on Wikipedia.",
            "rating": 1,
            "sanitized_title": "random_walk_for_generalization_in_goaldirected_human_navigation_on_wikipedia"
        }
    ],
    "cost": 0.015562,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Intrinsically Motivated Graph Exploration Using Network Theories of Human Curiosity
1 Dec 2023</p>
<p>Shubhankar P Patankar 
University of Pennsylvania</p>
<p>Mathieu Ouellet ouellet@seas.upenn.edu 
University of Pennsylvania</p>
<p>Juan Cerviño jcervino@seas.upenn.edu 
University of Pennsylvania</p>
<p>Alejandro Ribeiro aribeiro@seas.upenn.edu 
University of Pennsylvania</p>
<p>Kieran A Murphy kieranm@seas.upenn.edu 
University of Pennsylvania</p>
<p>Dani S Bassett 
University of Pennsylvania</p>
<p>Intrinsically Motivated Graph Exploration Using Network Theories of Human Curiosity
1 Dec 2023634A12F96A5735B86DC6241BD6BC8726arXiv:2307.04962v4[cs.LG]
Intrinsically motivated exploration has proven useful for reinforcement learning, even without additional extrinsic rewards.When the environment is naturally represented as a graph, how to guide exploration best remains an open question.In this work, we propose a novel approach for exploring graph-structured data motivated by two theories of human curiosity: the information gap theory and the compression progress theory.The theories view curiosity as an intrinsic motivation to optimize for topological features of subgraphs induced by nodes visited in the environment.We use these proposed features as rewards for graph neural-network-based reinforcement learning.On multiple classes of synthetically generated graphs, we find that trained agents generalize to longer exploratory walks and larger environments than are seen during training.Our method computes more efficiently than the greedy evaluation of the relevant topological properties.The proposed intrinsic motivations bear particular relevance for recommender systems.We demonstrate that next-node recommendations considering curiosity are more predictive of human choices than PageRank centrality in several real-world graph environments.</p>
<p>Introduction</p>
<p>Providing a task-agnostic incentive for exploration as an intrinsic reward has proven useful for reinforcement learning, even in the absence of any task-specific (extrinsic) rewards [1,2].Termed curiosity in reference to the analogous drive in humans, prior formulations are based on different means of quantifying the novelty or surprisal of states encountered by an agent [3].If states are represented as graphs, the task-agnostic motivation to explore can additionally be content-agnostic, depending only on the topological properties of the visited state subgraph.Leading theories of human curiosity are similarly content-agnostic, based only on the structural properties of a relational graph connecting atoms of knowledge without regard to their actual content [4].</p>
<p>Theories of curiosity seek to describe the intrinsic motivations that underlie human decision-making when acquiring information through exploration.The information gap theory (IGT) argues that curiosity collects knowledge to regulate gaps in our understanding of the world [5].Exposure to a small amount of novel information pushes an individual's uncertainty about the environment past an acceptable threshold, creating an information gap.Curious agents are driven to resolve the discrepancy by acquiring information to close the gap [6,7].An alternative account, the compression progress theory (CPT), posits that information-seeking behavior is motivated to build increasingly compressible state representations [8,9].Compression enables abstraction and improved generalization by emphasizing the essential latent structures of knowledge [10][11][12].Both theories provide optimization objectives for the human exploration of graph-structured environments.In this work, we demonstrate that network theoretic measurements of information gaps and compression progress can be meaningful exploration incentives for graph neural network (GNN)-based reinforcement learning (RL).Here, similar to human curiosity, which is typically conceived of as being non-instrumental, and unlike traditional RL formulations, where artificial curiosity is a means to an end, exploration itself is the broader goal.To that end, we train GNN agents to explore graph-structured environments while optimizing for gap creation and improved compression (Figure 1).Additionally, we use GNNs trained with human curiosity rewards to modify PageRank centrality.We measure an alternative form of PageRank by biasing underlying random walks towards nodes that create information gaps or improve network compressibility.We use human exploration trajectories acquired from spaces that can be naturally represented as graphs-movies, books, and Wikipedia-to evaluate predictions of user choices made by PageRank against those made by our new metric.</p>
<p>Our primary contributions are the following:</p>
<p>• We adapt intrinsic motivations for human curiosity as reward functions for reinforcement learning.</p>
<p>• We replace expensive reward computations with graph neural networks.Subject to training costs, our method is computationally efficient and generalizes to longer exploratory walks and larger environments than are seen during training.• We demonstrate that incorporating curiosity into PageRank centrality leads to better predictions of human preferences compared to standard PageRank.</p>
<p>Related work</p>
<p>Human curiosity as graph exploration.Curiosity in humans is conceptualized as the intrinsic motivation to gather information from the environment [5,13,14].Humans acquire information even when it is expensive [15,16] and may have no tangible utility [17,18], suggesting that exploration is inherently valuable.Recent work has expanded the traditional knowledge acquisition perspective on curiosity by also considering how units of knowledge relate to each other.This perspective defines curiosity as an exploratory walk on a graph.Here, curiosity entails building a growing knowledge network by acquiring informational units as nodes and their relationships as edges [4,19].The state of an individual's knowledge is viewed as the subgraph of the environment induced by the visited nodes [20,21].Under this formulation, humans explore Wikipedia via trajectories with fewer information gaps and greater network compressibility than relevant null models [21].</p>
<p>Intrinsic motivations in reinforcement learning.The need for improved exploration has led reinforcement learning to incorporate curiosity-like intrinsic motivations into its algorithmic framework [22,23].Exploration rewards in RL take several forms.At the core of all approaches is an inducement for the learning agent to seek novelty.Count-based approaches encourage visits to unfamiliar or infrequently visited states [24][25][26][27][28].When the state space is large, enumerating the frequencies of visits to all possible states is expensive.To overcome this challenge, density models derive uncertainty-based pseudo-counts [24,25].A complementary perspective emphasizes model building and formulates curiosity in terms of learning progress and surprisal [1,9,[29][30][31][32].For instance, in the prediction error approach-alongside an extrinsic task-the agent attempts to learn a model of the environment's dynamics.Curiosity rewards are proportional to the error when predicting transitions between states.Memory-based methods assign rewards considering how different a newly visited state is from those stored in memory [33,34].Instead of a prescriptive approach, parametric methods attempt to explicitly learn an intrinsic reward function [35][36][37][38].In general, improved exploration is a means to an end, with intrinsic rewards supplementing extrinsic task-specific rewards.</p>
<p>Graph combinatorial optimization and reinforcement learning.Combinatorial optimization entails selecting elements from a finite set of options such that the chosen subset satisfies an objective function [39].Graph analyses often involve combinatorial optimization, with graph structure imposing constraints on the solution space.Recent work combines graph neural networks and reinforcement learning to construct solutions by incrementally adding nodes to a partial set [40][41][42].First, a GNN constructs an embedding for the candidate solution; second, an agent, for instance, a deep Q-network (DQN), trained via RL, selects an action to expand the solution [43].The two networks can be trained end-to-end with an optimization objective driving gradients for learning.This approach solves various graph combinatorial tasks, such as the traveling salesperson problem [43][44][45], finding the maximum independent set [46], or the minimum vertex cover [43,47], and identifying isomorphic subgraphs [48].Instead of uncovering nodes, GNNs can also sequentially collapse nodes into each other with implications for matrix multiplication [49].Recent work has also sought to formulate the graph exploration task explicitly as a Markov decision process, using domain-specific node features and novelty rewards [50,51].GNNs, in combination with RL, have also been used to build and rewire graphs such that they possess high values of specific features of interest [52,53].</p>
<p>PageRank and human navigation on graphs.PageRank seeks to model and predict online human browsing preferences.PageRank assigns centrality scores to web pages, considering their importance and relevance, determined by the number and quality of links between pages [54].It employs a random walks-based approach that includes occasional jumps, known as teleportation, to simulate the likelihood that users will transition between different pages [55].Beyond its initial application to serving search results, PageRank has found broad utility in modeling human navigation in other graphstructured environments [54].PageRank-based recommendations show alignment with empirical observations of human behavior [56][57][58][59].Further, topological characteristics of the underlying graph impact user navigation, underscoring the importance of considering connectivity patterns when forecasting noisy human preferences [60].The PageRank algorithm explicitly factors topology into its computations by adjusting the underlying random walk process, aligning either the transition or teleportation weights with the environment's topological features [57,61].</p>
<p>Methods</p>
<p>Our goal is to train an agent to explore while optimizing for a structural property of the visited subgraph.Consider a graph-structured environment G = (V, E) with node set V and edge set
E ⊆ V × V. Let V T = {v 1 , v 2 , • • • , v T } ⊆ V be an ordered set of explored nodes at time T . The corresponding subgraph trajectory is the sequence S 1 ⊂ S 2 ⊂ • • • ⊂ S T
, wherein the t-th subgraph S t is induced by the first t visited nodes.Specifically, given the graph G, the number of nodes to visit T , a graph feature function F : 2 G → R, and a discount factor γ ∈ [0, 1], we seek an ordered set
V * T such that T t=1 γ t−1 F(S t
) is maximal.The function F acts as an intrinsic reward to encourage exploration.The discounting parameter determines the extent to which future values of F factor into the decision-making at each step.Drawing inspiration from human curiosity, we adopt information gap theory and compression progress theory to design two reward functions, F IGT and F CP T .</p>
<p>Network theories of curiosity</p>
<p>Information gap theory views human curiosity as an intrinsic motivation to regulate gaps in knowledge.Exposure to new information pushes the level of uncertainty about the environment past an acceptable threshold, creating an uncertainty gap.Curiosity seeks to find information units to close this gap.By modeling the state of knowledge as a graph, we can characterize information gaps as topological cavities.In a graph, cavities can take several forms: dimension 0 cavities represent disconnected network components, whereas those of dimension 1, known as 1-cycles, represent non-triangular loops of edges (Figure 2A).In order to identify and count topological cavities, a graph is first converted into a higher-order relational object known as a simplicial complex [62].A simplicial complex is comprised of simplices.Geometrically, a d-simplex is a shape with flat sides formed by connecting d + 1 points.For 0 ≤ d ≤ 2, by definition a node is a 0-simplex, an edge is a 1-simplex, and a filled triangle is a 2-simplex.We can construct a simplicial complex by assigning a d-simplex to each (d + 1)-clique in a binary graph.In a simplicial complex, a d-dimensional topological cavity is identified as an enclosure formed by d-simplices that cannot be filled by a higher-dimensional simplex.We refer the reader to Refs.[63][64][65][66][67] for more details on algebraic topology.</p>
<p>Given a simplicial complex, the d-th Betti number β d counts the number of topological gaps of dimension d.Prior work examining human curiosity finds compelling evidence in support of information gap theory.In particular, humans create induced subgraphs with an increasing number of 1-dimensional cavities [21].Therefore, in this work, at each time step t with a visited subgraph S t , we assign rewards equal to β 1 , that is, we set F IGT = β 1 (S t ).The information rate of a random walk x on a graph is given by its entropy.If we cluster the nodes, the walk sequence x is compressed into a new sequence y, where y is the cluster that contains node x.The new sequence has a lower information rate than the original sequence.The number of clusters defines the scale at which the network is described.We can find an optimal clustering at every scale of description that maximally lowers the information rate.These values can be recorded in a rate-distortion curve.Network compressibility is the maximal reduction in the information rate, averaged across all scales.Graphically, this value represents the area above the rate-distortion curve bounded by the entropy of the unclustered random walk.</p>
<p>Compression progress theory posits that curiosity is a drive to compress the state of knowledge [8].During graph exploration, at each step t in a trajectory, a reward for compression can be assigned as network compressibility [68].Consider a subgraph S t with t nodes and q edges, represented by a symmetric adjacency matrix M ∈ R t×t .Information about the subgraph's structure can be encoded in the form of a random walk x = (x 1 , x 2 , . . .).The walk sequence is generated by randomly transitioning from a node to one of its neighbors.Thus, for a random walk on S t , the probability of transitioning from node i to node j is P ij = M ij / j M ij .Since the walk is Markovian, its information content (or entropy) is given by H = − i π i j P ij log P ij .Here, π i is the stationary distribution representing the long-term probability that a walk arrives at node i, given by π i = j M ij /2q.</p>
<p>Assigning nodes to clusters leads to a coarse-grained sequence y = (y 1 , y 2 , . . .).The number of clusters n can be used to define a scale of the network's description s = 1 − n−1 t .When n = t, the network is described at a fine-grained scale s = 1/t; at the other extreme, when n = 1 the network is described at the coarsest scale s = 1.At every description scale in between, it is possible to identify a clustering of nodes that minimizes the information rate (Figure 2B).After computing these optimal clusterings across all scales, we arrive at a rate-distortion curve R(s), representing a bound on the information rate as a function of the scale s.The compressibility C of the network is then given as the average reduction in the information rate across all scales [68], C = H − 1 t s R(s).Human curiosity in graph-structured environments leads to induced subgraphs with increasing network compressibility [21].Therefore, we assign compression rewards as F CP T = C(S t ), where C(S t ) denotes the compressibility of subgraph S t .</p>
<p>Reinforcement learning for graph exploration</p>
<p>We formulate the graph exploration problem as a Markov decision process (MDP) [69]:</p>
<p>• States: The state is defined as the subgraph induced by the visited nodes at time t,
S t = G[V t ].
We specify the initial state S 1 by randomly selecting a starting node v 1 ∈ V.Each state represents a partial solution to the broader sequential exploration task.• Actions: The agent can transition to a neighbor of the most recently visited node.We denote the neighborhood of a node v as N (v) = {u ∈ V | (v, u) ∈ E}.Therefore, given the state at time t, the set of available next nodes is A(S t ) = N (v t )\V t .If no nodes are available in the immediate neighborhood, we expand the action set to include all neighbors of the explored subgraph.• Transitions: Given the pair S t and v ∈ A(S t ), the transition to state S t+1 is deterministic with P (S t+1 | S t , v) = 1.• Rewards: The reward at time t is defined as R t = F(S t ).Considering information gap theory, we reward agents for visiting nodes that create 1-cycles (F IGT ).Considering compression progress theory, we reward agents for visiting nodes that improve network compressibility (F CP T ).</p>
<p>The policy π(v | S t ) maps states to actions, fully describing the agent's behavior in the environment.At each step, the agent makes decisions using a value function Q(S t , v), which evaluates candidate nodes v ∈ A(S t ) in the context of the currently explored subgraph S t .The function measures the total (discounted) reward that is expected to accumulate if the agent selects action v in state S t and thereafter follows policy π.In turn, the policy can be viewed as behaving greedily with respect to the value function, π = arg max v∈A(St) Q (S t , v).Solving an MDP entails finding an optimal policy that maximizes the expected discounted sum of rewards.</p>
<p>We parameterize the value function Q using a GNN Φ(•) : G → R. GNNs build vector embeddings for nodes by iteratively aggregating their features with those from their local neighborhoods [70].Each aggregation step is typically followed by a fully connected layer and a non-linear activation function.Depending on the number of rounds of aggregation, features from more distant locations in the graph can inform the embedding for each node.Specifically, we use the GraphSAGE architecture [71], where at the l-th round of feature aggregation, the embedding for node u is given as,
h (l) u = f (l) h (l−1) u , h (l−1) N (u) = g θ (l) C h (l−1) u + θ (l) A Ã h (l−1) N (u) ,(1)
where Ã represents the aggregation operator, g [.] is the activation function, and θ C and θ A are parameters for combination and aggregation, respectively [42,71].Our choice of GraphSAGE is motivated not by its sampling-based approach but rather by its capacity for inductive learning.Therefore, we do not perform neighbor sampling during feature aggregation.Further, considering that leading network theories of human curiosity are agnostic to the precise content of individual nodes, we only use the local degree profile (LDP) of each node as the initial feature set [72].LDP comprises features of a node's neighborhood, including its degree, the minimum and maximum degrees of its neighbors, and the average and standard deviation of the degrees of its neighbors.</p>
<p>We train GNNs for exploration using the DQN algorithm, with a replay buffer for experience sampling, a target network, and a decaying ϵ-greedy exploration rate [73].Details of the full neural network architecture and the training process are included in the Supplement.</p>
<p>Curiosity-biased node centrality</p>
<p>Several graph theoretical quantities can be defined in terms of random walk processes.We can use agents trained to explore graphs to bias random walkers and, by extension, the corresponding quantities.PageRank is a widely recognized algorithm that assigns node centrality scores to graph data [54,55,74,75].The per-node score η can be interpreted as the stationary distribution of a random walk process on a network.With probability α, a random walker moves along an edge from node v i to one of its neighbors.The probability of reaching a connected node v j is P ij .Alternatively, with probability 1 − α, the walker jumps, or teleports, to a random node in the network.The probability of jumping to node v k is q k .Under conditions of irreducibility and aperiodicity [76], the stationary distribution is given as
i (I − αP t ij )η i = (1 − α)q j .(2)
The PageRank algorithm follows a random walk that is entirely Markovian.Typically, the probability P ij depends solely on the out-degree of node v i and, in the case of node-weighting, on the vector q.Personalized PageRank biases the random walk process using q k by taking into account nodes that are already visited in the network [77].</p>
<p>Adaptations of PageRank often incorporate biases in the weighting scheme or the teleportation mechanism to better predict human navigation in graph-structured environments [56][57][58][59][60][61].We can integrate agents trained to optimize for the exploration objectives described earlier into the PageRank algorithm in the form of similar biases.Specifically, given an already visited subgraph, we propose to modify transition probabilities using the Q-values assigned to candidate nodes.Consider a non-Markovian random walker sitting at node v l with a path history
V l = {v 1 , • • • , v l−1 , v l }.
The visited nodes in the path induce a corresponding subgraph S l .Paths are built starting from the most recent initialization or teleportation event.We use a Q-value function trained to optimize for an objective F to bias the walker.The transition probability from node v l to node v m can be re-defined as,
P F lm (S l ) ≡ (1−pg)p rank(Q(S l ,vm ))−1 g 1−p |A(S l )| , v m ∈ A(S l ), 0, otherwise,(3)
where rank(Q(S l , v m )) is the rank for v m considering the Q-values for the candidate nodes and p g ∈ [0, 1] is a parameter that controls how likely the walker is to select nodes greedily.To compute biased per-node PageRank values, we simulate a walker using P F ij (S i ) until probabilities converge.</p>
<p>Experiments</p>
<p>Exploration in synthetically generated networks</p>
<p>We train a curiosity-based GNN agent to explore synthetically generated graph environments that exhibit a broad range of degree profiles and topologies [78,79].We examine synthetic networks generated using the random geometric (RG), Watts-Strogatz (WS), Barabási-Albert (BA), and Erdös-Rényi (ER) graph models.Details surrounding the generation process are available in the Supplement.</p>
<p>For each of the four graph models, we build 100 training, 10 validation, and 10 testing environments.Each environment is constructed to have N = 50 nodes.Each episode lasts for 10 steps and, therefore, consists of visits to 10 distinct nodes.After training, we evaluate the GNN agent in the testing environments against four baseline approaches:</p>
<p>• Random: Select a candidate node at random.Table 1: Performance of GNN-based agents using information gap theory (IGT) and compression progress theory (CPT) compared to four baseline methods (random, max degree, min degree, greedy).We compare results using the total average return gathered by agents in four types of synthetic graph environments (random geometric -RG, Watts-Strogatz -WS, Barabási-Albert -BA, Erdős-Rényi -ER).</p>
<p>The total average reward gathered by the different agents is presented in Table 1.For the IGT reward, in all graph models except for ER, the GNN outperforms the greedy agent.By contrast, the one-step-ahead greedy agent consistently performs best for CPT, with the GNN a close second.Baseline approaches broadly perform well compared to the GNN for CPT than they do for IGT.When exploring a graph with the IGT objective, adding a single node can close several topological gaps simultaneously, requiring careful consideration of options.By contrast, compressibility is less sensitive to the choice of node at each step due to its strong correlation with the clustering coefficient [68].If exploring inside a cluster, neighbors of a node are likely to be neighbors of each other, lowering the likelihood that a single choice will significantly alter long-term network compressibility.For instance, the max degree baseline performs well for the CPT objective in random geometric graphs because high-degree nodes are centrally placed and surrounded by dense, highly clustered neighborhoods [79].Barabási-Albert graphs, similarly, have highly clustered cores due to preferential attachment in their generative process [80].Watts-Strogatz networks have high clustering when the edge rewiring probability is low.As a result, even random exploration in such topologies tends to occur inside clusters leading to greater compressibility.In support of this view, the minimum degree baseline, which is likely to select a node outside of a cluster, is typically further apart from the performance of the GNN compared to the other baselines.After training the GNN agent to explore 10 nodes in RG graph environments with 50 nodes, we evaluate generalization performance for longer trajectories and larger environments.We test trajectory length generalization while holding environment size fixed at 50 nodes.For walks shorter and longer than 10 steps, the GNN performs comparably to the greedy agent for both IGT and CPT (Figure 3).Next, we test environment size generalization by evaluating 10-step walks in graph environments that are larger than 50 nodes.In environments that are up to two orders of magnitude larger than those seen during training, the GNN is consistently superior to the greedy agent for IGT and exhibits comparable performance for CPT (with an average return of 9.4 compared to 10).In summary, the performance of trained GNNs does not degrade for settings outside the training regime.These results indicate that we can train GNNs for graph exploration in regimes where reward computations are relatively inexpensive due to the smaller size of subgraphs and expect them to scale to longer walks and larger networks.</p>
<p>Trajectory length and environment size generalization</p>
<p>Time complexity</p>
<p>Using graphs of different sizes, we evaluate the computational efficiency of our approach by comparing the wall time for a forward pass through the GNN with that for a greedy evaluation of the two By contrast, the computational complexity for the GNN grows linearly as O(|S t |).Comparing the rewards for the two theories of curiosity, the information gap reward is significantly cheaper to evaluate compared to network compressibility.Therefore, in addition to approximating human intrinsic motivations for exploration, we find that the GNN offers a route to efficient computation of meaningful topological features of graphs.</p>
<p>Predicting human choices during graph navigation</p>
<p>Next, we evaluate the utility of curiosity-trained agents for predicting human choices in graphstructured environments.We gather human trajectories of graph exploration from three real-world datasets: MovieLens [82], Amazon Books [83,84], and Wikispeedia [85,86].Each dataset can be naturally represented as a graph-structured environment.Details on how we process the data are available in the Supplement.We train GNNs for graph exploration in each environment for both information gap theory and compression progress theory.We use GNNs trained with curiosity rewards to bias PageRank centrality to predict next nodes visited by humans.</p>
<p>To incorporate person-specific data when computing PageRank, we modify the hop vector q to be zero for all nodes except a user's n burn-in most recently visited nodes [77].We assign a uniform jump probability to the n burn-in nodes, with q k = 1/n burn-in .Each graph feature function F yields a PageRank vector η F i .We combine these vectors linearly to obtain a final PageRank vector, denoted as η ′ such that η ′ ≡ βη PR (α) + γη IGT (α) + δη CPT (α) where β2 + γ2 + δ2 = 1 and η PR is the score vector obtained using standard PageRank.To evaluate this approach, we optimize the set of variables α, β, γ, δ using a training set of transitions.We then compare performance against unbiased PageRank, where only α is optimized.We split the set of user trajectories acquired from each dataset into S test and S train .These sets consist of portions of human trajectories with a length of n burn-in + 1. Next, we perform Bayesian optimization to compute parameters â and âbias for the two sets,
â ≡ arg max α S∈Strain rank vburn-in (η PR (α))(4)
âbias ≡ arg max α, β,γ, δ S∈Strain rank vburn-in (η ′ (α, β, γ, δ)).</p>
<p>To evaluate our method, we calculate the ratio of improvement on the test set, given as  Figure 5B shows the improvement in predicting the transitions made by humans in the Wikispeedia dataset.We compare percentile ranks for each transition made by the human when making predictions with and without biasing the random walk process.We find that biased curiosity assigns higher percentile ranks to actual transitions than standard PageRank.We also analyze the distance from the initial node with respect to time for individual random walk trajectories (Figure 5C).In general, observed differences between the biased walkers are small and fall within the standard deviation of the walk process.However, the CPT-biased walker stands out as it tends to remain closer to the initial node in both the MovieLens and the Wikispeedia datasets (see Supplement).These observations suggest that the differences observed in the biased PageRank algorithm are not solely attributable to changes in the diffusion properties of the random walks.
r Stest ≡ S∈Stest rank vburn-in (η ′ (â bias ))/ S∈Stest rank vburn-in (η PR (â)).(6)</p>
<p>Discussion</p>
<p>How to measure curiosity best remains an open question both in the context of humans and for reinforcement learning.While our specific choices-1-cycles and network compressibility-are motivated by recent work studying human behavior, other topological features may be more suited to drive graph exploration.Nonetheless, through our work, we demonstrate the utility of contentagnostic topology-aware intrinsic motivations.Similar to leading theories of human curiosity that are intentionally content independent, our method 1) uses no node information other than topological statistics and 2) uses no information in the reward other than what is available in the structure of visited subgraphs.Even at this level of abstraction, where topology takes precedence over content, we show that agents learn generalizable and transferable graph exploration strategies.Further, we show that agents trained with human-like motivations can help devise centrality measures that predict human behavior better than PageRank.This result has two critical implications.First, we can use our method to test hypotheses about human motivations when navigating graph-structured environments.</p>
<p>Trained agents can act as hypothesis testers by examining whether their choices for the subsequent nodes to visit align with human choices.Second, our method can be used to design recommender systems for environments where human navigation of graphs is largely goalless.</p>
<p>Figure 1 :
1
Figure 1: Neural network for graph exploration.The subgraph induced by the set of currently visited nodes is denoted in orange.Candidate nodes to visit at the next time step are denoted in green.We build candidate subgraphs by adding each neighbor to the already visited subgraph.The candidates are processed with a GNN to obtain Q-values, denoting their long-term potential to create or close gaps or to improve compressibility.Two example trajectories are shown: one with a high number of gaps and one with greater compressibility.</p>
<p>Figure 2 :
2
Figure 2: Quantifying network theories of human curiosity.(A) Gaps or cavities in a graph can be formalized using algebraic topology.A 1-dimensional cavity, also known as a 1-cycle, is a non-triangular loop of edges.(B)The information rate of a random walk x on a graph is given by its entropy.If we cluster the nodes, the walk sequence x is compressed into a new sequence y, where y is the cluster that contains node x.The new sequence has a lower information rate than the original sequence.The number of clusters defines the scale at which the network is described.We can find an optimal clustering at every scale of description that maximally lowers the information rate.These values can be recorded in a rate-distortion curve.Network compressibility is the maximal reduction in the information rate, averaged across all scales.Graphically, this value represents the area above the rate-distortion curve bounded by the entropy of the unclustered random walk.</p>
<p>Figure 3 :
3
Figure 3: Trajectory length and environment size generalization.GNNs trained for graph exploration generalize to shorter and longer trajectories and to smaller and larger environments than are seen during training.We train GNNs to explore 10 steps for IGT and CPT in random geometric environments with 50 nodes.Performance does not degrade for exploratory walks of a different length in 50-node environments.Similarly, when taking 10 steps, GNN-based agents outperform or match the greedy agent in smaller and larger environments than those of size 50 that are seen during training.Bands denote standard error.</p>
<p>Figure 4 :
4
Figure 4: Wall time.Wall time for a forward pass through the GNN compared to the greedy evaluation of rewards.Bands denote standard error over computations for 50 networks.</p>
<p>Figure 5 :
5
Figure 5: Re-defining centrality using agents trained for curiosity.(A) We measure curiosity-biased PageRank centrality using a set of biased walkers that explore the graph starting from a subset of already visited nodes.Biases are incorporated using GNNs trained for IGT and CPT rewards.(B) Example demonstrating the improvement in predicting human transitions when using curiosity-biased versus standard PageRank.Biased curiosity assigns higher percentile ranks to actual transitions than standard PageRank.(C) Random walker diffusion, measured as the distance from the initial node for each graph.A comparison is made between the unbiased (blue), IGT-biased (orange), and CPT-biased walkers (green).</p>
<p>• Greedy: For each candidate node, build a candidate state subgraph.Evaluate the reward function for each subgraph and select the node that results in the biggest one-step improvement.• Max Degree: Select the candidate node with the largest degree.• Min Degree: Select the candidate node with the smallest degree.±0.068 1.048 ±0.068 1.586 ±0.082 2.707 ±0.103 3.303 ±0.106 BA 7.593 ±0.145 2.565 ±0.083 3.932 ±0.115 19.332 ±0.206 21.970 ±0.169 ER 9.197 ±0.144 9.638 ±0.162 4.953 ±0.127 25.20 ±0.164 24.058 ±0.183 CPT RG 8.607 ±0.027 8.928 ±0.027 7.864 ±0.033 9.615 ±0.014 9.271 ±0.017 WS 7.117 ±0.021 6.788 ±0.025 6.937 ±0.021 7.668 ±0.012 7.174 ±0.014 BA 6.926 ±0.023 8.526 ±0.015 5.899 ±0.016 8.669 ±0.016 8.556 ±0.010 ER 6.767 ±0.020 6.931 ±0.019 6.022 ±0.017 8.262 ±0.016 7.880 ±0.015
FGRandomMax Degree Min Degree GreedyGNNIGT RG 0.312 ±0.034 0.010 ±0.007 0.144 ±0.027 1.495 ±0.0792.308 ±0.092WS 1.141</p>
<p>[81]insically Motivated Graph Exploration Using Network Theories of Human Curiosity reward functions.Figure4displays results for RG graphs.Wall time for greedy evaluation of the IGT and CPT objectives grows quickly with subgraph size, while the GNN offers a faster alternative.Calls to F IGT scale according to O(|S t | 2 )[81], whereas those to F CP T scale according to O(|S t | 3 ).</p>
<p>Table 2 displays
2
r Stest in percentage terms for the three datasets when considering curiosity theories alone or in combination.Across all combinations, improvement ranges from 2.9% to 32.2%, indicating that incorporating curiosity for the biasing of walks is useful.The IGT or CPT-trained agents perform better with roughly similar values depending on the dataset.In the Wikispeedia data, however, CPT leads to improvement nearly four times higher than IGT.The books and movie datasets exhibit similarities since the selection mechanism in both environments is not directed towards a goal.By contrast, the Wikispeedia dataset involves goal-directed navigation.We provide illustrative examples from the MovieLens dataset of user paths alongside predictions made by both unbiased and curiosity-biased PageRank in the Supplement.
Graph dataset GIGTCPTIGT + CPTMovieLens+4.2% ±2.1%+5.1% ±1.5%+7.9% ±1.7%Amazon Books +5.4% ±1.9%+4.6% ±1.6%+9.6% ±1.9%Wikispeedia+2.9% ±2.9% +12.2% ±3.2% +32.2% ±7.7%</p>
<p>Table 2 :
2
Percentage improvement (r Stest ) with curiosity-biased centrality for the MovieLens, Amazon Book, Wikispeedia datasets.</p>
<p>Curiosity-driven exploration by self-supervised prediction. Deepak Pathak, Pulkit Agrawal, Alexei A Efros, Trevor Darrell, Proceedings of the 34th International Conference on Machine Learning. the 34th International Conference on Machine Learning2017703</p>
<p>Large-scale study of curiosity-driven learning. Yuri Burda, Harri Edwards, Deepak Pathak, Amos Storkey, Trevor Darrell, Alexei A Efros, ICLR. 2019</p>
<p>BYOL-explore: Exploration by bootstrapped prediction. Zhaohan Daniel Guo, Shantanu Thakoor, Miruna Pislar, Bernardo Avila Pires, Florent Altché, Corentin Tallec, Alaa Saade, Daniele Calandriello, Jean-Bastien Grill, Yunhao Tang, Michal Valko, Remi Munos, Advances in Neural Information Processing Systems. Mohammad Gheshlaghi, Azar , Bilal Piot, 2022</p>
<p>The growth and form of knowledge networks by kinesthetic curiosity. Dale Zhou, David M Lydon-Staley, Perry Zurn, Danielle S Bassett, 10.1016/j.cobeha.2020.09.007.URLhttps://www.sciencedirect.com/science/article/pii/S235215462030142X.1,2Current Opinion in Behavioral Sciences. 2352-1546352020</p>
<p>The psychology of curiosity: A review and reinterpretation. George Loewenstein, Psychological Bulletin. 11611994</p>
<p>The wick in the candle of learning: Epistemic curiosity activates reward circuitry and enhances memory. Min Jeong Kang, Ming Hsu, Ian M Krajbich, George Loewenstein, M Samuel, Joseph Tao Yi Mcclure, Colin F Wang, Camerer, 10.1111/j.1467-9280.2009.02402.x19619181Psychological Science. 2082009</p>
<p>Intrinsically motivated oculomotor exploration guided by uncertainty reduction and conditioned reinforcement in non-human primates. Nabil Daddaoua, Manuel Lopes, Jacqueline Gottlieb, 10.1038/srep20202Scientific Reports. 61202022016</p>
<p>Driven by compression progress: A simple principle explains essential aspects of subjective beauty, novelty, surprise, interestingness, attention, curiosity, creativity, art, science, music, jokes. Juergen Schmidhuber, 200814arXiv pre-print</p>
<p>Formal theory of creativity, fun, and intrinsic motivation. Jürgen Schmidhuber, 10.1109/TAMD.2010.2056368.1IEEE Transactions on Autonomous Mental Development. 2331990-2010. 2010</p>
<p>How to grow a mind: Statistics, structure, and abstraction. Joshua B Tenenbaum, Charles Kemp, Thomas L Griffiths, Noah D Goodman, 10.1126/science.1192788Science. 33160222011</p>
<p>The cost of structure learning. G E Anne, Collins, 10.1162/jocn_a_01128Journal of Cognitive Neuroscience. 0898-929X291010 2017</p>
<p>Learning structures: predictive representations, replay, and generalization. Current Opinion in Behavioral Sciences. Ida Momennejad, 202032</p>
<p>Informationseeking, curiosity, and attention: computational and neural mechanisms. Jacqueline Gottlieb, Pierre-Yves Oudeyer, Manuel Lopes, Adrien Baranes, 10.1016/j.tics.2013.09.001.URLhttps://www.sciencedirect.com/science/article/pii/S1364661313002052.2Trends in Cognitive Sciences. 1364-661317112013</p>
<p>The psychology and neuroscience of curiosity. Celeste Kidd, Benjamin Y Hayden, 10.1016/j.neuron.2015.09.010.URLhttps://www.sciencedirect.com/science/article/pii/S0896627315007679.2Neuron. 0896-62738832015</p>
<p>The Pandora effect: The power and peril of curiosity. Christopher K Hsee, Bowen Ruan, Psychological Science. 2752016</p>
<p>Smokers' curiosity for tobacco-related trivia aids memory of tobacco-related information. Jaydin Clark, Asia Vincent, Xinyi Wang, Amanda L Mcgowan, David M Lydon-Staley, PsyArXiv. 22021</p>
<p>Intrinsic valuation of information in decision making under uncertainty. Daniel Bennett, Stefan Bode, Maja Brydevall, Hayley Warren, Carsten Murawski, 10.1371/journal.pcbi.1005020PLOS Computational Biology. 1272016</p>
<p>The neural encoding of information prediction errors during non-instrumental information seeking. Maja Brydevall, Daniel Bennett, Carsten Murawski, Stefan Bode, 10.1038/s41598-018-24566-xScientific Reports. 8161342018</p>
<p>On curiosity: A fundamental aspect of personality, a practice of network growth. Perry Zurn, Danielle S Bassett, 10.1017/pen.2018.3.2Personality Neuroscience. 1e132018</p>
<p>Hunters, busybodies and the knowledge network building associated with deprivation curiosity. M David, Dale Lydon-Staley, Ann Sizemore Zhou, Perry Blevins, Danielle S Zurn, Bassett, 10.1038/s41562-020-00985-7Nature Human Behaviour. 532021</p>
<p>Curiosity as filling, compressing, and reconfiguring knowledge networks. P Shubhankar, Dale Patankar, Christopher W Zhou, Jason Z Lynn, Mathieu Kim, Harang Ouellet, Perry Ju, Zurn, M David, Dani S Lydon-Staley, Bassett, 10.1177/26339137231207633Collective Intelligence. 242023</p>
<p>A survey on intrinsic motivation in reinforcement learning. Arthur Aubret, Laetitia Matignon, Salima Hassas, 2019arXiv pre-print</p>
<p>Exploration in deep reinforcement learning: A survey. Pawel Ladosz, Lilian Weng, Minwoo Kim, Hyondong Oh, org/10.1016/j.inffus.2022.03.003Information Fusion. 1566-2535852022</p>
<p>Unifying count-based exploration and intrinsic motivation. G Marc, Sriram Bellemare, Georg Srinivasan, Tom Ostrovski, David Schaul, Rémi Saxton, Munos, Proceedings of the 30th International Conference on Neural Information Processing Systems, NIPS'16. the 30th International Conference on Neural Information Processing Systems, NIPS'16Red Hook, NY, USACurran Associates Inc. ISBN 9781510838819201623</p>
<p>Aäron van den Oord, and Rémi Munos. Count-based exploration with neural density models. Georg Ostrovski, Marc G Bellemare, Proceedings of the 34th International Conference on Machine Learning. the 34th International Conference on Machine Learning201770</p>
<h1>exploration: A study of count-based exploration for deep reinforcement learning. Haoran Tang, Rein Houthooft, Davis Foote, Adam Stooke, Xi Chen, Yan Duan, John Schulman, Filip De Turck, Pieter Abbeel, Proceedings of the 31st International Conference on Neural Information Processing Systems, NIPS'17. the 31st International Conference on Neural Information Processing Systems, NIPS'17Red Hook, NY, USACurran Associates Inc2017ISBN 9781510860964</h1>
<p>Count-based exploration with the successor representation. C Marlos, Marc G Machado, Michael Bellemare, Bowling, 2018</p>
<p>Leco: Learnable episodic count for task-specific intrinsic reward. Daejin Jo, Sungwoong Kim, Daniel Wontae Nam, Taehwan Kwon, Seungeun Rho, Jongmin Kim, Donghoon Lee, 2022</p>
<p>What is intrinsic motivation? a typology of computational approaches. Pierre-Yves Oudeyer, Frederic Kaplan, 10.3389/neuro.12.006.2007Frontiers in Neurorobotics. 1662-521812007</p>
<p>Intrinsic motivation systems for autonomous mental development. Pierre-Yves Oudeyer, Frdric Kaplan, Verena V Hafner, 10.1109/TEVC.2006.890271IEEE Transactions on Evolutionary Computation. 1122007</p>
<p>Incentivizing exploration in reinforcement learning with deep predictive models. Bradly C Stadie, Sergey Levine, Pieter Abbeel, 2015arXiv pre-print</p>
<p>Vime: Variational information maximizing exploration. Rein Houthooft, Xi Chen, Yan Duan, John Schulman, Filip De Turck, Pieter Abbeel, Proceedings of the 30th International Conference on Neural Information Processing Systems, NIPS'16. the 30th International Conference on Neural Information Processing Systems, NIPS'16Red Hook, NY, USACurran Associates Inc2016</p>
<p>Ex2: Exploration with exemplar models for deep reinforcement learning. Justin Fu, John D Co-Reyes, Sergey Levine, 2017</p>
<p>Nikolay Savinov, Anton Raichuk, Raphaël Marinier, Damien Vincent, Marc Pollefeys, Timothy Lillicrap, Sylvain Gelly, Episodic curiosity through reachability. 2018arXiv pre-print</p>
<p>Reward design via online gradient ascent. Jonathan Sorg, Richard L Lewis, Satinder Singh, Advances in Neural Information Processing Systems. J Lafferty, C Williams, J Shawe-Taylor, R Zemel, A Culotta, Curran Associates, Inc201023</p>
<p>On learning intrinsic rewards for policy gradient methods. Zeyu Zheng, Junhyuk Oh, Satinder Singh, Proceedings of the 32nd International Conference on Neural Information Processing Systems, NIPS'18. the 32nd International Conference on Neural Information Processing Systems, NIPS'18Red Hook, NY, USACurran Associates Inc2018</p>
<p>Selfsupervised online reward shaping in sparse-reward environments. Farzan Memarian, Wonjoon Goo, Rudolf Lioutikov, Scott Niekum, Ufuk Topcu, 10.1109/IROS51168.2021.96360202021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE Press2021</p>
<p>Exploration-guided reward shaping for reinforcement learning under sparse rewards. Rati Devidze, Parameswaran Kamalaruban, Adish Singla, Advances in Neural Information Processing Systems. Alice H Oh, Alekh Agarwal, Danielle Belgrave, Kyunghyun Cho, 2022</p>
<p>Combinatorial Optimization: Algorithms and Complexity. Christos Papadimitriou, Kenneth Steiglitz, 1982Dover Publications</p>
<p>Graph learning for combinatorial optimization: A survey of state-of-the-art. Yun Peng, Byron Choi, Jianliang Xu, 10.1007/s41019-021-00155-3Data Science and Engineering. 2364-154162Jun 2021</p>
<p>Reinforcement learning for combinatorial optimization: A survey. Nina Mazyavkina, Sergey Sviridov, Sergei Ivanov, Evgeny Burnaev, 10.1016/j.cor.2021.105400.URLhttps://www.sciencedirect.com/science/article/pii/S0305054821001660Computers &amp; Operations Research. 0305-0548134105400. 2021</p>
<p>Challenges and opportunities in deep reinforcement learning with graph neural networks: A comprehensive review of algorithms and applications. Sai Munikoti, Deepesh Agarwal, Laya Das, Mahantesh Halappanavar, Balasubramaniam Natarajan, 202235arXiv pre-print</p>
<p>Learning combinatorial optimization algorithms over graphs. Hanjun Dai, Elias B Khalil, Yuyu Zhang, Bistra Dilkina, Le Song, Proceedings of the 31st International Conference on Neural Information Processing Systems, NIPS'17. the 31st International Conference on Neural Information Processing Systems, NIPS'17Red Hook, NY, USACurran Associates Inc2017</p>
<p>Learning the travelling salesperson problem requires rethinking generalization. K Chaitanya, Quentin Joshi, Louis-Martin Cappart, Thomas Rousseau, Laurent, 10.4230/LIPIcs.CP.2021.332020arXiv pre-print</p>
<p>A reinforcement learning approach for optimizing multiple traveling salesman problems over graphs. Yujiao Hu, Yuan Yao, Wee Sun, Lee , 10.1016/j.knosys.2020.106244.URLhttps://www.sciencedirect.com/science/article/pii/S0950705120304445.32020204106244Knowledge-Based Systems</p>
<p>Learning what to defer for maximum independent sets. Younggyo Sungsoo Ahn, Jinwoo Seo, Shin, Proceedings of the 37th International Conference on Machine Learning, ICML'20. JMLR.org. the 37th International Conference on Machine Learning, ICML'202020</p>
<p>Learning from obstructions: An effective deep learning approach for minimum vertex cover. N Faisal, Mohamed M Abd Abu-Khzam, Moussa El-Wahab, Noureldin Haidous, Yosri, 10.1007/s10472-022-09813-2Annals of Mathematics and Artificial Intelligence. 1573-7470Aug 2022</p>
<p>Reinforcement learning based query vertex ordering model for subgraph matching. Hanchen Wang, Ying Zhang, Lu Qin, Wei Wang, Wenjie Zhang, Xuemin Lin, 10.1109/ICDE53745.2022.00023.32022 IEEE 38th International Conference on Data Engineering (ICDE). 2022</p>
<p>Optimizing tensor network contraction using reinforcement learning. Eli A Meirom, Haggai Maron, Shie Mannor, Gal Chechik, 2022arXiv pre-print</p>
<p>Learning transferable graph exploration. Hanjun Dai, Yujia Li, Chenglong Wang, Rishabh Singh, Po-Sen Huang, Pushmeet Kohli, Advances in Neural Information Processing Systems. H Wallach, H Larochelle, A Beygelzimer, F Alché-Buc, E Fox, R Garnett, Curran Associates, Inc201932</p>
<p>Zero-shot reinforcement learning on graphs for autonomous exploration under uncertainty. Fanfei Chen, Paul Szenher, Yewei Huang, Jinkun Wang, Tixiao Shan, Shi Bai, Brendan Englot, 10.1109/ICRA48506.2021.9561917.32021 IEEE International Conference on Robotics and Automation (ICRA). 2021</p>
<p>Goal-directed graph construction using reinforcement learning. Victor-Alexandru Darvariu, Stephen Hailes, Mirco Musolesi, 10.1098/rspa.2021.0168Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences. 47720212254</p>
<p>Dynamic network reconfiguration for entropy maximization using deep reinforcement learning. Christoffel Doorman, Victor-Alexandru Darvariu, Stephen Hailes, Mirco Musolesi, PMLR 198:49:1-49:15Proceedings of the First Learning on Graphs Conference. the First Learning on Graphs ConferenceLoG 2022. 2022</p>
<p>David F Gleich, PageRank beyond the web. siam REVIEW. 2015575</p>
<p>Identification of key nodes in a power grid based on modified pagerank algorithm. Energies. Darui Zhu, Haifeng Wang, Rui Wang, Jiandong Duan, Jing Bai, 2022155</p>
<p>Random walk for generalization in goal-directed human navigation on Wikipedia. Gergely Dániel Ficzere, Attila Hollósi, András Frankó, Gulyás, International Conference on Complex Networks and Their Applications. Springer202236</p>
<p>A large-scale characterization of how readers browse Wikipedia. Tiziano Piccardi, Martin Gerlach, Akhil Arora, Robert West, ACM Transactions on the Web. 1722023</p>
<p>Concept hierarchies and human navigation. Salvador Aguinaga, Aditya Nambiar, Zuozhu Liu, Tim Weninger, 2015 IEEE International Conference on Big Data (Big Data). IEEE2015</p>
<p>Comparing personalized PageRank and activation spreading in Wikipedia diagram-based search. Hisham Benotman, David Maier, 2021 ACM/IEEE Joint Conference on Digital Libraries (JCDL). IEEE2021</p>
<p>What makes a link successful on Wikipedia?. Dimitar Dimitrov, Philipp Singer, Florian Lemmerich, Markus Strohmaier, Proceedings of the 26th International Conference on World Wide Web. the 26th International Conference on World Wide Web2017</p>
<p>How semantic structure influences teleportation in PageRank (a case study on bioportal). Lisette Espín-Noboa, Florian Lemmerich, Simon Walk, Markus Strohmaier, Mark Musen, Hoprank, The World Wide Web Conference. 201936</p>
<p>Topological Graph Theory. Jonathan L Gross, Thomas W Tucker, 1987Wiley-InterscienceUSA</p>
<p>. Gunnar Carlsson. Topology and data. Bulletin of the American Mathematical Society. 464January 2009</p>
<p>Barcode: The persistent topology of data. Robert Ghrist, Bulletin of the American Mathematical Society. 45October 2007</p>
<p>Algebraic Topology. Allen Hatcher, 2002Cambridge University Press</p>
<p>Computing persistent homology. Discrete &amp; Computational Geometry. Afra Zomorodian, Gunnar Carlsson, 10.1007/s00454-004-1146-y200533</p>
<p>Higher-Order Networks. Ginestra Bianconi, 10.1017/9781108770996.4Elements in Structure and Dynamics of Complex Networks. Cambridge University Press2021</p>
<p>Quantifying the compressibility of complex networks. Christopher W Lynn, Danielle S Bassett, 10.1073/pnas.2023473118Proceedings of the National Academy of Sciences. 118322021</p>
<p>Reinforcement Learning: An Introduction. Richard S Sutton, Andrew G Barto, 2018The MIT Press</p>
<p>A comprehensive survey on graph neural networks. Zonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang, Philip S Yu, 10.1109/TNNLS.2020.2978386.5IEEE Transactions on Neural Networks and Learning Systems. 3212021</p>
<p>Inductive representation learning on large graphs. William L Hamilton, Rex Ying, Jure Leskovec, Proceedings of the 31st International Conference on Neural Information Processing Systems, NIPS'17. the 31st International Conference on Neural Information Processing Systems, NIPS'17Red Hook, NY, USACurran Associates Inc2017</p>
<p>A simple yet effective baseline for non-attributed graph classification. Chen Cai, Yusu Wang, 2018arXiv pre-print</p>
<p>Human-level control through deep reinforcement learning. Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Andrei A Rusu, Joel Veness, Marc G Bellemare, Alex Graves, Martin Riedmiller, Andreas K Fidjeland, Georg Ostrovski, Stig Petersen, Charles Beattie, Amir Sadik, Ioannis Antonoglou, Helen King, Dharshan Kumaran, Daan Wierstra, Shane Legg, Demis Hassabis, 10.1038/nature14236Nature. 1476-46875187540Feb 2015</p>
<p>The anatomy of a large-scale hypertextual web search engine. Computer networks and ISDN systems. Sergey Brin, Lawrence Page, 199830</p>
<p>Extracting link spam using biased random walks from spam seed sets. Baoning Wu, Kumar Chellapilla, Proceedings of the 3rd international workshop on Adversarial information retrieval on the web. the 3rd international workshop on Adversarial information retrieval on the web2007</p>
<p>Finite Markov chains and algorithmic applications. Olle Häggström, 2002Cambridge University Press52</p>
<p>An analytical comparison of approaches to personalizing PageRank. Taher Haveliwala, Sepandar Kamvar, Glen Jeh, 20035Stanford UniversityTechnical report</p>
<p>Networks: An Introduction. Mark Newman, 2010Oxford University PressInc., USA</p>
<p>Random geometric graphs. Jesper Dall, Michael Christensen, Physical review E. 66172002</p>
<p>Exploring complex networks through random walks. Luciano Da, Fontoura Costa, Gonzalo Travieso, Physical Review E. 751161022007</p>
<p>Average complexity of matrix reduction for clique filtrations. Barbara Giunti, Guillaume Houry, Michael Kerber, Proceedings of the 2022 International Symposium on Symbolic and Algebraic Computation. the 2022 International Symposium on Symbolic and Algebraic Computation2022</p>
<p>The movielens datasets: History and context. Acm transactions on interactive intelligent systems (tiis). Maxwell Harper, Joseph A Konstan, 20155</p>
<p>Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative filtering. Ruining He, Julian Mcauley, proceedings of the 25th international conference on world wide web. the 25th international conference on world wide web2016</p>
<p>Image-based recommendations on styles and substitutes. Julian Mcauley, Christopher Targett, Qinfeng Shi, Anton Van Den, Hengel, Proceedings of the 38th international ACM SIGIR conference on research and development in information retrieval. the 38th international ACM SIGIR conference on research and development in information retrieval2015</p>
<p>Human wayfinding in information networks. Robert West, Jure Leskovec, Proceedings of the 21st international conference on World Wide Web. the 21st international conference on World Wide Web2012</p>
<p>Wikispeedia: An online game for inferring semantic distances between concepts. Robert West, Joelle Pineau, Doina Precup, Twenty-First International Joint Conference on Artificial Intelligence. 2009</p>            </div>
        </div>

    </div>
</body>
</html>