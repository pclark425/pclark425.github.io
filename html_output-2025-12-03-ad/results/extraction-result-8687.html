<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-8687 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-8687</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-8687</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-156.html">extraction-schema-156</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of representational formats of conceptual knowledge at a functional (not neural) level, including descriptions of the format, supporting or challenging evidence, cognitive tasks or phenomena used as evidence, comparisons between formats, and theoretical claims or implications.</div>
                <p><strong>Paper ID:</strong> paper-248798662</p>
                <p><strong>Paper Title:</strong> <a href="https://arxiv.org/pdf/2205.06783v1.pdf" target="_blank">Embodied-Symbolic Contrastive Graph Self-Supervised Learning for Molecular Graphs</a></p>
                <p><strong>Paper Abstract:</strong> Dual embodied-symbolic concept representations are the foundation for deep learning and symbolic AI integration. We discuss the use of dual embodied-symbolic concept representations for molecular graph representation learning, specifically with exemplar-based contrastive self-supervised learning (SSL). The embodied representations are learned from molecular graphs, and the symbolic representations are learned from the corresponding Chemical knowledge graph (KG). We use the Chemical KG to enhance molecular graphs with symbolic (semantic) knowledge and generate their augmented molecular graphs. We treat a molecular graph and its semantically augmented molecular graph as exemplars of the same semantic class, and use the pairs as positive pairs in exemplar-based contrastive SSL.</p>
                <p><strong>Cost:</strong> 0.011</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e8687.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e8687.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of representational formats of conceptual knowledge at a functional (not neural) level, including descriptions of the format, supporting or challenging evidence, cognitive tasks or phenomena used as evidence, comparisons between formats, and theoretical claims or implications.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Dual embodied-symbolic</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Dual embodied-symbolic concept representations</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A hybrid representational format that maintains two parallel levels for concepts: (1) embodied, modality-specific feature representations (e.g., image/graph embeddings), and (2) amodal symbolic concept graphs (knowledge graphs); both levels are used jointly for learning and inference.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Dual Embodied-Symbolic Concept Representations for Deep Learning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_name</strong></td>
                            <td>hybrid embodied-symbolic representation</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_description</strong></td>
                            <td>Functionally, concepts are represented at two complementary levels: (a) embodied representations as distributed feature vectors capturing modality-specific perceptual/structural properties (e.g., molecular graph embeddings), and (b) symbolic representations as explicit graph-structured semantic knowledge (KG triples) that encode relations and types; learning operates by aligning/fusing these two levels so each concept has both feature-based and graph-based encodings.</td>
                        </tr>
                        <tr>
                            <td><strong>format_type</strong></td>
                            <td>hybrid (distributed + symbolic)</td>
                        </tr>
                        <tr>
                            <td><strong>cognitive_task_or_phenomenon</strong></td>
                            <td>Applied and motivating tasks cited in the paper include exemplar-based contrastive self-supervised learning, few-shot class incremental learning, image-text matching (vision), and molecular downstream tasks such as molecular property prediction, molecular binding prediction, and drug discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Qualitative findings and claims: combining symbolic KG information with embodied graph embeddings via knowledge-guided augmentations yields richer augmented graphs used as positive pairs in contrastive SSL; this alignment is claimed to improve transfer/generalization and supports exemplar-based learning. No quantitative cognitive/neuropsychological data are presented in this paper; evidence is algorithmic and application-level (improved downstream performance is claimed in referenced works).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_formats</strong></td>
                            <td>The paper contrasts the hybrid approach with pure embodied (deep, modality-only) representations and pure symbolic AI: hybrid is presented as integrating strengths of both (generalization and structured semantics) and compensating their weaknesses. No formal quantitative comparison between representational theories is given here—comparisons are presented at the systems/method level (e.g., enhanced augmentation vs. standard augmentations).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_counter_evidence</strong></td>
                            <td>Limitations discussed implicitly include dependence on the availability and quality of symbolic KGs, increased heterogeneity and complexity of augmented graphs (requiring specialized encoders like KMPNN), and domain specificity (chemical KGs are required for molecular tasks). The paper does not present cognitive counter-evidence or behavioral data challenging the hybrid claim.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_claims_or_implications</strong></td>
                            <td>Theoretical claim: dual embodied-symbolic representations form a foundation for integrating deep learning and symbolic AI, enabling improved generalization, semantic-level reasoning, and exemplar-based learning; practically, fusion supports knowledge-guided data augmentation and better downstream performance in domain tasks.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8687.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e8687.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of representational formats of conceptual knowledge at a functional (not neural) level, including descriptions of the format, supporting or challenging evidence, cognitive tasks or phenomena used as evidence, comparisons between formats, and theoretical claims or implications.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Embodied repr.</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Embodied (modality-specific) representations</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Modality-specific distributed feature representations learned from raw data (e.g., molecular graph embeddings produced by GNNs) that capture perceptual or structural aspects of concepts.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_name</strong></td>
                            <td>embodied (feature-based / distributed) representation</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_description</strong></td>
                            <td>Functionally, a concept is represented as a vector or set of feature vectors derived from the modality in which the concept appears (images, molecular graphs, etc.); these vectors encode perceptual/structural attributes and are used for similarity-based retrieval and downstream prediction.</td>
                        </tr>
                        <tr>
                            <td><strong>format_type</strong></td>
                            <td>distributed / feature-based</td>
                        </tr>
                        <tr>
                            <td><strong>cognitive_task_or_phenomenon</strong></td>
                            <td>Used as the backbone encoder tasks in the paper's framework: graph self-supervised pretext tasks (contrastive SSL), downstream molecular prediction tasks (property prediction, binding prediction), and exemplar similarity computations in exemplar-based contrastive learning.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>The paper treats embodied embeddings as necessary building blocks whose utility is enhanced when paired with symbolic augmentations; embodied representations alone are the standard baseline in graph SSL, and the paper argues knowledge-enhanced augmentations produce richer inputs for these encoders. No detailed quantitative results are reported here.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_formats</strong></td>
                            <td>Embodied representations are contrasted with symbolic (KG) representations: embodied encodings are good at capturing modality-specific structure but lack explicit relational semantics; the hybrid approach is preferred to combine both strengths.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_counter_evidence</strong></td>
                            <td>Reported limitations include susceptibility to overfitting and weaker generalization when trained only with supervised downstream tasks and limited labels. The paper motivates adding symbolic knowledge to mitigate these issues but does not present direct empirical counter-evidence.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_claims_or_implications</strong></td>
                            <td>Embodied representations provide perceptual/structural grounding for concepts and, when aligned with symbolic representations, enable richer and more generalizable concept representations suited to tasks like few-shot learning and domain-specific prediction.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8687.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e8687.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of representational formats of conceptual knowledge at a functional (not neural) level, including descriptions of the format, supporting or challenging evidence, cognitive tasks or phenomena used as evidence, comparisons between formats, and theoretical claims or implications.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Symbolic KG</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Symbolic (knowledge graph) representations</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Explicit graph-structured semantic representations where entities (e.g., atoms, functional groups) and relations (triples) encode semantic and type information about concepts and their relations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_name</strong></td>
                            <td>symbolic knowledge graph representation</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_description</strong></td>
                            <td>Functionally, concepts and their relations are encoded as discrete graph nodes and labeled edges (subject–predicate–object triples). For molecules, KGs include element properties (Chemical Element KG) and functional-group/moiety relations (Functional Group KG) that provide amodal semantic information tied to concept tokens.</td>
                        </tr>
                        <tr>
                            <td><strong>format_type</strong></td>
                            <td>symbolic / graph-structured</td>
                        </tr>
                        <tr>
                            <td><strong>cognitive_task_or_phenomenon</strong></td>
                            <td>Used to generate semantically-augmented molecular graphs for contrastive SSL; domain tasks cited include molecular property prediction and using KG knowledge to guide graph augmentation (e.g., inserting property nodes or moiety nodes).</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>KG-derived augmentations (adding property nodes, moiety nodes, and labeled edges) preserve original molecular structure while introducing semantic neighborhood topologies; these augmented graphs serve as valid positive pairs for exemplar-based contrastive learning. Evidence is method-level and qualitative within this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_formats</strong></td>
                            <td>KGs provide explicit relational semantics that distributed embodied embeddings lack; the paper uses KG information to augment embodied graphs and argues the hybrid approach (KG + embeddings) performs better than relying on either alone (qualitative claim).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_counter_evidence</strong></td>
                            <td>Challenges include discretization of continuous properties, potential incompleteness of KGs, and domain-specificity (chemical KGs required for molecular tasks). No behavioral cognitive counter-evidence is provided.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_claims_or_implications</strong></td>
                            <td>Symbolic KGs supply amodal semantic structure enabling higher-level generalization and the construction of semantically-valid augmentations; they are proposed as the symbolic half of the dual representation enabling reasoning and knowledge-guided learning.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8687.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e8687.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of representational formats of conceptual knowledge at a functional (not neural) level, including descriptions of the format, supporting or challenging evidence, cognitive tasks or phenomena used as evidence, comparisons between formats, and theoretical claims or implications.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>KGE</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Knowledge graph embeddings (KGE)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Low-dimensional continuous vector embeddings of KG entities and relations intended to capture structural/relational information from triples for use in downstream models.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>DGL-KE: Training Knowledge Graph Embeddings at Scale</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_name</strong></td>
                            <td>knowledge graph embeddings (distributed embeddings of symbolic graphs)</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_description</strong></td>
                            <td>Functionally, each KG entity and relation is mapped to a continuous vector such that relational constraints in triples (h, r, t) are approximately preserved in embedding space (via translational or semantic matching models like TransE, RotatE, ComplEx). These vectors are used as initial features for property and relation nodes when augmenting molecular graphs.</td>
                        </tr>
                        <tr>
                            <td><strong>format_type</strong></td>
                            <td>distributed embedding of symbolic structure (hybrid usage)</td>
                        </tr>
                        <tr>
                            <td><strong>cognitive_task_or_phenomenon</strong></td>
                            <td>Operationalized in the molecular augmentation pipeline: KG embeddings (e.g., RotateE) initialize feature vectors for property nodes added to molecular graphs, enabling the GNN encoder to exploit KG structural information during contrastive SSL and downstream tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Using KGE to initialize added property/moiety node features helps capture structural information from triples and integrate symbolic semantics into embodied graph encodings; the paper reports this as a design choice (e.g., RotateE used for Chemical Element KG) but provides no new quantitative evaluation within this manuscript.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_formats</strong></td>
                            <td>KGEs are presented as a bridge between symbolic graphs and distributed embodied representations: they allow symbolic facts to be consumed by vector-based models; compared to raw symbolic triples, KGEs are more directly usable by neural encoders but may lose explicit logical structure.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_counter_evidence</strong></td>
                            <td>Embedding compresses symbolic structure into vectors, which can obscure explicit relations and logical interpretability; success depends on the chosen KGE model and training quality. The paper notes the use of KGE but does not empirically analyze these limitations.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_claims_or_implications</strong></td>
                            <td>KGEs functionally enable alignment/fusion of symbolic semantics with embodied neural representations, making symbolic knowledge actionable in contrastive SSL and downstream prediction pipelines.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8687.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e8687.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of representational formats of conceptual knowledge at a functional (not neural) level, including descriptions of the format, supporting or challenging evidence, cognitive tasks or phenomena used as evidence, comparisons between formats, and theoretical claims or implications.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Exemplar-based</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Exemplar-based contrastive self-supervised learning / exemplar representation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A representational and learning strategy that treats each instance (and semantically augmented variants) as exemplars of a semantic class and constructs contrastive objectives where exemplar pairs (original and semantically-augmented) are positive pairs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Exemplar-Based Contrastive Self-Supervised Learning with Few-Shot Class Incremental Learning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_name</strong></td>
                            <td>exemplar representation / exemplar-based model</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_description</strong></td>
                            <td>Functionally, concepts or classes are represented implicitly by collections of exemplars; learning proceeds by pulling together multiple views/augmentations of the same exemplar (or exemplar class) in representation space while pushing apart different exemplars, so class structure emerges from exemplar similarity.</td>
                        </tr>
                        <tr>
                            <td><strong>format_type</strong></td>
                            <td>instance-based / exemplar model</td>
                        </tr>
                        <tr>
                            <td><strong>cognitive_task_or_phenomenon</strong></td>
                            <td>Applied to contrastive SSL: the paper uses exemplar pairs (molecule and its semantically-augmented molecular graph) as positive pairs; motivating cognitive analogue tasks mentioned include few-shot class incremental learning and exemplar-based categorization.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Using semantically-valid, knowledge-guided augmentations as exemplar views produces positive pairs that better reflect semantic class membership and supports exemplar-based contrastive learning; claimed to improve robustness for downstream few-shot/incremental tasks, though the present paper mainly outlines the method and cites prior empirical work for quantitative support.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_formats</strong></td>
                            <td>Exemplar-based approach is set against generic augmentation-based contrastive methods: exemplar pairs are semantically meaningful (KG-guided) rather than arbitrary perturbations, and thus are argued to produce more semantically-coherent representations. No direct numerical comparison in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_counter_evidence</strong></td>
                            <td>Reliant on reliable semantic augmentation (quality of KG); exemplar approaches can be sensitive to exemplar selection and may not capture abstract class structure beyond sampled exemplars. The paper notes the need for semantically-valid augmentations but does not present counter-evidence.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_claims_or_implications</strong></td>
                            <td>Exemplar-based representations, when instantiated with symbolic augmentations, provide a functional mechanism for forming semantic classes in representation space and support few-shot/incremental learning by using exemplars as anchors for class identity.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Dual Embodied-Symbolic Concept Representations for Deep Learning <em>(Rating: 2)</em></li>
                <li>Concept Representation Learning with Contrastive Self-Supervised Learning <em>(Rating: 2)</em></li>
                <li>Exemplar-Based Contrastive Self-Supervised Learning with Few-Shot Class Incremental Learning <em>(Rating: 2)</em></li>
                <li>Molecular Ccontrastive Learning with Chemical Element Knowledge Graph <em>(Rating: 2)</em></li>
                <li>Incorporating Symbolic Domain Knowledge into Graph Neural Networks <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-8687",
    "paper_id": "paper-248798662",
    "extraction_schema_id": "extraction-schema-156",
    "extracted_data": [
        {
            "name_short": "Dual embodied-symbolic",
            "name_full": "Dual embodied-symbolic concept representations",
            "brief_description": "A hybrid representational format that maintains two parallel levels for concepts: (1) embodied, modality-specific feature representations (e.g., image/graph embeddings), and (2) amodal symbolic concept graphs (knowledge graphs); both levels are used jointly for learning and inference.",
            "citation_title": "Dual Embodied-Symbolic Concept Representations for Deep Learning",
            "mention_or_use": "use",
            "representational_format_name": "hybrid embodied-symbolic representation",
            "representational_format_description": "Functionally, concepts are represented at two complementary levels: (a) embodied representations as distributed feature vectors capturing modality-specific perceptual/structural properties (e.g., molecular graph embeddings), and (b) symbolic representations as explicit graph-structured semantic knowledge (KG triples) that encode relations and types; learning operates by aligning/fusing these two levels so each concept has both feature-based and graph-based encodings.",
            "format_type": "hybrid (distributed + symbolic)",
            "cognitive_task_or_phenomenon": "Applied and motivating tasks cited in the paper include exemplar-based contrastive self-supervised learning, few-shot class incremental learning, image-text matching (vision), and molecular downstream tasks such as molecular property prediction, molecular binding prediction, and drug discovery.",
            "key_findings": "Qualitative findings and claims: combining symbolic KG information with embodied graph embeddings via knowledge-guided augmentations yields richer augmented graphs used as positive pairs in contrastive SSL; this alignment is claimed to improve transfer/generalization and supports exemplar-based learning. No quantitative cognitive/neuropsychological data are presented in this paper; evidence is algorithmic and application-level (improved downstream performance is claimed in referenced works).",
            "comparison_with_other_formats": "The paper contrasts the hybrid approach with pure embodied (deep, modality-only) representations and pure symbolic AI: hybrid is presented as integrating strengths of both (generalization and structured semantics) and compensating their weaknesses. No formal quantitative comparison between representational theories is given here—comparisons are presented at the systems/method level (e.g., enhanced augmentation vs. standard augmentations).",
            "limitations_or_counter_evidence": "Limitations discussed implicitly include dependence on the availability and quality of symbolic KGs, increased heterogeneity and complexity of augmented graphs (requiring specialized encoders like KMPNN), and domain specificity (chemical KGs are required for molecular tasks). The paper does not present cognitive counter-evidence or behavioral data challenging the hybrid claim.",
            "theoretical_claims_or_implications": "Theoretical claim: dual embodied-symbolic representations form a foundation for integrating deep learning and symbolic AI, enabling improved generalization, semantic-level reasoning, and exemplar-based learning; practically, fusion supports knowledge-guided data augmentation and better downstream performance in domain tasks.",
            "uuid": "e8687.0"
        },
        {
            "name_short": "Embodied repr.",
            "name_full": "Embodied (modality-specific) representations",
            "brief_description": "Modality-specific distributed feature representations learned from raw data (e.g., molecular graph embeddings produced by GNNs) that capture perceptual or structural aspects of concepts.",
            "citation_title": "",
            "mention_or_use": "use",
            "representational_format_name": "embodied (feature-based / distributed) representation",
            "representational_format_description": "Functionally, a concept is represented as a vector or set of feature vectors derived from the modality in which the concept appears (images, molecular graphs, etc.); these vectors encode perceptual/structural attributes and are used for similarity-based retrieval and downstream prediction.",
            "format_type": "distributed / feature-based",
            "cognitive_task_or_phenomenon": "Used as the backbone encoder tasks in the paper's framework: graph self-supervised pretext tasks (contrastive SSL), downstream molecular prediction tasks (property prediction, binding prediction), and exemplar similarity computations in exemplar-based contrastive learning.",
            "key_findings": "The paper treats embodied embeddings as necessary building blocks whose utility is enhanced when paired with symbolic augmentations; embodied representations alone are the standard baseline in graph SSL, and the paper argues knowledge-enhanced augmentations produce richer inputs for these encoders. No detailed quantitative results are reported here.",
            "comparison_with_other_formats": "Embodied representations are contrasted with symbolic (KG) representations: embodied encodings are good at capturing modality-specific structure but lack explicit relational semantics; the hybrid approach is preferred to combine both strengths.",
            "limitations_or_counter_evidence": "Reported limitations include susceptibility to overfitting and weaker generalization when trained only with supervised downstream tasks and limited labels. The paper motivates adding symbolic knowledge to mitigate these issues but does not present direct empirical counter-evidence.",
            "theoretical_claims_or_implications": "Embodied representations provide perceptual/structural grounding for concepts and, when aligned with symbolic representations, enable richer and more generalizable concept representations suited to tasks like few-shot learning and domain-specific prediction.",
            "uuid": "e8687.1"
        },
        {
            "name_short": "Symbolic KG",
            "name_full": "Symbolic (knowledge graph) representations",
            "brief_description": "Explicit graph-structured semantic representations where entities (e.g., atoms, functional groups) and relations (triples) encode semantic and type information about concepts and their relations.",
            "citation_title": "",
            "mention_or_use": "use",
            "representational_format_name": "symbolic knowledge graph representation",
            "representational_format_description": "Functionally, concepts and their relations are encoded as discrete graph nodes and labeled edges (subject–predicate–object triples). For molecules, KGs include element properties (Chemical Element KG) and functional-group/moiety relations (Functional Group KG) that provide amodal semantic information tied to concept tokens.",
            "format_type": "symbolic / graph-structured",
            "cognitive_task_or_phenomenon": "Used to generate semantically-augmented molecular graphs for contrastive SSL; domain tasks cited include molecular property prediction and using KG knowledge to guide graph augmentation (e.g., inserting property nodes or moiety nodes).",
            "key_findings": "KG-derived augmentations (adding property nodes, moiety nodes, and labeled edges) preserve original molecular structure while introducing semantic neighborhood topologies; these augmented graphs serve as valid positive pairs for exemplar-based contrastive learning. Evidence is method-level and qualitative within this paper.",
            "comparison_with_other_formats": "KGs provide explicit relational semantics that distributed embodied embeddings lack; the paper uses KG information to augment embodied graphs and argues the hybrid approach (KG + embeddings) performs better than relying on either alone (qualitative claim).",
            "limitations_or_counter_evidence": "Challenges include discretization of continuous properties, potential incompleteness of KGs, and domain-specificity (chemical KGs required for molecular tasks). No behavioral cognitive counter-evidence is provided.",
            "theoretical_claims_or_implications": "Symbolic KGs supply amodal semantic structure enabling higher-level generalization and the construction of semantically-valid augmentations; they are proposed as the symbolic half of the dual representation enabling reasoning and knowledge-guided learning.",
            "uuid": "e8687.2"
        },
        {
            "name_short": "KGE",
            "name_full": "Knowledge graph embeddings (KGE)",
            "brief_description": "Low-dimensional continuous vector embeddings of KG entities and relations intended to capture structural/relational information from triples for use in downstream models.",
            "citation_title": "DGL-KE: Training Knowledge Graph Embeddings at Scale",
            "mention_or_use": "use",
            "representational_format_name": "knowledge graph embeddings (distributed embeddings of symbolic graphs)",
            "representational_format_description": "Functionally, each KG entity and relation is mapped to a continuous vector such that relational constraints in triples (h, r, t) are approximately preserved in embedding space (via translational or semantic matching models like TransE, RotatE, ComplEx). These vectors are used as initial features for property and relation nodes when augmenting molecular graphs.",
            "format_type": "distributed embedding of symbolic structure (hybrid usage)",
            "cognitive_task_or_phenomenon": "Operationalized in the molecular augmentation pipeline: KG embeddings (e.g., RotateE) initialize feature vectors for property nodes added to molecular graphs, enabling the GNN encoder to exploit KG structural information during contrastive SSL and downstream tasks.",
            "key_findings": "Using KGE to initialize added property/moiety node features helps capture structural information from triples and integrate symbolic semantics into embodied graph encodings; the paper reports this as a design choice (e.g., RotateE used for Chemical Element KG) but provides no new quantitative evaluation within this manuscript.",
            "comparison_with_other_formats": "KGEs are presented as a bridge between symbolic graphs and distributed embodied representations: they allow symbolic facts to be consumed by vector-based models; compared to raw symbolic triples, KGEs are more directly usable by neural encoders but may lose explicit logical structure.",
            "limitations_or_counter_evidence": "Embedding compresses symbolic structure into vectors, which can obscure explicit relations and logical interpretability; success depends on the chosen KGE model and training quality. The paper notes the use of KGE but does not empirically analyze these limitations.",
            "theoretical_claims_or_implications": "KGEs functionally enable alignment/fusion of symbolic semantics with embodied neural representations, making symbolic knowledge actionable in contrastive SSL and downstream prediction pipelines.",
            "uuid": "e8687.3"
        },
        {
            "name_short": "Exemplar-based",
            "name_full": "Exemplar-based contrastive self-supervised learning / exemplar representation",
            "brief_description": "A representational and learning strategy that treats each instance (and semantically augmented variants) as exemplars of a semantic class and constructs contrastive objectives where exemplar pairs (original and semantically-augmented) are positive pairs.",
            "citation_title": "Exemplar-Based Contrastive Self-Supervised Learning with Few-Shot Class Incremental Learning",
            "mention_or_use": "use",
            "representational_format_name": "exemplar representation / exemplar-based model",
            "representational_format_description": "Functionally, concepts or classes are represented implicitly by collections of exemplars; learning proceeds by pulling together multiple views/augmentations of the same exemplar (or exemplar class) in representation space while pushing apart different exemplars, so class structure emerges from exemplar similarity.",
            "format_type": "instance-based / exemplar model",
            "cognitive_task_or_phenomenon": "Applied to contrastive SSL: the paper uses exemplar pairs (molecule and its semantically-augmented molecular graph) as positive pairs; motivating cognitive analogue tasks mentioned include few-shot class incremental learning and exemplar-based categorization.",
            "key_findings": "Using semantically-valid, knowledge-guided augmentations as exemplar views produces positive pairs that better reflect semantic class membership and supports exemplar-based contrastive learning; claimed to improve robustness for downstream few-shot/incremental tasks, though the present paper mainly outlines the method and cites prior empirical work for quantitative support.",
            "comparison_with_other_formats": "Exemplar-based approach is set against generic augmentation-based contrastive methods: exemplar pairs are semantically meaningful (KG-guided) rather than arbitrary perturbations, and thus are argued to produce more semantically-coherent representations. No direct numerical comparison in this paper.",
            "limitations_or_counter_evidence": "Reliant on reliable semantic augmentation (quality of KG); exemplar approaches can be sensitive to exemplar selection and may not capture abstract class structure beyond sampled exemplars. The paper notes the need for semantically-valid augmentations but does not present counter-evidence.",
            "theoretical_claims_or_implications": "Exemplar-based representations, when instantiated with symbolic augmentations, provide a functional mechanism for forming semantic classes in representation space and support few-shot/incremental learning by using exemplars as anchors for class identity.",
            "uuid": "e8687.4"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Dual Embodied-Symbolic Concept Representations for Deep Learning",
            "rating": 2,
            "sanitized_title": "dual_embodiedsymbolic_concept_representations_for_deep_learning"
        },
        {
            "paper_title": "Concept Representation Learning with Contrastive Self-Supervised Learning",
            "rating": 2,
            "sanitized_title": "concept_representation_learning_with_contrastive_selfsupervised_learning"
        },
        {
            "paper_title": "Exemplar-Based Contrastive Self-Supervised Learning with Few-Shot Class Incremental Learning",
            "rating": 2,
            "sanitized_title": "exemplarbased_contrastive_selfsupervised_learning_with_fewshot_class_incremental_learning"
        },
        {
            "paper_title": "Molecular Ccontrastive Learning with Chemical Element Knowledge Graph",
            "rating": 2,
            "sanitized_title": "molecular_ccontrastive_learning_with_chemical_element_knowledge_graph"
        },
        {
            "paper_title": "Incorporating Symbolic Domain Knowledge into Graph Neural Networks",
            "rating": 1,
            "sanitized_title": "incorporating_symbolic_domain_knowledge_into_graph_neural_networks"
        }
    ],
    "cost": 0.011064,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Embodied-Symbolic Contrastive Graph Self-Supervised Learning for Molecular Graphs</p>
<p>Daniel T Chang dtchang43@gmail.com 
IBM (Retired)</p>
<p>Embodied-Symbolic Contrastive Graph Self-Supervised Learning for Molecular Graphs</p>
<p>Dual embodied-symbolic concept representations are the foundation for deep learning and symbolic AI integration. We discuss the use of dual embodied-symbolic concept representations for molecular graph representation learning, specifically with exemplar-based contrastive self-supervised learning (SSL). The embodied representations are learned from molecular graphs, and the symbolic representations are learned from the corresponding Chemical knowledge graph (KG). We use the Chemical KG to enhance molecular graphs with symbolic (semantic) knowledge and generate their augmented molecular graphs. We treat a molecular graph and its semantically augmented molecular graph as exemplars of the same semantic class, and use the pairs as positive pairs in exemplar-based contrastive SSL.</p>
<p>Introduction</p>
<p>Motivated by recent findings from cognitive neural science, we advocate the use of a dual-level model for concept representations [1]: the embodied level consists of concept-oriented feature representations, and the symbolic level consists of concept graphs (a.k.a. knowledge graphs). We further advocate the use of dual embodied-symbolic concept representations [3] for deep learning. That is, deep learning should learn from data not only modality-specific embodied representations such as image embeddings, graph embeddings, etc., but also the corresponding amodal symbolic (semantic) representations as knowledge graph embeddings. Dual embodied-symbolic concept representations are the foundation for deep learning and symbolic AI integration, which is an important direction for deep learning and AI since their integration reinforces each other's strength, compensates each other's weakness, and takes a major step toward human-level AI.</p>
<p>In this paper, we discuss the use of dual embodied-symbolic concept representations for molecular graph representation learning, specifically with exemplar-based contrastive self-supervised learning (SSL) [2]. The embodied representations are learned from molecular graphs which consist of atoms as nodes and (chemical) bonds as edges. The symbolic representations are learned from the corresponding Chemical knowledge graph (KG). We use the Chemical KG to enhance molecular graphs with symbolic (semantic) knowledge and generate their augmented molecular graphs. We treat a molecular graph and its semantically augmented molecular graph as exemplars of the same semantic class, and use the pairs as positive pairs in exemplar-based contrastive SSL.</p>
<p>DGL [4], DGL-LifeSci [5] and DGL-KE [6] are new open-source Python packages for deep graph learning, for deep graph learning in life sciences (particularly, molecular science), and for efficient generation of knowledge graph embeddings, respectively. They greatly facilitate the use of dual embodied-symbolic concept representations for molecular graph representation learning. We provide a brief review of each as background information.</p>
<p>Graph SSL [7] applies SSL methods to graphs. By training the graph neural network (GNN) model to solve welldesigned pretext tasks from unlabeled data, Graph SSL helps the GNN model learn more generalized representations so it can achieve better performance on downstream tasks. Graphs have rich underlying structural and attributive information from which various pretext tasks can be designed. Furthermore, graphs are usually formed by domain-specific rules. Thus, domain (symbolic) knowledge can be incorporated into the design of pretext tasks and learning process. The learning strategies for Graph SSL can be divided into three categories: Pre-training and Fine-tuning (P&amp;F), Joint Learning (JL), and (selfsupervised) Graph Representation Learning (GRL); whereas Graph SSL methods can be divided into three learning approaches: contrastive, generative, and predictive. We focus on the GRL strategy and the contrastive learning approach, in accordance with our focus on concept representation learning and our approach on contrastive SSL discussed in [1][2].</p>
<p>For molecular graphs, the associated domain (symbolic) knowledge is represented in Chemical knowledge graph (KG).</p>
<p>We focus on two fundamental kinds of Chemical KG: Chemical Element KG and Functional Group KG. They provide essential knowledge on physical chemical properties and chemical biological functions, respectively, of molecular graphs.</p>
<p>The Chemical Element KG [10] provides atom (node)-level knowledge on physical chemical properties of molecular graphs.</p>
<p>It is based on Periodic Table of Elements and describes associations between atoms that are not directly connected by bonds (edges) but related in fundamental physical chemical properties. The Functional Group KG [11][12] provides functional group (subgraph)-level knowledge on chemical biological functions of molecular graphs. Functional Groups are the substituent atoms or groups of atoms that are attached to specific molecules. They are responsible for the chemical reactions that the molecule they are attached to participate in.</p>
<p>The design of the contrastive learning approach to Graph SSL generally consists of three main modules: (1) graph augmentation, (2) pretext task, and (3) contrastive objective. Embodied-symbolic contrastive Graph SSL leverages background (domain) knowledge by using (1) knowledge-enhanced (i.e., embodied-symbolic fused [3]) graph augmentation and (2) graph representation learning as pretext task. KCL (Knowledge-enhanced Contrastive Learning) [10] is a framework that can be used for embodied-symbolic contrastive Graph SSL. It provides three modules: knowledge-guided graph augmentation, knowledge-aware graph representation, and contrastive objective. Knowledge-guided graph augmentation and encoding is core to the framework and domain specific, e.g., when applying the framework to molecular graphs. We discuss two fundamental kinds of knowledge-guided molecular graph augmentation and encoding based on, respectively, Chemical Element KG and Functional Group KG. The readout phase computes a representation for the entire graph. DGL graphs can be created from NetworkX graphs. [5] is an open-source Python toolkit for deep graph learning in life sciences (particularly, molecular science), based on DGL, PyTorch and RDKit. It allows GNN-based modeling of molecular graph data for prediction and generation tasks. DGL-LifeSci provides optimized modules for various stages of the molecular graph modeling pipeline. It provides high-quality and robust implementations of seven models for molecular property prediction (including GCN, MPNN, GAT, AttentiveFP and Weave), one model for molecule generation, and one model for chemical reaction prediction.</p>
<p>DGL-LifeSci</p>
<p>DGL-LifeSci</p>
<p>DGL-LifeSci contains four components: (i) programming APIs to develop custom molecular graph modeling pipelines and models; (ii) a set of pretrained models that can either be fine-tuned or directly used; (iii) a set of built-in datasets for quick experimentation; and (iv) a set of ready-to-run scripts for training and prediction.</p>
<p>DGL-LifeSci provides built-in support for constructing three kinds of graphs for molecules: molecular graphs, distancebased graphs, and complete graphs. In all of these graphs, each node corresponds to an atom in a molecule. In a molecular graph, the edges correspond to chemical bonds. For graph featurization, it allows initializing various node and edge features from atom and bond descriptors.</p>
<p>DGL-KE</p>
<p>DGL-KE [6] is an open-source Python package for efficient generation of knowledge graph embeddings (KGEs). It is implemented with Python on top of DGL along with a C++-based distributed key-value store. DGL-KE uses various optimizations to accelerate KGE generation on knowledge graphs with millions of nodes and billions of edges using multiprocessing, multi-GPU, and distributed parallelism. These optimizations are designed to increase data locality, reduce communication overhead, overlap computations with memory accesses, and achieve high operation efficiency.</p>
<p>KGE [3] is a widely adopted approach to knowledge graph (KG) representation in which entities and relations in a KG are embedded in low-dimensional continuous vector spaces. Most KGE models create a vector for each entity and each relation. In DGL-KE, a KG is viewed as a set of statements (facts) having the form of subject-predicate-object triples, using the notation (h, r, t) (head, relation, tail) to identify a statement. It uses the subject-predicate-object triples present in the KG to generate the vector representations, (h, r, t), for (head, relation, tail). DGL-KE supports three translational distance models (TransE, TransR, RotatE) and three semantic matching models (RESCAL, DistMul, ComplEx).</p>
<p>Graph Self-Supervised Learning</p>
<p>Most of the work on deep graph learning has focused on supervised learning, in which GNN models are trained by specific downstream tasks with abundant labeled data. However, labeled data are often limited, expensive, and inaccessible.</p>
<p>Furthermore, supervised learning methods, with specific downstream tasks, are prone to over-fitting, poor generalization, and weak robustness.</p>
<p>Graph self-supervised learning (SSL) [7] aims to overcome the above limitations by applying SSL methods to graphs.</p>
<p>The primary goal of SSL is to learn transferable knowledge from abundant unlabeled data with well-designed pretext tasks and then generalize the learned knowledge to downstream tasks. By training the GNN model to solve well-designed pretext tasks from unlabeled data, Graph SSL helps the GNN model learn more generalized representations so it can achieve better performance on downstream tasks. Graphs have rich underlying structural and attributive information, from which various pretext tasks can be designed. Furthermore, graphs are usually formed by domain-specific rules, e.g., bonds (edges) between atoms (nodes) in molecular graphs are defined by chemical bond theory. Thus, domain (symbolic) knowledge can be incorporated a priori into the design of pretext tasks and learning process.</p>
<p>The learning strategies for Graph SSL can be divided into three categories [7]: Pre-training and Fine-tuning (P&amp;F), Joint Learning (JL), and (self-supervised) Graph Representation Learning (GRL). In all cases, GNNs are used as the backbone encoder. In the P&amp;F strategy, the model is trained in a two-stage paradigm. At the pre-training stage, the encoder is pre-trained with the pretext tasks. At the fine-tuning stage, the pre-trained encoder is fine-tuned with a prediction head under the supervision of specific downstream tasks. In the JL strategy, the encoder is jointly trained with a prediction head under the supervision of pretext tasks and downstream tasks. Finally, in the GRL strategy, the model is also trained in a twostage paradigm, with the first stage similar to Pre-training. However, at the second stage, the model is trained on the frozen pre-trained encoder with a projection head trained on downstream tasks only.</p>
<p>Graph SSL methods can be divided into three learning approaches [7]: contrastive, generative, and predictive:  In the contrastive learning approach, multiple views are usually generated for each sample instance through various graph augmentations. Two views generated from the same instance are usually considered as a positive pair, while two views generated from different instances are considered as a negative pair. The primary goal of contrastive learning is to maximize the agreement of two jointly sampled positive pairs against the agreement of two independently sampled negative pairs. The design of the contrastive learning usually consists of three main modules: (1) graph augmentation, (2) pretext task, and (3) contrastive objective.</p>
<p> In the generative learning approach, the prediction head is called the graph decoder, which is used to perform graph reconstruction. There are two categories of methods: (1) graph autoencoder that performs reconstruction in a once-for-all manner; (2) graph autoregressive that iteratively performs reconstruction. The graph autoencoder is trained to reconstruct certain parts of the input graph data, e.g., the adjacency matrix which stores the graph structure information and the relations between nodes. This is the approach taken by Tiered Graph Autoencoders [8][9].</p>
<p> In the predictive learning approach, self-generated informative labels from the data are used as supervision to perform prediction tasks. There are four categories of labels: (1) Node Property labels, e.g., node degree, (2) Context-based labels, e.g., the shortest path length between nodes, (3) Self-Training labels, e.g., cluster from a previous learning stage, and (4) Domain Knowledge-based labels, e.g., functional group for molecular graphs.</p>
<p>In this paper, for Graph SSL, we focus on the GRL strategy and the contrastive learning approach, in accordance with our focus on concept representation learning and our approach on contrastive SSL discussed in [1][2]. In particular, for the contrastive learning approach, we focus on the exemplar-based approach [2] as it utilizes semantically-valid graph augmentation for the generation of positive pairs.</p>
<p>Chemical Knowledge Graphs</p>
<p>Chemical knowledge graph embeddings can be generated from Chemical knowledge graphs (KGs). We focus on two fundamental kinds of Chemical KG: Chemical Element KG and Functional Group KG. They provide essential knowledge on physical chemical properties and chemical biological functions, respectively, of molecular graphs.</p>
<p>Chemical Element KG</p>
<p>The Chemical Element KG [10] provides atom (node)-level knowledge on physical chemical properties of molecular graphs. It is based on Periodic Table of Elements and describes associations between atoms that are not directly connected by bonds (edges) but related in fundamental physical chemical properties.</p>
<p>There are 108 elements in the Chemical Element KG. Each element contains 17 types of physical chemical properties, including family, metallicity, periodicity, state, weight, electronegativity, electron affinity, melting point, boiling point, ionization, radius, hardness, modulus, density, conductivity, heat, and abundance.</p>
<p>The statements (facts) in the Chemical Element KG are represented as triples in the form of (property, relation, element), e.g., (Gas, isStateOf, Cl); For convenience of representation, continuous property values are discretized, resulting in a total of 107 property categories. There are 17 relation types, corresponding to the 17 types of physical chemical properties: isFamilyOf, isMetallicityOf, isPeriodOf, isStateOf, isWeightOf, isElectronegativityOf, isElectronAffinityOf, isMeltingPointOf, isBoilingPointOf, isIonizationOf, isRadiusOf, isHardnessOf, isModulusOf, isDensityOf, isConductivityOf, isHeatOf, and isAbundanceOf. In total, there are 1643 triples.</p>
<p>Functional Group KG</p>
<p>The Functional Group KG provides functional group (subgraph)-level knowledge on chemical biological functions of molecular graphs. Functional Groups are the substituent atoms or groups of atoms that are attached to specific molecules.</p>
<p>They are responsible for the chemical reactions that the molecule they are attached to participate in. Regardless of the molecule in which it is found, the same functional group will behave similarly and experience comparable chemical reactions. Thus, functional groups are the moieties which exhibit their own distinct features and properties independent of the molecule they are attached to. Covalent bonding links the atoms of functional groups and the functional group as a whole to the molecule.</p>
<p>The statements (facts) in the Functional Group KG [11][12] are represented as relations, specifically a collection of logic programs defining almost 100 relations for various functional groups and rings in a chemical compound (molecule with more than one type of chemical element), which for convenience are referred together as moieties. Functional groups are represented as functional_group(CompoundID, Atoms, Length, Type) and rings represented as ring(CompoundID, RingID, Atoms, Length, Type). In addition, three higher level relations are defined to infer the presence of composite structures: has_struc(CompoundId, Atoms, Length, Struc), fused(CompoundId, Struc1, Atoms1, Struc2, Atoms2), and connected(CompoundId, Struc1, Atoms1, Struc2, Atoms2).</p>
<p>The Functional Group KG consists of multiple hierarchies. The hierarchy available in functional groups and rings is shown in Fig. 3 and Fig. 4 of [12], respectively. The most specific types of moieties (a total of 77) are also listed in Table 1 of [11].</p>
<p>Embodied-Symbolic Contrastive Graph SSL for Molecular Graphs</p>
<p>Leveraging background knowledge in Graph SSL is important in many applications. For example, leveraging chemical knowledge (e.g., chemical elements, functional groups) in molecular graph representation learning is crucial for chemical property prediction, molecular binding prediction, and drug discovery.</p>
<p>As discusses in Section 3 Graph Self-Supervised Learning, the design of the contrastive learning approach to Graph SSL usually consists of three main modules: (1) graph augmentation, (2) pretext task, and (3) contrastive objective. Embodiedsymbolic contrastive Graph SSL leverages background knowledge by using (1) knowledge-enhanced (i.e., embodied-symbolic fused [3]) graph augmentation and (2) graph representation learning as pretext task.</p>
<p>KCL (Knowledge-enhanced Contrastive Learning) [10] is a framework that can be used for embodied-symbolic contrastive Graph SSL. It provides three modules:</p>
<p> The knowledge-guided graph augmentation module leverages Chemical KG to guide the graph augmentation process. (Note that KCL specifically leverages Chemical Element KG. In this paper, we extend it to general Chemical KG.)  The knowledge-aware graph representation module learns molecular representations. It adopts a commonly used graph encoder for the original molecular graphs and designs a Knowledge-aware Message Passing Neural Network (KMPNN) encoder to encode complex information in the augmented molecular graphs.</p>
<p> The contrastive objective module trains the encoders to maximize the agreement between the two views (original and augmented) of molecular graphs.</p>
<p>Knowledge-guided graph augmentation and encoding is core to embodied-symbolic contrastive Graph SSL and domain specific, e.g., when applying the framework to molecular graphs. In the following, we discuss two fundamental kinds of knowledge-guided molecular graph augmentation and encoding based on, respectively, Chemical Element KG and Functional Group KG, Note that in both cases, we use the Chemical KG to enhance molecular graphs with symbolic (semantic) knowledge and generate their augmented molecular graphs. We treat a molecular graph and its semantically augmented molecular graph as exemplars of the same semantic class, and use the pairs as positive pairs in exemplar-based contrastive SSL.</p>
<p>Molecular Graph Augmentation and Encoding Based on Chemical Element KG</p>
<p>For molecular graph augmentation, KCL [10] extracts 1-hop neighbor properties of atoms (as chemical elements) in a molecule from Chemical Element KG and adds the corresponding triples as new edges and nodes. For example, it adds a node "Gas" and an edge from "Gas" to "Cl" to the original molecular graph based on the triple (Gas, isStateOf, Cl). (Note that the direction of each edge between the property and the atom is from the former to the latter, as shown in Figure 1 of [10].) This results in an augmented molecular graph, in which the original molecular structure is preserved, and neighborhood topologies for atom-related properties are introduced. The augmented molecular graph thus contains richer and more complex information, and is treated as a positive sample in contrastive learning.</p>
<p>In order to obtain the initial features of properties and relations in the augmented molecular graph, KCL adopts the KG embedding method, RotateE, to train Chemical Element KG. In this way, the initial features can capture the structural information of the triples.</p>
<p>The augmented molecular graphs are complex heterogeneous graph-structured data that fuses two types of information:</p>
<p>the embodied structural information of molecular graphs, and the symbolic domain knowledge extracted from Chemical Element KG. KCL designs a KMPNN encoder to learn their graph-level representations. The key idea is to provide two types of message passing for different types of neighbors (atoms and properties), and assign them different attention according to their importance. It enables heterogeneous message passing with two MSG functions, where MSG a (.) is applied to neighbors representing atoms, and MSG p (.) is applied to neighbors representing properties.</p>
<p>Molecular Graph Augmentation and Encoding Based on Functional Group KG</p>
<p>A simple method to augment molecular graphs based on Functional Group KG is introduced in [11]: it inserts additional nodes with corresponding edges for each functional group and ring, jointly referred to as moiety, identified in a molecular graph.. (It makes use only of the most specific types of moieties.) This results in an augmented molecular graph, in which the original molecular structure is preserved, and neighborhood topologies for atom-related moieties as well as moiety-to-moiety relations (which are specific to the original molecular structure) are introduced. The augmented molecular graph thus contains richer and more complex information, and is treated as a positive sample in contrastive learning, same as the case based on Chemical Element FG.</p>
<p>To obtain the augmented molecular graph, the following steps are performed, as shown in Figure 1 of [11]:</p>
<ol>
<li>
<p>Nodes for all moieties defined in the Functional Group KG are added to the molecular graph.</p>
</li>
<li>
<p>Part-of edges between the moiety nodes and their constituent atoms are added. Atoms can be part of multiple moieties.</p>
</li>
<li>
<p>The moieties are linked with an edge labeled as: a) fused when their constituent atom-level subgraphs share one or more nodes; or as b) connected when their constituent atom-level subgraphs do not have any node in common, but there exists an edge connecting nodes belonging to the two different moieties. Edges connecting any moiety to an aliphatic chain are not labeled as connected but as either c) saturated if the chain is saturated, or d) unsaturated otherwise.</p>
</li>
</ol>
<p>The augmented molecular graphs are complex heterogeneous graph-structured data that fuses three types of information: the embodied structural information of molecular graphs, the symbolic domain knowledge extracted from Functional Group KG, and the embodied-symbolic structural information of moieties in molecular graphs. The structural information of moieties in molecular graphs, i.e., edges linking moieties as discussed in Step 3 above and shown in Figure 1 (c) of [11], is referred to as moiety graphs. An augmented molecular graph therefore consists of two graphs of different types: an atombond graph (the original molecular graph) and a moiety graph, as well as their interconnections, as shown in Figure 1 (d) of [11], An extended KMPNN encoder is needed to learn the graph representations of augmented molecular graphs. It involves four types of message passing for different types of edges: atom&lt;-&gt;atom for atom-bond graphs, moiety&lt;-&gt;moiety for moiety graphs, and (atom&lt;-moiety, moiety&lt;-atom) for their interconnections; and assign them different attention according to their importance. It enables heterogeneous message passing with four MSG functions, where MSG a (.) is applied to atom&lt;-&gt;atom edges, MSG m (.) is applied to moiety&lt;-&gt;moiety edges, MSG a&lt;-m (.) is applied to atom&lt;-moiety edges, and MSG m&lt;-a (.) is applied to moiety&lt;-atom edges.</p>
<p>Conclusion</p>
<p>Dual embodied-symbolic concept representations are the foundation for deep learning and symbolic AI integration. They have been used successfully in computer vision for embodied-symbolic knowledge distillation for few-shot class incremental learning, and embodied-symbolic fused representation for image-text matching. In this paper, we show that they can be used</p>
<p>Library (DGL) [4] is an open-source Python package designed specifically for deep graph learning (i.e., deep learning on graphs). It provides optimized implementations of well-known graph neural network (GNN) models, including graph convolutional network (GCN), relational GCN (R-GCN), graph attention network (GAT), and various message passing neural networks (MPNNs),. The different GNN models are unified by the message passing paradigm. When applying GNN models, there are two phases: a message passing phase and a readout phase. The message passing phase updates node representations simultaneously across the entire graph and consists of multiple iterations of message passing.
successfully for molecular graph representation learning, specifically with exemplar-based contrastive self-supervised learning (SSL). The key is that we use the Chemical knowledge graph (KG), i.e., Chemical Element KG and/or Functional Group KG, to enhance molecular graphs with symbolic (semantic) knowledge and generate their augmented molecular graphs. We treat a molecular graph and its semantically augmented molecular graph as exemplars of the same semantic class, and use the pairs as positive pairs in exemplar-based contrastive SSL.Acknowledgement: Thanks to my wife Hedy (郑期芳) for her support.
Daniel T Chang, arXiv:2112.05677Concept Representation Learning with Contrastive Self-Supervised Learning. arXiv preprintDaniel T. Chang, "Concept Representation Learning with Contrastive Self-Supervised Learning," arXiv preprint arXiv:2112.05677 (2021).</p>
<p>Exemplar-Based Contrastive Self-Supervised Learning with Few-Shot Class Incremental Learning. Daniel T Chang, arXiv:2202.02601arXiv preprintDaniel T. Chang, "Exemplar-Based Contrastive Self-Supervised Learning with Few-Shot Class Incremental Learning," arXiv preprint arXiv:2202.02601 (2022).</p>
<p>Dual Embodied-Symbolic Concept Representations for Deep Learning. Daniel T Chang, arXiv:2203.00600arXiv preprintDaniel T. Chang, "Dual Embodied-Symbolic Concept Representations for Deep Learning," arXiv preprint arXiv:2203.00600 (2022).</p>
<p>Minjie Wang, Lingfan Yu, Da Zheng, Quan Gan, Yu Gai, Zihao Ye, Mufei Li, Jinjing Zhou, Qi Huang, Chao Ma, arXiv:1909.01315Deep Gaph Library: Towards Efficient and Scalable Deep Learning on Graphs. arXiv preprintMinjie Wang, Lingfan Yu, Da Zheng, Quan Gan, Yu Gai, Zihao Ye, Mufei Li, Jinjing Zhou, Qi Huang, Chao Ma, et al., "Deep Gaph Library: Towards Efficient and Scalable Deep Learning on Graphs," arXiv preprint arXiv:1909.01315 (2019).</p>
<p>Mufei Li, Jinjing Zhou, Jiajing Hu, Wenxuan Fan, Yangkang Zhang, Yaxin Gu, George Karypis, arXiv:2106.14232DGL-LifeSci: An Open-Source Toolkit for Deep Learning on Graphs in Life Science. arXiv preprintMufei Li, Jinjing Zhou, Jiajing Hu, Wenxuan Fan, Yangkang Zhang, Yaxin Gu, and George Karypis, "DGL-LifeSci: An Open-Source Toolkit for Deep Learning on Graphs in Life Science," arXiv preprint arXiv:2106.14232 (2021).</p>
<p>Da Zheng, Xiang Song, Chao Ma, Zeyuan Tan, Zihao Ye, Jin Dong, Hao Xiong, Zheng Zhang, George Karypis, arXiv:2004.08532DGL-KE: Training Knowledge Graph Embeddings at Scale. arXiv preprintDa Zheng, Xiang Song, Chao Ma, Zeyuan Tan, Zihao Ye, Jin Dong, Hao Xiong, Zheng Zhang, and George Karypis, "DGL-KE: Training Knowledge Graph Embeddings at Scale," arXiv preprint arXiv:2004.08532 (2020).</p>
<p>Lirong Wu, Haitao Lin, Zhangyang Gao, Cheng Tan, Stan Z Li, arXiv:2105.07342Self-supervised Learning on Graphs: Contrastive, Generative, or Predictive. arXiv preprintLirong Wu, Haitao Lin, Zhangyang Gao, Cheng Tan, and Stan.Z.Li, "Self-supervised Learning on Graphs: Contrastive, Generative, or Predictive," arXiv preprint arXiv:2105.07342 (2021).</p>
<p>Tiered Graph Autoencoders with PyTorch Geometric for Molecular Graphs. Daniel T Chang, arXiv:1908.08612arXiv preprintDaniel T. Chang, "Tiered Graph Autoencoders with PyTorch Geometric for Molecular Graphs," arXiv preprint arXiv:1908.08612 (2019).</p>
<p>Deep Learning for Molecular Graphs with Tiered Graph Autoencoders and Graph Prediction. Daniel T Chang, arXiv:1910.11390arXiv preprintDaniel T. Chang, "Deep Learning for Molecular Graphs with Tiered Graph Autoencoders and Graph Prediction," arXiv preprint arXiv:1910.11390 (2019).</p>
<p>Molecular Ccontrastive Learning with Chemical Element Knowledge Graph. Yin Fang, Qiang Zhang, Haihong Yang, Xiang Zhuang, Shumin Deng, Wen Zhang, Ming Qin, Zhuo Chen, Xiaohui Fan, Huajun Chen, CoRRYin Fang, Qiang Zhang, Haihong Yang, Xiang Zhuang, Shumin Deng, Wen Zhang, Ming Qin, Zhuo Chen, Xiaohui Fan, and Huajun Chen, "Molecular Ccontrastive Learning with Chemical Element Knowledge Graph," in CoRR, 2021.</p>
<p>Molecular Graph Augmentation with Rings and Functional Groups. Kurt De Grave, Fabrizio Costa, J. Chem. Inf. Model. 50Kurt De Grave and Fabrizio Costa, "Molecular Graph Augmentation with Rings and Functional Groups," in J. Chem. Inf. Model, 50, 9, 1660-1668 (2010).</p>
<p>Incorporating Symbolic Domain Knowledge into Graph Neural Networks. Tirtharaj Dash, Ashwin Srinivasan, Lovekesh Vig, arXiv:arXiv:2010.13900arXiv preprintTirtharaj Dash, Ashwin Srinivasan, and Lovekesh Vig, "Incorporating Symbolic Domain Knowledge into Graph Neural Networks," arXiv preprint arXiv: arXiv:2010.13900 (2021).</p>            </div>
        </div>

    </div>
</body>
</html>