<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-565 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-565</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-565</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-16.html">extraction-schema-16</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <p><strong>Paper ID:</strong> paper-3869f81ebc4e7103acc6b867e5f781470cb5fdfa</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/3869f81ebc4e7103acc6b867e5f781470cb5fdfa" target="_blank">Semisupervised Manifold Alignment of Multimodal Remote Sensing Images</a></p>
                <p><strong>Paper Venue:</strong> IEEE Transactions on Geoscience and Remote Sensing</p>
                <p><strong>Paper TL;DR:</strong> The proposed semisupervised manifold alignment (SS-MA) method aligns the images working directly on their manifolds and is thus not restricted to images of the same resolutions, either spectral or spatial.</p>
                <p><strong>Paper Abstract:</strong> We introduce a method for manifold alignment of different modalities (or domains) of remote sensing images. The problem is recurrent when a set of multitemporal, multisource, multisensor, and multiangular images is available. In these situations, images should ideally be spatially coregistered, corrected, and compensated for differences in the image domains. Such procedures require massive interaction of the user, involve tuning of many parameters and heuristics, and are usually applied separately. Changes of sensors and acquisition conditions translate into shifts, twists, warps, and foldings of the (typically nonlinear) manifolds where images lie. The proposed semisupervised manifold alignment (SS-MA) method aligns the images working directly on their manifolds and is thus not restricted to images of the same resolutions, either spectral or spatial. SS-MA pulls close together samples of the same class while pushing those of different classes apart. At the same time, it preserves the geometry of each manifold along the transformation. The method builds a linear invertible transformation to a latent space where all images are alike and reduces to solving a generalized eigenproblem of moderate size. We study the performance of SS-MA in toy examples and in real multiangular, multitemporal, and multisource image classification problems. The method performs well for strong deformations and leads to accurate classification for all domains. A MATLAB implementation of the proposed method is provided at http://isp. uv.es/code/ssma.htm.</p>
                <p><strong>Cost:</strong> 0.015</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e565.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e565.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SS-MA</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Semisupervised Manifold Alignment</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A semi-supervised, linear manifold-alignment method that constructs domain-specific linear projection functions to a common latent space by combining geometry-preserving graph terms with class-similarity and class-dissimilarity graph terms, solved via a generalized eigenproblem.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_name</strong></td>
                            <td>Semisupervised Manifold Alignment (SS-MA)</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_description</strong></td>
                            <td>SS-MA learns one linear projection per domain that maps domain samples into a shared latent space in which: (1) local geometry of each domain is preserved via domain-specific graph Laplacians built from k-NN graphs (term G); (2) labeled samples of the same class from any domain are pulled together via a class-similarity Laplacian (term S); and (3) labeled samples of different classes are pushed apart via a class-dissimilarity Laplacian (term D). The method minimizes a trace-ratio (Rayleigh quotient) that combines these terms, which reduces to solving a generalized eigenvalue problem X(μL_g + L_s)X^T φ = λ X L_d X^T φ. The projection matrix F contains the eigenvectors scaled by sqrt(λ) and can be applied to new data by simple matrix multiplication. Unlabeled samples are used to build G; labeled samples define S and D. The method is linear (explicit projections), invertible (synthesis possible), multisensor (handles different dimensionalities), and multidomain (aligns arbitrary number of domains).</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>computational method / data analysis technique (manifold alignment / domain adaptation)</td>
                        </tr>
                        <tr>
                            <td><strong>source_domain</strong></td>
                            <td>machine learning / manifold learning / domain adaptation (computer science)</td>
                        </tr>
                        <tr>
                            <td><strong>target_domain</strong></td>
                            <td>remote sensing image analysis (geoscience / multisensor, multitemporal, multiangular image classification)</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_type</strong></td>
                            <td>adapted/modified for new context</td>
                        </tr>
                        <tr>
                            <td><strong>modifications_made</strong></td>
                            <td>Adapted generic manifold-alignment concepts to remote sensing specifics by: (1) making the method semi-supervised (explicitly combining labeled inter-domain similarity/dissimilarity graphs S and D with unlabeled per-domain geometry graphs G); (2) structuring the W and Laplacian matrices as a block-diagonal/concatenated form to allow different domain dimensionalities and non-coregistered images; (3) choosing a linear projection formulation leading to a d×d generalized eigenproblem (where d = sum of domain dimensions) for computational tractability; (4) scaling similarity matrices to equal Frobenius norm and using bisecting k-means for uniform unlabeled sampling; (5) specifying practical graph construction parameters (k-NN with k=9) and a tradeoff parameter μ between geometry and class similarity.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>successful - The adapted SS-MA worked effectively in remote sensing experiments (2D toy examples, multiangular, multitemporal, multisource) producing stable and high classification performance after alignment. The paper reports consistently improved Cohen's Kappa versus unprojected baselines and PCA; performance is comparable to or better than KPCA and graph-matching baselines and remains nearly flat across strong acquisition-angle shifts (examples report κ around ~0.8 in multiangular experiments), indicating robust transfer.</td>
                        </tr>
                        <tr>
                            <td><strong>barriers_encountered</strong></td>
                            <td>Computational and practical challenges: (1) construction and storage of large graph Laplacians for many vertices (memory and time); (2) need for at least a few labeled samples in each domain (method is not fully unsupervised); (3) choice of graph parameters (k, μ) and sampling strategy can affect results; (4) when domain shifts are very large, more latent dimensions may be required to capture discriminative structure.</td>
                        </tr>
                        <tr>
                            <td><strong>facilitating_factors</strong></td>
                            <td>Facilitators included the availability of abundant unlabeled pixels, a small number of labeled examples in each domain, the manifold assumption (local geometry informative), capacity to build per-domain graphs (k-NN), the linear eigen-decomposition formulation (solves a d×d problem), and the ability to scale/normalize similarity matrices to balance contributions.</td>
                        </tr>
                        <tr>
                            <td><strong>contextual_requirements</strong></td>
                            <td>Requires: (1) labeled examples from each domain (typically few); (2) unlabeled samples and ability to build per-domain k-NN graphs (computing graph Laplacians); (3) resources to store and manipulate matrices X and Laplacians for the chosen sample sizes or use of sparsification/landmarking strategies for very large graphs; (4) cross-validation to choose dimensionality and SVM/LDA or other classifier to evaluate projection quality.</td>
                        </tr>
                        <tr>
                            <td><strong>generalizability</strong></td>
                            <td>Highly generalizable within contexts that satisfy manifold assumptions: authors claim applicability to multiangular, multitemporal and multisensor remote sensing datasets, including unregistered images and different spectral/spatial resolutions; in principle applicable to other domains involving dataset shift where local geometry + limited labeled correspondences exist (provided graph construction and labeling are feasible).</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>primarily explicit procedural steps and theoretical principles (manifold alignment objective, graph Laplacian regularization) with some instrumental/technical skills (graph construction, eigen-decomposition, data sampling).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Semisupervised Manifold Alignment of Multimodal Remote Sensing Images', 'publication_date_yy_mm': '2014-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e565.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e565.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Graph Laplacian regularization</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Graph Laplacian-based geometry-preserving regularization</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The use of per-domain k-NN graphs and corresponding graph Laplacians to preserve local manifold geometry during projection into a shared latent space, implemented as a regularization term in the alignment objective.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_name</strong></td>
                            <td>Graph Laplacian-based geometry preservation (G term)</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_description</strong></td>
                            <td>For each domain a k-NN or ε-ball similarity graph W_g^m is built (here k=9), from which a degree matrix U_g^m and Laplacian L_g^m = U_g^m - W_g^m are computed. These per-domain Laplacians are arranged in a block-diagonal global L_g and enter the objective as a term G = tr(F^T X L_g X^T F) that penalizes changes in projection between neighboring samples, enforcing local smoothness and manifold structure preservation in the latent space.</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>computational method / regularization technique</td>
                        </tr>
                        <tr>
                            <td><strong>source_domain</strong></td>
                            <td>machine learning / spectral graph theory / manifold learning</td>
                        </tr>
                        <tr>
                            <td><strong>target_domain</strong></td>
                            <td>remote sensing image representation and domain adaptation</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_type</strong></td>
                            <td>direct application with adaptations for multi-domain structure</td>
                        </tr>
                        <tr>
                            <td><strong>modifications_made</strong></td>
                            <td>Applied domain-specific adaptations: per-domain (block-diagonal) Laplacians to allow differing domain dimensionalities and unregistered samples; scaling of similarity matrices to equal Frobenius norm to balance contributions across domains; practical graph construction choices (k-NN with k=9, inclusion of both labeled and unlabeled samples); selection of unlabeled nodes via bisecting k-means to produce compact graphs.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>successful as an enabling component of SS-MA — the G term preserved within-domain geometry and helped SS-MA align distributions without requiring coregistration; essential to stability of projections and classification performance.</td>
                        </tr>
                        <tr>
                            <td><strong>barriers_encountered</strong></td>
                            <td>Large graphs have high memory and computation cost for Laplacian construction and related operations; graph topology sensitive to parameter k and sample selection; raw Laplacians can be large/dense requiring sparsification or landmarking for very large datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>facilitating_factors</strong></td>
                            <td>Availability of many unlabeled samples, cluster-based sampling to reduce graph size, and established graph-processing solvers (authors cite techniques to reduce complexity) facilitated use.</td>
                        </tr>
                        <tr>
                            <td><strong>contextual_requirements</strong></td>
                            <td>Need to choose k (graph locality), have sufficient unlabeled samples to capture geometry, and have computational resources or sparsification strategies for large graphs.</td>
                        </tr>
                        <tr>
                            <td><strong>generalizability</strong></td>
                            <td>Generally applicable to other dataset-shift problems and domains where local manifold geometry is informative and neighborhood graphs are meaningful (e.g., medical imaging, other high-dimensional sensing domains).</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>explicit procedural know-how and theoretical principles (spectral graph theory / manifold regularization).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Semisupervised Manifold Alignment of Multimodal Remote Sensing Images', 'publication_date_yy_mm': '2014-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e565.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e565.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Graph matching baseline</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Graph matching alignment (unsupervised graph-based alignment)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An unsupervised graph-matching approach previously used in remote sensing that aligns datasets by matching graph structures across acquisitions; used here as a comparative baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_name</strong></td>
                            <td>Graph matching alignment (baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_description</strong></td>
                            <td>Graph matching methods build graphs (typically k-NN) for each domain and iteratively match nodes/structures between graphs to align datasets, often preserving neighborhood relations; in this paper graph-matching is applied in an unsupervised manner to align multiangular/multitemporal images and then used as a feature extractor for classification.</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>computational method / graph-based alignment</td>
                        </tr>
                        <tr>
                            <td><strong>source_domain</strong></td>
                            <td>graph matching / machine learning</td>
                        </tr>
                        <tr>
                            <td><strong>target_domain</strong></td>
                            <td>remote sensing image alignment (multiangular/multitemporal)</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_type</strong></td>
                            <td>direct application as comparative baseline</td>
                        </tr>
                        <tr>
                            <td><strong>modifications_made</strong></td>
                            <td>Applied as an unsupervised projector to the same datasets and labeled pixels from a nadir acquisition were used to train classifiers in the matched feature space (the paper does not describe further bespoke modifications).</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>partially successful - graph matching produced stable alignment across acquisitions (stable κ surface) but SS-MA produced higher numerical classification performance by combining semi-supervision; graph matching was competitive in stability but typically lower in absolute accuracy than SS-MA.</td>
                        </tr>
                        <tr>
                            <td><strong>barriers_encountered</strong></td>
                            <td>Requires reliable graph correspondences which can be hard for strong sensor differences or non-coregistered data; unsupervised graph matching may be less discriminative without labeled correspondence information.</td>
                        </tr>
                        <tr>
                            <td><strong>facilitating_factors</strong></td>
                            <td>Strong manifold structure in images and short temporal separation (for multiangular experiment) made graph matching feasible and stable.</td>
                        </tr>
                        <tr>
                            <td><strong>contextual_requirements</strong></td>
                            <td>Per-domain graph construction and computational resources for iterative graph matching; assumption that neighborhood correspondences exist between domains.</td>
                        </tr>
                        <tr>
                            <td><strong>generalizability</strong></td>
                            <td>Applicable to other image-alignment tasks where graph neighborhoods are comparable; less effective when cross-domain correspondences are weak or classes are highly mixed.</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>explicit procedural steps (graph construction and matching algorithms) and algorithmic know-how.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Semisupervised Manifold Alignment of Multimodal Remote Sensing Images', 'publication_date_yy_mm': '2014-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e565.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e565.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Cluster-based unlabeled sampling</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Bisecting k-means centroid sampling for unlabeled selection</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Use of an iterative bisecting k-means clustering strategy to select representative unlabeled samples (cluster centroids) for graph construction and computational tractability.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_name</strong></td>
                            <td>Bisecting k-means-based unlabeled sample selection</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_description</strong></td>
                            <td>An iterative clustering (bisecting k-means) partitions the unlabeled dataset into the desired number of clusters; the centroids of these clusters are then used as representative unlabeled samples (u_m per domain) to build k-NN graphs and reduce computational load while ensuring uniform sampling of the data manifold.</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>data sampling / preprocessing technique</td>
                        </tr>
                        <tr>
                            <td><strong>source_domain</strong></td>
                            <td>unsupervised clustering / machine learning</td>
                        </tr>
                        <tr>
                            <td><strong>target_domain</strong></td>
                            <td>remote sensing graph construction and domain adaptation preprocessing</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_type</strong></td>
                            <td>direct application with parameter choices for remote sensing</td>
                        </tr>
                        <tr>
                            <td><strong>modifications_made</strong></td>
                            <td>Used to produce a fixed number of unlabeled representatives per domain (u_m = 300 or 500 in experiments); selection intended to make graph construction tractable and uniform across domains.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>successful - enabled construction of manageable graphs and contributed to stable SS-MA performance by providing representative unlabeled nodes; used consistently across experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>barriers_encountered</strong></td>
                            <td>Choice of cluster count and clustering instability can influence representativeness; centroid sampling may miss fine-grained local structures if too aggressive.</td>
                        </tr>
                        <tr>
                            <td><strong>facilitating_factors</strong></td>
                            <td>Large unlabeled pools in remote sensing made centroid-based reduction effective; bisecting k-means provides balanced cluster sizes.</td>
                        </tr>
                        <tr>
                            <td><strong>contextual_requirements</strong></td>
                            <td>Parameter choice for stopping criterion (target number of clusters = number of unlabeled samples desired) and computational resources for clustering large datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>generalizability</strong></td>
                            <td>General technique for representative sampling of large unlabeled sets in many domains where graph-based methods are used.</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>explicit procedural know-how (clustering algorithm usage and sampling strategy).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Semisupervised Manifold Alignment of Multimodal Remote Sensing Images', 'publication_date_yy_mm': '2014-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e565.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e565.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Classical domain-adaptation projectors</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>PCA, kPCA, CCA, k-CCA, TCA and other projector baselines</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Standard statistical and kernel multivariate projection methods (PCA, kernel PCA, Canonical Correlation Analysis, kernel CCA, Transfer Component Analysis, etc.) used as comparative baselines for dataset alignment and feature extraction.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_name</strong></td>
                            <td>PCA / kPCA / CCA / k-CCA / TCA (baseline projectors)</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_description</strong></td>
                            <td>These methods project high-dimensional data into lower-dimensional spaces: PCA finds orthogonal directions of maximal variance; kernel PCA applies PCA in a feature/kernel space; CCA finds linear projections of two datasets maximizing cross-correlation; kernel CCA is the nonlinear kernelized variant; TCA (Transfer Component Analysis) finds latent components that minimize domain discrepancy for transfer learning. In the paper they are applied (often unsupervised) to remote sensing images as baseline projectors before classification.</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>computational method / dimensionality reduction / domain adaptation</td>
                        </tr>
                        <tr>
                            <td><strong>source_domain</strong></td>
                            <td>statistics / machine learning / multivariate analysis</td>
                        </tr>
                        <tr>
                            <td><strong>target_domain</strong></td>
                            <td>remote sensing feature extraction and domain adaptation</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_type</strong></td>
                            <td>direct application as baselines (some require coregistration or have limitations)</td>
                        </tr>
                        <tr>
                            <td><strong>modifications_made</strong></td>
                            <td>Applied without per-domain graph-regularization; when used as baselines, some methods required coregistered samples (CCA/kCCA) while PCA was applied in a straightforward manner; KPCA/TCA were used in kernelized settings but not augmented with SS-MA's class-graph constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>partially successful - these methods sometimes improved performance over raw data but had limitations: PCA lacks multisensor capability; (k)CCA requires strict coregistration; TCA and kPCA had mixed results and were generally outperformed by SS-MA in stability or accuracy for strong multisensor or non-coregistered shifts.</td>
                        </tr>
                        <tr>
                            <td><strong>barriers_encountered</strong></td>
                            <td>Method-specific constraints: PCA fails for multisensor data of different dimensionality; CCA/kCCA require strict coregistration and paired samples; kernel methods can be non-invertible and computationally heavier; unsupervised projectors lack discriminative supervision that SS-MA exploits.</td>
                        </tr>
                        <tr>
                            <td><strong>facilitating_factors</strong></td>
                            <td>These are well-known, easily-implemented techniques with available libraries, making them convenient baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>contextual_requirements</strong></td>
                            <td>Some require paired or coregistered samples (CCA), sufficient labeled data for supervised variants, kernel selection for kernelized versions.</td>
                        </tr>
                        <tr>
                            <td><strong>generalizability</strong></td>
                            <td>Widely used across domains; however, their direct application to unregistered, multisensor remote sensing scenarios is limited without adaptations.</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>explicit theoretical principles and procedural application steps.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Semisupervised Manifold Alignment of Multimodal Remote Sensing Images', 'publication_date_yy_mm': '2014-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <p class="empty-note">No potentially relevant new papers extracted.</p>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-565",
    "paper_id": "paper-3869f81ebc4e7103acc6b867e5f781470cb5fdfa",
    "extraction_schema_id": "extraction-schema-16",
    "extracted_data": [
        {
            "name_short": "SS-MA",
            "name_full": "Semisupervised Manifold Alignment",
            "brief_description": "A semi-supervised, linear manifold-alignment method that constructs domain-specific linear projection functions to a common latent space by combining geometry-preserving graph terms with class-similarity and class-dissimilarity graph terms, solved via a generalized eigenproblem.",
            "citation_title": "here",
            "mention_or_use": "use",
            "procedure_name": "Semisupervised Manifold Alignment (SS-MA)",
            "procedure_description": "SS-MA learns one linear projection per domain that maps domain samples into a shared latent space in which: (1) local geometry of each domain is preserved via domain-specific graph Laplacians built from k-NN graphs (term G); (2) labeled samples of the same class from any domain are pulled together via a class-similarity Laplacian (term S); and (3) labeled samples of different classes are pushed apart via a class-dissimilarity Laplacian (term D). The method minimizes a trace-ratio (Rayleigh quotient) that combines these terms, which reduces to solving a generalized eigenvalue problem X(μL_g + L_s)X^T φ = λ X L_d X^T φ. The projection matrix F contains the eigenvectors scaled by sqrt(λ) and can be applied to new data by simple matrix multiplication. Unlabeled samples are used to build G; labeled samples define S and D. The method is linear (explicit projections), invertible (synthesis possible), multisensor (handles different dimensionalities), and multidomain (aligns arbitrary number of domains).",
            "procedure_type": "computational method / data analysis technique (manifold alignment / domain adaptation)",
            "source_domain": "machine learning / manifold learning / domain adaptation (computer science)",
            "target_domain": "remote sensing image analysis (geoscience / multisensor, multitemporal, multiangular image classification)",
            "transfer_type": "adapted/modified for new context",
            "modifications_made": "Adapted generic manifold-alignment concepts to remote sensing specifics by: (1) making the method semi-supervised (explicitly combining labeled inter-domain similarity/dissimilarity graphs S and D with unlabeled per-domain geometry graphs G); (2) structuring the W and Laplacian matrices as a block-diagonal/concatenated form to allow different domain dimensionalities and non-coregistered images; (3) choosing a linear projection formulation leading to a d×d generalized eigenproblem (where d = sum of domain dimensions) for computational tractability; (4) scaling similarity matrices to equal Frobenius norm and using bisecting k-means for uniform unlabeled sampling; (5) specifying practical graph construction parameters (k-NN with k=9) and a tradeoff parameter μ between geometry and class similarity.",
            "transfer_success": "successful - The adapted SS-MA worked effectively in remote sensing experiments (2D toy examples, multiangular, multitemporal, multisource) producing stable and high classification performance after alignment. The paper reports consistently improved Cohen's Kappa versus unprojected baselines and PCA; performance is comparable to or better than KPCA and graph-matching baselines and remains nearly flat across strong acquisition-angle shifts (examples report κ around ~0.8 in multiangular experiments), indicating robust transfer.",
            "barriers_encountered": "Computational and practical challenges: (1) construction and storage of large graph Laplacians for many vertices (memory and time); (2) need for at least a few labeled samples in each domain (method is not fully unsupervised); (3) choice of graph parameters (k, μ) and sampling strategy can affect results; (4) when domain shifts are very large, more latent dimensions may be required to capture discriminative structure.",
            "facilitating_factors": "Facilitators included the availability of abundant unlabeled pixels, a small number of labeled examples in each domain, the manifold assumption (local geometry informative), capacity to build per-domain graphs (k-NN), the linear eigen-decomposition formulation (solves a d×d problem), and the ability to scale/normalize similarity matrices to balance contributions.",
            "contextual_requirements": "Requires: (1) labeled examples from each domain (typically few); (2) unlabeled samples and ability to build per-domain k-NN graphs (computing graph Laplacians); (3) resources to store and manipulate matrices X and Laplacians for the chosen sample sizes or use of sparsification/landmarking strategies for very large graphs; (4) cross-validation to choose dimensionality and SVM/LDA or other classifier to evaluate projection quality.",
            "generalizability": "Highly generalizable within contexts that satisfy manifold assumptions: authors claim applicability to multiangular, multitemporal and multisensor remote sensing datasets, including unregistered images and different spectral/spatial resolutions; in principle applicable to other domains involving dataset shift where local geometry + limited labeled correspondences exist (provided graph construction and labeling are feasible).",
            "knowledge_type": "primarily explicit procedural steps and theoretical principles (manifold alignment objective, graph Laplacian regularization) with some instrumental/technical skills (graph construction, eigen-decomposition, data sampling).",
            "uuid": "e565.0",
            "source_info": {
                "paper_title": "Semisupervised Manifold Alignment of Multimodal Remote Sensing Images",
                "publication_date_yy_mm": "2014-05"
            }
        },
        {
            "name_short": "Graph Laplacian regularization",
            "name_full": "Graph Laplacian-based geometry-preserving regularization",
            "brief_description": "The use of per-domain k-NN graphs and corresponding graph Laplacians to preserve local manifold geometry during projection into a shared latent space, implemented as a regularization term in the alignment objective.",
            "citation_title": "",
            "mention_or_use": "use",
            "procedure_name": "Graph Laplacian-based geometry preservation (G term)",
            "procedure_description": "For each domain a k-NN or ε-ball similarity graph W_g^m is built (here k=9), from which a degree matrix U_g^m and Laplacian L_g^m = U_g^m - W_g^m are computed. These per-domain Laplacians are arranged in a block-diagonal global L_g and enter the objective as a term G = tr(F^T X L_g X^T F) that penalizes changes in projection between neighboring samples, enforcing local smoothness and manifold structure preservation in the latent space.",
            "procedure_type": "computational method / regularization technique",
            "source_domain": "machine learning / spectral graph theory / manifold learning",
            "target_domain": "remote sensing image representation and domain adaptation",
            "transfer_type": "direct application with adaptations for multi-domain structure",
            "modifications_made": "Applied domain-specific adaptations: per-domain (block-diagonal) Laplacians to allow differing domain dimensionalities and unregistered samples; scaling of similarity matrices to equal Frobenius norm to balance contributions across domains; practical graph construction choices (k-NN with k=9, inclusion of both labeled and unlabeled samples); selection of unlabeled nodes via bisecting k-means to produce compact graphs.",
            "transfer_success": "successful as an enabling component of SS-MA — the G term preserved within-domain geometry and helped SS-MA align distributions without requiring coregistration; essential to stability of projections and classification performance.",
            "barriers_encountered": "Large graphs have high memory and computation cost for Laplacian construction and related operations; graph topology sensitive to parameter k and sample selection; raw Laplacians can be large/dense requiring sparsification or landmarking for very large datasets.",
            "facilitating_factors": "Availability of many unlabeled samples, cluster-based sampling to reduce graph size, and established graph-processing solvers (authors cite techniques to reduce complexity) facilitated use.",
            "contextual_requirements": "Need to choose k (graph locality), have sufficient unlabeled samples to capture geometry, and have computational resources or sparsification strategies for large graphs.",
            "generalizability": "Generally applicable to other dataset-shift problems and domains where local manifold geometry is informative and neighborhood graphs are meaningful (e.g., medical imaging, other high-dimensional sensing domains).",
            "knowledge_type": "explicit procedural know-how and theoretical principles (spectral graph theory / manifold regularization).",
            "uuid": "e565.1",
            "source_info": {
                "paper_title": "Semisupervised Manifold Alignment of Multimodal Remote Sensing Images",
                "publication_date_yy_mm": "2014-05"
            }
        },
        {
            "name_short": "Graph matching baseline",
            "name_full": "Graph matching alignment (unsupervised graph-based alignment)",
            "brief_description": "An unsupervised graph-matching approach previously used in remote sensing that aligns datasets by matching graph structures across acquisitions; used here as a comparative baseline.",
            "citation_title": "",
            "mention_or_use": "use",
            "procedure_name": "Graph matching alignment (baseline)",
            "procedure_description": "Graph matching methods build graphs (typically k-NN) for each domain and iteratively match nodes/structures between graphs to align datasets, often preserving neighborhood relations; in this paper graph-matching is applied in an unsupervised manner to align multiangular/multitemporal images and then used as a feature extractor for classification.",
            "procedure_type": "computational method / graph-based alignment",
            "source_domain": "graph matching / machine learning",
            "target_domain": "remote sensing image alignment (multiangular/multitemporal)",
            "transfer_type": "direct application as comparative baseline",
            "modifications_made": "Applied as an unsupervised projector to the same datasets and labeled pixels from a nadir acquisition were used to train classifiers in the matched feature space (the paper does not describe further bespoke modifications).",
            "transfer_success": "partially successful - graph matching produced stable alignment across acquisitions (stable κ surface) but SS-MA produced higher numerical classification performance by combining semi-supervision; graph matching was competitive in stability but typically lower in absolute accuracy than SS-MA.",
            "barriers_encountered": "Requires reliable graph correspondences which can be hard for strong sensor differences or non-coregistered data; unsupervised graph matching may be less discriminative without labeled correspondence information.",
            "facilitating_factors": "Strong manifold structure in images and short temporal separation (for multiangular experiment) made graph matching feasible and stable.",
            "contextual_requirements": "Per-domain graph construction and computational resources for iterative graph matching; assumption that neighborhood correspondences exist between domains.",
            "generalizability": "Applicable to other image-alignment tasks where graph neighborhoods are comparable; less effective when cross-domain correspondences are weak or classes are highly mixed.",
            "knowledge_type": "explicit procedural steps (graph construction and matching algorithms) and algorithmic know-how.",
            "uuid": "e565.2",
            "source_info": {
                "paper_title": "Semisupervised Manifold Alignment of Multimodal Remote Sensing Images",
                "publication_date_yy_mm": "2014-05"
            }
        },
        {
            "name_short": "Cluster-based unlabeled sampling",
            "name_full": "Bisecting k-means centroid sampling for unlabeled selection",
            "brief_description": "Use of an iterative bisecting k-means clustering strategy to select representative unlabeled samples (cluster centroids) for graph construction and computational tractability.",
            "citation_title": "",
            "mention_or_use": "use",
            "procedure_name": "Bisecting k-means-based unlabeled sample selection",
            "procedure_description": "An iterative clustering (bisecting k-means) partitions the unlabeled dataset into the desired number of clusters; the centroids of these clusters are then used as representative unlabeled samples (u_m per domain) to build k-NN graphs and reduce computational load while ensuring uniform sampling of the data manifold.",
            "procedure_type": "data sampling / preprocessing technique",
            "source_domain": "unsupervised clustering / machine learning",
            "target_domain": "remote sensing graph construction and domain adaptation preprocessing",
            "transfer_type": "direct application with parameter choices for remote sensing",
            "modifications_made": "Used to produce a fixed number of unlabeled representatives per domain (u_m = 300 or 500 in experiments); selection intended to make graph construction tractable and uniform across domains.",
            "transfer_success": "successful - enabled construction of manageable graphs and contributed to stable SS-MA performance by providing representative unlabeled nodes; used consistently across experiments.",
            "barriers_encountered": "Choice of cluster count and clustering instability can influence representativeness; centroid sampling may miss fine-grained local structures if too aggressive.",
            "facilitating_factors": "Large unlabeled pools in remote sensing made centroid-based reduction effective; bisecting k-means provides balanced cluster sizes.",
            "contextual_requirements": "Parameter choice for stopping criterion (target number of clusters = number of unlabeled samples desired) and computational resources for clustering large datasets.",
            "generalizability": "General technique for representative sampling of large unlabeled sets in many domains where graph-based methods are used.",
            "knowledge_type": "explicit procedural know-how (clustering algorithm usage and sampling strategy).",
            "uuid": "e565.3",
            "source_info": {
                "paper_title": "Semisupervised Manifold Alignment of Multimodal Remote Sensing Images",
                "publication_date_yy_mm": "2014-05"
            }
        },
        {
            "name_short": "Classical domain-adaptation projectors",
            "name_full": "PCA, kPCA, CCA, k-CCA, TCA and other projector baselines",
            "brief_description": "Standard statistical and kernel multivariate projection methods (PCA, kernel PCA, Canonical Correlation Analysis, kernel CCA, Transfer Component Analysis, etc.) used as comparative baselines for dataset alignment and feature extraction.",
            "citation_title": "",
            "mention_or_use": "use",
            "procedure_name": "PCA / kPCA / CCA / k-CCA / TCA (baseline projectors)",
            "procedure_description": "These methods project high-dimensional data into lower-dimensional spaces: PCA finds orthogonal directions of maximal variance; kernel PCA applies PCA in a feature/kernel space; CCA finds linear projections of two datasets maximizing cross-correlation; kernel CCA is the nonlinear kernelized variant; TCA (Transfer Component Analysis) finds latent components that minimize domain discrepancy for transfer learning. In the paper they are applied (often unsupervised) to remote sensing images as baseline projectors before classification.",
            "procedure_type": "computational method / dimensionality reduction / domain adaptation",
            "source_domain": "statistics / machine learning / multivariate analysis",
            "target_domain": "remote sensing feature extraction and domain adaptation",
            "transfer_type": "direct application as baselines (some require coregistration or have limitations)",
            "modifications_made": "Applied without per-domain graph-regularization; when used as baselines, some methods required coregistered samples (CCA/kCCA) while PCA was applied in a straightforward manner; KPCA/TCA were used in kernelized settings but not augmented with SS-MA's class-graph constraints.",
            "transfer_success": "partially successful - these methods sometimes improved performance over raw data but had limitations: PCA lacks multisensor capability; (k)CCA requires strict coregistration; TCA and kPCA had mixed results and were generally outperformed by SS-MA in stability or accuracy for strong multisensor or non-coregistered shifts.",
            "barriers_encountered": "Method-specific constraints: PCA fails for multisensor data of different dimensionality; CCA/kCCA require strict coregistration and paired samples; kernel methods can be non-invertible and computationally heavier; unsupervised projectors lack discriminative supervision that SS-MA exploits.",
            "facilitating_factors": "These are well-known, easily-implemented techniques with available libraries, making them convenient baselines.",
            "contextual_requirements": "Some require paired or coregistered samples (CCA), sufficient labeled data for supervised variants, kernel selection for kernelized versions.",
            "generalizability": "Widely used across domains; however, their direct application to unregistered, multisensor remote sensing scenarios is limited without adaptations.",
            "knowledge_type": "explicit theoretical principles and procedural application steps.",
            "uuid": "e565.4",
            "source_info": {
                "paper_title": "Semisupervised Manifold Alignment of Multimodal Remote Sensing Images",
                "publication_date_yy_mm": "2014-05"
            }
        }
    ],
    "potentially_relevant_new_papers": [],
    "cost": 0.014583249999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Semisupervised Manifold Alignment of Multimodal Remote Sensing Images</h1>
<p>Devis Tuia, Member, IEEE, Michele Volpi, Student Member, IEEE, Maxime Trolliet, and Gustau Camps-Valls, Senior Member, IEEE</p>
<h4>Abstract</h4>
<p>This is the pre-acceptance version, to read the final version published in 2014 in the IEEE Transactions on Geoscience and Remote Sensing (IEEE TGRS), please go to: 10.1109/TGRS.2014.2317499 We introduce a method for manifold alignment of different modalities (or domains) of remote sensing images. The problem is recurrent when a set of multitemporal, multisource, multisensor and multiangular images is available. In these situations, images should ideally be spatially coregistred, corrected and compensated for differences in the image domains. Such procedures require the interaction of the user, involve tuning of many parameters and heuristics, and are usually applied separately. Changes of sensors and acquisition conditions translate into shifts, twists, warps and foldings of the image distributions (or manifolds). The proposed semisupervised manifold alignment (SS-MA) method aligns the images working directly on their manifolds, and is thus not restricted to images of the same resolutions, either spectral or spatial. SS-MA pulls close together samples of the same class while pushing those of different</p>
<p>Manuscript received 2013;
This work has been partly supported by the Swiss National Science Foundation (grants PZ00P2-136827 (http://p3.snf.ch/project-136827) and P2LAP2-148432 (http://p3.snf.ch/Project-148432)) and by the spanish Ministry of Economy and Competitiveness (MINECO) under project LIFE-VISION TIN2012-38102-C03-01.</p>
<p>DT and MT are with the Laboratoire des Systèmes d’Information Géographique (LaSIG), Ecole Polytechnique Fédérale de Lausanne (EPFL), Switzerland. devis.tuia@epfl.ch, http://devis.tuia.googlepages.com, Phone: +41-216935785, Fax : +41216935790.</p>
<p>MV was with the Centre for Research on Terrestrial Environment, Université de Lausanne, Switzerland. He is now with the CALVIN at the Institute of Perception, Action and Behaviour, the University of Edinburgh, United Kingdom. Telephone: +44 (0) 131650 8741, Fax: +44 (0) 131651 5651, Email: michele.volpi@ed.ac.uk, Web: https://sites.google.com/site/michelevolpiresearch.</p>
<p>GCV is with the Image Processing Laboratory (IPL), Universitat de València, C/ Catedrático A. Escardino, 9 - 46980 Paterna, València (Spain). gustavo.camps@uv.es, http://isp.uv.es, Phone: +34-963544064, Fax: +34-963543261.</p>
<p>classes apart. At the same time, it preserves the geometry of each manifold along the transformation. The method builds a linear invertible transformation to a latent space where all images are alike, and reduces to solving a generalized eigenproblem of moderate size. We study the performance of SS-MA in toy examples and in real multiangular, multitemporal, and multisource image classification problems. The method performs well for strong deformations and leads to accurate classification for all domains. A Matlab implementation of the proposed method is provided at http://isp.uv.es/code/ssma.htm.</p>
<h1>Index Terms</h1>
<p>Feature extraction, Graph-based methods, Very high resolution, Domain adaptation, Multiangular, Multitemporal, Multisource, Classification</p>
<h2>I. INTRODUCTION</h2>
<p>Remote sensing analysts can nowadays exploit images of unprecedented spatial resolution (e.g. higher than the meter for commercial sensors such as WorldView 2) with increasing revisit time (which will be increased with the upcoming Sentinels) [1], [2]. With these very high resolution (VHR) images, it becomes possible to perform a large variety of monitoring studies, since the geographical area of interest can be covered with high frequency. This led to a variety of techniques for multitemporal [3], [4] and multiangular [5], [6] data processing for VHR data.</p>
<p>The increased access to information also induces a series of processing problems for the analyst performing the monitoring task: the images undergo a series of spectral distortions related to variations in the acquisition geometry, the atmospheric conditions, and the acquisition angle. To these acquisition-related differences, we must add a series of temporal specificities, such as the variations in the phenological cycle, or the appearance of small objects contaminating the class signature (flower pots on roofs, for example). All these changes in acquisition conditions and geometry, as well as differences in the properties of the sensors, produce local changes in the probability distribution function (PDF) of the images from one acquisition to another one, which in turn affect the performances of the classifier, when predicting data from another domain. As a consequence, the tempting direct application of a classifier optimal for one scene to another scene can lead to catastrophic results. The application of a classifier to a series of newly acquired scenes remains a priority for image analysts, who would like to reuse the available labeled samples, minimize the time/effort devoted to photointerpretation (or terrestrial campaigns) and eventually use images acquired by other sensors. Therefore, a classifier should</p>
<p>be applicable to new scenes regardless of the sensor and acquisition specificities. This property of portability is of the greatest importance, especially in the VHR context or when considering archives of images, for which labels are often unavailable.</p>
<p>To meet this objective, research has considered strategies of adaptation. By adaptation, we mean the ability of a method to modify its characteristics to new scenes acquired under different acquisition conditions, but representing a similar problem (typically sharing the same classes). Adaptation has been carried out in three main ways in remote sensing data processing: 1) at the level of the classifier, 2) to encode invariances of interest, and 3) at the level of the data representation. Let us briefly review the three families of approximations.</p>
<p>Regarding the adaptation of the classifier, most strategies are issued from semi-supervised learning: the adaptation is usually performed either by modifying the weights of the classifier using unlabeled data coming from the PDF of the image to be classified [7]-[9], by spatial regularization [10], or by adding few informative labeled examples carefully chosen from the new image [11], [12]. This family of approaches often comes with several free parameters, requires expertise in machine learning and statistics, and involves high computational costs.</p>
<p>When considering the incorporation of invariances in the classifier, one aims at making the classifier robust to variations in the data representation. In the specific example of remote sensing images, such variations can be rotations (objects can be arbitrarily oriented), presence of shadows (attenuations of the signal), and scale (objects of the same class can have different sizes, or the new image may have different spatial resolution), just to name a few. Invariance to these changes can be achieved in several ways. For some of these effects, one may develop physical models [13], for example to remove atmospheric of illumination effects. This, however, requires the accurate modeling of the physical processes involved and a detailed knowledge of the atmospheric conditions at the time of acquisition. Alternatively, the classifier can become invariant if one includes in the training set synthetic examples representing the phenomena that the classifier should be invariant to. For example, if using patches of the images as inputs, adding rotated versions of them will force invariance to rotation of the objects represented in the patches [14]. While good results are obtained in general, it becomes complex to encode several invariances simultaneously that cover a reasonable subspace of the image manifold.</p>
<p>The third family is the one considered in this paper. The rationale is to modify the data representation to perform the adaptation. Such a modification can be driven by physical properties</p>
<p>of the atmosphere [13], [15], by a data-driven feature extraction [16], [17], or both [18]. In all cases, however, the aim is to find a common data representation, in which the data are more similar (or aligned) to each other [19], independently from the processing steps that will follow. Since the data representation itself is modified, it is then possible to use any classifier on the aligned data.</p>
<p>This type of adaptation can be seen in a global or local perspective: in the first case, the PDFs of all images are compared and aligned, either by matching the histograms [20], [21] or by projecting the data distributions onto a common space using, for instance, Principal Component Analysis (PCA, [22]), Canonical Correlation Analysis (CCA [16]) or other more advanced nonlinear kernel multivariate methods [23]. In the case of local matching, the point clouds are matched regionally, in order to account for deformations that affect only certain parts of the image manifold. Local methods generally either minimize a cost function bringing the nodes of two graphs closer while maintaining the local neighborhoods in the projected space unchanged [24]-[26] or consider mixtures of local models [27], which are then merged in a global representation [28]-[31]. In the remote sensing literature, an application of the first of these two approaches is found in [17], where an iterative method is used to match graphs of the same sensor under angular and temporal variations.</p>
<p>A desirable alignment method must be capable of aligning images 1) under strong distortions, 2) of different sensors and 3) not co-registered. The methodologies so far proposed in remote sensing literature do not address all these issues simultaneously: PCA does not require coregistration, but fails in multisensor scenarios and under strong distortions. On the contrary, $(\mathrm{K})$ CCA is naturally multisensor and works under strong distortions, but requires strict coregistration. Table I summarizes these properties for a series of alignment methodologies found in remote sensing.</p>
<p>In this paper, we tackle these problems simultaneously by proposing a linear, efficient method for feature extraction and dataset alignment issued from the manifold alignment literature [19], [32]. The main idea of the method is to use labeled samples from both domains to bring the manifolds closer, while keeping their respective inherent structure unchanged using two proximity graphs built with unlabeled samples [33]. Therefore, the method includes constraints on the local manifold geometry in the aligned space. The alignment transformation is defined by a linear projection function that depends both on labeled and unlabeled samples, making the method</p>
<p>semi-supervised. In the aligned space, pixels from both domains can be used simultaneously and a classifier effective in all domains can be learned. We will refer to this method as semisupervised manifold alignment (SS-MA).</p>
<p>SS-MA is effective for large deformations, since it is not based on inter-graphs distances, as the methods in [17], [34]. It does not require co-registration of the image sources as [16], [35], and is naturally multisource, as it can align images of different dimensionality, unlike standard domain adaptation algorithms [8], [9]. Since the eigenvectors are defined with a discriminative term and are sorted by their eigenvalues, the classifier can then be learned using only the first dimensions: this makes SS-MA an interesting solution also for dimensionality reduction. The price to pay is the availability of some (typically few) labeled pixels in each domain.</p>
<p>The remainder of the paper is organized as follows. Section II presents the proposed methodology and the manifold alignment algorithm. Section III presents the VHR data used in the experiments, that are detailed and discussed in Section IV. We will illustrate the method in several problems: 2D toy datasets under different deformations, as well as multiangular adaptation for the same sensor, multitemporal and multisource image adaptation. Section V concludes the paper with some discussion and further work.</p>
<h1>II. SEMISUPERVISED MANIFOLD ALIGNMENT</h1>
<p>The main idea of the proposed method is to align the data manifolds by projecting them into a common representation, or joint latent space, $\mathcal{F}$. Such space has two desirable properties: 1) it preserves the local geometry of each dataset and 2) it brings regions belonging to the same class closer together, while pushing those belonging to different classes apart. The method searches for a set of projection functions, one per image, that achieve this double objective [33]. Figure 1 illustrates the two properties and the expected alignment.</p>
<h2>A. Notation</h2>
<p>Consider a series of $M$ images (or domains) and their corresponding data matrices $\mathbf{X}^{m}, m=$ $1, \ldots, M$. Each matrix $\mathbf{X}^{m}$ contains a large set of unlabeled samples $\left{\mathbf{x}<em i="1">{i}^{m}\right}</em>}^{u_{m}}$, and some inputoutput labeled sample pairs $\left{\mathbf{x<em j="j">{j}^{m}, y</em>\right}}^{m<em m="m">{j=1}^{l</em>$. These matrices contain both labeled and unlabeled points. Let us additionally denote the block diagonal}}$, typically with $l_{m} \ll u_{m}$. To fix notation, examples are column vectors and the data matrices are $\mathbf{X}^{m} \in \mathbb{R}^{d_{m} \times n_{m}}$ where $n_{m}=l_{m}+u_{m</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Fig. 1. Ingredients of the proposed algorithm: (a) two datasets ( $\bullet$ and $\bullet$ ) distorted by a $90^{\circ}$ rotation and labeled pixels of two classes ( $\bullet$ and $\square$ ); (b) Geometrical structures of each manifold to be preserved ( $G$ term, Eq. (2)); (c) Label similarity induced attraction (orange and cyan arrows, $S$ term, Eq. (3)) and repulsion (black arrows, $D$ term, Eq. (4)); (d) aligned dataset.
data matrix containing all samples $\mathbf{X}^{m}, m=1, \ldots, M$, as $\mathbf{X}=\operatorname{diag}\left(\mathbf{X}<em M="M">{1}, \ldots, \mathbf{X}</em>=1, \ldots, M$.}\right) \in \mathbb{R}^{d \times N}$, $N=\sum_{m} n_{m}, d=\sum_{m} d_{m}$. It is important to stress here that the images do not necessarily represent the same location and can be acquired by different sensors with different spatial and spectral resolutions, so in principle we may have different numbers of samples per data matrix, $n_{m} \neq n_{m^{\prime}}$, and different dimensions in each domain, i.e. $\mathbf{x}^{m} \in \mathbb{R}^{d_{m}}$ possibly with $d_{m} \neq d_{m^{\prime}}$, $\forall m, m^{\prime</p>
<h1>B. Semi-supervised loss function</h1>
<p>The problem of aligning the $M$-images dataset to a common representation boils down to constructing $M$ mapping functions to $\mathcal{F}$ by means of $M$ projection matrices, $\mathbf{f}^{m} \in \mathbb{R}^{d_{m} \times d}$, $m=1, \ldots, M$. The common latent space $\mathcal{F}$ is of dimension $d=\sum_{m=1}^{M} d_{m}$. Mapping to $\mathcal{F}$ requires that samples belonging to the same class become closer, while those of different classes are pushed far apart. Moreover, the mapping should preserve the geometry of each data manifold. Since we have terms to be minimized and others to be maximized, the problem reduces to solving</p>
<p>a standard Rayleigh quotient ${ }^{1}$ :</p>
<p>$$
\mathbf{F}^{o p t}=\arg \min _{\mathbf{F}}\left{\operatorname{tr}\left(\left(\mathbf{F}^{\top} \mathbf{B F}\right)^{-1} \mathbf{F}^{\top} \mathbf{A F}\right)\right}
$$</p>
<p>where $\mathbf{F}$ is a $d \times d$ projection matrix, whose row-blocks correspond to the $d_{m} \times d$ domainspecific projection functions, $\mathbf{f}^{m}$. $\mathbf{A}$ is a matrix that contains the quantity of data relations to be decreased by the projection, and $\mathbf{B}$ is a matrix that contains the quantity of data relations to be increased. In our case, we want find the set of projectors $\mathbf{F}^{o p t}$ that maximizes the distances between samples of different classes, represented by an affinity matrix $\mathbf{D}$ (thus $\mathbf{B}=\mathbf{D}$ ) and at the same time minimizes the distances between samples that are either close in each manifold (affinity matrix G) or of the same class (affinity matrix S). These two last matrices are combined as $\mathbf{A}=\mu \mathbf{G}+\mathbf{S}$, where $\mu$ is a tradeoff parameter. A favors discriminant projections (induced by $\mathbf{S}$ ) and at the same time preserves the original geometry of each manifold (summarized in G). The effect of the three terms G, S and D is illustrated in Fig. 1. The three matrices D, S and G will be approached by graphs Laplacians, as detailed below.</p>
<p>Let us now describe the computation of the corresponding scalar terms $G, S$, and $D$, which can be interpreted as the global quantities to be minimized (for $\mathbf{S}$ and $\mathbf{G}$ ), respectively maximized (for D), by the optimization.</p>
<p>The term $G$ ensures that the geometry of each manifold is preserved in the transform. For this reason it does not act among the sources, but only within each source. To this end, local similarity matrices $\mathbf{W}<em m="m">{g}^{m} \in \mathbb{R}^{n</em>} \times n_{m}}$ need to be defined. In this paper, similarity matrices are built using standard graphs, such as the $k \mathrm{NN}$ or $\epsilon$-ball [36], computed for each domain $m$ separately. Entries of the matrices are $W_{g}^{m}(i, j)=1$ if samples $\mathbf{x<em j="j">{i}$ and $\mathbf{x}</em>$. No geometric relation between domains are considered, the geometry is preserved solely within each graph. The geometry term reduces to:}$ from domain $m$ are neighbors in the $k \mathrm{NN}$ graph of that domain and 0 otherwise. The term ensures that neighboring samples in the original domains are mapped close in the projected space ${ }^{2</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>$$
\begin{aligned}
G &amp; =\sum_{m=1}^{M} \sum_{i, j=1}^{n_{m}} W_{g}^{m}(i, j)\left|\mathbf{f}^{m \top} \mathbf{x}<em j="j">{i}^{m}-\mathbf{f}^{m \top} \mathbf{x}</em> \
&amp; =\operatorname{tr}\left(\mathbf{F}^{\top} \mathbf{X} \mathbf{L}_{g} \mathbf{X}^{\top} \mathbf{F}\right)
\end{aligned}
$$}^{m}\right|^{2</p>
<p>where $\mathbf{f}^{m}$ are the functions projecting the domain $m$ in the latent space $\mathcal{F}$ and $\mathbf{L}<em g="g">{g}=\operatorname{diag}\left(\mathbf{L}</em>}^{1}, \ldots, \mathbf{L<em g="g">{g}^{M}\right)$ is a block-diagonal matrix containing the domain-specific graph Laplacians, reflecting the geometric similarity in each domain. For domain $m$, the corresponding Laplacian is $\mathbf{L}</em>}^{m}=\mathbf{U<em g="g">{g}^{m}-\mathbf{W}</em>}^{m}$, with degree matrix $\mathbf{U<em j="j">{g}^{m}(i, i)=\sum</em>(i, j)$.} \mathbf{W}_{g}^{m</p>
<p>The term $S$ enhances class similarity between the labeled instances of all domains. Its role is to pull labeled samples of the same class close together. To this end, we use a matrix of class-similarities, $\mathbf{W}<em s="s">{s}=\left[\mathbf{W}</em>=1, \ldots, M$,
where the components of each $\mathbf{W}}^{\left(m, m^{\prime}\right)}\right], m, m^{\prime<em m="m">{s}^{m, m^{\prime}} \in \mathbb{R}^{n</em>(i, j)=1$ for samples with the same label and 0 otherwise (including unlabeled data). Minimizing $S$ for all the image sources simultaneously corresponds to minimize the distance among all samples of the same class in the latent space:} \times n_{m}}$ are $W_{s}^{m, m^{\prime}</p>
<p>$$
\begin{aligned}
S &amp; =\sum_{m, m^{\prime}=1}^{M} \sum_{i, j=1}^{l_{m} J_{m^{\prime}}} W_{s}^{m, m^{\prime}}(i, j)\left|\mathbf{f}^{m \top} \mathbf{x}<em j="j">{i}^{m}-\mathbf{f}^{m^{\prime} \top} \mathbf{x}</em> \
&amp; =\operatorname{tr}\left(\mathbf{F}^{\top} \mathbf{X} \mathbf{L}_{s} \mathbf{X}^{\top} \mathbf{F}\right)
\end{aligned}
$$}^{m^{\prime}}\right|^{2</p>
<p>where $\mathbf{L}<em s="s">{s}$ is the corresponding joint graph Laplacian to $\mathbf{W}</em>$. What we want to achieve is to map all samples of the same class close to each other, independently from the source they come from. Note that this term considers relations of labeled samples in different domains.</p>
<p>The dissimilarity term $D$ encodes the opposite behavior. By maximizing $D$, one tries to pull samples belonging to different classes apart from each other. To this end, we employ a matrix of class-dissimilarities, $\mathbf{W}<em d="d">{d}=\left[\mathbf{W}</em>\right]$
where the components of each $\mathbf{W}}^{\left(m, m^{\prime}\right)<em m="m">{s}^{m, m^{\prime}} \in \mathbb{R}^{n</em>(i, j)=1$ for samples of different classes and 0 otherwise (including unlabeled data). The dissimilarity term is:} \times n_{m}}$ are $W_{s}^{m, m^{\prime}</p>
<p>$$
\begin{aligned}
D &amp; =\sum_{m, m^{\prime}=1}^{M} \sum_{i, j=1}^{l_{m} J_{m^{\prime}}} W_{d}^{m, m^{\prime}}(i, j)\left|\mathbf{f}^{m \top} \mathbf{x}<em j="j">{i}^{m}-\mathbf{f}^{m^{\prime} \top} \mathbf{x}</em> \
&amp; =\operatorname{tr}\left(\mathbf{F}^{\top} \mathbf{X} \mathbf{L}_{d} \mathbf{X}^{\top} \mathbf{F}\right)
\end{aligned}
$$}^{m^{\prime}}\right|^{2</p>
<p>where $\mathbf{L}<em d="d">{d}$ is the corresponding joint graph Laplacian for $\mathbf{W}</em>$. The term is maximized when labeled samples of different classes are mapped far from each other in the latent space.</p>
<h1>C. Projection functions</h1>
<p>All the $\mathbf{W}$ matrices $\left(\mathbf{W}<em s="s">{g}, \mathbf{W}</em>\right)$ and corresponding graph Laplacians are of size $N \times N$. Now, by plugging Eqs. (2), (3) and (4) into (1), we obtain:}\right.$ and $\left.\mathbf{W}_{d</p>
<p>$$
\min <em d="d">{\mathbf{F}}\left{\operatorname{tr}\left(\left(\mathbf{F}^{\top} \mathbf{X} \mathbf{L}</em>} \mathbf{X}^{\top} \mathbf{F}\right)^{-1} \mathbf{F}^{\top} \mathbf{X}\left(\mu \mathbf{L<em s="s">{g}+\mathbf{L}</em>\right)\right}
$$}\right) \mathbf{X}^{\top} \mathbf{F</p>
<p>The solution of the minimization problem in Eq. (1) is given by the eigenvectors $\varphi_{i}$ corresponding to the smallest eigenvalues of the following generalized eigenvalue decomposition [33]:</p>
<p>$$
\mathbf{X}\left(\mu \mathbf{L}<em s="s">{g}+\mathbf{L}</em> \varphi
$$}\right) \mathbf{X}^{\top} \varphi=\lambda \mathbf{X} \mathbf{L}_{d} \mathbf{X}^{\top</p>
<p>The optimal matrix $\mathbf{F}^{o p t}$ contains the projectors from the original spaces to the joint latent space in row blocks:</p>
<p>$$
\mathbf{F}^{o p t}=\left[\sqrt{\lambda_{1}} \boldsymbol{\varphi}<em d="d">{1}|\ldots| \sqrt{\lambda</em>}} \boldsymbol{\varphi<em 1="1">{d}\right]=\left[\begin{array}{cccc}
\mathbf{f}</em>}^{1} &amp; \ldots &amp; \mathbf{f<em 1="1">{d}^{1} \
\mathbf{f}</em>}^{2} &amp; \ldots &amp; \mathbf{f<em 1="1">{d}^{2} \
\vdots &amp; \vdots &amp; \vdots \
\mathbf{f}</em>
\end{array}\right]
$$}^{\lambda f} &amp; \ldots &amp; \mathbf{f}_{d}^{\lambda f</p>
<p>By looking at the structure of the $\mathbf{F}^{o p t}$ matrix, we observe that each row block contains the projection function from domain $m$ to the latent space. Each domain can thus be projected to the joint space by simple matrix multiplication (as in any multivariate analysis method like PCA). Projecting a data matrix in domain $m, \mathbf{X}_{*}^{m}$ to the $d$-dimensional latent space $\mathcal{F}$ just involves:</p>
<p>$$
\mathcal{P}<em>{f}\left(\mathbf{X}</em>{<em>}^{m}\right)=\mathbf{f}^{m \top} \mathbf{X}_{</em>}^{m}
$$</p>
<h2>D. Properties</h2>
<p>The method has the following properties:
a) Linearity: the method defines explicitly the projection functions, which can in turn be used to project large datasets into the latent space explicitly optimized for joint classification of all the sources.
b) Multisensor: since it only exploits the geometry of each manifold separately, there is no restriction on the number of bands to be aligned nor on their properties.</p>
<p>TABLE I
PROPERTIES OF THE DATA REPRESENTATION METHODS.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Method</th>
<th style="text-align: left;">No labeled pixels <br> in targets</th>
<th style="text-align: left;">Multisensor</th>
<th style="text-align: left;">No <br> registration</th>
<th style="text-align: left;">More than 2 im- <br> ages simult.</th>
<th style="text-align: left;">Invertible</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">PCA</td>
<td style="text-align: left;">$\checkmark$</td>
<td style="text-align: left;">$\times$</td>
<td style="text-align: left;">$\checkmark$</td>
<td style="text-align: left;">$\times$</td>
<td style="text-align: left;">$\checkmark$</td>
</tr>
<tr>
<td style="text-align: left;">k-PCA</td>
<td style="text-align: left;">$\checkmark$</td>
<td style="text-align: left;">$\times$</td>
<td style="text-align: left;">$\checkmark$</td>
<td style="text-align: left;">$\times$</td>
<td style="text-align: left;">$\times$</td>
</tr>
<tr>
<td style="text-align: left;">TCA</td>
<td style="text-align: left;">$\checkmark$</td>
<td style="text-align: left;">$\times$</td>
<td style="text-align: left;">$\checkmark$</td>
<td style="text-align: left;">$\times$</td>
<td style="text-align: left;">$\times$</td>
</tr>
<tr>
<td style="text-align: left;">CCA</td>
<td style="text-align: left;">$\checkmark$</td>
<td style="text-align: left;">$\checkmark$</td>
<td style="text-align: left;">$\times$</td>
<td style="text-align: left;">$\checkmark$</td>
<td style="text-align: left;">$\checkmark$</td>
</tr>
<tr>
<td style="text-align: left;">k-CCA</td>
<td style="text-align: left;">$\checkmark$</td>
<td style="text-align: left;">$\checkmark$</td>
<td style="text-align: left;">$\times$</td>
<td style="text-align: left;">$\checkmark$</td>
<td style="text-align: left;">$\times$</td>
</tr>
<tr>
<td style="text-align: left;">Graph matching [17]</td>
<td style="text-align: left;">$\checkmark$</td>
<td style="text-align: left;">$\times$</td>
<td style="text-align: left;">$\checkmark$</td>
<td style="text-align: left;">$\times$</td>
<td style="text-align: left;">$\checkmark$</td>
</tr>
<tr>
<td style="text-align: left;">SS-MA</td>
<td style="text-align: left;">$\times$</td>
<td style="text-align: left;">$\checkmark$</td>
<td style="text-align: left;">$\checkmark$</td>
<td style="text-align: left;">$\checkmark$</td>
<td style="text-align: left;">$\checkmark$</td>
</tr>
</tbody>
</table>
<p>c) Multidomain: as for CCA, the method can align an arbitrary number of domains in a common latent space. It does not necessarily require (as in the experiments below) a leading source domain to which all the others are aligned to (contrarily to PCA, TCA and graph matching [17]).
d) PDF-based: the method aligns directly the PDFs of the sources, without requiring coregistered samples. Unlike CCA, it can thus align images, which are unregistered, of different areas or of different spatial resolutions.
e) Invertibility: using the projection functions defined, it is possible to synthesize the bands of one sensor from images acquired with another one. This opens many possibilities for the design and evaluation of new instruments.</p>
<p>These properties are also summarized and compared to other feature extractors used to align domains in Table I.</p>
<h1>E. Computational complexity</h1>
<p>The proposed method reduces to solving a generalized eigenvalue problem of relatively small size, involving $d \times d$ matrices. The problem is linear with the number of data sources (in our case, images). Most of the computational effort is associated to the construction of the graph Laplacian $\mathbf{L}<em s="s">{g}$ involved in the geometry-preserving term $G$, because the two other graph Laplacians $\mathbf{L}</em>$ are constructed with a simple convolution between the vectors of labels, and hence the cost of their construction is negligible. Dealing with graph Laplacians with many vertices and edges}$ and $\mathbf{L}_{d</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Fig. 2. The five images used in the multiangular experiments.
can be computationally demanding for two main reasons: the calculation/storage of the matrix itself and the cost of operations such as eigendecomposition and inversion when dealing with these large matrices.</p>
<p>The memory requirements cannot be solved easily, but strategies to decrease the size of the matrices exist, such as intelligent node selection via landmark points [37], active learning [38], inclusion of additional constraints to regularize the graph spatially [39] or graph partitioning and sparsification [40]. Efficient solvers to construct the graph Laplacian have been recently proposed: the solver proposed in [41] scales linearly with the number of edges in both run time and storage. Also note that in SS-MA the graph Laplacian is computed only once and its calculation is performed off-line.</p>
<p>The second problem (the cost of the eigendecomposition) is not critical for SS-MA: since Eq. (5) decomposes an eigenproblem of relatively small size $(d \times d)$, there is no need to design specific strategies to reduce the size of the problem (by sample/nodes selection) or to improve the efficiency of the algebraic process. Note however that iterative methods can be used to reduce the computational load of the eigendecomposition to a logarithmic complexity (which is otherwise $\mathcal{O}\left(d^{3}\right)$ for our $d \times d$ matrix): examples can be found in [42], [43].</p>
<h1>III. DATA AND SETUP</h1>
<p>This section describes the data and the setups used in the experiments presented in Section IV.</p>
<h2>A. Datasets and evaluated scenarios</h2>
<p>The proposed SS-MA is tested in four scenarios:</p>
<ul>
<li>2D Toy dataset under different deformations: the first example is designed to test the robustness of the proposed SS-MA transformation to different deformations of different levels of complexity. To do so, we generated toy datasets composed by two spirals embedded in a 2D space (red and blue spirals on the first column of Fig. 4). The red spiral remains unchanged, while the blue one is either 1) scaled (S), 2) scaled and rotated (S + R), and 3) scaled, rotated and translated (S + R + T). The two domains are composed of 2000 labeled examples each, whose classes are illustrated on different colors on the second column of the figure.</li>
<li>Multiangular adaptation: the first real experiment considers portability of a model along a series of five angular views of the city center of Rio de Janeiro, Brazil, acquired by WorldView-2 [44]. The interest of this dataset is that the images are acquired at a very short time interval and capture the same area, so that the spectral deformations should be only due to angular effects, since the atmosphere is unchanged along the acquisitions. Figure 2 shows an RGB composite of the five images. The number of labeled pixels available for the twelve classes available in each domain is detailed in Tab. II.</li>
<li>Multitemporal adaptation for the same sensor: this is the classical scenario for domain adaptation in which, given one image with sufficient ground truth, we want to apply the best possible classifier for that image to other images taken at different times and places and with minimal effort in photointerpretation (i.e. the least number of new labeled pixels). The images in this experiment are three WorldView-2 scenes extracted from two images of the city of Lausanne, Switzerland: the Montelly and Malley images are subsets of images acquired the $29^{\text {th }}$ of September 2010, while the Prilly subset is part of a scene acquired the $2^{\text {nd }}$ of August 2011. All scenes have been pansharpened using the Gram-Schmidt transform. Figure 3 illustrates the RGB composite and the exhaustive ground truth of these datasets. The number of labeled pixels available is detailed in Tab. III.</li>
<li>Multisource adaptation: in the last experiment, we test the capability of the proposed SSMA to align manifolds of different input dimensionality. To do so, we consider the 8bands available in the Montelly and Prilly datasets, but use as a third image a 4-bands QuickBird image of Zurich (Switzerland) acquired the $6^{\text {th }}$ of October 2006. The image and the corresponding ground truth are illustrated in the last row of Fig. 3. The number of labeled pixels available is detailed in Tab. III. All the images show periurban areas and</li>
</ul>
<p>TABLE II
NUMBER OF LABELED PIXELS AVAILABLE FOR EACH DATASET IN THE MULTIANGULAR EXPERIMENTS ( $\theta=$ OFF-NADIR
ANGLE).</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Class</th>
<th style="text-align: center;">$-38.79^{\circ}$</th>
<th style="text-align: center;">$-29.16^{\circ}$</th>
<th style="text-align: center;">$6.09^{\circ}$</th>
<th style="text-align: center;">$26.76^{\circ}$</th>
<th style="text-align: center;">$39.5^{\circ}$</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Water</td>
<td style="text-align: center;">83260</td>
<td style="text-align: center;">79937</td>
<td style="text-align: center;">66084</td>
<td style="text-align: center;">63492</td>
<td style="text-align: center;">54769</td>
</tr>
<tr>
<td style="text-align: center;">Grass</td>
<td style="text-align: center;">8127</td>
<td style="text-align: center;">8127</td>
<td style="text-align: center;">8127</td>
<td style="text-align: center;">8127</td>
<td style="text-align: center;">8127</td>
</tr>
<tr>
<td style="text-align: center;">Pools</td>
<td style="text-align: center;">244</td>
<td style="text-align: center;">244</td>
<td style="text-align: center;">223</td>
<td style="text-align: center;">195</td>
<td style="text-align: center;">195</td>
</tr>
<tr>
<td style="text-align: center;">Trees</td>
<td style="text-align: center;">4231</td>
<td style="text-align: center;">4074</td>
<td style="text-align: center;">3066</td>
<td style="text-align: center;">3046</td>
<td style="text-align: center;">3046</td>
</tr>
<tr>
<td style="text-align: center;">Concrete</td>
<td style="text-align: center;">707</td>
<td style="text-align: center;">719</td>
<td style="text-align: center;">719</td>
<td style="text-align: center;">719</td>
<td style="text-align: center;">696</td>
</tr>
<tr>
<td style="text-align: center;">Bare soil</td>
<td style="text-align: center;">790</td>
<td style="text-align: center;">790</td>
<td style="text-align: center;">790</td>
<td style="text-align: center;">790</td>
<td style="text-align: center;">811</td>
</tr>
<tr>
<td style="text-align: center;">Asphalt</td>
<td style="text-align: center;">2949</td>
<td style="text-align: center;">2949</td>
<td style="text-align: center;">2949</td>
<td style="text-align: center;">2827</td>
<td style="text-align: center;">2827</td>
</tr>
<tr>
<td style="text-align: center;">Grey buildings</td>
<td style="text-align: center;">6291</td>
<td style="text-align: center;">6061</td>
<td style="text-align: center;">5936</td>
<td style="text-align: center;">4375</td>
<td style="text-align: center;">4527</td>
</tr>
<tr>
<td style="text-align: center;">Red buildings</td>
<td style="text-align: center;">1147</td>
<td style="text-align: center;">1080</td>
<td style="text-align: center;">1070</td>
<td style="text-align: center;">1046</td>
<td style="text-align: center;">1042</td>
</tr>
<tr>
<td style="text-align: center;">White buildings</td>
<td style="text-align: center;">1683</td>
<td style="text-align: center;">1683</td>
<td style="text-align: center;">1571</td>
<td style="text-align: center;">1571</td>
<td style="text-align: center;">1571</td>
</tr>
<tr>
<td style="text-align: center;">Shadows</td>
<td style="text-align: center;">1829</td>
<td style="text-align: center;">1056</td>
<td style="text-align: center;">705</td>
<td style="text-align: center;">512</td>
<td style="text-align: center;">525</td>
</tr>
<tr>
<td style="text-align: center;">Tarmac</td>
<td style="text-align: center;">5179</td>
<td style="text-align: center;">5179</td>
<td style="text-align: center;">5179</td>
<td style="text-align: center;">2166</td>
<td style="text-align: center;">2758</td>
</tr>
</tbody>
</table>
<p>TABLE III
NUMBER OF LABELED PIXELS AVAILABLE FOR EACH DATASET IN THE MULTITEMPORAL AND MULTISOURCE EXPERIMENTS</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Class</th>
<th style="text-align: center;">Color in <br> Fig. 3</th>
<th style="text-align: center;">Dataset</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Prilly</td>
<td style="text-align: center;">Montelly</td>
<td style="text-align: center;">Malley</td>
<td style="text-align: center;">Zurich</td>
</tr>
<tr>
<td style="text-align: left;">Residential</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">151271</td>
<td style="text-align: center;">179695</td>
<td style="text-align: center;">24898</td>
<td style="text-align: center;">78018</td>
</tr>
<tr>
<td style="text-align: left;">Meadows</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">148604</td>
<td style="text-align: center;">47865</td>
<td style="text-align: center;">143674</td>
<td style="text-align: center;">12347</td>
</tr>
<tr>
<td style="text-align: left;">Trees</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">116343</td>
<td style="text-align: center;">177203</td>
<td style="text-align: center;">63956</td>
<td style="text-align: center;">52812</td>
</tr>
<tr>
<td style="text-align: left;">Roads</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">141353</td>
<td style="text-align: center;">104582</td>
<td style="text-align: center;">294687</td>
<td style="text-align: center;">43005</td>
</tr>
<tr>
<td style="text-align: left;">Shadows</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">39404</td>
<td style="text-align: center;">218189</td>
<td style="text-align: center;">194321</td>
<td style="text-align: center;">14071</td>
</tr>
<tr>
<td style="text-align: left;">Commercial</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">13692</td>
<td style="text-align: center;">22506</td>
<td style="text-align: center;">437633</td>
<td style="text-align: center;">25389</td>
</tr>
<tr>
<td style="text-align: left;">Rail</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">8570</td>
<td style="text-align: center;">76802</td>
<td style="text-align: center;">-</td>
</tr>
<tr>
<td style="text-align: left;">Bare</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">2812</td>
<td style="text-align: center;">33305</td>
<td style="text-align: center;">-</td>
</tr>
<tr>
<td style="text-align: left;">Highway</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">28827</td>
</tr>
</tbody>
</table>
<p>involve a common set of classes.</p>
<h1>B. Experimental setup</h1>
<p>As proposed in [33], all the similarity matrices $\mathbf{W}$ are scaled to have the same Frobenius</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Fig. 3. The four images used in the multitemporal and multisource experiments.
norm in order to make them comparable in terms of energy. Consequently they all have the same contribution if $\mu=1$. From all the available labeled pixels in each image, $50 \%$ are kept apart as the testing set. The remaining $50 \%$ samples are used to extract the labeled and unlabeled pixels used in the feature extractor.</p>
<p>The projection matrices $\mathbf{F}$ are learned in a traditional domain adaptation setting, where one domain provides many labeled examples $l_{1}$, and the other(s) have limited examples $l_{M \backslash 1}$. Since the projectors and models are trained with labeled samples from each domain, all the classes of all the images are represented simultaneously. This way, problems related to the appearance of</p>
<p>TABLE IV
NUMBER OF LABELED AND UNLABELED PIXELS USED IN THE EXPERIMENTS.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Experiment</th>
<th style="text-align: center;">$l_{1}$</th>
<th style="text-align: center;">$l_{M \backslash 1}$</th>
<th style="text-align: center;">$u_{m}$</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Toy 2D</td>
<td style="text-align: center;">20 per class</td>
<td style="text-align: center;">$[5, \ldots, 20]$ per class</td>
<td style="text-align: center;">300 per source</td>
</tr>
<tr>
<td style="text-align: center;">Multiangular</td>
<td style="text-align: center;">100 per class</td>
<td style="text-align: center;">$[10,50]$ per class</td>
<td style="text-align: center;">500 per source</td>
</tr>
<tr>
<td style="text-align: center;">Multitemporal</td>
<td style="text-align: center;">100 per class</td>
<td style="text-align: center;">$[10, \ldots, 90]$ per class</td>
<td style="text-align: center;">500 per source</td>
</tr>
<tr>
<td style="text-align: center;">Multisource</td>
<td style="text-align: center;">100 per class</td>
<td style="text-align: center;">$[10, \ldots, 90]$ per class</td>
<td style="text-align: center;">500 per source</td>
</tr>
</tbody>
</table>
<p>new classes are obviated. All the domains provide the same number of unlabeled samples $u_{m}$. The dataset sizes reported in Table IV have been considered.</p>
<p>In the multiangular experiment, only the near-nadir image $\left(6.07^{\circ}\right)$ is considered as the heavily labeled one $\left(l_{1}\right)$. In the multitemporal and multisource experiments, all the domains are considered in turn as the heavily labeled.</p>
<p>The $u_{m}$ unlabeled examples are selected using an iterative clustering algorithm, the bisecting $k$-means [45]. As in [46], we run binary partitions of the dataset until retrieving $u_{m}$ clusters. The centroid of the cluster is then used as unlabeled example, thus ensuring an uniform sampling. The number of unlabeled samples used is reported for each experiment in Table IV. To build the geometrical Laplacian $\mathbf{L}<em m="m">{g}$ in Eq. (2), we used a series of $M$ graphs built using $k$-NN with $k=9$ and all the $n</em>$ labeled and unlabeled samples. The parameter $k$ defines the locality of the graph and, in our experimental tests, seemed not to influence the final results in a significant way, as long as it is set in a reasonable range, i.e. a range where the manifold structure is not lost in an over-connected graph or oversimplified by an under-connected graph.</p>
<p>After extraction of the projection matrix $\mathbf{F}$, the best number of dimensions for classification is cross-validated exploiting the same labeled pixels already used to minimize Eq. (1). To assess the performance of the alignment, a linear SVM has been used to classify the original and projected data. Even though one could use more sophisticated and eventually nonlinear classifiers, our interest here is to assess the quality and discriminative power of the encountered projection features. The algorithm is actually nonlinear through the definition of the graph Laplacian so in principle there is no need to perform nonlinear classification. The libSVM library [47] has been used for such a classification and the regularization $C$ parameter has been cross-validated using the entire labeled set in the range $[100, \ldots, 1000]$. In the multi-angular experiment, additional</p>
<p>results obtained with other projectors (PCA, KPCA and graph matching [17]) and classifiers (LDA) are also reported. Finally, an in-depth analysis of the best dimensionality of the latent space is also conducted for LDA.</p>
<p>A final remark concerns the multisource experiment. Since the domains have different dimensionality, it is not possible to learn a classifier using simultaneously pixels from WorldView-2 and QuickBird. To do so, we downgraded the WorldView-2 images to the four QuickBird bands and provide the results obtained using only the four bands.</p>
<p>In all cases, the results reported are averages of the estimated Cohen's Kappa agreement score ( $\kappa$ hereafter [48]) over five realizations of the sequence projection plus classification in all domains with the projected data. This means that the projections are derived once, a single classifier is trained on the projected training samples, and then applied to each of the projected images, considered in turn as the test image. We set the random generator in a way that the samples of each run are automatically included in the corresponding run using more labeled pixels, i.e. the pixels included in the first run using 10 pixels per class are also used in the first run using $20,30, \ldots$ pixels per class. Note that no specific training process for each test image is performed, as the aim is to classify in the latent space, regardless of the image which will be projected into it.</p>
<h1>IV. RESULTS AND DISCUSSION</h1>
<p>This section presents and discusses the results obtained in the four case studies described in Section III.</p>
<h2>A. 2D toy datasets</h2>
<p>The two first columns of Fig. 4 represent the three deformations considered: 1) scaling (S), 2) scaling plus rotation $(\mathrm{S}+\mathrm{R})$ and 3) scaling, rotation and translation $(\mathrm{S}+\mathrm{R}+\mathrm{T})$. The third column illustrates the result of SS-MA in one of the five experiments performed in each case. In all cases, the proposed method compensates for the present deformations and aligns the two spirals in the correct way. Subsequent classifications by a linear SVM (reported in the fourth and fifth columns of Fig. 4 show two trends:</p>
<ul>
<li>When predicting data from the first spiral ( $\bullet, 20$ labeled pixels per class), adding samples</li>
</ul>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Fig. 4. Toy examples considered to test the invariance to scaling (S) rotation (R) and translation (T) of the SS-MA solution. (a): the two sources ( $\bullet$ and $\bullet$ ) under different deformations ( $\mathrm{S}=$ scaling; $\mathrm{R}=$ rotation; $\mathrm{T}=$ translation). (b) The distribution of the three classes. (c) Result of alignment with SS-MA. (d) Classification results with a linear SVM trained using 20 samples from the first source ( $l_{\bullet}=20$ per class) plus an increasing number of samples from the second ( $l_{\bullet}=[0,5, \ldots, 20]$ per class) when predicting the test samples from the first spiral (Test $=\bullet$ ). (e) Classification results in the same conditions, but predicting the second spiral (Test $=\bullet$ ).
from the other one does not influence the classification results. On the contrary, when using unprojected data, a strong decrease in performance is observed in the three cases. SS-MA shows a stable behavior, since the distributions have been aligned correctly.</p>
<ul>
<li>When predicting data from the second spiral $(\bullet,[5, \ldots, 20]$ labeled pixels per class), SS-MA can exploit the common information of the two datasets efficiently and it always outperforms the unprojected data.</li>
</ul>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Fig. 5. SS-MA projections. Left: original acquisitions at $6.09^{\circ}$ and $-38.79^{\circ}$. Center: two first dimensions of the latent space. Right: three first dimensions of the latent space. In the top row, each color corresponds to a domain (an image), in the bottom row, each color corresponds to a class.</p>
<h1>B. Multiangular adaptation</h1>
<p>The first real experiment considers the multiangular sequence of Rio de Janeiro. As this dataset comprises a set of images from the same sensor and acquired at a very short time interval, the shifts observed are only related to angular effects of increasing strength. Besides analyzing the classification accuracy with respect to a set of competing methods, we also use this dataset to study the evolution of the performance with respect to the dimensionality of the latent space.</p>
<p>First, we visualize the latent space, to assess its discriminative power. Figure 5 illustrates the projections of the images at $6.09^{\circ}$ and $-38.79^{\circ}$ in the 2-dimensional ( 2 first eigenvectors) and 3-dimensional ( 3 first eigenvectors) latent space. From the plots, we can observe that the model defined a discriminative space, where joint linear classification is facilitated.</p>
<p>Figure 6 illustrates the results obtained by 1) the baseline (using only the labeled pixels from the $6.09^{\circ}$ image as training set), 2) the joint use of all the acquisitions, but without projection, 3) the joint use of all the acquisitions after projection with the proposed SS-MA and 4) three aligning methods such as PCA, KPCA and graph matching [17]. To be fair in the evaluation,</p>
<p>the projections for these methods are obtained in an unsupervised way, but then the classifier is trained using the original training points from the nadir acquisition, stacked to the transformed labeled pixels of the domain to be tested.</p>
<p>Using only the nadir acquisition leads to poor results for increasing off-nadir angles, at the point that the $\kappa$ statistic observed are close to 0.2 (black solid line with red markers). Adding labeled information from the specific viewing angle helps and improves notably the results (red dashed line). However, and especially when using a simple parametric model as LDA, the decrease in performance is still observed, especially for strong off-nadir acquisition. The proposed SS-MA (blue solid line) results in an almost flat $\kappa$ surface along the acquisitions, thus showing that projection in the latent space permits 1) to align efficiently the spectra of the acquisitions, and 2) to reduce all the image-specific problems to the same (latent) classification problem. The results observed for SS-MA are always accurate and stable along the acquisitions: they join the stability of the unsupervised method designed specifically for domain adaptation (graph matching, pink line) and the higher numerical results of a generic supervised one (the one depicted by the red curve, where samples from all acquisitions are used to train the model). SS-MA always outperforms PCA alignment (green line) and is always at least as accurate as KPCA (which is also nonlinear - cyan line). Compared to KPCA, SS-MA shows more stable results along the acquisitions, regardless of the classifier and of the number of labeled pixels used.</p>
<p>The use of the LDA classifier also allows to assess the discriminative power of the latent space across its dimensions. Unlike SVM, which is robust to high dimensionality with noisy dimensions, LDA is strongly affected by non-discriminative dimensions and by non-Gaussian class-conditional distributions. Therefore, we studied the evolution of accuracy, when increasing the dimension of the latent space in which the classifier is trained. Fig. 7(a) shows the evolution of the $\kappa$ statistic for one run of the algorithm in the nadir case $\left(\theta=6.09^{\circ}\right)$. Fig. 7(b) shows the same evolution for the off-nadir angles. From these plots, we can conclude that when the shift between the domain providing most of the labeled samples and the destination domain is low (as for the $6.09^{\circ}$ and the $26.76^{\circ}$ images), a lower number of dimensions is sufficient to achieve the best performances. On the contrary, when the shift is larger, the latent space provides informative dimensions up to the last components. Another measure of the complexity of the alignment problem can be provided by studying the dimension of the latent space corresponding</p>
<p><img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Fig. 6. Numerical performances of the multiangular experiments. The nadir image provides 100 labeled pixels per class, while the other are aligned with an increasing number of labeled pixels.
to the highest classification performance in each experiment (and not on a global average, as the dimension represented by the filled dots in Fig. 7): Table V illustrates the average dimension for the five angles and varying number of training examples. Two tendencies are observed: the most nadir acquisition $\left(\theta=6.09^{\circ}\right)$ requires the smallest number of dimensions of the latent space to achieve accurate classification. This is not surprising, as this domain is the one providing most of the labeled examples. For the other domains, a larger number of dimensions is necessary, ranging from 12 to 18 for the acquisition at $26.75^{\circ}$ and higher dimensionality for the other acquisitions, related to larger shift (cf. the lower performance of the LDA baseline in Fig. 6). The only exception observed is the result for 10 pixels per class at $-39.79^{\circ}$, which shows an unusually small average best dimensionality. This is due to the instability of the best dimensionality along the experiments, most likely due to the small number of pixels per class used to align the $-39.79^{\circ}$ domain: for two experiments it required three dimensions and for the rest about 30. However, note that this does not impact the classification performance reported in Fig. 6, which is stable around 0.82 in $\kappa$ statistic.</p>
<p><img alt="img-6.jpeg" src="img-6.jpeg" /></p>
<p>Fig. 7. Evolution of the average $\kappa$ along the dimensions of the latent space defined by the five domains $(d=5 \times 8=40)$ for the experiment using 50 pixels per class. (a) Predicting the most nadiral domain $\left(\theta=6.09^{\circ}\right)$; (b) predicting the four other domains. The filled dot corresponds to the dimension returning the higher average $\kappa$</p>
<p>TABLE V
AVERAGE NUMBER OF DIMENSIONS REQUIRED BY SS-MA TO OBTAIN THE BEST CLASSIFICATION PERFORMANCE (BLUE CURVE IN FIG. 6)</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: right;">Optimal dimensionality for $\theta$</th>
<th style="text-align: right;"></th>
<th style="text-align: right;"></th>
<th style="text-align: right;"></th>
<th style="text-align: right;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: right;">$-38.79^{\circ}$</td>
<td style="text-align: right;">$-29.16^{\circ}$</td>
<td style="text-align: right;">$6.09^{\circ}$</td>
<td style="text-align: right;">$26.76^{\circ}$</td>
<td style="text-align: right;">$39.5^{\circ}$</td>
</tr>
<tr>
<td style="text-align: left;">10 per class</td>
<td style="text-align: right;">10.6</td>
<td style="text-align: right;">34.4</td>
<td style="text-align: right;">3.0</td>
<td style="text-align: right;">18.0</td>
<td style="text-align: right;">32.2</td>
</tr>
<tr>
<td style="text-align: left;">50 per class</td>
<td style="text-align: right;">25.8</td>
<td style="text-align: right;">24.2</td>
<td style="text-align: right;">6.2</td>
<td style="text-align: right;">11.6</td>
<td style="text-align: right;">23.8</td>
</tr>
<tr>
<td style="text-align: left;">90 per class</td>
<td style="text-align: right;">25.0</td>
<td style="text-align: right;">31.6</td>
<td style="text-align: right;">3.0</td>
<td style="text-align: right;">11.2</td>
<td style="text-align: right;">21.4</td>
</tr>
</tbody>
</table>
<h1>C. Multitemporal adaptation for the same sensor</h1>
<p>Figures 8 and 9 illustrate the numerical results for the multitemporal experiments involving three World-View 2 scenes. The first figure shows the $\kappa$ surfaces for increasing number of labeled samples in the auxiliary domains $\mathbf{X}^{2}$ and $\mathbf{X}^{3}$ for both the original data and the data aligned with the SS-MA method. The leading domain $\mathbf{X}^{1}$ is always sampled with $l_{1}=100$ labeled samples per class. Figure 9 summarizes the former by illustrating the diagonal of the surfaces, and compares it to the baseline case (in green), where only the tested domain is used for training the model. This baseline is what would happen in a traditional supervised classification study.</p>
<p>In both cases, each row corresponds to the leading training domain $\mathbf{X}^{1}$ and each column correspond to a different testing image (the baseline is thus the same column-wise). We remind that in the 'SS-MA' case, one set of projections per combination of labeled samples in the three domains is extracted and all the images are then classified with the same SVM model, trained on the labeled pixels of the three domains. The three blocks of each row in the figures (one per</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{1}$ Also known as the Rayleigh-Ritz ratio, and widely used in the field of Fisher's discriminant analysis.
${ }^{2}$ The term acts as a form of graph regularization enforcing the smoothness (or manifold) assumption. Intuitively, this is equivalent to penalize "rapid changes" of the projection function $\mathbf{f}^{m}$ evaluated between samples that are close in the graphs $\mathbf{W}_{g}^{m}$.&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>