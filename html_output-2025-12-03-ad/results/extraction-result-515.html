<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-515 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-515</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-515</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-15.html">extraction-schema-15</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models encode, represent, or utilize spatial knowledge, procedural knowledge, or object-relational knowledge for embodied planning, navigation, or manipulation tasks, particularly when the model operates without direct sensory input.</div>
                <p><strong>Paper ID:</strong> paper-f7b1167f96dad61e00f8d724383f5ad472460837</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/f7b1167f96dad61e00f8d724383f5ad472460837" target="_blank">Extending Analogical Generalization with Near-Misses</a></p>
                <p><strong>Paper Venue:</strong> AAAI Conference on Artificial Intelligence</p>
                <p><strong>Paper TL;DR:</strong> Align’s analogical generalization process constructs multiple probabilistic representations per concept via clustering, and hence can learn disjunctive concepts and uses unsupervised analogical retrieval to find its own near-miss examples.</p>
                <p><strong>Paper Abstract:</strong> 
 
 Concept learning is a central problem for cognitive systems. Generalization techniques can help organize examples by their commonalities, but comparisons with non-examples, near-misses, can provide discrimination. Early work on near-misses required hand-selected examples by a teacher who understood the learner’s internal representations. This paper introduces Analogical Learning by Integrating Generalization and Near-misses (ALIGN) and describes three key advances. First, domain-general cognitive models of analogical processes are used to handle a wider range of examples. Second, ALIGN’s analogical generalization process constructs multiple probabilistic representations per concept via clustering, and hence can learn disjunctive concepts. Finally, ALIGN uses unsupervised analogical retrieval to find its own near-miss examples. We show that ALIGN out-performs analogical generalization on two perceptual data sets: (1) hand-drawn sketches; and (2) geospatial concepts from strategy-game maps.
 
</p>
                <p><strong>Cost:</strong> 0.013</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e515.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e515.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models encode, represent, or utilize spatial knowledge, procedural knowledge, or object-relational knowledge for embodied planning, navigation, or manipulation tasks, particularly when the model operates without direct sensory input.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ALIGN</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Analogical Learning by Integrating Generalization and Near-misses</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A cognitive concept-learning system that combines analogical retrieval (MAC/FAC + SME), incremental analogical generalization (SAGE), and unsupervised near-miss detection to derive inclusion/exclusion hypotheses for spatial concepts represented as structured qualitative descriptions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ALIGN</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>A symbolic, analogy-based learner that operates over structured relational encodings (from CogSketch). ALIGN retrieves similar cases with MAC/FAC, builds detailed SME mappings to generate candidate inferences (positive-to-negative and negative-to-positive), converts those into inclusion/exclusion hypotheses, and revises them via SAGE generalization (probabilistic generalizations over expressions).</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Spatial concept classification (sketches & geospatial regions)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Classification of sketched objects and circled geospatial regions (Freeciv map) into mutually-exclusive spatial concept labels (e.g., arch, bridge, isthmus, peninsula, strait, bay, archipelago, island). The system is given structured symbolic encodings produced by CogSketch (topological relations, medial-axis skeleton segments, qualitative edge properties) and must produce a label or null.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>spatial classification / spatial-concept recognition (relational)</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>spatial + object-relational (topology, relative position, shape skeletons, object relations); procedural knowledge is not the primary focus</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_source</strong></td>
                            <td>explicit symbolic encodings derived from visual input via CogSketch and an OpenCyc-derived concept vocabulary; hypotheses are learned from labeled examples via analogical retrieval and generalization</td>
                        </tr>
                        <tr>
                            <td><strong>has_direct_sensory_input</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>elicitation_method</strong></td>
                            <td>analogical retrieval (MAC/FAC), structured analogical mapping (SME), candidate-inference projection, SAGE incremental generalization (clustering and probabilistic prototypes)</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_representation</strong></td>
                            <td>explicit symbolic relational predicates (topological relations, touches, overlaps), medial-axis skeleton graphs segmented into directed edges with qualitative attributes (length, radius, curvature), SAGE probabilistic generalizations (expressions with probabilities), and inclusion/exclusion hypotheses expressed over example entities and variables</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>classification accuracy (cross-validated)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_result</strong></td>
                            <td>Experiment 1 (sketches): ALIGN = ~62% accuracy (7% above Prototypes/Examples at 55%); Experiment 2 (geospatial Freeciv): ALIGN peak = 77% accuracy vs Prototypes peak = 62% and Examples = 53% (10-fold cross-validation)</td>
                        </tr>
                        <tr>
                            <td><strong>success_patterns</strong></td>
                            <td>Successfully used structural/relational similarity and near-miss comparisons to derive discriminative inclusion and exclusion rules; handled disjunctive concepts by maintaining multiple SAGE generalizations; improved discrimination between visually/structurally similar categories (e.g., arch vs bridge, isthmus vs strait) by blocking labels with exclusion hypotheses.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_patterns</strong></td>
                            <td>Generated overly specific hypotheses from single comparisons that required pruning; performance sensitive to similarity/assimilation threshold (too low -> many incidental hypotheses; too high -> fragmented small generalizations); limited when category sizes are small (insufficient assimilation) or when near-miss retrievals are not appropriately similar.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Prototypes (ALIGN without near-miss analysis): 55% (Exp1) / peak 62% (Exp2); Examples (no near-misses, no generalization; raw retrieval): 55% (Exp1) / 53% (Exp2). ALIGN outperformed both, especially in geospatial task (77% vs 62%/53%).</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_results</strong></td>
                            <td>Two ablations evaluated: Prototypes (disable near-miss analysis but keep SAGE generalization) and Examples (disable both near-miss and SAGE generalization). Removing near-miss analysis reduced accuracy (ALIGN > Prototypes), and removing both reduced it further (Examples worst in Exp2). These ablations show near-miss detection and analogical generalization are critical components.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Symbolic analogical mechanisms can encode and utilize rich spatial and object-relational knowledge without end-to-end sensory inputs at reasoning time by operating on structured encodings: (1) near-miss detection via high-similarity but differently-labeled analogical retrieval yields candidate inclusion/exclusion criteria that improve discrimination; (2) probabilistic analogical generalization (SAGE) revises/prunes overly-specific hypotheses, enabling disjunctive category representations; (3) the approach is sensitive to the similarity threshold, which mediates the tradeoff between incidental hypotheses and insufficient generalization.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Extending Analogical Generalization with Near-Misses', 'publication_date_yy_mm': '2015-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e515.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e515.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models encode, represent, or utilize spatial knowledge, procedural knowledge, or object-relational knowledge for embodied planning, navigation, or manipulation tasks, particularly when the model operates without direct sensory input.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SAGE</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Sequential Analogical Generalization Engine</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An analogical generalization engine built on SME that incrementally clusters examples into generalizations, assigns probabilities to expressions based on frequency in cluster, and produces probabilistic prototypes separating characteristic from incidental structure.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>SAGE</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>A symbolic incremental generalizer that uses SME mappings to merge examples into clusters (generalizations) and maintains per-expression probabilities; prunes low-probability expressions to produce tractable probabilistic concept representations.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Prototype/generalization construction for concept learning</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Given labeled structured examples, SAGE clusters assimilable examples into generalizations and produces probabilistic prototypes that capture characteristic relations and prune incidental structure for downstream hypothesis testing and classification.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>ontology/prototype learning (relational)</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>object-relational + spatial (probabilistic relational expressions over entity attributes and relations)</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_source</strong></td>
                            <td>analogy-driven assimilation of examples provided as structured symbolic cases (from CogSketch)</td>
                        </tr>
                        <tr>
                            <td><strong>has_direct_sensory_input</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>elicitation_method</strong></td>
                            <td>incremental clustering via MAC/FAC retrieval and SME mapping; assimilation threshold controls merging</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_representation</strong></td>
                            <td>probabilistic symbolic generalizations (each expression has a p in [0,1]), generalized entities (representatives for corresponding entities across examples)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>indirect (improvement in downstream classification when used in ALIGN)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_result</strong></td>
                            <td>Not reported standalone; as part of ALIGN it contributed to improved classification (see ALIGN results); Prototypes (uses SAGE, no near-misses) achieved 55% (Exp1) and peak 62% (Exp2).</td>
                        </tr>
                        <tr>
                            <td><strong>success_patterns</strong></td>
                            <td>Preserved common structural relations across examples and suppressed incidental differences via probabilistic pruning, enabling robust inclusion hypothesis formation.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_patterns</strong></td>
                            <td>When examples per concept were few or highly variable, SAGE generalizations remained small/fragmented, limiting hypothesis pruning and reducing effectiveness.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared indirectly via ALIGN ablations: removing near-miss processing but keeping SAGE (Prototypes) reduced performance relative to full ALIGN.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_results</strong></td>
                            <td>Prototypes (SAGE present, near-miss disabled) shows the impact of removing near-miss-derived hypotheses; SAGE alone did not outperform simple retrieval in one experiment without near-misses (Exp1).</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Probabilistic analogical generalization provides an explicit, testable representation of characteristic vs incidental relational structure, enabling projection of hypotheses and pruning of near-miss-derived criteria even when operating on symbolic encodings rather than raw sensory data.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Extending Analogical Generalization with Near-Misses', 'publication_date_yy_mm': '2015-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e515.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e515.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models encode, represent, or utilize spatial knowledge, procedural knowledge, or object-relational knowledge for embodied planning, navigation, or manipulation tasks, particularly when the model operates without direct sensory input.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SME</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Structure-Mapping Engine</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A computational model of Gentner's structure-mapping theory that produces correspondences and candidate inferences between two structured representations using local-to-global matching and greedy coalescence.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>The structure-mapping engine: Algorithm and examples.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>SME</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>A symbolic analogical mapper that builds local match hypotheses in parallel and greedily combines them into global mappings, scoring mappings by structure-based measures and producing candidate inferences (including analogy skolems).</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Analogical mapping and candidate-inference generation</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Given a base and a target structured representation (cases), SME computes mappings (correspondences) and projects unshared structure as candidate inferences used for hypothesis generation (inclusion/exclusion) in ALIGN.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>relational mapping / inference projection</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>object-relational + spatial (relations and structured predicates)</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_source</strong></td>
                            <td>structured symbolic case encodings (from CogSketch); SME uses those structures to infer correspondences</td>
                        </tr>
                        <tr>
                            <td><strong>has_direct_sensory_input</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>elicitation_method</strong></td>
                            <td>pairwise structured analogical mapping</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_representation</strong></td>
                            <td>symbolic relational predicates and correspondences; candidate inferences including analogy skolems</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>normalized similarity score of mappings (0-1) used for retrieval and near-miss detection</td>
                        </tr>
                        <tr>
                            <td><strong>performance_result</strong></td>
                            <td>Used within ALIGN and MAC/FAC to produce mappings; mappings above a similarity threshold (e.g., 0.8) were treated as near-misses and used to generate hypotheses; no standalone numeric performance reported.</td>
                        </tr>
                        <tr>
                            <td><strong>success_patterns</strong></td>
                            <td>Produced interpretable correspondences enabling projection of relations and identification of structural differences (near-misses) that drive discriminative hypothesis formation.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_patterns</strong></td>
                            <td>Mappings can produce over-specific candidate inferences when based on single comparisons; depend on quality and granularity of input encodings.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Underlying component of MAC/FAC and ALIGN; not directly compared to other mappers in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_results</strong></td>
                            <td>Not ablated in isolation in this paper; its role is essential for both retrieval-stage FAC and hypothesis projection.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>SME enables explicit projection of relational structure (including hypothesized entities/skolems) which can be translated into testable inclusion/exclusion hypotheses for spatial concepts, supporting reasoning without raw sensory input by operating on symbolic encodings.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Extending Analogical Generalization with Near-Misses', 'publication_date_yy_mm': '2015-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e515.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e515.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models encode, represent, or utilize spatial knowledge, procedural knowledge, or object-relational knowledge for embodied planning, navigation, or manipulation tasks, particularly when the model operates without direct sensory input.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MAC/FAC</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>MAC/FAC</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A two-stage similarity-based retrieval model that first computes coarse, scalable content-vector similarities (MAC) and then uses SME for fine-grained analogical matching (FAC) to retrieve the best reminding cases.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>MAC/FAC: A model of similarity-based retrieval.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>MAC/FAC</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Retrieval system where MAC produces fast coarse similarity estimates via content vectors and FAC applies SME to top candidates for high-quality analogical reminders; used to find near-misses and candidate positive/negative comparisons in ALIGN.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Analogical retrieval for near-miss discovery</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Given a probe case, MAC/FAC scans a case library to return up to three most similar cases using scalable content-vector dot products followed by SME-based ranking for the top candidates.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>retrieval / memory-based similarity</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>object-relational + spatial (counts of predicates in content vectors approximating relational overlap)</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_source</strong></td>
                            <td>case library of structured symbolic encodings produced by CogSketch</td>
                        </tr>
                        <tr>
                            <td><strong>has_direct_sensory_input</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>elicitation_method</strong></td>
                            <td>retrieval via content-vector similarity (MAC) followed by SME mapping (FAC)</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_representation</strong></td>
                            <td>content vectors (redundant non-structured counts of predicate usage) for MAC; full structured relational representations for FAC/SME</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>retrieval similarity (content-vector dot product; normalized SME similarity)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_result</strong></td>
                            <td>Enabled identification of near-miss pairs when normalized SME similarity exceeded assimilation threshold (e.g., 0.8); no explicit retrieval precision/recall numbers reported.</td>
                        </tr>
                        <tr>
                            <td><strong>success_patterns</strong></td>
                            <td>Scalable pre-selection by MAC allows FAC/SME to focus on high-quality matches; effective at finding structurally similar but differently-labeled cases (near-misses) that drive hypothesis generation.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_patterns</strong></td>
                            <td>If content vectors poorly approximate structural similarity, candidate near-misses may be missed or irrelevant ones passed to FAC; sensitivity to thresholds affects downstream hypothesis quality.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Used as the retrieval backbone for ALIGN; no alternate retrieval baseline reported in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_results</strong></td>
                            <td>Not directly ablated, but retrieval failures would reduce near-miss discovery and degrade ALIGN performance.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>A two-stage retrieval (coarse content vectors then analogical mapping) lets a symbolic system efficiently find structurally similar examples to trigger near-miss based hypothesis generation, enabling relational spatial reasoning without direct sensor streams at the reasoning layer.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Extending Analogical Generalization with Near-Misses', 'publication_date_yy_mm': '2015-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e515.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e515.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models encode, represent, or utilize spatial knowledge, procedural knowledge, or object-relational knowledge for embodied planning, navigation, or manipulation tasks, particularly when the model operates without direct sensory input.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CogSketch</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>CogSketch (sketch understanding system)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An open-domain sketch understanding system that segments digital ink into glyphs, labels them with concepts drawn from an OpenCyc-derived vocabulary, computes visual and spatial relations, and encodes qualitative structured representations (edges, objects, skeletons, topological relations).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Cogsketch: Sketch understanding for cognitive science research and for education.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>CogSketch</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>A perception-to-symbols pipeline that converts user-drawn digital ink or rendered game maps into structured symbolic representations: glyph segmentation, topological relations (adjacency, touch), medial-axis skeleton decomposition, skeleton segmentation by radius changes, and encoding of qualitative attributes for edges and relations.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Perceptual encoding of sketches and geospatial regions</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Processes sketches or rendered Freeciv maps to produce symbolic cases comprising detected entities (glyphs), topological relations between selection glyph and terrain blobs, medial-axis-based skeletons segmented with qualitative attributes, and topological relations between skeleton edges and selection glyph.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>perceptual encoding / representation extraction</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>spatial + object-relational (topology, shape skeletons, relative size/position)</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_source</strong></td>
                            <td>digital ink input and rendered game map images; concept vocabulary from OpenCyc-derived knowledge base</td>
                        </tr>
                        <tr>
                            <td><strong>has_direct_sensory_input</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>elicitation_method</strong></td>
                            <td>algorithmic image/ink processing (segmentation, medial-axis transform, skeleton pruning/segmentation), labeling by user or interface</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_representation</strong></td>
                            <td>structured symbolic representations: glyph entities, topological relations, medial-axis skeleton graphs with qualitative attributes (length, radius function, curvature), and explicit relational facts</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>not directly evaluated here; provided encodings used downstream by ALIGN</td>
                        </tr>
                        <tr>
                            <td><strong>performance_result</strong></td>
                            <td>Not reported as a standalone metric in this paper; average case encodings contained ~4.5 entities/31 facts (sketches) or ~8 entities/60 facts (geospatial cases).</td>
                        </tr>
                        <tr>
                            <td><strong>success_patterns</strong></td>
                            <td>Produced rich structured encodings sufficient for analogical matching and hypothesis generation by ALIGN; supported multi-level descriptions (edges, objects, groups).</td>
                        </tr>
                        <tr>
                            <td><strong>failure_patterns</strong></td>
                            <td>Potential sensitivity to labeling and segmentation errors (not quantified here); encodings' granularity affects SME mappings and thus hypothesis quality.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Not compared to alternative encoders in this work.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_results</strong></td>
                            <td>Not ablated in this paper; CogSketch is the front-end that supplies symbolic cases for ALIGN.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>An explicit perception-to-symbols front-end allows relational analogical systems to perform spatial and object-relational reasoning and to generate discriminative hypotheses without requiring the reasoning components to consume raw sensory streams; the symbolic encodings (skeletons, topological relations) are critical substrates for analogical retrieval and near-miss-based learning.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Extending Analogical Generalization with Near-Misses', 'publication_date_yy_mm': '2015-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>The structure-mapping engine: Algorithm and examples. <em>(Rating: 2)</em></li>
                <li>MAC/FAC: A model of similarity-based retrieval. <em>(Rating: 2)</em></li>
                <li>Cogsketch: Sketch understanding for cognitive science research and for education. <em>(Rating: 2)</em></li>
                <li>SEQL: Category learning as progressive abstraction using structure mapping. <em>(Rating: 2)</em></li>
                <li>Learning structural descriptions from examples. <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-515",
    "paper_id": "paper-f7b1167f96dad61e00f8d724383f5ad472460837",
    "extraction_schema_id": "extraction-schema-15",
    "extracted_data": [
        {
            "name_short": "ALIGN",
            "name_full": "Analogical Learning by Integrating Generalization and Near-misses",
            "brief_description": "A cognitive concept-learning system that combines analogical retrieval (MAC/FAC + SME), incremental analogical generalization (SAGE), and unsupervised near-miss detection to derive inclusion/exclusion hypotheses for spatial concepts represented as structured qualitative descriptions.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "ALIGN",
            "model_size": null,
            "model_description": "A symbolic, analogy-based learner that operates over structured relational encodings (from CogSketch). ALIGN retrieves similar cases with MAC/FAC, builds detailed SME mappings to generate candidate inferences (positive-to-negative and negative-to-positive), converts those into inclusion/exclusion hypotheses, and revises them via SAGE generalization (probabilistic generalizations over expressions).",
            "task_name": "Spatial concept classification (sketches & geospatial regions)",
            "task_description": "Classification of sketched objects and circled geospatial regions (Freeciv map) into mutually-exclusive spatial concept labels (e.g., arch, bridge, isthmus, peninsula, strait, bay, archipelago, island). The system is given structured symbolic encodings produced by CogSketch (topological relations, medial-axis skeleton segments, qualitative edge properties) and must produce a label or null.",
            "task_type": "spatial classification / spatial-concept recognition (relational)",
            "knowledge_type": "spatial + object-relational (topology, relative position, shape skeletons, object relations); procedural knowledge is not the primary focus",
            "knowledge_source": "explicit symbolic encodings derived from visual input via CogSketch and an OpenCyc-derived concept vocabulary; hypotheses are learned from labeled examples via analogical retrieval and generalization",
            "has_direct_sensory_input": false,
            "elicitation_method": "analogical retrieval (MAC/FAC), structured analogical mapping (SME), candidate-inference projection, SAGE incremental generalization (clustering and probabilistic prototypes)",
            "knowledge_representation": "explicit symbolic relational predicates (topological relations, touches, overlaps), medial-axis skeleton graphs segmented into directed edges with qualitative attributes (length, radius, curvature), SAGE probabilistic generalizations (expressions with probabilities), and inclusion/exclusion hypotheses expressed over example entities and variables",
            "performance_metric": "classification accuracy (cross-validated)",
            "performance_result": "Experiment 1 (sketches): ALIGN = ~62% accuracy (7% above Prototypes/Examples at 55%); Experiment 2 (geospatial Freeciv): ALIGN peak = 77% accuracy vs Prototypes peak = 62% and Examples = 53% (10-fold cross-validation)",
            "success_patterns": "Successfully used structural/relational similarity and near-miss comparisons to derive discriminative inclusion and exclusion rules; handled disjunctive concepts by maintaining multiple SAGE generalizations; improved discrimination between visually/structurally similar categories (e.g., arch vs bridge, isthmus vs strait) by blocking labels with exclusion hypotheses.",
            "failure_patterns": "Generated overly specific hypotheses from single comparisons that required pruning; performance sensitive to similarity/assimilation threshold (too low -&gt; many incidental hypotheses; too high -&gt; fragmented small generalizations); limited when category sizes are small (insufficient assimilation) or when near-miss retrievals are not appropriately similar.",
            "baseline_comparison": "Prototypes (ALIGN without near-miss analysis): 55% (Exp1) / peak 62% (Exp2); Examples (no near-misses, no generalization; raw retrieval): 55% (Exp1) / 53% (Exp2). ALIGN outperformed both, especially in geospatial task (77% vs 62%/53%).",
            "ablation_results": "Two ablations evaluated: Prototypes (disable near-miss analysis but keep SAGE generalization) and Examples (disable both near-miss and SAGE generalization). Removing near-miss analysis reduced accuracy (ALIGN &gt; Prototypes), and removing both reduced it further (Examples worst in Exp2). These ablations show near-miss detection and analogical generalization are critical components.",
            "key_findings": "Symbolic analogical mechanisms can encode and utilize rich spatial and object-relational knowledge without end-to-end sensory inputs at reasoning time by operating on structured encodings: (1) near-miss detection via high-similarity but differently-labeled analogical retrieval yields candidate inclusion/exclusion criteria that improve discrimination; (2) probabilistic analogical generalization (SAGE) revises/prunes overly-specific hypotheses, enabling disjunctive category representations; (3) the approach is sensitive to the similarity threshold, which mediates the tradeoff between incidental hypotheses and insufficient generalization.",
            "uuid": "e515.0",
            "source_info": {
                "paper_title": "Extending Analogical Generalization with Near-Misses",
                "publication_date_yy_mm": "2015-01"
            }
        },
        {
            "name_short": "SAGE",
            "name_full": "Sequential Analogical Generalization Engine",
            "brief_description": "An analogical generalization engine built on SME that incrementally clusters examples into generalizations, assigns probabilities to expressions based on frequency in cluster, and produces probabilistic prototypes separating characteristic from incidental structure.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "SAGE",
            "model_size": null,
            "model_description": "A symbolic incremental generalizer that uses SME mappings to merge examples into clusters (generalizations) and maintains per-expression probabilities; prunes low-probability expressions to produce tractable probabilistic concept representations.",
            "task_name": "Prototype/generalization construction for concept learning",
            "task_description": "Given labeled structured examples, SAGE clusters assimilable examples into generalizations and produces probabilistic prototypes that capture characteristic relations and prune incidental structure for downstream hypothesis testing and classification.",
            "task_type": "ontology/prototype learning (relational)",
            "knowledge_type": "object-relational + spatial (probabilistic relational expressions over entity attributes and relations)",
            "knowledge_source": "analogy-driven assimilation of examples provided as structured symbolic cases (from CogSketch)",
            "has_direct_sensory_input": false,
            "elicitation_method": "incremental clustering via MAC/FAC retrieval and SME mapping; assimilation threshold controls merging",
            "knowledge_representation": "probabilistic symbolic generalizations (each expression has a p in [0,1]), generalized entities (representatives for corresponding entities across examples)",
            "performance_metric": "indirect (improvement in downstream classification when used in ALIGN)",
            "performance_result": "Not reported standalone; as part of ALIGN it contributed to improved classification (see ALIGN results); Prototypes (uses SAGE, no near-misses) achieved 55% (Exp1) and peak 62% (Exp2).",
            "success_patterns": "Preserved common structural relations across examples and suppressed incidental differences via probabilistic pruning, enabling robust inclusion hypothesis formation.",
            "failure_patterns": "When examples per concept were few or highly variable, SAGE generalizations remained small/fragmented, limiting hypothesis pruning and reducing effectiveness.",
            "baseline_comparison": "Compared indirectly via ALIGN ablations: removing near-miss processing but keeping SAGE (Prototypes) reduced performance relative to full ALIGN.",
            "ablation_results": "Prototypes (SAGE present, near-miss disabled) shows the impact of removing near-miss-derived hypotheses; SAGE alone did not outperform simple retrieval in one experiment without near-misses (Exp1).",
            "key_findings": "Probabilistic analogical generalization provides an explicit, testable representation of characteristic vs incidental relational structure, enabling projection of hypotheses and pruning of near-miss-derived criteria even when operating on symbolic encodings rather than raw sensory data.",
            "uuid": "e515.1",
            "source_info": {
                "paper_title": "Extending Analogical Generalization with Near-Misses",
                "publication_date_yy_mm": "2015-01"
            }
        },
        {
            "name_short": "SME",
            "name_full": "Structure-Mapping Engine",
            "brief_description": "A computational model of Gentner's structure-mapping theory that produces correspondences and candidate inferences between two structured representations using local-to-global matching and greedy coalescence.",
            "citation_title": "The structure-mapping engine: Algorithm and examples.",
            "mention_or_use": "use",
            "model_name": "SME",
            "model_size": null,
            "model_description": "A symbolic analogical mapper that builds local match hypotheses in parallel and greedily combines them into global mappings, scoring mappings by structure-based measures and producing candidate inferences (including analogy skolems).",
            "task_name": "Analogical mapping and candidate-inference generation",
            "task_description": "Given a base and a target structured representation (cases), SME computes mappings (correspondences) and projects unshared structure as candidate inferences used for hypothesis generation (inclusion/exclusion) in ALIGN.",
            "task_type": "relational mapping / inference projection",
            "knowledge_type": "object-relational + spatial (relations and structured predicates)",
            "knowledge_source": "structured symbolic case encodings (from CogSketch); SME uses those structures to infer correspondences",
            "has_direct_sensory_input": false,
            "elicitation_method": "pairwise structured analogical mapping",
            "knowledge_representation": "symbolic relational predicates and correspondences; candidate inferences including analogy skolems",
            "performance_metric": "normalized similarity score of mappings (0-1) used for retrieval and near-miss detection",
            "performance_result": "Used within ALIGN and MAC/FAC to produce mappings; mappings above a similarity threshold (e.g., 0.8) were treated as near-misses and used to generate hypotheses; no standalone numeric performance reported.",
            "success_patterns": "Produced interpretable correspondences enabling projection of relations and identification of structural differences (near-misses) that drive discriminative hypothesis formation.",
            "failure_patterns": "Mappings can produce over-specific candidate inferences when based on single comparisons; depend on quality and granularity of input encodings.",
            "baseline_comparison": "Underlying component of MAC/FAC and ALIGN; not directly compared to other mappers in the paper.",
            "ablation_results": "Not ablated in isolation in this paper; its role is essential for both retrieval-stage FAC and hypothesis projection.",
            "key_findings": "SME enables explicit projection of relational structure (including hypothesized entities/skolems) which can be translated into testable inclusion/exclusion hypotheses for spatial concepts, supporting reasoning without raw sensory input by operating on symbolic encodings.",
            "uuid": "e515.2",
            "source_info": {
                "paper_title": "Extending Analogical Generalization with Near-Misses",
                "publication_date_yy_mm": "2015-01"
            }
        },
        {
            "name_short": "MAC/FAC",
            "name_full": "MAC/FAC",
            "brief_description": "A two-stage similarity-based retrieval model that first computes coarse, scalable content-vector similarities (MAC) and then uses SME for fine-grained analogical matching (FAC) to retrieve the best reminding cases.",
            "citation_title": "MAC/FAC: A model of similarity-based retrieval.",
            "mention_or_use": "use",
            "model_name": "MAC/FAC",
            "model_size": null,
            "model_description": "Retrieval system where MAC produces fast coarse similarity estimates via content vectors and FAC applies SME to top candidates for high-quality analogical reminders; used to find near-misses and candidate positive/negative comparisons in ALIGN.",
            "task_name": "Analogical retrieval for near-miss discovery",
            "task_description": "Given a probe case, MAC/FAC scans a case library to return up to three most similar cases using scalable content-vector dot products followed by SME-based ranking for the top candidates.",
            "task_type": "retrieval / memory-based similarity",
            "knowledge_type": "object-relational + spatial (counts of predicates in content vectors approximating relational overlap)",
            "knowledge_source": "case library of structured symbolic encodings produced by CogSketch",
            "has_direct_sensory_input": false,
            "elicitation_method": "retrieval via content-vector similarity (MAC) followed by SME mapping (FAC)",
            "knowledge_representation": "content vectors (redundant non-structured counts of predicate usage) for MAC; full structured relational representations for FAC/SME",
            "performance_metric": "retrieval similarity (content-vector dot product; normalized SME similarity)",
            "performance_result": "Enabled identification of near-miss pairs when normalized SME similarity exceeded assimilation threshold (e.g., 0.8); no explicit retrieval precision/recall numbers reported.",
            "success_patterns": "Scalable pre-selection by MAC allows FAC/SME to focus on high-quality matches; effective at finding structurally similar but differently-labeled cases (near-misses) that drive hypothesis generation.",
            "failure_patterns": "If content vectors poorly approximate structural similarity, candidate near-misses may be missed or irrelevant ones passed to FAC; sensitivity to thresholds affects downstream hypothesis quality.",
            "baseline_comparison": "Used as the retrieval backbone for ALIGN; no alternate retrieval baseline reported in this paper.",
            "ablation_results": "Not directly ablated, but retrieval failures would reduce near-miss discovery and degrade ALIGN performance.",
            "key_findings": "A two-stage retrieval (coarse content vectors then analogical mapping) lets a symbolic system efficiently find structurally similar examples to trigger near-miss based hypothesis generation, enabling relational spatial reasoning without direct sensor streams at the reasoning layer.",
            "uuid": "e515.3",
            "source_info": {
                "paper_title": "Extending Analogical Generalization with Near-Misses",
                "publication_date_yy_mm": "2015-01"
            }
        },
        {
            "name_short": "CogSketch",
            "name_full": "CogSketch (sketch understanding system)",
            "brief_description": "An open-domain sketch understanding system that segments digital ink into glyphs, labels them with concepts drawn from an OpenCyc-derived vocabulary, computes visual and spatial relations, and encodes qualitative structured representations (edges, objects, skeletons, topological relations).",
            "citation_title": "Cogsketch: Sketch understanding for cognitive science research and for education.",
            "mention_or_use": "use",
            "model_name": "CogSketch",
            "model_size": null,
            "model_description": "A perception-to-symbols pipeline that converts user-drawn digital ink or rendered game maps into structured symbolic representations: glyph segmentation, topological relations (adjacency, touch), medial-axis skeleton decomposition, skeleton segmentation by radius changes, and encoding of qualitative attributes for edges and relations.",
            "task_name": "Perceptual encoding of sketches and geospatial regions",
            "task_description": "Processes sketches or rendered Freeciv maps to produce symbolic cases comprising detected entities (glyphs), topological relations between selection glyph and terrain blobs, medial-axis-based skeletons segmented with qualitative attributes, and topological relations between skeleton edges and selection glyph.",
            "task_type": "perceptual encoding / representation extraction",
            "knowledge_type": "spatial + object-relational (topology, shape skeletons, relative size/position)",
            "knowledge_source": "digital ink input and rendered game map images; concept vocabulary from OpenCyc-derived knowledge base",
            "has_direct_sensory_input": true,
            "elicitation_method": "algorithmic image/ink processing (segmentation, medial-axis transform, skeleton pruning/segmentation), labeling by user or interface",
            "knowledge_representation": "structured symbolic representations: glyph entities, topological relations, medial-axis skeleton graphs with qualitative attributes (length, radius function, curvature), and explicit relational facts",
            "performance_metric": "not directly evaluated here; provided encodings used downstream by ALIGN",
            "performance_result": "Not reported as a standalone metric in this paper; average case encodings contained ~4.5 entities/31 facts (sketches) or ~8 entities/60 facts (geospatial cases).",
            "success_patterns": "Produced rich structured encodings sufficient for analogical matching and hypothesis generation by ALIGN; supported multi-level descriptions (edges, objects, groups).",
            "failure_patterns": "Potential sensitivity to labeling and segmentation errors (not quantified here); encodings' granularity affects SME mappings and thus hypothesis quality.",
            "baseline_comparison": "Not compared to alternative encoders in this work.",
            "ablation_results": "Not ablated in this paper; CogSketch is the front-end that supplies symbolic cases for ALIGN.",
            "key_findings": "An explicit perception-to-symbols front-end allows relational analogical systems to perform spatial and object-relational reasoning and to generate discriminative hypotheses without requiring the reasoning components to consume raw sensory streams; the symbolic encodings (skeletons, topological relations) are critical substrates for analogical retrieval and near-miss-based learning.",
            "uuid": "e515.4",
            "source_info": {
                "paper_title": "Extending Analogical Generalization with Near-Misses",
                "publication_date_yy_mm": "2015-01"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "The structure-mapping engine: Algorithm and examples.",
            "rating": 2
        },
        {
            "paper_title": "MAC/FAC: A model of similarity-based retrieval.",
            "rating": 2
        },
        {
            "paper_title": "Cogsketch: Sketch understanding for cognitive science research and for education.",
            "rating": 2
        },
        {
            "paper_title": "SEQL: Category learning as progressive abstraction using structure mapping.",
            "rating": 2
        },
        {
            "paper_title": "Learning structural descriptions from examples.",
            "rating": 1
        }
    ],
    "cost": 0.013006249999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Extending Analogical Generalization with Near-Misses</h1>
<p>Matthew D. McLure<br>Qualitative Reasoning Group<br>Northwestern University<br>2133 Sheridan Road<br>Evanston, IL, 60208, USA<br>mclure@u.northwestern.edu</p>
<p>Scott E. Friedman<br>Smart Information Flow Technologies (SIFT)<br>Minneapolis, MN, USA<br>friedman@sift.net</p>
<p>Kenneth D. Forbus<br>Qualitative Reasoning Group<br>Northwestern University<br>2133 Sheridan Road<br>Evanston, IL, 60208, USA<br>forbus@northwestern.edu</p>
<h4>Abstract</h4>
<p>Concept learning is a central problem for cognitive systems. Generalization techniques can help organize examples by their commonalities, but comparisons with non-examples, near-misses, can provide discrimination. Early work on near-misses required hand-selected examples by a teacher who understood the learner's internal representations. This paper introduces Analogical Learning by Integrating Generalization and Near-misses (ALIGN) and describes three key advances. First, domain-general cognitive models of analogical processes are used to handle a wider range of examples. Second, ALIGN's analogical generalization process constructs multiple probabilistic representations per concept via clustering, and hence can learn disjunctive concepts. Finally, ALIGN uses unsupervised analogical retrieval to find its own near-miss examples. We show that ALIGN out-performs analogical generalization on two perceptual data sets: (1) hand-drawn sketches; and (2) geospatial concepts from strategy-game maps.</p>
<h2>Introduction</h2>
<p>Learning concepts from examples is a core capability for cognitive systems. While many approaches learn over feature vectors, this work involves learning from more expressive relational representations, similar to inductive logic programming (Muggleton and De Raedt 1994; Cleuziou, Martin, and Vrain 2003). We focus here on similarity-based supervised learning, where labeled examples are available. Winston (1970) introduced the idea of a near-miss, a negative example that is very similar to a positive example. The small number of differences ideally one - simplified the learner's search for necessary conditions for category membership. Winston's system used analogical matching to compare the structured representations of the positive and negative examples in order to find the difference(s). Winston's system had some important limitations: it used a domain-specific analogical matcher; it required the teacher to know the internal representations of the concept; it required the teacher to</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup>label near-misses; it learned one representation per concept and thus could not handle disjunctive concepts; and it was only tested on blocks-world scenes.</p>
<p>Since that time, the state of the art in knowledge representation and analogical reasoning has improved to the point where a more general model capable of using near-misses can be formulated over more general representations. This paper describes Analogical Learning by Integrating Generalization and Near-misses (ALIGN), which is built on Gentner's (1983) structure-mapping theory of analogy and similarity. Computational models of human analogical matching, retrieval, and generalization (summarized below) are combined and extended to yield three important advantages: (1) ALIGN learns both characteristic properties (i.e., descriptions generalized over positive examples) and discriminative properties (i.e., strict membership criteria) of categories; (2) ALIGN can learn disjunctive categories; and (3) ALIGN automatically identifies near-misses via analogical retrieval, so the teacher does not need to provide them or know the underlying knowledge representations.</p>
<p>We provide empirical results to support these claims, using ALIGN to learn spatial concepts from hand-sketched examples in a sketch understanding system. We use sketched materials for two reasons. First, visual and spatial information is of great importance in domains such as science, engineering, and art, and typically involves rich, relational representations. Second, encoding spatial representations automatically from raw ink reduces tailorability, as opposed to hand-generated representations.</p>
<p>We start by summarizing the analogical processing models that ALIGN uses, and the sketch understanding system we used to automatically encode examples for the experiments. We then describe ALIGN and two experimental analyses: (1) ALIGN learns concepts from sketches of everyday objects; and (2) ALIGN learns geospatial concepts from circled examples on a strategygame map. We close with related and future work.</p>
<h2>Background</h2>
<h2>Computational models of Structure-Mapping</h2>
<p>Structure-Mapping is a psychological theory of analogy and similarity that has been used to explain how people compare visual stimuli (Markman and Gentner 1996; Sagi, Gentner, and Lovett 2012), learn abstract categories (Gentner and Namy 1999), and learn contrastive categories via difference detection (Smith and Gentner 2014). It defines analogical comparison as a process of aligning two structured representations, a base and a target, guided by mapping constraints. The matching process produces correspondences that specify which elements (i.e., entities and expressions) in the base go with which elements in the target. Structure-mapping also generates candidate inferences that project unshared structure (i.e., noncorresponding expressions) from base to target or viceversa.</p>
<h2>The Structure-Mapping Engine (SME)</h2>
<p>The Structure-Mapping Engine (Falkenhainer, Forbus, and Gentner 1989) is a computational model of structuremapping theory. SME operates via a local-to-global process, initially constructing local match hypotheses in parallel, followed by a serial phase that greedily coalesces islands of matches into globally consistent mappings, guided by a scoring process based on structure-mapping principles. Each mapping contains a set of correspondences and a similarity score that captures the overall similarity. The similarity score is normalized to the closed interval [0, 1] by dividing by the mean of the scores of the selfmatches of base and target. Each mapping can contain candidate inferences, from base to target, and reverse candidate inferences, from target to base. Candidate inferences can include analogy skolems, which are entities hypothesized via projection because they lack a correspondent in the other case.</p>
<h2>MAC/FAC</h2>
<p>MAC/FAC (Forbus, Gentner, and Law 1995) is a model of similarity-based retrieval built on SME. The inputs are (1) a probe case and (2) a set of cases from which to retrieve, called a case library. MAC/FAC retrieves up to three similar cases from the case library based on similarity to the probe. The algorithm has two stages. The first stage (MAC) computes in parallel coarse similarity estimates between the probe and every case in the case library using content vectors, a redundant non-structured representation computed from the cases. Each dimension in a content vector is proportional to the number of statements using that predicate in the original case, thus the dot product estimates the number of local matches that SME will find between the probe and each case. This scales well to large case libraries. The cases with the highest dot product with the probe are passed to the second stage, FAC. FAC uses</p>
<p>SME to compare the probe to each MAC result, in parallel. The case with highest SME similarity score, plus up to two more if very close to the top scorer, are returned as the reminding(s).</p>
<h2>Sequential Analogical Generalization Engine (SAGE)</h2>
<p>The Sequential Analogical Generalization Engine (SAGE) is a model of analogical generalization built on SME, and the successor to SEQL (Kuehne et al. 2000). SAGE maintains a generalization context for each concept, where incoming training examples are incrementally clustered to form generalizations (two or more analogically mapped examples) and unassimilated examples (clusters of size one). SAGE generalizations are themselves cases, but each expression in a generalization is assigned a probability based on the frequency with which it corresponded to expressions in co-clustered examples.
<img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: An example is added to the "Arch" generalization context and generalized with a previously unassimilated example.</p>
<p>The SAGE algorithm consists of two stages: (1) select at most one existing cluster that is sufficiently similar to the incoming example, and (2) merge the incoming example into the cluster, if sufficiently similar. The select process uses MAC/FAC, with the new example as the probe and the generalization context as the case library. If the normalized similarity score of the best reminding is greater than the assimilation threshold of the generalization context, SAGE merges the example; otherwise, the new example is added as an unassimilated example.</p>
<p>The merge process uses the correspondences in the SME mapping to (1) update the probabilities associated with each existing expression in the generalization, and (2) add new expressions from the example to the generalization. When non-identical entities correspond in the mapping, SAGE replaces them with generalized entities (i.e., symbols that represent multiple symbols from examples). A merge is illustrated in Figure 1, where corresponding expressions in the resulting generalization have $\mathrm{p}=1.0$, and non-corresponding expressions have a $\mathrm{p}=0.5$. SME uses these probabilities to bias the local scores on match</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: Three pairs of sketched objects with decreasing normalized similarity scores, from top to bottom. All three pairs are potential near-misses because their labels differ.
hypotheses. As SAGE assimilates more examples into a generalization, some expressions will retain high probability, while others will diminish. Consequently, generalizations in SAGE express a probability distribution over their expressions, separating characteristic (high probability) structure from incidental (low-probability) structure. SAGE uses a probability threshold to prune low-probability expressions from the generalization and maintain tractability.</p>
<p>SAGE has been used to learn and classify musical genres (Dehghani and Lovett 2006), spatial prepositions (Lockwood, Lovett, and Forbus 2008), and sketched everyday objects (Lovett, Dehghani, and Forbus 2007; McLure, Friedman, and Forbus 2012), suggesting that it provides a domain-general foundation for ALIGN.</p>
<h2>CogSketch</h2>
<p>Sketching is a powerful way to express visual and spatial ideas. CogSketch (Forbus et al. 2011) is an open-domain sketch understanding system. Users draw digital ink, which they segment into visual entities (glyphs) and label with concepts drawn from a large (OpenCyc-derived) knowledge base. ${ }^{1}$ Conceptual labeling is a practical vehicle for information that is often conveyed with language during human-to-human sketching (e.g., "this is a block"). CogSketch constructs visual representations from what is drawn (e.g., that two glyphs have intersecting edges) and spatial representations from both the visual and conceptual information (e.g., that the objects depicted by the glyphs are touching). Figure 2 shows six examples. CogSketch's extensive vocabulary of representations is motivated by human spatial cognition, including relations</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3: A water glyph (top-left) is decomposed into its skeleton edges (bottom right) by using a grassfire algorithm (top-right) to compute a medial-axis transform, which is pruned and segmented according to its radius function.
for adjacency, relative position and size, and topological relationships. It is capable of analyzing the same sketch at multiple levels of description (i.e., edges, objects, and groups).</p>
<p>CogSketch interacts with the strategy game Freeciv to encode qualitative structured representations for regions on the map. CogSketch renders the map and creates glyphs for units, cities, and terrain blobs (i.e., polygons that outline groups of tiles that share some property). The user selects a region by drawing a glyph on the map (e.g., the red circle in Figure 3). When the user assigns a conceptual label to the selection glyph, CogSketch automatically encodes a case. The encoding scheme used in our geospatial classification task (illustrated in Figure 3) begins by detecting and recording topological relationships between the selection glyph and overlapping land or water terrain blobs. Any blob glyph that overlaps the selection glyph is decomposed into a skeleton based on the Medial Axis Transform (MAT). Each skeleton is further segmented at points corresponding to qualitative changes in the radius function (i.e., the distance from each point to its closest points on the exterior) - a strategy inspired by shock graphs (Siddiqi et al. 1999). The result for each blob glyph is a network of edges directed from its wider sections to its narrower sections. The scheme encodes qualitative properties over these edges including length, radius function, curvature, and various aspects of connectivity. Finally, topological relationships between each edge and the selection glyph are encoded.</p>
<p>CogSketch has been used to model visual problem solving (Lovett, Forbus, and Usher 2010), including</p>
<p>cultural differences (Lovett and Forbus 2011). It has also been used as a platform for sketch-based educational software (Yin et al. 2010). These experiments suggest that the representations it produces are both realistic and useful.</p>
<h2>ALIGN</h2>
<p>Similarity can be deceptive. Isthmuses are similar to straits, bays are similar to peninsulas, and bridges are similar to arches. In this section, we describe how ALIGN leverages these deceptive similarities as opportunities to learn and represent category boundaries. We begin by discussing how ALIGN detects and exploits deceptive similarities, then we describe how it represents and revises its hypotheses, and finally we describe how it classifies examples with a mix of similarity and hypothesis-testing.</p>
<h2>Detecting \&amp; Exploiting Near-Misses with Analogy</h2>
<p>Given a labeled training example (e.g., of an arch), ALIGN uses MAC/FAC to retrieve similar training examples with different labels (e.g., bridge) or a null label. ${ }^{2}$ High-similarity pairs of examples with different labels above a similarity threshold (equal to SAGE's assimilation threshold) are near-misses. Using the best SME mapping between the positive (arch) and negative (bridge or null) example, ALIGN uses the candidate inferences (i.e., projected expressions across cases) to produce hypotheses about category boundaries.</p>
<p>ALIGN distinguishes between two types of candidate inferences (CIs) that produce different hypotheses:</p>
<ol>
<li>Positive-to-negative CIs (PNCIs) project relations from the positive example in terms of the negative example's entities. ALIGN converts these to inclusion hypotheses: necessary criteria for asserting category membership.
<img alt="img-3.jpeg" src="img-3.jpeg" /></li>
</ol>
<p>Figure 4: A near-miss pair and hypothesis revision</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup>2. Negative-to-positive CIs (NPCIs) project relations from the negative example, in terms of the positive example's entities. ALIGN converts these to exclusion hypotheses: sufficient criteria for blocking category membership.
ALIGN associates hypotheses with the positive example, and represents hypotheses in terms of the positive example's entities. For PNCIs, this requires a translation step that replaces the entities mentioned (from the negative side) with their corresponding (positive) entities. In Figure 4 (top), H 1 is an inclusion hypothesis for the category arch resulting from the PNCI (isa e Block), and H3 is an exclusion hypothesis resulting from the NPCI (touches f g).</p>
<p>ALIGN also represents skolems in its hypotheses. A skolem in a PNCI is replaced with the positive entity from which it was projected, e.g. (AnalogySkolemFn m) translates to m . In contrast, NPCIs with skolems result in more complex exclusion hypotheses, because they need to</p>
<div class="codehilite"><pre><span></span><code><span class="err">\</span><span class="p">(</span><span class="err">\</span><span class="nx">mathbf</span><span class="p">{</span><span class="nx">C</span><span class="w"> </span><span class="nx">L</span><span class="p">}=</span><span class="err">\</span><span class="p">{</span><span class="w"> </span><span class="err">\</span><span class="p">}</span><span class="w"> </span><span class="p">;</span><span class="w"> </span><span class="p">;</span><span class="err">\</span><span class="p">)</span><span class="w"> </span><span class="nx">a</span><span class="w"> </span><span class="k">case</span><span class="w"> </span><span class="kn">library</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="nx">training</span><span class="w"> </span><span class="nx">examples</span>
<span class="p">;;</span><span class="w"> </span><span class="err">\</span><span class="p">(</span><span class="err">\</span><span class="nx">boldsymbol</span><span class="p">{</span><span class="nx">S</span><span class="p">}=</span><span class="err">\</span><span class="p">)</span><span class="w"> </span><span class="nx">similarity</span><span class="w"> </span><span class="nx">threshold</span><span class="p">,</span><span class="w"> </span><span class="err">\</span><span class="p">(</span><span class="nx">M_</span><span class="p">{</span><span class="nx">S</span><span class="w"> </span><span class="nx">S</span><span class="p">}=</span><span class="err">\</span><span class="p">)</span><span class="w"> </span><span class="nx">reverse</span><span class="w"> </span><span class="nx">mapping</span><span class="w"> </span><span class="nx">of</span><span class="w"> </span><span class="err">\</span><span class="p">(</span><span class="nx">M_</span><span class="p">{</span><span class="nx">S</span><span class="w"> </span><span class="nx">S</span><span class="p">}</span><span class="err">\</span><span class="p">)</span>
<span class="nx">TrainOn</span><span class="p">(</span><span class="nx">example</span><span class="w"> </span><span class="nx">P</span><span class="p">,</span><span class="w"> </span><span class="nx">label</span><span class="w"> </span><span class="nx">Lp</span><span class="p">)</span><span class="w"> </span><span class="p">;;</span><span class="w"> </span><span class="nx">label</span><span class="w"> </span><span class="nx">may</span><span class="w"> </span><span class="nx">be</span><span class="w"> </span><span class="nx">null</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="err">\</span><span class="p">(</span><span class="err">\</span><span class="nx">mathrm</span><span class="p">{</span><span class="nx">Lp</span><span class="p">}</span><span class="err">\</span><span class="p">)</span>
<span class="w">        </span><span class="err">\</span><span class="p">(</span><span class="err">\</span><span class="nx">mathrm</span><span class="p">{</span><span class="nx">GC</span><span class="p">}</span><span class="nx">_</span><span class="p">{</span><span class="err">\</span><span class="nx">mathrm</span><span class="p">{</span><span class="nx">P</span><span class="p">}}=</span><span class="err">\</span><span class="nx">operatorname</span><span class="p">{</span><span class="nx">Label</span><span class="p">}</span><span class="w"> </span><span class="err">\</span><span class="nx">rightarrow</span><span class="err">\</span><span class="p">)</span><span class="w"> </span><span class="nx">GeneralizationContext</span><span class="w"> </span><span class="err">\</span><span class="p">(</span><span class="err">\</span><span class="nx">left</span><span class="p">(</span><span class="err">\</span><span class="nx">mathrm</span><span class="p">{</span><span class="nx">L</span><span class="p">}</span><span class="nx">_</span><span class="p">{</span><span class="err">\</span><span class="nx">mathrm</span><span class="p">{</span><span class="nx">P</span><span class="p">}}</span><span class="err">\</span><span class="nx">right</span><span class="p">)</span><span class="err">\</span><span class="p">)</span>
<span class="w">        </span><span class="err">\</span><span class="p">(</span><span class="err">\</span><span class="nx">left</span><span class="err">\</span><span class="p">{</span><span class="err">\</span><span class="nx">mathrm</span><span class="p">{</span><span class="nx">G</span><span class="p">}</span><span class="nx">_</span><span class="p">{</span><span class="err">\</span><span class="nx">mathrm</span><span class="p">{</span><span class="nx">P</span><span class="p">}},</span><span class="w"> </span><span class="err">\</span><span class="nx">mathrm</span><span class="p">{</span><span class="nx">M</span><span class="p">}</span><span class="nx">_</span><span class="p">{</span><span class="err">\</span><span class="nx">mathrm</span><span class="p">{</span><span class="nx">GP</span><span class="p">}}</span><span class="err">\</span><span class="nx">right</span><span class="err">\</span><span class="p">}=</span><span class="err">\</span><span class="nx">operatorname</span><span class="p">{</span><span class="nx">SageAdd</span><span class="p">}(</span><span class="err">\</span><span class="nx">mathrm</span><span class="p">{</span><span class="nx">P</span><span class="p">},</span><span class="w"> </span><span class="err">\</span><span class="nx">mathrm</span><span class="p">{</span><span class="nx">GC</span><span class="p">}</span><span class="nx">_</span><span class="p">{</span><span class="err">\</span><span class="nx">mathrm</span><span class="p">{</span><span class="nx">P</span><span class="p">}},</span><span class="w"> </span><span class="err">\</span><span class="nx">mathrm</span><span class="p">{</span><span class="nx">S</span><span class="p">})</span><span class="w"> </span><span class="p">;</span><span class="w"> </span><span class="p">;</span><span class="err">\</span><span class="p">)</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="nx">unassimilated</span><span class="p">,</span>
<span class="w">            </span><span class="p">;</span><span class="w"> </span><span class="p">;</span><span class="w"> </span><span class="err">\</span><span class="p">(</span><span class="err">\</span><span class="nx">mathrm</span><span class="p">{</span><span class="nx">G</span><span class="p">}</span><span class="nx">_</span><span class="p">{</span><span class="err">\</span><span class="nx">mathrm</span><span class="p">{</span><span class="nx">P</span><span class="p">}}=</span><span class="err">\</span><span class="nx">mathrm</span><span class="p">{</span><span class="nx">P</span><span class="p">}</span><span class="w"> </span><span class="err">\</span><span class="o">&amp;</span><span class="w"> </span><span class="err">\</span><span class="nx">mathrm</span><span class="p">{</span><span class="nx">M</span><span class="p">}</span><span class="nx">_</span><span class="p">{</span><span class="err">\</span><span class="nx">mathrm</span><span class="p">{</span><span class="nx">GP</span><span class="p">}}=</span><span class="err">\</span><span class="nx">mathrm</span><span class="p">{</span><span class="nx">null</span><span class="p">}</span><span class="err">\</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="nx">each</span><span class="w"> </span><span class="err">\</span><span class="p">(</span><span class="err">\</span><span class="nx">left</span><span class="err">\</span><span class="p">{</span><span class="err">\</span><span class="nx">mathrm</span><span class="p">{</span><span class="nx">N</span><span class="p">},</span><span class="w"> </span><span class="err">\</span><span class="nx">mathrm</span><span class="p">{</span><span class="nx">M</span><span class="p">}</span><span class="nx">_</span><span class="p">{</span><span class="err">\</span><span class="nx">mathrm</span><span class="p">{</span><span class="nx">NP</span><span class="p">}}</span><span class="err">\</span><span class="nx">right</span><span class="err">\</span><span class="p">}</span><span class="err">\</span><span class="p">)</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="nx">MacFacRetrieve</span><span class="p">(</span><span class="nx">P</span><span class="p">,</span><span class="nx">CL</span><span class="p">)</span>
<span class="w">        </span><span class="err">\</span><span class="p">(</span><span class="err">\</span><span class="nx">mathrm</span><span class="p">{</span><span class="nx">L</span><span class="p">}</span><span class="nx">_</span><span class="p">{</span><span class="err">\</span><span class="nx">mathrm</span><span class="p">{</span><span class="nx">N</span><span class="p">}}=</span><span class="err">\</span><span class="nx">operatorname</span><span class="p">{</span><span class="nx">Example</span><span class="p">}</span><span class="w"> </span><span class="err">\</span><span class="nx">rightarrow</span><span class="w"> </span><span class="err">\</span><span class="nx">operatorname</span><span class="p">{</span><span class="nx">Label</span><span class="p">}(</span><span class="err">\</span><span class="nx">mathrm</span><span class="p">{</span><span class="nx">N</span><span class="p">})</span><span class="err">\</span><span class="p">)</span>
<span class="w">        </span><span class="err">\</span><span class="p">(</span><span class="err">\</span><span class="nx">left</span><span class="err">\</span><span class="p">{</span><span class="err">\</span><span class="nx">mathrm</span><span class="p">{</span><span class="nx">G</span><span class="p">}</span><span class="nx">_</span><span class="p">{</span><span class="err">\</span><span class="nx">mathrm</span><span class="p">{</span><span class="nx">N</span><span class="p">}},</span><span class="w"> </span><span class="err">\</span><span class="nx">mathrm</span><span class="p">{</span><span class="nx">M</span><span class="p">}</span><span class="nx">_</span><span class="p">{</span><span class="err">\</span><span class="nx">mathrm</span><span class="p">{</span><span class="nx">GN</span><span class="p">}}</span><span class="err">\</span><span class="nx">right</span><span class="err">\</span><span class="p">}=</span><span class="err">\</span><span class="nx">operatorname</span><span class="p">{</span><span class="nx">Example</span><span class="p">}</span><span class="w"> </span><span class="err">\</span><span class="nx">rightarrow</span><span class="err">\</span><span class="p">)</span><span class="w"> </span><span class="nx">Generalization</span><span class="w"> </span><span class="p">(</span><span class="nx">N</span><span class="p">)</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="err">\</span><span class="p">(</span><span class="err">\</span><span class="nx">mathrm</span><span class="p">{</span><span class="nx">Lp</span><span class="p">}</span><span class="w"> </span><span class="err">\</span><span class="nx">neq</span><span class="w"> </span><span class="err">\</span><span class="nx">mathrm</span><span class="p">{</span><span class="nx">L</span><span class="p">}</span><span class="nx">_</span><span class="p">{</span><span class="err">\</span><span class="nx">mathrm</span><span class="p">{</span><span class="nx">N</span><span class="p">}}</span><span class="err">\</span><span class="p">)</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="err">\</span><span class="p">(</span><span class="err">\</span><span class="nx">operatorname</span><span class="p">{</span><span class="nx">NormScore</span><span class="p">}</span><span class="err">\</span><span class="nx">left</span><span class="p">(</span><span class="err">\</span><span class="nx">mathrm</span><span class="p">{</span><span class="nx">M</span><span class="p">}</span><span class="nx">_</span><span class="p">{</span><span class="err">\</span><span class="nx">mathrm</span><span class="p">{</span><span class="nx">NP</span><span class="p">}}</span><span class="err">\</span><span class="nx">right</span><span class="p">)&gt;</span><span class="err">\</span><span class="nx">mathrm</span><span class="p">{</span><span class="nx">S</span><span class="p">}</span><span class="w"> </span><span class="p">;</span><span class="w"> </span><span class="p">;</span><span class="err">\</span><span class="p">)</span><span class="w"> </span><span class="nx">a</span><span class="w"> </span><span class="nx">near</span><span class="o">-</span><span class="nx">miss</span>
<span class="w">            </span><span class="nx">GenerateNewCriteria</span><span class="p">(</span><span class="w"> </span><span class="err">\</span><span class="p">(</span><span class="err">\</span><span class="nx">mathrm</span><span class="p">{</span><span class="nx">L</span><span class="p">}</span><span class="nx">_</span><span class="p">{</span><span class="err">\</span><span class="nx">mathrm</span><span class="p">{</span><span class="nx">P</span><span class="p">}},</span><span class="w"> </span><span class="err">\</span><span class="nx">mathrm</span><span class="p">{</span><span class="nx">G</span><span class="p">}</span><span class="nx">_</span><span class="p">{</span><span class="err">\</span><span class="nx">mathrm</span><span class="p">{</span><span class="nx">P</span><span class="p">}},</span><span class="w"> </span><span class="err">\</span><span class="nx">mathrm</span><span class="p">{</span><span class="nx">P</span><span class="p">},</span><span class="w"> </span><span class="err">\</span><span class="nx">mathrm</span><span class="p">{</span><span class="nx">N</span><span class="p">},</span><span class="w"> </span><span class="err">\</span><span class="nx">mathrm</span><span class="p">{</span><span class="nx">M</span><span class="p">}</span><span class="nx">_</span><span class="p">{</span><span class="err">\</span><span class="nx">mathrm</span><span class="p">{</span><span class="nx">NP</span><span class="p">}},</span><span class="w"> </span><span class="err">\</span><span class="nx">mathrm</span><span class="p">{</span><span class="nx">M</span><span class="p">}</span><span class="nx">_</span><span class="p">{</span><span class="err">\</span><span class="nx">mathrm</span><span class="p">{</span><span class="nx">PG</span><span class="p">}}</span><span class="err">\</span><span class="p">)</span>
<span class="w">            </span><span class="nx">GenerateNewCriteria</span><span class="p">(</span><span class="w"> </span><span class="err">\</span><span class="p">(</span><span class="err">\</span><span class="nx">mathrm</span><span class="p">{</span><span class="nx">L</span><span class="p">}</span><span class="nx">_</span><span class="p">{</span><span class="err">\</span><span class="nx">mathrm</span><span class="p">{</span><span class="nx">N</span><span class="p">}},</span><span class="w"> </span><span class="err">\</span><span class="nx">mathrm</span><span class="p">{</span><span class="nx">G</span><span class="p">}</span><span class="nx">_</span><span class="p">{</span><span class="err">\</span><span class="nx">mathrm</span><span class="p">{</span><span class="nx">N</span><span class="p">}},</span><span class="w"> </span><span class="err">\</span><span class="nx">mathrm</span><span class="p">{</span><span class="nx">N</span><span class="p">},</span><span class="w"> </span><span class="err">\</span><span class="nx">mathrm</span><span class="p">{</span><span class="nx">P</span><span class="p">},</span><span class="w"> </span><span class="err">\</span><span class="nx">mathrm</span><span class="p">{</span><span class="nx">M</span><span class="p">}</span><span class="nx">_</span><span class="p">{</span><span class="err">\</span><span class="nx">mathrm</span><span class="p">{</span><span class="nx">PN</span><span class="p">}},</span><span class="w"> </span><span class="err">\</span><span class="nx">mathrm</span><span class="p">{</span><span class="nx">M</span><span class="p">}</span><span class="nx">_</span><span class="p">{</span><span class="err">\</span><span class="nx">mathrm</span><span class="p">{</span><span class="nx">NG</span><span class="p">}}</span><span class="err">\</span><span class="p">)</span>
<span class="w">    </span><span class="err">\</span><span class="p">(</span><span class="err">\</span><span class="nx">mathrm</span><span class="p">{</span><span class="nx">CL</span><span class="p">}=</span><span class="err">\</span><span class="nx">mathrm</span><span class="p">{</span><span class="nx">CL</span><span class="p">}</span><span class="o">+</span><span class="err">\</span><span class="nx">mathrm</span><span class="p">{</span><span class="nx">P</span><span class="p">}</span><span class="err">\</span><span class="p">)</span>
</code></pre></div>

<p>GenerateNewCriteria(label L, gen G, pos $\mathbf{P}$, neg $\mathbf{N}$, mapping $\mathbf{M}<em _PG="{PG" _text="\text">{\text {NP }}$, mapping $\mathbf{M}</em>$ )
if $L$ and not BlockedByCriteria( $\left.\mathrm{N}, \mathrm{G}, \mathrm{M}}<em _mathrm_PN="\mathrm{PN">{\mathrm{GP}}, \mathrm{M}</em>}}\right)$ $\mathrm{H<em _mathrm_NP="\mathrm{NP">{\mathrm{PL}}=$ ExtractCriteria( $\left.\mathrm{P}, \mathrm{L}, \mathrm{M}</em>\right)$
AddCriteria( G , GeneralizeCriteria $\left.\left(\mathrm{H}}<em _mathrm_PG="\mathrm{PG">{\mathrm{PL}}, \mathrm{M}</em>\right)\right)$
TestOn(unlabeled example U)
$\mathbf{D}={ } ; ;$ discarded remindings
for 1 to 3
$\mathrm{R}=$ MacFacRetrieve $(\mathrm{U},(\mathrm{CL}-\mathrm{D}))$
for each $\left{\mathrm{E}, \mathrm{M}}<em _mathrm_E="\mathrm{E">{\mathrm{EU}}\right}$ in SortByGenSimilarity $(\mathrm{R}, \mathrm{U})$
$\mathrm{L}</em>=$ Example $\rightarrow$ Label(E)
$\left{\mathrm{G}}<em _mathrm_GE="\mathrm{GE">{\mathrm{E}}, \mathrm{M}</em>\right}=$ Example $\rightarrow$ Generalization(E)
if BlockedByCriteria( $\left.\mathrm{U}, \mathrm{G}}<em _mathrm_GE="\mathrm{GE">{\mathrm{E}}, \mathrm{M}</em>}}, \mathrm{M<em _mathrm_E="\mathrm{E">{\mathrm{EU}}\right)$
$\mathrm{D}=\mathrm{D}+\mathrm{E}$
else return $\mathrm{L}</em>$
return Example $\rightarrow$ Label(LeastBlocked(D))
Figure 5: ALIGN's top-level training and testing procedures.}</p>
<p>specify criteria about extra entities that aren't represented in the positive case while remaining embedded in the case. For these NPCIs, ALIGN replaces each skolem with a variable, and constrains each variable so that it cannot bind to any entity from the positive example that entered into the near-miss mapping. Thus, a NPCI such as (touches j (AnalogySkolemFn x)) is translated to capture the hypothesis that there cannot be something extra that touches $j$, as follows (cannot is implicit because it is an exclusion hypothesis):</p>
<div class="codehilite"><pre><span></span><code>(and (different i ?skolem)
    (different j ?skolem)
    (different k ?skolem)
    (different l ?skolem)
    (touches j ?skolem))
</code></pre></div>

<p>ALIGN discards near-miss pairs that are explained away by existing hypotheses associated with the positive example.</p>
<p>In practice, hypotheses produced from a single comparison can be over-specific, and must be revised to be practically useful. We describe this process next.</p>
<h2>Revising Hypotheses with Analogical Generalization</h2>
<p>ALIGN maintains one SAGE generalization context for every (non-null) label encountered, and each training example is added to the generalization context corresponding to its label, if any. If SAGE assimilates the example into a generalization, its associated hypotheses are generalized to refer to the entities in the generalization. Generalized hypotheses are pruned if they include conditions not true of all examples assimilated into the generalization (i.e., expressions with $\mathrm{p}&lt;1.0$ for inclusion hypotheses, and $\mathrm{p}&gt;0$ for exclusion hypotheses). Figure 4 (bottom) demonstrates pruning an inclusion hypothesis.</p>
<p>ALIGN uses generalized hypotheses to block labels and explain away new near-misses. An extra analogical translation step is required to project these hypotheses from the generalization to an unlabeled or negative example, via the positive (assimilated) example. The degree to which a failed hypothesis blocks a label is weighted using the size of the generalization it is associated with, with the intuition being that hypotheses that persist after more generalization operations are more accurate, all else being equal.</p>
<p>Since SAGE can produce multiple clusters from the positive examples of a single concept, ALIGN can maintain alternative sets of hypotheses for a given concept, resulting in a disjunctive category structure. Structural similarity (via analogical retrieval) determines which disjunct(s) get tested against a given unlabeled example.</p>
<h2>Classification via Analogy</h2>
<p>To classify an unlabeled example, ALIGN retrieves similar labeled examples from memory. Those retrieved examples that have been assimilated during learning are exchanged
for their associated generalizations. Starting with the most similar case, ALIGN tests each of the case's associated hypotheses by:</p>
<ol>
<li>Translating the hypothesis to refer to entities in the unlabeled example, using the entity correspondences of the best mapping.</li>
<li>Testing whether the translated condition holds. If an exclusion hypothesis holds or an inclusion hypothesis fails to hold (skolems count as failures), do not infer that label.
If these hypotheses are consistent with the new example, ALIGN classifies the new example with the retrieved label. Otherwise, ALIGN iterates to the next retrieved example. This is important for distinguishing similar categories.</li>
</ol>
<p>Because we assume that the set of concepts is collectively exhaustive, ALIGN conducts repeated retrievals during classification until it finds an unblocked label. If no unblocked label is found after 3 retrievals, then the label of the most highly supported retrieval is chosen. Support is determined by subtracting the cumulative weight of the inconsistent hypotheses from that of the consistent hypotheses. Since null-labeled retrievals cannot have associated hypotheses, they have neutral (0) support.</p>
<h2>Evaluation</h2>
<p>To evaluate the extension of analogical generalization with near-misses, we ran two classification tasks under different conditions: (1) ALIGN is the full system described above; (2) Prototypes is ALIGN without near-miss analysis; and (3) Examples is ALIGN without near-misses and also without analogical generalization, so classification is reduced to similarity-based retrieval over the library of training examples. For moderately high similarity thresholds (0.6-0.9), we expected Prototypes to outperform Examples and ALIGN to outperform both.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Arches: 8</th>
<th style="text-align: center;">Bridges: 4</th>
<th style="text-align: center;">False arches: 8</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Skeletal arms: 4</td>
<td style="text-align: center;">Triangles: 4</td>
<td style="text-align: center;">False triangles: 4</td>
</tr>
<tr>
<td style="text-align: left;">Skeletal legs: 4</td>
<td style="text-align: center;">Quadrilaterals: 4</td>
<td style="text-align: center;">False quads: 4</td>
</tr>
</tbody>
</table>
<p>Table 1: A dataset of sketched concepts. "False" categories were negative examples of all categories.</p>
<h2>Experiment 1</h2>
<p>ALIGN was compared with the Prototypes and Examples conditions in a classification task involving objects sketched in CogSketch. There were 44 sketches distributed over 6 mutually exclusive labels, where 16 of the sketches had null labels (i.e., no positive labels) but were potential near-misses for some of the concepts (e.g., false arches are nearly arches) as summarized in Table 1. The cases produced by CogSketch each contained, on average, 4.5</p>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Figure 6: Classification performance of ALIGN compared to Examples and Prototypes.
unique entities and 31 facts. The task was to choose one or none of the 6 labels, with chance at $21 \%$ accuracy. Performance was evaluated via 4 -fold cross-validation. Statistical significance was measured using a one-tailed, paired t-test. The similarity threshold for ALIGN was set to 0.8 . This was also the assimilation threshold used for the Prototypes condition.</p>
<h2>Results</h2>
<p>Figure 6 shows the results of Experiment 1. The Prototypes and Examples approaches performed identically at $55 \%$ accuracy, well above chance ( $\mathrm{p}&lt;0.01$ ). ALIGN demonstrated a $7 \%$ improvement over these conditions ( p $&lt;0.01$ ).</p>
<h2>Experiment 2</h2>
<p>This experiment evaluated classification performance in a task involving geospatial concepts. Examples were circled on a Freeciv map using CogSketch as described above. The dataset consisted of 60 examples evenly distributed over 6 mutually exclusive and collectively exhaustive categories: Isthmus, Peninsula, Strait, Bay, Archipelago and Island. The cases produced by CogSketch each contained, on average, 8 unique entities and 60 facts. 10 -fold cross-
<img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Figure 7: Classification accuracy on a geospatial dataset.
validation was used. ALIGN was compared to the Prototypes approach over a range of similarity thresholds. At a threshold of 1 , both reduce to Examples.</p>
<h2>Results</h2>
<p>As shown in Figure 7, ALIGN achieved a peak accuracy of $77 \%$, significantly outperforming the Prototypes peak performance of $62 \%(\mathrm{p}&lt;0.05)$. The Prototypes condition where similarity threshold $(\mathrm{S})$ is 1 is by definition the Examples condition, since $\mathrm{S}=1$ effectively prevents generalization and near-miss analysis. Here, Examples performed significantly worse than ALIGN with an accuracy of $53 \%(\mathrm{p}&lt;0.05)$, which was not significantly different from the peak of Prototypes.</p>
<h2>Discussion</h2>
<p>This data demonstrates that extending analogical generalization with near-misses can improve classification for spatial concepts represented as structured, qualitative descriptions. The interaction between the similarity threshold and the marginal benefit of near-misses suggests that there is a "sweet spot" for comparison; when the threshold is too low, more distant near-miss comparisons are generated, resulting in more hypotheses, most of which are incidental differences and should be pruned. When the similarity threshold is too high, the generalizations in SAGE end up smaller in size and more numerous, providing less basis for pruning bad hypotheses.</p>
<p>Using analogical generalization alone (Prototypes) did not significantly improve performance over simple retrieval (Examples) as we expected. The identical performance in Experiment 1 is likely related to the size of the categories; out of a group of four bridges, at least three must be sufficiently similar for two to generalize in the training set and a third to match with the resulting prototype during classification. Also recall that Experiment 1 contains examples without any positive label, which are not given a chance to generalize. Thus, their incidental similarities to other categories are not suppressed.</p>
<h2>Related Work</h2>
<p>ALIGN is capable of learning with relatively few examples. It requires orders of magnitude fewer examples than existing connectionist models (e.g., Elman 1998; Krizhevsky, Sutskever, and Hinton 2012). We believe ALIGN makes more realistic demands.</p>
<p>The IDeAL system (Bhatta and Goel 1997) learned by analogy over structured representations similar to those used by ALIGN, but it was applied to a design problemsolving task instead of recognition. Its retrieval mechanism indexed previous designs by their function, whereas retrieval in ALIGN uses domain-general similarity-based</p>
<p>retrieval. IDeAL learned generic teleological mechanisms by comparing a correct solution provided by a teacher to designs retrieved from memory - similar to near-miss discovery in ALIGN - but it relied on design-specific background knowledge to abstract the appropriate aspects from the design pair. Hypothesis production in ALIGN is domain-general, so instead it relies on finding similar positive examples to properly refine its hypotheses.</p>
<p>Cleuziou, Martin and Vrain (2003) described an inductive logic programming (ILP) approach to learning disjunctive concepts that bore similarities to ALIGN. Positive examples were clustered into subconcepts according to a similarity measure, and a separate conjunctive definition was learned for each subconcept based on the negative examples. Its representations, similarity metric, and hypothesis generation were all based in first order logic; the rules learned contained logical variables and were tested deductively, in contrast with the hypotheses here, which are embedded in learned models and tested via analogical projection. Winston $(1982,1986)$ also explored learning rules from analogies, producing logical rules via generalizing on one example. His if-then rules and censors were functionally similar to our inclusion and exclusion hypotheses, respectively.</p>
<p>Another analogous approach is K-Means+ID3 (Gaddam, Phoha, and Balagani 2007), which cascaded k-means clustering and ID3 decision trees for anomaly detection. While their approach used feature-vector data, it shared the idea that rule-based class boundaries can apply better when trained locally in some similarity space.</p>
<h2>Conclusions and Future Work</h2>
<p>This paper describes ALIGN, a concept learning model that extends analogical generalization with near-misses. It is capable of automatically finding its own near-miss examples, and we have shown evidence from two experiments that near-misses significantly improve performance over analogical generalization and retrieval alone. We plan on experimenting with ALIGN in other domains, as well as expanding the range of concepts in sketched domains.</p>
<h2>Acknowledgements</h2>
<p>This material is based upon work supported by the Air Force Office of Scientific Research under Award No. FA2386-10-1-4128.</p>
<h2>References</h2>
<p>Bhatta, S., \&amp; Goel, A., 1997. Learning generic mechanisms for innovative strategies in adaptive design. The Journal of the Learning Sciences 6(4), 367-396.</p>
<p>Cleuziou, G., Martin, L., \&amp; Vrain, C., 2003. Disjunctive learning with a soft-clustering method. In ILP'03: 13th International Conference on Inductive Logic Programming, 75-92.
Elman, J., 1998. Generalization, simple recurrent networks, and the emergence of structure. In Proceedings of the Twentieth Annual Conference of the Cognitive Science Society. Mahwah, NJ: Lawrence Erlbaum Associates.
Falkenhainer, B., Forbus, K., \&amp; Gentner, D., 1989. The structuremapping engine: Algorithm and examples. Artificial Intelligence 41(1), 1-63.
Forbus, K., Gentner, D., and Law, K., 1995. MAC/FAC: A model of similarity-based retrieval. Cognitive Science 19, 141-205.
Forbus, K. D., Usher, J., Lovett, A., Lockwood, K. and Wetzel, J., 2011. Cogsketch: Sketch understanding for cognitive science research and for education. Topics in Cognitive Science 3.
Gaddam, S., Phoha, V., \&amp; Balagani, K., 2007. K-Means+ID3: A novel method for supervised anomaly detection by cascading kmeans clustering and ID3 decision tree learning methods. IEEE Transactions on Knowledge and Data Engineering 19(3).
Gentner, D., \&amp; Namy, L., 1999. Comparison in the development of categories. Cognitive Development 14, 487-513.
Gentner, D., 1983. Structure-mapping: A theoretical framework for analogy. Cognitive Science 7(2), 155-170.
Krizhevsky, A., Sutskever, I., and Hinton, G. E., 2012. Imagenet classification with deep convolutional neural networks. Advances in Neural Information Processing Systems, 1097-1105.
Kuehne, S., Forbus, K., Gentner, D. and Quinn, B., 2000. SEQL: Category learning as progressive abstraction using structure mapping. Proceedings of CogSci. 2000.
Lovett, A., Forbus, K., and Usher, J., 2010. A structure-mapping model of Raven's Progressive Matrices. Proc. of CogSci 2010.
Lovett, A., \&amp; Forbus, K., 2011. Cultural commonalities and differences in spatial problem solving: A computational analysis. Cognition 121, 281-287.
Markman, A. B., \&amp; Gentner, D., 1996. Commonalities and differences in similarity comparisons. Memory \&amp; Cognition 24(2), 235-249.
Muggleton, S., \&amp; De Raedt, L., 1994. Inductive logic programming: Theory and methods. Journal of Logic Programming 19-20, 629-679.
Sagi, E., Gentner, D., \&amp; Lovett, A., 2012. What difference reveals about similarity. Cognitive Science 36, 1019-1050.
Siddiqi, K., Shokoufandeh, A., Dickinson, S. J., and Zucker, S. W., 1999. Shock graphs and shape matching. International Journal of Computer Vision 30, 1-24.
Smith, L., \&amp; Gentner, D., 2014. The role of difference-detection in learning contrastive categories. Proceedings of CogSci. 2014.
Winston, P. H., 1970. Learning structural descriptions from examples. Ph.D. diss., MIT, Cambridge, MA.
Winston, P. H., 1982. Learning new principles from precedents and exercises. Artificial Intelligence 23(12).
Winston, P. H., 1986. Learning by augmenting rules and accumulating censors. In Machine Learning: An Artificial Intelligence Approach 2, 45-62. Morgan-Kaufman.
Yin, P., Forbus, K., Usher, J., Sageman, B. and Jee, B., 2010. Sketch Worksheets: A Sketch-based Educational Software System. Proceedings of the 22nd Annual Conference on Innovative Applications of Artificial Intelligence.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{2}$ In this paper, categories are mutually exclusive, and some training and testing examples have a null label (i.e., they are confusers).&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>