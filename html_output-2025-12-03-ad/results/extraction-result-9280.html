<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-9280 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-9280</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-9280</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-162.html">extraction-schema-162</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <p><strong>Paper ID:</strong> paper-273993243</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2411.08561v5.pdf" target="_blank">LogLLM: Log-based Anomaly Detection Using Large Language Models</a></p>
                <p><strong>Paper Abstract:</strong> Software systems often record important runtime information in logs to help with troubleshooting. Log-based anomaly detection has become a key research area that aims to identify system issues through log data, ultimately enhancing the reliability of software systems. Traditional deep learning methods often struggle to capture the semantic information embedded in log data, which is typically organized in natural language. In this paper, we propose LogLLM, a log-based anomaly detection framework that leverages large language models (LLMs). LogLLM employs BERT for extracting semantic vectors from log messages, while utilizing Llama, a transformer decoder-based model, for classifying log sequences. Additionally, we introduce a projector to align the vector representation spaces of BERT and Llama, ensuring a cohesive understanding of log semantics. Unlike conventional methods that require log parsers to extract templates, LogLLM preprocesses log messages with regular expressions, streamlining the entire process. Our framework is trained through a novel three-stage procedure designed to enhance performance and adaptability. Experimental results across four public datasets demonstrate that LogLLM outperforms state-of-the-art methods. Even when handling unstable logs, it effectively captures the semantic meaning of log messages and detects anomalies accurately.</p>
                <p><strong>Cost:</strong> 0.017</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e9280.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e9280.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LogLLM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LogLLM: Log-based Anomaly Detection Using Large Language Models</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A supervised log-anomaly detection framework that uses BERT to embed each log message, a linear projector to map BERT embeddings into LLaMA's token embedding space, and Llama (decoder LLM) to classify whole log sequences via a prompt-style query; trained with a three-stage fine-tuning procedure and regex-based preprocessing replacing variable parameters with '<*>'.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>BERT (bert-base) + Llama (Llama-3-8B primary; Llama-3.2-1B ablations)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Transformer encoder (BERT) + Transformer decoder (Llama)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>BERT-base; Llama-3-8B (primary), Llama-3.2-1B (ablation)</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Textual ordered log-message sequences (grouped by session windows or sliding windows)</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>System logs (HDFS, BlueGene/L (BGL), Liberty, Thunderbird supercomputer/Hadoop logs)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Anomalous log sequences/events (errors/failures) indicated by at least one anomalous log message in a sequence</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Fine-tuning-based approach: (1) preprocess log messages by replacing variable parameters with '<*>' via regex; (2) use BERT to produce per-message embeddings (one embedding per message), map these embeddings through a learned linear projector into Llama's token embedding space; (3) construct a prompt consisting of an intro, the projected embeddings as the message block, and a question token; (4) fine-tune Llama to answer 'The sequence is normal.' or 'The sequence is anomalous.' using a three-stage training schedule (stage1: fine-tune Llama on answer template; stage2: train BERT+projector to align embeddings; stage3: fine-tune entire model). Uses QLoRA for memory-efficient fine-tuning and minority-class oversampling to address imbalance.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>DeepLog, LogAnomaly, PLELog, Fast-LogAD, LogBERT, LogRobust, CNN, NeuralLog, RAPID (as used in comparisons in this paper)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Precision, Recall, F1-score (per dataset and averaged)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Per Table II: HDFS P=0.994 R=1.000 F1=0.997; BGL P=0.861 R=0.979 F1=0.916; Liberty P=0.992 R=0.926 F1=0.958; Thunderbird P=0.966 R=0.966 F1=0.966; Average F1 = 0.959. Computational cost (Table III): Training time ≈ 1065.15 minutes, Testing time ≈ 64.48 minutes (reported averaged over datasets).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Outperforms all compared methods in average F1 (6.6% absolute improvement over best baseline NeuralLog). Achieves better balance between precision and recall versus methods that are overly sensitive (FastLogAD) or insensitive (RAPID). Higher computational cost and GPU memory compared to smaller baseline models.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>High computation and memory cost due to LLMs; direct tokenization of entire concatenated sequences into Llama causes out-of-memory (OOM) issues — mitigated by per-message embedding via BERT + projector; requires labeled anomalies (supervised) and is sensitive to extreme class imbalance (very low anomaly ratios may bias to always-normal predictions); needs careful oversampling but paper finds β in [30%,50%] acceptable; relies on regex-based preprocessing (works well in experiments but may require adapting regexes for new log formats).</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Combining a transformer encoder (BERT) for per-message semantic summarization with a transformer-decoder (Llama) classifier via a learned projector aligns semantic spaces and reduces tokenization/OOM problems while preserving sequence-level reasoning; a three-stage training (capture answer template → train embedder → fine-tune end-to-end) significantly improves performance; simple regex-based parameter masking ('<*>') outperforms log-parsers and template ID inputs for semantic LLM-based detection.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'LogLLM: Log-based Anomaly Detection Using Large Language Models', 'publication_date_yy_mm': '2024-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9280.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e9280.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>NeuralLog</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A supervised log-anomaly baseline that uses BERT to extract semantic vectors from raw log messages and then applies a transformer-based classification model (smaller model than decoder LLMs) to detect anomalous sequences.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>BERT (pretrained encoder used for embeddings) + transformer classifier (smaller)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Transformer encoder (BERT) for embeddings; transformer classifier for sequence labeling</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>Not specified in this paper (described as smaller models compared to large decoder LLMs)</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Textual log-message sequences</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>System logs (used as a baseline on same datasets: HDFS, BGL, Liberty, Thunderbird)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Anomalous log sequences/events</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Fine-tuning-based: BERT encodes raw log messages to semantic vectors; those embeddings are used by a (smaller) transformer-based classifier to classify sequences as normal/anomalous.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Compared directly against in this paper (used as a state-of-the-art baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Precision, Recall, F1-score</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Per Table II: HDFS P=0.971 R=0.988 F1=0.979; BGL P=0.792 R=0.884 F1=0.835; Liberty P=0.875 R=0.926 F1=0.900; Thunderbird P=0.794 R=0.931 F1=0.857; Average F1 = 0.893.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Strong baseline performance but LogLLM reports higher average F1 (0.959) than NeuralLog (0.893).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Uses smaller models (so may be less capable at capturing long-range or richer semantic patterns compared to larger decoder LLMs) and thus achieves lower F1 than LogLLM in these experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Demonstrates benefit of encoder-based semantic embeddings for log sequences but suggests value in scaling model capacity or aligning encoder embeddings with decoder LLMs for further gains (as LogLLM does).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'LogLLM: Log-based Anomaly Detection Using Large Language Models', 'publication_date_yy_mm': '2024-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9280.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e9280.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RAPID</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A retrieval-based anomaly detection method that uses pre-trained language models to embed log sequences and performs detection via nearest-neighbor/document retrieval instead of training a deep classifier.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Training-free retrieval-based log anomaly detection with pre-trained language model considering tokenlevel information.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Pretrained language model used for embedding (unspecified here), retrieval-based (no classifier fine-tuning)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Transformer encoder for embeddings + retrieval/indexing</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>Not specified in this paper</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Textual log-message sequences</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>System logs (same datasets)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Anomalous log sequences/events</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Training-free retrieval-based approach: embed log sequences (using pretrained LM) and determine anomaly by similarity to stored examples of normal sequences (nearest document comparison) rather than supervised classifier training.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Compared in this paper as a non-trained retrieval baseline</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Precision, Recall, F1-score</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Per Table II: HDFS P=1.000 R=0.859 F1=0.924; BGL P=0.874 R=0.399 F1=0.548; Liberty P=0.911 R=0.611 F1=0.732; Thunderbird P=0.200 R=0.207 F1=0.203; Average F1 = 0.602.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>RAPID achieves high precision but low recall on some datasets (e.g., BGL), indicating it is conservative and misses many anomalies; overall lower average F1 than supervised methods like NeuralLog and LogLLM.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Not sensitive enough in some datasets (low recall); performance depends on available normal examples and effectiveness of embedding/retrieval; computational cost at test time can be high due to retrieval.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Demonstrates a trade-off: training-free retrieval can yield high-precision detection but often at the cost of recall; highlights value of supervised fine-tuning for recall-sensitive anomaly detection.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'LogLLM: Log-based Anomaly Detection Using Large Language Models', 'publication_date_yy_mm': '2024-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9280.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e9280.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LogBERT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LogBERT: Log anomaly detection via BERT</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A method that uses BERT (encoder) to reconstruct sequences of log template IDs and detect anomalies based on reconstruction error; it relies on log parsing to map messages to templates and does not exploit message natural-language semantics.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Logbert: Log anomaly detection via bert.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>BERT (encoder)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Transformer encoder</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>Not specified in this paper</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Sequences of log template IDs (numeric/template sequences)</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>System logs</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Anomalous sequences inferred by reconstruction errors</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Fine-tuning-based reconstruction: use BERT to reconstruct input template-ID sequences (from a log parser) and flag sequences with high reconstruction error as anomalies.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Used as a comparison baseline in experiments</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Precision, Recall, F1-score</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Per Table II: Average F1 = 0.456 (dataset breakdown in Table II).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Performs worse than semantic-aware methods (NeuralLog, LogLLM), indicating loss of detection power when template semantics are discarded.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Relies on log parsers to extract templates (parsers may fail/OOV issues); ignores natural-language semantics inside messages because it uses template IDs; less effective on unstable logs.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Shows that template-ID-only reconstruction approaches are less effective than approaches that preserve message semantics for LLM-based detection.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'LogLLM: Log-based Anomaly Detection Using Large Language Models', 'publication_date_yy_mm': '2024-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9280.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e9280.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>FastLogAD</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>FastLogAD</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A recent method that applies mask-guided pseudo-anomaly generation and discrimination for log anomaly detection (reported to adopt BERT in prior work), evaluated as a baseline in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Fastlogad: Log anomaly detection with mask-guided pseudo anomaly generation and discrimination.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>BERT (used in prior work as reported), discriminator-based model</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Transformer encoder-based components; adversarial/discriminator framework</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>Not specified in this paper</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Log template ID sequences or message-derived features depending on original method</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>System logs</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Anomalies generated/identified via pseudo-anomaly generation and discriminative training</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Uses mask-guided pseudo-anomaly generation to create anomalous samples and a discriminator to distinguish real normal vs generated anomalies; evaluated as a semi-supervised method in comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Compared in the experiments</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Precision, Recall, F1-score</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Per Table II: Average F1 = 0.341; on BGL recall=1.0 but precision low (0.167) indicating many false positives.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>High recall in some datasets but very low precision leads to poor F1 and impractical false alarm rates compared to LogLLM.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Tends to be overly sensitive (high false positive rate) as observed on BGL; may produce too many false alarms for real-world deployment.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Highlights risk of high recall-only approaches: generating pseudo anomalies can increase sensitivity but needs balancing to avoid unacceptable false positive rates.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'LogLLM: Log-based Anomaly Detection Using Large Language Models', 'publication_date_yy_mm': '2024-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9280.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e9280.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Prompt-engineering LLM methods</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Prompt-engineering / zero-/few-shot decoder-LLM methods for log anomaly detection (e.g., LogGPT / ChatGPT usage, RAGLog)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Methods that use large decoder-only LLMs (ChatGPT/GPT family, other decoder LLMs) via prompting (zero- or few-shot) or retrieval-augmented prompts to classify log entries/sequences without model fine-tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT / GPT-family decoders, other decoder LLMs (unnamed sizes)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Transformer decoder (large pre-trained LLMs)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>Various (GPT-4, Llama family, ChatGLM etc. cited in paper)</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Concatenated log messages or summarized history (text strings), sometimes with retrieval-augmented contexts</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>System logs</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Anomalous log messages/sequences</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Zero/few-shot prompting: construct prompt templates that include the log sequence (or summary/retrieval-augmented context) and ask the LLM to judge normal vs anomalous; RAG variants retrieve similar normal entries and include them in prompts.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Mentioned in related work and compared conceptually; examples include LogGPT (Qi et al.), Egersdoerfer's ChatGPT experiments, RAGLog.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Varies by work; in this paper they are discussed qualitatively (precision/recall tradeoffs not given here for prompt-only methods).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>This paper does not report numeric performance for prompt-only methods; discusses that prompt methods can be impractical with large window sizes and often yield suboptimal dataset-specific performance.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Prompt-based approaches are easier to deploy zero-shot but typically underperform fine-tuned, dataset-specific methods on detection accuracy according to the paper's discussion.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Token-length limits and memory: concatenating large windows of log messages into a single prompt is impractical and can cause memory/latency issues; prompt methods are hard to customize to dataset-specific anomalies; may require summarization/memory which complicates pipeline; retrieval-augmentation mitigates but adds complexity.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Prompt-engineering approaches demonstrate useful zero-shot capabilities but struggle with scale (long sequences) and dataset-specific adaptation; motivates hybrid approaches or fine-tuning for production-grade detection.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'LogLLM: Log-based Anomaly Detection Using Large Language Models', 'publication_date_yy_mm': '2024-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9280.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e9280.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Hadadi et al. (GPTs on unstable logs)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Anomaly detection on unstable logs with GPT models</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A referenced study that fine-tunes GPT models on template sequences parsed from logs and highlights issues with ambiguous template boundaries and tokenization causing token-count blowup leading to LLM token/memory limits.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Anomaly detection on unstable logs with gpt models.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-family decoder models (fine-tuned on template sequences)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Transformer decoder</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>Not specified in this paper</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Sequences of log templates (tokenized into LLM tokens)</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>System logs (unstable logs subject to software evolution)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Anomalous sequences identified by sequence-label prediction</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Fine-tune GPT (decoder LLM) on sequences of parsed log templates to predict sequence labels; direct tokenization of template sequences into the LLM input.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Discussed in related work and used to illustrate tokenization/sequence-length limitations</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Not reported here (discussion-focused in this paper)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Not numerically reported in this paper; cited as illustrative of OOM/token-limit problems.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Paper cites this work to motivate the use of per-message embedding (BERT) + projector + Llama instead of direct tokenization of long template sequences.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Two main issues: (1) unclear boundaries between templates when concatenated, making sequence dependency learning hard; (2) tokenization multiplies tokens per template and long sequences exceed LLM token/memory limits causing OOM.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Used by the authors to justify LogLLM's design: summarizing each log message with an encoder reduces token count and clarifies message boundaries, enabling decoder LLMs to reason about longer sequences without OOM.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'LogLLM: Log-based Anomaly Detection Using Large Language Models', 'publication_date_yy_mm': '2024-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Loggpt: Exploring chatgpt for log-based anomaly detection. <em>(Rating: 2)</em></li>
                <li>Raglog: Log anomaly detection using retrieval augmented generation. <em>(Rating: 2)</em></li>
                <li>Anomaly detection on unstable logs with gpt models. <em>(Rating: 2)</em></li>
                <li>Logbert: Log anomaly detection via bert. <em>(Rating: 2)</em></li>
                <li>Fastlogad: Log anomaly detection with mask-guided pseudo anomaly generation and discrimination. <em>(Rating: 1)</em></li>
                <li>Training-free retrieval-based log anomaly detection with pre-trained language model considering tokenlevel information. <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-9280",
    "paper_id": "paper-273993243",
    "extraction_schema_id": "extraction-schema-162",
    "extracted_data": [
        {
            "name_short": "LogLLM",
            "name_full": "LogLLM: Log-based Anomaly Detection Using Large Language Models",
            "brief_description": "A supervised log-anomaly detection framework that uses BERT to embed each log message, a linear projector to map BERT embeddings into LLaMA's token embedding space, and Llama (decoder LLM) to classify whole log sequences via a prompt-style query; trained with a three-stage fine-tuning procedure and regex-based preprocessing replacing variable parameters with '&lt;*&gt;'.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "BERT (bert-base) + Llama (Llama-3-8B primary; Llama-3.2-1B ablations)",
            "model_type": "Transformer encoder (BERT) + Transformer decoder (Llama)",
            "model_size": "BERT-base; Llama-3-8B (primary), Llama-3.2-1B (ablation)",
            "data_type": "Textual ordered log-message sequences (grouped by session windows or sliding windows)",
            "data_domain": "System logs (HDFS, BlueGene/L (BGL), Liberty, Thunderbird supercomputer/Hadoop logs)",
            "anomaly_type": "Anomalous log sequences/events (errors/failures) indicated by at least one anomalous log message in a sequence",
            "method_description": "Fine-tuning-based approach: (1) preprocess log messages by replacing variable parameters with '&lt;*&gt;' via regex; (2) use BERT to produce per-message embeddings (one embedding per message), map these embeddings through a learned linear projector into Llama's token embedding space; (3) construct a prompt consisting of an intro, the projected embeddings as the message block, and a question token; (4) fine-tune Llama to answer 'The sequence is normal.' or 'The sequence is anomalous.' using a three-stage training schedule (stage1: fine-tune Llama on answer template; stage2: train BERT+projector to align embeddings; stage3: fine-tune entire model). Uses QLoRA for memory-efficient fine-tuning and minority-class oversampling to address imbalance.",
            "baseline_methods": "DeepLog, LogAnomaly, PLELog, Fast-LogAD, LogBERT, LogRobust, CNN, NeuralLog, RAPID (as used in comparisons in this paper)",
            "performance_metrics": "Precision, Recall, F1-score (per dataset and averaged)",
            "performance_results": "Per Table II: HDFS P=0.994 R=1.000 F1=0.997; BGL P=0.861 R=0.979 F1=0.916; Liberty P=0.992 R=0.926 F1=0.958; Thunderbird P=0.966 R=0.966 F1=0.966; Average F1 = 0.959. Computational cost (Table III): Training time ≈ 1065.15 minutes, Testing time ≈ 64.48 minutes (reported averaged over datasets).",
            "comparison_to_baseline": "Outperforms all compared methods in average F1 (6.6% absolute improvement over best baseline NeuralLog). Achieves better balance between precision and recall versus methods that are overly sensitive (FastLogAD) or insensitive (RAPID). Higher computational cost and GPU memory compared to smaller baseline models.",
            "limitations_or_failure_cases": "High computation and memory cost due to LLMs; direct tokenization of entire concatenated sequences into Llama causes out-of-memory (OOM) issues — mitigated by per-message embedding via BERT + projector; requires labeled anomalies (supervised) and is sensitive to extreme class imbalance (very low anomaly ratios may bias to always-normal predictions); needs careful oversampling but paper finds β in [30%,50%] acceptable; relies on regex-based preprocessing (works well in experiments but may require adapting regexes for new log formats).",
            "unique_insights": "Combining a transformer encoder (BERT) for per-message semantic summarization with a transformer-decoder (Llama) classifier via a learned projector aligns semantic spaces and reduces tokenization/OOM problems while preserving sequence-level reasoning; a three-stage training (capture answer template → train embedder → fine-tune end-to-end) significantly improves performance; simple regex-based parameter masking ('&lt;*&gt;') outperforms log-parsers and template ID inputs for semantic LLM-based detection.",
            "uuid": "e9280.0",
            "source_info": {
                "paper_title": "LogLLM: Log-based Anomaly Detection Using Large Language Models",
                "publication_date_yy_mm": "2024-11"
            }
        },
        {
            "name_short": "NeuralLog",
            "name_full": "",
            "brief_description": "A supervised log-anomaly baseline that uses BERT to extract semantic vectors from raw log messages and then applies a transformer-based classification model (smaller model than decoder LLMs) to detect anomalous sequences.",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": "BERT (pretrained encoder used for embeddings) + transformer classifier (smaller)",
            "model_type": "Transformer encoder (BERT) for embeddings; transformer classifier for sequence labeling",
            "model_size": "Not specified in this paper (described as smaller models compared to large decoder LLMs)",
            "data_type": "Textual log-message sequences",
            "data_domain": "System logs (used as a baseline on same datasets: HDFS, BGL, Liberty, Thunderbird)",
            "anomaly_type": "Anomalous log sequences/events",
            "method_description": "Fine-tuning-based: BERT encodes raw log messages to semantic vectors; those embeddings are used by a (smaller) transformer-based classifier to classify sequences as normal/anomalous.",
            "baseline_methods": "Compared directly against in this paper (used as a state-of-the-art baseline)",
            "performance_metrics": "Precision, Recall, F1-score",
            "performance_results": "Per Table II: HDFS P=0.971 R=0.988 F1=0.979; BGL P=0.792 R=0.884 F1=0.835; Liberty P=0.875 R=0.926 F1=0.900; Thunderbird P=0.794 R=0.931 F1=0.857; Average F1 = 0.893.",
            "comparison_to_baseline": "Strong baseline performance but LogLLM reports higher average F1 (0.959) than NeuralLog (0.893).",
            "limitations_or_failure_cases": "Uses smaller models (so may be less capable at capturing long-range or richer semantic patterns compared to larger decoder LLMs) and thus achieves lower F1 than LogLLM in these experiments.",
            "unique_insights": "Demonstrates benefit of encoder-based semantic embeddings for log sequences but suggests value in scaling model capacity or aligning encoder embeddings with decoder LLMs for further gains (as LogLLM does).",
            "uuid": "e9280.1",
            "source_info": {
                "paper_title": "LogLLM: Log-based Anomaly Detection Using Large Language Models",
                "publication_date_yy_mm": "2024-11"
            }
        },
        {
            "name_short": "RAPID",
            "name_full": "",
            "brief_description": "A retrieval-based anomaly detection method that uses pre-trained language models to embed log sequences and performs detection via nearest-neighbor/document retrieval instead of training a deep classifier.",
            "citation_title": "Training-free retrieval-based log anomaly detection with pre-trained language model considering tokenlevel information.",
            "mention_or_use": "mention",
            "model_name": "Pretrained language model used for embedding (unspecified here), retrieval-based (no classifier fine-tuning)",
            "model_type": "Transformer encoder for embeddings + retrieval/indexing",
            "model_size": "Not specified in this paper",
            "data_type": "Textual log-message sequences",
            "data_domain": "System logs (same datasets)",
            "anomaly_type": "Anomalous log sequences/events",
            "method_description": "Training-free retrieval-based approach: embed log sequences (using pretrained LM) and determine anomaly by similarity to stored examples of normal sequences (nearest document comparison) rather than supervised classifier training.",
            "baseline_methods": "Compared in this paper as a non-trained retrieval baseline",
            "performance_metrics": "Precision, Recall, F1-score",
            "performance_results": "Per Table II: HDFS P=1.000 R=0.859 F1=0.924; BGL P=0.874 R=0.399 F1=0.548; Liberty P=0.911 R=0.611 F1=0.732; Thunderbird P=0.200 R=0.207 F1=0.203; Average F1 = 0.602.",
            "comparison_to_baseline": "RAPID achieves high precision but low recall on some datasets (e.g., BGL), indicating it is conservative and misses many anomalies; overall lower average F1 than supervised methods like NeuralLog and LogLLM.",
            "limitations_or_failure_cases": "Not sensitive enough in some datasets (low recall); performance depends on available normal examples and effectiveness of embedding/retrieval; computational cost at test time can be high due to retrieval.",
            "unique_insights": "Demonstrates a trade-off: training-free retrieval can yield high-precision detection but often at the cost of recall; highlights value of supervised fine-tuning for recall-sensitive anomaly detection.",
            "uuid": "e9280.2",
            "source_info": {
                "paper_title": "LogLLM: Log-based Anomaly Detection Using Large Language Models",
                "publication_date_yy_mm": "2024-11"
            }
        },
        {
            "name_short": "LogBERT",
            "name_full": "LogBERT: Log anomaly detection via BERT",
            "brief_description": "A method that uses BERT (encoder) to reconstruct sequences of log template IDs and detect anomalies based on reconstruction error; it relies on log parsing to map messages to templates and does not exploit message natural-language semantics.",
            "citation_title": "Logbert: Log anomaly detection via bert.",
            "mention_or_use": "mention",
            "model_name": "BERT (encoder)",
            "model_type": "Transformer encoder",
            "model_size": "Not specified in this paper",
            "data_type": "Sequences of log template IDs (numeric/template sequences)",
            "data_domain": "System logs",
            "anomaly_type": "Anomalous sequences inferred by reconstruction errors",
            "method_description": "Fine-tuning-based reconstruction: use BERT to reconstruct input template-ID sequences (from a log parser) and flag sequences with high reconstruction error as anomalies.",
            "baseline_methods": "Used as a comparison baseline in experiments",
            "performance_metrics": "Precision, Recall, F1-score",
            "performance_results": "Per Table II: Average F1 = 0.456 (dataset breakdown in Table II).",
            "comparison_to_baseline": "Performs worse than semantic-aware methods (NeuralLog, LogLLM), indicating loss of detection power when template semantics are discarded.",
            "limitations_or_failure_cases": "Relies on log parsers to extract templates (parsers may fail/OOV issues); ignores natural-language semantics inside messages because it uses template IDs; less effective on unstable logs.",
            "unique_insights": "Shows that template-ID-only reconstruction approaches are less effective than approaches that preserve message semantics for LLM-based detection.",
            "uuid": "e9280.3",
            "source_info": {
                "paper_title": "LogLLM: Log-based Anomaly Detection Using Large Language Models",
                "publication_date_yy_mm": "2024-11"
            }
        },
        {
            "name_short": "FastLogAD",
            "name_full": "FastLogAD",
            "brief_description": "A recent method that applies mask-guided pseudo-anomaly generation and discrimination for log anomaly detection (reported to adopt BERT in prior work), evaluated as a baseline in this paper.",
            "citation_title": "Fastlogad: Log anomaly detection with mask-guided pseudo anomaly generation and discrimination.",
            "mention_or_use": "mention",
            "model_name": "BERT (used in prior work as reported), discriminator-based model",
            "model_type": "Transformer encoder-based components; adversarial/discriminator framework",
            "model_size": "Not specified in this paper",
            "data_type": "Log template ID sequences or message-derived features depending on original method",
            "data_domain": "System logs",
            "anomaly_type": "Anomalies generated/identified via pseudo-anomaly generation and discriminative training",
            "method_description": "Uses mask-guided pseudo-anomaly generation to create anomalous samples and a discriminator to distinguish real normal vs generated anomalies; evaluated as a semi-supervised method in comparisons.",
            "baseline_methods": "Compared in the experiments",
            "performance_metrics": "Precision, Recall, F1-score",
            "performance_results": "Per Table II: Average F1 = 0.341; on BGL recall=1.0 but precision low (0.167) indicating many false positives.",
            "comparison_to_baseline": "High recall in some datasets but very low precision leads to poor F1 and impractical false alarm rates compared to LogLLM.",
            "limitations_or_failure_cases": "Tends to be overly sensitive (high false positive rate) as observed on BGL; may produce too many false alarms for real-world deployment.",
            "unique_insights": "Highlights risk of high recall-only approaches: generating pseudo anomalies can increase sensitivity but needs balancing to avoid unacceptable false positive rates.",
            "uuid": "e9280.4",
            "source_info": {
                "paper_title": "LogLLM: Log-based Anomaly Detection Using Large Language Models",
                "publication_date_yy_mm": "2024-11"
            }
        },
        {
            "name_short": "Prompt-engineering LLM methods",
            "name_full": "Prompt-engineering / zero-/few-shot decoder-LLM methods for log anomaly detection (e.g., LogGPT / ChatGPT usage, RAGLog)",
            "brief_description": "Methods that use large decoder-only LLMs (ChatGPT/GPT family, other decoder LLMs) via prompting (zero- or few-shot) or retrieval-augmented prompts to classify log entries/sequences without model fine-tuning.",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": "ChatGPT / GPT-family decoders, other decoder LLMs (unnamed sizes)",
            "model_type": "Transformer decoder (large pre-trained LLMs)",
            "model_size": "Various (GPT-4, Llama family, ChatGLM etc. cited in paper)",
            "data_type": "Concatenated log messages or summarized history (text strings), sometimes with retrieval-augmented contexts",
            "data_domain": "System logs",
            "anomaly_type": "Anomalous log messages/sequences",
            "method_description": "Zero/few-shot prompting: construct prompt templates that include the log sequence (or summary/retrieval-augmented context) and ask the LLM to judge normal vs anomalous; RAG variants retrieve similar normal entries and include them in prompts.",
            "baseline_methods": "Mentioned in related work and compared conceptually; examples include LogGPT (Qi et al.), Egersdoerfer's ChatGPT experiments, RAGLog.",
            "performance_metrics": "Varies by work; in this paper they are discussed qualitatively (precision/recall tradeoffs not given here for prompt-only methods).",
            "performance_results": "This paper does not report numeric performance for prompt-only methods; discusses that prompt methods can be impractical with large window sizes and often yield suboptimal dataset-specific performance.",
            "comparison_to_baseline": "Prompt-based approaches are easier to deploy zero-shot but typically underperform fine-tuned, dataset-specific methods on detection accuracy according to the paper's discussion.",
            "limitations_or_failure_cases": "Token-length limits and memory: concatenating large windows of log messages into a single prompt is impractical and can cause memory/latency issues; prompt methods are hard to customize to dataset-specific anomalies; may require summarization/memory which complicates pipeline; retrieval-augmentation mitigates but adds complexity.",
            "unique_insights": "Prompt-engineering approaches demonstrate useful zero-shot capabilities but struggle with scale (long sequences) and dataset-specific adaptation; motivates hybrid approaches or fine-tuning for production-grade detection.",
            "uuid": "e9280.5",
            "source_info": {
                "paper_title": "LogLLM: Log-based Anomaly Detection Using Large Language Models",
                "publication_date_yy_mm": "2024-11"
            }
        },
        {
            "name_short": "Hadadi et al. (GPTs on unstable logs)",
            "name_full": "Anomaly detection on unstable logs with GPT models",
            "brief_description": "A referenced study that fine-tunes GPT models on template sequences parsed from logs and highlights issues with ambiguous template boundaries and tokenization causing token-count blowup leading to LLM token/memory limits.",
            "citation_title": "Anomaly detection on unstable logs with gpt models.",
            "mention_or_use": "mention",
            "model_name": "GPT-family decoder models (fine-tuned on template sequences)",
            "model_type": "Transformer decoder",
            "model_size": "Not specified in this paper",
            "data_type": "Sequences of log templates (tokenized into LLM tokens)",
            "data_domain": "System logs (unstable logs subject to software evolution)",
            "anomaly_type": "Anomalous sequences identified by sequence-label prediction",
            "method_description": "Fine-tune GPT (decoder LLM) on sequences of parsed log templates to predict sequence labels; direct tokenization of template sequences into the LLM input.",
            "baseline_methods": "Discussed in related work and used to illustrate tokenization/sequence-length limitations",
            "performance_metrics": "Not reported here (discussion-focused in this paper)",
            "performance_results": "Not numerically reported in this paper; cited as illustrative of OOM/token-limit problems.",
            "comparison_to_baseline": "Paper cites this work to motivate the use of per-message embedding (BERT) + projector + Llama instead of direct tokenization of long template sequences.",
            "limitations_or_failure_cases": "Two main issues: (1) unclear boundaries between templates when concatenated, making sequence dependency learning hard; (2) tokenization multiplies tokens per template and long sequences exceed LLM token/memory limits causing OOM.",
            "unique_insights": "Used by the authors to justify LogLLM's design: summarizing each log message with an encoder reduces token count and clarifies message boundaries, enabling decoder LLMs to reason about longer sequences without OOM.",
            "uuid": "e9280.6",
            "source_info": {
                "paper_title": "LogLLM: Log-based Anomaly Detection Using Large Language Models",
                "publication_date_yy_mm": "2024-11"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Loggpt: Exploring chatgpt for log-based anomaly detection.",
            "rating": 2,
            "sanitized_title": "loggpt_exploring_chatgpt_for_logbased_anomaly_detection"
        },
        {
            "paper_title": "Raglog: Log anomaly detection using retrieval augmented generation.",
            "rating": 2,
            "sanitized_title": "raglog_log_anomaly_detection_using_retrieval_augmented_generation"
        },
        {
            "paper_title": "Anomaly detection on unstable logs with gpt models.",
            "rating": 2,
            "sanitized_title": "anomaly_detection_on_unstable_logs_with_gpt_models"
        },
        {
            "paper_title": "Logbert: Log anomaly detection via bert.",
            "rating": 2,
            "sanitized_title": "logbert_log_anomaly_detection_via_bert"
        },
        {
            "paper_title": "Fastlogad: Log anomaly detection with mask-guided pseudo anomaly generation and discrimination.",
            "rating": 1,
            "sanitized_title": "fastlogad_log_anomaly_detection_with_maskguided_pseudo_anomaly_generation_and_discrimination"
        },
        {
            "paper_title": "Training-free retrieval-based log anomaly detection with pre-trained language model considering tokenlevel information.",
            "rating": 1,
            "sanitized_title": "trainingfree_retrievalbased_log_anomaly_detection_with_pretrained_language_model_considering_tokenlevel_information"
        }
    ],
    "cost": 0.017444249999999998,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>LogLLM: Log-based Anomaly Detection Using Large Language Models
14 Apr 2025</p>
<p>Wei Guan guan-wei@sjtu.edu.cn 
Department of Computer Science and Engineering
SJTU
ShanghaiChina</p>
<p>Jian Cao cao-jian@sjtu.edu.cn 
Department of Computer Science and Engineering
SJTU
ShanghaiChina</p>
<p>Shiyou Qian 
Department of Computer Science and Engineering
SJTU
ShanghaiChina</p>
<p>Jianqi Gao 
Department of Computer Science and Engineering
SJTU
ShanghaiChina</p>
<p>Chun Ouyang c.ouyang@qut.edu.au 
The School of Information Systems
QUT
BrisbaneAustralia</p>
<p>LogLLM: Log-based Anomaly Detection Using Large Language Models
14 Apr 2025FB83E6DB44533E5CD1A46BC66200A957arXiv:2411.08561v5[cs.SE]System loganomaly detectionlarge language modeldeep learninglog analysis
Software systems often record important runtime information in logs to help with troubleshooting.Log-based anomaly detection has become a key research area that aims to identify system issues through log data, ultimately enhancing the reliability of software systems.Traditional deep learning methods often struggle to capture the semantic information embedded in log data, which is typically organized in natural language.In this paper, we propose LogLLM, a log-based anomaly detection framework that leverages large language models (LLMs).LogLLM employs BERT for extracting semantic vectors from log messages, while utilizing Llama, a transformer decoder-based model, for classifying log sequences.Additionally, we introduce a projector to align the vector representation spaces of BERT and Llama, ensuring a cohesive understanding of log semantics.Unlike conventional methods that require log parsers to extract templates, LogLLM preprocesses log messages with regular expressions, streamlining the entire process.Our framework is trained through a novel three-stage procedure designed to enhance performance and adaptability.Experimental results across four public datasets demonstrate that LogLLM outperforms state-of-the-art methods.Even when handling unstable logs, it effectively captures the semantic meaning of log messages and detects anomalies accurately.</p>
<p>I. INTRODUCTION</p>
<p>Ensuring high availability and reliability is crucial for largescale software-intensive systems [1], [2].As these systems become more complex and expansive, the occurrence of anomalies becomes unavoidable [3], [4].Even a minor issue can lead to performance degradation, data integrity problems, and substantial losses in both customers and revenue.Therefore, anomaly detection is vital for maintaining the health and stability of complex software-intensive systems [5].</p>
<p>Software-intensive systems typically produce console logs that record system states and critical runtime events [6].Engineers can utilize this log data to evaluate system health, identify anomalies, and trace the root causes of issues.However, due to the potentially vast volume of logs, manually analyzing them for anomalies can be both labor-intensive and prone to mistakes [7].Consequently, log-based anomaly detection has emerged as a key area in automated log analysis, focusing on the automatic identification of system anomalies through log data.</p>
<p>Numerous deep learning-based methods [8]- [22] for logbased anomaly detection have been proposed.These methods typically employ sequential deep learning models such as LSTM [23] and transformers [24].These methods can be further divided into reconstruction-based methods [8]- [15] and binary classification-based methods [16]- [22].Reconstructionbased methods involve designing and training a deep neural network to reconstruct input log sequences, with anomalies detected based on reconstruction errors.The underlying principle is that anomalous samples cannot be accurately reconstructed.Binary classification-based methods, on the other hand, involve designing a binary classifier to classify samples as either normal or anomalous.These methods often require labeled anomalies for training purposes.It is recognized that system logs are documented in natural language and contain a significant amount of semantic information.Nevertheless, traditional deep learning-based methods struggle to effectively capture this information.</p>
<p>In recent years, significant advancements have been achieved in LLMs, such as GPT-4 [25], Llama 3 [26], and ChatGLM [27].These models are characterized by their vast parameter sizes and are pretrained on substantially larger datasets, ranging from several gigabytes to terabytes in size.This extensive pretraining equips them with remarkable language comprehension abilities, enabling superior performance in tasks such as summarization, paraphrasing, and instruction following even in zero-shot scenarios [28].Existing methods that utilize LLMs for log-based anomaly detection can be categorized into prompt engineering-based [7], [29]- [31] and fine-tuning-based [3], [32]- [40] approaches.Prompt engineering-based methods leverage the zero/few-shot capabilities of LLMs to detect anomalies based solely on the models' internal knowledge.However, these methods often struggle to customize solutions for specific datasets, leading to suboptimal detection performance.Fine-tuning-based methods integrate LLMs into deep neural networks and tailor them to user-specific datasets.Nevertheless, these methods encounter challenges such as limited semantic understanding, suboptimal LLM utilization (relying solely on LLMs for semantic information extraction), and insufficient consideration of input data format, which can lead to memory overflow.</p>
<p>To tackle the aforementioned challenges, we propose LogLLM, a novel log-based anomaly detection framework that harnesses LLMs.Unlike traditional methods that rely on log parsers for template extraction, LogLLM preprocesses log messages using regular expressions, thereby streamlining the entire process.LogLLM, a fine-tuning-based method, utilizes BERT, a transformer encoder-based model, to extract semantic vectors from log messages.Additionally, it employs Llama, a transformer decoder-based model, to classify log sequences.To ensure coherence in log semantics, we introduce a projector that aligns the vector representation spaces of BERT and Llama.Our framework is trained using a novel threestage procedure designed to enhance both performance and adaptability.</p>
<p>As illustrated in Section V-G, LLMs frequently face out-ofmemory challenges due to their extensive parameter sizes [41].Directly inputting the entire log sequence (by concatenating log messages into a long string) into Llama can lead to outof-memory issues and potentially confuse the LLM, making it difficult to focus on key points for distinguishing anomalies.By adopting BERT to summarize each log message, LogLLM effectively mitigates these problems.We conduct experiments across four public datasets, and the results demonstrate that LogLLM outperforms state-of-the-art methods.Even when handling unstable logs, where new log templates frequently emerge due to software evolution, it effectively captures the semantic meaning of log messages and detects anomalies accurately.The ablation study confirms the effectiveness of the three-stage training procedure.</p>
<p>The main contributions of our work are as follows:</p>
<p>II. RELATED WORK</p>
<p>In this section, we explore related work in the field of log-based anomaly detection, with a particular focus on deep learning-based methods.We give special attention to approaches that utilize pretrained LLMs.</p>
<p>A. Traditional Deep Learning for Log-based Anomaly Detection</p>
<p>Many traditional deep learning-based methods for log-based anomaly detection have been proposed.These works can be grouped into two types based on the training paradigm: reconstruction-based methods and binary classification-based methods.</p>
<p>Reconstruction-based methods [8]- [15] involve designing and training a deep neural network to reconstruct input log sequences.Anomalies are detected based on reconstruction errors.Normal log sequences can be reconstructed with minimal errors, while anomalous log sequences cannot be effectively reconstructed, resulting in significantly higher reconstruction errors.These methods consistently train the deep model on normal data that is free of anomalies, which means they are semi-supervised.</p>
<p>DeepLog [8] adopts LSTM to predict the next log template ID based on past log sequences.Similarly, LogAnomaly [9] predicts the next log template ID based on both sequential and quantitative patterns.Autoencoders (AEs) [10]- [13] and generative adversarial networks (GANs) [14], [15] are widely used in reconstruction-based methods.For example, LogAttn [10] adopts an AE that incorporates a temporal convolutional network (TCN) to capture temporal semantic correlations and a deep neural network (DNN) to capture statistical correlations.Duan et al. [14] use a GAN, where an encoder-decoder framework based on LSTM serves as the generator.Convolutional neural networks (CNNs) are used as the discriminator.The reconstruction error is calculated based on the difference between the input and the output from the generator.</p>
<p>Binary classification-based methods [16]- [22] often employ deep neural networks that output either one or two values.Typically, a single value represents the probability that a sample belongs to the anomalous class, and anomalies are detected by applying a threshold to convert this probability into a binary classification.When two values are output, they represent the probabilities of the sample belonging to the normal and anomalous classes, respectively.</p>
<p>Most methods [16]- [20] typically train deep models in a supervised manner.For example, Zhang et al. [16] propose LayerLog, which integrates word, log, and logseq layers to extract semantic features from log sequences.CNNs are utilized in [17], [18] to develop a binary classifier.LogRobust [19] integrates a pre-trained Word2Vec model, specifically FastText [42], and combines it with TF-IDF weights to learn representation vectors of log templates.These vectors are then fed into an attention-based Bi-LSTM model for anomaly detection.LogGD [20] transforms log sequences into graphs and utilizes a graph transformer neural network that combines graph structure and node semantics for log-based anomaly detection.</p>
<p>Some work [21], [22] involves training binary classifiers in a semi-supervised manner.For example, Trine [21] uses a transformer encoder [24] to encode normal log sequences into vector representations and a generator to produce random fake vector representations.The discriminator, which is composed of a transformer and a multi-layer perceptron (MLP), is trained to distinguish whether the given vector representations are normal log sequences and it is subsequently used to detect anomalies.PLELog [22] tackles the challenge of insufficient labeling by employing probabilistic label estimation and develops an attention-based GRU neural network for anomaly detection.</p>
<p>It is acknowledged that system logs are recorded in natural Fig. 1: An example of a system log.</p>
<p>language and contain a substantial amount of semantic information.However, traditional deep learning-based methods face challenges in capturing this information.</p>
<p>B. LLMs for Log-based Anomaly Detection</p>
<p>Existing LLMs can be categorized into transformer encoderbased models, such as BERT [43], RoBERTa [44], and Span-BERT [45], and transformer decoder-based models, including GPT-4 [25], Llama 3 [26], and ChatGLM [27].Two prevalent strategies for utilizing LLMs are prompt engineering and finetuning.</p>
<p>Prompt engineering-based methods [7], [29]- [31] detect anomalies solely by relying on the internal knowledge of LLMs.These methods typically employ transformer decoderbased models.For instance, Qi et al. [7] employ ChatGPT for zero-shot and few-shot log-based anomaly detection, utilizing prompt templates that integrate the log sequence directly.However, this approach becomes impractical when using a large window size for grouping log messages.Egersdoerfer et al. [30] address this issue by maintaining a summary-based memory, which summarizes the previous log messages, eliminating the need to input the entire log sequence for anomaly detection.RAGLog [31] uses a retrieval augmented generative (RAG) framework [46] to analyze log entries by querying its store of samples of normal log entries.They design prompt templates for LLMs to determine whether a queried log entry is normal or abnormal.Prompt engineering-based methods often struggle to customize solutions for specific datasets, which can lead to suboptimal detection performance in particular datasets.</p>
<p>Fine-tuning-based methods [3], [32]- [40] incorporate LLMs into deep neural networks and customize them to the user's own dataset.Some methods [32]- [35], although adopting transformer encoder-based LLMs for anomaly detection, do not capture the semantic information within log sequences.For example, LogBERT [32] and LAnoBERT [33] utilize BERT to reconstruct the input sequence of log template IDs (IDs of log string templates) and detect anomalies based on reconstruction errors, disregarding the semantic information.Other methods [3], [36]- [39] use transformer encoder-based LLMs solely for extracting semantic information from log messages and then employ either smaller models [3], [36]- [38] or distance-based comparison [39] for classification.For instance, NeuralLog [3] leverages BERT to extract semantic vectors from raw log messages, which are subsequently used to detect anomalies via a transformer-based classification model.Similarly, RAPID [39] utilizes transformer encoder-based models to extract semantic vectors and performs anomaly detection by comparing each query log sequence with its nearest document log sequence.Hadadi et al. [40] directly input template sequences parsed from log sequences, into GPT models and fine-tune it to accurately predict sequence labels.However, this approach faces two key challenges.First, the boundaries between templates within the sequences are unclear, making it difficult for the model to learn the sequential dependencies.Second, each template may be tokenized into multiple tokens by the LLM's tokenizer, and a single sequence can contain numerous log templates.As a result, an excessive number of tokens may be generated, often exceeding the token (memory) limits of LLMs [41], thereby restricting the length of sequences that can be processed.These two challenges are further demonstrated in Section V-G.</p>
<p>LogLLM is a fine-tuning-based method that utilizes BERT for extracting semantic vectors from log messages and Llama, a transformer decoder-based model, for log sequence classification.This method aligns the vector representation spaces of BERT and Llama using a projector.The use of BERT ensures clear boundaries between log messages, as each message is represented by a distinct embedding vector, thereby enhancing classification performance.Moreover, when memory and parameter size of Llama are held constant, this approach can handle longer sequences compared to directly tokenizing the entire log sequence using Llama's tokenizer.</p>
<p>III. PRELIMINARIES</p>
<p>To establish the groundwork for subsequent sections, we introduce the system log, which records the system's events and internal states during runtime.A system log contains a list of log messages in chronological order.</p>
<p>Fig. 1 presents a snippet of a raw system log generated by the BGL (the BlueGene/L supercomputer system), with each log message ordered according to the recorded time.These raw log messages are semi-structured texts consisting of a header and content.The header, determined by the logging framework, includes information such as timestamp, verbosity level (e.g., WARN/INFO), and component [47].The log content comprises a constant part (keywords that reveal the log template) and a variable part (parameters that carry dynamic runtime information).In this paper, we focus solely on the content of each log message.</p>
<p>The log messages can be grouped into log sequences (i.e., series of log messages that record specific execution flows) based on session or fixed/sliding windows [48].Session window partitioning groups log messages according to their session IDs, thereby generating sequences that include the log  messages within each session.For example, Fig. 2a illustrates the HDFS [49] logs undergoing the session window grouping process, where the block_id serves as the session ID.In contrast, fixed/sliding window partitioning groups log messages based on a fixed size (window size), which can be defined by either the time span or the number of log messages.This method creates sequences that capture snapshots of system log messages over time.For example, Fig. 2b illustrates the BGL [50] logs undergoing the sliding window grouping process, with a window size of 2 messages and a step size of 2 messages.</p>
<p>The objective of log-based anomaly detection is to identify anomalous log sequences, facilitating the recognition of potential issues within the system's operational behavior.</p>
<p>IV. METHODOLOGY</p>
<p>In this section, we present our innovative anomaly detection framework, LogLLM.As illustrated in Fig. 3, the log sequence undergoes preprocessing using regular expressions before being fed into a deep neural network that integrates BERT [43], a projector, and Llama [26] for log sequence classification.In the following sections, we will provide detailed insights into log sequence preprocessing, the architecture of the deep model, and the model training procedure.</p>
<p>A. Preprocessing</p>
<p>Considering that the log message content includes variable parameters carrying dynamic runtime information, which is always irrelevant to the anomalies and complicates deep model training, as demonstrated in Section V-F, a technique is needed to identify these parameters and replace them with a constant token.Log parsers, such as Drain [51] and Spell [52], are widely adopted in log-based anomaly detection methods and appear to be a useful technique.However, as noted by Le et al. [3], existing log parsers do not always perform correctly on all log datasets and struggle to handle out-of-vocabulary (OOV) words in new log messages, resulting in a loss of semantic information.When logs are unstable, these parsers become increasingly ineffective over time, making it difficult to support subsequent anomaly detection.</p>
<p>Thanks to the structured log generation process, the textual format of parameters representing specific objects can be easily identified using regular expressions [53].Consequently, we replace each variable parameter, such as account, directory path, and IP address, with '&lt;*&gt;'.Despite its simplicity, this technique offers significant performance advantages.Compared with log parsers, this preprocessing technique is more effective and does not require training.</p>
<p>B. Model Architecture</p>
<p>As shown in Fig. 3, our deep model consists of three main components: BERT, a projector, and Llama.Both BERT and Llama are pretrained LLMs.BERT is utilized to extract vector representations of log messages, while Llama is employed to classify the log sequences.The projector serves as a bridge, aligning the vector representation spaces of BERT and Llama.It is important to note that our model incorporates only one instance of BERT and one projector.</p>
<p>1) BERT: BERT generates a semantic vector by processing the semantic vector of the classification token ([CLS]) through a linear layer followed by a tanh activation function.Each log message, once preprocessed, is encoded into a semantic vector using the BERT tokenizer and BERT model.For a preprocessed log sequence, the output of BERT is a sequence of semantic vectors C = (c 1 , c 2 , . . ., c N ) ∈ R N ×d BERT , where N represents the length of the log sequence (i.e., the number of log messages) and d BERT is the dimension of each semantic vector (i.e., hidden size).</p>
<p>2) Projector: The projector is a linear layer that maps the semantic vectors C ∈ R N ×d BERT to the token embedding vectors accepted by Llama, represented as E = (e 1 , e 2 , . . ., e N ) ∈ R N ×d Llama , where d Llama is the hidden size of Llama.The projector is designed to align the vector representation spaces of BERT and Llama.</p>
<p>3) Llama: To conduct prompt tuning on Llama, the transformer decoder-based LLM, we generate corresponding textual queries based on embedded log sequences.Specifically, each query consists of three components.</p>
<p>The first component introduces the log sequence, such as "Below is a sequence of system log messages:".The second component comprises the token embeddings E output by the projector.The third component queries whether the sequence is anomalous, asking, for instance, ".Is this sequence normal or anomalous?".The first and third components are fed into the Llama tokenizer and Llama embedding layer sequentially, producing E 1 ∈ R A×d Llama and E 3 ∈ R Q×d Llama , where A and Q are the number of tokens produced by tokenizing the first and third components, respectively.Then, the token embeddings of the three components are concatenated, rep-</p>
<p>C. Training</p>
<p>1) Minority Class Oversampling: LogLLM is a supervised anomaly detection method, which means it needs labeled normal and anomalous samples for training.However, supervised anomaly detection methods often face the challenge of data imbalance, which can lead to biased model training.In an anomaly detection task, there are only two classes: normal and anomalous, and the number of instances in each class is uncertain.To cope with data imbalance, we oversample the class with fewer samples, ensuring that the proportion of the minority class is no less than β.Formally, let the proportion of the minority class be α and α &lt; β, and the total number of samples be Sample_num.To achieve a proportion of β for the minority class, it will be oversampled to the following quantity:
β(1 − α) 1 − β × Sample_num(1)
This adjustment will make the proportion of the minority class equal to β.</p>
<p>2) Training Objective: Our objective is to train the deep model to predict whether a given log sequence is normal or anomalous.We fine-tune the model to respond appropriately: if the sequence is anomalous, it outputs 'The sequence is anomalous.';if normal, it outputs 'The sequence is normal.'.We utilize cross-entropy loss [54] as our loss function.</p>
<p>3) Training Procedure: To train our deep model, we follow three main stages.</p>
<p>Stage 1. Fine-tuning Llama to capture the answer template: The first stage involves fine-tuning Llama to capture the answer template.Specifically, we train Llama to respond to the prompt 'Is this sequence normal or anomalous?' with 'The sequence is anomalous/normal.'.This stage requires only a few data samples.</p>
<p>Stage 2. Training the embedder of log messages:</p>
<p>The second stage involves training the embedder of log messages, specifically BERT and the projector.This stage aims to project each log message to the embedding of the most suitable token in Llama, enabling Llama to discern whether the given log sequence is normal or anomalous.</p>
<p>Stage 3. Fine-tuning the entire model: Finally, we fine-tune the entire model to ensure cohesive and accurate performance across all components.</p>
<p>4) Efficient Fine-Tuning on LLMs: To reduce the costs involved in fine-tuning LLMs (BERT and Llama) with a substantial number of parameters, we utilize QLoRA [55] to minimize memory usage.QLoRA accomplishes this by backpropagating gradients into a frozen 4-bit quantized model, while maintaining the performance levels achieved during the full 16-bit fine-tuning process.</p>
<p>V. EXPERIMENTS</p>
<p>In this section, we conduct extensive experiments on four real-life logs to investigate the following research questions (RQs): LogLLM is coded in Python, and the source code is available at https://github.com/guanwei49/LogLLM.</p>
<p>A. Benchmark Methods</p>
<p>To verify the superiority of the proposed method, we compare LogLLM with five state-of-the-art semi-supervised methods: DeepLog [8], LogAnomaly [9], PLELog [22], Fast-LogAD [34], and LogBERT [32].We also compare it with three supervised methods: LogRobust [19], CNN [18] and NeuralLog [3], and one method that does not require training a deep model but needs some normal samples for retrieval: RAPID [39].</p>
<p>Notably, FastLogAD, LogBERT, NeuralLog, and RAPID adopt LLMs for anomaly detection.</p>
<p>B. Experimental Settings</p>
<p>We conduct all experiments on a server equipped with an Intel Xeon Gold 6330 CPU (38 cores), 256GB of memory, and an NVIDIA A40 GPU with 48 GB of memory.</p>
<p>In our experiment, we utilize the BERT-base model1 and Llama-3-8B model2 as backbones.The hyperparameter β, which is described in Section IV-C1, is set to 30%.We use the AdamW optimizer [56] to train the model with a mini-batch size of 16.Unless otherwise specified, the training procedure is configured as follows: In the first stage, only 1,000 samples are involved with a learning rate of 5e-4.The second and third stages each consist of two epochs with a learning rate of 5e-5.</p>
<p>For a fair comparison, we configure the hyperparameters for all compared methods according to the values provided in their original articles.</p>
<p>C. Metrics</p>
<p>We evaluate the performance of these methods using the widely adopted P recision, Recall and F 1 − score.These metrics are calculated as follows:</p>
<p>P recision = T P T P + F P</p>
<p>(2)
Recall = T P T P + F N(3)F 1 −score = 2 * P recision * Recall P recision + Recall(4)
, where T P , F N , F P represent true positives, false negatives and false positives respectively.Precision refers to the percentage of correctly detected anomalies among all anomalies identified by the model, while recall represents the percentage of anomalies that are correctly identified from all real anomalies.The F 1 -score combines these two metrics into a single measure, providing a balanced assessment of the model's performance in detecting anomalies.</p>
<p>D. Dataset</p>
<p>To evaluate our method for log-based anomaly detection, we selected four public datasets [57]: HDFS, BGL, Liberty, and Thunderbird.The details for each dataset are provided below:</p>
<p>HDFS (Hadoop Distributed File System) dataset [49] is generated by running Hadoop-based mapreduce jobs on over 200 Amazon EC2 nodes and contains a total of 11,175,629 log messages.These log messages are grouped into different log windows based on their block_id, which reflect program executions in the HDFS, resulting in 575,061 blocks.Among these, 16,838 blocks (2.93%) indicate system anomalies.</p>
<p>BGL (Blue Gene/L) dataset [50] is a supercomputing system log dataset collected from a BlueGene/L supercomputer system at lawrence livermore national labs (LLNL).The dataset contains 4,747,963 log messages, each of which has been manually labeled as either normal or anomalous.There are 348,460 log messages (7.34%) that are labeled as anomalous.</p>
<p>Thunderbird dataset [50] is a publicly accessible collection of log data sourced from the Thunderbird supercomputer at sandia national laboratories (SNL).This dataset consists of both normal and anomalous messages, each of which has been manually categorized.Although the dataset contains over 200 million log messages, we focus on a subset of 10 million continuous log messages for computational efficiency.This subset includes 4,937 anomalous log messages, representing approximately 0.049% of the total.</p>
<p>Liberty dataset [50] comprises system logs from the Liberty supercomputer at sandia national labs (SNL) in Albuquerque.This supercomputer features 512 processors and 944 GB of memory, and the dataset contains over 200 million log messages.For computational efficiency, we sample 5 million consecutive log messages, among which 1,600,525 are identified as anomalous, constituting approximately 32.01% of the total sampled messages.</p>
<p>In the context of HDFS, we adopt a session window strategy, which involves grouping log messages into sequences based on the block_id present in each log message.Each session is labeled using ground truth.For other datasets, including BGL, Thunderbird, and Liberty, we utilize a sliding window strategy to group log messages, with a window size of 100 messages and a step size of 100 messages.A log sequence is deemed anomalous if it contains at least one anomalous log message according to the ground truth.</p>
<p>Similar to existing work [8], [9], [19], [22], [34], [39], we split each dataset into a training set and a testing set with a ratio of 8:2 to evaluate the performance of a log-based anomaly detection approach.For the HDFS dataset, we randomly split the log sequences into training and testing data.In contrast, for the BGL, Thunderbird, and Liberty datasets, we adhere to a chronological split [6].This strategy ensures that all log sequences in the training set precede those in the testing set, reflecting real-world conditions and mitigating potential data leakage from unstable log data.</p>
<p>Table I summarizes the statistics of the datasets used in the experiments.</p>
<p>E. Performance Evaluation (RQ1)</p>
<p>Table II presents the experimental results of various logbased anomaly detection methods on the HDFS, BGL, Liberty, and Thunderbird datasets.The best results are highlighted in bold.We have the following observations:  The proposed LogLLM achieves the highest F 1 -score across all datasets.On average, LogLLM's F 1 -scores are 6.6% better than the best existing method, NeuralLog, demonstrating its effectiveness in log-based anomaly detection.Despite the adoption of LLMs in FastLogAD, LogBERT, NeuralLog, and RAPID for anomaly detection, their performance remains unsatisfactory.FastLogAD and LogBERT utilize BERT, a transformer encoder-based model, for detecting anomalies based on log sequence reconstruction errors.Their inputs consist of sequences of log template IDs (IDs of log string templates) extracted from log messages via log parsers, lacking semantic information.In contrast, NeuralLog and RAPID utilize transformer encoder-based models to extract semantic vectors from log messages.However, NeuralLog utilizes smaller models, whereas RAPID relies on distance-based comparison for anomaly sequence classification.LogLLM, on the other hand, leverages both BERT for extracting semantic vectors and Llama, a transformer decoder-based LLM, for anomaly detection.The representation spaces of BERT and Llama are aligned via a projector, fully harnessing the potential of LLMs for log-based anomaly detection.</p>
<p>Moreover, LogLLM achieves a balance between precision and recall, indicating that it maintains low false alarm rates and minimizes missed reports.In contrast, methods like Fast-LogAD are excessively sensitive to anomalies, often resulting in numerous false alarms.For example, on the BGL dataset, despite FastLogAD having a recall of 1, it only achieves a precision of 0.167, making it impractical for real-world use.Similarly, methods such as DeepLog, LogAnomaly and LogBERT exhibit similar issues.On the other hand, RAPID is not sensitive enough to anomalies, leading to many undetected anomalies.For instance, on the BGL dataset, RAPID achieves a precision of 0.874 but a recall of only 0.399.</p>
<p>Effect of labeled anomalies: As illustrated in Table II, in contrast to methods such as DeepLog, LogAnomaly, FastLo-gAD, LogBERT, and RAPID, which require clean datasets devoid of anomalies to build anomaly detection models, methods like PLELog, LogRobust, CNN, NeuralLog, and LogLLM demonstrate superior performance.These models are trained using not only normal samples but also labeled anomalies.For instance, these five methods achieve an average F 1 -score above 0.771 across four datasets, whereas others that do not utilize labeled anomalies perform poorly, with an average F 1score below 0.602 across four datasets.This demonstrates that incorporating labeled anomalies can provide a significant advantage to anomaly detection methods.</p>
<p>Computational cost: The time consumption of each method is presented in Table III.These results have been averaged across all the datasets.</p>
<p>Although RAPID does not require training a deep model, the extraction and retrieval of vector representations remain time-consuming.In comparison to other methods, FastLogAD requires relatively high training time, but it has the shortest testing time because it uses only the discriminator of the model during testing.As anticipated, while our proposed LogLLM demonstrates the best performance, it also incurs the highest  computational cost due to its large number of parameters.However, the testing time of LogLLM remains acceptable when compared to other methods that utilize LLMs, such as LogBERT, NeuralLog, and RAPID.</p>
<p>F. Different Preprocessing Techniques (RQ2)</p>
<p>We evaluate the effectiveness of the different preprocessing techniques.The results are shown in Table IV.In this table, 'Raw' indicates that the content of log messages is not preprocessed and is directly input into the proposed deep model.'Template' indicates that sequences of log templates produced by Drain [51], a log parser, are used as input for the proposed deep model.'Template ID' signifies that the IDs of log templates, obtained by Drain, are simply encoded into numeric vectors using an embedding layer instead of BERT.The preprocessing technique 'Template ID' renders the model unable to capture the semantic information within log messages.Notably, the parser Drain is applied to the entire dataset, rather than only the training dataset, to avoid performance degradation due to the OOV problem.'RE' indicates that regular expressions, as introduced in Section IV-A, are used for preprocessing log messages.</p>
<p>As anticipated, the preprocessing technique 'RE' yields the highest F 1 -score across all datasets.Conversely, the preprocessing technique 'Template ID' consistently results in the lowest F 1 -score across all datasets, averaging 36.8% lower than that of 'RE'.This can be attributed to the fact that 'Template ID' hinders the model's ability to capture the semantic information within log messages, thereby impairing its capability to detect anomalies from a natural language perspective.The preprocessing techniques 'Raw' and 'Template' result in relatively good performance, but their F 1 -scores are still 6.4% and 5.7% lower than that of 'RE', respectively.For the preprocessing technique 'Raw', the variable parts (parameters that carry dynamic runtime information) within the content of each log message have little influence on anomaly detection.However, due to their high randomness, they can confuse the model, making it difficult to discern anomalies.For the preprocessing technique 'Template', the parser is not always reliable, sometimes incorrectly removing the constant parts or retaining the variable parts, which can lead to information loss or confusion for the model, making it difficult to discern anomalies.</p>
<p>G. Effect of the Embedder (RQ3)</p>
<p>We investigate whether the embedder (BERT and adapter) is necessary for LogLLM.The results are presented in Table V. 'L.-1B' refers to directly inputting the log sequence (by concatenating log messages with semicolons (;) as separators into a long string) into the 'Llama-3.2-1B'model3 .'Emb.&amp; L.-1B' represents LogLLM based on 'Llama-3.2-1B'.</p>
<p>As expected, with the assistance of the embedder, the model requires less GPU memory, thereby avoiding out-of-memory (OOM) errors.Additionally, it enhances model performance by clarifying the boundaries between messages within a sequence.This improved representation enables the LLM to capture sequential dependencies better.</p>
<p>H. Effect of the Llama Model Size (RQ4)</p>
<p>As shown in Table V, larger LLaMA model sizes lead to better performance, at the cost of increased GPU memory usage and longer training times.</p>
<p>On average, compared to using Llama-3.2-1B,adopting Llama-3-8B improves the F 1 -score by 4.3%, but increases GPU memory usage by 7.7 GB and extends training time by 443.2 minutes.</p>
<p>I. Ablation Study of the Training Procedure (RQ5)</p>
<p>We investigate the effect of each training procedure through an ablation study.The results are presented in Table VI, where 'W/O' denotes 'without'.We have the following observations:</p>
<p>Skipping any training stage results in a decrease in the F 1score across all datasets, demonstrating the effectiveness of our This stage allows the embedder to generate better semantic vectors of log messages for Llama to discern anomalies.In summary, our proposed three-stage training procedure is well-suited for our deep model in log-based anomaly detection.</p>
<p>J. Impact of Minority Class Oversampling (RQ6)</p>
<p>Note that normal and anomalous samples in the training dataset are imbalanced, as shown in Table I.For the HDFS, BGL, and Thunderbird datasets, normal samples outnumber anomalous samples.Conversely, in the Liberty dataset, anomalous samples exceed normal samples.As described in Section IV-C1, the hyper-parameter β controls the proportion of the minority class by oversampling to address the data imbalance problem.In this section, we investigate the impact of β by varying its value.Fig. 4 illustrates the performance of LogLLM on the four datasets under different magnitudes of β.When β = 0, the samples are not oversampled; instead, the original datasets are utilized directly for training.</p>
<p>As illustrated in Fig. 4b, for the HDFS, BGL, and Thunderbird datasets, the recall always increases, while for the Liberty dataset, recall decreases as β increases.This can be attributed to the fact that for the HDFS, BGL, and Thunderbird datasets, when β increases, anomalies are oversampled, making the model more prone to identifying samples as anomalies.In As illustrated in Fig. 4c, the trend of the F 1 -score is basically the same across all datasets.The F 1 -score increases and then decreases as β increases.However, the LogLLM seems not to be sensitive to β; when β is between 10% and 80%, the variation in the F 1 -score is no more than 0.07.Thanks to the substantial semantic knowledge embedded in LLMs, a trained model can effectively learn anomalous patterns and detect anomalies, even when the minority class constitutes only 10% of the dataset.However, LogLLM appears unable to effectively handle extremely imbalanced scenarios.For instance, in the Thunderbird dataset, anomalies constitute only 1.05% of the samples, causing the trained model to be biased and classify all samples as normal.As a result, precision, recall, and F 1score are all equal to 0.</p>
<p>Compared to the BGL and Thunderbird datasets, the precision, recall and F 1 -score for the HDFS and Liberty datasets exhibit minimal variation with respect to β.This consistency arises from the more distinct patterns between abnormal and normal samples in the HDFS and Liberty datasets, allowing LogLLM to easily differentiate them, regardless of the ratio of normal and abnormal samples.</p>
<p>As anticipated, as β increases, the training time also increases, as shown in Fig. 4d.This relationship arises because a higher β leads to more oversampled data samples, as indicated by equation ( 1), thereby enlarging the training dataset.</p>
<p>To summarize, minority class oversampling is essential; however, the value of the hyperparameter β does not significantly impact the performance of LogLLM, making careful selection unnecessary.Moreover, excessively large values of β are undesirable, as they result in prolonged training times.Values between 30% and 50% are deemed acceptable.</p>
<p>VI. CONCLUSION</p>
<p>In this paper, we propose LogLLM, a novel log-based anomaly detection framework that leverages LLMs.LogLLM employs both transformer encoder-based and decoder-based LLMs, specifically BERT and Llama, for log-based anomaly detection.BERT is utilized to extract semantic vectors from log messages, while Llama is used to classify log sequences.To ensure coherence in log semantics, we introduce a projector that aligns the vector representation spaces of BERT and Llama.LogLLM is trained using an innovative three-stage procedure designed to enhance both performance and adaptability.Extensive experiments conducted on four public realworld datasets demonstrate that LogLLM achieves remarkable performance.Subsequent ablation studies further confirm the effectiveness of our three-stage training procedure.</p>
<p>Log Sequence # 2 1 2 CELogFig. 2 :
222
Fig. 2: Illustrative examples of log message partitioning.</p>
<p>Fig. 3 :
3
Fig. 3: The framework of LogLLM.Notably, the model includes a single instance of BERT and the projector.</p>
<p>•:</p>
<p>RQ1How effective is LogLLM in log-based anomaly detection?• RQ2: How do different preprocessing techniques impact the performance of LogLLM?• RQ3: How effective is the embedder for Llama?• RQ4: How does the size of the Llama model affect the performance of LogLLM?• RQ5: How does each stage of the three-stage training process influence the performance of LogLLM?• RQ6: How do different levels of minority class oversampling, determined by the hyperparameter β, affect the performance of LogLLM?</p>
<p>Fig. 4 :
4
Fig. 4: Impact of minority class oversampling.</p>
<p>TABLE I :
I
The statistics of datasets used in the experiments.</p>
<h1>Log messages # Log sequencesTraining DataTesting Data# Log sequences # Anomalies Anomaly ratio # Log sequences # Anomalies Anomaly ratioHDFS11,175,629575,061460,04813,4972.93%115,0133,3412.90%BGL4,747,96347,13537,7084,00910.63%9,4278178.67%Liberty5,000,00050,00040,00034,14485.36%10,0006516.51%Thunderbird10,000,00099,99779,9978371.05%20,000290.15%</h1>
<p>TABLE II :
II
Experimental results on HDFS, BGL, Liberty, and Thunderbird datasets.The best results are highlighted in bold.
MethodsDatasets Log parserPrec.HDFS Rec.F 1Prec.BGL Rec.F 1Prec.Liberty Rec.F 1Prec.Thunderbird Rec.F 1Avg. F 1DeepLog0.835 0.994 0.908 0.166 0.988 0.285 0.751 0.855 0.800 0.017 0.966 0.0330.506LogAnomaly0.886 0.893 0.966 0.176 0.985 0.299 0.684 0.876 0.768 0.025 0.966 0.0500.521PLELog0.893 0.979 0.934 0.595 0.880 0.710 0.795 0.874 0.832 0.808 0.724 0.7640.810FastLogAD0.721 0.893 0.798 0.167 1.000 0.287 0.151 0.999 0.263 0.008 0.931 0.0170.341LogBERT0.989 0.614 0.758 0.165 0.989 0.283 0.902 0.633 0.744 0.022 0.172 0.0390.456LogRobust0.961 1.000 0.980 0.696 0.968 0.810 0.695 0.979 0.813 0.318 1.000 0.4820.771CNN0.966 1.000 0.982 0.698 0.965 0.810 0.580 0.914 0.709 0.870 0.690 0.7690.818NeuralLog0.971 0.988 0.979 0.792 0.884 0.835 0.875 0.926 0.900 0.794 0.931 0.8570.893RAPID1.000 0.859 0.924 0.874 0.399 0.548 0.911 0.611 0.732 0.200 0.207 0.2030.602LogLLM0.994 1.000 0.997 0.861 0.979 0.916 0.992 0.926 0.958 0.966 0.966 0.9660.959</p>
<p>TABLE III :
III
Computational cost.
Training time (Minutes)Testing time (Minutes)DeepLog72.173.42LogAnomaly156.167.25PLELog315.4733.59LogRobust108.422.48CNN98.162.16FastLogAD254.170.29LogBERT429.0443.77NeuralLog267.4621.44RAPID63.9838.43LogLLM1,065.1564.48</p>
<p>TABLE IV :
IV
Effects of different preprocessing techniques on HDFS, BGL, Liberty, and Thunderbird datasets.The best results are highlighted in bold.
HDFSBGLLibertyThunderbirdAvg. F 1Prec.Rec.F 1Prec.Rec.F 1Prec.Rec.F 1Prec.Rec.F 1Raw0.9940.9910.9930.9430.7670.8460.9110.9080.9090.8060.8620.8330.895Template ID0.9950.9450.9690.7750.2860.4180.9940.2700.4251.0000.3790.5500.591Template0.9911.0000.9950.8610.9190.8890.9680.9310.9490.9500.6550.7760.902RE (LogLLM)0.9941.0000.9970.8610.9790.9160.9920.9260.9580.9660.9660.9660.959</p>
<p>TABLE V :
V
Effects of the embedder (BERT &amp; adapter) and LLaMA model size, where 'Mem.' indicates GPU memory usage (GB), and 'Tim.' indicates training time (Minutes).'-' indicates an out-of-memory (OOM) error.
HDFSBGLLibertyThunderbirdPrec. Rec.F 1 Mem. Tim. Prec. Rec.F 1 Mem. Tim. Prec. Rec.F 1 Mem. Tim. Prec. Rec.F 1 Mem. Tim.L.-1B0.986 0.995 0.991 16.5 1022.1-----0.960 0.699 0.809 42.6 443.2 1.000 0.724 0.840 44.5 1732.1Emb. &amp; L.-1B 0.996 0.996 0.996 8.0 1412.2 0.734 0.944 0.825 32.4 187.1 0.950 0.905 0.927 29.3 173.2 0.875 0.966 0.918 32.4 715.1L.-8B0.988 0.997 0.992 43.0 4712.1---------------Emb. &amp; L.-8B 0.994 1.000 0.997 16.6 2168.2 0.861 0.979 0.916 38.0 396.2 0.992 0.926 0.958 36.1 412.1 0.966 0.966 0.966 38.2 1284.2</p>
<p>TABLE VI :
VI
Ablation study of the training procedure on HDFS, BGL, Liberty, and Thunderbird datasets.The best results are highlighted in bold.(i.e., directly training the embedder), the embedder may be misdirected, resulting in incorrect semantic capture of log messages and model failure.Training without stage 3 yields relatively poor performance, with an average F 1score decrease of 10.5%.This indicates that sequentially finetuning Llama and training the embedder alone is insufficient for the model to capture anomalous patterns; cohesive finetuning of the entire model is essential.Training without stages 2 and 1&amp;2 also results in a performance decrease, with average F 1 -score reductions of 2.5% and 3.2%, respectively.This demonstrates that individually training the embedder before fine-tuning the entire model can also enhance performance.
HDFSBGLLibertyThunderbirdAvg. F 1Prec.Rec.F 1Prec.Rec.F 1Prec.Rec.F 1Prec.Rec.F 1W/O Stage 10.9911.0000.9950.5780.9710.7250.6850.2900.4080.3810.8280.5220.662W/O Stage 20.9941.0000.9970.8580.9200.8880.9950.9060.9490.8480.9660.9030.934W/O Stage 1&amp;20.9921.0000.9960.8530.8820.8680.9950.9060.9490.8970.8970.8970.927W/O Stage 30.9930.9990.9960.7040.7760.7381.0000.6840.8120.9580.7930.8680.854LogLLM0.9941.0000.9970.8610.9790.9160.9920.9260.9580.9660.9660.9660.959three-stage training procedure. It is noteworthy that trainingwithout stage 1 leads to the worst performance, with the F 1 -score averaged across all datasets decreasing by as much as29.7%. However, training without stages 1&amp;2 (only adoptingtraining stage 3: fine-tuning the entire model) yields acceptableperformance, with only a 3.2% decrease in the average F 1 -score. This demonstrates that fine-tuning Llama to capturethe answer template (Stage 1) is essential before training theembedder (BERT and projector) of log messages (Stage 2).Without stage 1
https://huggingface.co/google-bert/bert-base-uncased
https://huggingface.co/meta-llama/Meta-Llama-3-8B
https://huggingface.co/meta-llama/Llama-3.2-1B</p>
<p>Reliable and highly available distributed publish/subscribe service. R S Kazemzadeh, H.-A Jacobsen, 2009 28th IEEE International Symposium on Reliable Distributed Systems. IEEE2009</p>
<p>Reliability and availability of cloud computing. E Bauer, R Adams, 2012John Wiley &amp; Sons</p>
<p>Log-based anomaly detection without log parsing. V.-H Le, H Zhang, 2021 36th IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEE2021</p>
<p>Survey and benchmark of anomaly detection in business processes. W Guan, J Cao, H Zhao, Y Gu, S Qian, IEEE Transactions on Knowledge and Data Engineering. 2024</p>
<p>End-to-end automl for unsupervised log anomaly detection. S Zhang, Y Ji, J Luan, X Nie, Z Chen, M Ma, Y Sun, D Pei, 2024Automated Software Engineering (ASE'24</p>
<p>Log-based anomaly detection with deep learning: How far are we?. V.-H Le, H Zhang, Proceedings of the 44th international conference on software engineering. the 44th international conference on software engineering2022</p>
<p>Loggpt: Exploring chatgpt for log-based anomaly detection. J Qi, S Huang, Z Luan, S Yang, C Fung, H Yang, D Qian, J Shang, Z Xiao, Z Wu, 2023 IEEE International Conference on High Performance Computing &amp; Communications, Data Science &amp; Systems, Smart City &amp; Dependability in Sensor, Cloud &amp; Big Data Systems &amp; Application. HPCC/DSS/SmartCity/DependSys. IEEE2023</p>
<p>Deeplog: Anomaly detection and diagnosis from system logs through deep learning. M Du, F Li, G Zheng, V Srikumar, Proceedings of the 2017 ACM SIGSAC conference on computer and communications security. the 2017 ACM SIGSAC conference on computer and communications security2017</p>
<p>Loganomaly: Unsupervised detection of sequential and quantitative anomalies in unstructured logs. W Meng, Y Liu, Y Zhu, S Zhang, D Pei, Y Liu, Y Chen, R Zhang, S Tao, P Sun, IJCAI. 1972019</p>
<p>Logattn: Unsupervised log anomaly detection with an autoencoder based attention mechanism. L Zhang, W Li, Z Zhang, Q Lu, C Hou, P Hu, T Gui, S Lu, International conference on knowledge science, engineering and management. Springer2021</p>
<p>Autolog: Anomaly detection by deep autoencoding of system logs. M Catillo, A Pecchia, U Villano, Expert Systems with Applications. 1911162632022</p>
<p>Log anomaly detection by adversarial autoencoders with graph feature fusion. Y Xie, K Yang, IEEE Transactions on Reliability. 2023</p>
<p>Anomaly detection model for log based on lstm network and variational autoencoder. X Zhang, X Chai, M Yu, D Qiu, 2023 4th International Conference on Information Science, Parallel and Distributed Systems (ISPDS). IEEE2023</p>
<p>A generative adversarial networks for log anomaly detection. X Duan, S Ying, W Yuan, H Cheng, X Yin, Comput. Syst. Sci. Eng. 3712021</p>
<p>Graph-based log anomaly detection via adversarial training. Z He, Y Tang, K Zhao, J Liu, W Chen, International Symposium on Dependable Software Engineering: Theories, Tools, and Applications. Springer2023</p>
<p>Layerlog: Log sequence anomaly detection based on hierarchical semantics. C Zhang, X Wang, H Zhang, J Zhang, H Zhang, C Liu, P Han, Applied Soft Computing. 1321098602023</p>
<p>Onelog: towards end-to-end software log anomaly detection. S Hashemi, M Mäntylä, Automated Software Engineering. 312372024</p>
<p>Detecting anomaly in big data system logs using convolutional neural network. S Lu, X Wei, Y Li, L Wang, 2018 IEEE 16th Intl Conf on Dependable, Autonomic and Secure Computing, 16th Intl Conf on Pervasive Intelligence and Computing, 4th Intl Conf on Big Data Intelligence and Computing and Cyber Science and Technology Congress. </p>
<p>Robust log-based anomaly detection on unstable log data. X Zhang, Y Xu, Q Lin, B Qiao, H Zhang, Y Dang, C Xie, X Yang, Q Cheng, Z Li, Proceedings of the 2019 27th ACM joint meeting on European software engineering conference and symposium on the foundations of software engineering. the 2019 27th ACM joint meeting on European software engineering conference and symposium on the foundations of software engineering2019</p>
<p>Loggd: Detecting anomalies from system logs with graph neural networks. Y Xie, H Zhang, M A Babar, 2022 IEEE 22nd International conference on software quality, reliability and security (QRS). IEEE2022</p>
<p>Trine: Syslog anomaly detection with three transformer encoders in one generative adversarial network. Z Zhao, W Niu, X Zhang, R Zhang, Z Yu, C Huang, Applied Intelligence. 5282022</p>
<p>Semi-supervised log-based anomaly detection via probabilistic label estimation. L Yang, J Chen, Z Wang, W Wang, J Jiang, X Dong, W Zhang, 2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE). IEEE2021</p>
<p>Long short-term memory. S Hochreiter, 1997Neural Computation MIT-Press</p>
<p>Attention is all you need. A Vaswani, Advances in Neural Information Processing Systems. 2017</p>
<p>J Achiam, S Adler, S Agarwal, L Ahmad, I Akkaya, F L Aleman, D Almeida, J Altenschmidt, S Altman, S Anadkat, arXiv:2303.08774Gpt-4 technical report. 2023arXiv preprint</p>
<p>The llama 3 herd of models. A Dubey, A Jauhri, A Pandey, A Kadian, A Al-Dahle, A Letman, A Mathur, A Schelten, A Yang, A Fan, arXiv:2407.217832024arXiv preprint</p>
<p>T Glm, A Zeng, B Xu, B Wang, C Zhang, D Yin, D Rojas, G Feng, H Zhao, H Lai, arXiv:2406.12793Chatglm: A family of large language models from glm-130b to glm-4 all tools. 2024arXiv preprint</p>
<p>Dabl: Detecting semantic anomalies in business processes using large language models. W Guan, J Cao, J Gao, H Zhao, S Qian, arXiv:2406.157812024arXiv preprint</p>
<p>Logprompt: Prompt engineering towards zero-shot and interpretable log analysis. Y Liu, S Tao, W Meng, F Yao, X Zhao, H Yang, Proceedings of the 2024 IEEE/ACM 46th International Conference on Software Engineering: Companion Proceedings. the 2024 IEEE/ACM 46th International Conference on Software Engineering: Companion Proceedings2024</p>
<p>Early exploration of using chatgpt for log-based anomaly detection on parallel file systems logs. C Egersdoerfer, D Zhang, D Dai, Proceedings of the 32nd International Symposium on High-Performance Parallel and Distributed Computing. the 32nd International Symposium on High-Performance Parallel and Distributed Computing2023</p>
<p>Raglog: Log anomaly detection using retrieval augmented generation. J Pan, W S Liang, Y Yidi, 2024 IEEE World Forum on Public Safety Technology (WFPST). IEEE2024</p>
<p>Logbert: Log anomaly detection via bert. H Guo, S Yuan, X Wu, 2021 international joint conference on neural networks (IJCNN). IEEE2021</p>
<p>Lanobert: System log anomaly detection based on bert masked language model. Y Lee, J Kim, P Kang, Applied Soft Computing. 1461106892023</p>
<p>Fastlogad: Log anomaly detection with mask-guided pseudo anomaly generation and discrimination. Y Lin, H Deng, X Li, arXiv:2404.087502024arXiv preprint</p>
<p>Logfit: Log anomaly detection using fine-tuned language models. C Almodovar, F Sabrina, S Karimi, S Azad, IEEE Transactions on Network and Service Management. 2024</p>
<p>Bert-log: Anomaly detection for system logs based on pre-trained language model. S Chen, H Liao, Applied Artificial Intelligence. 36121456422022</p>
<p>Sarlog: Semantic-aware robust log anomaly detection via bert-augmented contrastive learning. J L Adeba, D.-H Kim, J Kwak, IEEE Internet of Things Journal. 2024</p>
<p>Mlog: Mogrifier lstm-based log anomaly detection approach using semantic representation. Y Fu, K Liang, J Xu, IEEE Transactions on Services Computing. 1652023</p>
<p>Training-free retrieval-based log anomaly detection with pre-trained language model considering tokenlevel information. G No, Y Lee, H Kang, P Kang, Engineering Applications of Artificial Intelligence. 1331086132024</p>
<p>Anomaly detection on unstable logs with gpt models. F Hadadi, Q Xu, D Bianculli, L Briand, arXiv:2406.074672024arXiv preprint</p>
<p>The working limitations of large language models. M Burtsev, M Reeves, A Job, MIT Sloan Management Review. 6522024</p>
<p>Fasttext. zip: Compressing text classification models. A Joulin, arXiv:1612.036512016arXiv preprint</p>
<p>Bert: Pre-training of deep bidirectional transformers for language understanding. J Devlin, arXiv:1810.048052018arXiv preprint</p>
<p>Roberta: A robustly optimized bert pretraining approach. Y Liu, arXiv:1907.116922019arXiv preprint</p>
<p>Spanbert: Improving pre-training by representing and predicting spans. M Joshi, D Chen, Y Liu, D S Weld, L Zettlemoyer, O Levy, Transactions of the association for computational linguistics. 82020</p>
<p>Retrievalaugmented generation for knowledge-intensive nlp tasks. P Lewis, E Perez, A Piktus, F Petroni, V Karpukhin, N Goyal, H Küttler, M Lewis, W -T. Yih, T Rocktäschel, Advances in Neural Information Processing Systems. 202033</p>
<p>Tools and benchmarks for automated log parsing. J Zhu, S He, J Liu, P He, Q Xie, Z Zheng, M R Lyu, 2019 IEEE/ACM 41st International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP). IEEE2019</p>
<p>An evaluation study on log parsing and its use in log mining. P He, J Zhu, S He, J Li, M R Lyu, 2016 46th annual IEEE/IFIP international conference on dependable systems and networks (DSN). </p>
<p>Online system problem detection by mining patterns of console logs. W Xu, L Huang, A Fox, D Patterson, M Jordan, 2009 ninth IEEE international conference on data mining. IEEE2009</p>
<p>What supercomputers say: A study of five system logs. A Oliner, J Stearley, 37th annual IEEE/IFIP international conference on dependable systems and networks (DSN'07. IEEE2007</p>
<p>Drain: An online log parsing approach with fixed depth tree. P He, J Zhu, Z Zheng, M R Lyu, 2017 IEEE international conference on web services (ICWS). IEEE2017</p>
<p>Spell: Streaming parsing of system event logs. M Du, F Li, 2016 IEEE 16th International Conference on Data Mining (ICDM). </p>
<p>Log parsing with prompt-based few-shot learning. V.-H Le, H Zhang, 2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE). IEEE2023</p>
<p>Probabilistic interpretation of feedforward classification network outputs, with relationships to statistical pattern recognition. J S Bridle, Neurocomputing: Algorithms, architectures and applications. Springer1990</p>
<p>Qlora: Efficient finetuning of quantized llms. T Dettmers, A Pagnoni, A Holtzman, L Zettlemoyer, Advances in Neural Information Processing Systems. 202436</p>
<p>Decoupled weight decay regularization. I Loshchilov, arXiv:1711.051012017arXiv preprint</p>
<p>Loghub: A large collection of system log datasets for ai-driven log analytics. J Zhu, S He, P He, J Liu, M R Lyu, 2023 IEEE 34th International Symposium on Software Reliability Engineering (ISSRE). </p>            </div>
        </div>

    </div>
</body>
</html>