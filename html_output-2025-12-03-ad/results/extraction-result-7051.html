<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-7051 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-7051</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-7051</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-131.html">extraction-schema-131</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' approaches to strict logical reasoning, including model details, reasoning methods, benchmarks, tasks, performance results, comparative findings, and noted limitations.</div>
                <p><strong>Paper ID:</strong> paper-5889e9afbcc3935867f9ae16fe46c71b9f2b071f</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/5889e9afbcc3935867f9ae16fe46c71b9f2b071f" target="_blank">End-to-end Differentiable Proving</a></p>
                <p><strong>Paper Venue:</strong> Neural Information Processing Systems</p>
                <p><strong>Paper TL;DR:</strong> It is demonstrated that this architecture outperforms ComplEx, a state-of-the-art neural link prediction model, on three out of four benchmark knowledge bases while at the same time inducing interpretable function-free first-order logic rules.</p>
                <p><strong>Paper Abstract:</strong> We introduce neural networks for end-to-end differentiable proving of queries to knowledge bases by operating on dense vector representations of symbols. These neural networks are constructed recursively by taking inspiration from the backward chaining algorithm as used in Prolog. Specifically, we replace symbolic unification with a differentiable computation on vector representations of symbols using a radial basis function kernel, thereby combining symbolic reasoning with learning subsymbolic vector representations. By using gradient descent, the resulting neural network can be trained to infer facts from a given incomplete knowledge base. It learns to (i) place representations of similar symbols in close proximity in a vector space, (ii) make use of such similarities to prove queries, (iii) induce logical rules, and (iv) use provided and induced logical rules for multi-hop reasoning. We demonstrate that this architecture outperforms ComplEx, a state-of-the-art neural link prediction model, on three out of four benchmark knowledge bases while at the same time inducing interpretable function-free first-order logic rules.</p>
                <p><strong>Cost:</strong> 0.017</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e7051.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e7051.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' approaches to strict logical reasoning, including model details, reasoning methods, benchmarks, tasks, performance results, comparative findings, and noted limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>NTP</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Neural Theorem Prover</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A neuro-symbolic, end-to-end differentiable prover that instantiates Prolog-style backward chaining as a recursive neural network over subsymbolic vector representations; uses an RBF-based soft unification to compare predicate/constant embeddings and learns function-free first-order rules via gradient descent.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Neural Theorem Prover (NTP)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Recursive neural module network implementing Prolog's OR/AND/backward-chaining; symbolic variable binding is retained while non-variable symbols are embedded and compared via an RBF kernel; proof success is aggregated with min/max operations producing differentiable scores used for gradient-based learning of embeddings and parameterized rule predicates.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>architecture_type</strong></td>
                            <td>neuro-symbolic; differentiable backward-chaining prover (recursive neural modules)</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>Knowledge-base completion splits used in paper: Countries (S1,S2,S3 tasks), Kinship (Alyawarra kinship), Nations, UMLS</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method</strong></td>
                            <td>Differentiable backward chaining with soft (RBF) unification on embeddings, multi-hop rule application, and gradient-based induction of parameterized function-free first-order rules</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_used</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>Countries (S1,S2,S3), Kinship, Nations, UMLS</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_description</strong></td>
                            <td>Countries: synthetic KB tasks designed to test multi-hop/transitive inference (three task variants removing varying amounts of location information); Kinship/Nations/UMLS: standard KBs for relation prediction and multi-hop reasoning / rule induction.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>Multi-hop logical deduction / knowledge-base completion and rule induction (function-free first-order rules)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>AUC-PR for Countries tasks; MRR and HITS@k for Kinship, Nations, UMLS</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>Countries S1 AUC-PR = 90.83 ± 15.4; S2 = 87.40 ± 11.7; S3 = 56.68 ± 17.6. Kinship: MRR = 0.60, HITS@1 = 0.48, HITS@3 = 0.70, HITS@10 = 0.78. Nations: MRR = 0.75, HITS@1 = 0.62, HITS@3 = 0.86, HITS@10 = 0.99. UMLS: MRR = 0.88, HITS@1 = 0.82, HITS@3 = 0.92, HITS@10 = 0.97.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>Vanilla NTP underperforms the ComplEx baseline on Kinship and UMLS, outperforms ComplEx on Countries S3 and some Nations metrics; overall improved substantially when combined with an auxiliary ComplEx loss (NTPλ).</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>NTPs can induce human-interpretable, function-free first-order rules and perform multi-hop reasoning by operating on embeddings and differentiable unification; however, learning good embeddings from unification alone is difficult, and performance is much improved when NTP is jointly trained with a local link-prediction model (ComplEx).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>High computational cost due to construction of all proofs up to depth (explosion of proof graph); requires approximations (K-max heuristic) and batch-proving to be practical; currently supports only function-free terms; uses cycle-detection heuristic that prevents reapplying same non-ground rule; learning embeddings from scratch via NTP alone is slow/unstable, necessitating auxiliary losses.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'End-to-end Differentiable Proving', 'publication_date_yy_mm': '2017-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7051.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e7051.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' approaches to strict logical reasoning, including model details, reasoning methods, benchmarks, tasks, performance results, comparative findings, and noted limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>NTPλ</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>NTP with ComplEx auxiliary loss (NTPλ)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An NTP variant jointly trained with the ComplEx neural link-prediction model that shares embeddings so that ComplEx provides an auxiliary local-scoring loss to speed and stabilize embedding learning for the differentiable prover.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>NTPλ (Neural Theorem Prover with ComplEx auxiliary)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Same NTP architecture but shares subsymbolic representations with ComplEx and is trained with a combined loss: NTP negative log-likelihood + ComplEx negative log-likelihood; RBF unification defined over complex embeddings when used.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>architecture_type</strong></td>
                            <td>neuro-symbolic NTP augmented with an embedding-based neural link-prediction auxiliary (ComplEx)</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>Countries (S1,S2,S3), Kinship, Nations, UMLS (same KB splits as NTP experiments)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method</strong></td>
                            <td>Differentiable backward chaining with RBF unification plus an auxiliary local triple-scoring objective (ComplEx) to improve embedding quality for multi-hop proofs and rule induction</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_used</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>Countries (S1,S2,S3), Kinship, Nations, UMLS</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_description</strong></td>
                            <td>See NTP entry; NTPλ evaluated on same KB completion and multi-hop inference tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>Multi-hop logical deduction / KB completion and rule induction</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>AUC-PR for Countries; MRR and HITS@k for Kinship, Nations, UMLS</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>Countries S1 AUC-PR = 100.00 ± 0.0; S2 = 93.04 ± 0.4; S3 = 77.26 ± 17.0. Kinship: MRR = 0.80, HITS@1 = 0.76, HITS@3 = 0.82, HITS@10 = 0.89. Nations: MRR = 0.74, HITS@1 = 0.59, HITS@3 = 0.89, HITS@10 = 0.99. UMLS: MRR = 0.93, HITS@1 = 0.87, HITS@3 = 0.98, HITS@10 = 1.00.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>NTPλ outperforms ComplEx on the majority of Countries tasks and UMLS, and shows statistically significant improvements on Countries tasks (p < 0.0001); overall best-performing variant in most evaluated settings.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Joint training with a local link-prediction objective (ComplEx) yields higher-quality embeddings that materially improve multi-hop reasoning and rule induction for the differentiable prover; NTPλ combines benefits of local scoring and explicit multi-hop symbolic structure.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Retains NTP's computational and scalability constraints; depends on the auxiliary model for embedding learning (i.e., not purely self-contained); still limited to function-free terms and uses approximation heuristics (K-max) for tractability.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'End-to-end Differentiable Proving', 'publication_date_yy_mm': '2017-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7051.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e7051.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' approaches to strict logical reasoning, including model details, reasoning methods, benchmarks, tasks, performance results, comparative findings, and noted limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ComplEx</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ComplEx (Complex embeddings for simple link prediction)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An embedding-based neural link-prediction model that represents entities and relations as complex-valued vectors and scores triples via a complex-bilinear form, able to model asymmetric relations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Complex embeddings for simple link prediction</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ComplEx</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Complex-valued embedding model scoring triples with inner products among real/imaginary parts; outputs sigmoid of bilinear score for triple plausibility; used both as a baseline link-prediction model and as an auxiliary loss for NTPλ.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>architecture_type</strong></td>
                            <td>embedding-based neural link-prediction (complex embeddings)</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>Countries (S1,S2,S3), Kinship, Nations, UMLS (used as baseline training/eval in this paper)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method</strong></td>
                            <td>Local triple scoring (no explicit multi-hop symbolic reasoning); generalization via embeddings that capture similarity and relation patterns</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_used</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>Countries (S1,S2,S3), Kinship, Nations, UMLS</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_description</strong></td>
                            <td>Same KB completion tasks as used for NTP/NTPλ evaluation; ComplEx evaluated as a strong neural baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>Knowledge-base completion (local triple scoring)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>AUC-PR for Countries; MRR and HITS@k for Kinship, Nations, UMLS</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>Countries S1 AUC-PR = 99.37 ± 0.4; S2 = 87.95 ± 2.8; S3 = 48.44 ± 6.3. Kinship: MRR = 0.81, HITS@1 = 0.70, HITS@3 = 0.89, HITS@10 = 0.98. Nations: MRR = 0.75, HITS@1 = 0.02, HITS@3 = 0.84, HITS@10 = 0.99. UMLS: MRR = 0.89, HITS@1 = 0.82, HITS@3 = 0.96, HITS@10 = 1.00.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>Serves as the primary baseline; strong at local scoring and competitive on several metrics, but lacks explicit multi-hop/transitive reasoning and interpretability that NTPs provide; also used to accelerate NTP embedding learning (NTPλ).</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>ComplEx is an effective local link-prediction model and provides useful auxiliary supervision for NTPλ; however it cannot directly induce or exploit explicit multi-hop rules (transitivity) in an interpretable way.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>No explicit symbolic multi-hop reasoning or rule induction; cannot easily incorporate domain rules for interpretable proofs; in experiments it cannot handle unary predicates (so unary atoms were removed).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'End-to-end Differentiable Proving', 'publication_date_yy_mm': '2017-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7051.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e7051.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' approaches to strict logical reasoning, including model details, reasoning methods, benchmarks, tasks, performance results, comparative findings, and noted limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>TensorLog</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>TensorLog (differentiable deductive database)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A differentiable deductive database system that compiles logical inference into sparse differentiable matrix operations enabling gradient-based learning of logical rules/weights.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Tensorlog: A differentiable deductive database</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>TensorLog</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Differentiable proof/inference engine that reduces certain Datalog-style inference computations to differentiable algebraic operations (sparse matrix ops) for scalable learning.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>architecture_type</strong></td>
                            <td>differentiable deductive database / neural-symbolic inference</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method</strong></td>
                            <td>Differentiable compilation of logical rules/inference to linear algebra operations</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_used</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>Mentioned as related: scalable differentiable inference for rule-based reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>Mentioned as related work and noted as more scalable than the NTP implementation in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>TensorLog exemplifies a differentiable approach to logical inference that scales better than the full end-to-end NTP construction used here.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Does not learn subsymbolic vector representations in the same end-to-end fashion as NTPs (different design trade-offs); specifics not evaluated in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'End-to-end Differentiable Proving', 'publication_date_yy_mm': '2017-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7051.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e7051.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' approaches to strict logical reasoning, including model details, reasoning methods, benchmarks, tasks, performance results, comparative findings, and noted limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Logic Tensor Networks</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Logic Tensor Networks (LTN)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A neuro-symbolic approach that integrates deep learning with logical constraints by grounding first-order logic formulas into real-valued loss functions, requiring grounding of formulas.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Logic tensor networks: Deep learning and logical reasoning from data and knowledge</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Logic Tensor Networks (LTN)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Approach that grounds first-order logic predicates and formulas into differentiable functions over real-valued vectors and optimizes them jointly with neural components.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>architecture_type</strong></td>
                            <td>neuro-symbolic; grounded first-order logic with neural components</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method</strong></td>
                            <td>Grounding of FOL formulas into differentiable losses and joint optimization</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_used</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>Mentioned as related work in differentiable neuro-symbolic reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>Positioned as conceptually similar but requiring full grounding of first-order rules (different scaling/expressivity trade-offs) compared to NTPs.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>LTNs show how logic can be integrated with deep learning but differ from NTPs in that they typically require grounding and do not operate via Prolog-style backward chaining on embeddings.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Needs full grounding of formulas (scalability concern); supports function terms while NTP (as implemented in this paper) currently does not.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'End-to-end Differentiable Proving', 'publication_date_yy_mm': '2017-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Tensorlog: A differentiable deductive database <em>(Rating: 2)</em></li>
                <li>Complex embeddings for simple link prediction <em>(Rating: 2)</em></li>
                <li>Differentiable learning of logical rules for knowledge base completion <em>(Rating: 2)</em></li>
                <li>Logic tensor networks: Deep learning and logical reasoning from data and knowledge <em>(Rating: 2)</em></li>
                <li>Neural prolog-the concepts, construction and mechanism <em>(Rating: 1)</em></li>
                <li>Unification neural networks: unification by error-correction learning <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-7051",
    "paper_id": "paper-5889e9afbcc3935867f9ae16fe46c71b9f2b071f",
    "extraction_schema_id": "extraction-schema-131",
    "extracted_data": [
        {
            "name_short": "NTP",
            "name_full": "Neural Theorem Prover",
            "brief_description": "A neuro-symbolic, end-to-end differentiable prover that instantiates Prolog-style backward chaining as a recursive neural network over subsymbolic vector representations; uses an RBF-based soft unification to compare predicate/constant embeddings and learns function-free first-order rules via gradient descent.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Neural Theorem Prover (NTP)",
            "model_description": "Recursive neural module network implementing Prolog's OR/AND/backward-chaining; symbolic variable binding is retained while non-variable symbols are embedded and compared via an RBF kernel; proof success is aggregated with min/max operations producing differentiable scores used for gradient-based learning of embeddings and parameterized rule predicates.",
            "model_size": null,
            "architecture_type": "neuro-symbolic; differentiable backward-chaining prover (recursive neural modules)",
            "training_data": "Knowledge-base completion splits used in paper: Countries (S1,S2,S3 tasks), Kinship (Alyawarra kinship), Nations, UMLS",
            "reasoning_method": "Differentiable backward chaining with soft (RBF) unification on embeddings, multi-hop rule application, and gradient-based induction of parameterized function-free first-order rules",
            "external_tool_used": false,
            "external_tool_description": null,
            "benchmark_name": "Countries (S1,S2,S3), Kinship, Nations, UMLS",
            "benchmark_description": "Countries: synthetic KB tasks designed to test multi-hop/transitive inference (three task variants removing varying amounts of location information); Kinship/Nations/UMLS: standard KBs for relation prediction and multi-hop reasoning / rule induction.",
            "task_type": "Multi-hop logical deduction / knowledge-base completion and rule induction (function-free first-order rules)",
            "performance_metric": "AUC-PR for Countries tasks; MRR and HITS@k for Kinship, Nations, UMLS",
            "performance_value": "Countries S1 AUC-PR = 90.83 ± 15.4; S2 = 87.40 ± 11.7; S3 = 56.68 ± 17.6. Kinship: MRR = 0.60, HITS@1 = 0.48, HITS@3 = 0.70, HITS@10 = 0.78. Nations: MRR = 0.75, HITS@1 = 0.62, HITS@3 = 0.86, HITS@10 = 0.99. UMLS: MRR = 0.88, HITS@1 = 0.82, HITS@3 = 0.92, HITS@10 = 0.97.",
            "comparison_with_baseline": "Vanilla NTP underperforms the ComplEx baseline on Kinship and UMLS, outperforms ComplEx on Countries S3 and some Nations metrics; overall improved substantially when combined with an auxiliary ComplEx loss (NTPλ).",
            "key_findings": "NTPs can induce human-interpretable, function-free first-order rules and perform multi-hop reasoning by operating on embeddings and differentiable unification; however, learning good embeddings from unification alone is difficult, and performance is much improved when NTP is jointly trained with a local link-prediction model (ComplEx).",
            "limitations": "High computational cost due to construction of all proofs up to depth (explosion of proof graph); requires approximations (K-max heuristic) and batch-proving to be practical; currently supports only function-free terms; uses cycle-detection heuristic that prevents reapplying same non-ground rule; learning embeddings from scratch via NTP alone is slow/unstable, necessitating auxiliary losses.",
            "uuid": "e7051.0",
            "source_info": {
                "paper_title": "End-to-end Differentiable Proving",
                "publication_date_yy_mm": "2017-05"
            }
        },
        {
            "name_short": "NTPλ",
            "name_full": "NTP with ComplEx auxiliary loss (NTPλ)",
            "brief_description": "An NTP variant jointly trained with the ComplEx neural link-prediction model that shares embeddings so that ComplEx provides an auxiliary local-scoring loss to speed and stabilize embedding learning for the differentiable prover.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "NTPλ (Neural Theorem Prover with ComplEx auxiliary)",
            "model_description": "Same NTP architecture but shares subsymbolic representations with ComplEx and is trained with a combined loss: NTP negative log-likelihood + ComplEx negative log-likelihood; RBF unification defined over complex embeddings when used.",
            "model_size": null,
            "architecture_type": "neuro-symbolic NTP augmented with an embedding-based neural link-prediction auxiliary (ComplEx)",
            "training_data": "Countries (S1,S2,S3), Kinship, Nations, UMLS (same KB splits as NTP experiments)",
            "reasoning_method": "Differentiable backward chaining with RBF unification plus an auxiliary local triple-scoring objective (ComplEx) to improve embedding quality for multi-hop proofs and rule induction",
            "external_tool_used": false,
            "external_tool_description": null,
            "benchmark_name": "Countries (S1,S2,S3), Kinship, Nations, UMLS",
            "benchmark_description": "See NTP entry; NTPλ evaluated on same KB completion and multi-hop inference tasks.",
            "task_type": "Multi-hop logical deduction / KB completion and rule induction",
            "performance_metric": "AUC-PR for Countries; MRR and HITS@k for Kinship, Nations, UMLS",
            "performance_value": "Countries S1 AUC-PR = 100.00 ± 0.0; S2 = 93.04 ± 0.4; S3 = 77.26 ± 17.0. Kinship: MRR = 0.80, HITS@1 = 0.76, HITS@3 = 0.82, HITS@10 = 0.89. Nations: MRR = 0.74, HITS@1 = 0.59, HITS@3 = 0.89, HITS@10 = 0.99. UMLS: MRR = 0.93, HITS@1 = 0.87, HITS@3 = 0.98, HITS@10 = 1.00.",
            "comparison_with_baseline": "NTPλ outperforms ComplEx on the majority of Countries tasks and UMLS, and shows statistically significant improvements on Countries tasks (p &lt; 0.0001); overall best-performing variant in most evaluated settings.",
            "key_findings": "Joint training with a local link-prediction objective (ComplEx) yields higher-quality embeddings that materially improve multi-hop reasoning and rule induction for the differentiable prover; NTPλ combines benefits of local scoring and explicit multi-hop symbolic structure.",
            "limitations": "Retains NTP's computational and scalability constraints; depends on the auxiliary model for embedding learning (i.e., not purely self-contained); still limited to function-free terms and uses approximation heuristics (K-max) for tractability.",
            "uuid": "e7051.1",
            "source_info": {
                "paper_title": "End-to-end Differentiable Proving",
                "publication_date_yy_mm": "2017-05"
            }
        },
        {
            "name_short": "ComplEx",
            "name_full": "ComplEx (Complex embeddings for simple link prediction)",
            "brief_description": "An embedding-based neural link-prediction model that represents entities and relations as complex-valued vectors and scores triples via a complex-bilinear form, able to model asymmetric relations.",
            "citation_title": "Complex embeddings for simple link prediction",
            "mention_or_use": "use",
            "model_name": "ComplEx",
            "model_description": "Complex-valued embedding model scoring triples with inner products among real/imaginary parts; outputs sigmoid of bilinear score for triple plausibility; used both as a baseline link-prediction model and as an auxiliary loss for NTPλ.",
            "model_size": null,
            "architecture_type": "embedding-based neural link-prediction (complex embeddings)",
            "training_data": "Countries (S1,S2,S3), Kinship, Nations, UMLS (used as baseline training/eval in this paper)",
            "reasoning_method": "Local triple scoring (no explicit multi-hop symbolic reasoning); generalization via embeddings that capture similarity and relation patterns",
            "external_tool_used": false,
            "external_tool_description": null,
            "benchmark_name": "Countries (S1,S2,S3), Kinship, Nations, UMLS",
            "benchmark_description": "Same KB completion tasks as used for NTP/NTPλ evaluation; ComplEx evaluated as a strong neural baseline.",
            "task_type": "Knowledge-base completion (local triple scoring)",
            "performance_metric": "AUC-PR for Countries; MRR and HITS@k for Kinship, Nations, UMLS",
            "performance_value": "Countries S1 AUC-PR = 99.37 ± 0.4; S2 = 87.95 ± 2.8; S3 = 48.44 ± 6.3. Kinship: MRR = 0.81, HITS@1 = 0.70, HITS@3 = 0.89, HITS@10 = 0.98. Nations: MRR = 0.75, HITS@1 = 0.02, HITS@3 = 0.84, HITS@10 = 0.99. UMLS: MRR = 0.89, HITS@1 = 0.82, HITS@3 = 0.96, HITS@10 = 1.00.",
            "comparison_with_baseline": "Serves as the primary baseline; strong at local scoring and competitive on several metrics, but lacks explicit multi-hop/transitive reasoning and interpretability that NTPs provide; also used to accelerate NTP embedding learning (NTPλ).",
            "key_findings": "ComplEx is an effective local link-prediction model and provides useful auxiliary supervision for NTPλ; however it cannot directly induce or exploit explicit multi-hop rules (transitivity) in an interpretable way.",
            "limitations": "No explicit symbolic multi-hop reasoning or rule induction; cannot easily incorporate domain rules for interpretable proofs; in experiments it cannot handle unary predicates (so unary atoms were removed).",
            "uuid": "e7051.2",
            "source_info": {
                "paper_title": "End-to-end Differentiable Proving",
                "publication_date_yy_mm": "2017-05"
            }
        },
        {
            "name_short": "TensorLog",
            "name_full": "TensorLog (differentiable deductive database)",
            "brief_description": "A differentiable deductive database system that compiles logical inference into sparse differentiable matrix operations enabling gradient-based learning of logical rules/weights.",
            "citation_title": "Tensorlog: A differentiable deductive database",
            "mention_or_use": "mention",
            "model_name": "TensorLog",
            "model_description": "Differentiable proof/inference engine that reduces certain Datalog-style inference computations to differentiable algebraic operations (sparse matrix ops) for scalable learning.",
            "model_size": null,
            "architecture_type": "differentiable deductive database / neural-symbolic inference",
            "training_data": null,
            "reasoning_method": "Differentiable compilation of logical rules/inference to linear algebra operations",
            "external_tool_used": false,
            "external_tool_description": null,
            "benchmark_name": null,
            "benchmark_description": null,
            "task_type": "Mentioned as related: scalable differentiable inference for rule-based reasoning",
            "performance_metric": null,
            "performance_value": null,
            "comparison_with_baseline": "Mentioned as related work and noted as more scalable than the NTP implementation in this paper.",
            "key_findings": "TensorLog exemplifies a differentiable approach to logical inference that scales better than the full end-to-end NTP construction used here.",
            "limitations": "Does not learn subsymbolic vector representations in the same end-to-end fashion as NTPs (different design trade-offs); specifics not evaluated in this paper.",
            "uuid": "e7051.3",
            "source_info": {
                "paper_title": "End-to-end Differentiable Proving",
                "publication_date_yy_mm": "2017-05"
            }
        },
        {
            "name_short": "Logic Tensor Networks",
            "name_full": "Logic Tensor Networks (LTN)",
            "brief_description": "A neuro-symbolic approach that integrates deep learning with logical constraints by grounding first-order logic formulas into real-valued loss functions, requiring grounding of formulas.",
            "citation_title": "Logic tensor networks: Deep learning and logical reasoning from data and knowledge",
            "mention_or_use": "mention",
            "model_name": "Logic Tensor Networks (LTN)",
            "model_description": "Approach that grounds first-order logic predicates and formulas into differentiable functions over real-valued vectors and optimizes them jointly with neural components.",
            "model_size": null,
            "architecture_type": "neuro-symbolic; grounded first-order logic with neural components",
            "training_data": null,
            "reasoning_method": "Grounding of FOL formulas into differentiable losses and joint optimization",
            "external_tool_used": false,
            "external_tool_description": null,
            "benchmark_name": null,
            "benchmark_description": null,
            "task_type": "Mentioned as related work in differentiable neuro-symbolic reasoning",
            "performance_metric": null,
            "performance_value": null,
            "comparison_with_baseline": "Positioned as conceptually similar but requiring full grounding of first-order rules (different scaling/expressivity trade-offs) compared to NTPs.",
            "key_findings": "LTNs show how logic can be integrated with deep learning but differ from NTPs in that they typically require grounding and do not operate via Prolog-style backward chaining on embeddings.",
            "limitations": "Needs full grounding of formulas (scalability concern); supports function terms while NTP (as implemented in this paper) currently does not.",
            "uuid": "e7051.4",
            "source_info": {
                "paper_title": "End-to-end Differentiable Proving",
                "publication_date_yy_mm": "2017-05"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Tensorlog: A differentiable deductive database",
            "rating": 2
        },
        {
            "paper_title": "Complex embeddings for simple link prediction",
            "rating": 2
        },
        {
            "paper_title": "Differentiable learning of logical rules for knowledge base completion",
            "rating": 2
        },
        {
            "paper_title": "Logic tensor networks: Deep learning and logical reasoning from data and knowledge",
            "rating": 2
        },
        {
            "paper_title": "Neural prolog-the concepts, construction and mechanism",
            "rating": 1
        },
        {
            "paper_title": "Unification neural networks: unification by error-correction learning",
            "rating": 1
        }
    ],
    "cost": 0.01749775,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>End-to-End Differentiable Proving</h1>
<p>Tim Rocktäschel<br>University of Oxford<br>tim.rocktaschel@cs.ox.ac.uk</p>
<p>Sebastian Riedel<br>University College London \&amp; Bloomsbury AI<br>s.riedel@cs.ucl.ac.uk</p>
<h4>Abstract</h4>
<p>We introduce neural networks for end-to-end differentiable proving of queries to knowledge bases by operating on dense vector representations of symbols. These neural networks are constructed recursively by taking inspiration from the backward chaining algorithm as used in Prolog. Specifically, we replace symbolic unification with a differentiable computation on vector representations of symbols using a radial basis function kernel, thereby combining symbolic reasoning with learning subsymbolic vector representations. By using gradient descent, the resulting neural network can be trained to infer facts from a given incomplete knowledge base. It learns to (i) place representations of similar symbols in close proximity in a vector space, (ii) make use of such similarities to prove queries, (iii) induce logical rules, and (iv) use provided and induced logical rules for multi-hop reasoning. We demonstrate that this architecture outperforms ComplEx, a state-of-the-art neural link prediction model, on three out of four benchmark knowledge bases while at the same time inducing interpretable function-free first-order logic rules.</p>
<h2>1 Introduction</h2>
<p>Current state-of-the-art methods for automated Knowledge Base (KB) completion use neural link prediction models to learn distributed vector representations of symbols (i.e. subsymbolic representations) for scoring fact triples [1-7]. Such subsymbolic representations enable these models to generalize to unseen facts by encoding similarities: If the vector of the predicate symbol grandfatherOf is similar to the vector of the symbol grandpaOf, both predicates likely express a similar relation. Likewise, if the vector of the constant symbol LISA is similar to MAGGIE, similar relations likely hold for both constants (e.g. they live in the same city, have the same parents etc.).
This simple form of reasoning based on similarities is remarkably effective for automatically completing large KBs. However, in practice it is often important to capture more complex reasoning patterns that involve several inference steps. For example, if ABE is the father of HOMER and HOMER is a parent of BART, we would like to infer that ABE is a grandfather of BART. Such transitive reasoning is inherently hard for neural link prediction models as they only learn to score facts locally. In contrast, symbolic theorem provers like Prolog [8] enable exactly this type of multi-hop reasoning. Furthermore, Inductive Logic Programming (ILP) [9] builds upon such provers to learn interpretable rules from data and to exploit them for reasoning in KBs. However, symbolic provers lack the ability to learn subsymbolic representations and similarities between them from large KBs, which limits their ability to generalize to queries with similar but not identical symbols.</p>
<p>While the connection between logic and machine learning has been addressed by statistical relational learning approaches, these models traditionally do not support reasoning with subsymbolic representations (e.g. [10]), and when using subsymbolic representations they are not trained end-to-end from training data (e.g. [11-13]). Neural multi-hop reasoning models [14-18] address the aforementioned limitations to some extent by encoding reasoning chains in a vector space or by iteratively refining subsymbolic representations of a question before comparison with answers. In many ways, these models operate like basic theorem provers, but they lack two of their most crucial ingredients:</p>
<p>interpretability and straightforward ways of incorporating domain-specific knowledge in form of rules.</p>
<p>Our approach to this problem is inspired by recent neural network architectures like Neural Turing Machines [19], Memory Networks [20], Neural Stacks/Queues [21, 22], Neural Programmer [23], Neural Programmer-Interpreters [24], Hierarchical Attentive Memory [25] and the Differentiable Forth Interpreter [26]. These architectures replace discrete algorithms and data structures by end-toend differentiable counterparts that operate on real-valued vectors. At the heart of our approach is the idea to translate this concept to basic symbolic theorem provers, and hence combine their advantages (multi-hop reasoning, interpretability, easy integration of domain knowledge) with the ability to reason with vector representations of predicates and constants. Specifically, we keep variable binding symbolic but compare symbols using their subsymbolic vector representations.</p>
<p>Concretely, we introduce Neural Theorem Provers (NTPs): End-to-end differentiable provers for basic theorems formulated as queries to a KB. We use Prolog's backward chaining algorithm as a recipe for recursively constructing neural networks that are capable of proving queries to a KB using subsymbolic representations. The success score of such proofs is differentiable with respect to vector representations of symbols, which enables us to learn such representations for predicates and constants in ground atoms, as well as parameters of function-free first-order logic rules of predefined structure. By doing so, NTPs learn to place representations of similar symbols in close proximity in a vector space and to induce rules given prior assumptions about the structure of logical relationships in a KB such as transitivity. Furthermore, NTPs can seamlessly reason with provided domain-specific rules. As NTPs operate on distributed representations of symbols, a single hand-crafted rule can be leveraged for many proofs of queries with symbols that have a similar representation. Finally, NTPs demonstrate a high degree of interpretability as they induce latent rules that we can decode to human-readable symbolic rules.</p>
<p>Our contributions are threefold: (i) We present the construction of NTPs inspired by Prolog's backward chaining algorithm and a differentiable unification operation using subsymbolic representations, (ii) we propose optimizations to this architecture by joint training with a neural link prediction model, batch proving, and approximate gradient calculation, and (iii) we experimentally show that NTPs can learn representations of symbols and function-free first-order rules of predefined structure, enabling them to learn to perform multi-hop reasoning on benchmark KBs and to outperform ComplEx [7], a state-of-the-art neural link prediction model, on three out of four KBs.</p>
<h1>2 Background</h1>
<p>In this section, we briefly introduce the syntax of KBs that we use in the remainder of the paper. We refer the reader to $[27,28]$ for a more in-depth introduction. An atom consists of a predicate symbol and a list of terms. We will use lowercase names to refer to predicate and constant symbols (e.g. fatherOf and BART), and uppercase names for variables (e.g. $\mathrm{X}, \mathrm{Y}, \mathrm{Z}$ ). As we only consider function-free first-order logic rules, a term can only be a constant or a variable. For instance, [grandfatherOf, $Q$, BART] is an atom with the predicate grandfatherOf, and two terms, the variable $Q$ and the constant BART. We consider rules of the form $\mathrm{H}:-\mathbb{B}$, where the body $\mathbb{B}$ is a possibly empty conjunction of atoms represented as a list, and the head H is an atom. We call a rule with no free variables a ground rule. All variables are universally quantified. We call a ground rule with an empty body a fact. A substitution set $\psi=\left{\mathrm{X}<em 1="1">{1} / t</em>}, \ldots, \mathrm{X<em N="N">{N} / t</em>}\right}$ is an assignment of variable symbols $\mathrm{X<em i="i">{i}$ to terms $t</em>}$, and applying substitutions to an atom replaces all occurrences of variables $\mathrm{X<em i="i">{i}$ by their respective term $t</em>$.</p>
<p>Given a query (also called goal) such as [grandfatherOf, $Q$, BART], we can use Prolog's backward chaining algorithm to find substitutions for $Q$ [8] (see appendix A for pseudocode). On a high level, backward chaining is based on two functions called OR and AND. OR iterates through all rules (including rules with an empty body, i.e., facts) in a KB and unifies the goal with the respective rule head, thereby updating a substitution set. It is called OR since any successful proof suffices (disjunction). If unification succeeds, OR calls AND to prove all atoms (subgoals) in the body of the rule. To prove subgoals of a rule body, AND first applies substitutions to the first atom that is then proven by again calling OR, before proving the remaining subgoals by recursively calling AND. This function is called AND as all atoms in the body need to be proven together (conjunction). As an example, a rule such as [grandfatherOf, $\mathrm{X}, \mathrm{Y}$ ] :- [[fatherOf, $\mathrm{X}, \mathrm{Z}$ ], [parentOf, $\mathrm{Z}, \mathrm{Y}$ ]] is used</p>
<p>in OR for translating a goal like [grandfatherOf, Q, BART] into subgoals [fatherOf, Q, Z] and [parentOf, Z, BART] that are subsequently proven by AND. ${ }^{1}$</p>
<h1>3 Differentiable Prover</h1>
<p>In the following, we describe the recursive construction of NTPs - neural networks for end-to-end differentiable proving that allow us to calculate the gradient of proof successes with respect to vector representations of symbols. We define the construction of NTPs in terms of modules similar to dynamic neural module networks [29]. Each module takes as inputs discrete objects (atoms and rules) and a proof state, and returns a list of new proof states (see Figure 1 for a graphical representation).</p>
<p>A proof state $S=(\psi, \rho)$ is a tuple consisting of the substitution set $\psi$ constructed in the proof so far and a neural network $\rho$ that outputs a real-valued success score of a (partial) proof. While discrete objects and the substitution set are only used during construction of the neural network, once the network is constructed a continuous proof success score can be calculated for many different goals at training and test time. To summarize, modules are instantiated by discrete objects and the substitution set. They construct a neural network representing the (partial) proof success score and recursively
<img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: A module is mapping an upstream proof state (left) to a list of new proof states (right), thereby extending the substitution set $S_{\psi}$ and adding nodes to the computation graph of the neural network $S_{\rho}$ representing the proof success.
instantiate submodules to continue the proof.
The shared signature of modules is $\mathcal{D} \times \mathcal{S} \rightarrow \mathcal{S}^{N}$ where $\mathcal{D}$ is a domain that controls the construction of the network, $\mathcal{S}$ is the domain of proof states, and $N$ is the number of output proof states. Furthermore, let $S_{\psi}$ denote the substitution set of the proof state $S$ and let $S_{\rho}$ denote the neural network for calculating the proof success.
We use pseudocode in style of a functional programming language to define the behavior of modules and auxiliary functions. Particularly, we are making use of pattern matching to check for properties of arguments passed to a module. We denote sets by Euler script letters (e.g. $\mathcal{E}$ ), lists by small capital letters (e.g. E), lists of lists by blackboard bold letters (e.g. $\mathbb{E}$ ) and we use : to refer to prepending an element to a list (e.g. $e: \mathrm{E}$ or $\mathrm{E}: \mathbb{E}$ ). While an atom is a list of a predicate symbol and terms, a rule can be seen as a list of atoms and thus a list of lists where the head of the list is the rule head. ${ }^{2}$</p>
<h3>3.1 Unification Module</h3>
<p>Unification of two atoms, e.g., a goal that we want to prove and a rule head, is a central operation in backward chaining. Two non-variable symbols (predicates or constants) are checked for equality and the proof can be aborted if this check fails. However, we want to be able to apply rules even if symbols in the goal and head are not equal but similar in meaning (e.g. grandfatherOf and grandpaOf) and thus replace symbolic comparison with a computation that measures the similarity of both symbols in a vector space.
The module unify updates a substitution set and creates a neural network for comparing the vector representations of non-variable symbols in two sequences of terms. The signature of this module is $\mathcal{L} \times \mathcal{L} \times \mathcal{S} \rightarrow \mathcal{S}$ where $\mathcal{L}$ is the domain of lists of terms. unify takes two atoms represented as lists of terms and an upstream proof state, and maps these to a new proof state (substitution set and proof success). To this end, unify iterates through the list of terms of two atoms and compares their symbols. If one of the symbols is a variable, a substitution is added to the substitution set. Otherwise, the vector representations of the two non-variable symbols are compared using a Radial Basis Function (RBF) kernel [30] where $\mu$ is a hyperparameter that we set to $\frac{1}{\sqrt{2}}$ in our experiments. The following pseudocode implements unify. Note that "_" matches every argument and that the</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>order matters, i.e., if arguments match a line, subsequent lines are not evaluated.</p>
<ol>
<li>$\operatorname{unify}_{\boldsymbol{\theta}}([],[], S)=S$</li>
<li>unify $\boldsymbol{\theta}\left([],<em -="-">{-},</em>$}\right)=\mathrm{FAIL</li>
<li>unify $\boldsymbol{\theta}\left(\left.\ldots,[],_{-}\right)=\right.$ FAIL</li>
<li>unify $\boldsymbol{\theta}\left(h: \mathrm{H}, g: \mathrm{G}, S\right)=\operatorname{unify}<em _psi="\psi">{\boldsymbol{\theta}}\left(\mathrm{H}, \mathrm{G}, S^{\prime}\right)=\left(S</em>\right)$ where}^{\prime}, S_{\rho}^{\prime</li>
</ol>
<p>$$
S_{\psi}^{\prime}=\left{\begin{array}{ll}
S_{\psi} \cup{h / g} &amp; \text { if } h \in \mathcal{V} \
S_{\psi} \cup{g / h} &amp; \text { if } g \in \mathcal{V}, h \notin \mathcal{V} \
S_{\psi} &amp; \text { otherwise }
\end{array}\right}, \quad S_{\rho}^{\prime}=\min \left(S_{\rho},\left{\begin{array}{ll}
\exp \left(\frac{-\left|\boldsymbol{\theta}<em g="g">{h},-\boldsymbol{\theta}</em> \
1 &amp; \text { otherwise }
\end{array}\right}\right)
$$}\right|_{2}}{2 \rho^{2}}\right) &amp; \text { if } h, g \notin \mathcal{V</p>
<p>Here, $S^{\prime}$ refers to the new proof state, $\mathcal{V}$ refers to the set of variable symbols, $h / g$ is a substitution from the variable symbol $h$ to the symbol $g$, and $\boldsymbol{\theta}_{g}$ denotes the embedding lookup of the non-variable symbol with index $g$. unify is parameterized by an embedding matrix $\boldsymbol{\theta} \in \mathbb{R}^{|\mathcal{Z}| \times k}$ where $\mathcal{Z}$ is the set of non-variables symbols and $k$ is the dimension of vector representations of symbols. Furthermore, FAIL represents a unification failure due to mismatching arity of two atoms. Once a failure is reached, we abort the creation of the neural network for this branch of proving. In addition, we constrain proofs to be cycle-free by checking whether a variable is already bound. Note that this is a simple heuristic that prohibits applying the same non-ground rule twice. There are more sophisticated ways for finding and avoiding cycles in a proof graph such that the same rule can still be applied multiple times (e.g. [31]), but we leave this for future work.</p>
<p>Example Assume that we are unifying two atoms [grandpaOf, ABE, BART] and $[s, \mathrm{Q}, i]$ given an upstream proof state $S=(\varnothing, \rho)$ where the latter input atom has placeholders for a predicate $s$ and a constant $i$, and the neural network $\rho$ would output 0.7 when evaluated. Furthermore, assume grandpaOf, ABE and BART represent the indices of the respective symbols in a global symbol vocabulary. Then, the new proof state constructed by unify is:</p>
<p>$$
\begin{aligned}
&amp; \text { unify }<em _psi="\psi">{\boldsymbol{\theta}}([\text { grandpaOf, ABE, BART }],[s, \mathrm{Q}, i],(\varnothing, \rho))=\left(S</em>\right)= \
&amp; \quad\left({\mathrm{Q} / \mathrm{ABE}}, \min \left(\rho, \exp \left(-\left|\boldsymbol{\theta}}^{\prime}, S_{\rho}^{\prime<em _=";" s="s">{\text {grandpaOf }}-\boldsymbol{\theta}</em>\right|<em _BART="{BART" _text="\text">{2}\right), \exp \left(-\left|\boldsymbol{\theta}</em>}}-\boldsymbol{\theta<em 2="2">{i ;}\right|</em>\right)\right)\right)
\end{aligned}
$$</p>
<p>Thus, the output score of the neural network $S_{\rho}^{\prime}$ will be high if the subsymbolic representation of the input $s$ is close to grandpaOf and the input $i$ is close to BART. However, the score cannot be higher than 0.7 due to the upstream proof success score in the forward pass of the neural network $\rho$. Note that in addition to extending the neural networks $\rho$ to $S_{\rho}^{\prime}$, this module also outputs a substitution set ${\mathrm{Q} / \mathrm{ABE}}$ at graph creation time that will be used to instantiate submodules.</p>
<h1>3.2 OR Module</h1>
<p>Based on unify, we now define the or module which attempts to apply rules in a KB. The signature of or is $\mathcal{L} \times \mathbb{N} \times \mathcal{S} \rightarrow \mathcal{S}^{N}$ where $\mathcal{L}$ is the domain of goal atoms and $\mathbb{N}$ is the domain of integers used for specifying the maximum proof depth of the neural network. Furthermore, $N$ is the number of possible output proof states for a goal of a given structure and a provided KB. ${ }^{3}$ We implement or as</p>
<ol>
<li>$\operatorname{or}<em _boldsymbol_theta="\boldsymbol{\theta">{\boldsymbol{\theta}}^{\mathcal{A}}(\mathrm{G}, d, S)=\left[S^{\prime} \mid S^{\prime} \in \operatorname{and}</em>\right]$
where $\mathrm{H}:-\mathbb{B}$ denotes a rule in a given KB $\mathfrak{K}$ with a head atom H and a list of body atoms $\mathbb{B}$. In contrast to the symbolic OR method, the or module is able to use the grandfatherOf rule above for a query involving grandpaOf provided that the subsymbolic representations of both predicates are similar as measured by the RBF kernel in the unify module.}}^{\mathcal{A}}(\mathbb{B}, d, \operatorname{unify}_{\boldsymbol{\theta}}(\mathrm{H}, \mathrm{G}, S)) \operatorname{for} \mathrm{H}:-\mathbb{B} \in \mathfrak{K</li>
</ol>
<p>Example For a goal $[s, \mathrm{Q}, i]$, or would instantiate an and submodule based on the rule [grandfatherOf, $\mathrm{X}, \mathrm{Y}]:-[[$ fatherOf, $\mathrm{X}, \mathrm{Z}],[$ parentOf, $\mathrm{Z}, \mathrm{Y}]$ ] as follows</p>
<p>$$
\operatorname{or}<em _boldsymbol_theta="\boldsymbol{\theta">{\boldsymbol{\theta}}^{\mathcal{A}}([s, \mathrm{Q}, i], d, S)=\left[S^{\prime} \mid S^{\prime} \in \operatorname{and}</em>\right)\right), \ldots]
$$}}^{\mathcal{A}}\left([[\text { fatherOf, } \mathrm{X}, \mathrm{Z}],[\text { parentOf, } \mathrm{Z}, \mathrm{Y}]\right], d,\left(\left{\mathrm{X} / \mathrm{Q}, \mathrm{Y} / i\right}, \hat{S}_{\rho</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<h1>3.3 AND Module</h1>
<p>For implementing and we first define an auxiliary function called substitute which applies substitutions to variables in an atom if possible. This is realized via</p>
<ol>
<li>substitute $([],_{-})=[]$</li>
<li>substitute $(g: \mathrm{G}, \psi)=\left{\begin{array}{ll}x &amp; \text { if } g / x \in \psi \ g &amp; \text { otherwise }\end{array}\right}$ : substitute $(\mathrm{G}, \psi)$</li>
</ol>
<p>For example, substitute $([\text { fatherOf }, \mathrm{X}, \mathrm{Z}],{\mathrm{X} / \mathrm{Q}, \mathrm{Y} / i})$ results in $[\text { fatherOf, } \mathrm{Q}, \mathrm{Z}]$.
The signature of and is $\mathcal{L} \times \mathbb{N} \times \mathcal{S} \rightarrow \mathcal{S}^{N}$ where $\mathcal{L}$ is the domain of lists of atoms and $N$ is the number of possible output proof states for a list of atoms with a known structure and a provided KB. This module is implemented as</p>
<ol>
<li>$\operatorname{and}_{\boldsymbol{\theta}}^{\mathcal{R}}(-, _, \mathrm{FAIL})=$ FAIL</li>
<li>$\operatorname{and}_{\boldsymbol{\theta}}^{\mathcal{R}}(-, 0, _\rangle=$FAIL</li>
<li>$\operatorname{and}<em -="-">{\boldsymbol{\theta}}^{\mathcal{R}}([],</em>, S)=S$</li>
<li>$\operatorname{and}<em _boldsymbol_theta="\boldsymbol{\theta">{\boldsymbol{\theta}}^{\mathcal{R}}(\mathrm{G}: \mathbb{G}, d, S)=\left[S^{\prime \prime} \mid S^{\prime \prime} \in \operatorname{and}</em>}}^{\mathcal{R}}\left(\mathbb{G}, d, S^{\prime}\right)\right.$ for $S^{\prime} \in \operatorname{or<em _psi="\psi">{\boldsymbol{\theta}}^{\mathcal{R}}\left(\right.$ substitute $\left(\mathrm{G}, S</em>\right), d-1, S)]$
where the first two lines define the failure of a proof, either because of an upstream unification failure that has been passed from the or module (line 1), or because the maximum proof depth has been reached (line 2). Line 3 specifies a proof success, i.e., the list of subgoals is empty before the maximum proof depth has been reached. Lastly, line 4 defines the recursion: The first subgoal G is proven by instantiating an or module after substitutions are applied, and every resulting proof state $S^{\prime}$ is used for proving the remaining subgoals $\mathbb{G}$ by again instantiating and modules.</li>
</ol>
<p>Example Continuing the example from Section 3.2, the and module would instantiate submodules as follows:</p>
<p>$$
\begin{aligned}
&amp; \operatorname{and}<em _rho="\rho">{\boldsymbol{\theta}}^{\mathcal{R}}\left(\left[\left[\text { fatherOf }, \mathrm{X}, \mathrm{Z}\right],\left[\text { parentOf }, \mathrm{Z}, \mathrm{Y}\right]\right], d,\left({\mathrm{X} / \mathrm{Q}, \mathrm{Y} / i}, \hat{S}</em>\right)\right)= \
&amp; \quad\left[S^{\prime \prime} \mid S^{\prime \prime} \in \operatorname{and}<em _boldsymbol_theta="\boldsymbol{\theta">{\boldsymbol{\theta}}^{\mathcal{R}}\left(\left[\left[\text { parentOf }, \mathrm{Z}, \mathrm{Y}\right]\right], d, S^{\prime}\right) \text { for } S^{\prime} \in \operatorname{or}</em>\right)\right)\right]
\end{aligned}
$$}}^{\mathcal{R}}\left(\left[\text { fatherOf }, \mathrm{Q}, \mathrm{Z}\right], d-1,\left({\mathrm{X} / \mathrm{Q}, \mathrm{Y} / i}, \hat{S}_{\rho</p>
<h3>3.4 Proof Aggregation</h3>
<p>Finally, we define the overall success score of proving a goal G using a KB $\mathfrak{K}$ with parameters $\boldsymbol{\theta}$ as</p>
<p>$$
\operatorname{ntp}<em _mathcal_R="\mathcal{R">{\boldsymbol{\theta}}^{\mathcal{R}}(\mathrm{G}, d)=\underset{\substack{\text { argmax } \
S \in \text { or }</em>
$$}}^{\mathcal{R}}(\mathrm{G}, d,(\varnothing, 1))}}{ } S_{\rho</p>
<p>where $d$ is a predefined maximum proof depth and the initial proof state is set to an empty substitution set and a proof success score of 1 .</p>
<p>Example Figure 2 illustrates an examplary NTP computation graph constructed for a toy KB. Note that such an NTP is constructed once before training, and can then be used for proving goals of the structure $[s, i, j]$ at training and test time where $s$ is the index of an input predicate, and $i$ and $j$ are indices of input constants. Final proof states which are used in proof aggregation are underlined.</p>
<h3>3.5 Neural Inductive Logic Programming</h3>
<p>We can use NTPs for ILP by gradient descent instead of a combinatorial search over the space of rules as, for example, done by the First Order Inductive Learner (FOIL) [32]. Specifically, we are using the concept of learning from entailment [9] to induce rules that let us prove known ground atoms, but that do not give high proof success scores to sampled unknown ground atoms.
Let $\boldsymbol{\theta}<em s:="s:">{r:}, \boldsymbol{\theta}</em>$ be representations of some unknown predicates with indices $r, s$ and $t$ respectively. The prior knowledge of a transitivity between three unknown predicates can be specified via}, \boldsymbol{\theta}_{t:} \in \mathbb{R}^{k</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: Exemplary construction of an NTP computation graph for a toy knowledge base. Indices on arrows correspond to application of the respective KB rule. Proof states (blue) are subscripted with the sequence of indices of the rules that were applied. Underlined proof states are aggregated to obtain the final proof success. Boxes visualize instantiations of modules (omitted for unify). The proofs $S_{33}, S_{313}$ and $S_{323}$ fail due to cycle-detection (the same rule cannot be applied twice).</p>
<p>$r(\mathrm{X}, \mathrm{Y}):-s(\mathrm{X}, \mathrm{Z}), t(\mathrm{Z}, \mathrm{Y})$. We call this a <em>parameterized rule</em> as the corresponding predicates are unknown and their representations are learned from data. Such a rule can be used for proofs at training and test time in the same way as any other given rule. During training, the predicate representations of parameterized rules are optimized jointly with all other subsymbolic representations. Thus, the model can adapt parameterized rules such that proofs for known facts succeed while proofs for sampled unknown ground atoms fail, thereby inducing rules of predefined structures like the one above. Inspired by [33], we use rule templates for conveniently defining the structure of multiple parameterized rules by specifying the number of parameterized rules that should be instantiated for a given rule structure (see appendix E for examples). For inspection after training, we decode a parameterized rule by searching for the closest representations of known predicates. In addition, we provide users with a rule confidence by taking the minimum similarity between unknown and decoded predicate representations using the RBF kernel in unify. This confidence score is an upper bound on the proof success score that can be achieved when the induced rule is used in proofs.</p>
<h2>4 Optimization</h2>
<p>In this section, we present the basic training loss that we use for NTPs, a training loss where a neural link prediction models is used as auxiliary task, as well as various computational optimizations.</p>
<h3>4.1 Training Objective</h3>
<p>Let $\mathcal{K}$ be the set of known facts in a given KB. Usually, we do not observe negative facts and thus resort to sampling corrupted ground atoms as done in previous work [34]. Specifically, for every $[s, i, j] \in \mathcal{K}$ we obtain corrupted ground atoms $[s, \hat{i}, j],[s, i, \hat{j}],[s, \hat{i}, \hat{j}] \notin \mathcal{K}$ by sampling $i, \hat{j}, \hat{i}$ and $\hat{j}$ from the set of constants. These corrupted ground atoms are resampled in every iteration of training, and we denote the set of known and corrupted ground atoms together with their target score (1.0 for known ground atoms and 0.0 for corrupted ones) as $\mathcal{T}$. We use the negative log-likelihood of the proof success score as loss function for an NTP with parameters $\boldsymbol{\theta}$ and a given KB $\mathcal{K}$</p>
<p>$$
\mathcal{L}<em _boldsymbol_theta="\boldsymbol{\theta">{\text {ntp }</em>}}^{\mathcal{K}}}=\sum_{([s, i, j], y) \in \mathcal{T}}-y \log (\text { ntp <em _rho="\rho">{\boldsymbol{\theta}}^{\mathcal{K}}([s, i, j], d)</em>})-(1-y) \log (1-\text { ntp <em _rho="\rho">{\boldsymbol{\theta}}^{\mathcal{K}}([s, i, j], d)</em>)
$$</p>
<p>where $[s, i, j]$ is a training ground atom and $y$ its target proof success score. Note that since in our application all training facts are ground atoms, we only make use of the proof success score $\rho$ and not</p>
<p>the substitution list of the resulting proof state. We can prove known facts trivially by a unification with themselves, resulting in no parameter updates during training and hence no generalization. Therefore, during training we are masking the calculation of the unification success of a known ground atom that we want to prove. Specifically, we set the unification score to 0 to temporarily hide that training fact and assume it can be proven from other facts and rules in the KB.</p>
<h1>4.2 Neural Link Prediction as Auxiliary Loss</h1>
<p>At the beginning of training all subsymbolic representations are initialized randomly. When unifying a goal with all facts in a KB we consequently get very noisy success scores in early stages of training. Moreover, as only the maximum success score will result in gradient updates for the respective subsymbolic representations along the maximum proof path, it can take a long time until NTPs learn to place similar symbols close to each other in the vector space and to make effective use of rules.</p>
<p>To speed up learning subsymbolic representations, we train NTPs jointly with ComplEx [7] (Appendix B). ComplEx and the NTP share the same subsymbolic representations, which is feasible as the RBF kernel in unify is also defined for complex vectors. While the NTP is responsible for multi-hop reasoning, the neural link prediction model learns to score ground atoms locally. At test time, only the NTP is used for predictions. Thus, the training loss for ComplEx can be seen as an auxiliary loss for the subsymbolic representations learned by the NTP. We term the resulting model NTP $\lambda$. Based on the loss in Section 4.1, the joint training loss is defined as
$\mathcal{L}<em _boldsymbol_theta="\boldsymbol{\theta">{\text {ntp } \lambda</em>}}^{g}}=\mathcal{L<em _boldsymbol_theta="\boldsymbol{\theta">{\text {ntp }</em>}}^{g}}+\sum_{([s, i, j], y) \in \mathcal{T}}-y \log \left(\operatorname{complex<em _boldsymbol_theta="\boldsymbol{\theta">{\boldsymbol{\theta}}(s, i, j)\right)-(1-y) \log \left(1-\operatorname{complex}</em>(s, i, j)\right)$
where $[s, i, j]$ is a training atom and $y$ its ground truth target.}</p>
<h3>4.3 Computational Optimizations</h3>
<p>NTPs as described above suffer from severe computational limitations since the neural network is representing all possible proofs up to some predefined depth. In contrast to symbolic backward chaining where a proof can be aborted as soon as unification fails, in differentiable proving we only get a unification failure for atoms whose arity does not match or when we detect cyclic rule application. We propose two optimizations to speed up NTPs in the Appendix. First, we make use of modern GPUs by batch processing many proofs in parallel (Appendix C). Second, we exploit the sparseness of gradients caused by the min and max operations used in the unification and proof aggregation respectively to derive a heuristic for a truncated forward and backward pass that drastically reduces the number of proofs that have to be considered for calculating gradients (Appendix D).</p>
<h2>5 Experiments</h2>
<p>Consistent with previous work, we carry out experiments on four benchmark KBs and compare ComplEx with the NTP and NTP $\lambda$ in terms of area under the Precision-Recall-curve (AUC-PR) on the Countries KB, and Mean Reciprocal Rank (MRR) and HITS@m [34] on the other KBs described below. Training details, including hyperparameters and rule templates, can be found in Appendix E.</p>
<p>Countries The Countries KB is a dataset introduced by [35] for testing reasoning capabilities of neural link prediction models. It consists of 244 countries, 5 regions (e.g. EUROPE), 23 subregions (e.g. WESTERN EUROPE, NORTHERN AMERICA), and 1158 facts about the neighborhood of countries, and the location of countries and subregions. We follow [36] and split countries randomly into a training set of 204 countries (train), a development set of 20 countries (dev), and a test set of 20 countries (test), such that every dev and test country has at least one neighbor in the training set. Subsequently, three different task datasets are created. For all tasks, the goal is to predict $\operatorname{locatedIn}(c, r)$ for every test country $c$ and all five regions $r$, but the access to training atoms in the KB varies.
S1: All ground atoms locatedIn $(c, r)$ where $c$ is a test country and $r$ is a region are removed from the KB. Since information about the subregion of test countries is still contained in the KB, this task can be solved by using the transitivity rule $\operatorname{locatedIn}(\mathrm{X}, \mathrm{Y}):-\operatorname{locatedIn}(\mathrm{X}, \mathrm{Z}), \operatorname{locatedIn}(\mathrm{Z}, \mathrm{Y})$.
S2: In addition to S1, all ground atoms locatedIn $(c, s)$ are removed where $c$ is a test country and $s$</p>
<p>Table 1: AUC-PR results on Countries and MRR and HITS@m on Kinship, Nations, and UMLS.</p>
<table>
<thead>
<tr>
<th>Corpus</th>
<th></th>
<th>Metric</th>
<th>Model</th>
<th></th>
<th></th>
<th>Examples of induced rules and their confidence</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td></td>
<td></td>
<td>ComplEx</td>
<td>NTP</td>
<td>NTP $\lambda$</td>
<td></td>
</tr>
<tr>
<td>Countries</td>
<td>S1</td>
<td>AUC-PR</td>
<td>$99.37 \pm 0.4$</td>
<td>$90.83 \pm 15.4$</td>
<td>$\mathbf{1 0 0 . 0 0} \pm 0.0$</td>
<td>0.90 locatedIn(X,Y) $:=$ locatedIn(X,Z), locatedIn(Z,Y).</td>
</tr>
<tr>
<td></td>
<td>S2</td>
<td>AUC-PR</td>
<td>$87.95 \pm 2.8$</td>
<td>$87.40 \pm 11.7$</td>
<td>$\mathbf{9 3 . 0 4} \pm 0.4$</td>
<td>0.63 locatedIn(X,Y) $:=$ neighborOf(X,Z), locatedIn(Z,Y).</td>
</tr>
<tr>
<td></td>
<td>S3</td>
<td>AUC-PR</td>
<td>$48.44 \pm 6.3$</td>
<td>$56.68 \pm 17.6$</td>
<td>$\mathbf{7 7 . 2 6} \pm 17.0$</td>
<td>0.32 locatedIn(X,Y) $:=$</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>neighborOf(X,Z), neighborOf(Z,W), locatedIn(W,Y).</td>
</tr>
<tr>
<td>Kinship</td>
<td></td>
<td>MRR</td>
<td>$\mathbf{0 . 8 1}$</td>
<td>0.60</td>
<td>0.80</td>
<td>0.98 term1b(X,Y) $:=$ term6(X,X)</td>
</tr>
<tr>
<td></td>
<td></td>
<td>HITS@1</td>
<td>0.70</td>
<td>0.48</td>
<td>$\mathbf{0 . 7 6}$</td>
<td>0.97 term18(X,Y) $:=$ term18(X,X)</td>
</tr>
<tr>
<td></td>
<td></td>
<td>HITS@3</td>
<td>$\mathbf{0 . 8 9}$</td>
<td>0.70</td>
<td>0.82</td>
<td>0.86 term4(X,Y) $:=$ term4(X,X)</td>
</tr>
<tr>
<td></td>
<td></td>
<td>HITS@10</td>
<td>$\mathbf{0 . 9 8}$</td>
<td>0.78</td>
<td>0.89</td>
<td>0.73 term12(X,Y) $:=$ term10(X, Z), term12(Z, Y).</td>
</tr>
<tr>
<td>Nations</td>
<td></td>
<td>MRR</td>
<td>$\mathbf{0 . 7 5}$</td>
<td>$\mathbf{0 . 7 5}$</td>
<td>0.74</td>
<td>0.68 blockpositionindex(X,Y) $:=$ blockpositionindex(Y,X).</td>
</tr>
<tr>
<td></td>
<td></td>
<td>HITS@1</td>
<td>$\mathbf{0 . 0 2}$</td>
<td>$\mathbf{0 . 6 2}$</td>
<td>0.59</td>
<td>0.46 expeldiplomate(X,Y) $:=$ negativebehavior(X,Y).</td>
</tr>
<tr>
<td></td>
<td></td>
<td>HITS@3</td>
<td>0.84</td>
<td>0.86</td>
<td>$\mathbf{0 . 8 9}$</td>
<td>0.38 negativecomm(X,Y) $:=$ commonbloc0(X,Y).</td>
</tr>
<tr>
<td></td>
<td></td>
<td>HITS@10</td>
<td>$\mathbf{0 . 9 9}$</td>
<td>$\mathbf{0 . 9 9}$</td>
<td>$\mathbf{0 . 9 9}$</td>
<td>0.38 intergovorgx3(X,Y) $:=$ intergovorge(Y,X).</td>
</tr>
<tr>
<td>UMLS</td>
<td></td>
<td>MRR</td>
<td>0.89</td>
<td>0.88</td>
<td>$\mathbf{0 . 9 3}$</td>
<td>0.88 interacts_with(X,Y) $:$</td>
</tr>
<tr>
<td></td>
<td></td>
<td>HITS@1</td>
<td>0.82</td>
<td>0.82</td>
<td>$\mathbf{0 . 8 7}$</td>
<td>interacts_with(X,Z), interacts_with(Z,Y).</td>
</tr>
<tr>
<td></td>
<td></td>
<td>HITS@3</td>
<td>0.96</td>
<td>0.92</td>
<td>$\mathbf{0 . 9 8}$</td>
<td>0.77 issx(X,Y) $:=$ issx(X,Z), issx(Z,Y).</td>
</tr>
<tr>
<td></td>
<td></td>
<td>HITS@10</td>
<td>$\mathbf{1 . 0 0}$</td>
<td>0.97</td>
<td>$\mathbf{1 . 0 0}$</td>
<td>0.71 derivative_of(X,Y) $:=$</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>derivative_of(X,Z), derivative_of(Z,Y).</td>
</tr>
</tbody>
</table>
<p>is a subregion. The location of test countries needs to be inferred from the location of its neighboring countries: locatedIn(X, Y) $:=$ neighborOf $(\mathrm{X}, \mathrm{Z})$, locatedIn $(\mathrm{Z}, \mathrm{Y})$. This task is more difficult than $\mathbf{S 1}$, as neighboring countries might not be in the same region, so the rule above will not always hold.
S3: In addition to S2, all ground atoms locatedIn $(c, r)$ where $r$ is a region and $c$ is a training country that has a test or dev country as a neighbor are also removed. The location of test countries can for instance be inferred using the three-hop rule locatedIn(X, Y) $:=$ neighborOf $(\mathrm{X}, \mathrm{Z})$, neighborOf $(\mathrm{Z}, \mathrm{W})$, locatedIn $(\mathrm{W}, \mathrm{Y})$.</p>
<p>Kinship, Nations \&amp; UMLS We use the Nations, Alyawarra kinship (Kinship) and Unified Medical Language System (UMLS) KBs from [10]. We left out the Animals dataset as it only contains unary predicates and can thus not be used for evaluating multi-hop reasoning. Nations contains 56 binary predicates, 111 unary predicates, 14 constants and 2565 true facts, Kinship contains 26 predicates, 104 constants and 10686 true facts, and UMLS contains 49 predicates, 135 constants and 6529 true facts. Since our baseline ComplEx cannot deal with unary predicates, we remove unary atoms from Nations. We split every KB into $80 \%$ training facts, $10 \%$ development facts and $10 \%$ test facts. For evaluation, we take a test fact and corrupt its first and second argument in all possible ways such that the corrupted fact is not in the original KB. Subsequently, we predict a ranking of every test fact and its corruptions to calculate MRR and HITS@m.</p>
<h1>6 Results and Discussion</h1>
<p>Results for the different model variants on the benchmark KBs are shown in Table 1. Another method for inducing rules in a differentiable way for automated KB completion has been introduced recently by [37] and our evaluation setup is equivalent to their Protocol II. However, our neural link prediction baseline, ComplEx, already achieves much higher HITS@10 results ( 1.00 vs. 0.70 on UMLS and 0.98 vs. 0.73 on Kinship). We thus focus on the comparison of NTPs with ComplEx.</p>
<p>First, we note that vanilla NTPs alone do not work particularly well compared to ComplEx. They only outperform ComplEx on Countries S3 and Nations, but not on Kinship or UMLS. This demonstrates the difficulty of learning subsymbolic representations in a differentiable prover from unification alone, and the need for auxiliary losses. The NTP $\lambda$ with ComplEx as auxiliary loss outperforms the other models in the majority of tasks. The difference in AUC-PR between ComplEx and NTP $\lambda$ is significant for all Countries tasks $(p&lt;0.0001)$.
A major advantage of NTPs is that we can inspect induced rules which provide us with an interpretable representation of what the model has learned. The right column in Table 1 shows examples of induced rules by NTP $\lambda$ (note that predicates on Kinship are anonymized). For Countries, the NTP recovered those rules that are needed for solving the three different tasks. On UMLS, the NTP induced transitivity rules. Those relationships are particularly hard to encode by neural link prediction models like ComplEx, as they are optimized to locally predict the score of a fact.</p>
<h1>7 Related Work</h1>
<p>Combining neural and symbolic approaches to relational learning and reasoning has a long tradition and let to various proposed architectures over the past decades (see [38] for a review). Early proposals for neural-symbolic networks are limited to propositional rules (e.g., EBL-ANN [39], KBANN [40] and C-IL ${ }^{2} \mathrm{P}$ [41]). Other neural-symbolic approaches focus on first-order inference, but do not learn subsymbolic vector representations from training facts in a KB (e.g., SHRUTI [42], Neural Prolog [43], CLIP++ [44], Lifted Relational Neural Networks [45], and TensorLog [46]). Logic Tensor Networks [47] are in spirit similar to NTPs, but need to fully ground first-order logic rules. However, they support function terms, whereas NTPs currently only support function-free terms.
Recent question-answering architectures such as $[15,17,18]$ translate query representations implicitly in a vector space without explicit rule representations and can thus not easily incorporate domainspecific knowledge. In addition, NTPs are related to random walk [48, 49, 11, 12] and path encoding models [14, 16]. However, instead of aggregating paths from random walks or encoding paths to predict a target predicate, reasoning steps in NTPs are explicit and only unification uses subsymbolic representations. This allows us to induce interpretable rules, as well as to incorporate prior knowledge either in the form of rules or in the form of rule templates which define the structure of logical relationships that we expect to hold in a KB. Another line of work [50-54] regularizes distributed representations via domain-specific rules, but these approaches do not learn such rules from data and only support a restricted subset of first-order logic. NTPs are constructed from Prolog's backward chaining and are thus related to Unification Neural Networks [55, 56]. However, NTPs operate on vector representations of symbols instead of scalar values, which are more expressive.
As NTPs can learn rules from data, they are related to ILP systems such as FOIL [32], Sherlock [57] and meta-interpretive learning of higher-order dyadic Datalog (Metagol) [58]. While these ILP systems operate on symbols and search over the discrete space of logical rules, NTPs work with subsymbolic representations and induce rules using gradient descent. Recently, [37] introduced a differentiable rule learning system based on TensorLog and a neural network controller similar to LSTMs [59]. Their method is more scalable than the NTPs introduced here. However, on UMLS and Kinship our baseline already achieved stronger generalization by learning subsymbolic representations. Still, scaling NTPs to larger KBs for competing with more scalable relational learning methods is an open problem that we seek to address in future work.</p>
<h2>8 Conclusion and Future Work</h2>
<p>We proposed an end-to-end differentiable prover for automated KB completion that operates on subsymbolic representations. To this end, we used Prolog's backward chaining algorithm as a recipe for recursively constructing neural networks that can be used to prove queries to a KB. Specifically, we introduced a differentiable unification operation between vector representations of symbols. The constructed neural network allowed us to compute the gradient of proof successes with respect to vector representations of symbols, and thus enabled us to train subsymbolic representations end-toend from facts in a KB, and to induce function-free first-order logic rules using gradient descent. On benchmark KBs, our model outperformed ComplEx, a state-of-the-art neural link prediction model, on three out of four KBs while at the same time inducing interpretable rules.
To overcome the computational limitations of the end-to-end differentiable prover introduced in this paper, we want to investigate the use of hierarchical attention [25] and reinforcement learning methods such as Monte Carlo tree search [60, 61] that have been used for learning to play Go [62] and chemical synthesis planning [63]. In addition, we plan to support function terms in the future. Based on [64], we are furthermore interested in applying NTPs to automated proving of mathematical theorems, either in logical or natural language form, similar to recent approaches by [65] and [66].</p>
<h2>Acknowledgements</h2>
<p>We thank Pasquale Minervini, Tim Dettmers, Matko Bosnjak, Johannes Welbl, Naoya Inoue, Kai Arulkumaran, and the anonymous reviewers for very helpful comments on drafts of this paper. This work has been supported by a Google PhD Fellowship in Natural Language Processing, an Allen Distinguished Investigator Award, and a Marie Curie Career Integration Award.</p>
<h1>References</h1>
<p>[1] Maximilian Nickel, Volker Tresp, and Hans-Peter Kriegel. Factorizing YAGO: scalable machine learning for linked data. In Proceedings of the 21st World Wide Web Conference 2012, WWW 2012, Lyon, France, April 16-20, 2012, pages 271-280, 2012. doi: 10.1145/2187836.2187874.
[2] Sebastian Riedel, Limin Yao, Andrew McCallum, and Benjamin M. Marlin. Relation extraction with matrix factorization and universal schemas. In Human Language Technologies: Conference of the North American Chapter of the Association of Computational Linguistics, Proceedings, June 9-14, 2013, Westin Peachtree Plaza Hotel, Atlanta, Georgia, USA, pages 74-84, 2013.
[3] Richard Socher, Danqi Chen, Christopher D. Manning, and Andrew Y. Ng. Reasoning with neural tensor networks for knowledge base completion. In Advances in Neural Information Processing Systems 26: 27th Annual Conference on Neural Information Processing Systems 2013. Proceedings of a meeting held December 5-8, 2013, Lake Tahoe, Nevada, United States., pages 926-934, 2013.
[4] Kai-Wei Chang, Wen-tau Yih, Bishan Yang, and Christopher Meek. Typed tensor decomposition of knowledge bases for relation extraction. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing, EMNLP 2014, October 25-29, 2014, Doha, Qatar, A meeting of SIGDAT, a Special Interest Group of the ACL, pages 1568-1579, 2014.
[5] Bishan Yang, Wen-tau Yih, Xiaodong He, Jianfeng Gao, and Li Deng. Embedding entities and relations for learning and inference in knowledge bases. In International Conference on Learning Representations (ICLR), 2015.
[6] Kristina Toutanova, Danqi Chen, Patrick Pantel, Hoifung Poon, Pallavi Choudhury, and Michael Gamon. Representing text for joint embedding of text and knowledge bases. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, EMNLP 2015, Lisbon, Portugal, September 17-21, 2015, pages 1499-1509, 2015.
[7] Théo Trouillon, Johannes Welbl, Sebastian Riedel, Éric Gaussier, and Guillaume Bouchard. Complex embeddings for simple link prediction. In Proceedings of the 33nd International Conference on Machine Learning, ICML 2016, New York City, NY, USA, June 19-24, 2016, pages 2071-2080, 2016.
[8] Hervé Gallaire and Jack Minker, editors. Logic and Data Bases, Symposium on Logic and Data Bases, Centre d'études et de recherches de Toulouse, 1977, Advances in Data Base Theory, New York, 1978. Plemum Press. ISBN 0-306-40060-X.
[9] Stephen Muggleton. Inductive logic programming. New Generation Comput., 8(4):295-318, 1991. doi: 10.1007/BF03037089.
[10] Stanley Kok and Pedro M. Domingos. Statistical predicate invention. In Machine Learning, Proceedings of the Twenty-Fourth International Conference (ICML 2007), Corvallis, Oregon, USA, June 20-24, 2007, pages 433-440, 2007. doi: 10.1145/1273496.1273551.
[11] Matt Gardner, Partha Pratim Talukdar, Bryan Kisiel, and Tom M. Mitchell. Improving learning and inference in a large knowledge-base using latent syntactic cues. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, EMNLP 2013, 18-21 October 2013, Grand Hyatt Seattle, Seattle, Washington, USA, A meeting of SIGDAT, a Special Interest Group of the ACL, pages 833-838, 2013.
[12] Matt Gardner, Partha Pratim Talukdar, Jayant Krishnamurthy, and Tom M. Mitchell. Incorporating vector space similarity in random walk inference over knowledge bases. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing, EMNLP 2014, October 25-29, 2014, Doha, Qatar, A meeting of SIGDAT, a Special Interest Group of the ACL, pages 397-406, 2014.
[13] Islam Beltagy, Stephen Roller, Pengxiang Cheng, Katrin Erk, and Raymond J Mooney. Representing meaning with a combination of logical and distributional models. Computational Linguistics, 2017.
[14] Arvind Neelakantan, Benjamin Roth, and Andrew McCallum. Compositional vector space models for knowledge base completion. In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing, ACL 2015, July 26-31, 2015, Beijing, China, Volume 1: Long Papers, pages 156-166, 2015.
[15] Baolin Peng, Zhengdong Lu, Hang Li, and Kam-Fai Wong. Towards neural network-based reasoning. CoRR, abs/1508.05508, 2015.</p>
<p>[16] Rajarshi Das, Arvind Neelakantan, David Belanger, and Andrew McCallum. Chains of reasoning over entities, relations, and text using recurrent neural networks. In Conference of the European Chapter of the Association for Computational Linguistics (EACL), 2017.
[17] Dirk Weissenborn. Separating answers from queries for neural reading comprehension. CoRR, abs/1607.03316, 2016.
[18] Yelong Shen, Po-Sen Huang, Jianfeng Gao, and Weizhu Chen. Reasonet: Learning to stop reading in machine comprehension. In Proceedings of the Workshop on Cognitive Computation: Integrating neural and symbolic approaches 2016 co-located with the 30th Annual Conference on Neural Information Processing Systems (NIPS 2016), Barcelona, Spain, December 9, 2016., 2016.
[19] Alex Graves, Greg Wayne, and Ivo Danihelka. Neural turing machines. CoRR, abs/1410.5401, 2014.
[20] Jason Weston, Sumit Chopra, and Antoine Bordes. Memory networks. CoRR, abs/1410.3916, 2014.
[21] Edward Grefenstette, Karl Moritz Hermann, Mustafa Suleyman, and Phil Blunsom. Learning to transduce with unbounded memory. In Advances in Neural Information Processing Systems 28: Annual Conference on Neural Information Processing Systems 2015, December 7-12, 2015, Montreal, Quebec, Canada, pages 1828-1836, 2015.
[22] Armand Joulin and Tomas Mikolov. Inferring algorithmic patterns with stack-augmented recurrent nets. In Advances in Neural Information Processing Systems 28: Annual Conference on Neural Information Processing Systems 2015, December 7-12, 2015, Montreal, Quebec, Canada, pages 190-198, 2015.
[23] Arvind Neelakantan, Quoc V. Le, and Ilya Sutskever. Neural programmer: Inducing latent programs with gradient descent. In International Conference on Learning Representations (ICLR), 2016.
[24] Scott E. Reed and Nando de Freitas. Neural programmer-interpreters. In International Conference on Learning Representations (ICLR), 2016.
[25] Marcin Andrychowicz, Misha Denil, Sergio Gomez Colmenarejo, Matthew W. Hoffman, David Pfau, Tom Schaul, and Nando de Freitas. Learning to learn by gradient descent by gradient descent. In Advances in Neural Information Processing Systems 29: Annual Conference on Neural Information Processing Systems 2016, December 5-10, 2016, Barcelona, Spain, pages 3981-3989, 2016.
[26] Matko Bosnjak, Tim Rocktäschel, Jason Naradowsky, and Sebastian Riedel. Programming with a differentiable forth interpreter. In International Conference on Machine Learning (ICML), 2017.
[27] Stuart J. Russell and Peter Norvig. Artificial Intelligence - A Modern Approach (3. internat. ed.). Pearson Education, 2010. ISBN 978-0-13-207148-2.
[28] Lise Getoor. Introduction to statistical relational learning. MIT press, 2007.
[29] Jacob Andreas, Marcus Rohrbach, Trevor Darrell, and Dan Klein. Learning to compose neural networks for question answering. In NAACL HLT 2016, The 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, San Diego California, USA, June 12-17, 2016, pages 1545-1554, 2016.
[30] David S Broomhead and David Lowe. Radial basis functions, multi-variable functional interpolation and adaptive networks. Technical report, DTIC Document, 1988.
[31] Allen Van Gelder. Efficient loop detection in prolog using the tortoise-and-hare technique. J. Log. Program., 4(1):23-31, 1987. doi: 10.1016/0743-1066(87)90020-3.
[32] J. Ross Quinlan. Learning logical definitions from relations. Machine Learning, 5:239-266, 1990. doi: 10.1007/BF00117105.
[33] William Yang Wang and William W. Cohen. Joint information extraction and reasoning: A scalable statistical relational learning approach. In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing, ACL 2015, July 26-31, 2015, Beijing, China, Volume 1: Long Papers, pages 355-364, 2015.
[34] Antoine Bordes, Nicolas Usunier, Alberto García-Durán, Jason Weston, and Oksana Yakhnenko. Translating embeddings for modeling multi-relational data. In Advances in Neural Information Processing Systems 26: 27th Annual Conference on Neural Information Processing Systems 2013. Proceedings of a meeting held December 5-8, 2013, Lake Yahoo, Nevada, United States., pages 2787-2795, 2013.</p>
<p>[35] Guillaume Bouchard, Sameer Singh, and Theo Trouillon. On approximate reasoning capabilities of low-rank vector spaces. In Proceedings of the 2015 AAAI Spring Symposium on Knowledge Representation and Reasoning (KRR): Integrating Symbolic and Neural Approaches, 2015.
[36] Maximilian Nickel, Lorenzo Rosasco, and Tomaso A. Poggio. Holographic embeddings of knowledge graphs. In Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence, February 12-17, 2016, Phoenix, Arizona, USA., pages 1955-1961, 2016.
[37] Fan Yang, Zhilin Yang, and William W. Cohen. Differentiable learning of logical rules for knowledge base completion. CoRR, abs/1702.08367, 2017.
[38] Artur S. d’Avila Garcez, Krysia Broda, and Dov M. Gabbay. Neural-symbolic learning systems: foundations and applications. Springer Science \&amp; Business Media, 2012.
[39] Jude W Shavlik and Geoffrey G Towell. An approach to combining explanation-based and neural learning algorithms. Connection Science, 1(3):231-253, 1989.
[40] Geoffrey G. Towell and Jude W. Shavlik. Knowledge-based artificial neural networks. Artif. Intell., 70 (1-2):119-165, 1994. doi: 10.1016/0004-3702(94)90105-8.
[41] Artur S. d’Avila Garcez and Gerson Zaverucha. The connectionist inductive learning and logic programming system. Appl. Intell., 11(1):59-77, 1999. doi: 10.1023/A:1008328630915.
[42] Lokendra Shastri. Neurally motivated constraints on the working memory capacity of a production system for parallel processing: Implications of a connectionist model based on temporal synchrony. In Proceedings of the Fourteenth Annual Conference of the Cognitive Science Society: July 29 to August 1, 1992, Cognitive Science Program, Indiana University, Bloomington, volume 14, page 159. Psychology Press, 1992.
[43] Liya Ding. Neural prolog-the concepts, construction and mechanism. In Systems, Man and Cybernetics, 1995. Intelligent Systems for the 21st Century,, IEEE International Conference on, volume 4, pages 3603-3608. IEEE, 1995.
[44] Manoel V. M. França, Gerson Zaverucha, and Artur S. d’Avila Garcez. Fast relational learning using bottom clause propositionalization with artificial neural networks. Machine Learning, 94(1):81-104, 2014. doi: $10.1007 / \mathrm{s} 10994-013-5392-1$.
[45] Gustav Sourek, Vojtech Aschenbrenner, Filip Zelezný, and Ondrej Kuzelka. Lifted relational neural networks. In Proceedings of the NIPS Workshop on Cognitive Computation: Integrating Neural and Symbolic Approaches co-located with the 29th Annual Conference on Neural Information Processing Systems (NIPS 2015), Montreal, Canada, December 11-12, 2015., 2015.
[46] William W. Cohen. Tensorlog: A differentiable deductive database. CoRR, abs/1605.06523, 2016.
[47] Luciano Serafini and Artur S. d’Avila Garcez. Logic tensor networks: Deep learning and logical reasoning from data and knowledge. In Proceedings of the 11th International Workshop on Neural-Symbolic Learning and Reasoning (NeSy'16) co-located with the Joint Multi-Conference on Human-Level Artificial Intelligence (HLAI 2016), New York City, NY, USA, July 16-17, 2016., 2016.
[48] Ni Lao, Tom M. Mitchell, and William W. Cohen. Random walk inference and learning in A large scale knowledge base. In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, EMNLP 2011, 27-31 July 2011, John McIntyre Conference Centre, Edinburgh, UK, A meeting of SIGDAT, a Special Interest Group of the ACL, pages 529-539, 2011.
[49] Ni Lao, Amarnag Subramanya, Fernando C. N. Pereira, and William W. Cohen. Reading the web with learned syntactic-semantic inference rules. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, EMNLP-CoNLL 2012, July 12-14, 2012, Jeju Island, Korea, pages 1017-1026, 2012.
[50] Tim Rocktäschel, Matko Bosnjak, Sameer Singh, and Sebastian Riedel. Low-Dimensional Embeddings of Logic. In ACL Workshop on Semantic Parsing (SP'14), 2014.
[51] Tim Rocktäschel, Sameer Singh, and Sebastian Riedel. Injecting logical background knowledge into embeddings for relation extraction. In NAACL HLT 2015, The 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Denver, Colorado, USA, May 31 - June 5, 2015, pages 1119-1129, 2015.
[52] Ivan Vendrov, Ryan Kiros, Sanja Fidler, and Raquel Urtasun. Order-embeddings of images and language. In International Conference on Learning Representations (ICLR), 2016.</p>
<p>[53] Zhiting Hu, Xuezhe Ma, Zhengzhong Liu, Eduard H. Hovy, and Eric P. Xing. Harnessing deep neural networks with logic rules. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, ACL 2016, August 7-12, 2016, Berlin, Germany, Volume 1: Long Papers, 2016.
[54] Thomas Demeester, Tim Rocktäschel, and Sebastian Riedel. Lifted rule injection for relation embeddings. In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, EMNLP 2016, Austin, Texas, USA, November 1-4, 2016, pages 1389-1399, 2016.
[55] Ekaterina Komendantskaya. Unification neural networks: unification by error-correction learning. Logic Journal of the IGPL, 19(6):821-847, 2011. doi: 10.1093/jigpal/jzq012.
[56] Steffen Hölldobler. A structured connectionist unification algorithm. In Proceedings of the 8th National Conference on Artificial Intelligence. Boston, Massachusetts, July 29 - August 3, 1990, 2 Volumes., pages 587-593, 1990.
[57] Stefan Schoenmackers, Jesse Davis, Oren Etzioni, and Daniel S. Weld. Learning first-order horn clauses from web text. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, EMNLP 2010, 9-11 October 2010, MIT Stata Center, Massachusetts, USA, A meeting of SIGDAT, a Special Interest Group of the ACL, pages 1088-1098, 2010.
[58] Stephen H Muggleton, Dianhuan Lin, and Alireza Tamaddoni-Nezhad. Meta-interpretive learning of higher-order dyadic datalog: Predicate invention revisited. Machine Learning, 100(1):49-73, 2015.
[59] Sepp Hochreiter and Jürgen Schmidhuber. Long short-term memory. Neural Computation, 9(8):1735-1780, 1997. doi: 10.1162/neco.1997.9.8.1735.
[60] Rémi Coulom. Efficient selectivity and backup operators in monte-carlo tree search. In Computers and Games, 5th International Conference, CG 2006, Turin, Italy, May 29-31, 2006. Revised Papers, pages 72-83, 2006. doi: 10.1007/978-3-540-75538-8_7.
[61] Levente Kocsis and Csaba Szepesvári. Bandit based monte-carlo planning. In Machine Learning: ECML 2006, 17th European Conference on Machine Learning, Berlin, Germany, September 18-22, 2006, Proceedings, pages 282-293, 2006. doi: 10.1007/11871842_29.
[62] David Silver, Aja Huang, Chris J. Maddison, Arthur Guez, Laurent Sifre, George van den Driessche, Julian Schrittwieser, Ioannis Antonoglou, Vedavyas Panneershelvam, Marc Lanctot, Sander Dieleman, Dominik Grewe, John Nham, Nal Kalchbrenner, Ilya Sutskever, Timothy P. Lillicrap, Madeleine Leach, Koray Kavukcuoglu, Thore Graepel, and Demis Hassabis. Mastering the game of go with deep neural networks and tree search. Nature, 529(7587):484-489, 2016. doi: 10.1038/nature16961.
[63] Marwin H. S. Segler, Mike Preuß, and Mark P. Waller. Towards "alphachem": Chemical synthesis planning with tree search and deep neural network policies. CoRR, abs/1702.00020, 2017.
[64] Mark E. Stickel. A prolog technology theorem prover. New Generation Comput., 2(4):371-383, 1984. doi: 10.1007/BF03037328.
[65] Cezary Kaliszyk, François Chollet, and Christian Szegedy. Holstep: A machine learning dataset for higher-order logic theorem proving. In International Conference on Learning Representations (ICLR), 2017.
[66] Sarah M. Loos, Geoffrey Irving, Christian Szegedy, and Cezary Kaliszyk. In International Conferences on Logic for Programming, Artificial Intelligence and Reasoning (LPAR), 2017.
[67] Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In International Conference on Learning Representations (ICLR), 2015.
[68] Xavier Glorot and Yoshua Bengio. Understanding the difficulty of training deep feedforward neural networks. In Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics, AISTATS 2010, Chia Laguna Resort, Sardinia, Italy, May 13-15, 2010, pages 249-256, 2010.
[69] Martín Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen, Craig Citro, Gregory S. Corrado, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Ian J. Goodfellow, Andrew Harp, Geoffrey Irving, Michael Isard, Yangqing Jia, Rafal Józefowicz, Lukasz Kaiser, Manjunath Kudlur, Josh Levenberg, Dan Mané, Rajat Monga, Sherry Moore, Derek Gordon Murray, Chris Olah, Mike Schuster, Jonathon Shlens, Benoit Steiner, Ilya Sutskever, Kunal Talwar, Paul A. Tucker, Vincent Vanhoucke, Vijay Vasudevan, Fernanda B. Viégas, Oriol Vinyals, Pete Warden, Martin Wattenberg, Martin Wicke, Yuan Yu, and Xiaoqiang Zheng. Tensorflow: Large-scale machine learning on heterogeneous distributed systems. CoRR, abs/1603.04467, 2016.</p>
<h1>Appendix</h1>
<h2>A Backward Chaining Pseudocode</h2>
<p>Simplified pseudocode for symbolic backward chaining (cycle detection omitted for brevity, see $[27,31,8]$ for details).</p>
<ol>
<li>or $(\mathrm{G}, S)=\left[S^{\prime} \mid S^{\prime} \in \operatorname{and}(\mathbb{B}, \operatorname{unify}(\mathrm{H}, \mathrm{G}, S)) \operatorname{for} \mathrm{H}:-\mathbb{B} \in \mathfrak{K}\right]$</li>
<li>and $\left(\right.$ _ FAIL $=$ FAIL</li>
<li>and $([], S)=S$</li>
<li>and $(\mathrm{G}: \mathbb{G}, S)=\left[S^{\prime \prime} \mid S^{\prime \prime} \in \operatorname{and}\left(\mathbb{G}, S^{\prime}\right)\right.$ for $S^{\prime} \in \operatorname{or}(\operatorname{substitute}(\mathrm{G}, S), S)]$</li>
<li>unify $\left(\right.$ _ FAIL $=$ FAIL</li>
<li>unify $([],[], S)=S$</li>
<li>unify $\left([],<em -="-">{-},</em>\right)=\right.$ FAIL</li>
<li>unify $\left(\right.$ _ $[]$, _ $=$ FAIL</li>
<li>unify $(h: \mathrm{H}, g: \mathrm{G}, S)=$ unify $\left(\right.$ H, G, $\left{\begin{array}{ll}\frac{S \cup{h / g}}{S \cup{g / h}} &amp; \text { if } h \in \mathcal{V} \ \text { if } g \in \mathcal{V}, h \notin \mathcal{V} \ \text { if } g=h \ \text { FAIL } &amp; \text { otherwise }\end{array}\right}$</li>
<li>substitute $\left([],_{-}\right)=[]$</li>
<li>substitute $(g: \mathrm{G}, S)=\left{\begin{array}{ll}x &amp; \text { if } g / x \in S \ g &amp; \text { otherwise }\end{array}\right}$ : substitute $(\mathrm{G}, S)$</li>
</ol>
<h2>B ComplEx</h2>
<p>ComplEx [7] is a state-of-the-art neural link prediction model that represents symbols as complex vectors. Let real $\left(\boldsymbol{\theta}<em i:="i:">{i:}\right)$ denote the real part and $\operatorname{imag}\left(\boldsymbol{\theta}</em>}\right)$ the imaginary part of a complex vector $\boldsymbol{\theta<em _boldsymbol_theta="\boldsymbol{\theta">{i:} \in \mathbb{C}^{k}$ representing the symbol with the $i$ th index. The scoring function defined by ComplEx is
$\operatorname{complex}</em>}}(s, i, j)=\sigma\left(\operatorname{real}\left(\boldsymbol{\theta<em i:="i:">{s:}\right)^{\top}\left(\operatorname{real}\left(\boldsymbol{\theta}</em>}\right) \odot \operatorname{real}\left(\boldsymbol{\theta<em s:="s:">{j:}\right)\right)+\operatorname{real}\left(\boldsymbol{\theta}</em>}\right)^{\top}\left(\operatorname{imag}\left(\boldsymbol{\theta<em j:="j:">{i:}\right) \odot \operatorname{imag}\left(\boldsymbol{\theta}</em>}\right)\right)+\right.$ $\left.\operatorname{imag}\left(\boldsymbol{\theta<em i:="i:">{s:}\right)^{\top}\left(\operatorname{real}\left(\boldsymbol{\theta}</em>}\right) \odot \operatorname{imag}\left(\boldsymbol{\theta<em s:="s:">{j:}\right)\right)-\operatorname{imag}\left(\boldsymbol{\theta}</em>}\right)^{\top}\left(\operatorname{imag}\left(\boldsymbol{\theta<em j:="j:">{i:}\right) \odot \operatorname{real}\left(\boldsymbol{\theta}</em>\right)\right)\right)$
where $\odot$ denotes the element-wise multiplication and $\sigma$ the sigmoid function. The benefit of ComplEx over other neural link prediction models such as RESCAL [1] or DistMult [5] is that by using complex vectors as subsymbolic representations it can capture symmetric as well as asymmetric relations.</p>
<h2>C Batch Proving</h2>
<p>Let $\boldsymbol{A} \in \mathbb{R}^{N \times k}$ be a matrix of $N$ subsymbolic representations that are to be unified with $M$ other representations $\boldsymbol{B} \in \mathbb{R}^{M \times k}$. We can adapt the unification module to calculate the unification success in a batched way using</p>
<p>$$
\exp \left(-\sqrt{\left(\left[\begin{array}{c}
\sum_{i=1}^{k} \boldsymbol{A}<em i="1">{1 i}^{2} \
\vdots \
\sum</em>}^{k} \boldsymbol{A<em M="M">{N i}^{2}
\end{array}\right] \mathbf{1}</em>
\sum_{i=1}^{k} \boldsymbol{B}}^{\top}\right)+\left(\begin{array}{c<em i="1">{1 i}^{2} \
\vdots \
\sum</em>
\end{array}\right]^{\top}}\right)-2 \boldsymbol{A} \boldsymbol{B}^{\top}\right) \in \mathbb{R}^{N \times M}
$$}^{k} \boldsymbol{B}_{M i}^{2</p>
<p>where $\mathbf{1}<em M="M">{N}$ and $\mathbf{1}</em>$ are vectors of $N$ and $M$ ones respectively, and the square root is taken elementwise. In practice, we partition the KB into rules that have the same structure and batch-unify goals with all rule heads per partition at the same time on a Graphics Processing Unit (GPU). Furthermore, substitution sets bind variables to vectors of symbol indices instead of single symbol indices, and min and max operations are taken per goal.</p>
<h1>D $K$ max Gradient Approximation</h1>
<p>NTPs allow us to calculate the gradient of proof success scores with respect to subsymbolic representations and rule parameters. While backpropagating through this large computation graph will give us the exact gradient, it is computationally infeasible for any reasonably-sized KB. Consider the parameterized rule $\boldsymbol{\theta}<em 2:="2:">{1:}(\mathrm{X}, \mathrm{Y}):-\boldsymbol{\theta}</em>)$ and let us assume the given KB contains 1000 facts with binary predicates. While X and Y will be bound to the respective representations in the goal, Z we will be substituted with every possible second argument of the 1000 facts in the KB when proving the first atom in the body. Moreover, for each of these 1000 substitutions, we will again need to compare with all facts in the KB when proving the second atom in the body of the rule, resulting in 1000000 proof success scores. However, note that since we use the max operator for aggregating the success of different proofs, only subsymbolic representations in one out of 1000000 proofs will receive gradients.}(\mathrm{X}, \mathrm{Z}), \boldsymbol{\theta}_{3:}(\mathrm{Z}, \mathrm{Y</p>
<p>To overcome this computational limitation, we propose the following heuristic. We assume that when unifying the first atom with facts in the KB, it is unlikely for any unification successes below the top $K$ successes to attain the maximum proof success when unifying the remaining atoms in the body of a rule with facts in the KB. That is, after the unification of the first atom, we only keep the top $K$ substitutions and their success scores, and continue proving only with these. This means that all other partial proofs will not contribute to the forward pass at this stage, and consequently not receive any gradients on the backward pass of backpropagation. We term this the $K \max$ heuristic. Note that we cannot guarantee anymore that the gradient of the proof success is the exact gradient, but for a large enough $K$ we get a close approximation to the true gradient.</p>
<h2>E Training Details</h2>
<p>We use ADAM [67] with an initial learning rate of 0.001 and a mini-batch size of 50 (10 known and 40 corrupted atoms) for optimization. We apply an $\ell_{2}$ regularization of 0.01 to all model parameters, and clip gradient values at $[-1.0,1.0]$. All subsymbolic representations and rule parameters are initialized using Xavier initialization [68]. We train all models for 100 epochs and repeat every experiment on the Countries corpus ten times. Statistical significance is tested using the independent $t$-test. All models are implemented in TensorFlow [69]. We use a maximum proof depth of $d=2$ and add the following rule templates where the number in front of the rule template indicates how often a parameterized rule of the given structure will be instantiated. Note that a rule template such as $# 1(\mathrm{X}, \mathrm{Y}):-# 2(\mathrm{X}, \mathrm{Z}), # 2(\mathrm{Z}, \mathrm{Y})$ specifies that the two predicate representations in the body are shared.</p>
<h2>Countries S1</h2>
<p>$3 # 1(\mathrm{X}, \mathrm{Y}):-# 1(\mathrm{Y}, \mathrm{X})$.
$3 # 1(\mathrm{X}, \mathrm{Y}):-# 2(\mathrm{X}, \mathrm{Z}), # 2(\mathrm{Z}, \mathrm{Y})$.</p>
<h2>Countries S2</h2>
<p>$3 # 1(\mathrm{X}, \mathrm{Y}):-# 1(\mathrm{Y}, \mathrm{X})$.
$3 # 1(\mathrm{X}, \mathrm{Y}):-# 2(\mathrm{X}, \mathrm{Z}), # 2(\mathrm{Z}, \mathrm{Y})$.
$3 # 1(\mathrm{X}, \mathrm{Y}):-# 2(\mathrm{X}, \mathrm{Z}), # 3(\mathrm{Z}, \mathrm{Y})$.</p>
<h2>Countries S3</h2>
<p>$3 # 1(\mathrm{X}, \mathrm{Y}):-# 1(\mathrm{Y}, \mathrm{X})$.
$3 # 1(\mathrm{X}, \mathrm{Y}):-# 2(\mathrm{X}, \mathrm{Z}), # 2(\mathrm{Z}, \mathrm{Y})$.
$3 # 1(\mathrm{X}, \mathrm{Y}):-# 2(\mathrm{X}, \mathrm{Z}), # 3(\mathrm{Z}, \mathrm{Y})$.
$3 # 1(\mathrm{X}, \mathrm{Y}):-# 2(\mathrm{X}, \mathrm{Z}), # 3(\mathrm{Z}, \mathrm{W}), # 4(\mathrm{~W}, \mathrm{Y})$.</p>
<h2>Kinship, Nations \&amp; UMLS</h2>
<p>$20 # 1(\mathrm{X}, \mathrm{Y}):-# 2(\mathrm{X}, \mathrm{Y})$.
$20 # 1(\mathrm{X}, \mathrm{Y}):-# 2(\mathrm{Y}, \mathrm{X})$.
$20 # 1(\mathrm{X}, \mathrm{Y}):-# 2(\mathrm{X}, \mathrm{Z}), # 3(\mathrm{Z}, \mathrm{Y})$.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{3}$ The creation of the neural network is dependent on the KB but also the structure of the goal. For instance, the goal $s(\mathrm{Q}, i)$ would result in a different neural network, and hence a different number of output proof states, than $s(i, j)$.&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>