<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-4251 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-4251</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-4251</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-98.html">extraction-schema-98</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs being used to process scholarly papers and extract qualitative laws, principles, patterns, or theories from them.</div>
                <p><strong>Paper ID:</strong> paper-268553675</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2403.14280v4.pdf" target="_blank">Large Language Models for Blockchain Security: A Systematic Literature Review</a></p>
                <p><strong>Paper Abstract:</strong> Large Language Models (LLMs) have emerged as powerful tools in various domains involving blockchain security (BS). Several recent studies are exploring LLMs applied to BS. However, there remains a gap in our understanding regarding the full scope of applications, impacts, and potential constraints of LLMs on blockchain security. To ﬁll this gap, we conduct a literature review on LLM4BS. As the ﬁrst review of LLM’s application on blockchain security, our study aims to comprehensively analyze existing research and elucidate how LLMs contribute to enhancing the security of blockchain systems. Through a thorough examination of scholarly works, we delve into the integration of LLMs into various aspects of blockchain security. We explore the mechanisms through which LLMs can bolster blockchain security, including their applications in smart contract auditing, identity veriﬁcation, anomaly detection, vulnerable repair, and so on. Furthermore, we critically assess the challenges and limitations associated with leveraging LLMs for blockchain security, considering factors such as scalability, privacy concerns, and adversarial attacks. Our review sheds light on the opportunities and potential risks inherent in this convergence, providing valuable insights for researchers, practitioners, and policymakers alike.</p>
                <p><strong>Cost:</strong> 0.006</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e4251.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e4251.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs being used to process scholarly papers and extract qualitative laws, principles, patterns, or theories from them.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLM-assisted Scientific Research</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Large Language Models for Scientific Research (paper-level analysis, summarization, hypothesis generation)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A general mention in this review that LLMs can support scientific discovery by ingesting and analyzing research papers to summarize findings, generate hypotheses, and aid data interpretation, i.e., extracting high-level themes and empirical generalizations from scholarly literature.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>The paper states at a conceptual level that LLMs can analyze and summarize research papers, produce hypotheses, and assist in data interpretation. No concrete method, prompting strategy, retrieval pipeline, multi-step workflow, or implementation details are provided in this review — the claim is a high-level capability attribution rather than a described experiment.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_field</strong></td>
                            <td>scientific research / general</td>
                        </tr>
                        <tr>
                            <td><strong>type_of_laws_extracted</strong></td>
                            <td>high-level empirical generalizations, hypotheses, thematic patterns and summarizations (qualitative generalizations rather than formal mechanistic laws)</td>
                        </tr>
                        <tr>
                            <td><strong>example_laws_extracted</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>The review asserts that LLMs are useful for analyzing and summarizing scholarly literature and generating hypotheses, but does not provide any empirical evaluation or concrete extracted laws from papers; it frames this as a promising application area while calling for further work and human oversight.</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>No experimental validation provided here; the authors note general limitations of LLM deployment (risk of hallucination/inaccuracies, ethical concerns, bias, privacy, scalability and energy costs) that apply to using LLMs for scholarly-papers analysis and synthesis.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Large Language Models for Blockchain Security: A Systematic Literature Review', 'publication_date_yy_mm': '2024-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4251.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e4251.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs being used to process scholarly papers and extract qualitative laws, principles, patterns, or theories from them.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLM-in-the-loop (thematic analysis)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLM-in-the-loop: Leveraging large language model for thematic analysis</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A referenced work (in the paper's bibliography) that, by its title and placement, appears to use LLMs to perform thematic analysis — i.e., extracting themes, patterns, and qualitative constructs from textual corpora (which can include scholarly texts).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Llm-in-the-loop: Leveraging large language model for thematic analysis</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>LLM-in-the-loop (thematic analysis)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Only cited by title in the review; the review does not reproduce or describe the method in detail. From the citation context, this external work likely integrates LLMs interactively into a thematic analysis workflow (human+LLM loop) to identify themes/patterns from text; the review itself does not provide prompting details, retrieval augmentation, iterative labeling steps, or evaluation specifics.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_field</strong></td>
                            <td>textual thematic analysis / social science / qualitative analysis (general)</td>
                        </tr>
                        <tr>
                            <td><strong>type_of_laws_extracted</strong></td>
                            <td>thematic patterns and qualitative constructs (themes), i.e., patterns/regularities in text corpora rather than formal scientific laws</td>
                        </tr>
                        <tr>
                            <td><strong>example_laws_extracted</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>The review includes this citation as an example of LLMs being leveraged for thematic analysis, implying that such methods exist and are relevant to extracting patterns from text, but the review does not report the methods' results or strengths/weaknesses in detail.</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>No details in this review; general concerns applicable include LLM hallucination, inconsistent theme extraction, dependence on prompts and human-in-the-loop processes, and lack of standardized evaluation for extracted qualitative laws.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Large Language Models for Blockchain Security: A Systematic Literature Review', 'publication_date_yy_mm': '2024-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Llm-in-the-loop: Leveraging large language model for thematic analysis <em>(Rating: 2)</em></li>
                <li>Datatales: Investigating the use of large language models for authoring data-driven articles <em>(Rating: 1)</em></li>
                <li>Chatgpt and large language models in academia: opportunities and challenges <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-4251",
    "paper_id": "paper-268553675",
    "extraction_schema_id": "extraction-schema-98",
    "extracted_data": [
        {
            "name_short": "LLM-assisted Scientific Research",
            "name_full": "Large Language Models for Scientific Research (paper-level analysis, summarization, hypothesis generation)",
            "brief_description": "A general mention in this review that LLMs can support scientific discovery by ingesting and analyzing research papers to summarize findings, generate hypotheses, and aid data interpretation, i.e., extracting high-level themes and empirical generalizations from scholarly literature.",
            "citation_title": "here",
            "mention_or_use": "mention",
            "model_name": null,
            "model_size": null,
            "method_name": null,
            "method_description": "The paper states at a conceptual level that LLMs can analyze and summarize research papers, produce hypotheses, and assist in data interpretation. No concrete method, prompting strategy, retrieval pipeline, multi-step workflow, or implementation details are provided in this review — the claim is a high-level capability attribution rather than a described experiment.",
            "number_of_papers": null,
            "domain_or_field": "scientific research / general",
            "type_of_laws_extracted": "high-level empirical generalizations, hypotheses, thematic patterns and summarizations (qualitative generalizations rather than formal mechanistic laws)",
            "example_laws_extracted": null,
            "evaluation_method": null,
            "performance_metrics": null,
            "comparison_baseline": null,
            "key_findings": "The review asserts that LLMs are useful for analyzing and summarizing scholarly literature and generating hypotheses, but does not provide any empirical evaluation or concrete extracted laws from papers; it frames this as a promising application area while calling for further work and human oversight.",
            "challenges_limitations": "No experimental validation provided here; the authors note general limitations of LLM deployment (risk of hallucination/inaccuracies, ethical concerns, bias, privacy, scalability and energy costs) that apply to using LLMs for scholarly-papers analysis and synthesis.",
            "uuid": "e4251.0",
            "source_info": {
                "paper_title": "Large Language Models for Blockchain Security: A Systematic Literature Review",
                "publication_date_yy_mm": "2024-03"
            }
        },
        {
            "name_short": "LLM-in-the-loop (thematic analysis)",
            "name_full": "LLM-in-the-loop: Leveraging large language model for thematic analysis",
            "brief_description": "A referenced work (in the paper's bibliography) that, by its title and placement, appears to use LLMs to perform thematic analysis — i.e., extracting themes, patterns, and qualitative constructs from textual corpora (which can include scholarly texts).",
            "citation_title": "Llm-in-the-loop: Leveraging large language model for thematic analysis",
            "mention_or_use": "mention",
            "model_name": null,
            "model_size": null,
            "method_name": "LLM-in-the-loop (thematic analysis)",
            "method_description": "Only cited by title in the review; the review does not reproduce or describe the method in detail. From the citation context, this external work likely integrates LLMs interactively into a thematic analysis workflow (human+LLM loop) to identify themes/patterns from text; the review itself does not provide prompting details, retrieval augmentation, iterative labeling steps, or evaluation specifics.",
            "number_of_papers": null,
            "domain_or_field": "textual thematic analysis / social science / qualitative analysis (general)",
            "type_of_laws_extracted": "thematic patterns and qualitative constructs (themes), i.e., patterns/regularities in text corpora rather than formal scientific laws",
            "example_laws_extracted": null,
            "evaluation_method": null,
            "performance_metrics": null,
            "comparison_baseline": null,
            "key_findings": "The review includes this citation as an example of LLMs being leveraged for thematic analysis, implying that such methods exist and are relevant to extracting patterns from text, but the review does not report the methods' results or strengths/weaknesses in detail.",
            "challenges_limitations": "No details in this review; general concerns applicable include LLM hallucination, inconsistent theme extraction, dependence on prompts and human-in-the-loop processes, and lack of standardized evaluation for extracted qualitative laws.",
            "uuid": "e4251.1",
            "source_info": {
                "paper_title": "Large Language Models for Blockchain Security: A Systematic Literature Review",
                "publication_date_yy_mm": "2024-03"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Llm-in-the-loop: Leveraging large language model for thematic analysis",
            "rating": 2,
            "sanitized_title": "llmintheloop_leveraging_large_language_model_for_thematic_analysis"
        },
        {
            "paper_title": "Datatales: Investigating the use of large language models for authoring data-driven articles",
            "rating": 1,
            "sanitized_title": "datatales_investigating_the_use_of_large_language_models_for_authoring_datadriven_articles"
        },
        {
            "paper_title": "Chatgpt and large language models in academia: opportunities and challenges",
            "rating": 1,
            "sanitized_title": "chatgpt_and_large_language_models_in_academia_opportunities_and_challenges"
        }
    ],
    "cost": 0.0059482499999999995,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Large Language Models for Blockchain Security: A Systematic Literature Review
March 26, 2024</p>
<p>Zheyuan He 
University of Electronic Science and Technology of China
China</p>
<p>Zihao Li 
The Hong Kong Polytechnic University
China</p>
<p>Sen Yang 
University of Electronic Science and Technology of China
China</p>
<p>Cryptocurrency Governance </p>
<p>Capabilities and Limitations</p>
<p>Ethical and Legal Considerations</p>
<p>Large Language Models for Blockchain Security: A Systematic Literature Review
March 26, 2024554C42389F445E94C2BAD4360091981BarXiv:2403.14280v2[cs.CR]PACS: 0000, 1111 2000 MSC: 0000, 1111 Preprint submitted to Infomation FusionBlockchain SecurityLarge Language ModelSurvey * Contextual Integration <em>Complex Logical Oversights Anomaly Detection </em>Real-time <em>Big Data </em>Constantly Updating <em>Context Comprehension Transaction management </em>Risk Assessment <em>Regulatory Compliance </em>Precision and Clarity <em>Urgent Security Needs Lifecycle Enhancement * Generation to Maintenance </em>Dynamic Learn Synergy * Facilitating Collaboration
Large Language Models (LLMs) have emerged as powerful tools in various domains involving blockchain security (BS).Several recent studies are exploring LLMs applied to BS.However, there remains a gap in our understanding regarding the full scope of applications, impacts, and potential constraints of LLMs on blockchain security.To fill this gap, we conduct a literature review on LLM4BS.As the first review of LLM's application on blockchain security, our study aims to comprehensively analyze existing research and elucidate how LLMs contribute to enhancing the security of blockchain systems.Through a thorough examination of scholarly works, we delve into the integration of LLMs into various aspects of blockchain security.We explore the mechanisms through which LLMs can bolster blockchain security, including their applications in smart contract auditing, identity verification, anomaly detection, vulnerable repair, and so on.Furthermore, we critically assess the challenges and limitations associated with leveraging LLMs for blockchain security, considering factors such as scalability, privacy concerns, and adversarial attacks.Our review sheds light on the opportunities and potential risks inherent in this convergence, providing valuable insights for researchers, practitioners, and policymakers alike.</p>
<p>Introduction</p>
<p>As the digital epoch progresses, the confluence of artificial intelligence with blockchain technology emerges as a groundbreaking development, particularly at the juncture where Large Language Models (LLMs) [1,2,3,4] intersect with the ever-evolving domain of blockchain security [5,6,7,8].LLMs have catapulted to the forefront of natural language processing (NLP), demonstrating profound capabilities in text generation and comprehension-abilities that mirror human-like proficiency.This transformative impact is attributable to their expansive datasets, sophisticated architectures, and the deep neural networks that underpin their operational frameworks [9,10].</p>
<p>The robustness of LLMs in discerning and synthesizing complex patterns within data positions them as invaluable assets in enhancing the security measures within blockchain systems [11].The granular analysis of smart contracts, the meticulous scrutiny of transactions, and the proactive monitoring of network behavior are among the critical tasks that LLMs are adept at performing with remarkable efficacy [12,13].</p>
<p>However, the path to integrating these cognitive powerhouses into blockchain security is met with an array of challenges that beckon for consideration.From navigating the intricate dynamics of ever-advancing cybersecurity threats to addressing the ethical concerns that accompany AI deployment, the trajectory is as demanding as it is promising.</p>
<p>Our work seeks to delve into the multifaceted role of LLMs within the realm of blockchain security, exploring the comprehensive spectrum of their applications, the inherent challenges that surface in this merger, and the prospective future directions that such an integration opens up.As we ebb further into this digital age, the collaborative dance between LLMs and blockchain security is not merely a fleeting trend but a seminal movement, promising to redefine the parameters within which we comprehend, construct, and protect our digital sanctums.</p>
<p>This paper makes the following contributions:</p>
<p>• To the best of our knowledge, and after a meticulous review of the extant literature, we can confidently assert that our work represents the inaugural systematic examination focusing on the application of Large Language Models (LLMs) to tasks within the realm of blockchain security, offering a pioneering exploration of the interplay between advanced AI and cryptographic ledger systems.</p>
<p>• In our comprehensive survey, we meticulously chronicle the current landscape of Large Language Model (LLM) applications in the domain of blockchain security, delving into a detailed analysis of how LLMs are employed across various scenarios, from the enhancement of smart contract reliability to the fortification of distributed ledger integrity, thereby shedding light on the multifaceted contributions of this cuttingedge technology.</p>
<p>• Emanating from our research, we rigorously compile and summarize a suite of practical academic accomplishments pertaining to the application of Large Language Models (LLMs) in fortifying blockchain security, in conjunction with proposing an array of promising and prospective avenues for future research, which we anticipate will catalyze substantial advancements and innovations within this burgeoning intersection of fields.</p>
<p>Overview of LLM4BS</p>
<p>We will provide some basic knowledge about LLM4BS tasks.</p>
<p>Introduction to Large Language Models</p>
<p>This subsection will interpret the definition, characteristics, and diverse applications of Large Language Models (LLMs)</p>
<p>Definition and Characteristics of LLMs</p>
<p>Large Language Models (LLMs) represent a groundbreaking advancement in artificial intelligence, particularly within the domain of natural language processing (NLP) [14].These models are characterized by their immense size, depth, and complexity, enabling them to process and generate humanlike text with remarkable fluency and coherence [15].At the heart of LLMs lies the transformer architecture, a powerful framework for sequence modeling that has revolutionized the field of NLP [16].</p>
<p>The defining characteristics of LLMs include their unprecedented scale, which involves training on vast corpora of text data containing billions or even trillions of words.This extensive training data allows LLMs to capture the intricate nuances of language, including syntax, semantics, and pragmatics, thereby endowing them with a deep understanding of linguistic structures and conventions [17].Additionally, LLMs exhibit a high degree of generative ability, capable of producing text that is contextually relevant and coherent across a wide range of tasks and domains.</p>
<p>Moreover, LLMs possess a remarkable degree of adaptability, thanks to their ability to be fine-tuned or specialized for specific applications or domains through techniques such as transfer learning [18].By leveraging pretrained models and fine-tuning them on task-specific datasets, practitioners can tailor LLMs to address a diverse array of NLP tasks, ranging from sentiment analysis and language translation to document summarization and conversational agents [2].</p>
<p>Furthermore, LLMs demonstrate an advanced understanding of context within language, enabling them to generate responses or predictions that are sensitive to the surrounding textual context [19].This contextual awareness is achieved through mechanisms such as attention mechanisms and positional encodings, which enable LLMs to attend to relevant parts of the input sequence and model long-range dependencies effectively [20].</p>
<p>Overall, LLMs represent a significant milestone in AI research and have unlocked new possibilities for human-computer interaction, content generation, information retrieval, and more.Their ability to understand and generate natural language at scale has led to transformative applications across various domains, shaping the future of AI-driven technologies [21].</p>
<p>Applications of LLMs in Various Domains</p>
<p>The versatility and efficacy of LLMs have led to their widespread adoption across diverse domains and applications, where they have demonstrated exceptional performance and utility [22].Some notable applications of LLMs include:</p>
<p>Natural Language Understanding (NLU): LLMs excel in tasks such as sentiment analysis, named entity recognition, and text classification, where the comprehension of semantic meaning and context is paramount [23].By leveraging their deep understanding of language, LLMs can accurately analyze and interpret textual data, enabling tasks such as sentiment analysis in social media monitoring or categorization of customer feedback.</p>
<p>Natural Language Generation (NLG): LLMs are proficient in generating human-like text for a variety of applications, including content creation, dialogue systems, and virtual assistants [24].Their ability to produce coherent and contextually relevant responses makes them invaluable for tasks such as generating product descriptions, composing personalized messages, or facilitating natural language interactions in conversational interfaces.</p>
<p>Information Retrieval and Summarization: LLMs play a crucial role in extracting relevant information from large volumes of text and generating concise summaries, thereby facilitating efficient information retrieval and knowledge extraction [25].Whether summarizing news articles, extracting key insights from research papers, or generating abstracts for documents, LLMs offer a powerful solution for distilling vast amounts of textual data into digestible and informative summaries.</p>
<p>Language Translation: LLMs have revolutionized machine translation by providing more accurate and fluent translations across multiple languages [26].By leveraging their vast linguistic knowledge and contextual understanding, LLMs can produce translations that preserve the meaning, tone, and style of the original text, enabling seamless communication across language barriers in various domains, including e-commerce, international diplomacy, and multicultural communication.</p>
<p>Dialogue Systems: LLMs power conversational agents and chatbots, enabling natural and contextually appropriate interactions with users [27].Whether assisting customers with product inquiries, providing personalized recommendations, or offering customer support, LLM-based dialogue systems offer a user-friendly and efficient means of communication, enhancing user experience and engagement.</p>
<p>Code Generation: LLMs are increasingly being used to generate code snippets and assist developers in programming tasks by understanding and generating code in various programming languages [24,28].By analyzing code repositories and documentation, LLMs can generate code that adheres to programming conventions, syntax rules, and best practices, thereby accelerating the development process and aiding in code maintenance and debugging [29] Scientific Research: LLMs support scientific discovery by analyzing and summarizing research papers, generating hypotheses, and aiding in data interpretation [30,22].By ingesting vast amounts of scientific literature and domain-specific knowledge, LLMs can assist researchers in navigating the ever-expanding body of scientific literature, identifying relevant publications, and extracting valuable insights to inform their research endeavors [31].</p>
<p>These applications underscore the broad utility and transformative potential of LLMs across a wide range of domains and industries, highlighting their significance in advancing AI capabilities and enabling human-computer interaction at unprecedented levels of sophistication.As LLMs continue to evolve and improve, their impact on various fields is expected to grow, driving innovation, efficiency, and discovery in the years to come.</p>
<p>Blockchain Security Fundamentals</p>
<p>This section will discuss the key components and common security threats of blockchain systems.</p>
<p>Key Components of Blockchain Security</p>
<p>Blockchain security is a multifaceted endeavor aimed at safeguarding the integrity, confidentiality, and availability of data stored and processed within a blockchain network.Key components of blockchain security include:</p>
<p>Cryptography: Cryptography lies at the heart of blockchain security, serving to encrypt data, authenticate participants, and ensure the integrity of transactions [32,33].Techniques such as hashing, digital signatures, and cryptographic keys are utilized to secure data and verify the authenticity of transactions on the blockchain [34].</p>
<p>Consensus Mechanisms: Consensus mechanisms are protocols that govern how transactions are validated and added to the blockchain.By achieving agreement among network participants, consensus mechanisms ensure the immutability and integrity of the distributed ledger [35,36].Popular consensus mechanisms include Proof of Work (PoW) [37], Proof of Stake (PoS) [38], and Delegated Proof of Stake (DPoS) [39], each with its own strengths and vulnerabilities.</p>
<p>Decentralization: Decentralization is a core principle of blockchain security, distributing control and decision-making authority across a network of nodes [40,41].By eliminating single points of failure and reducing the risk of censorship or manipulation, decentralization enhances the resilience and security of the blockchain network [42].However, achieving true decentralization requires careful consideration of factors such as node distribution, governance structures, and network incentives [43].</p>
<p>Smart Contract Security: Smart contracts are self-executing contracts with predefined rules and conditions encoded on the blockchain.Ensuring the security of smart contracts is essential to prevent vulnerabilities, exploits, and unauthorized access [44,45].Techniques such as formal verification, code auditing, and secure development practices are employed to mitigate risks associated with smart contracts, including reentrancy attacks, integer overflow/underflow, and unchecked external calls [46].</p>
<p>Common Security Threats in Blockchain Systems</p>
<p>Despite the robust security measures inherent in blockchain technology, various security threats and vulnerabilities pose risks to the integrity and functionality of blockchain systems [47,48].Some common security threats in blockchain systems include:</p>
<p>Consensus-Based Attacks: Consensus-based attacks exploit vulnerabilities in the consensus mechanism to compromise the integrity or availability of the blockchain network [49].Examples include 51% attacks, where a single entity or coalition controls the majority of the network's hash rate, enabling them to manipulate transaction confirmations or execute double spending attacks [50].Similarly, attacks such as selfish mining, eclipse attacks, and long-range attacks target weaknesses in specific consensus protocols, undermining the security and reliability of the blockchain network [51].</p>
<p>Smart Contract Exploits: Smart contract vulnerabilities pose significant risks to blockchain security, as they can be exploited to execute unauthorized transactions, drain funds, or trigger unintended behavior [52,53].Common smart contract vulnerabilities include reentrancy attacks, where an attacker repeatedly calls a vulnerable contract's function before the previous invocation completes, enabling them to manipulate the contract's state and steal funds [54].Other vulnerabilities, such as integer overflow/underflow, unchecked external calls, and gas limit vulnerabilities, can also be exploited to compromise the security of smart contracts and the underlying blockchain network [55].</p>
<p>DeFi Protocol Vulnerabilities: Decentralized finance (DeFi) protocols introduce new security challenges due to their complex interactions and composability [56,56].Vulnerabilities in DeFi protocols, such as flash loan attacks, oracle manipulation, and governance exploits, can result in significant financial losses for users and undermine trust in the DeFi ecosystem [57,58].Additionally, vulnerabilities in specific DeFi protocols can have cascading effects on other interconnected protocols, amplifying the impact of security breaches and systemic risks within the DeFi space [59].</p>
<p>Auxiliary Service Vulnerabilities: Auxiliary services, such as wallets, exchanges, oracles, and decentralized applications (DApps), serve as entry points for attackers to exploit vulnerabilities and compromise the security of blockchain systems [60].Security breaches in auxiliary services, such as exchange hacks, wallet vulnerabilities, or oracle manipulation attacks, can lead to the loss of funds, unauthorized access to user data, or manipulation of on-chain transactions [61,62].Furthermore, the interconnected nature of auxiliary services within the blockchain ecosystem amplifies the impact of security breaches, as vulnerabilities in one service can propagate to others, resulting in widespread disruption and financial losse.</p>
<p>Addressing these security threats and vulnerabilities requires a comprehensive approach that encompasses technical measures, best practices, and community collaboration to strengthen the resilience and security of blockchain systems [63].By understanding the key components of blockchain security and mitigating common security threats, stakeholders can foster greater trust, transparency, and adoption in the decentralized ecosystem, driving innovation and value creation for users worldwide.</p>
<p>Taxonomy of LLM4BS task</p>
<p>In this section, we introduce a thematic taxonomy devised to systematically categorize the body of literature about tasks associated with large language models for blockchain security (LLM4BS), emphasizing the function of the LLM within these contexts.Fig. 1 depicts the five applications of LLM4BS task.</p>
<p>LLM as Code auditor on Smart Contracts</p>
<p>The application of LLM in the domain of smart contract code auditing and vulnerability detection can be succinctly encapsulated as follows: Advanced tools [64,65,66,67,68,69,70,71,72] powered by Large Language Models, such as GPTScan [65] and SMARTINV [64], signify a monumental shift from traditional, pattern-based analysis methodologies towards more contextually aware and comprehensive inspection techniques.These cuttingedge tools extend their analytical prowess beyond static patterns by knitting together disparate threads of information, including the nuanced aspects of natural language documentation that detail the intended functions and transactional constructs of smart contracts.</p>
<p>This marriage of code and contextual data through a multimodal lens equips such tools with the capacity to unravel complex logical oversights and identify subtle "machine un-auditable" bugs, which would otherwise evade detection.By assimilating and interpreting the richer tapestry of human language explanations paired with code, LLM-based tools delve deeper into the intricate web of smart contract interactions.The profound understanding garnered from this approach not only sheds light on hidden vulnerabilities but also fortifies smart contracts against the myriad of risks that could lead to substantial financial repercussions.</p>
<p>LLM</p>
<p>In essence, the integration of Large Language Models in smart contract analysis marks a significant leap in safeguarding blockchain technology's infrastructural integrity.It underscores an evolving landscape where artificial intelligence converges with software development practices to bolster security measures.This proactive identification and remediation of weaknesses within smart contracts, facilitated by the keen insights offered by LLMs, are instrumental in cementing trust and reliability in blockchain transactions-hence mitigating potential financial liabilities and reinforcing the bedrock of digital contracts.</p>
<p>Expanding further on the key roles LLMs play, it's worth noting the vast potential these models have in enhancing the entire lifecycle of smart contract development.From generation to maintenance, LLMs facilitate the crafting of more secure and robust smart contracts.They do so by potentially providing recommendations during the development phase, suggesting best practices, and even generating code snippets that align with security guidelines.Throughout the auditing process, tools like GPTScan and SMARTINV can continuously learn and adapt to new patterns of vulnerabilities emerging from the evolving landscape of blockchain technology and cyber threats.This dynamic learning process is pivotal, as it allows for the development of increasingly refined models capable of detecting even the most covert and sophisticated vulnerabilities.</p>
<p>Moreover, the capacity of LLMs to assimilate context and understand code as it correlates to business logic makes them particularly effective in scenarios where contractual agreements are complex and layered with intricate logic.This is especially crucial in fields such as finance, where smart contracts govern transactions involving significant sums and numerous stakeholders.The vulnerability in such a domain could have catastrophic effects, not just financially but also in terms of reputational damage for the entities involved.Hence, the stakes in accurate and effective smart contract auditing cannot be overstated.</p>
<p>LLMs also enhance collaborative efforts throughout the industry by facilitating a common understanding among developers, auditors, and end-users.Their ability to parse and explain code in natural language bridges communication gaps, enabling stakeholders with varying levels of technical expertise to engage in meaningful dialogue regarding the security and functionality of smart contracts.This collaborative environment fosters a culture of shared responsibility and proactive engagement in addressing and preempting security concerns.</p>
<p>LLM as Analyzers for abnormal transaction</p>
<p>The application of LLMs for blockchain transaction analysis [73,74] underscores their crucial role in conducting real-time monitoring to detect signs of irregular or suspicious behavior.These models represent a significant advancement in the field, as they provide a more dynamic and adaptable approach to identifying potential threats within blockchain transactions.</p>
<p>Unlike static, rule-based systems, LLMs are capable of processing and learning from vast amounts of transaction data in real-time, which enables them to uncover not just known types of fraudulent activity, but also novel patterns that emerge as technology and attack methods evolve.By leveraging the power of machine learning, these models can constantly update their understanding of what constitutes normal transactional behavior.This continuous learning process is essential for adapting to the ever-changing landscape of blockchain technology and the complex strategies employed by malicious actors.</p>
<p>Furthermore, the adaptability of LLMs is not limited to pattern recognition-they also excel in understanding the context of transactions.This includes the analysis of smart contract interactions, execution traces, gas prices, and other transaction metadata that could provide hints about the legitimacy of a transaction.Contextual analysis allows LLMs to differentiate between legitimate, though unusual, transactional behavior and genuine anomalies that could indicate fraudulent activities, such as money laundering, phishing, or exploitation of contract vulnerabilities.</p>
<p>In addition to identifying potentially fraudulent transactions, LLMs also contribute to risk assessment and regulatory compliance.By analyzing the transaction data against current compliance standards and risk models, LLMs can assist financial institutions in managing their risk exposure and adhering to anti-money laundering (AML) and know your customer (KYC) regulations.Their sophisticated analysis capabilities can provide valuable insights to compliance officers and regulatory bodies, allowing for a more proactive approach to detecting and preventing financial crimes.</p>
<p>In summary, the application of LLMs in blockchain transaction analysis reflects a commitment to enhancing the security measures of digital financial systems.By combining deep learning algorithms with extensive transaction datasets, LLMs stand as a formidable line of defense, capable of not only identifying anomalous activities in real-time but also evolving with the advancing threats, ensuring a resilient and secure framework for managing blockchain-based transactions.</p>
<p>LLM as Fuzzer for Smart Contract</p>
<p>Large Language Models (LLMs) have been increasingly employed to elevate the process of fuzzing, particularly in the realm of smart contract security analysis [75,76].This methodology involves utilizing LLMs to accurately assess the complexity and vulnerability likelihood of specific code regions within a smart contract.Consequently, these metrics serve to guide the direction and focus of fuzzers, steering them towards code segments that are more likely to harbor potential security threats.</p>
<p>The application of LLMs to fuzzing exercises significantly elevates the efficiency of these operations by narrowing down the vast state space that fuzzers typically navigate.This precision-targeted fuzzing approach contributes to higher coverage and reveals more vulnerabilities than conventional tools, especially those pertaining to the intricate nature of smart contract code that traditional methods may overlook.</p>
<p>Moreover, this refined fuzzing technique allows for the integration of userdefined invariants-manually inserted assertions to monitor and manage the state during fuzzing.By doing so, it reduces the exploration overhead and improves the detection of more profound logical issues that regular fuzzing routines might miss.Evaluations of this LLM-enhanced fuzzing method within real-world decentralized finance (DeFi) projects have demonstrated its effectiveness, outperforming baseline fuzzing parameters and uncovering significant vulnerabilities.These vulnerabilities, if left undetected and exploited, could potentially result in substantial financial losses.</p>
<p>In summary, the fusion of LLMs into the fuzzing workflow offers a promising and intelligent solution to the challenges faced in automated security analysis of smart contracts, underscoring their potential for increasing the robustness of blockchain-based platforms.</p>
<p>LLM as Developer for Smart Contract</p>
<p>Recent studies [77,67,78,79,80] have begun to scrutinize the efficacy and reliability of Large Language Models (LLMs) like ChatGPT and Google Palm2 in the automated generation of smart contracts.These smart contracts are integral to the blockchain ecosystem, executing agreements without the need for intermediaries, and their accuracy and security are paramount.The research primarily constructs a testing framework that assesses smart contracts on multiple fronts -validity, correctness, efficiency, security, and maintainability.</p>
<p>These results have demonstrated that LLMs, despite showing proficiency in understanding contractual terms and generating syntactically correct Solidity code, often produce contracts with considerable security vulnerabilities.This finding signals a critical issue in the code's operational quality.The evaluations suggest that while LLMs can streamline the contract creation process, there's an underlying risk of generating code that could be exploited if used without a thorough review.</p>
<p>Importantly, the studies underscore the role of effective prompt engineering.It emerged that the LLMs' outputs are significantly influenced by the specificity and clarity of the prompts, which must be meticulously designed to minimize the risk of ambiguous or flawed code generation.This is particularly challenging because generating smart contracts requires precision, and the semantics of legal terms must be correctly interpreted and applied by the models.</p>
<p>These works point to the necessity for comprehensive analysis and improvement in the methodologies employed by LLMs.There is optimism that future iterations of LLMs, with better training and prompt-design considerations, could enhance the quality and security of AI-generated smart contracts.</p>
<p>It also hints at the potential for these tools to revolutionize contract generation by reducing the time and effort required, while flagging the urgent need for more robust security measures and testing methods.</p>
<p>Such research analysis provides an overarching view of the current state of LLM applications in smart contract generation.The discoveries made serve as a cautionary note about over-reliance on AI without adequate checks but also lay out a roadmap for future advancements that could harness AI's full potential responsibly.</p>
<p>LLM as participants for Cryptocurrency community</p>
<p>Large Language Models (LLMs) such as GPT-3.5 and ChatGPT are emerging as powerful tools in the cryptocurrency community [81, 82, 83, 84? ], albeit with their respective strengths and weaknesses.Related works collectively depict a landscape where LLMs are being explored for their potential to revolutionize governance and legal processes within the high-stakes, highly volatile realm of cryptocurrency.</p>
<p>Governance emerges as a major theme, as LLMs could contribute significantly to the structuring and transparency of this largely unregulated space.The first document outlines the broader governance challenges faced by AI systems, suggesting blockchain as a viable solution to introduce verifiability and accountability.On the other hand, limitations of LLMs in capturing the complexities of legal reasoning are highlighted, a concern that is echoed across the three studies to varying degrees.</p>
<p>The practical applications of these models in legal settings, specifically detailed in the second and third documents, emphasize their innovative role in drafting legal complaints.This development is promising for the future of legal work related to cryptocurrency regulations and litigation, as it suggests that LLMs could alleviate some of the workload from human experts, although the need for human oversight remains.</p>
<p>While governance and legal assistance dominate the discourse, there's a tone of cautious optimism throughout the texts.There is recognition of the transformative potential of LLMs in the cryptocurrency sector, but also a clear acknowledgment of the need for further advancement in AI technology to fully integrate into complex decision-making processes where legal and ethical considerations are paramount.</p>
<p>In essence, the collective narrative from the three documents converges on the premise that LLMs hold transformative potential for the cryptocurrency community's governance and legal sectors but must overcome challenges in understanding and application before they can be fully trusted in autonomous roles.</p>
<p>Miscellaneous</p>
<p>In addition, LLM is also used in blockchain security fields, involving smart contract compilers [85], zero-knowledge proofs [86], model training [87], NFT generation [88].We will introduce their applications in detail in future work.</p>
<p>Case study of LLM4BS</p>
<p>In this section, we engage in an in-depth examination through three distinct case studies, each serving to illustrate and shed light on the diverse and concrete applications of Large Language Models for Blockchain Systems (LLM4BS).These cases have been meticulously selected to encompass a broad range of scenarios.</p>
<p>LLM4Fuzz</p>
<p>LLM4FUZZ [75] emerges as an innovative technique in the cybersecurity landscape, specifically in the niche of smart contract security within blockchain networks.It intricately combines the prowess of Large Language Models (LLMs) with fuzz testing methodologies to proactively unearth vulnerabilities that could potentially compromise the integrity of smart contracts.</p>
<p>LLMs are highly sophisticated AI models that have made significant strides in understanding and generating human-like text, and more recently, they have proven to be adept at comprehending programming languages and code structure.LLM4FUZZ exploits this capacity by deploying LLMs to guide fuzzing processes intelligently.This results in a more incisive and nuanced exploration of smart contracts, focusing testing efforts on areas that LLMs determine to be most likely to contain security flaws.By doing so, LLM4FUZZ succeeds in not only streamlining the anomaly detection process but also in enhancing its accuracy and depth.</p>
<p>In the world of blockchain technology, where smart contracts serve as immutable agreements that execute automatically based on coded conditions, the potential negative impact of a security breach is heightened.Smart contracts control significant digital assets and are essential to the functioning of distributed applications (dApps).The immutable nature of blockchain adds a layer of complexity as deployed smart contracts, once committed to the blockchain, cannot be altered.Therefore, preemptive security assurances become crucial to ensuring their reliability and safeguarding the assets and processes they govern.</p>
<p>LLM4FUZZ provides a novel layer of security analysis by identifying and prioritizing potential problem areas within smart contract code.This prioritization is achieved through the LLM's learned understanding of code patterns that are historically or commonly associated with vulnerabilities.The methodology enhances traditional fuzzing strategies, which typically adopt a more scattergun approach by bombarding the code with random data inputs.LLM4FUZZ's targeted testing is not just more efficient but also more effective in discovering complex vulnerabilities that might otherwise be missed.</p>
<p>Following implementation, LLM4FUZZ has been benchmarked against existing fuzzing techniques and has consistently demonstrated superior performance.It expedites the vulnerability detection process and increases the breadth of security flaws that can be detected, thereby reinforcing the overall security posture.</p>
<p>The case of LLM4FUZZ is emblematic of the foresight in AI integration into cybersecurity regimes.It encapsulates the transformative effects of AI on improving and redefining existing technological processes, particularly in areas critical to the burgeoning digital economy.Through its lens, we catch a glimpse of the future of smart contract security -a future where AI-driven tools not only anticipate but actively engage in the continuous battle against cyber threats.</p>
<p>SMARTINV</p>
<p>Proposed with the intention of enhancing the reliability and security of blockchain smart contracts, SMARTINV [64] represents a significant breakthrough in the field.Its primary function is to infer invariants within smart contracts which can be integral in automating the process of identifying elusive bugs that typically elude conventional machine-auditing methods.</p>
<p>The unique aspect of SMARTINV lies in its multimodal learning strategy, which acknowledges that truly understanding the operational behavior of smart contracts requires a multifaceted approach-one that combines and analyzes different types of information, or modalities.SMARTINV specifically leverages both the static code within a smart contract and dynamic transaction data.By correlating code patterns with transaction behaviors, SMARTINV is poised to uncover invariant conditions that point to a smart contract's expected and intended state throughout its lifecycle.This holistic approach ensures a more thorough examination and superior detection rate of potential security weaknesses that could lead to future vulnerabilities and exploits.</p>
<p>The framework operates on the premise that no singular mode of information can fully articulate a smart contract's intricate logic and potential edge cases.Hence, by fusing multiple data sources, SMARTINV captures a more accurate depiction of a smart contract's functionality, leading to a significant reduction in false positives and more precise bug detection.Such an integrated approach to smart contract analysis promotes greater assurance in their deployment and operation, which is a critical concern in blockchain applications where security and trust are paramount.</p>
<p>In deploying SMARTINV, the researchers demonstrate its efficacy by testing on a collection of smart contracts, where it shows not only a high degree of accuracy but also an impressive capability in scalability.SMARTINV emerges as an invaluable asset in the realm of smart contract development and auditing, setting a precedent for future methodologies to build upon its multimodal analysis framework for enhanced security measures in the everevolving domain of blockchain technology.</p>
<p>BLOCKGPT</p>
<p>BLOCKGPT [73] serves as a paradigm shift in the domain of blockchain security, acting as a state-of-the-art Intrusion Detection System (IDS) specifically engineered to counteract and identify potentially malicious transactions within blockchain networks.The system is underpinned by a highly sophisticated large language model that has been meticulously trained with a significant corpus of transactional data from the Ethereum blockchain, one of the most widely utilized platforms in the industry.</p>
<p>The innovation expressed by BLOCKGPT is its departure from traditional detection methodologies that largely depend on predetermined rules or known patterns.Instead, BLOCKGPT adopts a proactive and learningbased approach that enables it to recognize a spectrum of anomalies, includ-ing sophisticated and previously unseen threats that could bypass conventional rule-based systems.</p>
<p>Demonstrating the prowess of its detection capabilities, BLOCKGPT has proven remarkably successful in testing scenarios.It proficiently identified and appropriately ranked 49 out of 124 verified attack transactions among the most abnormal three transactions that have occurred within their respective victim contracts.This high level of precision points to the system's refined anomaly recognition algorithms, indicating substantial progress in the field of IDS for blockchain.</p>
<p>Beyond its detection accuracy, the efficiency of BLOCKGPT is exemplified by its processing speed, handling transactions at an average rate of 2,284 per second, with relatively minimal deviation.This capability is not merely theoretical but is indicative of the system's readiness for deployment in realworld blockchain environments where real-time monitoring and response are critical.</p>
<p>The adaptability of BLOCKGPT extends to various blockchain architectures and applications, from finance to smart contracts.This versatility, combined with its real-time processing faculties, provides a robust and scalable solution that can be integrated seamlessly into existing blockchain infrastructures to fortify their resilience against a wide array of security threats.</p>
<p>As blockchain technology continues its integration into the fabric of digital transactions and smart contract deployment, systems such as BLOCK-GPT represent vital components in the ongoing effort to safeguard these platforms.With the adoption of machine learning models like the one upon which BLOCKGPT is built, the future of blockchain IDS appears increasingly secure, paving the way for safer and more reliable blockchain operations.</p>
<p>Future Direction and Challenge of LLM4BS</p>
<p>In delving into the future of Large Language Models for Blockchain Security (LLM4BS), the academic community contends with a series of pivotal focus areas that necessitate concerted scholarly efforts to address inherent challenges and extend LLM's utility in blockchain systems.The following focal points are elaborated to reflect the nuances and complexity inherent in this field of study:</p>
<p>Interdisciplinary Relationships: The essence of the next stage in LLM4BS is undeniably grounded in a harmonized interplay among the domains of artificial intelligence, cyber protection mechanisms, and distributed ledger technologies [89,90].This interdisciplinary collaboration is not merely additive but synergistic, as it draws upon the strengths and insights of each discipline to forge a formidable shield against cyber animosities.There is a clarion call within the academic and industrial spheres for a robust alliance, emphasizing that the amalgamation of cognitive computing with cryptographic resilience and decentralized architectures can lead to paradigm shift in securing blockchain networks.</p>
<p>Regulatory and Compliance Challenges: The shifting sands of regulatory frameworks demand not only compliance but a proactive engagement with regulatory bodies by scholars and practitioners in the LLM4BS field [7,91].This relationship is reciprocal; as regulatory agencies develop deeper understandings of the implications of integrating AI in blockchain, it is incumbent upon the actors within this space to advocate for regulations that encourage innovation while maintaining robust security measures.The dynamic interplay between cutting-edge technology and regulation is a delicate balance to strike, fostering a stable yet flexible platform for growth and adaptation in blockchain security solutions.</p>
<p>Dynamic Security Threats: The cyber threat horizon is akin to a chimeric beast-constantly mutating and presenting unforeseen challenges [10,92].Security models like LLM4BS must be engineered with inherent plasticity, allowing them to evolve alongside the threats they are designed to counteract.The integration of LLMs in blockchain security is not a static solution but a continually adapting safeguard, necessitating an expansive approach to cybersecurity that accounts for the proliferation of sophisticated cyberattacks as well as the subtleties of targeted breaches.Sustaining the integrity of blockchain transactions hinges on the preemptive identification and neutralization of these mercurial threats.</p>
<p>Ethical Governance and Bias Mitigation: The ethical tapestry within which LLM4BS operates is rich and complex, mandating a conscientious approach towards the examination and resolution of security practices that may inadvertently propagate bias or unfair outcomes [93,94].The quest for equitable algorithms expands beyond the technical realm, engaging with sociocultural dynamics and the moral dimensions of technological deployments.Therefore, a concerted effort in research that transcends statistical bias mitigation, touching upon philosophy, sociology, and ethics, is essential for fostering a climate where AI not only fortifies security but does so with an underlying commitment to justice and fairness.</p>
<p>Energy Considerations and AI Sustainability: In addressing the carbon footprint of blockchain operations, there is also a pressing need to confront the energy-intensive nature of training and deploying Large Language Models [95,96,97].The ecological impact of these AI systems necessitates a dual strategy: enhancing algorithmic efficiency to reduce computational load and alternative energy sources that can power these activities sustainably.This pursuit of ecological harmonization in the application of LLM4BS must be reflective of a broader commitment to sustainability across all aspects of blockchain technology, ensuring that the acceleration of security capabilities does not come at an unsustainable environmental cost.</p>
<p>Ethical Considerations in AI: The role of ethics cannot be overstated in the trajectory of LLM4BS implementation, as it undergirds every facet of AI application-from the source of data to the transparency of algorithms and the accountability for decisions made by or with the aid of AI.Implementing a robust ethical framework for LLM4BS entails a deep interrogation of the principles guiding AI development, encouraging scrutiny that permeates every layer of model design, deployment, and monitoring.Thus, creating an environment where trust in AI-fueled security measures is not merely assumed but carefully cultivated through responsible practices.</p>
<p>Data Quality and Access: At the heart of robust LLM4BS deployments lies the foundational element of data-its caliber, its scope, and the accessibility afforded to it.Herein lies the challenge: constructing and maintaining databases that are not only comprehensive and representative but are also curated with an eye towards enhancing the efficacy of Large Language Models in detecting anomalies and reinforcing security parameters in blockchain transactions.The task extends to crafting protocols that ensure data integrity and sourcing that conforms to ethical standards, thereby upholding the sanctity and reliability of these AI systems.</p>
<p>Navigating these considerations requires a strategic, methodological approach to utilize the full promise of LLM4BS.This involves a commitment to ongoing research, rigorous ethical scrutiny, and a concerted effort to evolve in tandem with the technological and regulatory landscape.With a fundamental understanding of these points, the community is better equipped to pave the way for LLM4BS to enhance the resilience and efficiency of blockchain security measures.</p>
<p>Conclusion</p>
<p>In summing up this review on the incorporation of Large Language Models (LLMs) into blockchain security, we have traversed through the technological advancements and intricate challenges presented by this union.The potential of LLMs to augment security protocols in blockchain is clear, offering innovative solutions for smart contract auditing, identity verification, and anomaly detection.Yet, this potential comes with the necessity for vigilance regarding scalability, privacy, advancing cyber threats, and ethical implications of AI.As we look ahead, the success of LLMs in blockchain security depends not only on continuous technological refinement but also on ethical practices, regulatory alignment, and informed community engagement.The integration of LLM into blockchain heralds a transformative era in digital security that demands a collaborative approach, balancing innovation with prudent oversight to forge a resilient and equitable digital future.DPM 2017 and CBT 2017, Oslo, Norway, September 14-15, 2017, Proceedings, Springer, 2017, pp.297-315.</p>
<p>Figure 1 :
1
Figure 1: The applications of LLM on the task of blockchain security.</p>
<p>Chatgpt for good? on opportunities and challenges of large language models for education. E Kasneci, K Seßler, S Küchemann, M Bannert, D Dementieva, F Fischer, U Gasser, G Groh, S Günnemann, E Hüllermeier, Learning and individual differences. 1031022742023</p>
<p>Not what you've signed up for: Compromising real-world llm-integrated applications with indirect prompt injection. K Greshake, S Abdelnabi, S Mishra, C Endres, T Holz, M Fritz, Proceedings of the 16th ACM Workshop on Artificial Intelligence and Security. the 16th ACM Workshop on Artificial Intelligence and Security2023</p>
<p>Hugginggpt: Solving ai tasks with chatgpt and its friends in hugging face. Y Shen, K Song, X Tan, D Li, W Lu, Y Zhuang, Advances in Neural Information Processing Systems. 362024</p>
<p>Y Yao, J Duan, K Xu, Y Cai, Z Sun, Y Zhang, A survey on large language model (llm) security and privacy: The good, the bad, and the ugly, High-Confidence Computing. 2024100211</p>
<p>A survey on evaluation of large language models. Y Chang, X Wang, J Wang, Y Wu, L Yang, K Zhu, H Chen, X Yi, C Wang, Y Wang, ACM Transactions on Intelligent Systems and Technology. 2023</p>
<p>Is your code generated by chatgpt really correct? rigorous evaluation of large language models for code generation. J Liu, C S Xia, Y Wang, L Zhang, Advances in Neural Information Processing Systems. 362024</p>
<p>A brief overview of chatgpt: The history, status quo and potential future development. T Wu, S He, J Liu, S Sun, K Liu, Q.-L Han, Y Tang, IEEE/CAA Journal of Automatica Sinica. 102023</p>
<p>W Ma, S Liu, W Wang, Q Hu, Y Liu, C Zhang, L Nie, Y Liu, arXiv:2305.12138The scope of chatgpt in software engineering: A thorough investigation. 2023arXiv preprint</p>
<p>S Hu, T Huang, F İlhan, S F Tekin, L Liu, arXiv:2310.01152Large language model-powered smart contract vulnerability detection: New perspectives. 2023arXiv preprint</p>
<p>Summary of chatgpt-related research and perspective towards the future of large language models. Y Liu, T Han, S Ma, J Zhang, Y Yang, J Tian, H He, A Li, M He, Z Liu, Meta-Radiology. 1000172023</p>
<p>A survey on the security of blockchain systems. X Li, P Jiang, T Chen, X Luo, Q Wen, Future generation computer systems. 1072020</p>
<p>Large language models for software engineering: A systematic literature review. X Hou, Y Zhao, Y Liu, Z Yang, K Wang, L Li, X Luo, D Lo, J C Grundy, H Wang, ArXiv abs/2308.106202023</p>
<p>W X Zhao, K Zhou, J Li, T Tang, X Wang, Y Hou, Y Min, B Zhang, J Zhang, Z Dong, Y Du, C Yang, Y Chen, Z Chen, J Jiang, R Ren, Y Li, X Tang, Z Liu, P Liu, J Nie, J Wen, ArXiv abs/2303.18223A survey of large language models. 2023</p>
<p>X Hou, Y Zhao, Y Liu, Z Yang, K Wang, L Li, X Luo, D Lo, J Grundy, H Wang, arXiv:2308.10620Large language models for software engineering: A systematic literature review. 2023arXiv preprint</p>
<p>Llm-planner: Few-shot grounded planning for embodied agents with large language models. C H Song, J Wu, C Washington, B M Sadler, W.-L Chao, Y Su, Proceedings of the IEEE/CVF International Conference on Computer Vision. the IEEE/CVF International Conference on Computer Vision2023</p>
<p>Why johnny can't prompt: how non-ai experts try (and fail) to design llm prompts. J Zamfirescu-Pereira, R Y Wong, B Hartmann, Q Yang, Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems. the 2023 CHI Conference on Human Factors in Computing Systems2023</p>
<p>Large language models are few-shot testers: Exploring llm-based general bug reproduction. S Kang, J Yoon, S Yoo, 2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE). IEEE2023</p>
<p>Universal language model fine-tuning for text classification. J Howard, S Ruder, Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics. the 56th Annual Meeting of the Association for Computational Linguistics20181</p>
<p>Tabert: Pretraining for joint understanding of textual and tabular data. P Yin, G Neubig, W -T. Yih, S Riedel, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. the 58th Annual Meeting of the Association for Computational Linguistics2020</p>
<p>Transformer-xl: Attentive language models beyond a fixed-length context. Z Dai, Z Yang, Y Yang, J Carbonell, Q Le, R Salakhutdinov, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. the 57th Annual Meeting of the Association for Computational LinguisticsAssociation for Computational Linguistics2019</p>
<p>Compost: Characterizing and evaluating caricature in llm simulations. M Cheng, T Piccardi, D Yang, Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing. the 2023 Conference on Empirical Methods in Natural Language Processing2023</p>
<p>S.-C Dai, A Xiong, L.-W Ku, arXiv:2310.15100Llm-in-the-loop: Leveraging large language model for thematic analysis. 2023arXiv preprint</p>
<p>Visually-situated natural language understanding with contrastive reading model and frozen large language models. G Kim, H Lee, D Kim, H Jung, S Park, Y Kim, S Yun, T Kil, B Lee, S Park, The 2023 Conference on Empirical Methods in Natural Language Processing. 2023</p>
<p>Lever: Learning to verify language-to-code generation with execution. A Ni, S Iyer, D Radev, V Stoyanov, W -T. Yih, S Wang, X V Lin, International Conference on Machine Learning. PMLR2023</p>
<p>Llm aided semi-supervision for efficient extractive dialog summarization. N Mishra, G Sahu, I Calixto, A Abu-Hanna, I H Laradji, The 2023 Conference on Empirical Methods in Natural Language Processing. 2023</p>
<p>Deplot: One-shot visual language reasoning by plot-to-table translation. F Liu, J M Eisenschlos, F Piccinno, S Krichene, C Pang, K Lee, M Joshi, W Chen, N Collier, Y Altun, arXiv:2212.105052022arXiv preprint</p>
<p>Towards nextgeneration intelligent assistants leveraging llm techniques. X L Dong, S Moon, Y E Xu, K Malik, Z Yu, Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining. the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining2023</p>
<p>Llm-based code generation method for golang compiler testing. Q Gu, Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering. the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering2023</p>
<p>Expectation vs. experience: Evaluating the usability of code generation tools powered by large language models. P Vaithilingam, T Zhang, E L Glassman, Chi conference on human factors in computing systems extended abstracts. 2022</p>
<p>Llm-based interaction for content generation: A case study on the perception of employees in an it department. A Agossah, F Krupa, M Perreira Da, P Le Silva, Callet, Proceedings of the 2023 ACM International Conference on Interactive Media Experiences. the 2023 ACM International Conference on Interactive Media Experiences2023</p>
<p>Datatales: Investigating the use of large language models for authoring data-driven articles. N Sultanum, A Srinivasan, 2023 IEEE Visualization and Visual Analytics (VIS). IEEE2023</p>
<p>The blockchain model of cryptography and privacy-preserving smart contracts. A Kosba, A Miller, E Shi, Z Wen, C Papamanthou, Hawk, 2016 IEEE symposium on security and privacy (SP. IEEE2016</p>
<p>A blockchain-based shamir's threshold cryptography for data protection in industrial internet of things of smart city. L Tan, K Yu, C Yang, A K Bashir, Proceedings of the 1st Workshop on Artificial Intelligence and Blockchain Technologies for Smart Cities with 6G. the 1st Workshop on Artificial Intelligence and Blockchain Technologies for Smart Cities with 6G2021</p>
<p>Untangling blockchain: A data processing view of blockchain systems. T T A Dinh, R Liu, M Zhang, G Chen, B C Ooi, J Wang, IEEE transactions on knowledge and data engineering. 302018</p>
<p>Performance modeling of pbft consensus process for permissioned blockchain network (hyperledger fabric). H Sukhwani, J M Martínez, X Chang, K S Trivedi, A Rindos, 2017 IEEE 36th symposium on reliable distributed systems (SRDS). IEEE2017</p>
<p>A scalable multilayer pbft consensus for blockchain. W Li, C Feng, L Zhang, H Xu, B Cao, M A Imran, IEEE Transactions on Parallel and Distributed Systems. 322020</p>
<p>On the security and performance of proof of work blockchains. A Gervais, G O Karame, K Wüst, V Glykantzis, H Ritzdorf, S Capkun, Proceedings of the 2016 ACM SIGSAC conference on computer and communications security. the 2016 ACM SIGSAC conference on computer and communications security2016</p>
<p>Proof-of-stake sidechains. P Gaži, A Kiayias, D Zindros, 2019 IEEE Symposium on Security and Privacy (SP). IEEE2019</p>
<p>Securing proof-of-stake blockchain protocols. W Li, S Andreina, J.-M Bohli, G Karame, Data Privacy Management, Cryptocurrencies and Blockchain Technology: ESORICS 2017 International Workshops. </p>
<p>Peer to peer for privacy and decentralization in the internet of things. M Conoscenti, A Vetro, J C De Martin, IEEE/ACM 39th International Conference on Software Engineering Companion (ICSE-C). IEEE2017. 2017</p>
<p>Scaling blockchains without giving up decentralization and security: A solution to the blockchain scalability trilemma. G D Monte, D Pennino, M Pizzonia, Proceedings of the 3rd Workshop on Cryptocurrencies and Blockchains for Distributed Systems. the 3rd Workshop on Cryptocurrencies and Blockchains for Distributed Systems2020</p>
<p>Decentralizing privacy: Using blockchain to protect personal data. G Zyskind, O Nathan, 2015 IEEE security and privacy workshops. IEEE2015</p>
<p>Crowdbc: A blockchain-based decentralized framework for crowdsourcing. M Li, J Weng, A Yang, W Lu, Y Zhang, L Hou, J.-N Liu, Y Xiang, R H Deng, 201830</p>
<p>Smart contract development: Challenges and opportunities. W Zou, D Lo, P S Kochhar, X.-B D Le, X Xia, Y Feng, Z Chen, B Xu, IEEE Transactions on Software Engineering. 472019</p>
<p>. K Hu, J Zhu, Y Ding, X Bai, J Huang, Smart contract engineering. 920422020Electronics</p>
<p>Sok: Decentralized finance (defi) attacks. L Zhou, X Xiong, J Ernstberger, S Chaliasos, Z Wang, Y Wang, K Qin, R Wattenhofer, D Song, A Gervais, 2023 IEEE Symposium on Security and Privacy (SP). IEEE2023</p>
<p>Blockchain security: A survey of techniques and research directions. J Leng, M Zhou, J L Zhao, Y Huang, Y Bian, IEEE Transactions on Services Computing. 152020</p>
<p>D Berdik, S Otoum, N Schmidt, D Porter, Y Jararweh, A survey on blockchain for information systems management and security, Information Processing. 202158102397</p>
<p>Towards multiple-mix-attack detection via consensus-based trust management in iot networks. Z Ma, L Liu, W Meng, Computers &amp; Security. 961018982020</p>
<p>Sg-pbft: A secure and highly efficient distributed blockchain pbft consensus algorithm for intelligent internet of vehicles. G Xu, H Bai, J Xing, T Luo, N N Xiong, X Cheng, S Liu, X Zheng, Journal of Parallel and Distributed Computing. 1642022</p>
<p>Modeling the impact of network connectivity on consensus security of proof-of-work blockchain. Y Xiao, N Zhang, W Lou, Y T Hou, IEEE INFOCOM 2020-IEEE Conference on Computer Communications. IEEE2020</p>
<p>Ethainter: a smart contract security analyzer for composite vulnerabilities. L Brent, N Grech, S Lagouvardos, B Scholz, Y Smaragdakis, Proceedings of the 41st ACM SIGPLAN Conference on Programming Language Design and Implementation. the 41st ACM SIGPLAN Conference on Programming Language Design and Implementation2020</p>
<p>Smart contract security: A practitioners' perspective. Z Wan, X Xia, D Lo, J Chen, X Luo, X Yang, 2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE). IEEE2021</p>
<p>A {Mixed-Methods} study of security practices of smart contract developers. T Sharma, Z Zhou, A Miller, Y Wang, 32nd USENIX Security Symposium (USENIX Security 23. 2023</p>
<p>Smarter smart contract development tools. M Coblenz, J Sunshine, J Aldrich, B A Myers, IEEE/ACM 2nd International Workshop on Emerging Trends in Software Engineering for Blockchain. IEEE2019. 2019</p>
<p>Smart contract and defi security tools: Do they meet the needs of practitioners?. S Chaliasos, M A Charalambous, L Zhou, R Galanopoulou, A Gervais, D Mitropoulos, B Livshits, Proceedings of the 46th IEEE/ACM International Conference on Software Engineering. the 46th IEEE/ACM International Conference on Software Engineering2024</p>
<p>On the just-intime discovery of profit-generating transactions in defi protocols. L Zhou, K Qin, A Cully, B Livshits, A Gervais, 2021 IEEE Symposium on Security and Privacy (SP). IEEE2021</p>
<p>Impact and user perception of sandwich attacks in the defi ecosystem. Y Wang, P Zuest, Y Yao, Z Lu, R Wattenhofer, Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems. the 2022 CHI Conference on Human Factors in Computing Systems2022</p>
<p>Defitainter: Detecting price manipulation vulnerabilities in defi protocols. Q Kong, J Chen, Y Wang, Z Jiang, Z Zheng, Proceedings of the 32nd ACM SIGSOFT International Symposium on Software Testing and Analysis. the 32nd ACM SIGSOFT International Symposium on Software Testing and Analysis2023</p>
<p>As strong as its weakest link: How to break blockchain dapps at rpc service. K Li, J Chen, X Liu, Y R Tang, X Wang, X Luo, 2021NDSS</p>
<p>Etherdiffer: Differential testing on rpc services of ethereum nodes. S Kim, S Hwang, Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering. the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering2023</p>
<p>Deter: Denial of ethereum txpool services. K Li, Y Wang, Y Tang, Proceedings of the 2021 ACM SIGSAC Conference on Computer and Communications Security. the 2021 ACM SIGSAC Conference on Computer and Communications Security2021</p>
<p>A survey of blockchain technology on security, privacy, and trust in crowdsourcing services. Y Ma, Y Sun, Y Lei, N Qin, J Lu, World Wide Web. 232020</p>
<p>Smartinv: Multimodal learning for smart contract invariant inference. S J Wang, K Pei, J Yang, 2024 IEEE Symposium on Security and Privacy (SP). IEEE Computer Society2024</p>
<p>Gptscan: Detecting logic vulnerabilities in smart contracts by combining gpt with program analysis. Y Sun, D Wu, Y Xue, H Liu, H Wang, Z Xu, X Xie, Y Liu, Proc. IEEE/ACM ICSE. IEEE/ACM ICSE2024</p>
<p>Do you still need a manual smart contract audit?. I David, L Zhou, K Qin, D Song, L Cavallaro, A Gervais, arXiv:2306.123382023arXiv preprint</p>
<p>Who is smarter? an empirical study of ai-based smart contract creation. R Karanjai, E Li, L Xu, W Shi, 5th Conference on Blockchain Research &amp; Applications for Innovative Networks and Services (BRAINS). IEEE2023</p>
<p>Contractarmor: Attack surface generator for smart contracts. F Ö Sönmez, W J Knottenbelt, Procedia Computer Science. 2312024</p>
<p>Identifying and fixing vulnerable patterns in ethereum smart contracts: A comparative study of fine-tuning and prompt engineering using large language models. M Ortu, G Ibba, C Conversano, R Tonelli, G Destefanis, Available at SSRN. 4530467</p>
<p>Assbert: Active and semi-supervised bert for smart contract vulnerability detection. X Sun, L Tu, J Zhang, J Cai, B Li, Y Wang, Journal of Information Security and Applications. 731034232023</p>
<p>Pscvfinder: A prompttuning based framework for smart contract vulnerability detection. L Yu, J Lu, X Liu, L Yang, F Zhang, J Ma, 2023 IEEE 34th International Symposium on Software Reliability Engineering (ISSRE). IEEE2023</p>
<p>Y Sun, D Wu, Y Xue, H Liu, W Ma, L Zhang, M Shi, Y Liu, arXiv:2401.16185Llm4vuln: A unified evaluation framework for decoupling and enhancing llms' vulnerability reasoning. 2024arXiv preprint</p>
<p>Y Gai, L Zhou, K Qin, D Song, A Gervais, arXiv:2304.12749Blockchain large language models. 2023arXiv preprint</p>
<p>J Nicholls, A Kuppa, N.-A Le-Khac, arXiv:2310.13787Enhancing illicit activity detection using xai: A multimodal graph-llm framework. 2023arXiv preprint</p>
<p>C Shou, J Liu, D Lu, K Sen, arXiv:2401.11108Llm4fuzz: Guided fuzzing of smart contracts with large language models. 2024arXiv preprint</p>
<p>Acfix: Guiding llms with mined common rbac practices for context-aware repair of access control vulnerabilities in smart contracts. L Zhang, K Li, K Sun, D Wu, Y Liu, H Tian, Y Liu, arXiv:2403.068382024arXiv preprint</p>
<p>Efficient avoidance of vulnerabilities in autocompleted smart contract code using vulnerability-constrained decoding. A Storhaug, J Li, T Hu, 2023 IEEE 34th International Symposium on Software Reliability Engineering (ISSRE). IEEE2023</p>
<p>N O O Dade, M Lartey-Quaye, E T .-K. Odonkor, P Ammah, arXiv:2310.05178Optimizing large language models to expedite the development of smart contracts. 2023arXiv preprint</p>
<p>Evaluation of chatgpt's smart contract auditing capabilities based on chain of thought. Y Du, X Tang, arXiv:2402.120232024arXiv preprint</p>
<p>Gptutor: an opensource ai pair programming tool alternative to copilot. E Chen, R Huang, J Liang, D Chen, P Hung, arXiv:2310.138962023arXiv preprint</p>
<p>Large language models in cryptocurrency securities cases: Can chatgpt replace lawyers?. A Trozze, T Davies, B Kleinberg, arXiv:2308.060322023arXiv preprint</p>
<p>H Axelsen, S Axelsen, V Licht, J Potts, arXiv:2312.07693Scaling culture in blockchain gaming: Generative ai and pseudonymous engagement. 2023arXiv preprint</p>
<p>Decentralised governance for foundation model based ai systems: Exploring the role of blockchain in responsible ai. Y Liu, Q Lu, L Zhu, H.-Y Paik, IEEE Software. 2024</p>
<p>C Ziegler, M Miranda, G Cao, G Arentoft, D W Nam, arXiv:2401.07059Classifying proposals of decentralized autonomous organizations using large language models. 2024arXiv preprint</p>
<p>R Karanjai, L Xu, W Shi, arXiv:2403.09740Teaching machines to code: Smart contract translation with llms. 2024arXiv preprint</p>
<p>S Wellington, arXiv:2403.01008Basedai: A decentralized p2p network for zero knowledge large language models (zk-llms). 2024arXiv preprint</p>
<p>H Luo, J Luo, A V Vasilakos, arXiv:2310.06278Bc4llm: Trusted artificial intelligence when blockchain meets large language models. 2023arXiv preprint</p>
<p>Learning profitable nft image diffusions via multiple visual-policy guided reinforcement learning. H He, T Wang, H Yang, J Fu, N J Yuan, J Yin, H Chao, Q Zhang, Proceedings of the 31st ACM International Conference on Multimedia. the 31st ACM International Conference on Multimedia2023</p>
<p>Chatgpt and large language model (llm) chatbots: The current state of acceptability and a proposal for guidelines on utilization in academic medicine. J K Kim, M Chua, M Rickard, A Lorenzo, Journal of Pediatric Urology. 2023</p>
<p>J G Meyer, R J Urbanowicz, P C Martin, K O'connor, R Li, P.-C Peng, T J Bright, N Tatonetti, K J Won, G Gonzalez-Hernandez, Chatgpt and large language models in academia: opportunities and challenges. 20231620</p>
<p>Welcome to the era of chatgpt et al. the prospects of large language models. T Teubner, C M Flath, C Weinhardt, W Van Der Aalst, O Hinz, Business &amp; Information Systems Engineering. 652023</p>
<p>Can chatgpt replace traditional kbqa models? an in-depth analysis of the question answering performance of the gpt llm family. Y Tan, D Min, Y Li, W Li, N Hu, Y Chen, G Qi, International Semantic Web Conference. Springer2023</p>
<p>Is chatgpt leading generative ai? what is beyond expectations?. Ö Aydin, E Karaarslan, Academic Platform Journal of Engineering and Smart Systems. 112023</p>
<p>Chatgpt: A comprehensive review on background, applications, key challenges, bias, ethics, limitations and future scope. P P Ray, Internet of Things and Cyber-Physical Systems. 2023</p>
<p>Chatgpt and open-ai models: A preliminary review. K I Roumeliotis, N D Tselikas, Future Internet. 151922023</p>
<p>Y Qin, S Liang, Y Ye, K Zhu, L Yan, Y Lu, Y Lin, X Cong, X Tang, B Qian, arXiv:2307.16789Toolllm: Facilitating large language models to master 16000+ real-world apis. 2023arXiv preprint</p>
<p>Dao to hanoi via desci: Ai paradigm shifts from alphago to chatgpt. Q Miao, W Zheng, Y Lv, M Huang, W Ding, F.-Y Wang, IEEE/CAA Journal of Automatica Sinica. 102023</p>            </div>
        </div>

    </div>
</body>
</html>