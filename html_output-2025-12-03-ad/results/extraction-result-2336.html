<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2336 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2336</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2336</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-63.html">extraction-schema-63</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <p><strong>Paper ID:</strong> paper-259936960</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2307.07522v3.pdf" target="_blank">The Future of Fundamental Science Led by Generative Closed-Loop Artificial Intelligence</a></p>
                <p><strong>Paper Abstract:</strong> Recent advances in machine learning and AI, including Generative AI and LLMs, are disrupting technological innovation, product development, and society as a whole. AI's contribution to technology can come from multiple approaches that require access to large training data sets and clear performance evaluation criteria, ranging from pattern recognition and classification to generative models. Yet, AI has contributed less to fundamental science in part because large data sets of high-quality data for scientific practice and model discovery are more difficult to access. Generative AI, in general, and Large Language Models in particular, may represent an opportunity to augment and accelerate the scientific discovery of fundamental deep science with quantitative models. Here we explore and investigate aspects of an AI-driven, automated, closed-loop approach to scientific discovery, including self-driven hypothesis generation and open-ended autonomous exploration of the hypothesis space. Integrating AI-driven automation into the practice of science would mitigate current problems, including the replication of findings, systematic production of data, and ultimately democratisation of the scientific process. Realising these possibilities requires a vision for augmented AI coupled with a diversity of AI approaches able to deal with fundamental aspects of causality analysis and model discovery while enabling unbiased search across the space of putative explanations. These advances hold the promise to unleash AI's potential for searching and discovering the fundamental structure of our world beyond what human scientists have been able to achieve. Such a vision would push the boundaries of new fundamental science rather than automatize current workflows and instead open doors for technological innovation to tackle some of the greatest challenges facing humanity today.</p>
                <p><strong>Cost:</strong> 0.028</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2336.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2336.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Deep neural networks</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Deep neural networks (deep learning)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Multi-layer neural network models that learn hierarchical representations from data and have been widely applied for pattern recognition, prediction, and representation tasks in scientific domains.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>General across domains (protein folding, image-based sensing, classification tasks)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Learning predictive mappings or representations from high-dimensional empirical data (images, sequences, tabular measurements) to perform classification, regression, or representation learning to support scientific analysis.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Often large-scale/abundant in successful applications (e.g., protein sequence databases used by folding models); performance depends on access to extensive labelled datasets; quality varies by domain; when data scarce, deep nets struggle without augmentation or priors.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>High-dimensional numerical arrays (images, sequences, tensors), sometimes multimodal when combined with other data types; typically structured but represented as dense vectors/matrices.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>High: large parameter counts (millions), nonlinear function approximation, high-dimensional search spaces, potential overparameterisation and overfitting without sufficient data or regularisation.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Varies by domain: mature in imaging and some bioinformatics tasks (where historic datasets exist), less mature where labeled large datasets are scarce or mechanistic models dominate.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Medium to high in fundamental science â€” authors emphasise that black-box deep nets are insufficient where mechanistic/causal insight is needed; interpretability often required.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Deep neural networks (including convolutional networks, LSTMs, transformers)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Stacked layers of nonlinear units trained by gradient-based optimisation on large datasets to minimise loss functions; architectures include convolutions for spatial data and transformer attention for sequence/text; often lack explicit mechanistic structure and require large labelled datasets or domain priors.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Supervised / representation learning (with unsupervised and self-supervised variants)</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Applicable for pattern recognition and prediction tasks with abundant data; less appropriate alone for hypothesis generation or causal discovery in fundamental-science contexts without integration with symbolic or mechanistic methods.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Worked well for classification and representation tasks (e.g., image, sequence tasks) but are described as 'black boxes' with limitations for causality and interpreting new mechanistic laws; susceptible to spurious correlations and poor generalisation outside training distribution.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>High for accelerating data-rich experimental workflows, noise filtering, and prediction tasks; limited for producing new fundamental explanatory theories without hybridisation with mechanistic/symbolic approaches.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Paper contrasts deep networks' statistical strengths with their lack of causal inference and interpretability versus symbolic or model-driven approaches; no quantitative comparison provided.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Availability of large, high-quality labelled datasets; appropriate architectural inductive biases (e.g., convolution for images); integration with domain knowledge or priors to mitigate black-box limitations.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Deep neural networks excel at pattern extraction when abundant labelled data exist but are insufficient alone for discovering mechanistic scientific laws due to interpretability and causal inference gaps.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Future of Fundamental Science Led by Generative Closed-Loop Artificial Intelligence', 'publication_date_yy_mm': '2023-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2336.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2336.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Generative models / GANs</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Generative adversarial networks and other generative models</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Models trained to generate novel synthetic data (images, sequences, examples) by learning the data distribution, often via adversarial training between generator and discriminator networks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Data augmentation, simulation, scenario generation across domains (e.g., driving simulations, adversarial example generation)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Produce synthetic examples to expand training datasets, explore rare event spaces, or test model robustness by generating counterexamples (e.g., crash scenarios for autonomous vehicles).</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Used when real-world data of rare events are limited; require existing datasets to learn distribution; quality depends on training data representativeness.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>High-dimensional continuous data (images, signals) typically represented as tensors.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Moderate-to-high: training instability (mode collapse), need for careful balancing of generator and discriminator; exploring long-tail rare events is challenging.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Moderately mature for image and signal domains; emerging usage in scientific simulation and robustness testing.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Low-to-medium: generative models are mainly used for producing examples rather than providing mechanistic explanations; interpretability limited.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Generative adversarial networks and other generative architectures</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Adversarial training where a generator network proposes examples and a discriminator network classifies real vs generated; used to create synthetic data for training, stress-testing models, or exploring hypothetical scenarios.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Unsupervised / generative modeling</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Applicable for data augmentation and exploring counterfactuals where real examples are scarce; not sufficient for causal discovery or deriving mechanistic models.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Useful to generate difficult or rare examples for training/robustness (e.g., crash scenarios) and to probe model limitations; however, generated data can still reflect biases of the original dataset.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Can reduce need for costly real-world data collection and enable testing of edge cases; limited in producing explanatory scientific insights.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared conceptually to simulation-based and model-driven generation; generative ML provides flexible data-driven synthesis but lacks guarantees from mechanistic simulators.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Quality and diversity of training data, architecture/stability improvements, and integration with domain constraints to avoid unrealistic samples.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Generative models help explore rare or dangerous scenarios and augment scarce data, but they inherit dataset biases and do not replace mechanistic simulations for causal understanding.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Future of Fundamental Science Led by Generative Closed-Loop Artificial Intelligence', 'publication_date_yy_mm': '2023-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2336.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2336.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Large Language Models</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Large Language Models (LLMs, transformer-based foundation models)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Large transformer-based statistical models trained on massive text corpora to predict or generate natural language and perform language understanding and synthesis tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Knowledge synthesis, hypothesis generation, experimental protocol translation, literature mining across all scientific domains</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Digest and synthesise vast human scientific literature, translate high-level human conjectures into modular computational tasks, propose hypotheses and design experiments expressed in natural language.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Require extremely large corpora of scientific and general text; training benefits from abundant, diverse, and high-quality literature; for niche domains data may be limited and degrade performance.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Unstructured text (natural language) possibly combined with code and structured scientific metadata when fine-tuned.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>High: complex long-range dependencies in text, need to maintain factuality and avoid hallucinations; exploration of long-tail or novel hypotheses requires calibrated sampling (temperature) and grounding.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Rapidly maturing; widely adopted for NLP tasks but still limited in rigorous causal reasoning and trustworthy mechanistic discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>High in fundamental science contexts: outputs must be verifiable and interpretable; LLMs often lack internally aligned mechanistic explanations, so external verification is needed.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Transformer-based Large Language Models</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Self-attention-based transformer architectures trained with autoregressive or masked language modelling objectives on massive corpora; used as interfaces to translate goals into sub-tasks, to mine literature, and to assist experiment design, but their internal statistical nature can produce ungrounded outputs requiring symbolic/mechanistic verification.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Foundation models / self-supervised learning</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Highly applicable as a language interface for scientists and to synthesise literature; limited when used alone for generating novel mechanistic theories without integration with causal or model-driven components.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Promising for hypothesis-space exploration and interfacing human goals with automated modules, but currently limited by statistical biases, hallucinations, and lack of deep causal understanding; authors recommend supplementing LLMs with symbolic, active, or causal methods.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>High potential to accelerate literature review, translate high-level ideas into executable experimental plans, and democratise access to scientific knowledge; risk of reinforcing dataset biases and producing unreliable conjectures without verification.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared to purely statistical ML and symbolic approaches: LLMs excel at natural-language integration but lack causal/mechanistic guarantees provided by symbolic/model-driven methods.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Large, diverse, high-quality training corpora; grounding mechanisms, integration with mechanistic verification systems, active learning to probe long-tail hypotheses.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>LLMs can be powerful translators and synthesizers for scientific workflows, but their statistical nature necessitates hybridisation with causal/model-driven methods to produce reliable mechanistic discoveries.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Future of Fundamental Science Led by Generative Closed-Loop Artificial Intelligence', 'publication_date_yy_mm': '2023-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2336.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2336.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AlphaFold 2</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>AlphaFold 2 (DeepMind protein structure prediction system)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A deep learning system that predicts 3D protein structures from amino acid sequences with high accuracy, representing a major application of ML to a fundamental scientific problem.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Protein folding / structural biology</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Predict the 3D atomic structure of proteins from their amino-acid sequences to accelerate understanding of function and drug design.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Leveraged large existing protein databases and structural data (e.g., PDB); abundant domain data and decades of curated experimental structures aided training and performance.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Sequence data and structural coordinates (multidimensional arrays describing atom positions); often combined with evolutionary multiple-sequence alignments.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Very high: large combinatorial conformational space, complex physics and energetics; AlphaFold reduced this by learning from data and leveraging structural priors.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Mature experimental domain with extensive prior data and mechanistic knowledge (biophysics, molecular dynamics); historical community benchmarks (CASP) provide evaluation standards.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>High for scientific acceptance, but AlphaFold focuses on predictive accuracy rather than providing full mechanistic explanatory models; interpretability limited.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Deep learning protein structure prediction (end-to-end deep transformer-based models)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>End-to-end neural architectures trained on sequence-to-structure mappings incorporating evolutionary and geometric priors; used large curated datasets and domain expertise embedded in inputs and training strategies.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Supervised / representation learning / domain-informed deep learning</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Highly applicable in protein structure prediction where large quantities of training data and established evaluation metrics (CASP GDT) exist; benefited from domain knowledge integration.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Described as a major success story: AlphaFold 2 achieved high GDT scores in CASP and significantly outperformed previous methods; however, it relied on extensive domain data and expertise and does not itself produce new physical laws.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>High impact on structural biology, enabling faster hypothesis generation for function and drug discovery, and large-scale structure databases; exemplifies ML success when clear evaluation metrics and abundant data exist.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared favorably to prior methods in CASP competitions; success attributed to architecture and training on abundant, curated data and integration of domain priors.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Large, high-quality structural datasets, clear evaluation metrics (CASP), integration of domain expertise and priors, and careful engineering of architecture and training.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>AlphaFold 2 demonstrates that ML can produce transformative predictive performance in domains with abundant curated data and well-defined evaluation criteria, but such success does not equate to discovery of new mechanistic laws.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Future of Fundamental Science Led by Generative Closed-Loop Artificial Intelligence', 'publication_date_yy_mm': '2023-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2336.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2336.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Robot Scientist</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Robot Scientist (automated hypothesis-led experimentation system)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An integrated robotic platform capable of autonomously generating hypotheses, designing and executing high-throughput experiments, and interpreting results, demonstrated in yeast functional genomics and drug screening.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Functional genomics, drug screening (experimental biology)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Automate hypothesis-driven experimental cycles including experiment design, execution, and analysis to accelerate discovery and reproducibility in high-throughput biological experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Operates in laboratory settings producing structured, high-throughput experimental data; data availability depends on the lab automation throughput but is typically abundant for the implemented assays.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Structured experimental measurement data, time-series or endpoint measurements from assays; machine-readable laboratory metadata.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Moderate-to-high: experimental design space combinatorial; requires integration of robotic execution, sensing, data analysis and model selection with resource/cost constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Applied in mature laboratory experimental domains with standard assays and protocols; domain expertise used to seed system operation.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Medium: system conducts hypothesis testing and can propose mechanistic explanations, but human interpretable mechanistic insight is often desired.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Automated experimental planning and analysis (rule-based and machine-learning components)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Combines knowledge representation, experiment design heuristics, and statistical analysis to autonomously propose and execute experiments in a closed-loop; integrates laboratory robotics with computational inference.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Hybrid (rule-based + statistical learning + automation)</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Applicable to high-throughput, well-instrumented laboratory workflows where experiments can be encoded and executed robotically; less applicable where experiments cannot be automated or require complex human judgement.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Demonstrated autonomous execution of hypothesis-led research in yeast functional genomics and drug screening, improving throughput and reproducibility; presented as a concrete example of closing the scientific loop.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Significant potential to accelerate reproducible experimental science and reduce human repetitive tasks; can enable larger-scale hypothesis testing than feasible manually.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Argued to outperform manual experimental pipelines in throughput and consistency; not directly compared numerically in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Laboratory automation infrastructure, machine-readable protocols, integration between planning algorithms and robotic execution, and clear evaluation metrics for experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Automated closed-loop experimental platforms can materially increase throughput and reproducibility in domains amenable to robotic execution, but require integration of knowledge representation and experiment automation.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Future of Fundamental Science Led by Generative Closed-Loop Artificial Intelligence', 'publication_date_yy_mm': '2023-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2336.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e2336.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Eureqa / Symbolic regression</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Eureqa (symbolic regression via evolutionary search)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A computational tool that performs symbolic regression by evolving mathematical expressions to fit time-series or other data, producing interpretable equations as models.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Model discovery from time-series and numerical datasets (general scientific modelling)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Find compact mathematical expressions that explain observed data, enabling interpretable, equation-based models rather than purely statistical predictors.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Requires measured time-series or numerical datasets of sufficient length and quality; typically moderate-sized datasets are used for symbolic regression.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Structured numerical/tabular/time-series data.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>High combinatorial search over space of symbolic expressions; tractability depends on chosen operator set and search heuristics.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Mature as a computational technique with historical tools; applicability depends on whether data can be explained compactly by analytic expressions.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>High: symbolic regression explicitly aims for interpretable mechanistic-like equations useful for scientific insight.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Symbolic regression via evolutionary/genetic programming (Eureqa)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Evolves mathematical expressions composed from building blocks (operators, functions) using evolutionary search to optimise fit to data, yielding human-readable equations that can suggest mechanistic relations.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Evolutionary search / symbolic AI / model discovery</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Appropriate when underlying processes admit compact symbolic descriptions and sufficient data exist; less effective for extremely noisy, high-dimensional datasets without strong low-dimensional structure.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Valuable for producing interpretable, equation-based models (a 'virtual data scientist') and for hypothesis generation; search complexity and overfitting can limit results without constraints or priors.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>High for domains seeking interpretable models and compact laws from data; can guide mechanistic hypothesis formation and reduce black-box dependence.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared conceptually to black-box statistical methods; offers interpretability advantage though potentially higher computational cost and search complexity.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Choice of function/operator primitives, regularisation favouring simplicity, adequate and informative data, and hybridisation with domain knowledge to constrain search.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Symbolic regression provides a direct route to interpretable, equation-like models when data support compact representations, but search complexity and noise sensitivity limit blind application.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Future of Fundamental Science Led by Generative Closed-Loop Artificial Intelligence', 'publication_date_yy_mm': '2023-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2336.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e2336.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DENDRAL</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>DENDRAL (early expert-system for organic chemistry)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>One of the earliest AI systems for scientific discovery, using rule-based expert systems to reason about chemical structure elucidation from mass spectrometry and related data.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Applications of Artificial Intelligence for Organic Chemistry: The DENDRAL Project</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Organic chemistry / structure elucidation</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Infer molecular structures compatible with observed analytical data (e.g., mass spectra) using encoded chemical knowledge and heuristic search.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Operates with specialized laboratory analytical data (mass spectrometry) and curated domain knowledge encoded as rules; data are structured and domain-specific.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Structured symbolic representations of molecules and measured spectra; rule-based knowledge bases.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Combinatorial complexity in potential molecular structures compatible with spectra; requires constrained search guided by domain rules.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Historically mature expert-system application domain with rich chemical knowledge to encode.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>High: DENDRAL was explicitly designed to produce human-understandable, rule-based explanations for structure assignments.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Rule-based expert system / symbolic AI</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Encodes domain heuristics and chemical rules to generate candidate structures and rank them against observed data; reasoning is symbolic and interpretable.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Symbolic/knowledge-based AI</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Highly applicable when rich domain knowledge can be formalised as rules and when data are the right format for rule application; less applicable for poorly understood domains.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Historically influential demonstration that symbolic AI can automate parts of scientific reasoning with interpretable outputs; limited by the need to encode extensive domain knowledge.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Showed feasibility of encoding expert knowledge to automate scientific tasks and served as a template for later AI-in-science systems.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Contrasted with later statistical ML approaches: DENDRAL emphasised interpretability but required heavier knowledge engineering.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Availability of codified domain knowledge, well-defined problem formalism, and the ability to express rules for inference.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Symbolic expert systems can deliver interpretable scientific reasoning when domain knowledge is codified, but their scalability depends on knowledge-engineering effort.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Future of Fundamental Science Led by Generative Closed-Loop Artificial Intelligence', 'publication_date_yy_mm': '2023-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2336.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e2336.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GALILEO</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GALILEO (Guided Analysis of Logical Inconsistencies Leads to Evolved Ontologies)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A project aiming to model and repair faulty theories in physics by detecting contradictions between theory and empirical evidence and evolving ontologies.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Theoretical physics / ontology repair and theory revision</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Detect logical inconsistencies between theoretical predictions and empirical data and propose repairs or evolved ontological representations to reconcile them.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Depends on the availability of theory predictions and empirical datasets for contradiction detection; often relies on symbolic/theoretical representations rather than large empirical corpora.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Symbolic representations of theories, logical propositions, and empirical counterexamples.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>High: requires logical inference over formalised theories, detection and resolution of contradictions, and search over ontology space; can be computationally intensive.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Conceptual/experimental â€” an earlier AI-in-physics project illustrating automated reasoning about theories; domain requires deep expert knowledge and formalisation.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>High: inherently aims at discovering or repairing mechanistic/theoretical descriptions and must remain interpretable to scientists.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Symbolic reasoning and ontology evolution</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Uses logical inference to identify contradictions and evolutionary or search procedures to modify ontologies/theories to fit evidence; emphasises explainable symbolic change.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Symbolic / knowledge-based / automated reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Applicable to domains where theories can be formalised symbolically and contradictions with data detected; less applicable where formalisation is infeasible.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Serves as a conceptual precursor showing potential for automated theory repair; practical scaling and automation challenges exist for complex modern theories.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Potential to help maintain consistency between theory and data and to propose targeted theoretical revisions, aiding scientific theory development.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Distinct from data-driven ML approaches; offers explainability advantages but demands formal symbolic encodings that are laborious to produce.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Ability to formalise theoretical statements, availability of contradictory empirical evidence, and mechanisms for guided ontology evolution.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Symbolic automated reasoning can target theory-level inconsistencies to propose interpretable repairs, but scaling to complex modern theories requires significant formalisation.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Future of Fundamental Science Led by Generative Closed-Loop Artificial Intelligence', 'publication_date_yy_mm': '2023-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2336.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e2336.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Algorithmic Information Dynamics (AID)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Algorithmic Information Dynamics (AID)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A framework for causal discovery and analysis based on algorithmic information theory and perturbation analysis that searches for generative models compatible with observations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Causal discovery and open-ended hypothesis generation across scientific domains</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Explore hypothesis spaces bottom-up by searching for generative (computable) models that explain observations, including handling stochastic, deterministic, and mixed processes.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Not prescriptive about dataset size; can operate with limited data but computational tractability is a concern; emphasis is on model-space exploration rather than reliance on large labelled datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Can work with symbolic or computable representations of processes and perturbation data; data may be time-series, network dynamics, or other observations amenable to perturbation analysis.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Very high: searches over large or unbounded algorithmic model spaces, confronting issues of intractability and uncomputability; requires heuristics to manage search.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Emerging research framework (conceptual and early-methodological development) rather than a widely deployed tool.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>High: explicitly targets mechanistic and causal model discovery and values interpretable generative explanations.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Algorithmic/model-driven discovery (AID)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Seeks agnostic generative models that are compatible with observational data using algorithmic information-theoretic criteria and perturbation/intervention analysis; aims for bottom-up exploration of hypothesis spaces, including open-ended and evolutionary search techniques.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Model-driven / causal discovery / algorithmic information theory</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Promising for domains where mechanistic generative explanations are required and where statistical methods confound causation with correlation; constrained by computational tractability for large model spaces.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Proposed as a promising route to abduction and counterfactual reasoning and to avoid statistical confounding, but noted to face intractability/uncomputability challenges and potential difficulty in human interpretability of some bottom-up results.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>High for foundational science seeking mechanistic laws and causal explanations; could enable exploration of novel hypothesis spaces unreachable by statistical ML alone if computational challenges can be mitigated.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Contrasts with statistical/graphical methods that estimate correlations; AID seeks generative models and is less biased towards purely stochastic assumptions but is more computationally demanding.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Development of tractable heuristics, hybridisation with symbolic and statistical methods, and computational resources to explore algorithmic model spaces.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>AID offers a principled bottom-up path to mechanistic causal discovery, especially for non-stochastic or mixed generative processes, but practical utility hinges on computational strategies to manage intractable model spaces.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Future of Fundamental Science Led by Generative Closed-Loop Artificial Intelligence', 'publication_date_yy_mm': '2023-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2336.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e2336.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Physics-informed ML</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Physics-informed machine learning</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Machine learning methods that incorporate physical laws, conservation principles, or differential equation constraints as inductive priors to improve learning, generalisation, and interpretability.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Physical sciences, fluid dynamics, materials, and other domains governed by known physical laws</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Improve predictive performance and ensure physical plausibility by embedding known equations/constraints into ML models to reduce data requirements and enhance extrapolation.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Helpful when data are limited or expensive to collect; physics priors can compensate for scarce labelled data by constraining solution space.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Often spatio-temporal numerical data, simulation outputs, or sensor measurements that are amenable to differential equation constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>High: model must satisfy PDEs or other constraints while learning from noisy/limited data; trade-offs between fidelity to physics and data fit.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Growing and increasingly adopted; several research efforts integrating ML with mechanistic models are ongoing.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>High: design explicitly encodes mechanistic constraints and seeks interpretable/physically consistent solutions.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Physics-informed machine learning / physics-constrained neural networks</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Augment learning objectives with terms enforcing differential equations, conservation laws, or invariants; architectures may include structured priors or penalty terms to encourage physical consistency.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Hybrid / physics-informed ML</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Appropriate where reliable mechanistic equations exist to impose as priors and where extrapolation/generalisation beyond available data is needed.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Promising for improving generalisation and reducing data needs; still an active research area to understand limits and best practices.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>High for bridging data-driven methods with mechanistic science, enabling more trustworthy predictions and aiding discovery when partial mechanistic knowledge exists.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Offers better extrapolation and physical consistency compared to unconstrained statistical models; requires credible mechanistic knowledge which may not always be available.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Quality and correctness of the embedded physical priors, careful weighting between data and physics loss terms, and appropriate architecture choices.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Incorporating mechanistic priors into ML models improves scientific applicability and trustworthiness, especially in data-limited regimes, but depends critically on the correctness of the priors.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Future of Fundamental Science Led by Generative Closed-Loop Artificial Intelligence', 'publication_date_yy_mm': '2023-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2336.10">
                <h3 class="extraction-instance">Extracted Data Instance 10 (e2336.10)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Neuro-symbolic / hybrid models</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Neuro-symbolic (hybrid neural-symbolic) approaches</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Methods combining statistical learning (neural networks) with symbolic reasoning or knowledge representation to leverage pattern recognition and high-level abstraction/logic.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Scientific model discovery, knowledge integration, reasoning and interpretability across domains</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Merge strengths of neural models (perception, pattern extraction) with symbolic systems (logic, rules, causal reasoning) to enable abstraction, generalisation, and interpretable inference for scientific tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Can operate across data regimes: neural components benefit from data abundance; symbolic parts require curated rules/ontologies but can work with less data.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Heterogeneous: unstructured text and images for neural components, structured symbolic knowledge graphs or ontologies for symbolic parts.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>High: requires interfacing disparate representations and ensuring consistent reasoning across statistical and symbolic components.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Emerging and actively researched; identified by authors as promising for discovery tasks requiring both perception and abstraction.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>High: designed to provide interpretable reasoning and map to mechanistic explanations where needed.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Neuro-symbolic hybrid models</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Architectures combine learned vector representations and neural inference with symbolic logic engines, rules, or causal calculus to perform tasks requiring both pattern recognition and high-level reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Hybrid (neural + symbolic)</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Highly applicable to scientific domains requiring both data-driven discovery and interpretable causal reasoning; proposed as a way to overcome limits of purely statistical ML.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Promoted as a crucial direction to enable abstraction and inference beyond statistical correlations; practical integration remains challenging and an active area of work.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Potentially high to enable mechanistic insight from large datasets and to bridge human-understandable reasoning with ML-scale pattern detection.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Offers interpretability and causal reasoning advantages over purely neural models, and scalability and perception advantages over purely symbolic systems.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Effective interfaces between neural and symbolic modules, good knowledge representation, and alignment of objectives across components.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Neuro-symbolic hybrids are promising for scientific discovery because they combine perceptual power with interpretable reasoning needed for mechanistic insights.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Future of Fundamental Science Led by Generative Closed-Loop Artificial Intelligence', 'publication_date_yy_mm': '2023-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2336.11">
                <h3 class="extraction-instance">Extracted Data Instance 11 (e2336.11)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Statistical Relational Learning (SRL)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Statistical Relational Learning (SRL)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A family of methods combining relational (first-order) representations with probabilistic graphical models to model structured, relational scientific data with uncertainty.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Biomedicine, bioinformatics, and other domains with relational structured data (e.g., gene-disease networks)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Represent and learn probabilistic relationships over relational domains to integrate background scientific knowledge and discover structured dependencies.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Depends on availability of structured relational databases and ontologies; can leverage existing bio-ontologies and integrated datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Relational/graph-structured data with entities and relations; can combine symbolic facts with probabilistic annotations.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>High: inference and learning over large relational domains can be computationally expensive; requires scalable probabilistic inference over first-order structures.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Established research area with applications in bioinformatics; maturity varies by implementation and scale.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Medium-to-high: supports interpretable relational models and incorporation of background knowledge for mechanistic reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Statistical relational learning (probabilistic logic models, relational learning)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Frameworks that represent beliefs about relational data using probabilistic graphical models over first-order predicate logic, enabling incorporation of background knowledge and learning of structured dependencies.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Probabilistic / symbolic-hybrid</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Appropriate when structured domain knowledge and relational data exist and when interpretability is important; can exploit ontologies and knowledge bases.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Useful to integrate background scientific knowledge and learn over structured objects; offers interpretable relational models though scaling and inference complexity can be limiting.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Good for domains like genomics or drug-repurposing where relations and background knowledge are critical; enables hypothesis generation grounded in existing ontologies.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Provides structured, interpretable modeling advantages over flat statistical models; may be less scalable than purely neural methods.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Availability of curated ontologies and relational datasets, efficient inference algorithms, and integration with domain knowledge.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>SRL enables probabilistic modelling over relational scientific knowledge, making it effective where structured ontologies and interpretability are required, but computational scalability is a challenge.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Future of Fundamental Science Led by Generative Closed-Loop Artificial Intelligence', 'publication_date_yy_mm': '2023-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2336.12">
                <h3 class="extraction-instance">Extracted Data Instance 12 (e2336.12)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Active learning / bandit methods</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Active learning and bandit-style optimisation methods</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Adaptive sampling and optimisation techniques that select experiments or data points to maximise information gain or reward under budget constraints, reducing experimental cost.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Experimental design in materials, chemistry, battery optimisation, and biology</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Efficiently choose experiments or measurements to perform so as to rapidly identify optimal conditions or informative data under cost/time constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Suited to regimes with limited experimental budget where labelled outcomes are expensive; initial datasets may be small and sequential data acquisition is planned.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Often tabular experimental condition â†’ outcome mappings; can be continuous parameter spaces or discrete options.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Moderate-to-high: balancing exploration vs exploitation, expensive-to-evaluate objective functions, potentially high-dimensional parameter spaces.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Mature in ML research and increasingly applied in scientific experimental optimisation.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Low-to-medium: primarily focused on efficient empirical optimisation rather than mechanistic explanation, though results can feed mechanistic modelling.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Active learning / Bayesian optimisation / multi-armed bandits</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Iteratively selects next experiments to maximise utility (information gain, expected improvement) using acquisition functions and models (e.g., Gaussian processes or surrogate models); bandit methods manage exploration-exploitation trade-offs.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Sequential decision-making / reinforcement-style / Bayesian optimisation</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Highly applicable when experiments are costly and sequential selection can greatly reduce required runs; requires a surrogate model and utility metric.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Shown to reduce experimental campaigns and accelerate design (e.g., battery design, biological condition optimisation); effectiveness depends on surrogate model fidelity and acquisition strategy.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>High for resource-limited experimental programmes, enabling faster convergence to optimal conditions and reducing cost/time.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Outperforms naive or grid search experimental strategies in many contexts; paper notes Bayesian approaches empirically outperform manual experiment selection.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Accurate surrogate models, well-chosen acquisition functions, and realistic noise/error models for experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Active learning and bandit methods can dramatically reduce experimental effort by focusing on maximally informative experiments, particularly in costly laboratory contexts.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Future of Fundamental Science Led by Generative Closed-Loop Artificial Intelligence', 'publication_date_yy_mm': '2023-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2336.13">
                <h3 class="extraction-instance">Extracted Data Instance 13 (e2336.13)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Bayesian experiment selection</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Bayesian experiment selection / Bayesian optimal experimental design</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Frameworks that quantify the expected information gain or utility of candidate experiments under probabilistic models and select experiments to maximise expected scientific return.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Experimental design across scientific disciplines (e.g., Robot Scientist applications)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Determine which experiments to run next to most effectively test hypotheses or reduce uncertainty given costs and time constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Operates with prior probability models and can function with moderate existing data; effectiveness increases with quality of priors and likelihood models.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Probabilistic models over experimental outcomes; data are structured experimental results with associated uncertainties.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>High: computationally expensive to evaluate expected utilities over large experiment spaces; requires probabilistic modelling and integration.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Established statistical framework with practical implementations in automated experimental systems.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Medium-to-high: Bayesian methods provide uncertainty quantification which aids mechanistic interpretation, but require specification of priors and likelihoods.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Bayesian optimal experiment selection</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Compute expected value or information gain of candidate experiments under a posterior predictive model and select experiments maximising utility accounting for costs; used to automate experiment scheduling.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Probabilistic modeling / decision theory</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Well-suited when credible probabilistic models and evaluation metrics exist; paper notes Bayesian selection empirically outperforms manual choices.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Reported as empirically sound and effective in reducing number of experiments needed and prioritising valuable tests; practical utility seen in Robot Scientist and similar systems.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Substantial for making experiment-driven science more efficient and principled, improving resource allocation and speeding discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Shown to outperform manual experiment selection strategies in cited empirical work; no numeric comparisons in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Accurate prior models, tractable computation of expected utility, and clear experimental cost modelling.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Bayesian experiment selection provides a principled way to prioritise experiments and can accelerate discovery by optimising information gain under uncertainty.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Future of Fundamental Science Led by Generative Closed-Loop Artificial Intelligence', 'publication_date_yy_mm': '2023-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2336.14">
                <h3 class="extraction-instance">Extracted Data Instance 14 (e2336.14)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Adversarial testing for causality</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Adversarial example generation for robustness and causal probing</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Using adversarial generation techniques to produce challenging examples that probe model robustness and help learn causal relations by exposing failures.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Robustness testing (autonomous driving, classification systems) and probing causal learning</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Generate edge-case or adversarial scenarios that reveal model weaknesses and encourage learning of causal relationships rather than spurious correlations.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Used when rare or dangerous events are under-represented in real datasets; generation supplements limited empirical data.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Typically high-dimensional input domains (images, sensor streams); generated examples are of the same structure as training inputs.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Moderate-to-high: crafting meaningful adversarial examples that correspond to realistic but rare events is challenging; ensuring coverage of causal factors is nontrivial.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Well-studied in ML robustness literature; application to causal learning is exploratory.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Medium: goal is to push models toward causal features rather than relying on correlational cues; interpretability of failures aids causal understanding.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Adversarial generation / adversarial networks for stress-testing</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Use adversarial objectives or generators to create inputs that cause model errors or represent rare events; these examples are used to retrain or analyse models for robustness and causal sensitivity.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Generative / adversarial / robustness testing</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Applicable to safety-critical domains and for diagnosing when models rely on spurious patterns; does not in itself identify causal mechanisms but helps surface weaknesses.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Helps identify brittleness and spurious pattern reliance; can produce realistic stress scenarios for retraining, though may produce unrealistic examples without domain constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Important for improving safety and reliability of ML systems and for moving models toward causal feature reliance when combined with proper grounding.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Provides complementary advantages to simulation-based stress testing; adversarial examples can be cheaper but risk producing non-physical cases unless constrained.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Domain-constrained generators, realistic modelling of rare events, and coupling with retraining or causal analysis procedures.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Adversarial generation is useful to reveal and mitigate spurious pattern reliance in ML models, aiding robustness and indirectly supporting causal learning when properly constrained.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Future of Fundamental Science Led by Generative Closed-Loop Artificial Intelligence', 'publication_date_yy_mm': '2023-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2336.15">
                <h3 class="extraction-instance">Extracted Data Instance 15 (e2336.15)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Knowledge representation & ontologies (GO)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Knowledge representation systems and ontologies (e.g., Gene Ontology)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Structured vocabularies and ontologies used to encode biological knowledge in machine-readable form, enabling integration, querying, and computational reasoning across datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Bioinformatics, systems biology, integrative biology</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Provide standardized, computable representations of biological entities, processes, and experimental metadata to support integration, reasoning, and automated hypothesis testing.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Large, curated ontologies and associated annotation databases exist (e.g., GO, Human Phenotype Ontology); widely accessible and machine-readable.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Structured symbolic graphs/ontologies with hierarchical relations, controlled vocabularies, and annotations linking entities to data.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Moderate-to-high: constructing, aligning, and maintaining ontologies across diverse datasets is laborious; reasoning over large knowledge graphs can be computationally heavy.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Mature in many biological subfields with well-established ontologies and integration efforts (e.g., Monarch).</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>High: ontologies facilitate interpretable integration and reasoning and are crucial where mechanistic interpretability is required.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Knowledge representation using ontologies and knowledge graphs</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Use curated ontologies (Gene Ontology, Human Phenotype Ontology, etc.) and knowledge integration platforms to represent domain knowledge, support reasoning, and augment data-driven methods.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Symbolic / knowledge-based</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Highly applicable in biology and medicine where community ontologies exist; essential for combining datasets and enabling explainable reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Enables machine-readable domain knowledge ingestion and supports downstream ML and reasoning; reduces curation duplication and improves contextualisation of new findings.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>High for accelerating integrative analyses, reproducibility, and automated hypothesis evaluation in bioinformatics.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Outperforms ad-hoc or unstructured representations for interoperability and explainability; requires community curation effort.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Community adoption, comprehensive curation, clear standards for annotations, and tooling for integration with ML systems.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Structured ontologies are foundational for integrating domain knowledge with AI systems, enabling interpretable and reproducible discovery in biology.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Future of Fundamental Science Led by Generative Closed-Loop Artificial Intelligence', 'publication_date_yy_mm': '2023-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2336.16">
                <h3 class="extraction-instance">Extracted Data Instance 16 (e2336.16)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Open-ended evolutionary computation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Open-ended evolutionary computation and evolutionary search</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Algorithms that simulate evolutionary processes to explore vast hypothesis or design spaces adaptively, generating novel and unexpected solutions over time.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Hypothesis generation, design discovery, automated model search across scientific and engineering domains</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Search unbounded or large design/hypothesis spaces to produce novel candidate models, experiments, or designs without strong prior specification.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Does not require large labelled datasets; evaluation depends on fitness functions or experimental evaluation pipelines which may be costly.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Candidate solutions often symbolic or encoded genomes; fitness evaluations produce scalar rewards or scores.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Very high: open-ended search over huge or unbounded spaces, risk of brittleness or drifting into uninteresting regions without careful objective design.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Established as a research area with practical successes in optimization and creative search; open-endedness remains an active challenge.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Variable: often produces novel artefacts that may require post-hoc interpretation; can be paired with mechanisms to favour interpretable solutions.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Evolutionary algorithms / open-ended evolutionary computation</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Population-based search using variation (mutation/crossover) and selection guided by fitness; extended schemes promote novelty and open-ended exploration rather than optimisation toward a fixed objective.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Evolutionary / optimisation / generative search</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Good for exploratory hypothesis generation and design where objectives are hard to formalise; needs evaluation mechanisms (simulators or experiments) to assess candidates.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Useful for finding unexpected solutions and exploring creative spaces; can be computationally intensive and may generate un-interpretable or impractical solutions without constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Potentially high for discovery in poorly specified domains and for generating novel hypotheses or designs beyond human intuition.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Offers broader exploration than gradient-based optimisation; lacks gradient efficiency and may require many evaluations.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Well-designed fitness or novelty metrics, integration with efficient evaluation (simulators or automated experiments), and constraints to maintain scientific relevance.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Open-ended evolutionary methods enable exploration of vast hypothesis spaces and discovery of novel candidates, but require effective evaluation and constraints to produce scientifically useful outcomes.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Future of Fundamental Science Led by Generative Closed-Loop Artificial Intelligence', 'publication_date_yy_mm': '2023-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Highly accurate protein structure prediction with AlphaFold <em>(Rating: 2)</em></li>
                <li>Applications of Artificial Intelligence for Organic Chemistry: The DENDRAL Project <em>(Rating: 2)</em></li>
                <li>Causality: Models, Reasoning and Inference <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2336",
    "paper_id": "paper-259936960",
    "extraction_schema_id": "extraction-schema-63",
    "extracted_data": [
        {
            "name_short": "Deep neural networks",
            "name_full": "Deep neural networks (deep learning)",
            "brief_description": "Multi-layer neural network models that learn hierarchical representations from data and have been widely applied for pattern recognition, prediction, and representation tasks in scientific domains.",
            "citation_title": "",
            "mention_or_use": "mention",
            "scientific_problem_domain": "General across domains (protein folding, image-based sensing, classification tasks)",
            "problem_description": "Learning predictive mappings or representations from high-dimensional empirical data (images, sequences, tabular measurements) to perform classification, regression, or representation learning to support scientific analysis.",
            "data_availability": "Often large-scale/abundant in successful applications (e.g., protein sequence databases used by folding models); performance depends on access to extensive labelled datasets; quality varies by domain; when data scarce, deep nets struggle without augmentation or priors.",
            "data_structure": "High-dimensional numerical arrays (images, sequences, tensors), sometimes multimodal when combined with other data types; typically structured but represented as dense vectors/matrices.",
            "problem_complexity": "High: large parameter counts (millions), nonlinear function approximation, high-dimensional search spaces, potential overparameterisation and overfitting without sufficient data or regularisation.",
            "domain_maturity": "Varies by domain: mature in imaging and some bioinformatics tasks (where historic datasets exist), less mature where labeled large datasets are scarce or mechanistic models dominate.",
            "mechanistic_understanding_requirements": "Medium to high in fundamental science â€” authors emphasise that black-box deep nets are insufficient where mechanistic/causal insight is needed; interpretability often required.",
            "ai_methodology_name": "Deep neural networks (including convolutional networks, LSTMs, transformers)",
            "ai_methodology_description": "Stacked layers of nonlinear units trained by gradient-based optimisation on large datasets to minimise loss functions; architectures include convolutions for spatial data and transformer attention for sequence/text; often lack explicit mechanistic structure and require large labelled datasets or domain priors.",
            "ai_methodology_category": "Supervised / representation learning (with unsupervised and self-supervised variants)",
            "applicability": "Applicable for pattern recognition and prediction tasks with abundant data; less appropriate alone for hypothesis generation or causal discovery in fundamental-science contexts without integration with symbolic or mechanistic methods.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "Worked well for classification and representation tasks (e.g., image, sequence tasks) but are described as 'black boxes' with limitations for causality and interpreting new mechanistic laws; susceptible to spurious correlations and poor generalisation outside training distribution.",
            "impact_potential": "High for accelerating data-rich experimental workflows, noise filtering, and prediction tasks; limited for producing new fundamental explanatory theories without hybridisation with mechanistic/symbolic approaches.",
            "comparison_to_alternatives": "Paper contrasts deep networks' statistical strengths with their lack of causal inference and interpretability versus symbolic or model-driven approaches; no quantitative comparison provided.",
            "success_factors": "Availability of large, high-quality labelled datasets; appropriate architectural inductive biases (e.g., convolution for images); integration with domain knowledge or priors to mitigate black-box limitations.",
            "key_insight": "Deep neural networks excel at pattern extraction when abundant labelled data exist but are insufficient alone for discovering mechanistic scientific laws due to interpretability and causal inference gaps.",
            "uuid": "e2336.0",
            "source_info": {
                "paper_title": "The Future of Fundamental Science Led by Generative Closed-Loop Artificial Intelligence",
                "publication_date_yy_mm": "2023-07"
            }
        },
        {
            "name_short": "Generative models / GANs",
            "name_full": "Generative adversarial networks and other generative models",
            "brief_description": "Models trained to generate novel synthetic data (images, sequences, examples) by learning the data distribution, often via adversarial training between generator and discriminator networks.",
            "citation_title": "",
            "mention_or_use": "mention",
            "scientific_problem_domain": "Data augmentation, simulation, scenario generation across domains (e.g., driving simulations, adversarial example generation)",
            "problem_description": "Produce synthetic examples to expand training datasets, explore rare event spaces, or test model robustness by generating counterexamples (e.g., crash scenarios for autonomous vehicles).",
            "data_availability": "Used when real-world data of rare events are limited; require existing datasets to learn distribution; quality depends on training data representativeness.",
            "data_structure": "High-dimensional continuous data (images, signals) typically represented as tensors.",
            "problem_complexity": "Moderate-to-high: training instability (mode collapse), need for careful balancing of generator and discriminator; exploring long-tail rare events is challenging.",
            "domain_maturity": "Moderately mature for image and signal domains; emerging usage in scientific simulation and robustness testing.",
            "mechanistic_understanding_requirements": "Low-to-medium: generative models are mainly used for producing examples rather than providing mechanistic explanations; interpretability limited.",
            "ai_methodology_name": "Generative adversarial networks and other generative architectures",
            "ai_methodology_description": "Adversarial training where a generator network proposes examples and a discriminator network classifies real vs generated; used to create synthetic data for training, stress-testing models, or exploring hypothetical scenarios.",
            "ai_methodology_category": "Unsupervised / generative modeling",
            "applicability": "Applicable for data augmentation and exploring counterfactuals where real examples are scarce; not sufficient for causal discovery or deriving mechanistic models.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "Useful to generate difficult or rare examples for training/robustness (e.g., crash scenarios) and to probe model limitations; however, generated data can still reflect biases of the original dataset.",
            "impact_potential": "Can reduce need for costly real-world data collection and enable testing of edge cases; limited in producing explanatory scientific insights.",
            "comparison_to_alternatives": "Compared conceptually to simulation-based and model-driven generation; generative ML provides flexible data-driven synthesis but lacks guarantees from mechanistic simulators.",
            "success_factors": "Quality and diversity of training data, architecture/stability improvements, and integration with domain constraints to avoid unrealistic samples.",
            "key_insight": "Generative models help explore rare or dangerous scenarios and augment scarce data, but they inherit dataset biases and do not replace mechanistic simulations for causal understanding.",
            "uuid": "e2336.1",
            "source_info": {
                "paper_title": "The Future of Fundamental Science Led by Generative Closed-Loop Artificial Intelligence",
                "publication_date_yy_mm": "2023-07"
            }
        },
        {
            "name_short": "Large Language Models",
            "name_full": "Large Language Models (LLMs, transformer-based foundation models)",
            "brief_description": "Large transformer-based statistical models trained on massive text corpora to predict or generate natural language and perform language understanding and synthesis tasks.",
            "citation_title": "",
            "mention_or_use": "mention",
            "scientific_problem_domain": "Knowledge synthesis, hypothesis generation, experimental protocol translation, literature mining across all scientific domains",
            "problem_description": "Digest and synthesise vast human scientific literature, translate high-level human conjectures into modular computational tasks, propose hypotheses and design experiments expressed in natural language.",
            "data_availability": "Require extremely large corpora of scientific and general text; training benefits from abundant, diverse, and high-quality literature; for niche domains data may be limited and degrade performance.",
            "data_structure": "Unstructured text (natural language) possibly combined with code and structured scientific metadata when fine-tuned.",
            "problem_complexity": "High: complex long-range dependencies in text, need to maintain factuality and avoid hallucinations; exploration of long-tail or novel hypotheses requires calibrated sampling (temperature) and grounding.",
            "domain_maturity": "Rapidly maturing; widely adopted for NLP tasks but still limited in rigorous causal reasoning and trustworthy mechanistic discovery.",
            "mechanistic_understanding_requirements": "High in fundamental science contexts: outputs must be verifiable and interpretable; LLMs often lack internally aligned mechanistic explanations, so external verification is needed.",
            "ai_methodology_name": "Transformer-based Large Language Models",
            "ai_methodology_description": "Self-attention-based transformer architectures trained with autoregressive or masked language modelling objectives on massive corpora; used as interfaces to translate goals into sub-tasks, to mine literature, and to assist experiment design, but their internal statistical nature can produce ungrounded outputs requiring symbolic/mechanistic verification.",
            "ai_methodology_category": "Foundation models / self-supervised learning",
            "applicability": "Highly applicable as a language interface for scientists and to synthesise literature; limited when used alone for generating novel mechanistic theories without integration with causal or model-driven components.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "Promising for hypothesis-space exploration and interfacing human goals with automated modules, but currently limited by statistical biases, hallucinations, and lack of deep causal understanding; authors recommend supplementing LLMs with symbolic, active, or causal methods.",
            "impact_potential": "High potential to accelerate literature review, translate high-level ideas into executable experimental plans, and democratise access to scientific knowledge; risk of reinforcing dataset biases and producing unreliable conjectures without verification.",
            "comparison_to_alternatives": "Compared to purely statistical ML and symbolic approaches: LLMs excel at natural-language integration but lack causal/mechanistic guarantees provided by symbolic/model-driven methods.",
            "success_factors": "Large, diverse, high-quality training corpora; grounding mechanisms, integration with mechanistic verification systems, active learning to probe long-tail hypotheses.",
            "key_insight": "LLMs can be powerful translators and synthesizers for scientific workflows, but their statistical nature necessitates hybridisation with causal/model-driven methods to produce reliable mechanistic discoveries.",
            "uuid": "e2336.2",
            "source_info": {
                "paper_title": "The Future of Fundamental Science Led by Generative Closed-Loop Artificial Intelligence",
                "publication_date_yy_mm": "2023-07"
            }
        },
        {
            "name_short": "AlphaFold 2",
            "name_full": "AlphaFold 2 (DeepMind protein structure prediction system)",
            "brief_description": "A deep learning system that predicts 3D protein structures from amino acid sequences with high accuracy, representing a major application of ML to a fundamental scientific problem.",
            "citation_title": "",
            "mention_or_use": "mention",
            "scientific_problem_domain": "Protein folding / structural biology",
            "problem_description": "Predict the 3D atomic structure of proteins from their amino-acid sequences to accelerate understanding of function and drug design.",
            "data_availability": "Leveraged large existing protein databases and structural data (e.g., PDB); abundant domain data and decades of curated experimental structures aided training and performance.",
            "data_structure": "Sequence data and structural coordinates (multidimensional arrays describing atom positions); often combined with evolutionary multiple-sequence alignments.",
            "problem_complexity": "Very high: large combinatorial conformational space, complex physics and energetics; AlphaFold reduced this by learning from data and leveraging structural priors.",
            "domain_maturity": "Mature experimental domain with extensive prior data and mechanistic knowledge (biophysics, molecular dynamics); historical community benchmarks (CASP) provide evaluation standards.",
            "mechanistic_understanding_requirements": "High for scientific acceptance, but AlphaFold focuses on predictive accuracy rather than providing full mechanistic explanatory models; interpretability limited.",
            "ai_methodology_name": "Deep learning protein structure prediction (end-to-end deep transformer-based models)",
            "ai_methodology_description": "End-to-end neural architectures trained on sequence-to-structure mappings incorporating evolutionary and geometric priors; used large curated datasets and domain expertise embedded in inputs and training strategies.",
            "ai_methodology_category": "Supervised / representation learning / domain-informed deep learning",
            "applicability": "Highly applicable in protein structure prediction where large quantities of training data and established evaluation metrics (CASP GDT) exist; benefited from domain knowledge integration.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "Described as a major success story: AlphaFold 2 achieved high GDT scores in CASP and significantly outperformed previous methods; however, it relied on extensive domain data and expertise and does not itself produce new physical laws.",
            "impact_potential": "High impact on structural biology, enabling faster hypothesis generation for function and drug discovery, and large-scale structure databases; exemplifies ML success when clear evaluation metrics and abundant data exist.",
            "comparison_to_alternatives": "Compared favorably to prior methods in CASP competitions; success attributed to architecture and training on abundant, curated data and integration of domain priors.",
            "success_factors": "Large, high-quality structural datasets, clear evaluation metrics (CASP), integration of domain expertise and priors, and careful engineering of architecture and training.",
            "key_insight": "AlphaFold 2 demonstrates that ML can produce transformative predictive performance in domains with abundant curated data and well-defined evaluation criteria, but such success does not equate to discovery of new mechanistic laws.",
            "uuid": "e2336.3",
            "source_info": {
                "paper_title": "The Future of Fundamental Science Led by Generative Closed-Loop Artificial Intelligence",
                "publication_date_yy_mm": "2023-07"
            }
        },
        {
            "name_short": "Robot Scientist",
            "name_full": "Robot Scientist (automated hypothesis-led experimentation system)",
            "brief_description": "An integrated robotic platform capable of autonomously generating hypotheses, designing and executing high-throughput experiments, and interpreting results, demonstrated in yeast functional genomics and drug screening.",
            "citation_title": "",
            "mention_or_use": "mention",
            "scientific_problem_domain": "Functional genomics, drug screening (experimental biology)",
            "problem_description": "Automate hypothesis-driven experimental cycles including experiment design, execution, and analysis to accelerate discovery and reproducibility in high-throughput biological experiments.",
            "data_availability": "Operates in laboratory settings producing structured, high-throughput experimental data; data availability depends on the lab automation throughput but is typically abundant for the implemented assays.",
            "data_structure": "Structured experimental measurement data, time-series or endpoint measurements from assays; machine-readable laboratory metadata.",
            "problem_complexity": "Moderate-to-high: experimental design space combinatorial; requires integration of robotic execution, sensing, data analysis and model selection with resource/cost constraints.",
            "domain_maturity": "Applied in mature laboratory experimental domains with standard assays and protocols; domain expertise used to seed system operation.",
            "mechanistic_understanding_requirements": "Medium: system conducts hypothesis testing and can propose mechanistic explanations, but human interpretable mechanistic insight is often desired.",
            "ai_methodology_name": "Automated experimental planning and analysis (rule-based and machine-learning components)",
            "ai_methodology_description": "Combines knowledge representation, experiment design heuristics, and statistical analysis to autonomously propose and execute experiments in a closed-loop; integrates laboratory robotics with computational inference.",
            "ai_methodology_category": "Hybrid (rule-based + statistical learning + automation)",
            "applicability": "Applicable to high-throughput, well-instrumented laboratory workflows where experiments can be encoded and executed robotically; less applicable where experiments cannot be automated or require complex human judgement.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "Demonstrated autonomous execution of hypothesis-led research in yeast functional genomics and drug screening, improving throughput and reproducibility; presented as a concrete example of closing the scientific loop.",
            "impact_potential": "Significant potential to accelerate reproducible experimental science and reduce human repetitive tasks; can enable larger-scale hypothesis testing than feasible manually.",
            "comparison_to_alternatives": "Argued to outperform manual experimental pipelines in throughput and consistency; not directly compared numerically in this paper.",
            "success_factors": "Laboratory automation infrastructure, machine-readable protocols, integration between planning algorithms and robotic execution, and clear evaluation metrics for experiments.",
            "key_insight": "Automated closed-loop experimental platforms can materially increase throughput and reproducibility in domains amenable to robotic execution, but require integration of knowledge representation and experiment automation.",
            "uuid": "e2336.4",
            "source_info": {
                "paper_title": "The Future of Fundamental Science Led by Generative Closed-Loop Artificial Intelligence",
                "publication_date_yy_mm": "2023-07"
            }
        },
        {
            "name_short": "Eureqa / Symbolic regression",
            "name_full": "Eureqa (symbolic regression via evolutionary search)",
            "brief_description": "A computational tool that performs symbolic regression by evolving mathematical expressions to fit time-series or other data, producing interpretable equations as models.",
            "citation_title": "",
            "mention_or_use": "mention",
            "scientific_problem_domain": "Model discovery from time-series and numerical datasets (general scientific modelling)",
            "problem_description": "Find compact mathematical expressions that explain observed data, enabling interpretable, equation-based models rather than purely statistical predictors.",
            "data_availability": "Requires measured time-series or numerical datasets of sufficient length and quality; typically moderate-sized datasets are used for symbolic regression.",
            "data_structure": "Structured numerical/tabular/time-series data.",
            "problem_complexity": "High combinatorial search over space of symbolic expressions; tractability depends on chosen operator set and search heuristics.",
            "domain_maturity": "Mature as a computational technique with historical tools; applicability depends on whether data can be explained compactly by analytic expressions.",
            "mechanistic_understanding_requirements": "High: symbolic regression explicitly aims for interpretable mechanistic-like equations useful for scientific insight.",
            "ai_methodology_name": "Symbolic regression via evolutionary/genetic programming (Eureqa)",
            "ai_methodology_description": "Evolves mathematical expressions composed from building blocks (operators, functions) using evolutionary search to optimise fit to data, yielding human-readable equations that can suggest mechanistic relations.",
            "ai_methodology_category": "Evolutionary search / symbolic AI / model discovery",
            "applicability": "Appropriate when underlying processes admit compact symbolic descriptions and sufficient data exist; less effective for extremely noisy, high-dimensional datasets without strong low-dimensional structure.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "Valuable for producing interpretable, equation-based models (a 'virtual data scientist') and for hypothesis generation; search complexity and overfitting can limit results without constraints or priors.",
            "impact_potential": "High for domains seeking interpretable models and compact laws from data; can guide mechanistic hypothesis formation and reduce black-box dependence.",
            "comparison_to_alternatives": "Compared conceptually to black-box statistical methods; offers interpretability advantage though potentially higher computational cost and search complexity.",
            "success_factors": "Choice of function/operator primitives, regularisation favouring simplicity, adequate and informative data, and hybridisation with domain knowledge to constrain search.",
            "key_insight": "Symbolic regression provides a direct route to interpretable, equation-like models when data support compact representations, but search complexity and noise sensitivity limit blind application.",
            "uuid": "e2336.5",
            "source_info": {
                "paper_title": "The Future of Fundamental Science Led by Generative Closed-Loop Artificial Intelligence",
                "publication_date_yy_mm": "2023-07"
            }
        },
        {
            "name_short": "DENDRAL",
            "name_full": "DENDRAL (early expert-system for organic chemistry)",
            "brief_description": "One of the earliest AI systems for scientific discovery, using rule-based expert systems to reason about chemical structure elucidation from mass spectrometry and related data.",
            "citation_title": "Applications of Artificial Intelligence for Organic Chemistry: The DENDRAL Project",
            "mention_or_use": "mention",
            "scientific_problem_domain": "Organic chemistry / structure elucidation",
            "problem_description": "Infer molecular structures compatible with observed analytical data (e.g., mass spectra) using encoded chemical knowledge and heuristic search.",
            "data_availability": "Operates with specialized laboratory analytical data (mass spectrometry) and curated domain knowledge encoded as rules; data are structured and domain-specific.",
            "data_structure": "Structured symbolic representations of molecules and measured spectra; rule-based knowledge bases.",
            "problem_complexity": "Combinatorial complexity in potential molecular structures compatible with spectra; requires constrained search guided by domain rules.",
            "domain_maturity": "Historically mature expert-system application domain with rich chemical knowledge to encode.",
            "mechanistic_understanding_requirements": "High: DENDRAL was explicitly designed to produce human-understandable, rule-based explanations for structure assignments.",
            "ai_methodology_name": "Rule-based expert system / symbolic AI",
            "ai_methodology_description": "Encodes domain heuristics and chemical rules to generate candidate structures and rank them against observed data; reasoning is symbolic and interpretable.",
            "ai_methodology_category": "Symbolic/knowledge-based AI",
            "applicability": "Highly applicable when rich domain knowledge can be formalised as rules and when data are the right format for rule application; less applicable for poorly understood domains.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "Historically influential demonstration that symbolic AI can automate parts of scientific reasoning with interpretable outputs; limited by the need to encode extensive domain knowledge.",
            "impact_potential": "Showed feasibility of encoding expert knowledge to automate scientific tasks and served as a template for later AI-in-science systems.",
            "comparison_to_alternatives": "Contrasted with later statistical ML approaches: DENDRAL emphasised interpretability but required heavier knowledge engineering.",
            "success_factors": "Availability of codified domain knowledge, well-defined problem formalism, and the ability to express rules for inference.",
            "key_insight": "Symbolic expert systems can deliver interpretable scientific reasoning when domain knowledge is codified, but their scalability depends on knowledge-engineering effort.",
            "uuid": "e2336.6",
            "source_info": {
                "paper_title": "The Future of Fundamental Science Led by Generative Closed-Loop Artificial Intelligence",
                "publication_date_yy_mm": "2023-07"
            }
        },
        {
            "name_short": "GALILEO",
            "name_full": "GALILEO (Guided Analysis of Logical Inconsistencies Leads to Evolved Ontologies)",
            "brief_description": "A project aiming to model and repair faulty theories in physics by detecting contradictions between theory and empirical evidence and evolving ontologies.",
            "citation_title": "",
            "mention_or_use": "mention",
            "scientific_problem_domain": "Theoretical physics / ontology repair and theory revision",
            "problem_description": "Detect logical inconsistencies between theoretical predictions and empirical data and propose repairs or evolved ontological representations to reconcile them.",
            "data_availability": "Depends on the availability of theory predictions and empirical datasets for contradiction detection; often relies on symbolic/theoretical representations rather than large empirical corpora.",
            "data_structure": "Symbolic representations of theories, logical propositions, and empirical counterexamples.",
            "problem_complexity": "High: requires logical inference over formalised theories, detection and resolution of contradictions, and search over ontology space; can be computationally intensive.",
            "domain_maturity": "Conceptual/experimental â€” an earlier AI-in-physics project illustrating automated reasoning about theories; domain requires deep expert knowledge and formalisation.",
            "mechanistic_understanding_requirements": "High: inherently aims at discovering or repairing mechanistic/theoretical descriptions and must remain interpretable to scientists.",
            "ai_methodology_name": "Symbolic reasoning and ontology evolution",
            "ai_methodology_description": "Uses logical inference to identify contradictions and evolutionary or search procedures to modify ontologies/theories to fit evidence; emphasises explainable symbolic change.",
            "ai_methodology_category": "Symbolic / knowledge-based / automated reasoning",
            "applicability": "Applicable to domains where theories can be formalised symbolically and contradictions with data detected; less applicable where formalisation is infeasible.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "Serves as a conceptual precursor showing potential for automated theory repair; practical scaling and automation challenges exist for complex modern theories.",
            "impact_potential": "Potential to help maintain consistency between theory and data and to propose targeted theoretical revisions, aiding scientific theory development.",
            "comparison_to_alternatives": "Distinct from data-driven ML approaches; offers explainability advantages but demands formal symbolic encodings that are laborious to produce.",
            "success_factors": "Ability to formalise theoretical statements, availability of contradictory empirical evidence, and mechanisms for guided ontology evolution.",
            "key_insight": "Symbolic automated reasoning can target theory-level inconsistencies to propose interpretable repairs, but scaling to complex modern theories requires significant formalisation.",
            "uuid": "e2336.7",
            "source_info": {
                "paper_title": "The Future of Fundamental Science Led by Generative Closed-Loop Artificial Intelligence",
                "publication_date_yy_mm": "2023-07"
            }
        },
        {
            "name_short": "Algorithmic Information Dynamics (AID)",
            "name_full": "Algorithmic Information Dynamics (AID)",
            "brief_description": "A framework for causal discovery and analysis based on algorithmic information theory and perturbation analysis that searches for generative models compatible with observations.",
            "citation_title": "",
            "mention_or_use": "mention",
            "scientific_problem_domain": "Causal discovery and open-ended hypothesis generation across scientific domains",
            "problem_description": "Explore hypothesis spaces bottom-up by searching for generative (computable) models that explain observations, including handling stochastic, deterministic, and mixed processes.",
            "data_availability": "Not prescriptive about dataset size; can operate with limited data but computational tractability is a concern; emphasis is on model-space exploration rather than reliance on large labelled datasets.",
            "data_structure": "Can work with symbolic or computable representations of processes and perturbation data; data may be time-series, network dynamics, or other observations amenable to perturbation analysis.",
            "problem_complexity": "Very high: searches over large or unbounded algorithmic model spaces, confronting issues of intractability and uncomputability; requires heuristics to manage search.",
            "domain_maturity": "Emerging research framework (conceptual and early-methodological development) rather than a widely deployed tool.",
            "mechanistic_understanding_requirements": "High: explicitly targets mechanistic and causal model discovery and values interpretable generative explanations.",
            "ai_methodology_name": "Algorithmic/model-driven discovery (AID)",
            "ai_methodology_description": "Seeks agnostic generative models that are compatible with observational data using algorithmic information-theoretic criteria and perturbation/intervention analysis; aims for bottom-up exploration of hypothesis spaces, including open-ended and evolutionary search techniques.",
            "ai_methodology_category": "Model-driven / causal discovery / algorithmic information theory",
            "applicability": "Promising for domains where mechanistic generative explanations are required and where statistical methods confound causation with correlation; constrained by computational tractability for large model spaces.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "Proposed as a promising route to abduction and counterfactual reasoning and to avoid statistical confounding, but noted to face intractability/uncomputability challenges and potential difficulty in human interpretability of some bottom-up results.",
            "impact_potential": "High for foundational science seeking mechanistic laws and causal explanations; could enable exploration of novel hypothesis spaces unreachable by statistical ML alone if computational challenges can be mitigated.",
            "comparison_to_alternatives": "Contrasts with statistical/graphical methods that estimate correlations; AID seeks generative models and is less biased towards purely stochastic assumptions but is more computationally demanding.",
            "success_factors": "Development of tractable heuristics, hybridisation with symbolic and statistical methods, and computational resources to explore algorithmic model spaces.",
            "key_insight": "AID offers a principled bottom-up path to mechanistic causal discovery, especially for non-stochastic or mixed generative processes, but practical utility hinges on computational strategies to manage intractable model spaces.",
            "uuid": "e2336.8",
            "source_info": {
                "paper_title": "The Future of Fundamental Science Led by Generative Closed-Loop Artificial Intelligence",
                "publication_date_yy_mm": "2023-07"
            }
        },
        {
            "name_short": "Physics-informed ML",
            "name_full": "Physics-informed machine learning",
            "brief_description": "Machine learning methods that incorporate physical laws, conservation principles, or differential equation constraints as inductive priors to improve learning, generalisation, and interpretability.",
            "citation_title": "",
            "mention_or_use": "mention",
            "scientific_problem_domain": "Physical sciences, fluid dynamics, materials, and other domains governed by known physical laws",
            "problem_description": "Improve predictive performance and ensure physical plausibility by embedding known equations/constraints into ML models to reduce data requirements and enhance extrapolation.",
            "data_availability": "Helpful when data are limited or expensive to collect; physics priors can compensate for scarce labelled data by constraining solution space.",
            "data_structure": "Often spatio-temporal numerical data, simulation outputs, or sensor measurements that are amenable to differential equation constraints.",
            "problem_complexity": "High: model must satisfy PDEs or other constraints while learning from noisy/limited data; trade-offs between fidelity to physics and data fit.",
            "domain_maturity": "Growing and increasingly adopted; several research efforts integrating ML with mechanistic models are ongoing.",
            "mechanistic_understanding_requirements": "High: design explicitly encodes mechanistic constraints and seeks interpretable/physically consistent solutions.",
            "ai_methodology_name": "Physics-informed machine learning / physics-constrained neural networks",
            "ai_methodology_description": "Augment learning objectives with terms enforcing differential equations, conservation laws, or invariants; architectures may include structured priors or penalty terms to encourage physical consistency.",
            "ai_methodology_category": "Hybrid / physics-informed ML",
            "applicability": "Appropriate where reliable mechanistic equations exist to impose as priors and where extrapolation/generalisation beyond available data is needed.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "Promising for improving generalisation and reducing data needs; still an active research area to understand limits and best practices.",
            "impact_potential": "High for bridging data-driven methods with mechanistic science, enabling more trustworthy predictions and aiding discovery when partial mechanistic knowledge exists.",
            "comparison_to_alternatives": "Offers better extrapolation and physical consistency compared to unconstrained statistical models; requires credible mechanistic knowledge which may not always be available.",
            "success_factors": "Quality and correctness of the embedded physical priors, careful weighting between data and physics loss terms, and appropriate architecture choices.",
            "key_insight": "Incorporating mechanistic priors into ML models improves scientific applicability and trustworthiness, especially in data-limited regimes, but depends critically on the correctness of the priors.",
            "uuid": "e2336.9",
            "source_info": {
                "paper_title": "The Future of Fundamental Science Led by Generative Closed-Loop Artificial Intelligence",
                "publication_date_yy_mm": "2023-07"
            }
        },
        {
            "name_short": "Neuro-symbolic / hybrid models",
            "name_full": "Neuro-symbolic (hybrid neural-symbolic) approaches",
            "brief_description": "Methods combining statistical learning (neural networks) with symbolic reasoning or knowledge representation to leverage pattern recognition and high-level abstraction/logic.",
            "citation_title": "",
            "mention_or_use": "mention",
            "scientific_problem_domain": "Scientific model discovery, knowledge integration, reasoning and interpretability across domains",
            "problem_description": "Merge strengths of neural models (perception, pattern extraction) with symbolic systems (logic, rules, causal reasoning) to enable abstraction, generalisation, and interpretable inference for scientific tasks.",
            "data_availability": "Can operate across data regimes: neural components benefit from data abundance; symbolic parts require curated rules/ontologies but can work with less data.",
            "data_structure": "Heterogeneous: unstructured text and images for neural components, structured symbolic knowledge graphs or ontologies for symbolic parts.",
            "problem_complexity": "High: requires interfacing disparate representations and ensuring consistent reasoning across statistical and symbolic components.",
            "domain_maturity": "Emerging and actively researched; identified by authors as promising for discovery tasks requiring both perception and abstraction.",
            "mechanistic_understanding_requirements": "High: designed to provide interpretable reasoning and map to mechanistic explanations where needed.",
            "ai_methodology_name": "Neuro-symbolic hybrid models",
            "ai_methodology_description": "Architectures combine learned vector representations and neural inference with symbolic logic engines, rules, or causal calculus to perform tasks requiring both pattern recognition and high-level reasoning.",
            "ai_methodology_category": "Hybrid (neural + symbolic)",
            "applicability": "Highly applicable to scientific domains requiring both data-driven discovery and interpretable causal reasoning; proposed as a way to overcome limits of purely statistical ML.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "Promoted as a crucial direction to enable abstraction and inference beyond statistical correlations; practical integration remains challenging and an active area of work.",
            "impact_potential": "Potentially high to enable mechanistic insight from large datasets and to bridge human-understandable reasoning with ML-scale pattern detection.",
            "comparison_to_alternatives": "Offers interpretability and causal reasoning advantages over purely neural models, and scalability and perception advantages over purely symbolic systems.",
            "success_factors": "Effective interfaces between neural and symbolic modules, good knowledge representation, and alignment of objectives across components.",
            "key_insight": "Neuro-symbolic hybrids are promising for scientific discovery because they combine perceptual power with interpretable reasoning needed for mechanistic insights.",
            "uuid": "e2336.10",
            "source_info": {
                "paper_title": "The Future of Fundamental Science Led by Generative Closed-Loop Artificial Intelligence",
                "publication_date_yy_mm": "2023-07"
            }
        },
        {
            "name_short": "Statistical Relational Learning (SRL)",
            "name_full": "Statistical Relational Learning (SRL)",
            "brief_description": "A family of methods combining relational (first-order) representations with probabilistic graphical models to model structured, relational scientific data with uncertainty.",
            "citation_title": "",
            "mention_or_use": "mention",
            "scientific_problem_domain": "Biomedicine, bioinformatics, and other domains with relational structured data (e.g., gene-disease networks)",
            "problem_description": "Represent and learn probabilistic relationships over relational domains to integrate background scientific knowledge and discover structured dependencies.",
            "data_availability": "Depends on availability of structured relational databases and ontologies; can leverage existing bio-ontologies and integrated datasets.",
            "data_structure": "Relational/graph-structured data with entities and relations; can combine symbolic facts with probabilistic annotations.",
            "problem_complexity": "High: inference and learning over large relational domains can be computationally expensive; requires scalable probabilistic inference over first-order structures.",
            "domain_maturity": "Established research area with applications in bioinformatics; maturity varies by implementation and scale.",
            "mechanistic_understanding_requirements": "Medium-to-high: supports interpretable relational models and incorporation of background knowledge for mechanistic reasoning.",
            "ai_methodology_name": "Statistical relational learning (probabilistic logic models, relational learning)",
            "ai_methodology_description": "Frameworks that represent beliefs about relational data using probabilistic graphical models over first-order predicate logic, enabling incorporation of background knowledge and learning of structured dependencies.",
            "ai_methodology_category": "Probabilistic / symbolic-hybrid",
            "applicability": "Appropriate when structured domain knowledge and relational data exist and when interpretability is important; can exploit ontologies and knowledge bases.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "Useful to integrate background scientific knowledge and learn over structured objects; offers interpretable relational models though scaling and inference complexity can be limiting.",
            "impact_potential": "Good for domains like genomics or drug-repurposing where relations and background knowledge are critical; enables hypothesis generation grounded in existing ontologies.",
            "comparison_to_alternatives": "Provides structured, interpretable modeling advantages over flat statistical models; may be less scalable than purely neural methods.",
            "success_factors": "Availability of curated ontologies and relational datasets, efficient inference algorithms, and integration with domain knowledge.",
            "key_insight": "SRL enables probabilistic modelling over relational scientific knowledge, making it effective where structured ontologies and interpretability are required, but computational scalability is a challenge.",
            "uuid": "e2336.11",
            "source_info": {
                "paper_title": "The Future of Fundamental Science Led by Generative Closed-Loop Artificial Intelligence",
                "publication_date_yy_mm": "2023-07"
            }
        },
        {
            "name_short": "Active learning / bandit methods",
            "name_full": "Active learning and bandit-style optimisation methods",
            "brief_description": "Adaptive sampling and optimisation techniques that select experiments or data points to maximise information gain or reward under budget constraints, reducing experimental cost.",
            "citation_title": "",
            "mention_or_use": "mention",
            "scientific_problem_domain": "Experimental design in materials, chemistry, battery optimisation, and biology",
            "problem_description": "Efficiently choose experiments or measurements to perform so as to rapidly identify optimal conditions or informative data under cost/time constraints.",
            "data_availability": "Suited to regimes with limited experimental budget where labelled outcomes are expensive; initial datasets may be small and sequential data acquisition is planned.",
            "data_structure": "Often tabular experimental condition â†’ outcome mappings; can be continuous parameter spaces or discrete options.",
            "problem_complexity": "Moderate-to-high: balancing exploration vs exploitation, expensive-to-evaluate objective functions, potentially high-dimensional parameter spaces.",
            "domain_maturity": "Mature in ML research and increasingly applied in scientific experimental optimisation.",
            "mechanistic_understanding_requirements": "Low-to-medium: primarily focused on efficient empirical optimisation rather than mechanistic explanation, though results can feed mechanistic modelling.",
            "ai_methodology_name": "Active learning / Bayesian optimisation / multi-armed bandits",
            "ai_methodology_description": "Iteratively selects next experiments to maximise utility (information gain, expected improvement) using acquisition functions and models (e.g., Gaussian processes or surrogate models); bandit methods manage exploration-exploitation trade-offs.",
            "ai_methodology_category": "Sequential decision-making / reinforcement-style / Bayesian optimisation",
            "applicability": "Highly applicable when experiments are costly and sequential selection can greatly reduce required runs; requires a surrogate model and utility metric.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "Shown to reduce experimental campaigns and accelerate design (e.g., battery design, biological condition optimisation); effectiveness depends on surrogate model fidelity and acquisition strategy.",
            "impact_potential": "High for resource-limited experimental programmes, enabling faster convergence to optimal conditions and reducing cost/time.",
            "comparison_to_alternatives": "Outperforms naive or grid search experimental strategies in many contexts; paper notes Bayesian approaches empirically outperform manual experiment selection.",
            "success_factors": "Accurate surrogate models, well-chosen acquisition functions, and realistic noise/error models for experiments.",
            "key_insight": "Active learning and bandit methods can dramatically reduce experimental effort by focusing on maximally informative experiments, particularly in costly laboratory contexts.",
            "uuid": "e2336.12",
            "source_info": {
                "paper_title": "The Future of Fundamental Science Led by Generative Closed-Loop Artificial Intelligence",
                "publication_date_yy_mm": "2023-07"
            }
        },
        {
            "name_short": "Bayesian experiment selection",
            "name_full": "Bayesian experiment selection / Bayesian optimal experimental design",
            "brief_description": "Frameworks that quantify the expected information gain or utility of candidate experiments under probabilistic models and select experiments to maximise expected scientific return.",
            "citation_title": "",
            "mention_or_use": "mention",
            "scientific_problem_domain": "Experimental design across scientific disciplines (e.g., Robot Scientist applications)",
            "problem_description": "Determine which experiments to run next to most effectively test hypotheses or reduce uncertainty given costs and time constraints.",
            "data_availability": "Operates with prior probability models and can function with moderate existing data; effectiveness increases with quality of priors and likelihood models.",
            "data_structure": "Probabilistic models over experimental outcomes; data are structured experimental results with associated uncertainties.",
            "problem_complexity": "High: computationally expensive to evaluate expected utilities over large experiment spaces; requires probabilistic modelling and integration.",
            "domain_maturity": "Established statistical framework with practical implementations in automated experimental systems.",
            "mechanistic_understanding_requirements": "Medium-to-high: Bayesian methods provide uncertainty quantification which aids mechanistic interpretation, but require specification of priors and likelihoods.",
            "ai_methodology_name": "Bayesian optimal experiment selection",
            "ai_methodology_description": "Compute expected value or information gain of candidate experiments under a posterior predictive model and select experiments maximising utility accounting for costs; used to automate experiment scheduling.",
            "ai_methodology_category": "Probabilistic modeling / decision theory",
            "applicability": "Well-suited when credible probabilistic models and evaluation metrics exist; paper notes Bayesian selection empirically outperforms manual choices.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "Reported as empirically sound and effective in reducing number of experiments needed and prioritising valuable tests; practical utility seen in Robot Scientist and similar systems.",
            "impact_potential": "Substantial for making experiment-driven science more efficient and principled, improving resource allocation and speeding discovery.",
            "comparison_to_alternatives": "Shown to outperform manual experiment selection strategies in cited empirical work; no numeric comparisons in this paper.",
            "success_factors": "Accurate prior models, tractable computation of expected utility, and clear experimental cost modelling.",
            "key_insight": "Bayesian experiment selection provides a principled way to prioritise experiments and can accelerate discovery by optimising information gain under uncertainty.",
            "uuid": "e2336.13",
            "source_info": {
                "paper_title": "The Future of Fundamental Science Led by Generative Closed-Loop Artificial Intelligence",
                "publication_date_yy_mm": "2023-07"
            }
        },
        {
            "name_short": "Adversarial testing for causality",
            "name_full": "Adversarial example generation for robustness and causal probing",
            "brief_description": "Using adversarial generation techniques to produce challenging examples that probe model robustness and help learn causal relations by exposing failures.",
            "citation_title": "",
            "mention_or_use": "mention",
            "scientific_problem_domain": "Robustness testing (autonomous driving, classification systems) and probing causal learning",
            "problem_description": "Generate edge-case or adversarial scenarios that reveal model weaknesses and encourage learning of causal relationships rather than spurious correlations.",
            "data_availability": "Used when rare or dangerous events are under-represented in real datasets; generation supplements limited empirical data.",
            "data_structure": "Typically high-dimensional input domains (images, sensor streams); generated examples are of the same structure as training inputs.",
            "problem_complexity": "Moderate-to-high: crafting meaningful adversarial examples that correspond to realistic but rare events is challenging; ensuring coverage of causal factors is nontrivial.",
            "domain_maturity": "Well-studied in ML robustness literature; application to causal learning is exploratory.",
            "mechanistic_understanding_requirements": "Medium: goal is to push models toward causal features rather than relying on correlational cues; interpretability of failures aids causal understanding.",
            "ai_methodology_name": "Adversarial generation / adversarial networks for stress-testing",
            "ai_methodology_description": "Use adversarial objectives or generators to create inputs that cause model errors or represent rare events; these examples are used to retrain or analyse models for robustness and causal sensitivity.",
            "ai_methodology_category": "Generative / adversarial / robustness testing",
            "applicability": "Applicable to safety-critical domains and for diagnosing when models rely on spurious patterns; does not in itself identify causal mechanisms but helps surface weaknesses.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "Helps identify brittleness and spurious pattern reliance; can produce realistic stress scenarios for retraining, though may produce unrealistic examples without domain constraints.",
            "impact_potential": "Important for improving safety and reliability of ML systems and for moving models toward causal feature reliance when combined with proper grounding.",
            "comparison_to_alternatives": "Provides complementary advantages to simulation-based stress testing; adversarial examples can be cheaper but risk producing non-physical cases unless constrained.",
            "success_factors": "Domain-constrained generators, realistic modelling of rare events, and coupling with retraining or causal analysis procedures.",
            "key_insight": "Adversarial generation is useful to reveal and mitigate spurious pattern reliance in ML models, aiding robustness and indirectly supporting causal learning when properly constrained.",
            "uuid": "e2336.14",
            "source_info": {
                "paper_title": "The Future of Fundamental Science Led by Generative Closed-Loop Artificial Intelligence",
                "publication_date_yy_mm": "2023-07"
            }
        },
        {
            "name_short": "Knowledge representation & ontologies (GO)",
            "name_full": "Knowledge representation systems and ontologies (e.g., Gene Ontology)",
            "brief_description": "Structured vocabularies and ontologies used to encode biological knowledge in machine-readable form, enabling integration, querying, and computational reasoning across datasets.",
            "citation_title": "",
            "mention_or_use": "mention",
            "scientific_problem_domain": "Bioinformatics, systems biology, integrative biology",
            "problem_description": "Provide standardized, computable representations of biological entities, processes, and experimental metadata to support integration, reasoning, and automated hypothesis testing.",
            "data_availability": "Large, curated ontologies and associated annotation databases exist (e.g., GO, Human Phenotype Ontology); widely accessible and machine-readable.",
            "data_structure": "Structured symbolic graphs/ontologies with hierarchical relations, controlled vocabularies, and annotations linking entities to data.",
            "problem_complexity": "Moderate-to-high: constructing, aligning, and maintaining ontologies across diverse datasets is laborious; reasoning over large knowledge graphs can be computationally heavy.",
            "domain_maturity": "Mature in many biological subfields with well-established ontologies and integration efforts (e.g., Monarch).",
            "mechanistic_understanding_requirements": "High: ontologies facilitate interpretable integration and reasoning and are crucial where mechanistic interpretability is required.",
            "ai_methodology_name": "Knowledge representation using ontologies and knowledge graphs",
            "ai_methodology_description": "Use curated ontologies (Gene Ontology, Human Phenotype Ontology, etc.) and knowledge integration platforms to represent domain knowledge, support reasoning, and augment data-driven methods.",
            "ai_methodology_category": "Symbolic / knowledge-based",
            "applicability": "Highly applicable in biology and medicine where community ontologies exist; essential for combining datasets and enabling explainable reasoning.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "Enables machine-readable domain knowledge ingestion and supports downstream ML and reasoning; reduces curation duplication and improves contextualisation of new findings.",
            "impact_potential": "High for accelerating integrative analyses, reproducibility, and automated hypothesis evaluation in bioinformatics.",
            "comparison_to_alternatives": "Outperforms ad-hoc or unstructured representations for interoperability and explainability; requires community curation effort.",
            "success_factors": "Community adoption, comprehensive curation, clear standards for annotations, and tooling for integration with ML systems.",
            "key_insight": "Structured ontologies are foundational for integrating domain knowledge with AI systems, enabling interpretable and reproducible discovery in biology.",
            "uuid": "e2336.15",
            "source_info": {
                "paper_title": "The Future of Fundamental Science Led by Generative Closed-Loop Artificial Intelligence",
                "publication_date_yy_mm": "2023-07"
            }
        },
        {
            "name_short": "Open-ended evolutionary computation",
            "name_full": "Open-ended evolutionary computation and evolutionary search",
            "brief_description": "Algorithms that simulate evolutionary processes to explore vast hypothesis or design spaces adaptively, generating novel and unexpected solutions over time.",
            "citation_title": "",
            "mention_or_use": "mention",
            "scientific_problem_domain": "Hypothesis generation, design discovery, automated model search across scientific and engineering domains",
            "problem_description": "Search unbounded or large design/hypothesis spaces to produce novel candidate models, experiments, or designs without strong prior specification.",
            "data_availability": "Does not require large labelled datasets; evaluation depends on fitness functions or experimental evaluation pipelines which may be costly.",
            "data_structure": "Candidate solutions often symbolic or encoded genomes; fitness evaluations produce scalar rewards or scores.",
            "problem_complexity": "Very high: open-ended search over huge or unbounded spaces, risk of brittleness or drifting into uninteresting regions without careful objective design.",
            "domain_maturity": "Established as a research area with practical successes in optimization and creative search; open-endedness remains an active challenge.",
            "mechanistic_understanding_requirements": "Variable: often produces novel artefacts that may require post-hoc interpretation; can be paired with mechanisms to favour interpretable solutions.",
            "ai_methodology_name": "Evolutionary algorithms / open-ended evolutionary computation",
            "ai_methodology_description": "Population-based search using variation (mutation/crossover) and selection guided by fitness; extended schemes promote novelty and open-ended exploration rather than optimisation toward a fixed objective.",
            "ai_methodology_category": "Evolutionary / optimisation / generative search",
            "applicability": "Good for exploratory hypothesis generation and design where objectives are hard to formalise; needs evaluation mechanisms (simulators or experiments) to assess candidates.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "Useful for finding unexpected solutions and exploring creative spaces; can be computationally intensive and may generate un-interpretable or impractical solutions without constraints.",
            "impact_potential": "Potentially high for discovery in poorly specified domains and for generating novel hypotheses or designs beyond human intuition.",
            "comparison_to_alternatives": "Offers broader exploration than gradient-based optimisation; lacks gradient efficiency and may require many evaluations.",
            "success_factors": "Well-designed fitness or novelty metrics, integration with efficient evaluation (simulators or automated experiments), and constraints to maintain scientific relevance.",
            "key_insight": "Open-ended evolutionary methods enable exploration of vast hypothesis spaces and discovery of novel candidates, but require effective evaluation and constraints to produce scientifically useful outcomes.",
            "uuid": "e2336.16",
            "source_info": {
                "paper_title": "The Future of Fundamental Science Led by Generative Closed-Loop Artificial Intelligence",
                "publication_date_yy_mm": "2023-07"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Highly accurate protein structure prediction with AlphaFold",
            "rating": 2,
            "sanitized_title": "highly_accurate_protein_structure_prediction_with_alphafold"
        },
        {
            "paper_title": "Applications of Artificial Intelligence for Organic Chemistry: The DENDRAL Project",
            "rating": 2,
            "sanitized_title": "applications_of_artificial_intelligence_for_organic_chemistry_the_dendral_project"
        },
        {
            "paper_title": "Causality: Models, Reasoning and Inference",
            "rating": 2,
            "sanitized_title": "causality_models_reasoning_and_inference"
        }
    ],
    "cost": 0.0279025,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>The Future of Fundamental Science Led by Generative Closed-Loop Artificial Intelligence
29 Aug 2023</p>
<p>Hector Zenil hector.zenil@cs.ox.ac.uk 
Department of Chemical Engineering and Biotechnology
University of Cambridge</p>
<p>The Alan Turing Institute</p>
<p>Oxford Immune Algorithmics</p>
<p>Algorithmic Nature Group
LABORES for the Natural and Digital Sciences</p>
<p>Jesper TegnÃ©r 
School of Computer Science
23 Knowledge Lab
Living Systems Laboratory, BESE, CEMSE, King Abdullah University of Sciences and Technology 22
University of Birmingham
University of Chicago</p>
<p>Department of Medicine
Karolinska InstitutetStockholmSweden</p>
<p>Felipe S AbrahÃ£o 
Oxford Immune Algorithmics</p>
<p>Algorithmic Nature Group
LABORES for the Natural and Digital Sciences</p>
<p>Centre for Logic, Epistemology and the History of Science
University of Campinas
Brazil</p>
<p>DEXL, National Laboratory for Scientific Computing
Brazil</p>
<p>Alexander Lavin 
Vipin Kumar 
Department of Computer Science and Engineering
University of Minnesota</p>
<p>Jeremy G Frey 
Department of Chemistry
University of Southampton</p>
<p>Adrian Weller 
Department of Chemical Engineering and Biotechnology
University of Cambridge</p>
<p>The Alan Turing Institute</p>
<p>Larisa Soldatova 
Department of Computing
University of London
10 Vice-Chancellor's OfficeGoldsmiths</p>
<p>Loughborough University</p>
<p>Alan R Bundy 
School of Informatics
University of Edinburgh</p>
<p>Nicholas R Jennings 
Koichi Takahashi 
RIKEN Center for Biosystems Dynamics Research</p>
<p>Lawrence Hunter 
Center for Computational Pharmacology
School of Medicine
Department of Knowledge Technologies
Department of Materials
University of Colorado
15, Jozef Stefan Institute 16</p>
<p>University of Oxford</p>
<p>Saso Dzeroski 
Andrew Briggs 
Frederick D Gregory 
Carla P Gomes 
Department of Computer Science
Cornell University</p>
<p>Jon Rowe 
The Alan Turing Institute</p>
<p>James Evans 
Hiroaki Kitano 
The Alan Turing Institute</p>
<p>The Systems Biology Institute, Okinawa Institute of Science and Technology</p>
<p>Ross King 
Department of Chemical Engineering and Biotechnology
University of Cambridge</p>
<p>The Alan Turing Institute</p>
<p>The Future of Fundamental Science Led by Generative Closed-Loop Artificial Intelligence
29 Aug 20231 12 RIKEN Innovation Design Office 13 Keio University 17 DEVCOM ARL Army Research Office 19 Pasteur Labs 20 Institute for Simulation Intelligence * To whom correspondence should be addressed;
Recent machine learning and AI advances disrupt scientific practice, technological innovation, product development, and society. As a rule, success in classification, pattern recognition, and gaming occurs whenever there are clear performance evaluation criteria and access to extensive training data sets. Yet, AI has contributed less to fundamental science, such as discovering new principled explanatory models and equations. To set the stage for a fundamental AI4Science, we explore a perspective for an AI-driven, automated, generative, closed-loop approach to scientific discovery, including self-driven hypothesis generation and open-ended autonomous exploration of the hypothesis space.Generative AI, in general, and Large Language Models (LLMs), in particular, serve here to translate and break down high-level human or machine conjectures into smaller computable modules inserted in the automated loop.Discovering fundamental explanatory models requires causality analysis while enabling unbiased efficient search across the space of putative causal explanations. In addition, integrating AI-driven automation into the practice of science would mitigate current problems, including the replication of findings, systematic production of data, and ultimately democratisation of the scientific process. These advances promise to unleash AI's potential for searching and discovering the fundamental structure of our world beyond what human scientists have achieved or can achieve. Such a vision would push the boundaries of new fundamental science beyond automatizing current workflows and unleash new possibilities to solve some of humanity's most significant challenges.</p>
<p>Introduction</p>
<p>With the scientific revolution in the seventeenth century, the notion of mathematical modeling using equations became the efficient language of choice to understand and predict events in the natural world. Four hundred years later, we have vast amounts of data and increasing access to computational power. Recently, we have witnessed an ever-increasing comprehensive application of machine learning accelerating science in unprecedented ways with many questions around quantifying the speed up of discovery ( Fig. 1). One consequence of this increase in scientific production that the digital revolution enabled, it is increasingly challenging for individual scientists to keep abreast of their fields and digest the relevant literature. To advance science and perform end-to-end high-quality scientific investigations, scientists often require one or two orders of magnitude more hypothesis-led experiments than are currently humanly possible. Laboratories are under pressure to perform an increasing number of experiments needed to replicate results. This makes collaborations more challenging, given all the associated overheads, in particular for interdisciplinary research. It may be that some areas of science, such as new fundamental physics or theories in biology, will be too difficult for humans to advance by themselves. AI technologies may be required to be in the driving seat of knowledge discovery to continue the endeavor of human science.</p>
<p>Recent advances in AI since 2010 (1,2), fuelled by large data sets and computing power, have largely targeted problems such as pattern recognition, object classification, and gaming.</p>
<p>Yet, following this phase of difficult-to-understand and interpret -"black-box" neural network models -there has been a renewed interest in expanding the scope of machine learning models.</p>
<p>This includes efforts to search for inspiration from the human brain (3,4), to learn causality (5), to incorporate different geometric priors beyond convolutional filters in the learning (6),and physics-informed machine learning (7,8), to develop explanatory machine learning (9). In the most recent advances moving beyond classification, there has been a growing interest in what can be referred to as AI4Science, reflected, for example, in targeted workshops at machine learning conferences such as NeurIPS and ICML (10). This is evidently a vibrant community (11)(12)(13)(14)(15) active in numerous scientific areas. Naturally, much of the "early" focus has been on data integration, refining measurements, augmenting data, optimising parameters, automation of workflows and data analysis, and scientific visualisation (16). Most recently, with the emergence of foundational models (17), based on the transformer architecture for large language models (18), there is the idea that given large enough data, we can train foundational models which may learn emergent properties to "understand" their respective domains of knowledge (19). This is, however, an open question and challenge for the field. Do we need intelligent priors, or is a huge amount of data sufficient? Yet, regardless of the resolution of this current debate, there is, in our view, a distinct gap between all the exciting recent progress versus having systems, corresponding to an artificial scientist. Such an agent would truly discover and formulate new scientific laws using fundamental mathematical-physical models from observations. Here, in this perspective, we put forward a formulation of a closed-loop iterative formulation as a practical path towards this end.</p>
<p>To further conceptualise how AI can augment science, we like to distinguish between the following levels. First, AI and machine learning can operate as extractors of information. This includes text mining of scientific literature to find relevant papers and, in the best case, extract knowledge and synthesise a body of research from vast sources. A more "modern" use of AI, as mentioned above, has made existing workflows or procedures more efficient, such as being faster and more automatic. This includes augmented computations and simulations in physics.</p>
<p>Alternatively, to make an analysis workflow more automatic by constructing a loss function that incorporates several parameter-dependent steps into a single (complex) optimisation problem.</p>
<p>The first version of AlphaFold is one example (20). However, at these two levels, AI primar-ily supports and enhances current scientific practice. A third level, which is the target in the present perspective, is where AI could potentially discover and learn novel scientific laws, thus finding a "true" representation of a process in nature. For example, a useful compressed latent representation could be learned by training an AI system on data. Alternatively, the scientist could impose soft priors such that certain symmetries and invariants exist in the problem, thus forcing the AI system to discover interpretable structures in the physical process. Geometric machine learning is similar to the "classical" model-based analysis of nature initiated by the scientific revolution. Yet, it is an open problem, how to find such useful and "true" priors from observations in contrast to impose them as regularizing conditions as priors. Here in this review, we focus on the prospect of not only augmenting science, but also by finding such useful, interpretable representations leading to new scientific discoveries by involving AI in what we refer to as a closed-loop-science-AI iterative cycle.</p>
<p>AI can speed up the scientific discovery process and has the potential to advance AI itself in areas relevant to fundamental science, such as causal discovery, automation of experimental science, and the expansion of scientific knowledge. One current bottleneck is knowledge representation, which, by nature, is biased toward the limited understanding and application of the human (scientific) endeavour. A closed-loop-science-AI iterative cycle would be integrated with laboratory automation to execute cycles of planned experiments (21,22). However, the acceleration from automating and closing the loop of the whole scientific cycle leaves unanswered questions, some of which are illustrated in Fig. 1. These systems can fully automate simple forms of scientific research and can further facilitate collaboration across disciplines and between partners-humans or AI systems, but the actual performance of each combination is still unknown and it is still possible that human-machine collaboration produces the most productive outcome and the most relevant to human science too, as it may remain guardrailed to purely human interests. This, however, may also deprive us from undertaking less human Figure 1: A quantitative framework of domain-agnostic acceleration of scientific discovery with AI, its relationship with human-carried science, and the combination of human and machine. 'All knowledge' can be interpreted as potential knowledge if it were discoverable by humans through AI or by themselves. AI time T â€² to conduct certain tasks is traditionally taken to be faster than T by orders of magnitude (21) as it is also more scalable. Still, its domaindependency and relationship to T â€²â€² (human-machine hybrid) are likely highly domain-specific and has traditionally ignored closed-loopness or the removal of any human input. explorations that may have led to results of human interest. Another key question is whether teaming up or AI alone would allow us to cover a larger region of 'human knowledge' defined recursively as the knowledge that can potentially be reached by human understanding.</p>
<p>In contrast to finding new laws or representations, the applications of AI that have been successful so far have been largely limited to industrial applications, classification problems, and data science.A recipe for success has been to pick a problem that has a well-defined performance metric (23). Problems should preferentially have a history of previously increasingly successful attempts to solve them. Examples include board games (Chess, GO) and bioin-formatics workflows (transcription factor binding, protein folding, antibiotics) (24)(25)(26)(27). Yet, despite being impressive, the success of these examples, hinges upon clever search algorithms and efficient implementation of end-to-end workflows. But, in the end, no new fundamental laws of nature are being discovered. Furthermore, as a reflection of the lack of fundamental laws, the inner workings of these AI systems remain challenging to explain and disentangle. To advance beyond this state of affairs, we argue that we need AI systems that can discover new transparent representations and generative laws of the scientific problem at hand. The notion of an iterative closed-loop discovery scheme constitutes one putative path forward. Yet, only a few successful examples have closed the full loop of scientific discovery (28).</p>
<p>Human scientists today need to think about how to create AI systems that can partner with scientists and take on responsibilities over the complete arc of scientific discovery (29): from the process of observation and intervention to hypothesis generation; from a domain knowledge base to conducting experiments and evaluating results; and from rejecting or validating the assumptions to integrating them into the current knowledge base and filing them with the relevant existing literature. Thus, the question is how to make substantial and meaningful advances in AI to enable us to go even further in accelerating science, hitherto driven exclusively by humans, to not only rapidly expand human knowledge and improve the impact of scientific practice, but also to increase its reliability, availability, reproducibility, verifiability, transparency, and trustworthiness as the processes involved in scientific discovery become more automated.</p>
<p>In Fig. 1, we propose some quantitative measures that will not apply to all cases but rather instances where a combination of AI and human approaches can further accelerate science.</p>
<p>Nevertheless, the expectation is that AI will provide a real gain on most fronts and domains.</p>
<p>AI in Scientific Discovery</p>
<p>Challenges</p>
<p>Humans are traditionally biased and prone to very well-known cognitive fallacies or biases, which science is hardly a stranger to (30)(31)(32). One common and increasingly discussed issue is reproducibility across all domains (33,34). Humans are ill-equipped to deal with the repetitive tasks that reproducibility entails, and there are all sorts of inducements for consciously or unconsciously making dubious moves, particularly when it comes to the game of funding and high-impact publishing (35). Confirmation bias, fake rigour, prior assumptions/hypotheses omission, ad hoc methodologies, cherry-picking experimentation, selective data, hype and overstatement of results, network community effects, "rich-get-richer" phenomena widening the inequality gap in science, and poor reporting are examples (31,32,(36)(37)(38)(39)(40).</p>
<p>We used to think that science was entirely objective, but history has taught us that it is also driven by community choices and groups, where it becomes clear that political and social preferences and underlying cognitive biases can interfere with scientific progress (41)(42)(43). All these problems are leading to a crisis impacting scientific networks, putting collaborative networks at a disadvantage and favouring competitive ones, and often compromising the very principles of scientific practice.</p>
<p>Closed-loop-AI-led science has the potential to mitigate all these problems because it can bootstrap itself with the right mechanisms to detach itself from human-led science and its own biases, even if human scientists initially transfer them. Furthermore, this invites scientists with the task of initially guiding AI as to the type of meaningful research that should be conducted but then letting it explore regions of the scientific space that may never be reachable by human scientists while having the option to keep what human scientists believe is of greatest interest but letting the close-loop-AI system to potentially continue using less human-relevant content searching for novelty in terms of what is potentially interesting to go after. That is to have AI bootstrap itself out of and above the loop-AI-science without human guidance.</p>
<p>One challenge in this direction is that automation can easily fall into the over-fitting trap without human input, and mechanisms to avoid this must be in place. However, it has been found that simplicity and randomness are powerful mechanisms to avoid local minima and maxima when iterating over searching algorithms (44). A striking feature of supervised machine learning is its propensity for over-parametrisation (45). Deep networks contain millions of parameters, often exceeding the number of data points by orders of magnitude, so often, the model starts to over-fit right at the beginning (46). Broadly speaking, networks are designed to interpolate the data, learning/constructing an associated manifold by driving the training error to zero. Deep neural networks in particular are widely regarded as black-box approaches, illequipped to offer explanations of the produced models for classification, often with superhuman ability (47,48). One strategy that has enabled researchers to make progress in understanding the workings and limitations of deep learning is the use of what has been called 'generative models' (49). This involves training adversarial algorithms represented by neural networks that systematically tamper with data while asking it to generate novel examples (50,51). However, current approaches in science (see Fig. 2), including most machine and deep learning methods, rely heavily on traditional statistics and information theory. Consequently, such models are insufficient to capture certain fundamental properties of data and the world related to recursive and computable phenomena, and they are ill-equipped to deal with high-level functions such as inference, abstraction, modelling, and causation, being fragile and easily deceived (52-54), for example because they are prone to finding spurious patterns in large data sets (55,56). : Bubble landscape of current approaches to AI from and for science. Bubbles may occur more than once when related to several larger domains. Some approaches may have alternative names or have been re-branded in certain contexts. Neuro-symbolic models have sometimes been referred to as 'intuitive' while some statistical-driven approaches have been labelled as 'cognitive computing'. Generative AI (GenAI) has made little to no contributions to fundamental science so far but has great potential. Large Language Models (LLMs) may significantly tap into and contribute to the exploratory capabilities of the scientific hypothesis space, given their capabilities to process human language in which all human science has been written. GenAI and LLMs are approaches of statistical nature, but it remains unexplored to what extent they may develop symbolic capabilities from statistical (e.g. linguistic) patterns.</p>
<p>Most of these algorithms fail to be scalable in domains outside the training set. Such algorithms lack mechanisms for abstraction and logical inference, they fail at generalisation (57).</p>
<p>For example, in the case of driverless cars, one does not want a car to crash millions of times to learn how not to crash, so current techniques such as adversarial networks offer a way to produce examples in which not driving appropriately can lead to an event that is labelled a crash (58). However, driving and crashing are events where cause and effect need to be learned, which current approaches cannot do.</p>
<p>When AI leads science so that laboratory experiments are automated to execute cycles of planned experiments, AI frees humans from repetitive, tedious, and error-prone tasks and can deal with vast amounts of data that no human could handle (59). These human scientists, in turn, can feed the AI systems back with new insights and novel theories. Thus, such an emerging feedback loop of AI-human collaboration will synergistically boost scientific discovery toward previously unattainable results, rigour, and dissemination.</p>
<p>To overcome the above limitations and challenges, we claim that it will require the fostering of new theories and methods, as well as human and technological resources in AI, data science, and interdisciplinarity, so scientists become capable of dealing with this AI-human interplay both at an infrastructural and a metastructural level. One of these theories may involve developing mathematical frameworks that can deal with the fact that not only the empirical findings, but also the new theories themselves the scientists within the loop are devising can be influenced by other AI algorithms within the loop, and vice versa. For example, this may require causal analysis (or inverse-problem solving) (60) when both the observer and the observed system are mutually perturbing the underlying generative model of each other (61,62). One of these methods may involve AI that guides AI, and translates results to humans, and this intermediate AI may not be of the same type. For example, causal and model-driven AI (63,64) may be required to disentangle other AI systems to which human scientists cannot relate if they do not have a mechanistic explicative component, whether there is one or not. This may lead to some sort of meta-AI capable of dealing with knowledge representations at a meta-level (43), which includes the network dynamics of the each agent (whether AI or human) in the loop, so that this meta-AI still remains explainable to humans (65). This may not require Artificial General Intelligence but would require a different set of skills than purely statistical machine learning approaches.</p>
<p>Historical Context</p>
<p>Applications of AI in science are quite broad and cover many fields. The idea of automating reasoning goes back to Leibniz, where the modern incarnation can be traced back to efforts to build computing machines in Europe. In particular, the heroic efforts of Alan Turing's work at Bletchley to automate the problem of code breaking and his ideas of an imitation game (66,67).</p>
<p>It can also be traced back to Joshua Lederberg (Nobel laureate) (68), Ed. Feigenbaum (Turing award winner) (69), Karl Djerassi (co-inventor of the contraceptive pill) (70), and colleagues at Stanford in the 1960s, who worked on automating mass-spectroscopy for the Viking Mars lander (71,72). AI has long been a tradition of taking scientific discovery as an area of study.</p>
<p>In the 1970s the Nobel Prize laureate and Turing prize winner Herbert Simon developed Bacon, an AI system for science (73). Since this pioneering work, much has been achieved, and there are now many convincing examples of AI systems making clear contributions to scientific knowledge (e.g. the very recent (74,75)).</p>
<p>Eurisko (76) and Cyrano (77) are two examples of other attempts to perform automated discovery from basic principles in a variety of technical fields, in particular in mathematics, chemistry, and a few other domains. These are systems that can be viewed as heuristic search systems, with the additional advantage that they can reconfigure their own search space.</p>
<p>Some commercial products are specifically designed to be applied to knowledge and scientific discovery. For example, DataRobot (78) promotes Eureqa (79), having acquired Nu-tonian (80)(81)(82). Eureqa was designed to create models from time series data and is based on creating random equations from mathematical building blocks through evolutionary search to explain the data (81). It has been called a "Virtual Data Scientist" (79).</p>
<p>A team of researchers from Google DeepMind launched a machine learning project called AlphaFold in 2018 to participate in the Critical Assessment of Techniques for Protein Structure Prediction or CASP (83). CASP is a biennial competition that assesses state-of-the-art three-dimensional protein structure modelling. In its first version, AlphaFold was particularly successful at predicting the most accurate structure for targets rated as the most difficult by the competition's organisers, but it was not until the second program, AlphaFold 2, in 2020, when the team achieved a level of accuracy much higher than any other group before and scored above 90 for around two-thirds of the proteins in CASP's global distance test (GDT), a test that measures the degree to which a structure predicted by a computational program is similar to the structure validated experimentally, with 100 being a complete match. AlphaFold relied on a lot of human knowledge already generated in the years before, especially in areas such as molecular dynamics. The program was designed to include the expert domain in the form of the training data. How much molecular biological knowledge was introduced is still not known, but while it required a team that did draw heavily on domain expertise to tune it, most of the predictive power came from the AlphaFold 2 tool itself (75,84).</p>
<p>A precursor of AI in physics is the project GALILEO (Guided Analysis of Logical Inconsistencies Leads to Evolved Ontologies) (85). The GALILEO project tried to model the repair of faulty theories of Physics whose predictions were contradicted by empirical evidence. One area of successful application of machine learning from climate data, for example, was the discovery of climate dipoles through machine learning (85). Physics-driven AI has the potential to impact how we approach science, on our current predominantly data-reliant-as opposed to the modelcentred-scientific method, by placing the mechanistic model at the centre of modelling itself.</p>
<p>Paradoxically, current physics-led AI and machine learning research have distracted researchers from more fundamental research, even though the discussion has started, and researchers will hopefully eventually get around to the first principles they claim to care about.</p>
<p>On the knowledge side, there are many applications of knowledge extraction of interest, such as for drug re-purposing by pharmaceutical companies (86,87). On task-oriented problem solving, we can find an increasing number of workflow systems that understand scientific tasks and carry them out. There have been some success stories demonstrating that by collecting and integrating available molecular data into computational models, accurate predictions of interventions in the system can actually be made. An example is the Robot Scientist program (21) that was able to autonomously execute high-throughput hypothesis-led research investigating yeast-based functional genomics, with the next-generation scientific program later using the same principles for drug screening. In another example, a computational model of Halobacterium salinarum NRC-1 was first constructed through massive data integration and machine learning-driven inference of the regulatory network (88).</p>
<p>Another example was the ambitious whole-cell computational model of the life cycle of the human pathogen Mycoplasma genitalium (89). The model accounted for all annotated gene functions and was validated against a broad range of data. Now, the model encompasses approximately 500 genes and their interactions.</p>
<p>In the area of neural networks, there has been, for example, an effort to make them 'understand' cause and effect by algorithmic training. While more research is needed, fundamental research is aware that alternative approaches are required to capture the complexities of hypothesis and model generation or selection (44,53,90). In this sense, the research in this type of higher-order AI, such as deconvolution from searching for generative processes from the entire algorithmic space (60), will also be crucial to advance current research.</p>
<p>To present a summary of the current state of AI applications to each scientific domain, Ta-ble 1 displays an organisation of scientific domains 1 and the applicable AI algorithms' classes and approaches. Scientific domains are approximately ordered from smallest physical scales to largest. Overlapping areas are not reflected in this high-level table (e.g., semi-supervised RL methods, or the representation of neural networks (NNs) that conflates various deep learning types like LSTM and Transformers), not to mention complex, context-dependent multidisciplinarity. Table 1 To burst this bubble, it is essential to supplement LLMs with other methods and multiple sources. For instance, active learning could serve to maximise information gain, challenging the model with fresh data and different viewpoints cross-pollinating from different scientific domains. Hybrid models blending AI with symbolic reasoning could tackle scientific problems requiring high-level abstraction, thus broadening LLMs' capabilities. This approach would therefore fall into the neuro-symbolic category for purposes of scientific discovery.</p>
<p>Indeed, an area where LLMs could be especially impactful is in scientific model discovery.</p>
<p>By analysing patterns and correlations in vast datasets, LLMs could help identify mathematical relations and possibly reveal new potential (physical, or computational) laws just as it learns language grammar from natural language statistics. This could expedite the scientific process, enabling more rapid breakthroughs.</p>
<p>Furthermore, LLMs could make a significant contribution to causal analysis. By processing extensive scientific literature, they could draw links between causes and effects that might be overlooked by human researchers, proposing novel causal hypotheses for testing. Pairing this with counterfactual reasoning, where the AI predicts the outcome of modifying specific variables, could deepen our understanding of cause-effect relationships, and help simulate alternative model outcomes.</p>
<p>However, in addition to inheriting the limitations from statistical machine learning in general (54,91), it is also important to acknowledge the limitations of current LLMs. They currently lack the depth needed for any breakthrough to happen and require quality and diversity of data allowing an LLM 'temperature' (favouring less likely statistical patterns) to explore further along the potential long tails of the distribution of scientific results with potential breakthrough science away from incremental average science. A collaborative approach, in which human scientists guide the AI, can help harness the strengths of both worlds, mitigating the current weaknesses of LLMs and statistical ML, ensuring more effective utilisation of this technology today.<br />
Mathematics -âˆ¼ -âˆ¼ -âœ“ -âœ“ - -âˆ¼ âˆ¼ - - - - - - HE Physics -theo -âˆ¼ -âˆ¼ -âˆ¼ -âœ“ -âˆ¼ âˆ¼ - - -âˆ¼ âˆ¼ âœ“ - HE Physics -exp âœ“ âœ“ âœ“ âœ“ - -âœ“ -âœ“ âˆ¼ âˆ¼ âœ“ âˆ¼ - -âœ“ âœ“ âœ“ Optics &amp; Acoustics âœ“ âœ“ âˆ¼ âœ“ âˆ¼ âˆ¼ âœ“ -âˆ¼ -âˆ¼ âˆ¼ -âˆ¼ -âˆ¼ - - Complexity - -âˆ¼ âœ“ âˆ¼ âœ“ -âœ“ âœ“ âœ“ âˆ¼ âœ“ âˆ¼ âœ“ âœ“ -âˆ¼ - SynBio &amp; Ind Biotech âœ“ âœ“ âˆ¼ âœ“ âœ“ âˆ¼ âˆ¼ âœ“ âœ“ âˆ¼ âˆ¼ âœ“ âˆ¼ âœ“ âˆ¼ -âˆ¼ âˆ¼ Organic Chemistry âœ“ âœ“ âœ“ âœ“ âœ“ âœ“ âœ“ âœ“ âœ“ âœ“ âœ“ âœ“ âœ“ âœ“ âœ“ âœ“ âœ“ âœ“ Physical Chemistry âœ“ âœ“ âœ“ - - - - - - - - - - - - - - - Electrochemistry âœ“ âœ“ - - - - - - - - - - - - - - - - Materials âœ“ âœ“ âˆ¼ âœ“ âˆ¼ - -âœ“ -âˆ¼ âˆ¼ âœ“ âˆ¼ âˆ¼ âˆ¼ -âˆ¼ âˆ¼ Computing âœ“ âœ“ -âœ“ - -âˆ¼ - - -âˆ¼ âœ“ âˆ¼ âœ“ -âˆ¼ âœ“ âœ“ Medicine, molecules/proteins âœ“ âœ“ -âˆ¼ -âˆ¼ -âˆ¼ âˆ¼ âˆ¼ âˆ¼ âœ“ âˆ¼ âœ“ âˆ¼ - -âˆ¼ Medicine, drug development âœ“ âœ“ âˆ¼ âˆ¼ -âœ“ âˆ¼ âœ“ âœ“ âœ“ âœ“ âœ“ âˆ¼ âˆ¼ - - - - Medicine, clinical âœ“ âœ“ -âœ“ -âˆ¼ âˆ¼ âœ“ âœ“ âœ“ âˆ¼ âˆ¼ - - - - - - Botany &amp; Zoology âœ“ âœ“ âˆ¼ âˆ¼ âˆ¼ âˆ¼ - - -âˆ¼ - - -âœ“ âœ“ - - - Systems bio &amp; epidemiology âˆ¼ âœ“ âˆ¼ âœ“ -âˆ¼ âœ“ âœ“ âœ“ âœ“ âœ“ âœ“ âˆ¼ âœ“ âœ“ -âˆ¼ - Neuro and Cog sciences âœ“ âœ“ âˆ¼ âœ“ âˆ¼ âˆ¼ âœ“ -âœ“ âˆ¼ âœ“ âœ“ âˆ¼ âˆ¼ âˆ¼ âˆ¼ âœ“ âˆ¼ Energy -nuclear (fis/fus)ion âœ“ âœ“ -âˆ¼ -âˆ¼ âˆ¼ âœ“ âœ“ âˆ¼ âˆ¼ âœ“ âˆ¼ -âˆ¼ âˆ¼ âˆ¼ âˆ¼ Energy, generation &amp; storage âœ“ âœ“ -âœ“ -âˆ¼ âˆ¼ âœ“ âœ“ âˆ¼ -âœ“ âˆ¼ âœ“ âˆ¼ âˆ¼ -âˆ¼ Energy, oil &amp; gas âœ“ âœ“ âˆ¼ - - - -âœ“ âˆ¼ âˆ¼ -âœ“ - -âˆ¼ - - - Manufacturing âœ“ âœ“ - -âˆ¼ - -âœ“ - -âˆ¼ âˆ¼ -âˆ¼ - - - - Engineering &amp; Industrials âœ“ âœ“ -âˆ¼ âœ“ -âˆ¼ âœ“ âœ“ âˆ¼ âˆ¼ âœ“ - -âˆ¼ - -âˆ¼ Energy Systems âœ“ âœ“ -âˆ¼ âœ“ -âœ“ âœ“ âœ“ âˆ¼ âˆ¼ âˆ¼ - -âˆ¼ - - - Transp. &amp; Infrastructure âˆ¼ âœ“ - -âˆ¼ - -âœ“ âœ“ âˆ¼ -âˆ¼ - -âˆ¼ - - - Agriculture âˆ¼ âœ“ âˆ¼ âœ“ âˆ¼ -âˆ¼ âœ“ âœ“ âœ“ âˆ¼ âœ“ -âˆ¼ âˆ¼ - - - Ecology âœ“ âœ“ âˆ¼ âœ“ âˆ¼ -âˆ¼ âœ“ âœ“ âœ“ âˆ¼ âˆ¼ âˆ¼ âœ“ âœ“ - - - Socioeconomics &amp; Markets âœ“ âœ“ âˆ¼ - -âˆ¼ âˆ¼ âœ“ âœ“ âˆ¼ âˆ¼ âœ“ âˆ¼ âœ“ âˆ¼ - - - Finance âœ“ âœ“ - - - - -âœ“ âœ“ âˆ¼ âˆ¼ âœ“ -âœ“ - - - - Politics &amp; Geopolitics -âˆ¼ -âˆ¼ âˆ¼ -âˆ¼ âœ“ âˆ¼ âˆ¼ -âˆ¼ -âˆ¼ âˆ¼ - - - Defense, aerospace âœ“ âœ“ âœ“ - -âœ“ âœ“ âœ“ âˆ¼ âˆ¼ âˆ¼ âˆ¼ âˆ¼ âˆ¼ - - - - Climate, weather âˆ¼ âœ“ âœ“ âœ“ âˆ¼ - -âˆ¼ âœ“ âˆ¼ âœ“ âˆ¼ âˆ¼ âœ“ âœ“ -âˆ¼ âˆ¼ Earth Systems âˆ¼ âœ“ âˆ¼ âˆ¼ âˆ¼ âˆ¼ âˆ¼ âˆ¼ âœ“ âˆ¼ âœ“ âˆ¼ âˆ¼ âˆ¼ âˆ¼ -âˆ¼ - Astrophysics &amp; Cosmology âœ“ âœ“ âœ“ âœ“ âœ“ âœ“ - -âˆ¼ âˆ¼ - -âˆ¼ âˆ¼ âˆ¼ âˆ¼ âˆ¼ âˆ¼ Philosophy, Epistemology - - - - -âœ“ -âˆ¼ -âˆ¼ - - -âˆ¼ âœ“ - - -</p>
<p>Aspects of AI-Led Closed-Loop Science</p>
<p>The ability to predict and design (inverse design), while exceptionally useful, will not necessarily lead to new fundamental discoveries (new theories) unless AI and human goals in scientific discovery are aligned and synergistically intertwined to impose similar objectives quantified and introduced, for example, a loss function .</p>
<p>This is because scientific discovery cycles, such as those illustrated in Figs. 3, are not isolated parts but belong within a greater cycle of scientific inquiry spanning an entire topic or field comprised of a community of scientists.</p>
<p>It is the larger learning cycle that fuels the questions in the smaller learning cycles. The larger cycle is fuelled by human curiosity and human challenges and has a strong historical and social component, but the shorter cycles, being more well-defined, they are more prone to be automated. Nevertheless, the larger cycles may be needed to kick-start the discovery process of the smaller learning cycles.</p>
<p>In this sense, one option to integrate human scientists and AI-driven science is for humans to build the context of the greater cycle (for example, fulfilling the role of the 'Final Theory' and 'Background knowledge' steps at the leftmost smaller cycle in Fig. 3), feeding the AI with new insights, and leave the AI to independently deal with the smaller cycles (such as the rightmost smaller cycle in Fig. 3), guided by the greater ones. The LLM's could, for example, be very useful as a technical interface and translation of human high-level larger cycle aspirations and their respective "divide-and-conquer" breakdown into smaller cycles. If one aims at the highest degree of automation of the discovery cycle, more sophisticated forms of AI should include automation of the validation, dissemination, refereeing, and other aspects of human science and its practice.</p>
<p>To tackle such challenges, we propose in the following sections the steps and technology suggested to conduct an entire cycle of AI-led scientific discovery (92), as in Fig. 3. Figure 3: Visual representation of closed-loop full experimentation cycle for scientific discovery pathways, adapted and combining ideas from (59) and (21). LLMs can now facilitate closing this loop but require help to connect each module and process in a causal rather than only a statistical fashion.</p>
<p>Hypothesis Generation</p>
<p>One of the central components of the scientific practice is the 'hypothetico-deductive' method (93,94). An additional set of epistemological tools is induction (95), abduction (22) and counterfactual reasoning (96). To automate those knowledge processes, a deduction can be combined with simulation to infer the experimental consequences of hypotheses. Matching simulation with experimental output will be a reliable basis for an AI to accept or reject a hypothesis. Such experimental output is tested with multiple interventions in the automated series of perturbation analyses (61). However, while one traditional approach to automate induction may follow, for example, new methods for clustering and regression, automating abduction and the creation of counterfactual scenarios may pose an even more challenging problem. For this purpose, it would require the AI algorithm to explore irreducibly novel possibilities that are emergent to the current state of knowledge in which the AI is situated (62).</p>
<p>In this sense, neural networks are unlikely to be useful in the process of hypothesis generation, nor is any statistical machine learning. This is because they need training, and not only is Each method has its advantages and drawbacks and lies at different extremes of the causal inference spectrum. Guiding heuristics based on first principles are needed to explore the hypothesis space (100). Dovetailing partial results is necessary to avoid infinitely long cycles running the search. Here aspects of computability and tractability will be in play at every step, which we will need measures to deal with unless less powerful techniques are implemented (e.g. propositional logic or domain-restricted spaces such as a set of genetic circuits). At one extreme are the statistical tools that confound correlation and causation but can help scientists make a call and guide their experiments, viz., graphical models that combine probability with symbolic logic, reasoning, and interventional calculus. The statistical approach often leads to less computationally expensive methods and, although in general, they may present distortions or biases toward some selected features (52,101), it returns sound results in cases one knows a priori that the underlying generative processes are purely stochastic, stationary and ergodic.</p>
<p>At the other extreme is AID, which searches for sets of agnostic generative models compatible with observations, and exploits these models as testable underlying mechanisms and causal first principles (98,99), regardless of those being stochastic, computable, or mixed processes. In addition to offering less constrained methods, for example, deconvolution algorithms (60) and optimisation in non-differential spaces (44), this approach offers results in direction to tackling the abduction and counterfactual problem, as for example shown in new methods for openended evolutionary computation (102,103), and synergistic distributed computation (104,105).</p>
<p>However, bottom-up approaches like AID may not be humanly understandable, or when they are, scrutinising them may require great computational effort, as is the case in other areas such as automatic theorem proving (e.g., the four-colour theorem). LLMs may here again provide an advantage to interface between these model spaces as natural language processors integrating otherwise disparate systems translating among different domain databases and knowledge bases.</p>
<p>Experimentation and Sensing</p>
<p>One key task is to create AI systems for scientific discovery able to conduct experimentation and hypothesis testing independent of human instruction or with little to no human instruction. This is because what is desired to take scientific discovery to the next level is not the programming of algorithms able to conduct experiments, but open-ended algorithms able to set their own goals and experiments guided by previously conducted experiments (their own or from the human literature). To this end, involving the machine embodiment to perform as a physical scientist by combining sensing and action together in the fully automated smaller cycles (which in turn are part of the larger encompassing AI-led closed-loop of scientific discovery) of empirical hypothesis testing, instrument-driven approaches render robotics key to making progress in physical experimentation so that more and more of the physical execution of experiments will be done using robotics (106). This will increase the productivity of science, as robots work cheaper, faster, more accurately, and for longer than humans. Furthermore, if not embodied, the scientific experiment may collapse into a problem of data analysis and inference without the hypothesis, model, and theory testing that requires positive or negative feedback from the empirical side. Thus only a tiny part of the scientific discovery cycle would be tackled.</p>
<p>Neural networks can help physical machines to embed themselves in a physical world for representation purposes, as neural networks have proven useful in representing all sorts of images. Still, innovation in areas of robotics and mechatronics will be required to accommodate the kind of depth and range of scientific experiments, in particular when it comes to accuracy and precision-which should not present a problem-while also helping with the current, very human problem of reproducibility (40). This is expected to have a significant impact on the reproducibility of science, as automating science requires semantic precision. LLMs will also interface between human and robot instructions making it easier to create tools to automate experiments in natural language effectively instantiating a robot assistant able to process human instructions for scientific experimentation.</p>
<p>Rejection, Validation and Model Selection</p>
<p>Model selection and reduction have been a recurring theme across several sub-fields of areas, such as computational biology and neuroscience, with special reference to dynamical forward models. The idea is that if a complex nonlinear model can be reduced in complexity (fewer state variables and parameters), the investigator can more readily discern which parameters and state variables are more crucial to the model's behaviour, facilitating model analysis and understanding. One example is the reduction of the four-dimensional Hodgkin-Huxley model to a two-dimensional FitzHugh-Nagumo (FHN) system (107). The core idea was to perform a time-scale separation into fast and slow subsystems. This has been used in several model reduction studies, including the cell cycle. Techniques for dimension reduction, feature, and model selection will be helpful at this stage, from statistical approaches such as principal component analysis to more sophisticated ones such as minimal information loss techniques.</p>
<p>Another core idea for model selection is that each hypothesis formed will have a predicted probability of being correct, possibly along with the associated cost of the respective experiment. This may be the monetary cost of executing the experiment, plus a temporal discount rate to value finding results more quickly. It has been empirically shown that using a Bayesian approach to experiment selection is sound and outperforms experiments chosen manually (21).</p>
<p>Current AI has shown the ability to yield valuable insights from noisy or incomplete data, optimise procedure design, and learn notions of structure amongst heterogeneous observations.</p>
<p>Neural networks have shown utility in isolating proper signals from noisy datasets spanning disciplines from physics to biology; such capabilities could be critical to establishing scientific conclusions as we reach the practical limit of experimental data quality (108,109). Approaches from optimisation have demonstrated an ability to reduce the expense of experimental campaigns by optimising sampling patterns using, for instance, bandit-style methods to more rapidly design electric batteries or iteratively specify experimental conditions in biology. Structure learning techniques from the graphical model literature could find use in identifying statistically meaningful relationships from large amounts of unannotated data (108).</p>
<p>Knowledge Representation and Natural Language Processing</p>
<p>Ingested knowledge may no longer be machine-readable, either rule-based or probabilistic given that LLMs can interface between them but its possible caveats, such as low-level hidden misalignments, are difficult to unveil, making difficult traceability and liability. LLMs can allow machines to read, interpret, and exploit the current knowledge from a scientific domain in human natural language and digest the relevant literature in the target area. An AI-led scientific discovery approach will require at least access to the space of interest needed for the system to be able to validate or reject a hypothesis based on contradiction or confirmation of previous knowledge which may be difficult in a black box like an LLM. So, the LLM will need to be self-explanatory with the caveat that the output explanation may not fit the internal statistical derivation of what the LLM ends up producing. An independent system and a more explainable mechanistic process may need to verify the output. Without LLMs, this task would have required massive databases and curation efforts for domains that are not already significantly represented in a computable fashion. Although all sorts of languages can be used to represent knowledge, some domains will be aptly represented by propositional-logic rules, such as simplified genetic circuits, to avoid these potential misalignments from LLMs or statistical ML in general. Other domains will require more sophisticated representations, either to encompass the greater complexity of an extended domain or to deal with the greater sophistication of, e.g., a domain such as biomedicine, where system-expert rules with ifs, dos, and whiles are required, hence the full power of first-order logic and Turing-completeness.</p>
<p>For example, knowledge representation systems/ontologies are well developed in biology:</p>
<p>The Gene Ontology (GO), nascent Causal Activity Models with the GO, Human Phenotype Ontology, Chemical Entities of Biological Interest, Ontology of Biomedical Investigation, among others (110,111). So are integration efforts built on these ontologies, e.g., Monarch (112). The JST MIRAI 'Robotic Biology' project can also provide technologies to help adoption, such as LabCode, a common formal language for experimental protocols, LabLive, a laboratory information IoT platform, and real-time parallel workflow scheduling software that can decompose processes in a given protocol and assign each to different robots/equipment so these are executed considering dependencies and concurrency between them.</p>
<p>Another example is statistical relational learning (SRL), which combines relational learning and probability theory and is an area of ML research (e.g. (113)), enabling the representation of beliefs about relational data using probabilistic models. Relational Learning (RL) is a general representation language based on first-order predicate logic (113). Such probabilistic logic models enable the specification of graphical models (Bayesian networks, Markov networks, etc.) over large relational domains. One of the fundamental design goals of the representation formalisms developed in SRL is to abstract away from concrete entities and to represent instead general principles that are intended to be universally applicable. A key advantage of RL is that it can easily incorporate background scientific knowledge, and learn about structured objects such as scientific models particularly appropriate for utilising background bioinformatic data (114).</p>
<p>These approaches can be further enhanced or complemented by the do-calculus (96,115) or algorithmic information dynamics (61).</p>
<p>Deep neural networks are also good at capturing the apparent granularity and complexity of natural phenomena in a computable form (in weighted vectors of numerical matrices). The success of neural networks implies that once one captures an object in an optimal way, classification is trivial, as it was for deep learning in the protein-folding challenge (75,83) with its limitations.</p>
<p>Assuming that an appropriate formalism to record observation could be found for any domain, a modeller may be faced with a severe feature selection problem, which translates into a question of the identity of the relevant state variables of the systems of interest, e.g., drug</p>
<p>docking dynamics for drug discovery or cytokines for cell dynamics. On the one hand, all the system entities that are measured could define the set of state variables to be represented, e.g.</p>
<p>drugs or proteins, augmented with the set of rules to which the entities may be subjected, such as thermodynamics or collisions. However, this type of representation could quickly become very complex (116). On the other hand, a certain subset of combinations of measured state variables may be a useful representation of the governing dynamics driving a possible system, and this is a question that needs to be asked and resolved for scientific domains on a caseby-case basis. Such a feature selection problem in computably representable objects is often found in analyses in which one is assuming a pure stochastic nature of the system's generative processes, although the system also comprises deterministic, mechanistic, or computable subprocesses (101). In addition, even in cases the whole algorithmic space of possibilities is covered, analyzing the information content carried by a network highly depends on the multidimensional space into which it is embedded (117), where distortions may be exponential for multidimensionality-agnostic encodings.</p>
<p>Thus, developing expressive and efficient frameworks to computationally represent and capture a wide range of scientific knowledge about processes, models, observations and hypotheses is key. Additionally, in the opposite direction of knowledge representation by machines, the AI for scientific discovery may need to communicate in the form of a publication or other scientific means to explain the innovation and methods behind the discovery to humans and to articulate its significance and impact. Thus, not only we will have to improve knowledge representation (43) of these scientific objects of inquiry, but also include (meta)knowledge representation of the social dynamics constituted by the scientific practice of humans and AI algorithms in the loop. This in turn should lead to better mitigations of the aforementioned problems of reproducibility and biases in science. Capturing scientific knowledge will push the limits of the state of the art.</p>
<p>A choice that has to be made, on a case-by-case basis, is whether it is required that AI conducts the experiments without much human understanding or whether it is acceptable not to have a sophisticated translation of both the hypotheses generated and the process arriving at a conclusion. In cases where there is a requirement for human understanding, and even for the most general case, at least partial interpretation by human scientists may be required.</p>
<p>Thus, knowledge representation and natural language processing techniques will be needed to be jointly developed to both: feed the system with the current knowledge relevant to the hypothesis space; and guide the search (in cases of human-machine interaction) or be able to follow up the inference process and interpret the results (118,119). These requirements will force us to make progress on humanly readable and interpretable machine-human translation.</p>
<p>Integration, Interpretation and Interfacing</p>
<p>One of the most challenging aspects of scientific discovery is integrating a new piece of information with the corpus of existing human knowledge. Analysing the data will require moving to the larger learning loop where there is a broader view of the results for possible (re-)interpretation.</p>
<p>This is because while the specific objective for the target hypothesis may have been rejected, one of the main serendipity checkpoints is the reinterpretation of results in a broader context.</p>
<p>Machine learning systems have proven incredibly useful for automated knowledge base construction. They have recently contributed to creating multiple large databases describing, for instance, genome-wide association studies and drug-disease interactions directly from the published literature (120). This ability to create massive knowledge bases that rapidly and effectively contextualise new findings could substantially accelerate scientific discovery by ensuring that seemingly disparate dots are more rapidly connected.</p>
<p>However, exploring and understanding user context requires automating certain social, political, and economic aspects of interconnected knowledge that are intrinsic to science (37).</p>
<p>The AI systems' interactions with scientists must be guided by a knowledge-rich multi-agent model (106) that enables the AI systems to act as colleagues like LLMs now may allow.</p>
<p>This constitutes an inextricable loop in which human scientists and AI-scientists are parts of a whole system, which the AI algorithm should try to optimise. A striking example of such an optimal interplay has been the evolution of machine-human chess collaboration. After the defeat of Gary Kasparov, it became standard to have human chess players practice with computers, and for champions, it became impossible to reach the level of playing demanded without intensive computer training (121). To this day, the strongest freestyle chess teams have been those able to strike a perfect balance between machine and computer training and playing.</p>
<p>Again, neural networks and statistical machine learning will not help in this process, at least not on their own or in their traditional architectures. What is most likely needed here is first an inference engine able to extract knowledge readable by humans as well, especially under human-machine schemes. Classical logical inference engines are key, but so are hybrid approaches combining statistical learning and symbolic computation so that the AI algorithms' objectives and their respective performance measures are not always fixed in advance (23).</p>
<p>Techniques such as feature selection and data dimension reduction will be helpful in this regard.</p>
<p>Secondly, an AI algorithm that can simulate the network topological properties of scientific production (36) and perform the steps of the full cycle of AI-led scientific discovery, while taking into account the relational structures and biases that emerge when the AI-human relationship is analysed as a single system.</p>
<p>The application of AI to science will confer multiple advantages, and eliminate some of the disadvantages of having a human in the loop, such as biases and lack of reproducibility.</p>
<p>Yet, if humans rely on automated scientific discovery, verifiability and transparency are crucial because the coupled AI-human system has to be able to be formally verified to ensure that it matches the goals and that the results match the process. In this manner, the AI algorithm should be designed to continuously reiterate its data gathering from the outputs and behaviours of the whole system the AI is part of. The same for the human scientist, which needs to be able to perform, evaluate, and produce analytical reasoning while participating in this coupled computational-social system. This in turn may give rise to innovative methodologies and epistemological grounds that foster the scientific justification of the results and novelties discovered by such a coupled system.</p>
<p>Closing the Loop</p>
<p>Finally, connecting all the steps will require a meta-algorithm that will need to systematically manage each cycle and even decide when to break or restart the cycles (see Fig. 3), if human intervention is taking place. The whole cycle should be open to human intervention, and the AI algorithm should both reiterate the new insights and data given by humans and counter any bias that these may introduce.</p>
<p>Technology for remote web control and monitoring of full-cycle scientific discovery may require technologies such as TypeScript, React, GraphQL, Jest, and Redux to create a webbased beamline control system. Techniques such as optimisation and anomaly detection can be used to find possible gaps and even glitches (found or promoted). These gaps can be exploited to reinterpret data, explore other regions of the hypothesis space and kick-start the process of hypothesis generation again, thus closing and restarting the discovery cycle.</p>
<p>Notice that each of the above aspects of the AI-led closed-loop science can be considered landmark projects that will also require solutions to many standard technical problems (122).</p>
<p>Therefore, toward being able to close the loop with an AI-led science, the "grand challenge"</p>
<p>(122) that we propose ranges over automating not only laboratory practices and theory making, but also writing a paper, refereeing, and disseminating achievements.</p>
<p>Conclusion: the Future of AI in Scientific Discovery</p>
<p>Future scientific progress has become almost unthinkable without the involvement of machine learning. We have explored some challenges and opportunities in utilising and exploiting AI.</p>
<p>We argue that a closed-loop formulation not only augments and accelerates scientific discovery but also leads science in new directions, thus potentially disrupting the future trajectory of human science. Such closed-loop experimentation led by AI may also mitigate current challenges, such as the production and replication of data.</p>
<p>The development of AI to discover new fundamental scientific laws and representations is different compared to the application of AI to games such as chess, shogi, or Go. However, recent developments surprisingly suggest that some scientific challenges may not be that different from these games (123)(124)(125).</p>
<p>New questions for scientists and policymakers are increasingly pertinent. For example, do we require AI equipped with sufficient intelligence and autonomy to render it capable of sensing and making observations to ask novel scientific questions? Who should control AI4Science systems, humans or other tertiary systems we may trust? How will the role of the future scientist change? Yet, these challenges must be solved since we urgently need to solve problems like cancer and climate change.</p>
<p>By observing the resulting examples and how the classifier fails, they can understand the model's limitations and improve the classifier.</p>
<p>Figure 2
2Figure 2: Bubble landscape of current approaches to AI from and for science. Bubbles may occur more than once when related to several larger domains. Some approaches may have alternative names or have been re-branded in certain contexts. Neuro-symbolic models have sometimes been referred to as 'intuitive' while some statistical-driven approaches have been labelled as 'cognitive computing'. Generative AI (GenAI) has made little to no contributions to fundamental science so far but has great potential. Large Language Models (LLMs) may significantly tap into and contribute to the exploratory capabilities of the scientific hypothesis space, given their capabilities to process human language in which all human science has been written. GenAI and LLMs are approaches of statistical nature, but it remains unexplored to what extent they may develop symbolic capabilities from statistical (e.g. linguistic) patterns.</p>
<p>'s content was the consensus and understanding of a subset of this paper authors. While supervised statistical methods have contributed to almost every area of knowledge, these are of very different type mostly ranging from identification to classification. Some areas are more difficult than others across all approaches, such as mathematics, philosophy, and epistemology. In general, statistical approaches rank poorly at finding first principles or adding new mechanistic knowledge to scientific domains.Generative AI (GenAI) and Large Language Models (LLMs) are promising to advance science by assimilating and synthesising the vast corpus of human knowledge embedded in scientific literature. Through this synthesis, LLMs can interconnect disparate ideas, construct unique hypotheses, and venture into uncharted areas of scientific knowledge. However, this exploration is bound by the data they have been trained on, creating a theoretical bubble that could lead to model collapse through excessive training on the same data.</p>
<p>training over hypothesis generation exactly the problem to be solved in the first place, but training over previous hypotheses, dividing them into rejected or valid, may undermine the freedom and the unbiased exploration that is desired of regions of interest in the hypothesis space. For hypothesis generation, what is needed is a bottom-up approach (e.g., a model-driven AI) or a hybrid one able to conduct cycles of systematic hypothesizing, from either partial or exhaustive enumerations (even if redundant though universal)(64,97).A bottom-up approach that deals with this open-endedness concerning the role of novelty is the field of algorithmic information dynamics (AID) (61), a framework for causal discovery and causal analysis based on algorithmic information theory and perturbation analysis. Open-ended innovation in hypothesis generation and how to create and search over unbounded hypothesis spaces in less well-specified domains is an open challenge in itself, whereresearch on the topics of this document can help make progress. These spaces and the methods exploring them usually have to deal with problems of intractability or uncomputability(98,99).</p>
<p>Table 1 :
1Scientific domains and the applicable AI algorithms' classes and approaches. '-' and âœ“means simply no (or unknown) and yes, respectively; âˆ¼ implies the ML application is likely but not yet done nor sufficiently validated. This table is very dynamic and requires an update every quarter given the speed of developments impossible to keep up with without considerable effort or help from AI.
Note that: Complexity includes systems and intelligence as defined by the Santa Fe Institute; Manufacturing notably includes ML-based design of sensors and chips; and Earth systems includes oceans, land, air, and near space (see earthdna.org).</p>
<p>. Y Lecun, Y Bengio, G Hinton, 521:7553 521Nature. 436Y. LeCun, Y. Bengio, G. Hinton, Nature 2015 521:7553 521, 436 (2015).</p>
<p>. J Schmidhuber, Neural Networks. 6185J. Schmidhuber, Neural Networks 61, 85 (2015).</p>
<p>. D Hassabis, D Kumaran, C Summerfield, M Botvinick, Neuron. 95245D. Hassabis, D. Kumaran, C. Summerfield, M. Botvinick, Neuron 95, 245 (2017).</p>
<p>. A Zador, Nature Communications. 141597A. Zador, et al., Nature Communications 14, 1597 (2023).</p>
<p>J Pearl, Causality: Models, Reasoning and Inference. USACambridge University Presssecond ednJ. Pearl, Causality: Models, Reasoning and Inference (Cambridge University Press, USA, 2009), second edn.</p>
<p>. M M Bronstein, J Bruna, Y Lecun, A Szlam, P Vandergheynst, IEEE Signal Processing Magazine. 3418M. M. Bronstein, J. Bruna, Y. LeCun, A. Szlam, P. Vandergheynst, IEEE Signal Process- ing Magazine 34, 18 (2017).</p>
<p>. G E Karniadakis, Nature Reviews Physics. 3422G. E. Karniadakis, et al., Nature Reviews Physics 3, 422 (2021).</p>
<p>. A Lavin, arXiv:2112.03235arXiv Preprintscs.AIA. Lavin, et al., arXiv Preprints (2021). arXiv:2112.03235 [cs.AI].</p>
<p>A Holzinger, A Saranti, C Molnar, P Biecek, W Samek, Ai -Beyond Explainable, A I , A Holzinger, Series Title: Lecture Notes in Computer Science. ChamSpringer International Publishing13200A. Holzinger, A. Saranti, C. Molnar, P. Biecek, W. Samek, AI -Beyond Explainable AI, A. Holzinger, et al., eds. (Springer International Publishing, Cham, 2022), vol. 13200, pp. 13-38. Series Title: Lecture Notes in Computer Science.</p>
<p>. AI for Science. ai4sciencecommunity. AI for Science. ai4sciencecommunity. https://ai4sciencecommunity. github.io/.</p>
<p>. P Berens, K Cranmer, N D Lawrence, U Luxburg, J Montgomery, arXiv:2303.04217arXiv PreprintscsP. Berens, K. Cranmer, N. D. Lawrence, U. von Luxburg, J. Montgomery, arXiv Preprints (2023). arXiv:2303.04217 [cs].</p>
<p>. G Karagiorgi, G Kasieczka, S Kravitz, B Nachman, D Shih, Nature Reviews Physics. 4399G. Karagiorgi, G. Kasieczka, S. Kravitz, B. Nachman, D. Shih, Nature Reviews Physics 4, 399 (2022).</p>
<p>. M Raghu, E Schmidt, Preprints , arXiv:2003.11755cs, statM. Raghu, E. Schmidt, arXiv Preprints (2020). arXiv:2003.11755 [cs, stat].</p>
<p>. F NoÃ©, A Tkatchenko, K.-R MÃ¼ller, C Clementi, Annual Review of Physical Chemistry. 71361F. NoÃ©, A. Tkatchenko, K.-R. MÃ¼ller, C. Clementi, Annual Review of Physical Chemistry 71, 361 (2020).</p>
<p>. B A Richards, Nature Neuroscience. 221761B. A. Richards, et al., Nature Neuroscience 22, 1761 (2019).</p>
<p>. H Wang, Nature. 62047H. Wang, et al., Nature 620, 47 (2023).</p>
<p>. R Bommasani, arXiv:2108.07258arXiv PreprintsR. Bommasani, et al., arXiv Preprints (2022). arXiv:2108.07258 [cs].</p>
<p>. Arxiv Openai, Preprints, arXiv:2303.08774csOpenAI, arXiv Preprints (2023). arXiv:2303.08774 [cs].</p>
<p>. A Srivastava, Transactions on Machine Learning Research. A. Srivastava, et al., Transactions on Machine Learning Research (2023).</p>
<p>. A W Senior, Nature. 577706A. W. Senior, et al., Nature 577, 706 (2020).</p>
<p>. R D King, Nature. 427247R. D. King, et al., Nature 427, 247 (2004).</p>
<p>. R D King, Science. 324R. D. King, et al., Science 324 (2009).</p>
<p>. J Mccarthy, Artificial Intelligence. 1711174J. McCarthy, Artificial Intelligence 171, 1174 (2007).</p>
<p>. D Silver, Science. 3621140D. Silver, et al., Science 362, 1140 (2018).</p>
<p>. J M Stokes, Cell. 180688J. M. Stokes, et al., Cell 180, 688 (2020).</p>
<p>. B Alipanahi, A Delong, M T Weirauch, B J Frey, Nature Biotechnology. 33831B. Alipanahi, A. Delong, M. T. Weirauch, B. J. Frey, Nature Biotechnology 33, 831 (2015).</p>
<p>. A W Senior, Nature. 577706A. W. Senior, et al., Nature 577, 706 (2020).</p>
<p>. R D King, Scientific American. 30472R. D. King, Scientific American 304, 72 (2011).</p>
<p>. D Wang, Proceedings of the ACM on Human-Computer Interaction pp. D. Wang, et al., Proceedings of the ACM on Human-Computer Interaction pp. 1-24 (2019).</p>
<p>. B A Nosek, J R Spies, M Motyl, Perspectives on Psychological Science. 7615B. A. Nosek, J. R. Spies, M. Motyl, Perspectives on Psychological Science 7, 615 (2012).</p>
<p>. D Fanelli, R Costas, J Ioannidis, PNAS. 143714D. Fanelli, R. Costas, J. Ioannidis, PNAS 14, 3714 (2017).</p>
<p>. R Nuzzo, Nature. R. Nuzzo, Nature pp. 182-185 (2015).</p>
<p>S N Goodman, D Fanelli, J P Ioannidis, Getting to Good: Research Integrity in the Biomedical Sciences. S. N. Goodman, D. Fanelli, J. P. Ioannidis, Getting to Good: Research Integrity in the Biomedical Sciences pp. 96-102 (2018).</p>
<p>. J K Harris, Public Health Reports. 134109J. K. Harris, et al., Public Health Reports 134, 109 (2019).</p>
<p>. P Kaanders, P Sepulveda, T Folke, P Ortoleva, B D Martino, 2021.06.29.450332P. Kaanders, P. Sepulveda, T. Folke, P. Ortoleva, B. D. Martino, bioRxiv p. 2021.06.29.450332 (2021).</p>
<p>W Dashun, B Albert-LÃ¡szlÃ³, The Science of Science. Cambridge, UKCambridge University PressW. Dashun, B. Albert-LÃ¡szlÃ³, The Science of Science (Cambridge University Press, Cam- bridge, UK, 2021).</p>
<p>. S Fortunato, Science. 359S. Fortunato, et al., Science 359 (2018).</p>
<p>. Nature. 537465NatureNature, Nature 537, 465 (2016).</p>
<p>. V Colizza, A Flammini, M A Serrano, A Vespignani, Nat. Phys. 2110V. Colizza, A. Flammini, M. A. Serrano, A. Vespignani, Nat. Phys. 2, 110 (2006).</p>
<p>. M Baker, Nature. 533452M. Baker, Nature 533, 452 (2016).</p>
<p>. M Baddeley, Embo Rep, 16902M. Baddeley, EMBO Rep. 16, 902 (2015).</p>
<p>. D B Resnik, K C Elliott, Accountability in research. 2331D. B. Resnik, K. C. Elliott, Accountability in research 23, 31 (2016).</p>
<p>. J A Evans, J G Foster, Science. 331J. A. Evans, J. G. Foster, Science 331 (2011).</p>
<p>. S HernÃ¡ndez-Orozco, Frontiers in Artificial Intelligence. 3567356S. HernÃ¡ndez-Orozco, et al., Frontiers in Artificial Intelligence 3, 567356 (2021).</p>
<p>. L Venturi, A Bandeira, J Bruna, Journal on Machine Learning Research. 201L. Venturi, A. Bandeira, J. Bruna, Journal on Machine Learning Research 20, 1 (2019).</p>
<p>. Y Goodfellow, Y Bengio, A Courville, MIT PressY. Goodfellow, Y. Bengio, A. Courville (MIT Press, 2016).</p>
<p>. V Buhrmester, D MÃ¼nch, M Arens, V. Buhrmester, D. MÃ¼nch, M. Arens (2019).</p>
<p>. C Rudin, Nature Machine Intelligence. 1206C. Rudin, Nature Machine Intelligence 1, 206 (2019).</p>
<p>. R Salakhutdinov, Annual Review of Statistics and Its Application. 2361R. Salakhutdinov, Annual Review of Statistics and Its Application 2, 361 (2015).</p>
<p>. A Creswell, IEEE Signal Process. Mag. 3553A. Creswell, et al., IEEE Signal Process. Mag. 35, 53 (2018).</p>
<p>. Y Bian, X.-Q Xie, J. Mol. Model. 2771Y. Bian, X.-Q. Xie, J. Mol. Model. 27, 71 (2021).</p>
<p>. H , Entropy. 22612H. Zenil, Entropy 22, 612 (2020).</p>
<p>. B Scholkopf, Proceedings of the IEEE. 109612B. Scholkopf, et al., Proceedings of the IEEE 109, 612 (2021).</p>
<p>. M J Colbrook, V Antun, A C Hansen, Proceedings of the National Academy of Sciences. 119M. J. Colbrook, V. Antun, A. C. Hansen, Proceedings of the National Academy of Sciences 119 (2022).</p>
<p>. C S Calude, G Longo, Foundations of Science. 22595C. S. Calude, G. Longo, Foundations of Science 22, 595 (2017).</p>
<p>. G Smith, SN Applied Sciences. 2G. Smith, SN Applied Sciences 2 (2020).</p>
<p>. C Nadeau, Mach. Learn. 52239C. Nadeau, Mach. Learn. 52, 239 (2003).</p>
<p>. J Spooner, V Palade, M Cheah, S Kanarachos, A Daneshkhah, Applied Sciences. 11471J. Spooner, V. Palade, M. Cheah, S. Kanarachos, A. Daneshkhah, Applied Sciences 11, 471 (2021).</p>
<p>. H Kitano, AI Magazine. 37H. Kitano, AI Magazine 37 (2016).</p>
<p>. H Zenil, N A Kiani, A A Zea, J TegnÃ©r, Nature Machine Intelligence. 158H. Zenil, N. A. Kiani, A. A. Zea, J. TegnÃ©r, Nature Machine Intelligence 1, 58 (2019).</p>
<p>. H Zenil, N Kiani, F AbrahÃ£o, J TegnÃ©r, Scholarpedia Journal. 1553143H. Zenil, N. Kiani, F. AbrahÃ£o, J. TegnÃ©r, Scholarpedia Journal 15, 53143 (2020).</p>
<p>. F S AbrahÃ£o, H Zenil, Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences. 380F. S. AbrahÃ£o, H. Zenil, Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences 380 (2022).</p>
<p>. X.-B Jin, R J Robert Jeremiah, T.-L Su, Y.-T Bai, J.-L Kong, Sensors (Basel). 212085X.-B. Jin, R. J. Robert Jeremiah, T.-L. Su, Y.-T. Bai, J.-L. Kong, Sensors (Basel) 21, 2085 (2021).</p>
<p>Knowledge Representation and Organization in Machine Learning. S Thieme, Springer-VerlagBerlin/HeidelbergS. Thieme, Knowledge Representation and Organization in Machine Learning (Springer- Verlag, Berlin/Heidelberg, 2005), pp. 177-191.</p>
<p>. R Goebel, Lecture Notes in Computer Science. Springer International PublishingLecture notes in computer scienceR. Goebel, et al., Lecture Notes in Computer Science, Lecture notes in computer science (Springer International Publishing, Cham, 2018), pp. 295-303.</p>
<p>Alan Turing: The codebreaker who saved 'millions of lives. J Copeland, BBC NewsJ. Copeland, Alan Turing: The codebreaker who saved 'millions of lives' -BBC News (2012).</p>
<p>Codebreaker and Computer Pioneer -AlanTuring.net The Turing Archive for the History of Computing. J Copeland, D Proudfoot, Alan Turing, J. Copeland, D. Proudfoot, Alan Turing, Codebreaker and Computer Pioneer -AlanTur- ing.net The Turing Archive for the History of Computing (2004).</p>
<p>. L L Cavalli-Sforza, Cell. 132L. L. Cavalli-Sforza, Cell 132 (2008).</p>
<p>. IEEE Intelligent Systems. 26IEEEIEEE, IEEE Intelligent Systems 26 (2011).</p>
<p>. J. I. Seeman, Chemical &amp; Engineering News. J. I. Seeman, Chemical &amp; Engineering News pp. 10-14 (2013).</p>
<p>Applications of Artificial Intelligence for Organic Chemistry: The DENDRAL Project. J Lederberg, E A Feigenbaum, B G Buchanan, R K Lindsay, McGraw-HillJ. Lederberg, E. A. Feigenbaum, B. G. Buchanan, R. K. Lindsay, Applications of Artificial Intelligence for Organic Chemistry: The DENDRAL Project (McGraw-Hill, 1980).</p>
<p>Rule-Based Expert Systems: The MYCIN Experiments of the Stanford Heuristic Programming Project. B G Buchanan, E H Shortliffe, Addison-WesleyReading, MAB. G. Buchanan, E. H. Shortliffe, Rule-Based Expert Systems: The MYCIN Experiments of the Stanford Heuristic Programming Project (Addison-Wesley, Reading, MA, 1984).</p>
<p>P W Langley, H A Simon, G Bradshaw, J M Zytkow, Scientific Discovery: Computational Explorations of the Creative Process. Cambridge, MassMIT PressP. W. Langley, H. A. Simon, G. Bradshaw, J. M. Zytkow, Scientific Discovery: Computa- tional Explorations of the Creative Process (MIT Press, Cambridge, Mass, 1987).</p>
<p>. B Burger, Nature. 583B. Burger, et al., Nature 583 (2020).</p>
<p>. J Jumper, Nature. 596583J. Jumper, et al., Nature 596, 583 (2021).</p>
<p>. D B Lenat, R Learning, J Michalski, Carbonell, T Mitchell, SpringerBerlin, HeidelbergD. B. Lenat, Machine Learning, R. Michalski, J. Carbonell, Mitchell T.M., eds. (Springer, Berlin, Heidelberg, 1983).</p>
<p>Artificial Intelligence Laboratoy MIT. K W Haase, Discovery Systems AI Memo. 898Tech. rep.K. W. Haase, Discovery Systems AI Memo 898, Tech. rep., Artificial Intelligence Labo- ratoy MIT, Cambridge Mass. (1986).</p>
<p>The Next Generation of AI. Datarobot -Ai Datarobot, Cloud, DataRobot, DataRobot -AI Cloud -The Next Generation of AI.</p>
<p>. Eureqa Eureqa, Models -Datarobot, Eureqa, Eureqa Models -DataRobot.</p>
<p>. Datarobot Ai Cloud Nutonian, Platform, Nutonian, DataRobot AI Cloud Platform.</p>
<p>. R DubÄÃ¡kovÃ¡, Genet. Program. Evolvable Mach. 12173R. DubÄÃ¡kovÃ¡, Genet. Program. Evolvable Mach. 12, 173 (2011).</p>
<p>. J L Awange, B PalÃ¡ncz, R H Lewis, L VÃ¶lgyesi, Mathematical Geosciences. Springer International PublishingJ. L. Awange, B. PalÃ¡ncz, R. H. Lewis, L. VÃ¶lgyesi, Mathematical Geosciences (Springer International Publishing, Cham, 2018), pp. 321-357.</p>
<p>. G.-W Wei, Nature Machine Intelligence. 1336G.-W. Wei, Nature Machine Intelligence 1, 336 (2019).</p>
<p>. J Skolnick, M Gao, H Zhou, S Singh, J. Chem. Inf. Model. 614827J. Skolnick, M. Gao, H. Zhou, S. Singh, J. Chem. Inf. Model. 61, 4827 (2021).</p>
<p>. J Liu, Geophys. Res. Lett. 48J. Liu, et al., Geophys. Res. Lett. 48 (2021).</p>
<p>. R Gupta, Mol. Divers. 251315R. Gupta, et al., Mol. Divers. 25, 1315 (2021).</p>
<p>. R Liu, L Wei, P Zhang, Nat Mach Intell. 368R. Liu, L. Wei, P. Zhang, Nat Mach Intell 3, 68 (2021).</p>
<p>. R Bonneau, Cell. 1311354R. Bonneau, et al., Cell 131, 1354 (2007).</p>
<p>. J R Karr, Cell. 150389J. R. Karr, et al., Cell 150, 389 (2012).</p>
<p>. Y Luo, J Peng, J Ma, Nat Mach Intell. 2426Y. Luo, J. Peng, J. Ma, Nat Mach Intell 2, 426 (2020).</p>
<p>. F S AbrahÃ£o, arXiv:2112.12275arXiv Preprintscs.ITF. S. AbrahÃ£o, et al., arXiv Preprints (2023). arXiv:2112.12275 [cs.IT].</p>
<p>. Y Gil, M Greaves, J Hendler, H Hirsh, Science. 346171Y. Gil, M. Greaves, J. Hendler, H. Hirsh, Science 346, 171 (2014).</p>
<p>K R Popper, Objective Knowledge: An Evolutionary Approach. New YorkOxford University PressK. R. Popper, Objective Knowledge: An Evolutionary Approach (Oxford University Press, New York, 1972).</p>
<p>. R D King, M Liakata, C Lu, S G Oliver, L N Soldatova, Journal of the Royal Society Interface. 81440R. D. King, M. Liakata, C. Lu, S. G. Oliver, L. N. Soldatova, Journal of the Royal Society Interface 8, 1440 (2011).</p>
<p>The Problems of Philosophy. Bertrand Russell, Home University LibraryBertrand Russell, The Problems of Philosophy (Home University Library, 1912).</p>
<p>. J Pearl, Biometrika. 82669J. Pearl, Biometrika 82, 669 (1995).</p>
<p>. C G Morgan, Artificial Intelligence. 2179C. G. Morgan, Artificial Intelligence 2, 179 (1971).</p>
<p>. H Zenil, SSRN Electron. J. H. Zenil, et al., SSRN Electron. J. (2018).</p>
<p>. H Zenil, H. Zenil, et al., iScience pp. 1160--1172 (2019).</p>
<p>. D B Lenat, Artificial Intelligence. 19189D. B. Lenat, Artificial Intelligence 19, 189 (1982).</p>
<p>. H Zenil, N A Kiani, J TegnÃ©r, Physical Review E. 9612308H. Zenil, N. A. Kiani, J. TegnÃ©r, Physical Review E 96, 012308 (2017).</p>
<p>. S HernÃ¡ndez-Orozco, F HernÃ¡ndez-Quiroz, H Zenil, Artificial Life. 2456S. HernÃ¡ndez-Orozco, F. HernÃ¡ndez-Quiroz, H. Zenil, Artificial Life 24, 56 (2018).</p>
<p>. S HernÃ¡ndez-Orozco, N A Kiani, H Zenil, Royal Society Open Science. 5180399S. HernÃ¡ndez-Orozco, N. A. Kiani, H. Zenil, Royal Society Open Science 5, 180399 (2018).</p>
<p>. F S AbrahÃ£o, K Wehmuth, A Ziviani, Theoretical Computer Science. 78583F. S. AbrahÃ£o, K. Wehmuth, A. Ziviani, Theoretical Computer Science 785, 83 (2019).</p>
<p>. F S AbrahÃ£o, K Wehmuth, A Ziviani, Complex Systems. 27F. S. AbrahÃ£o, K. Wehmuth, A. Ziviani, Complex Systems 27 (2018).</p>
<p>. H Kitano, AI Magazine. 1873H. Kitano, et al., AI Magazine 18, 73 (1997).</p>
<p>. B Lindner, L Schimansky-Geier, Physical Review E. 607270B. Lindner, L. Schimansky-Geier, Physical Review E 60, 7270 (1999).</p>
<p>. M Drton, M H Maathuis, Annual Review of Statistics and Its Application. 4365M. Drton, M. H. Maathuis, Annual Review of Statistics and Its Application 4, 365 (2017).</p>
<p>. S R Eddy, Nat. Biotechnol. 221177S. R. Eddy, Nat. Biotechnol. 22, 1177 (2004).</p>
<p>. R Stevens, C A Goble, S Bechhofer, Brief. Bioinform. 1398R. Stevens, C. A. Goble, S. Bechhofer, Brief. Bioinform. 1, 398 (2000).</p>
<p>. J B L Bard, S Y Rhee, Nat. Rev. Genet. 5213J. B. L. Bard, S. Y. Rhee, Nat. Rev. Genet. 5, 213 (2004).</p>
<p>. K A Shefchek, Nucleic Acids Res. 48704K. A. Shefchek, et al., Nucleic Acids Res. 48, D704 (2020).</p>
<p>L D Raedt, Logical and Relational Learning. Berlin Heidelberg, Berlin, HeidelbergSpringerL. D. Raedt, Logical and Relational Learning (Springer Berlin Heidelberg, Berlin, Hei- delberg, 2008).</p>
<p>. O I Orhobor, N N Alexandrov, R D King, Machine Learning. 109112195O. I. Orhobor, N. N. Alexandrov, R. D. King, Machine Learning 2020 109:11 109, 2195 (2020).</p>
<p>J Pearl, Uncertainty in Artificial Intelligence -Proceedings of the 28th Conference, UAI. J. Pearl, Uncertainty in Artificial Intelligence -Proceedings of the 28th Conference, UAI 2012 pp. 4-11 (2012).</p>
<p>. C Tang, Neural Netw. 117163C. Tang, et al., Neural Netw. 117, 163 (2019).</p>
<p>. F S AbrahÃ£o, K Wehmuth, H Zenil, A Ziviani, Entropy. 23F. S. AbrahÃ£o, K. Wehmuth, H. Zenil, A. Ziviani, Entropy 23 (2021).</p>
<p>. G G Chowdhury, Annual Review of Information Science and Technology. 3751G. G. Chowdhury, Annual Review of Information Science and Technology 37, 51 (2005).</p>
<p>. E Cambria, B White, IEEE Comput. Intell. Mag. 948E. Cambria, B. White, IEEE Comput. Intell. Mag. 9, 48 (2014).</p>
<p>. C Andronis, A Sharma, V Virvilis, S Deftereos, A Persidis, Brief. Bioinform. 12357C. Andronis, A. Sharma, V. Virvilis, S. Deftereos, A. Persidis, Brief. Bioinform. 12, 357 (2011).</p>
<p>. M Campbell, A J Hoane, F Hsu, Artificial Intelligence. 13457M. Campbell, A. J. Hoane, F. Hsu, Artificial Intelligence 134, 57 (2002).</p>
<p>. H Kitano, M Asada, I Noda, H Matsubara, IEEE Robot. Autom. Mag. 530H. Kitano, M. Asada, I. Noda, H. Matsubara, IEEE Robot. Autom. Mag. 5, 30 (1998).</p>
<p>. D Silver, Nature. 7587484D. Silver, et al., Nature 7587, 484-(2016).</p>
<p>. D Hassabis, Nature. D. Hassabis, Nature pp. 413-414 (2017).</p>
<p>H Kitano, npj Systems Biology and Applications. 71H. Kitano, npj Systems Biology and Applications 2021 7:1 7, 1 (2021).</p>            </div>
        </div>

    </div>
</body>
</html>