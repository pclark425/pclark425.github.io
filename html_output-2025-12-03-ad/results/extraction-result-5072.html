<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-5072 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-5072</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-5072</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-106.html">extraction-schema-106</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models (LLMs or neural language models) being used to solve puzzle games that require spatial knowledge (such as Sudoku or other spatial reasoning tasks). Include details about the models, the puzzles, the mechanisms or strategies used, performance metrics, evidence of spatial reasoning, limitations, and comparisons.</div>
                <p><strong>Paper ID:</strong> paper-162e2e9ac70702c146c0aa8432e4a6806bb8c42e</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/162e2e9ac70702c146c0aa8432e4a6806bb8c42e" target="_blank">Coupling Large Language Models with Logic Programming for Robust and General Reasoning from Text</a></p>
                <p><strong>Paper Venue:</strong> Annual Meeting of the Association for Computational Linguistics</p>
                <p><strong>Paper TL;DR:</strong> This study observes that a large language model can serve as a highly effective few-shot semantic parser that can convert natural language sentences into a logical form that serves as input for answer set programs, a logic-based declarative knowledge representation formalism.</p>
                <p><strong>Paper Abstract:</strong> While large language models (LLMs), such as GPT-3, appear to be robust and general, their reasoning ability is not at a level to compete with the best models trained for specific natural language reasoning problems. In this study, we observe that a large language model can serve as a highly effective few-shot semantic parser. It can convert natural language sentences into a logical form that serves as input for answer set programs, a logic-based declarative knowledge representation formalism. The combination results in a robust and general system that can handle multiple question-answering tasks without requiring retraining for each new task. It only needs a few examples to guide the LLM's adaptation to a specific task, along with reusable ASP knowledge modules that can be applied to multiple tasks. We demonstrate that this method achieves state-of-the-art performance on several NLP benchmarks, including bAbI, StepGame, CLUTRR, and gSCAN. Additionally, it successfully tackles robot planning tasks that an LLM alone fails to solve.</p>
                <p><strong>Cost:</strong> 0.018</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e5072.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e5072.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models (LLMs or neural language models) being used to solve puzzle games that require spatial knowledge (such as Sudoku or other spatial reasoning tasks). Include details about the models, the puzzles, the mechanisms or strategies used, performance metrics, evidence of spatial reasoning, limitations, and comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-3+ASP (StepGame)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-3 (text-davinci-002 / text-davinci-003) as semantic parser coupled with Answer Set Programming for StepGame</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>This work uses GPT-3 variants as few-shot semantic parsers to convert spatial natural-language sentences into atomic facts, and uses an ASP location knowledge module to perform multi-hop spatial reasoning on the StepGame benchmark.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Coupling Large Language Models with Logic Programming for Robust and General Reasoning from Text</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>OpenAI GPT-3 variants (text-davinci-002, text-davinci-003) used as semantic parsers + CLINGO Answer Set Programming solver</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Transformer-based large pre-trained language models from the GPT-3 family (engines referenced as text-curie-001, text-davinci-002, text-davinci-003 in the paper) used in few-shot in-context prompting mode to produce canonical atomic facts. The exact model sizes/parameter counts are not specified in this paper. The symbolic component is Answer Set Programming (CLINGO v5.6.0) with hand-written ASP knowledge modules (not learned).</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_name</strong></td>
                            <td>StepGame</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_description</strong></td>
                            <td>A contextual QA benchmark requiring interpretation of textual descriptions of 2D spatial relations among many entities and multi-hop spatial reasoning (up to 10 hops in experiments). Stories describe relative positions (including clock-face style directions) and queries ask for the relation between two entities.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanism_or_strategy</strong></td>
                            <td>Few-shot prompting of GPT-3 to parse each sentence separately into atomic spatial facts (e.g., top_right("C","D") or is(A,R,B)). Prompt engineering included enumerating clock-number to cardinal-direction mappings when needed. The ASP 'location' module encodes spatial offsets (9 predefined offsets) and a multi-hop rule location(A,Xa,Ya) :- location(B,Xb,Yb), is(A,R,B), offset(R,Dx,Dy), Xa=Xb+Dx, Ya=Yb+Dy. The query is resolved by fixing one object's location and deriving the other object's coordinates and mapping offsets back to relations. The pipeline is LLM -> atomic facts -> ASP reasoner -> answer.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_of_spatial_reasoning</strong></td>
                            <td>Indirect but strong: (1) High task performance on multi-hop spatial queries (up to 10 hops) demonstrates use of compositional spatial reasoning via the ASP location module; (2) qualitative examples show GPT-3 normalizes diverse spatial language (e.g., '45 degree angle', '2 o'clock') into canonical relations used by ASP; (3) the ASP module explicitly computes coordinates and propagates multi-hop offsets, providing inspectable derivations (interpretable symbolic proof traces). The paper does not present internal probing of the LLM's spatial representations, only task performance and interpretable ASP traces.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Test accuracy reported per chain length k (k = number of hops). Using text-davinci-002 + ASP (denoted GPT-3(d2)+ASP) achieved very high accuracy across k: e.g., k=1: 92.6%, k=2: 89.9%, k=3: 89.1%, k=4: 93.8%, k=5: 92.9%, and for k=6..10 ranged 91.6% down to 88.3% (Table 2). In contrast, GPT-3 few-shot and CoT baselines had much lower accuracies for larger k (e.g., few-shot(d3) 55% at k=1 down to ~31% at k=5; CoT varied). The combined system (GPT-3+ASP) outperformed many prior methods (RN, RRN, STM, UT) on long-chain cases.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Primary limitations were semantic-parsing errors from GPT-3 (argument misorder, wrong relation, missing grounding of adverbs/clock mappings) that required careful prompt engineering; LLMs alone performed poorly on multi-step reasoning. The approach relies on hand-authored ASP knowledge modules (manual effort). Some dataset label errors in StepGame (paper found ~10.7% wrong labels in sample) complicate evaluation. Chain-of-Thought prompting sometimes decreased performance for long chains (more chance to make mistakes).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Outperforms prior state-of-the-art methods on StepGame for k>=4 (e.g., TPR-RNN, TP-MANN, STM, SynSup): GPT-3(d2)+ASP gave substantially higher accuracy on long chains; SynSup had higher apparent accuracy for small k but the paper attributes that to dataset labeling errors. Baselines include GPT-3 few-shot and GPT-3 with Chain-of-Thought prompting (CoT), both evaluated and shown to be inferior on long multi-hop spatial tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Coupling Large Language Models with Logic Programming for Robust and General Reasoning from Text', 'publication_date_yy_mm': '2023-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5072.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e5072.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models (LLMs or neural language models) being used to solve puzzle games that require spatial knowledge (such as Sudoku or other spatial reasoning tasks). Include details about the models, the puzzles, the mechanisms or strategies used, performance metrics, evidence of spatial reasoning, limitations, and comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-3+ASP (gSCAN)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-3 (text-davinci-002 / text-curie-001) as semantic parser coupled with ASP planner for gSCAN</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>GPT-3 extracts command-level atomic facts from natural-language instructions while a small ASP planning module (plus a Python extractor for grid) computes the action sequence to execute the command in the gSCAN grid environment.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Coupling Large Language Models with Logic Programming for Robust and General Reasoning from Text</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>OpenAI GPT-3 variants (text-davinci-002, text-curie-001) used as semantic parsers + CLINGO ASP for plan generation</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>GPT-3 family models used in few-shot prompting to parse the natural-language command into atomic predicates such as query(pull), queryDesc(yellow), while(hesitantly). Grid state facts are extracted by a Python script from JSON environment descriptions and fed to ASP (CLINGO) to plan a sequence of actions. Exact parameter counts for GPT-3 engines are not stated in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_name</strong></td>
                            <td>gSCAN (compositional generalization in grounded language understanding)</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_description</strong></td>
                            <td>An instruction-following grid navigation task where an agent must execute a sequence of low-level actions to satisfy a natural-language command in a 2D grid world; requires grounding of descriptors (color, shape, size), adverbs (modes of movement), and often compositional generalization with held-out combinations.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanism_or_strategy</strong></td>
                            <td>Two-stage pipeline: (1) Python extractor converts grid JSON to facts (pos(agent,(x,y)), object features); GPT-3 parses the command into query and attribute predicates; (2) ASP encodes action preconditions/effects and generates the action sequence to achieve the goal. The paper uses few-shot prompts for parsing and a reusable ASP knowledge module for action planning.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_of_spatial_reasoning</strong></td>
                            <td>Task-level evidence: perfect or near-perfect execution of spatially grounded action sequences when GPT-3 parsing is correct; ASP performs exact plan synthesis accounting for agent position, object positions and intermediate state changes. The ASP derivations are explicit symbolic plans (inspectable). No internal LLM spatial probing was performed; evidence is via correct plans and high split-wise task performance.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>On the evaluated portions (first 1000 instances per split) GPT-3(d2)+ASP achieved 100% accuracy across splits A–H (Table 5). GPT-3(curie)+ASP was slightly lower (e.g., 98.3% with 17 errors in split A) due to parsing omissions. Compared baselines (GECA, DualSys, Vilbert+CMA) had much lower scores on many splits.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Parsing errors (LLM failing to extract adverbs or to ground the final token) were the primary failure modes; when parsing was correct, ASP produced correct plans. The system depends on a correct mapping from natural-language descriptors to symbolic predicates (requires prompt design), and ASP modules must be written by hand.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>GPT-3+ASP (d2) outperformed GECA, DualSys, and Vilbert+CMA on the gSCAN splits evaluated (reported 100% vs substantially lower numbers for many splits). The paper also notes that curie model performed worse than davinci-002.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Coupling Large Language Models with Logic Programming for Robust and General Reasoning from Text', 'publication_date_yy_mm': '2023-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5072.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e5072.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models (LLMs or neural language models) being used to solve puzzle games that require spatial knowledge (such as Sudoku or other spatial reasoning tasks). Include details about the models, the puzzles, the mechanisms or strategies used, performance metrics, evidence of spatial reasoning, limitations, and comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-3+ASP (Pick&Place robot planning)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-3 (text-davinci-003) semantic parsing + ASP planning for Pick&Place tabletop domain</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>In a virtual Pick&Place domain, GPT-3 was used to parse initial and goal states into atomic on/goal facts, and ASP computed a shortest executable plan; the combined system succeeded where GPT-3 planning alone failed.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Coupling Large Language Models with Logic Programming for Robust and General Reasoning from Text</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>OpenAI GPT-3 (text-davinci-003) as semantic parser; ASP planner (CLINGO) encodes pick_and_place actions and constraints</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>GPT-3 (text-davinci-003) with few-shot prompts to convert natural-language descriptions of initial and goal states into atomic facts of form on(A,B,0) and on(A,B). ASP encodes domain dynamics and constraints and searches for shortest plans. Paper does not provide model parameter counts.</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_name</strong></td>
                            <td>Pick&Place (virtual tabletop robot planning)</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_description</strong></td>
                            <td>A planning task where a robot must transform an initial stacking/placement configuration of colored blocks and bowls into a goal configuration (3–10 steps), handling constraints like 'cannot move a block if something is on it', bowl capacities, and intermediate states.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanism_or_strategy</strong></td>
                            <td>GPT-3 converts textual state descriptions to symbolic facts; ASP (event calculus like axioms / planning module) performs search for an executable shortest sequence of pick_and_place actions respecting constraints. The baseline using GPT-3 alone to produce plans directly was also evaluated.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_of_spatial_reasoning</strong></td>
                            <td>Demonstrated by successful, correct multi-step plans produced by ASP given GPT-3 parsed facts; the symbolic planner reasons about intermediate spatial configurations explicitly. Quantitative evidence: 100% success on sampled instances when using GPT-3+ASP; 0% success for GPT-3-alone baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>On 40 randomly sampled instances (20 blocks-only, 20 blocks+bowls), GPT-3(d3) alone: 0% successful plans. GPT-3(d3)+ASP: 100% successful plans for both categories (Table 6).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Requires accurate parsing of initial/goal states; GPT-3-alone fails as a planner (supports critique that LLMs do not reliably plan sequence of stateful actions). The system relies on manually written ASP planning modules and correct prompts for parsing.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>GPT-3 alone (direct plan generation via prompt) failed on all sampled instances, while GPT-3+ASP succeeded on all, showing the advantage of explicit symbolic planning over direct LLM planning for these spatial planning problems.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Coupling Large Language Models with Logic Programming for Robust and General Reasoning from Text', 'publication_date_yy_mm': '2023-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5072.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e5072.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models (LLMs or neural language models) being used to solve puzzle games that require spatial knowledge (such as Sudoku or other spatial reasoning tasks). Include details about the models, the puzzles, the mechanisms or strategies used, performance metrics, evidence of spatial reasoning, limitations, and comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-3+ASP (bAbI positional reasoning)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-3 (text-davinci-003) semantic parsing + ASP for bAbI spatial and other reasoning tasks</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>GPT-3 is used to parse bAbI stories into facts; ASP modules (including location) perform reasoning for tasks that include positional/spatial queries (e.g., task 17 'positional reasoning'), producing near-perfect performance.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Coupling Large Language Models with Logic Programming for Robust and General Reasoning from Text</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>OpenAI GPT-3 (text-davinci-003) as semantic parser + CLINGO ASP</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>text-davinci-003 used in few-shot and Chain-of-Thought baselines for bAbI; in the GPT-3+ASP pipeline GPT-3 produces atomic facts and ASP knowledge modules (DEC, location, action) perform reasoning. Exact model capacities not given in paper.</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_name</strong></td>
                            <td>bAbI (task suite including positional reasoning)</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_description</strong></td>
                            <td>A suite of toy textual reasoning tasks; several tasks (e.g., task 17) require understanding and reasoning about spatial relations (e.g., 'A is north of B').</td>
                        </tr>
                        <tr>
                            <td><strong>mechanism_or_strategy</strong></td>
                            <td>Few-shot prompting or CoT to extract facts from sentences; ASP modules (Discrete Event Calculus for temporal tasks and location module for spatial tasks) then perform symbolic reasoning to answer queries. LLM parsing is applied sentence-by-sentence for independence where appropriate.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_of_spatial_reasoning</strong></td>
                            <td>High accuracy on spatial tasks: GPT-3(d3)+ASP achieves near-perfect per-task performance; for positional reasoning (task 17) GPT-3 few-shot/CoT underperform (66%/70.8%) while GPT-3+ASP achieves 100% on that task (Table 1). ASP computes location offsets providing explicit spatial derivations.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Overall GPT-3(d3)+ASP average across 20 bAbI tasks: 99.99% (only two disagreements which authors attribute to malformed labels). For positional reasoning (task 17) GPT-3(d3)+ASP reported 100% accuracy vs GPT-3 few-shot 66.0% and CoT 70.8% (Table 1).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Parsing failures from GPT-3 and need for prompt engineering (e.g., to handle clock-face descriptions) were noted. The approach needs hand-authored ASP modules for domain knowledge. LLM Chain-of-Thought helps some tasks but not all.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared to GPT-3 few-shot and GPT-3 CoT baselines, GPT-3+ASP substantially improves accuracy on spatial and multi-step problems. Compared to trained models (STM, QRN), GPT-3+ASP achieved state-of-the-art performance without task-specific retraining.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Coupling Large Language Models with Logic Programming for Robust and General Reasoning from Text', 'publication_date_yy_mm': '2023-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Stepgame: A new benchmark for robust multi-hop spatial reasoning in texts <em>(Rating: 2)</em></li>
                <li>A benchmark for systematic generalization in grounded language understanding <em>(Rating: 2)</em></li>
                <li>Do as I can, not as I say: Grounding language in robotic affordances <em>(Rating: 2)</em></li>
                <li>Large language models still can't plan (a benchmark for LLMs on planning and reasoning about change) <em>(Rating: 2)</em></li>
                <li>Improving coherence and consistency in neural sequence models with dual-system, neuro-symbolic reasoning <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-5072",
    "paper_id": "paper-162e2e9ac70702c146c0aa8432e4a6806bb8c42e",
    "extraction_schema_id": "extraction-schema-106",
    "extracted_data": [
        {
            "name_short": "GPT-3+ASP (StepGame)",
            "name_full": "GPT-3 (text-davinci-002 / text-davinci-003) as semantic parser coupled with Answer Set Programming for StepGame",
            "brief_description": "This work uses GPT-3 variants as few-shot semantic parsers to convert spatial natural-language sentences into atomic facts, and uses an ASP location knowledge module to perform multi-hop spatial reasoning on the StepGame benchmark.",
            "citation_title": "Coupling Large Language Models with Logic Programming for Robust and General Reasoning from Text",
            "mention_or_use": "use",
            "model_name": "OpenAI GPT-3 variants (text-davinci-002, text-davinci-003) used as semantic parsers + CLINGO Answer Set Programming solver",
            "model_description": "Transformer-based large pre-trained language models from the GPT-3 family (engines referenced as text-curie-001, text-davinci-002, text-davinci-003 in the paper) used in few-shot in-context prompting mode to produce canonical atomic facts. The exact model sizes/parameter counts are not specified in this paper. The symbolic component is Answer Set Programming (CLINGO v5.6.0) with hand-written ASP knowledge modules (not learned).",
            "puzzle_name": "StepGame",
            "puzzle_description": "A contextual QA benchmark requiring interpretation of textual descriptions of 2D spatial relations among many entities and multi-hop spatial reasoning (up to 10 hops in experiments). Stories describe relative positions (including clock-face style directions) and queries ask for the relation between two entities.",
            "mechanism_or_strategy": "Few-shot prompting of GPT-3 to parse each sentence separately into atomic spatial facts (e.g., top_right(\"C\",\"D\") or is(A,R,B)). Prompt engineering included enumerating clock-number to cardinal-direction mappings when needed. The ASP 'location' module encodes spatial offsets (9 predefined offsets) and a multi-hop rule location(A,Xa,Ya) :- location(B,Xb,Yb), is(A,R,B), offset(R,Dx,Dy), Xa=Xb+Dx, Ya=Yb+Dy. The query is resolved by fixing one object's location and deriving the other object's coordinates and mapping offsets back to relations. The pipeline is LLM -&gt; atomic facts -&gt; ASP reasoner -&gt; answer.",
            "evidence_of_spatial_reasoning": "Indirect but strong: (1) High task performance on multi-hop spatial queries (up to 10 hops) demonstrates use of compositional spatial reasoning via the ASP location module; (2) qualitative examples show GPT-3 normalizes diverse spatial language (e.g., '45 degree angle', '2 o'clock') into canonical relations used by ASP; (3) the ASP module explicitly computes coordinates and propagates multi-hop offsets, providing inspectable derivations (interpretable symbolic proof traces). The paper does not present internal probing of the LLM's spatial representations, only task performance and interpretable ASP traces.",
            "performance_metrics": "Test accuracy reported per chain length k (k = number of hops). Using text-davinci-002 + ASP (denoted GPT-3(d2)+ASP) achieved very high accuracy across k: e.g., k=1: 92.6%, k=2: 89.9%, k=3: 89.1%, k=4: 93.8%, k=5: 92.9%, and for k=6..10 ranged 91.6% down to 88.3% (Table 2). In contrast, GPT-3 few-shot and CoT baselines had much lower accuracies for larger k (e.g., few-shot(d3) 55% at k=1 down to ~31% at k=5; CoT varied). The combined system (GPT-3+ASP) outperformed many prior methods (RN, RRN, STM, UT) on long-chain cases.",
            "limitations_or_failure_cases": "Primary limitations were semantic-parsing errors from GPT-3 (argument misorder, wrong relation, missing grounding of adverbs/clock mappings) that required careful prompt engineering; LLMs alone performed poorly on multi-step reasoning. The approach relies on hand-authored ASP knowledge modules (manual effort). Some dataset label errors in StepGame (paper found ~10.7% wrong labels in sample) complicate evaluation. Chain-of-Thought prompting sometimes decreased performance for long chains (more chance to make mistakes).",
            "comparison_baseline": "Outperforms prior state-of-the-art methods on StepGame for k&gt;=4 (e.g., TPR-RNN, TP-MANN, STM, SynSup): GPT-3(d2)+ASP gave substantially higher accuracy on long chains; SynSup had higher apparent accuracy for small k but the paper attributes that to dataset labeling errors. Baselines include GPT-3 few-shot and GPT-3 with Chain-of-Thought prompting (CoT), both evaluated and shown to be inferior on long multi-hop spatial tasks.",
            "uuid": "e5072.0",
            "source_info": {
                "paper_title": "Coupling Large Language Models with Logic Programming for Robust and General Reasoning from Text",
                "publication_date_yy_mm": "2023-07"
            }
        },
        {
            "name_short": "GPT-3+ASP (gSCAN)",
            "name_full": "GPT-3 (text-davinci-002 / text-curie-001) as semantic parser coupled with ASP planner for gSCAN",
            "brief_description": "GPT-3 extracts command-level atomic facts from natural-language instructions while a small ASP planning module (plus a Python extractor for grid) computes the action sequence to execute the command in the gSCAN grid environment.",
            "citation_title": "Coupling Large Language Models with Logic Programming for Robust and General Reasoning from Text",
            "mention_or_use": "use",
            "model_name": "OpenAI GPT-3 variants (text-davinci-002, text-curie-001) used as semantic parsers + CLINGO ASP for plan generation",
            "model_description": "GPT-3 family models used in few-shot prompting to parse the natural-language command into atomic predicates such as query(pull), queryDesc(yellow), while(hesitantly). Grid state facts are extracted by a Python script from JSON environment descriptions and fed to ASP (CLINGO) to plan a sequence of actions. Exact parameter counts for GPT-3 engines are not stated in the paper.",
            "puzzle_name": "gSCAN (compositional generalization in grounded language understanding)",
            "puzzle_description": "An instruction-following grid navigation task where an agent must execute a sequence of low-level actions to satisfy a natural-language command in a 2D grid world; requires grounding of descriptors (color, shape, size), adverbs (modes of movement), and often compositional generalization with held-out combinations.",
            "mechanism_or_strategy": "Two-stage pipeline: (1) Python extractor converts grid JSON to facts (pos(agent,(x,y)), object features); GPT-3 parses the command into query and attribute predicates; (2) ASP encodes action preconditions/effects and generates the action sequence to achieve the goal. The paper uses few-shot prompts for parsing and a reusable ASP knowledge module for action planning.",
            "evidence_of_spatial_reasoning": "Task-level evidence: perfect or near-perfect execution of spatially grounded action sequences when GPT-3 parsing is correct; ASP performs exact plan synthesis accounting for agent position, object positions and intermediate state changes. The ASP derivations are explicit symbolic plans (inspectable). No internal LLM spatial probing was performed; evidence is via correct plans and high split-wise task performance.",
            "performance_metrics": "On the evaluated portions (first 1000 instances per split) GPT-3(d2)+ASP achieved 100% accuracy across splits A–H (Table 5). GPT-3(curie)+ASP was slightly lower (e.g., 98.3% with 17 errors in split A) due to parsing omissions. Compared baselines (GECA, DualSys, Vilbert+CMA) had much lower scores on many splits.",
            "limitations_or_failure_cases": "Parsing errors (LLM failing to extract adverbs or to ground the final token) were the primary failure modes; when parsing was correct, ASP produced correct plans. The system depends on a correct mapping from natural-language descriptors to symbolic predicates (requires prompt design), and ASP modules must be written by hand.",
            "comparison_baseline": "GPT-3+ASP (d2) outperformed GECA, DualSys, and Vilbert+CMA on the gSCAN splits evaluated (reported 100% vs substantially lower numbers for many splits). The paper also notes that curie model performed worse than davinci-002.",
            "uuid": "e5072.1",
            "source_info": {
                "paper_title": "Coupling Large Language Models with Logic Programming for Robust and General Reasoning from Text",
                "publication_date_yy_mm": "2023-07"
            }
        },
        {
            "name_short": "GPT-3+ASP (Pick&Place robot planning)",
            "name_full": "GPT-3 (text-davinci-003) semantic parsing + ASP planning for Pick&Place tabletop domain",
            "brief_description": "In a virtual Pick&Place domain, GPT-3 was used to parse initial and goal states into atomic on/goal facts, and ASP computed a shortest executable plan; the combined system succeeded where GPT-3 planning alone failed.",
            "citation_title": "Coupling Large Language Models with Logic Programming for Robust and General Reasoning from Text",
            "mention_or_use": "use",
            "model_name": "OpenAI GPT-3 (text-davinci-003) as semantic parser; ASP planner (CLINGO) encodes pick_and_place actions and constraints",
            "model_description": "GPT-3 (text-davinci-003) with few-shot prompts to convert natural-language descriptions of initial and goal states into atomic facts of form on(A,B,0) and on(A,B). ASP encodes domain dynamics and constraints and searches for shortest plans. Paper does not provide model parameter counts.",
            "puzzle_name": "Pick&Place (virtual tabletop robot planning)",
            "puzzle_description": "A planning task where a robot must transform an initial stacking/placement configuration of colored blocks and bowls into a goal configuration (3–10 steps), handling constraints like 'cannot move a block if something is on it', bowl capacities, and intermediate states.",
            "mechanism_or_strategy": "GPT-3 converts textual state descriptions to symbolic facts; ASP (event calculus like axioms / planning module) performs search for an executable shortest sequence of pick_and_place actions respecting constraints. The baseline using GPT-3 alone to produce plans directly was also evaluated.",
            "evidence_of_spatial_reasoning": "Demonstrated by successful, correct multi-step plans produced by ASP given GPT-3 parsed facts; the symbolic planner reasons about intermediate spatial configurations explicitly. Quantitative evidence: 100% success on sampled instances when using GPT-3+ASP; 0% success for GPT-3-alone baseline.",
            "performance_metrics": "On 40 randomly sampled instances (20 blocks-only, 20 blocks+bowls), GPT-3(d3) alone: 0% successful plans. GPT-3(d3)+ASP: 100% successful plans for both categories (Table 6).",
            "limitations_or_failure_cases": "Requires accurate parsing of initial/goal states; GPT-3-alone fails as a planner (supports critique that LLMs do not reliably plan sequence of stateful actions). The system relies on manually written ASP planning modules and correct prompts for parsing.",
            "comparison_baseline": "GPT-3 alone (direct plan generation via prompt) failed on all sampled instances, while GPT-3+ASP succeeded on all, showing the advantage of explicit symbolic planning over direct LLM planning for these spatial planning problems.",
            "uuid": "e5072.2",
            "source_info": {
                "paper_title": "Coupling Large Language Models with Logic Programming for Robust and General Reasoning from Text",
                "publication_date_yy_mm": "2023-07"
            }
        },
        {
            "name_short": "GPT-3+ASP (bAbI positional reasoning)",
            "name_full": "GPT-3 (text-davinci-003) semantic parsing + ASP for bAbI spatial and other reasoning tasks",
            "brief_description": "GPT-3 is used to parse bAbI stories into facts; ASP modules (including location) perform reasoning for tasks that include positional/spatial queries (e.g., task 17 'positional reasoning'), producing near-perfect performance.",
            "citation_title": "Coupling Large Language Models with Logic Programming for Robust and General Reasoning from Text",
            "mention_or_use": "use",
            "model_name": "OpenAI GPT-3 (text-davinci-003) as semantic parser + CLINGO ASP",
            "model_description": "text-davinci-003 used in few-shot and Chain-of-Thought baselines for bAbI; in the GPT-3+ASP pipeline GPT-3 produces atomic facts and ASP knowledge modules (DEC, location, action) perform reasoning. Exact model capacities not given in paper.",
            "puzzle_name": "bAbI (task suite including positional reasoning)",
            "puzzle_description": "A suite of toy textual reasoning tasks; several tasks (e.g., task 17) require understanding and reasoning about spatial relations (e.g., 'A is north of B').",
            "mechanism_or_strategy": "Few-shot prompting or CoT to extract facts from sentences; ASP modules (Discrete Event Calculus for temporal tasks and location module for spatial tasks) then perform symbolic reasoning to answer queries. LLM parsing is applied sentence-by-sentence for independence where appropriate.",
            "evidence_of_spatial_reasoning": "High accuracy on spatial tasks: GPT-3(d3)+ASP achieves near-perfect per-task performance; for positional reasoning (task 17) GPT-3 few-shot/CoT underperform (66%/70.8%) while GPT-3+ASP achieves 100% on that task (Table 1). ASP computes location offsets providing explicit spatial derivations.",
            "performance_metrics": "Overall GPT-3(d3)+ASP average across 20 bAbI tasks: 99.99% (only two disagreements which authors attribute to malformed labels). For positional reasoning (task 17) GPT-3(d3)+ASP reported 100% accuracy vs GPT-3 few-shot 66.0% and CoT 70.8% (Table 1).",
            "limitations_or_failure_cases": "Parsing failures from GPT-3 and need for prompt engineering (e.g., to handle clock-face descriptions) were noted. The approach needs hand-authored ASP modules for domain knowledge. LLM Chain-of-Thought helps some tasks but not all.",
            "comparison_baseline": "Compared to GPT-3 few-shot and GPT-3 CoT baselines, GPT-3+ASP substantially improves accuracy on spatial and multi-step problems. Compared to trained models (STM, QRN), GPT-3+ASP achieved state-of-the-art performance without task-specific retraining.",
            "uuid": "e5072.3",
            "source_info": {
                "paper_title": "Coupling Large Language Models with Logic Programming for Robust and General Reasoning from Text",
                "publication_date_yy_mm": "2023-07"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Stepgame: A new benchmark for robust multi-hop spatial reasoning in texts",
            "rating": 2
        },
        {
            "paper_title": "A benchmark for systematic generalization in grounded language understanding",
            "rating": 2
        },
        {
            "paper_title": "Do as I can, not as I say: Grounding language in robotic affordances",
            "rating": 2
        },
        {
            "paper_title": "Large language models still can't plan (a benchmark for LLMs on planning and reasoning about change)",
            "rating": 2
        },
        {
            "paper_title": "Improving coherence and consistency in neural sequence models with dual-system, neuro-symbolic reasoning",
            "rating": 2
        }
    ],
    "cost": 0.017772999999999997,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Coupling Large Language Models with Logic Programming for Robust and General Reasoning from Text</h1>
<p>Zhun Yang, Adam Ishay ${ }^{1}$<br>${ }^{1}$ Arizona State University<br>{zyang90,aishay}@asu.edu</p>
<p>Joohyung Lee ${ }^{1,2}$<br>${ }^{2}$ Samsung Research<br>joolee@asu.edu</p>
<h4>Abstract</h4>
<p>While large language models (LLMs), such as GPT-3, appear to be robust and general, their reasoning ability is not at a level to compete with the best models trained for specific natural language reasoning problems. In this study, we observe that a large language model can serve as a highly effective few-shot semantic parser. It can convert natural language sentences into a logical form that serves as input for answer set programs, a logic-based declarative knowledge representation formalism. The combination results in a robust and general system that can handle multiple question-answering tasks without requiring retraining for each new task. It only needs a few examples to guide the LLM's adaptation to a specific task, along with reusable ASP knowledge modules that can be applied to multiple tasks. We demonstrate that this method achieves state-of-the-art performance on several NLP benchmarks, including bAbI, StepGame, CLUTRR, and gSCAN. Additionally, it successfully tackles robot planning tasks that an LLM alone fails to solve.</p>
<h2>1 Introduction</h2>
<p>A typical way to handle a question-answering task is to train a neural network model on large training data and test it on similar data. Such models work well with linguistic variability and ambiguity but often learn statistical features and correlations rather than true reasoning (Ruder, 2021), which makes them not robust, lack generalization, and difficult to interpret.</p>
<p>Alternatively, transformer-based large language models (LLMs) have recently shown wide success on many downstream tasks, demonstrating general reasoning capability on diverse tasks without being retrained. However, when we restrict our attention to individual NLP reasoning benchmarks, they usually do not perform as well as state-of-the-art models despite various efforts to improve accuracy through prompt engineering (Wei et al., 2022; Zhou
et al., 2022).
Similarly, LLMs gained attention for plan generation for robots due to the rich semantic knowledge they acquired about the world (Ahn et al., 2022; Huang et al., 2022; Zeng et al., 2022). However, LLMs are known to perform shallow reasoning and cannot find complex plans (Valmeekam et al., 2022).</p>
<p>In another context, Nye et al. (2021) note that while LLMs are good at System-1 thinking, their outputs are often inconsistent and incoherent. This is because LLMs are trained to predict subsequent words in a sequence and do not appear to have a deep understanding of concepts such as cause and effect, logic, and probability, which are important for reasoning.</p>
<p>Nevertheless, we note that the rich semantic knowledge that LLMs possess makes them effective general-purpose few-shot semantic parsers that can convert linguistically variable natural language sentences into atomic facts that serve as input to logic programs. We also note that the fully declarative nature of answer set programs (Lifschitz, 2008; Brewka et al., 2011) makes them a good pair with the LLM semantic parsers, providing interpretable and explainable reasoning on the parsed result of the LLMs using background knowledge. Combining large language models and answer set programs leads to an attractive dual-process, neuro-symbolic reasoning that works across multiple QA tasks without retraining for individual tasks.</p>
<p>We tested this idea with several NLP benchmarks, bAbI (Weston et al., 2016), StepGame (Shi et al., 2022), CLUTRR (Sinha et al., 2019), and gSCAN (Ruis et al., 2020), by applying the same dual-system model and achieved state-of-the-art performance in all of them. Furthermore, the high accuracy and transparency allow us to easily identify the source of errors, making our system a useful data set validation tool as well. In particular, we found a significant amount of errors in the original</p>
<p>CLUTRR dataset that are hard to detect manually.
While the new version of GPT-3 (Brown et al., 2020) (text-davinci-003) shows improvement over its predecessors, we observe that it also retains critical limitations. In the process, we develop prompt methods for semantic parsing to overcome some of them.</p>
<p>The implementation of our method is publicly available online at https://github.com/ azreasoners/LLM-ASP.</p>
<h2>2 Preliminaries</h2>
<h3>2.1 Semantic Parsing and LLMs</h3>
<p>Semantic parsing involves converting a natural language query or statement into a structured representation that a computer can understand and manipulate. Statistical methods have increased in popularity (Zelle and Mooney, 1996; Miller et al., 1996; Zettlemoyer and Collins, 2005; Wong and Mooney, 2007), and encoder-decoder models in particular have been widely used (Dong and Lapata, 2016; Jia and Liang, 2016; Kočiskỳ et al., 2016). However, these statistical methods require annotated input and output pairs. Furthermore, machine learning models often fail to compositionally generalize to unseen data (Lake and Baroni, 2018).</p>
<p>More recently, pre-trained language models have been applied to semantic parsing tasks (Liu et al., 2021), such as generating SQL queries, SPARQL queries, logical forms, or programs, from natural language, together with fine-tuning or prompttuning on pre-trained models, such as BART, RoBERTa and GPT-2 (Chen et al., 2020a; Shin et al., 2021; Schucher et al., 2022). With larger pre-trained networks, such as GPT-3, prompting appears to yield a reasonable semantic parser without the need for fine-tuning (Shin et al., 2021; Drozdov et al., 2022).</p>
<p>Another line of related work is to apply pretrained language models to relation extraction, the task of extracting semantic relationships from a text given two or more entities (Liu et al., 2021). Wang et al. (2022) do zero-shot relation extraction with pre-trained language models from the BERT family and GPT-2 variants. Zhou and Chen (2022) finetune BERT and RoBERTa models for the extraction of sentence-level relations. Chen et al. (2022) apply prompt-tuning to RoBERT_LARGE for relation extraction. Similar to ours, Agrawal et al. (2022) use a few-shot prompt with GPT-3 for the extraction of clinical relations.</p>
<h3>2.2 Dual-System Model</h3>
<p>There is increasing interest in combining neural and symbolic systems (Marcus, 2018; Lamb et al., 2020; Sarker et al., 2021). Such dual-system models achieved new state-of-the-art results in visual question answering (Goldman et al., 2018; Sampat and Lee, 2018; Yi et al., 2019; Chen et al., 2020b; Ding et al., 2021). In the case of textual problems, to improve LLMs to generate more consistent and coherent sentences, Nye et al. (2021) suggest that generation be decomposed into two parts: candidate sentence generation by an LLM (system 1 thinking) and a logical pruning process (system 2 thinking) implemented via a separate symbolic module. They demonstrate that this neurosymbolic, dual-process model requires less training data, achieves higher accuracy, and exhibits better generalization. However, the main limitation of their work is that the symbolic module is manually constructed in Python code for the specific task at hand, requiring subtantial efforts. Additionally, their Python symbolic module is not readily reusable or composable. Furthermore, their main results primarily focus on the problem of consistent text generation, rather than evaluating the method on the datasets and comparing it with existing models. This is because writing the world models in Python is not a scalable approach.</p>
<p>In our work, we follow the idea presented in (Nye et al., 2021) but adopt logic programming in place of the System 2 process. We argue that this combination is much more appealing than the approach in (Nye et al., 2021), as it can achieve the promised results without the limitations mentioned above.</p>
<h3>2.3 Answer Set Programming</h3>
<p>Answer Set Programming (ASP) (Lifschitz, 2008; Brewka et al., 2011) is a declarative logic programming paradigm that has been shown to be effective in knowledge-intensive applications. It is based on the stable model (a.k.a. answer set) semantics of logic programs (Gelfond and Lifschitz, 1988), which could express causal reasoning, default reasoning, aggregates, and various other constraints. There are several efficient solvers, such as CLINGO, DLV, and WASP. We use CLINGO v5.6.0 as the answer set solver. For the language of CLINGO, we refer the reader to the textbook (Lifschitz, 2019) or</p>
<p>the CLINGO manual. ${ }^{1}$
It is also known that classical logic-based action formalisms, such as the situation calculus (McCarthy and Hayes, 1969; Reiter, 2001) and the event calculus (Shanahan, 1995), can be formulated as answer set programs. For example, the following is one of the axioms in Discrete Event Calculus stating the commonsense law of inertia, saying that fluent $F$ holds at the next time if there is no action affecting it.</p>
<div class="codehilite"><pre><span></span><code><span class="c1">% (DEC5)</span>
<span class="nf">holds_at</span><span class="p">(</span><span class="nv">F</span><span class="p">,</span><span class="nv">T</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">:-</span> <span class="nf">timepoint</span><span class="p">(</span><span class="nv">T</span><span class="p">),</span> <span class="nf">fluent</span><span class="p">(</span><span class="nv">F</span><span class="p">),</span>
    <span class="nf">holds_at</span><span class="p">(</span><span class="nv">F</span><span class="p">,</span><span class="nv">T</span><span class="p">),</span> <span class="o">-</span><span class="nf">released_at</span><span class="p">(</span><span class="nv">F</span><span class="p">,</span><span class="nv">T</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span>
    <span class="o">not</span> <span class="nf">terminated</span><span class="p">(</span><span class="nv">F</span><span class="p">,</span><span class="nv">T</span><span class="p">).</span>
</code></pre></div>

<p>Such a rule is universal and applies to almost all objects.</p>
<p>Answer set programs are also known to be elaboration tolerant (McCarthy, 1998). There has been work on modularizing knowledge bases in ASP, such as module theorem (Oikarinen and Janhunen, 2006; Babb and Lee, 2012) and knowledge modules (Baral et al., 2006). While ASP has been widely applied to many reasoning problems, it has not been considered as much in reasoning with natural language text because its input is expected to be strictly in a logical form, giving little flexibility in accepting diverse forms of natural language input.</p>
<h2>3 Our Method</h2>
<p>We refer to our framework as [LLM]+ASP where [LLM] denotes a large pre-trained network such as GPT-3, which we use as a semantic parser to generate input to the ASP reasoner. Specifically, we assume data instances of the form $\langle S, q, a\rangle$, where $S$ is a context story in natural language, $q$ is a natural language query associated with $S$, and $a$ is the answer. We use an LLM to convert a problem description (that is, context $S$ and query $q$ ) into atomic facts, which are then fed into the ASP solver along with background knowledge encoded as ASP rules. The output of the ASP solver is interpreted as the prediction for the given data instance. Figure 1 illustrates the inference flow in the context of StepGame. The pipeline is simple but general enough to bke applied to various tasks without the need for retraining. It only requires replacing the few-shot prompts to the LLM and the ASP background knowledge with those suitable for the new</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup>tasks.
By combining LLMs and ASP in this manner, we enable robust symbolic reasoning that can handle diverse and unprocessed textual input. The ASP knowledge modules remain unaffected by the diverse forms of input text that express the same facts. Our method does not rely on training datasets. Instead, a few examples that turn natural language sentences into atomic facts are sufficient to build a semantic parser due to the learned representations in LLMs. Furthermore, ASP knowledge modules can be reused for different tasks.</p>
<h3>3.1 Prompts for Fact Extraction</h3>
<p>We use GPT-3 to extract atomic facts from the story and query. Most of the time, giving several examples yields accurate semantic parsing. The following is an example prompt for bAbI.</p>
<div class="codehilite"><pre><span></span><code><span class="n">Please</span><span class="w"> </span><span class="nf">parse</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">following</span><span class="w"> </span><span class="n">statements</span><span class="w"> </span><span class="k">into</span><span class="w"> </span><span class="n">facts</span>
<span class="w">    </span><span class="p">.</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="n">available</span><span class="w"> </span><span class="n">keywords</span><span class="w"> </span><span class="k">are</span><span class="err">:</span><span class="w"> </span><span class="n">pickup</span><span class="p">,</span><span class="w"> </span><span class="k">drop</span><span class="p">,</span>
<span class="w">    </span><span class="ow">and</span><span class="w"> </span><span class="k">go</span><span class="p">.</span>
<span class="nl">Sentence</span><span class="p">:</span><span class="w"> </span><span class="nf">Max</span><span class="w"> </span><span class="n">journeyed</span><span class="w"> </span><span class="k">to</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">bathroom</span><span class="p">.</span>
<span class="n">Semantic</span><span class="w"> </span><span class="nf">parse</span><span class="err">:</span><span class="w"> </span><span class="k">go</span><span class="p">(</span><span class="nf">Max</span><span class="p">,</span><span class="w"> </span><span class="n">bathroom</span><span class="p">).</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="n">Sentence</span><span class="o">:</span><span class="w"> </span><span class="n">Mary</span><span class="w"> </span><span class="n">grabbed</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">football</span><span class="w"> </span><span class="n">there</span><span class="o">.</span>
<span class="n">Semantic</span><span class="w"> </span><span class="n">parse</span><span class="o">:</span><span class="w"> </span><span class="n">pickup</span><span class="o">(</span><span class="n">Mary</span><span class="o">,</span><span class="w"> </span><span class="n">football</span><span class="o">).</span>
</code></pre></div>

<p>We find that GPT-3 is highly tolerable to linguistic variability. For example, in StepGame, GPT-3 can turn various sentences below into the same atomic fact top_right ("C", "D").</p>
<div class="codehilite"><pre><span></span><code>C is to the top right of D.
C is to the right and above D at an angle of
    about 45 degrees.
C is at a 45 degree angle to D, in the upper
    righthand corner.
C is directly north east of D.
C is above D at 2 o&#39;clock.
</code></pre></div>

<p>In the experiments to follow, we find that the following strategy works well for fact extraction.</p>
<ol>
<li>In general, we find that if the information in a story (or query) can be extracted independently, parsing each sentence separately (using the same prompt multiple times) typically works better than parsing the whole story.</li>
<li>There is certain commonsense knowledge that GPT-3 is not able to leverage from the examples in the prompt. In this case, detailing the missing knowledge in the prompt could work. For example, in StepGame, clock numbers are used to denote cardinal directions, but GPT-3 couldn't translate correctly even with a few</li>
</ol>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: The GPT-3+ASP pipeline for the StepGame dataset.</p>
<p>examples in the prompt. It works after enumerating all cases ("12 denotes top, 1 and 2 denote top_right, 3 denotes right, . . .") in the prompt.</p>
<ol>
<li>Semantic parsing tends to work better if we instruct GPT-3 to use a predicate name that better reflects the intended meaning of the sentence. For example, "A is there and B is at the 5 position of a clock face" is better to be turned into down_right (B, A) than top_left (A, B) although, logically speaking, the relations are symmetric.</li>
</ol>
<p>The complete set of prompts for semantic parsing is given in Appendix C.</p>
<h3>3.2 Knowledge Modules</h3>
<p>Instead of constructing a minimal world model for each task in Python code (Nye et al., 2021), we use ASP knowledge modules. While some knowledge could be lengthy to be described in English, it could be concisely expressed in ASP. For example, the <strong>location</strong> module contains rules for spatial reasoning in a 2D grid space and is used for bAbI, StepGame, and gSCAN. Below is the main rule in the <strong>location</strong> module that computes the location (Xa, Ya) of object A from the location (Xb, Yb) of object B by adding the offsets (Dx, Dy) defined by the spatial relation R between A and B.</p>
<div class="codehilite"><pre><span></span><code><span class="nf">location</span><span class="p">(</span><span class="nv">A</span><span class="p">,</span> <span class="nv">Xa</span><span class="p">,</span> <span class="nv">Ya</span><span class="p">)</span> <span class="o">:-</span> <span class="nf">location</span><span class="p">(</span><span class="nv">B</span><span class="p">,</span> <span class="nv">Xb</span><span class="p">,</span> <span class="nv">Yb</span><span class="p">),</span>
    <span class="o">is</span><span class="p">(</span><span class="nv">A</span><span class="p">,</span> <span class="nv">R</span><span class="p">,</span> <span class="nv">B</span><span class="p">),</span> <span class="nf">offset</span><span class="p">(</span><span class="nv">R</span><span class="p">,</span> <span class="nv">Dx</span><span class="p">,</span> <span class="nv">Dy</span><span class="p">),</span>
    <span class="nv">Xa</span><span class="o">=</span><span class="nv">Xb</span><span class="o">+</span><span class="nv">Dx</span><span class="p">,</span> <span class="nv">Ya</span><span class="o">=</span><span class="nv">Yb</span><span class="o">+</span><span class="nv">Dy</span><span class="p">.</span>
</code></pre></div>

<p>The <strong>location</strong> module also includes 9 predefined offsets, e.g., offset(left, -1, 0), that can be used to model multi-hop spatial relations of objects or effects of a robot's moving in a 2D space. For example, queries in StepGame are about the spatial relation R of object A to B. Using the <strong>location</strong> module, one can fix B's location to be (0, 0) and compute the spatial relation R based on the location of A as follows.</p>
<div class="codehilite"><pre><span></span><code><span class="nf">location</span><span class="p">(</span><span class="nv">B</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">:-</span> <span class="nf">query</span><span class="p">(</span><span class="nv">A</span><span class="p">,</span> <span class="nv">B</span><span class="p">).</span>
<span class="nf">answer</span><span class="p">(</span><span class="nv">R</span><span class="p">)</span> <span class="o">:-</span> <span class="nf">query</span><span class="p">(</span><span class="nv">A</span><span class="p">,</span> <span class="nv">B</span><span class="p">),</span> <span class="nf">location</span><span class="p">(</span><span class="nv">A</span><span class="p">,</span> <span class="nv">X</span><span class="p">,</span> <span class="nv">Y</span><span class="p">),</span>
    <span class="nf">offset</span><span class="p">(</span><span class="nv">R</span><span class="p">,</span> <span class="nv">Dx</span><span class="p">,</span> <span class="nv">Dy</span><span class="p">),</span>
    <span class="nv">Dx</span><span class="s s-Atom">=-</span><span class="mi">1</span><span class="o">:</span> <span class="nv">X</span><span class="o">&lt;</span><span class="mi">0</span><span class="p">;</span> <span class="nv">Dx</span><span class="o">=</span><span class="mi">0</span><span class="o">:</span> <span class="nv">X</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="nv">Dx</span><span class="o">=</span><span class="mi">1</span><span class="o">:</span> <span class="nv">X</span><span class="o">&gt;</span><span class="mi">0</span><span class="p">;</span>
    <span class="nv">Dy</span><span class="s s-Atom">=-</span><span class="mi">1</span><span class="o">:</span> <span class="nv">Y</span><span class="o">&lt;</span><span class="mi">0</span><span class="p">;</span> <span class="nv">Dy</span><span class="o">=</span><span class="mi">0</span><span class="o">:</span> <span class="nv">Y</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="nv">Dy</span><span class="o">=</span><span class="mi">1</span><span class="o">:</span> <span class="nv">Y</span><span class="o">&gt;</span><span class="mf">0.</span>
</code></pre></div>

<p>The second rule above contains six <em>conditional literals</em> among which Dx=-1: X&lt;0 says that "Dx must be -1 if X&lt;0." For example, if A's location (X, Y) is (-3, 0), then (Dx, Dy) is (-1, 0) and the answer R is left. Similar rules can also be applied to bAbI task 17, which asks if A is R of B.</p>
<p>In the above rules, the relation R in, e.g., is (A, R, B), is a variable and can be substituted by any binary relation. Such high-order representation turns out to be quite general and applicable to many tasks that query relation or its arguments.</p>
<table>
<thead>
<tr>
<th>StepGame</th>
<th>bAbI</th>
<th>gSCAN</th>
<th>Pick&amp;Place</th>
<th>CLUTRR</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td>location</td>
<td>action</td>
<td>OKC</td>
<td>family</td>
<td></td>
</tr>
</tbody>
</table>
<p>Figure 2: The knowledge modules at the bottom are used in each task on the top.</p>
<p>Figure 2 shows the knowledge modules used in this paper, where DEC denotes the Discrete Event Calculus axioms from <em>Mueller (2006); Lee and Palla (2012)</em>. In this section, we explained the main rules in the location module. The complete ASP knowledge modules are given in Appendix E.</p>
<h2>4 Experiments</h2>
<p>We apply the method in the previous section to four datasets. As a reminder, our approach involves few-shot in-context learning and does not require training. We use the same pipeline as shown in Figure 1, but with different prompts and knowledge modules for each dataset. For more detailed information about the experimental settings, please refer to the appendix.</p>
<h3>4.1 bAbI</h3>
<p>The bAbI dataset <em>Weston et al. (2016)</em> is a collection of 20 QA tasks that have been widely applied to test various natural language reasoning problems, such as deduction, path-finding, spatial reasoning, and counting. State-of-the-art models, such as self-attentive associative-based two-memory model (STM) <em>Le et al. (2020)</em> and Query-Reduction networks (QRN) <em>Seo et al. (2017)</em> achieve close to 100% accuracy after training with 10k instances while QRN’s accuracy drops to 90% with 1k training instances.</p>
<p>We first designed two GPT-3 baselines, one with few shot prompts (containing a few example questions and answers) and the other with Chain-of-Thought (CoT) prompts <em>Wei et al. (2022)</em>, which state the relevant information to derive the answer.</p>
<p>We also apply GPT-3+ASP. For example, we use GPT-3 to turn “the kitchen is south of the bathroom” into an atomic fact is (kitchen, southOf, bathroom) by giving a few examples of the same kind. Regarding knowledge modules, Tasks 1–3, 6–9, 10–14, and 19 are about events over time and use the DEC knowledge module. Tasks 4, 17, and 19 require various domain knowledge modules such as location and action knowledge modules. The remaining tasks do not require domain knowledge and rely only on simple rules to extract answers from parsed facts.</p>
<p>Table 1 compares our method with the two GPT-3 baselines, as well as two state-of-the-art methods on bAbI datasets, STM and QRN. Interestingly, the new GPT-3, text-davinci-003 (denoted GPT-3 (d3)), with basic few-shot prompting achieves 80.34% accuracy, while CoT improves it to 86.18%. GPT-3(d3)+ASP achieves state-of-the-art performance on bAbI with 99.99% average performance among all tasks, producing only two answers that disagree with the labels in the dataset. It turns out that the two questions are malformed since the answers are ambiguous, and our model’s answers can be considered correct.</p>
<h3>4.2 StepGame</h3>
<p>Although bAbI has been extensively tested, it has several problems. <em>Shi et al. (2022)</em> note data leakage between the train and the test sets where named entities are fixed and only a small number of relations are used. <em>Palm et al. (2018)</em> point out that models do not need multi-hop reasoning to solve the bAbI dataset. To address the issues, <em>Shi et al. (2022)</em> propose the StepGame dataset. It is a contextual QA dataset in which the system is required to interpret a story $S$ about spatial relationships among several entities and answers a query $q$ about the relative position of two of those entities, as illustrated in Figure 1. Unlike the bAbI dataset, StepGame uses a large number of named entities, and requires multi-hop reasoning up to as many as 10 reasoning steps.</p>
<p>In the basic form of the StepGame dataset, each story consists of $k$ sentences that describe $k$ spatial relationships between $k+1$ entities in a chain-like shape. In this paper, we evaluate the StepGame dataset with noise, where the original chain is extended with noise statements by branching out with new entities and relations.</p>
<p>Similarly to bAbI, we designed two GPT-3 baselines and applied our method to the StepGame data set. More details on the prompts are available in Appendix C.2.</p>
<p>For each $k \in{1, \ldots, 10}$, the StepGame dataset with noise consists of 30,000 training samples, 1000 validation samples, and 10,000 test samples. To save the API cost for GPT-3, we only evaluated the two GPT-3 baselines on the first 100 test samples and evaluated our method on the first 1,000 test samples for each $k \in{1, \ldots, 10}$. Table 2 compares the accuracy of our method with the two baselines of GPT-3 and the current methods, i.e. RN <em>Santoro et al. (2017)</em>, RRN <em>Palm et al. (2018)</em>, UT <em>Dehghani et al. (2018)</em>, STM <em>Le et al. (2020)</em>,</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<table>
<thead>
<tr>
<th>Task</th>
<th>GPT-3(d3)</th>
<th>GPT-3(d3)</th>
<th>GPT-3(d3)</th>
<th>STM(Le et al., 2020)</th>
<th>QRN(Seo et al., 2017)</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Few-Shot</td>
<td>CoT</td>
<td>+ASP</td>
<td>(10k train)</td>
<td>(10k train) (1k train)</td>
</tr>
<tr>
<td>1: Single supporting fact</td>
<td>98.4</td>
<td>97.3</td>
<td>100.0</td>
<td>$100.0 \pm 0.0$</td>
<td>100.0 100.0</td>
</tr>
<tr>
<td>2: Two supporting facts</td>
<td>60.8</td>
<td>72.2</td>
<td>100.0</td>
<td>$99.79 \pm 0.23$</td>
<td>100.0 99.3</td>
</tr>
<tr>
<td>3: Three supporting facts</td>
<td>39.6</td>
<td>54.1</td>
<td>100.0</td>
<td>$97.87 \pm 1.14$</td>
<td>100.0 94.3</td>
</tr>
<tr>
<td>4: Two arg relations</td>
<td>60.4</td>
<td>72.7</td>
<td>100.0</td>
<td>$100.0 \pm 0.0$</td>
<td>100.0 100.0</td>
</tr>
<tr>
<td>5: Three arg relations</td>
<td>88.2</td>
<td>89.1</td>
<td>99.8</td>
<td>$99.43 \pm 0.18$</td>
<td>100.0 98.9</td>
</tr>
<tr>
<td>6: Yes/no questions</td>
<td>97.4</td>
<td>97.3</td>
<td>100.0</td>
<td>$100.0 \pm 0.0$</td>
<td>100.0 99.1</td>
</tr>
<tr>
<td>7: Counting</td>
<td>90.6</td>
<td>88.6</td>
<td>100.0</td>
<td>$99.19 \pm 0.27$</td>
<td>100.0 90.4</td>
</tr>
<tr>
<td>8: Lists/sets</td>
<td>96.2</td>
<td>97.1</td>
<td>100.0</td>
<td>$99.88 \pm 0.07$</td>
<td>99.6 94.4</td>
</tr>
<tr>
<td>9 : Simple negation</td>
<td>98.4</td>
<td>98.2</td>
<td>100.0</td>
<td>$100.0 \pm 0.0$</td>
<td>100.0 100.0</td>
</tr>
<tr>
<td>10: Indefinite knowledge</td>
<td>93.6</td>
<td>92.4</td>
<td>100.0</td>
<td>$99.97 \pm 0.06$</td>
<td>100.0 100.0</td>
</tr>
<tr>
<td>11: Basic coreference</td>
<td>93.6</td>
<td>99.2</td>
<td>100.0</td>
<td>$99.99 \pm 0.03$</td>
<td>100.0 100.0</td>
</tr>
<tr>
<td>12: Conjunction</td>
<td>88.6</td>
<td>88.8</td>
<td>100.0</td>
<td>$99.96 \pm 0.05$</td>
<td>100.0 100.0</td>
</tr>
<tr>
<td>13: Compound coreference</td>
<td>98.4</td>
<td>97.3</td>
<td>100.0</td>
<td>$99.99 \pm 0.03$</td>
<td>100.0 100.0</td>
</tr>
<tr>
<td>14: Time reasoning</td>
<td>78.0</td>
<td>91.5</td>
<td>100.0</td>
<td>$99.84 \pm 0.17$</td>
<td>99.9 99.2</td>
</tr>
<tr>
<td>15: Basic deduction</td>
<td>57.0</td>
<td>95.0</td>
<td>100.0</td>
<td>$100.0 \pm 0.0$</td>
<td>100.0 100.0</td>
</tr>
<tr>
<td>16: Basic induction</td>
<td>90.8</td>
<td>97.5</td>
<td>100.0</td>
<td>$99.71 \pm 0.15$</td>
<td>100.0 47.0</td>
</tr>
<tr>
<td>17: Positional reasoning</td>
<td>66.0</td>
<td>70.8</td>
<td>100.0</td>
<td>$98.82 \pm 1.07$</td>
<td>95.9 65.6</td>
</tr>
<tr>
<td>18: Size reasoning</td>
<td>89.8</td>
<td>97.1</td>
<td>100.0</td>
<td>$99.73 \pm 0.28$</td>
<td>99.3 92.1</td>
</tr>
<tr>
<td>19: Path finding</td>
<td>21.0</td>
<td>28.7</td>
<td>100.0</td>
<td>$97.94 \pm 2.79$</td>
<td>99.9 21.3</td>
</tr>
<tr>
<td>20: Agents motivations</td>
<td>100.0</td>
<td>100.0</td>
<td>100.0</td>
<td>$100.0 \pm 0.0$</td>
<td>100.0 99.8</td>
</tr>
<tr>
<td>Average</td>
<td>80.34</td>
<td>86.18</td>
<td>99.99</td>
<td>99.85</td>
<td>99.70 90.1</td>
</tr>
</tbody>
</table>
<p>Table 1: Test accuracy on 20 tasks in bAbI data</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Method</th>
<th style="text-align: left;">$\mathrm{k}=1$</th>
<th style="text-align: left;">$\mathrm{k}=2$</th>
<th style="text-align: left;">$\mathrm{k}=3$</th>
<th style="text-align: left;">$\mathrm{k}=4$</th>
<th style="text-align: left;">$\mathrm{k}=5$</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">RN</td>
<td style="text-align: left;">22.6</td>
<td style="text-align: left;">17.1</td>
<td style="text-align: left;">15.1</td>
<td style="text-align: left;">12.8</td>
<td style="text-align: left;">11.5</td>
</tr>
<tr>
<td style="text-align: left;">RRN</td>
<td style="text-align: left;">24.1</td>
<td style="text-align: left;">20.0</td>
<td style="text-align: left;">16.0</td>
<td style="text-align: left;">13.2</td>
<td style="text-align: left;">12.3</td>
</tr>
<tr>
<td style="text-align: left;">UT</td>
<td style="text-align: left;">45.1</td>
<td style="text-align: left;">28.4</td>
<td style="text-align: left;">17.4</td>
<td style="text-align: left;">14.1</td>
<td style="text-align: left;">13.5</td>
</tr>
<tr>
<td style="text-align: left;">STM</td>
<td style="text-align: left;">53.4</td>
<td style="text-align: left;">36.0</td>
<td style="text-align: left;">23.0</td>
<td style="text-align: left;">18.5</td>
<td style="text-align: left;">15.1</td>
</tr>
<tr>
<td style="text-align: left;">TPR-RNN</td>
<td style="text-align: left;">70.3</td>
<td style="text-align: left;">46.0</td>
<td style="text-align: left;">36.1</td>
<td style="text-align: left;">26.8</td>
<td style="text-align: left;">24.8</td>
</tr>
<tr>
<td style="text-align: left;">TP-MANN</td>
<td style="text-align: left;">85.8</td>
<td style="text-align: left;">60.3</td>
<td style="text-align: left;">50.2</td>
<td style="text-align: left;">37.5</td>
<td style="text-align: left;">31.3</td>
</tr>
<tr>
<td style="text-align: left;">SynSup</td>
<td style="text-align: left;">$\mathbf{9 8 . 6}$</td>
<td style="text-align: left;">$\mathbf{9 5 . 0}$</td>
<td style="text-align: left;">$\mathbf{9 2 . 0}$</td>
<td style="text-align: left;">79.1</td>
<td style="text-align: left;">70.3</td>
</tr>
<tr>
<td style="text-align: left;">Few-Shot (d3)</td>
<td style="text-align: left;">55.0</td>
<td style="text-align: left;">37.0</td>
<td style="text-align: left;">25.0</td>
<td style="text-align: left;">30.0</td>
<td style="text-align: left;">32.0</td>
</tr>
<tr>
<td style="text-align: left;">CoT (d3)</td>
<td style="text-align: left;">61.0</td>
<td style="text-align: left;">45.0</td>
<td style="text-align: left;">30.0</td>
<td style="text-align: left;">35.0</td>
<td style="text-align: left;">35.0</td>
</tr>
<tr>
<td style="text-align: left;">GPT-3(c1)+ASP</td>
<td style="text-align: left;">44.7</td>
<td style="text-align: left;">38.8</td>
<td style="text-align: left;">40.5</td>
<td style="text-align: left;">58.8</td>
<td style="text-align: left;">62.4</td>
</tr>
<tr>
<td style="text-align: left;">GPT-3(d2)+ASP</td>
<td style="text-align: left;">92.6</td>
<td style="text-align: left;">89.9</td>
<td style="text-align: left;">89.1</td>
<td style="text-align: left;">$\mathbf{9 3 . 8}$</td>
<td style="text-align: left;">$\mathbf{9 2 . 9}$</td>
</tr>
<tr>
<td style="text-align: left;">Method</td>
<td style="text-align: left;">$\mathrm{k}=6$</td>
<td style="text-align: left;">$\mathrm{k}=7$</td>
<td style="text-align: left;">$\mathrm{k}=8$</td>
<td style="text-align: left;">$\mathrm{k}=9$</td>
<td style="text-align: left;">$\mathrm{k}=10$</td>
</tr>
<tr>
<td style="text-align: left;">RN</td>
<td style="text-align: left;">11.1</td>
<td style="text-align: left;">11.5</td>
<td style="text-align: left;">11.2</td>
<td style="text-align: left;">11.1</td>
<td style="text-align: left;">11.3</td>
</tr>
<tr>
<td style="text-align: left;">RRN</td>
<td style="text-align: left;">11.6</td>
<td style="text-align: left;">11.4</td>
<td style="text-align: left;">11.8</td>
<td style="text-align: left;">11.2</td>
<td style="text-align: left;">11.7</td>
</tr>
<tr>
<td style="text-align: left;">UT</td>
<td style="text-align: left;">12.7</td>
<td style="text-align: left;">12.1</td>
<td style="text-align: left;">11.4</td>
<td style="text-align: left;">11.4</td>
<td style="text-align: left;">11.7</td>
</tr>
<tr>
<td style="text-align: left;">STM</td>
<td style="text-align: left;">13.8</td>
<td style="text-align: left;">12.6</td>
<td style="text-align: left;">11.5</td>
<td style="text-align: left;">11.3</td>
<td style="text-align: left;">11.8</td>
</tr>
<tr>
<td style="text-align: left;">TPR-RNN</td>
<td style="text-align: left;">22.3</td>
<td style="text-align: left;">19.9</td>
<td style="text-align: left;">15.5</td>
<td style="text-align: left;">13.0</td>
<td style="text-align: left;">12.7</td>
</tr>
<tr>
<td style="text-align: left;">TP-MANN</td>
<td style="text-align: left;">28.5</td>
<td style="text-align: left;">26.5</td>
<td style="text-align: left;">23.7</td>
<td style="text-align: left;">22.5</td>
<td style="text-align: left;">21.5</td>
</tr>
<tr>
<td style="text-align: left;">SynSup</td>
<td style="text-align: left;">63.4</td>
<td style="text-align: left;">58.7</td>
<td style="text-align: left;">52.1</td>
<td style="text-align: left;">48.4</td>
<td style="text-align: left;">45.7</td>
</tr>
<tr>
<td style="text-align: left;">Few-Shot (d3)</td>
<td style="text-align: left;">29.0</td>
<td style="text-align: left;">21.0</td>
<td style="text-align: left;">22.0</td>
<td style="text-align: left;">34.0</td>
<td style="text-align: left;">31.0</td>
</tr>
<tr>
<td style="text-align: left;">CoT (d3)</td>
<td style="text-align: left;">27.0</td>
<td style="text-align: left;">22.0</td>
<td style="text-align: left;">24.0</td>
<td style="text-align: left;">23.0</td>
<td style="text-align: left;">25.0</td>
</tr>
<tr>
<td style="text-align: left;">GPT-3(c1)+ASP</td>
<td style="text-align: left;">57.4</td>
<td style="text-align: left;">56.2</td>
<td style="text-align: left;">58.0</td>
<td style="text-align: left;">56.5</td>
<td style="text-align: left;">54.1</td>
</tr>
<tr>
<td style="text-align: left;">GPT-3(d2)+ASP</td>
<td style="text-align: left;">$\mathbf{9 1 . 6}$</td>
<td style="text-align: left;">$\mathbf{9 1 . 2}$</td>
<td style="text-align: left;">$\mathbf{9 0 . 4}$</td>
<td style="text-align: left;">$\mathbf{8 9 . 0}$</td>
<td style="text-align: left;">$\mathbf{8 8 . 3}$</td>
</tr>
</tbody>
</table>
<p>Table 2: Test accuracy on the StepGame test dataset, where (c1), (d2), and (d3) denote text-curie-001, text-davinci-002, and text-davinci-003 models, respectively</p>
<p>TPR-RNN (Schlag and Schmidhuber, 2018), TPMANN (Shi et al., 2022), and SynSup (with pretraining on the SPARTUN dataset) (Mirzaee and Kordjamshidi, 2022). Surprisingly, the GPT-3 baselines could achieve accuracy comparable to other
models (except for SynSup) for large $k$ values. CoT does not always help and decreases the accuracy with big $k$ s. This may be because there is a higher chance of making a mistake in a long chain of thought. GPT-3(d2)+ASP outperforms all state-of-the-art methods and the GPT-3 baselines by a large margin for $k=4, \ldots, 10$. Although SynSup achieves a higher accuracy for $k=1,2,3$, this is misleading due to errors in the dataset. As we analyze below, about $10.7 \%$ labels in the data are wrong. The SynSup training makes the model learn to make the same mistakes over the test dataset, which is why its performance looks better than ours.</p>
<p>The modular design of GPT-3+ASP enables us to analyze the reasons behind its wrong predictions. We collected the first 100 data instances for each $k \in{1, \ldots, 10}$ and manually analyzed the predictions on them. Among 1000 predictions of GPT-3(d2)+ASP, 108 of them disagree with the dataset labels, and we found that 107 of those have errors in the labels. For example, given the story and question " $J$ and $Y$ are horizontal and $J$ is to the right of $Y$. What is the relation of the agent $Y$ with the agent $J$ ?", the label in the dataset is "right" while the correct relation should be "left". ${ }^{4}$ Recall</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>that our method is interpretable, so we could easily identify the source of errors.</p>
<h3>4.3 CLUTRR</h3>
<p>CLUTRR <em>Sinha et al. (2019)</em> is a contextual QA dataset that requires inferring family relationships from a story. Sentences in CLUTRR are generated using 6k template narratives written by Amazon Mechanical Turk crowd-workers, and thus are more realistic and complex compared to those in bAbI and StepGame.</p>
<p>CLUTRR consists of two subtasks, systematic generalization that evaluates stories containing unseen combinations of logical rules <em>Minervini et al. (2020); Bergen et al. (2021)</em> and robust reasoning that evaluates stories with noisy descriptions <em>Tian et al. (2021)</em>. Since we use ASP for logical reasoning, which easily works for any combination of logical rules, we focus on the robust reasoning task.</p>
<table>
<thead>
<tr>
<th>Method</th>
<th>CLU.</th>
<th>clean</th>
<th>supp.</th>
<th>irre.</th>
<th>disc.</th>
</tr>
</thead>
<tbody>
<tr>
<td>RN</td>
<td>1.0</td>
<td>49</td>
<td>68</td>
<td>50</td>
<td>45</td>
</tr>
<tr>
<td>MAC</td>
<td>1.0</td>
<td>63</td>
<td>65</td>
<td>56</td>
<td>40</td>
</tr>
<tr>
<td>Bi-att</td>
<td>1.0</td>
<td>58</td>
<td>67</td>
<td>51</td>
<td>57</td>
</tr>
<tr>
<td>GSM</td>
<td>1.0</td>
<td>$\mathbf{6 8 . 5}$</td>
<td>48.6</td>
<td>62.9</td>
<td>52.8</td>
</tr>
<tr>
<td>GPT-3(d3)+ASP</td>
<td>1.0</td>
<td>$\mathbf{6 8 . 5}$</td>
<td>$\mathbf{8 2 . 8}$</td>
<td>$\mathbf{7 4 . 8}$</td>
<td>$\mathbf{6 7 . 4}$</td>
</tr>
<tr>
<td>GPT-3(d3)+ASP</td>
<td>1.3</td>
<td>97.0</td>
<td>84.0</td>
<td>92.0</td>
<td>90.0</td>
</tr>
</tbody>
</table>
<p>Table 3: Test accuracy on 4 categories in CLUTRR 1.0 and CLUTRR 1.3 datasets</p>
<p>Table 3 compares our method with RN <em>Santoro et al. (2017)</em>, MAC <em>Hudson and Manning (2018)</em>, BiLSTM-attention <em>Sinha et al. (2019)</em>, and GSM <em>Tian et al. (2021)</em> on the original CLUTRR dataset, namely CLUTRR 1.0, in four categories of data instances: clean, supporting, irrelevant, and disconnected <em>Sinha et al. (2019)</em>. Except for our method, all other models are trained on the corresponding category of CLUTRR training data. Although our method achieves similar or higher accuracies in all categories, they are still much lower than we expected.</p>
<p>We found that such low accuracy is due to the clear errors in CLUTRR, originating mostly from errors in the template narratives or the generated family graphs that violate common sense. The authors of CLUTRR recently published CLUTRR 1.3 codes to partially resolve this issue. With the new code, we created a new dataset, namely CLUTRR did not re-run the whole experiments with text-davinci-003. https://github.com/facebookresearch/clutrr/tree/develop 1.3, consisting of 400 data instances with 100 for each of the four categories. The last row in Table 3 shows that our method actually performs well on realistic sentences in CLUTRR. Indeed, with our method (using text-davinci-003) on CLUTRR 1.3 dataset, 363 out of 400 predictions are correct, 16 are still wrong due to data mistakes (e.g., the label says "Maryann has an uncle Bruno" while the noise sentence added to the story is "Maryann told her son Bruno to give the dog a bath"), and 21 are wrong due to GPT-3’s parsing mistakes (e.g., GPT-3 turned the sentence "Watt and Celestine asked their mother, if they could go play in the pool" into mother("Watt", "Celestine"). Since the sentences in CLUTRR 1.3 are more realistic than those in bAbI and StepGame, GPT-3 makes more mistakes even after reasonable efforts of prompt engineering. More details on data errors and GPT-3 errors are available in Appendix F.2 and Appendix D.</p>
<table>
<thead>
<tr>
<th>Method</th>
<th>clean</th>
<th>supp.</th>
<th>irre.</th>
<th>disc.</th>
</tr>
</thead>
<tbody>
<tr>
<td>DeepProbLog</td>
<td>100</td>
<td>100</td>
<td>100</td>
<td>94</td>
</tr>
<tr>
<td>GPT-3(d2)+ASP</td>
<td>100</td>
<td>100</td>
<td>97</td>
<td>97</td>
</tr>
<tr>
<td>GPT-3(d3)+ASP</td>
<td>100</td>
<td>100</td>
<td>100</td>
<td>100</td>
</tr>
</tbody>
</table>
<p>Table 4: Test accuracy on CLUTRR-S dataset We also evaluated our method on a simpler and cleaner variant of the CLUTRR data set, namely CLUTRR-S, that was used as a benchmark problem for a state-of-the-art neuro-symbolic approach DeepProbLog <em>Manhaeve et al. (2021)</em>. Table 4 compares the accuracy of our method and DeepProbLog in all 4 categories of test data. GPT-3(d3)+ASP achieves 100% accuracy, outperforming DeepProbLog without the need for training.</p>
<p>Remark: Due to the modular structure, our method could serve as a data set validation tool to detect errors in a dataset. We detected 107 wrong data instances in the first 1000 data in StepGame and 16 wrong data instances in the 400 data in CLUTRR 1.3.</p>
<h3>4.4 gSCAN</h3>
<p>The gSCAN dataset <em>Ruis et al. (2020)</em> poses a task in which an agent must execute action sequences to achieve a goal (specified by a command in a natural language sentence) in a grid-based visual navigation environment. The dataset consists of two tasks, and we evaluate our method on the data splits from the compositional generalization task. There is one shared training set, one test set (split</p>
<p>A) randomly sampled from the same distribution of the training set, and seven test sets (splits B to H) with only held-out data instances (i.e., not appearing in the training set) in different ways.</p>
<p>In the gSCAN dataset, each data instance is a tuple $\langle G, q, a\rangle$ where $G$ is the grid configuration (in JSON format) describing the size of the gird, the location and direction of the agent, and the location and features of each object in the grid; $q$ is a query (e.g., "pull a yellow small cylinder hesitantly"); and $a$ is the answer in the form of a sequence of actions (e.g., "turn right, walk, stay, pull, stay, pull, stay"). For each data instance, we (i) use a Python script to extract atomic facts (e.g., pos (agent, (2, 3))) from the grid configuration $G$; (ii) extract atomic facts from query $q$ into atomic facts (e.g., query(pull), queryDesc(yellow), while(hesitantly)) using GPT-3; and (iii) predict the sequence of actions for this query using ASP. The details of the prompts are given in Appendix C.4.</p>
<table>
<thead>
<tr>
<th>Method</th>
<th>A</th>
<th>B</th>
<th>C</th>
<th>D</th>
</tr>
</thead>
<tbody>
<tr>
<td>GECA</td>
<td>87.60</td>
<td>34.92</td>
<td>78.77</td>
<td>0.00</td>
</tr>
<tr>
<td>DualSys</td>
<td>74.7</td>
<td>81.3</td>
<td>78.1</td>
<td>0.01</td>
</tr>
<tr>
<td>Vilbert+CMA</td>
<td>99.95</td>
<td>99.90</td>
<td>99.25</td>
<td>0.00</td>
</tr>
<tr>
<td>GPT-3(c1)+ASP</td>
<td>98.30</td>
<td>100</td>
<td>100</td>
<td>100</td>
</tr>
<tr>
<td>GPT-3(d2)+ASP</td>
<td>100</td>
<td>100</td>
<td>100</td>
<td>100</td>
</tr>
<tr>
<td>Method</td>
<td>E</td>
<td>F</td>
<td>G</td>
<td>H</td>
</tr>
<tr>
<td>GECA</td>
<td>33.19</td>
<td>85.99</td>
<td>0.00</td>
<td>11.83</td>
</tr>
<tr>
<td>DualSys</td>
<td>53.6</td>
<td>76.2</td>
<td>0.0</td>
<td>21.8</td>
</tr>
<tr>
<td>Vilbert+CMA</td>
<td>99.02</td>
<td>99.98</td>
<td>0.00</td>
<td>22.16</td>
</tr>
<tr>
<td>GPT-3(c1)+ASP</td>
<td>100</td>
<td>100</td>
<td>100</td>
<td>100</td>
</tr>
<tr>
<td>GPT-3(d2)+ASP</td>
<td>100</td>
<td>100</td>
<td>100</td>
<td>100</td>
</tr>
</tbody>
</table>
<p>Table 5: Test accuracy on the gSCAN dataset Table 5 compares the accuracy of our method and the state-of-the-art methods, i.e., GECA (Ruis et al., 2020), DualSys (Nye et al., 2021) and Vil-bert+CMA (Qiu et al., 2021), on the gSCAN test dataset in eight splits. To save API cost for GPT- 3, we only evaluated the first 1000 data instances of each split. With text-davinci-002, our method GPT-3+ASP achieves 100\% accuracy. With text-curie-001, the accuracy is slightly lower, making 17 errors in split A. The errors are of two kinds. The language model fails to extract adverbs in the correct format for 11 data instances (e.g., GPT-3 responded queryDesc (while spinning) instead of while(spinning)) and didn't ground the last word in a query for 6 data instances (e.g., for query walk to a small square, GPT-</p>
<p>3 missed an atomic fact queryDesc (square)). Once the parsed results are correct, ASP does not make a mistake in producing plans.</p>
<h3>4.5 Findings</h3>
<p>The following summarizes the findings of the experimental evaluation.</p>
<ul>
<li>Our experiments confirm that LLMs like GPT3 are still not good at multi-step reasoning despite various prompts we tried. Chain-ofThought is less likely to improve accuracy when a long chain of thought is required.</li>
<li>On the other hand, LLMs are surprisingly good at turning a variety of expressions into a "canonical form" of information extraction. This in turn allows ASP knowledge modules to be isolated from linguistic variability in the input.</li>
<li>Even for generating simple atomic facts, larger models tend to perform better. For example, in StepGame and gSCAN, text-curie001 performs significantly worse compared to text-davinci-002 (Tables 2 and 5).</li>
<li>The total amount of knowledge that needs to be encoded for all of the above datasets is not too large. This is in part due to the fact that GPT-3 "normalized" various forms of input sentences for ASP to process and that knowledge modules could be reused across different datasets.</li>
<li>The modular design of our approach makes it possible to locate the root cause of each failed prediction in the training data and improve upon it. There are three sources of errors: semantic parsing in LLMs, symbolic constraints, and the dataset itself, and we can resolve the first two issues by improving the prompts and updating the constraints, respectively.</li>
<li>Our framework could serve as a few-shot dataset justifier and corrector. Among all predictions by our method that do not align with the labels, almost all of them (with only a few exceptions discussed in the paper) are due to errors in the dataset.</li>
</ul>
<h2>5 Conclusion</h2>
<p>Symbolic logic programming was previously considered limited in its ability to reason from text due</p>
<p>to its inability to handle various and ambiguous linguistic expressions. However, combining it with a large language model that has learned distributed representations helps alleviate this problem. The method not only achieves high accuracy but also produces interpretable results, as the source of the errors can be identified. It is also general; by using pre-trained networks with few-shot prompts and reusable knowledge modules, adapting to a new domain does not require extensive training.</p>
<p>The knowledge modules used in our experiments are reusable. For the above experiments, the modules are relatively simple to write, as are the prompts for parsing natural language for LLMs. However, acquiring this kind of knowledge on a massive scale is also an important line of research (Liu and Singh, 2004; Bosselut et al., 2019; Hwang et al., 2021) that needs to be combined. In addition, it is possible to use LLM's code generation capability (Chen et al., 2021) to generate logic program rules, which we leave for future work.</p>
<p>One may think that the logic rules are too rigid. However, there are many weighted or probabilistic rules that can be defeated (Richardson and Domingos, 2006; Fierens et al., 2013; Lee and Wang, 2018). They could be used for more realistic settings, but for the benchmark problems above, they were not needed.</p>
<h2>Ethical Considerations</h2>
<p>All datasets used in this paper are publicly available. For CLUTRR dataset, the gender information is essential to tell if, e.g., A is B's uncle or niece. We used GPT-3 to predict the genders of persons in each story. Since each story is systematically generated using sampled common first names and sampled sentence templates, it does not reveal any identity. As mentioned, the original CLUTRR dataset had some errors, and we describe carefully the codes and settings of the generated CLUTRR 1.3 dataset in Appendix B.1.</p>
<h2>Limitations</h2>
<p>The current work requires that knowledge modules be written by hand. Commonly used axioms, such as general knowledge like the commonsense law of inertia expressed by event calculus, can be reused easily, but there are vast amounts of other commonsense knowledge that are not easy to obtain. LLMs could be used to supply this information, but we have not tried. Knowledge graphs, such as Con-
ceptNet (Liu and Singh, 2004), COMET (Bosselut et al., 2019) and ATOMIC (Hwang et al., 2021), can be utilized to populate ASP rules. Like code models, we expect that LLMs could generate ASP code, which we leave for future work.</p>
<p>Also, when using large language models, despite various efforts, sometimes it is not understandable why they do not behave as expected.</p>
<h2>Acknowledgements</h2>
<p>This work was partially supported by the National Science Foundation under Grant IIS-2006747.</p>
<h2>References</h2>
<p>Monica Agrawal, Stefan Hegselmann, Hunter Lang, Yoon Kim, and David Sontag. 2022. Large language models are few-shot clinical information extractors. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, page 1998-2022. Association for Computational Linguistics.</p>
<p>Michael Ahn, Anthony Brohan, Yevgen Chebotar, Chelsea Finn, Karol Hausman, Alexander Herzog, Daniel Ho, Julian Ibarz, Alex Irpan, Eric Jang, Ryan Julian, et al. 2022. Do as I can, not as I say: Grounding language in robotic affordances. In 6th Annual Conference on Robot Learning.</p>
<p>Joseph Babb and Joohyung Lee. 2012. Module theorem for the general theory of stable models. Theory and Practice of Logic Programming, 12(4-5):719-735.</p>
<p>Chitta Baral, Juraj Dzifcak, and Hiro Takahashi. 2006. Macros, macro calls and use of ensembles in modular answer set programming. In International Conference on Logic Programming, pages 376-390. Springer.</p>
<p>Leon Bergen, Timothy O’Donnell, and Dzmitry Bahdanau. 2021. Systematic generalization with edge transformers. Advances in Neural Information Processing Systems, 34:1390-1402.</p>
<p>Antoine Bosselut, Hannah Rashkin, Maarten Sap, Chaitanya Malaviya, Asli Celikyilmaz, and Yejin Choi. 2019. Comet: Commonsense transformers for knowledge graph construction. In Association for Computational Linguistics (ACL).</p>
<p>Gerhard Brewka, Ilkka Niemelä, and Miroslaw Truszczynski. 2011. Answer set programming at a glance. Communications of the ACM, 54(12):92103.</p>
<p>Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners. Advances in neural information processing systems, 33:1877-1901.</p>
<p>Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et al. 2021. Evaluating large language models trained on code. arXiv preprint arXiv:2107.03374.</p>
<p>Xiang Chen, Ningyu Zhang, Xin Xie, Shumin Deng, Yunzhi Yao, Chuanqi Tan, Fei Huang, Luo Si, and Huajun Chen. 2022. Knowprompt: Knowledgeaware prompt-tuning with synergistic optimization for relation extraction. In Proceedings of the ACM Web Conference 2022, pages 2778-2788.</p>
<p>Xilun Chen, Asish Ghoshal, Yashar Mehdad, Luke Zettlemoyer, and Sonal Gupta. 2020a. Low-resource domain adaptation for compositional task-oriented semantic parsing. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 5090-5100.</p>
<p>Zhenfang Chen, Jiayuan Mao, Jiajun Wu, KwanYee Kenneth Wong, Joshua B Tenenbaum, and Chuang Gan. 2020b. Grounding physical concepts of objects and events through dynamic visual reasoning. In International Conference on Learning Representations.</p>
<p>Mostafa Dehghani, Stephan Gouws, Oriol Vinyals, Jakob Uszkoreit, and Lukasz Kaiser. 2018. Universal transformers. In International Conference on Learning Representations.</p>
<p>Mingyu Ding, Zhenfang Chen, Tao Du, Ping Luo, Josh Tenenbaum, and Chuang Gan. 2021. Dynamic visual reasoning by learning differentiable physics models from video and language. Advances in Neural Information Processing Systems, 34.</p>
<p>Li Dong and Mirella Lapata. 2016. Language to logical form with neural attention. In 54th Annual Meeting of the Association for Computational Linguistics, pages 33-43. Association for Computational Linguistics (ACL).</p>
<p>Andrew Drozdov, Nathanael Schärli, Ekin Akyürek, Nathan Scales, Xinying Song, Xinyun Chen, Olivier Bousquet, and Denny Zhou. 2022. Compositional semantic parsing with large language models. arXiv preprint arXiv:2209.15003.</p>
<p>Daan Fierens, Guy Van den Broeck, Joris Renkens, Dimitar Shterionov, Bernd Gutmann, Ingo Thon, Gerda Janssens, and Luc De Raedt. 2013. Inference and learning in probabilistic logic programs using weighted boolean formulas. Theory and Practice of Logic Programming, pages 1-44.</p>
<p>Michael Gelfond and Vladimir Lifschitz. 1988. The stable model semantics for logic programming. In Proceedings of International Logic Programming Conference and Symposium, pages 1070-1080. MIT Press.</p>
<p>Omer Goldman, Veronica Latcinnik, Ehud Nave, Amir Globerson, and Jonathan Berant. 2018. Weakly supervised semantic parsing with abstract examples. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1809-1819.</p>
<p>Wenlong Huang, Fei Xia, Ted Xiao, Harris Chan, Jacky Liang, Pete Florence, Andy Zeng, Jonathan Tompson, Igor Mordatch, Yevgen Chebotar, Pierre Sermanet, Tomas Jackson, Noah Brown, Linda Luu, Sergey Levine, Karol Hausman, and brian ichter. 2022. Inner monologue: Embodied reasoning through planning with language models. In 6th Annual Conference on Robot Learning.</p>
<p>Drew A Hudson and Christopher D Manning. 2018. Compositional attention networks for machine reasoning. In International Conference on Learning Representations.</p>
<p>Jena D Hwang, Chandra Bhagavatula, Ronan Le Bras, Jeff Da, Keisuke Sakaguchi, Antoine Bosselut, and Yejin Choi. 2021. (comet-) atomic 2020: On symbolic and neural commonsense knowledge graphs. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 35, pages 6384-6392.</p>
<p>Robin Jia and Percy Liang. 2016. Data recombination for neural semantic parsing. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages $12-22$.</p>
<p>Tomáš Kočiskỳ, Gábor Melis, Edward Grefenstette, Chris Dyer, Wang Ling, Phil Blunsom, and Karl Moritz Hermann. 2016. Semantic parsing with semi-supervised sequential autoencoders. In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 10781087.</p>
<p>Brenden Lake and Marco Baroni. 2018. Generalization without systematicity: On the compositional skills of sequence-to-sequence recurrent networks. In International conference on machine learning, pages 2873-2882. PMLR.</p>
<p>Luis C Lamb, Artur Garcez, Marco Gori, Marcelo Prates, Pedro Avelar, and Moshe Vardi. 2020. Graph neural networks meet neural-symbolic computing: A survey and perspective. In Proceedings of International Joint Conference on Artificial Intelligence (IJCAI), pages 4877-4884.</p>
<p>Hung Le, Truyen Tran, and Svetha Venkatesh. 2020. Self-attentive associative memory. In International Conference on Machine Learning, pages 5682-5691. PMLR.</p>
<p>Joohyung Lee and Ravi Palla. 2012. Reformulating the situation calculus and the event calculus in the general theory of stable models and in answer set programming. Journal of Artificial Inteligence Research (JAIR), 43:571-620.</p>
<p>Joohyung Lee and Yi Wang. 2018. Weight learning in a probabilistic extension of answer set programs. In Proceedings of International Conference on Principles of Knowledge Representation and Reasoning $(K R)$, pages $22-31$.</p>
<p>Vladimir Lifschitz. 2008. What is answer set programming? In Proceedings of the AAAI Conference on Artificial Intelligence, pages 1594-1597. MIT Press.</p>
<p>Vladimir Lifschitz. 2019. Answer set programming. Springer Heidelberg.</p>
<p>Hugo Liu and Push Singh. 2004. Conceptnet-a practical commonsense reasoning tool-kit. BT technology journal, 22(4):211-226.</p>
<p>Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, and Graham Neubig. 2021. Pretrain, prompt, and predict: A systematic survey of prompting methods in natural language processing. ACM Computing Surveys (CSUR).</p>
<p>Robin Manhaeve, Sebastijan Dumančić, Angelika Kimmig, Thomas Demeester, and Luc De Raedt. 2021. Neural probabilistic logic programming in deepproblog. Artificial Intelligence, 298:103504.</p>
<p>Gary Marcus. 2018. Deep learning: A critical appraisal. arXiv preprint arXiv:1801.00631.</p>
<p>John McCarthy. 1998. Elaboration tolerance. In Working Papers of the Fourth Symposium on Logical Formalizations of Commonsense Reasoning.</p>
<p>John McCarthy and Patrick Hayes. 1969. Some philosophical problems from the standpoint of artificial intelligence. In B. Meltzer and D. Michie, editors, Machine Intelligence, volume 4, pages 463-502. Edinburgh University Press, Edinburgh.</p>
<p>Scott Miller, David Stallard, Robert Bobrow, and Richard Schwartz. 1996. A fully statistical approach to natural language interfaces. In 34th Annual Meeting of the Association for Computational Linguistics, pages 55-61.</p>
<p>Pasquale Minervini, Sebastian Riedel, Pontus Stenetorp, Edward Grefenstette, and Tim Rocktäschel. 2020. Learning reasoning strategies in end-to-end differentiable proving. In International Conference on Machine Learning, pages 6938-6949. PMLR.</p>
<p>Roshanak Mirzaee and Parisa Kordjamshidi. 2022. Transfer learning with synthetic corpora for spatial role labeling and reasoning. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, page 6148-6165. Association for Computational Linguistics.</p>
<p>Erik Mueller. 2006. Commonsense reasoning. Elsevier.
Maxwell Nye, Michael Tessler, Josh Tenenbaum, and Brenden M Lake. 2021. Improving coherence and consistency in neural sequence models with dualsystem, neuro-symbolic reasoning. Advances in Neural Information Processing Systems, 34:2519225204.</p>
<p>Emilia Oikarinen and Tomi Janhunen. 2006. Modular equivalence for normal logic programs. In 17th European Conference on Artificial Intelligence(ECAI), pages 412-416.</p>
<p>Rasmus Palm, Ulrich Paquet, and Ole Winther. 2018. Recurrent relational networks. In Proceedings of Advances in Neural Information Processing Systems, pages 3368-3378.</p>
<p>Linlu Qiu, Hexiang Hu, Bowen Zhang, Peter Shaw, and Fei Sha. 2021. Systematic generalization on gscan: What is nearly solved and what is next? In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 2180-2188.</p>
<p>Raymond Reiter. 2001. Knowledge in Action: Logical Foundations for Specifying and Implementing Dynamical Systems. MIT Press.</p>
<p>Matthew Richardson and Pedro Domingos. 2006. Markov logic networks. Machine Learning, 62(12):107-136.</p>
<p>Sebastian Ruder. 2021. Challenges and Opportunities in NLP Benchmarking. http://ruder.io/ nlp-benchmarking.</p>
<p>Laura Ruis, Jacob Andreas, Marco Baroni, Diane Bouchacourt, and Brenden M Lake. 2020. A benchmark for systematic generalization in grounded language understanding. Advances in neural information processing systems, 33:19861-19872.</p>
<p>Shailaja Sampat and Joohyung Lee. 2018. A modelbased approach to visual reasoning on cnlvr dataset. In Sixteenth International Conference on Principles of Knowledge Representation and Reasoning.</p>
<p>Adam Santoro, David Raposo, David G Barrett, Mateusz Malinowski, Razvan Pascanu, Peter Battaglia, and Timothy Lillicrap. 2017. A simple neural network module for relational reasoning. In Advances in neural information processing systems, pages 49674976.</p>
<p>Md Kamruzzaman Sarker, Lu Zhou, Aaron Eberhart, and Pascal Hitzler. 2021. Neuro-symbolic artificial intelligence. AI Communications, pages 1-13.</p>
<p>Imanol Schlag and Jürgen Schmidhuber. 2018. Learning to reason with third order tensor products. Advances in neural information processing systems, 31.</p>
<p>Nathan Schucher, Siva Reddy, and Harm de Vries. 2022. The power of prompt tuning for low-resource semantic parsing. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 148-156.</p>
<p>Min Joon Seo, Sewon Min, Ali Farhadi, and Hannaneh Hajishirzi. 2017. Query-reduction networks for question answering. In 5th International Conference on Learning Representations, ICLR 2017, Toulon, France, April 24-26, 2017, Conference Track Proceedings.</p>
<p>Murray Shanahan. 1995. A circumscriptive calculus of events. Artif. Intell., 77(2):249-284.</p>
<p>Zhengxiang Shi, Qiang Zhang, and Aldo Lipani. 2022. Stepgame: A new benchmark for robust multi-hop spatial reasoning in texts. Association for the Advancement of Artificial Intelligence.</p>
<p>Richard Shin, Christopher Lin, Sam Thomson, Charles Chen Jr, Subhro Roy, Emmanouil Antonios Platanios, Adam Pauls, Dan Klein, Jason Eisner, and Benjamin Van Durme. 2021. Constrained language models yield few-shot semantic parsers. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 7699-7715.</p>
<p>Koustuv Sinha, Shagun Sodhani, Jin Dong, Joelle Pineau, and William L Hamilton. 2019. Clutrr: A diagnostic benchmark for inductive reasoning from text. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 4506-4515.</p>
<p>Jidong Tian, Yitian Li, Wenqing Chen, HE Hao, and Yaohui Jin. 2021. A generative-symbolic model for logical reasoning in nlu. In Is Neuro-Symbolic SOTA still a myth for Natural Language Inference? The first workshop.</p>
<p>Karthik Valmeekam, Alberto Olmo, Sarath Sreedharan, and Subbarao Kambhampati. 2022. Large language models still can't plan (a benchmark for LLMs on planning and reasoning about change). In NeurIPS 2022 Foundation Models for Decision Making Workshop.</p>
<p>Chenguang Wang, Xiao Liu, and Dawn Song. 2022. Ielm: An open information extraction benchmark for pre-trained language models. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, page 8417-8437. Association for Computational Linguistics.</p>
<p>Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, brian ichter, Fei Xia, Ed H. Chi, Quoc V Le, and Denny Zhou. 2022. Chain of thought prompting elicits reasoning in large language models. In Advances in Neural Information Processing Systems.</p>
<p>Jason Weston, Antoine Bordes, Sumit Chopra, and Tomás Mikolov. 2016. Towards ai-complete question answering: A set of prerequisite toy tasks. In 4th International Conference on Learning Representations, ICLR 2016, San Juan, Puerto Rico, May 2-4, 2016, Conference Track Proceedings.</p>
<p>Yuk Wah Wong and Raymond Mooney. 2007. Learning synchronous grammars for semantic parsing with lambda calculus. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 960-967.</p>
<p>Kexin Yi, Chuang Gan, Yunzhu Li, Pushmeet Kohli, Jiajun Wu, Antonio Torralba, and Joshua B Tenenbaum. 2019. CLEVRER: Collision events for video representation and reasoning. In ICLR.</p>
<p>John M Zelle and Raymond J Mooney. 1996. Learning to parse database queries using inductive logic programming. In Proceedings of the national conference on artificial intelligence, pages 1050-1055.</p>
<p>Andy Zeng, Adrian Wong, Stefan Welker, Krzysztof Choromanski, Federico Tombari, Aveek Purohit, Michael Ryoo, Vikas Sindhwani, Johnny Lee, Vincent Vanhoucke, et al. 2022. Socratic models: Composing zero-shot multimodal reasoning with language. arXiv preprint arXiv:2204.00598.</p>
<p>Luke S Zettlemoyer and Michael Collins. 2005. Learning to map sentences to logical form: structured classification with probabilistic categorial grammars. In Proceedings of the Twenty-First Conference on Uncertainty in Artificial Intelligence, pages 658-666.</p>
<p>Denny Zhou, Nathanael Schärli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schuurmans, Olivier Bousquet, Quoc Le, and Ed Chi. 2022. Least-to-most prompting enables complex reasoning in large language models. arXiv preprint arXiv:2205.10625.</p>
<p>Wenxuan Zhou and Muhao Chen. 2022. An improved baseline for sentence-level relation extraction. In Proceedings of the 2nd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 12th International Joint Conference on Natural Language Processing (Volume 2: Short Papers), pages 161-168, Online only. Association for Computational Linguistics.</p>
<p>Appendix</p>
<p>Section A presents another experiment with robot planning. Section B discusses more details about how we generated CLUTRR dataset and the experimental result on CLUTRR 1.0. Section C presents GPT-3 prompts for semantic parsing. Section D enumerates the errors with GPT-3 in semantic parsing. Section E presents ASP knowledge modules we used for the experiments. Section F enumerates the errors in the datasets.</p>
<p>For bAbI, the prompts for the baseline few-shot prompting can be found in the directory bAbI_ baseline/example_prompts, while the prompts for chain-of-thought can be found in bAbI_baseline/COT_prompts_v3. For StepGame, the prompts for the baseline few-shot prompting and chain-of-thought can be found in the directory stepGame/prompts. The following table records the cost for GPT-3 queries used in GPT-3 baselines and our method, where Eng. denotes the engine of GPT-3, c1, d2, d3 denote text-curie-001, text-davinci-002, and text-davinci-003.</p>
<table>
<thead>
<tr>
<th>Dataset</th>
<th>Method</th>
<th>Eng.</th>
<th>#Data</th>
<th>Cost</th>
</tr>
</thead>
<tbody>
<tr>
<td>bAbI</td>
<td>Few-Shot</td>
<td>d3</td>
<td>20k</td>
<td>$190</td>
</tr>
<tr>
<td></td>
<td>CoT</td>
<td>d3</td>
<td>20k</td>
<td>$280</td>
</tr>
<tr>
<td></td>
<td>GPT-3+ASP</td>
<td>d3</td>
<td>20k</td>
<td>$41</td>
</tr>
<tr>
<td>StepGame</td>
<td>Few-Shot</td>
<td>d3</td>
<td>1k</td>
<td>$21</td>
</tr>
<tr>
<td></td>
<td>CoT</td>
<td>d3</td>
<td>1k</td>
<td>$26</td>
</tr>
<tr>
<td></td>
<td>GPT-3+ASP</td>
<td>c1</td>
<td>10k</td>
<td>$89</td>
</tr>
<tr>
<td></td>
<td>GPT-3+ASP</td>
<td>d2</td>
<td>10k</td>
<td>$886</td>
</tr>
<tr>
<td>CLUTRR 1.0</td>
<td>GPT-3+ASP</td>
<td>d3</td>
<td>879</td>
<td>$37</td>
</tr>
<tr>
<td>CLUTRR 1.3</td>
<td>GPT-3+ASP</td>
<td>d3</td>
<td>400</td>
<td>$17</td>
</tr>
<tr>
<td>CLUTRR-S</td>
<td>GPT-3+ASP</td>
<td>d3</td>
<td>563</td>
<td>$19</td>
</tr>
<tr>
<td>gSCAN</td>
<td>GPT-3+ASP</td>
<td>c1</td>
<td>8k</td>
<td>$0.2</td>
</tr>
<tr>
<td>Pick&amp;Place</td>
<td>Few-Shot</td>
<td>d3</td>
<td>40</td>
<td>$0.5</td>
</tr>
<tr>
<td></td>
<td>GPT-3+ASP</td>
<td>d3</td>
<td>40</td>
<td>$0.4</td>
</tr>
</tbody>
</table>
<p>All experiments were conducted on Ubuntu 18.04.2 LTS with two 10-core CPU Intel(R) Xeon(R) CPU E5-2640 v4 @ 2.40GHz and four GP104 [GeForce GTX 1080] graphics cards.</p>
<p>All datasets used in this paper are publicly available. The bAbI dataset is under BSD license. The CLUTRR dataset is released under “Attribution-NonCommercial 4.0 International” license. The StepGame dataset doesn’t have a specified license. The gSCAN dataset is released under MIT license.</p>
<h2>Appendix A Robot Planning</h2>
<p>Recently, there has been increasing interest in using LLMs to find a sequence of executable actions for robots, aiming to achieve high-level goals expressed in natural language, such as SayCan <em>Ahn et al. (2022)</em> and Innermonologue <em>Huang et al. (2022)</em>. However, it is worth noting that the actions generated by LLMs tend to be loosely connected and do not take into account the intermediate state changes that occur during the execution of these actions.</p>
<p>Figure 3: The GPT-3+ASP pipeline for Pick&amp;Place</p>
<p>We based our work on SayCan’s open-source virtual tabletop environment, where a robot is tasked with achieving a goal, such as "stack the blocks," on a table with colored blocks and bowls. We noticed that the successful plans demonstrated by SayCan are restricted to simple one-step look-ahead plans that do not take into account intermediate state changes.</p>
<p>We randomly sampled 40 data instances of the form $\langle S_{i},S_{g},L\rangle$ in the Pick&amp;Place domain with 4 to 7 blocks and 3 to 7 bowls, possibly stacked together and with 3 to 10 steps of pick_and_place actions required by the robot to change the initial state $S_{i}$ to the goal state $S_{g}$. Here, the label $L$ is the set of instructions to achieve the goals (e.g., “1. Move the violet block onto the blue block. 2…”). Among 40 data instances, 20 data instances contain only blocks that can be placed on the table while 20 data instances contain both blocks and bowls and assume all blocks must be on the bowls.</p>
<p>The baseline for this dataset follows the method in SayCan’s open-source virtual tabletop environment, where GPT-3 is used as the large language model to directly find the sequence of actions from $S_{i}$ to $S_{g}$. However, the baseline fails to find successful plans for all 40 randomly sampled data instances. This result confirms the claim by <em>Valmeekam et al. (2022)</em> that large language models are not suitable as planners.</p>
<p>We also applied our method to this task. We let GPT-3 turn the states $S_{i}$ and $S_{g}$ into atomic facts of the form $on(A,B,0)$ and $on(A,B)$, respectively.</p>
<p>We also applied our method to this task. We let GPT-3 turn the states $S_{i}$ and $S_{g}$ into atomic facts of the form $on(A,B,0)$ and $on(A,B)$, respectively.</p>
<table>
<thead>
<tr>
<th>Method</th>
<th>Blocks</th>
<th>Blocks+Bowls</th>
</tr>
</thead>
<tbody>
<tr>
<td>GPT-3(d3)</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>GPT-3(d3)+ASP</td>
<td>$\mathbf{1 0 0}$</td>
<td>$\mathbf{1 0 0}$</td>
</tr>
</tbody>
</table>
<p>Table 6: Test accuracy on the Pick&amp;Place dataset. (d3) denotes the text-davinci-003 model.
<img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 4: A simple plan predicted by GPT-3+ASP in the Pick&amp;Place domain.</p>
<h2>B More about CLUTRR</h2>
<h3>B.1 CLUTRR 1.3 Data Generation</h3>
<p>We used CLUTRR 1.3 codes to generate 400 test data instances. ${ }^{7}$ Our generated CLUTRR 1.3 dataset consists of 100 data for each of the four categories: (assuming that the query is asking about the relation between persons $A$ and $D$ )</p>
<ul>
<li>clean: each story describes 3 relations in a chain of four persons $A-B-C-D$;</li>
</ul>
<p><sup id="fnref4:0"><a class="footnote-ref" href="#fn:0">1</a></sup>- supporting: each story describes 3 relations in a chain of four persons $A-B-C-D$ as well as an additional relation $X-Y$ such that $X, Y \in{A, B, C, D}$ and $X-Y$ is not the queried pair;
- irrelevant: each story describes 3 relations in a chain of four persons $A-B-C-D$ as well as an additional relation $X-Y$ such that $X \in{A, B, C, D}$ and $Y \notin{A, B, C, D}$;
- disconnected: each story describes 3 relations in a chain of four persons $A-B-C-D$ as well as an additional relation $X-Y$ such that $X, Y \notin{A, B, C, D}$.</p>
<h3>B.2 Evaluation on CLUTRR 1.0</h3>
<table>
<thead>
<tr>
<th style="text-align: center;">Training</th>
<th style="text-align: center;">Testing</th>
<th style="text-align: center;">BA</th>
<th style="text-align: center;">GSM</th>
<th style="text-align: center;">d2</th>
<th style="text-align: center;">d3</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Clean</td>
<td style="text-align: center;">Clean</td>
<td style="text-align: center;">58</td>
<td style="text-align: center;">69</td>
<td style="text-align: center;">63</td>
<td style="text-align: center;">68</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Supporting</td>
<td style="text-align: center;">76</td>
<td style="text-align: center;">66</td>
<td style="text-align: center;">62</td>
<td style="text-align: center;">62</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Irrelevant</td>
<td style="text-align: center;">70</td>
<td style="text-align: center;">77</td>
<td style="text-align: center;">66</td>
<td style="text-align: center;">71</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Disconnected</td>
<td style="text-align: center;">49</td>
<td style="text-align: center;">36</td>
<td style="text-align: center;">59</td>
<td style="text-align: center;">59</td>
</tr>
<tr>
<td style="text-align: center;">Supporting</td>
<td style="text-align: center;">Supporting</td>
<td style="text-align: center;">67</td>
<td style="text-align: center;">49</td>
<td style="text-align: center;">83</td>
<td style="text-align: center;">83</td>
</tr>
<tr>
<td style="text-align: center;">Irrelevant</td>
<td style="text-align: center;">Irrelevant</td>
<td style="text-align: center;">51</td>
<td style="text-align: center;">63</td>
<td style="text-align: center;">72</td>
<td style="text-align: center;">75</td>
</tr>
<tr>
<td style="text-align: center;">Disconnected</td>
<td style="text-align: center;">Disconnected</td>
<td style="text-align: center;">57</td>
<td style="text-align: center;">53</td>
<td style="text-align: center;">63</td>
<td style="text-align: center;">67</td>
</tr>
</tbody>
</table>
<p>Table 7: Test accuracy on the CLUTRR dataset. BA denotes BiLSTM-Attention. d2 and d3 denote GPT-3+ASP with text-davinci-002 and text-davinci-003 model.</p>
<p>Table 7 compares the accuracy of our method and the state-of-the-art methods, i.e., BiLSTMAttention (Sinha et al., 2019) and GSM (with a BiLSTM encoder) (Tian et al., 2021), on the (original) CLUTRR test dataset. Except for our method, all other models are trained on a specific split of the CLUTRR training dataset.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Training</th>
<th style="text-align: center;">Testing</th>
<th style="text-align: center;">DP</th>
<th style="text-align: center;">d2</th>
<th style="text-align: center;">d3</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Clean</td>
<td style="text-align: center;">Clean</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">100</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Supporting</td>
<td style="text-align: center;">99</td>
<td style="text-align: center;">96</td>
<td style="text-align: center;">99</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Irrelevant</td>
<td style="text-align: center;">98</td>
<td style="text-align: center;">99</td>
<td style="text-align: center;">100</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Disconnected</td>
<td style="text-align: center;">99</td>
<td style="text-align: center;">98</td>
<td style="text-align: center;">100</td>
</tr>
<tr>
<td style="text-align: center;">Supporting</td>
<td style="text-align: center;">Supporting</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">100</td>
</tr>
<tr>
<td style="text-align: center;">Irrelevant</td>
<td style="text-align: center;">Irrelevant</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">97</td>
<td style="text-align: center;">100</td>
</tr>
<tr>
<td style="text-align: center;">Disconnected</td>
<td style="text-align: center;">Disconnected</td>
<td style="text-align: center;">94</td>
<td style="text-align: center;">97</td>
<td style="text-align: center;">100</td>
</tr>
</tbody>
</table>
<p>Table 8: Test accuracy on the CLUTRR-S dataset. DP denotes DeepProbLog, d2 and d3 denote GPT-3+ASP with the text-davinci-002 and text-davinci-003 model.</p>
<p>Table 8 compares the accuracy of our method and the state-of-the-art method, DeepProbLog (Manhaeve et al., 2021) on the CLUTRR-S test dataset. With GPT-3(d2)+ASP on the CLUTRRS dataset, 550 out of 563 predictions are correct,</p>
<p>and 13 are wrong. All errors occur due to the entities in a relation being swapped. For example, we use "son (A, B)" to represent "A has a son B" while GPT-3 text-davinci-002 responded with "son (Robert, Ryan)" for the sentence "Robert is Ryan's son." On the other hand, text-davinci-003 performed better, with only a single error and 562 out of 563 predictions being correct.</p>
<h2>C Prompts for Semantic Parsing</h2>
<p>Below, we present the details of the general knowledge of the prompts that we summarized and applied in this paper, followed by some examples.</p>
<ol>
<li>
<p>If the information in a story (or query) can be extracted independently, parsing each sentence separately (using the same prompt multiple times) typically works better than parsing the whole story. Since people usually cache all GPT-3 responses to save cost by avoiding duplicated GPT-3 requests for the same prompt, parsing each sentence separately also yields better usage of cached responses. Below are some examples.</p>
</li>
<li>
<p>In most bAbI tasks (except for tasks 11 and 13), the sentences in a story (including the query sentence) are independent of each other. We parse each sentence separately using GPT-3 as in the Appendix C.1.</p>
</li>
<li>In the stepGame dataset, each sentence in a story describes the spatial relation between 2 objects. There are 4 sentences in a story when $k=1$ and about 20 sentences when $k=10$. If we ask GPT-3 to extract all the atomic facts from the whole story, it always misses some atoms or predicts wrong atoms. Since every sentence is independent of each other as shown in Figure 1, we use the following (truncated) prompt multiple times for each data instance where each time [INPUT] is replaced with one sentence in the story or the query. This yields a much higher accuracy as in Section 4.3. The complete prompt is available in Appendix C.2.</li>
</ol>
<div class="codehilite"><pre><span></span><code>Please parse each sentence into a fact
    . If the sentence is describing
    clock-wise information, then 12
    denotes top, 1 and 2 denote
    top_right, 3 denotes right, ... If
</code></pre></div>

<p>the sentence is describing cardinal directions, then north denotes top, ...</p>
<p>Sentence: What is the relation of the agent $X$ to the agent $K$ ?
Semantic Parse: query("X", "K").
Sentence: H is positioned in the front right corner of M.
Semantic Parse: top_right("H", "M").
...
Sentence: [INPUT]
Semantic Parse:
However, if some sentences in a story are dependent, splitting them may lead to unexpected results in the GPT-3 response. Below are some examples.</p>
<ul>
<li>In bAbI task #11 and #13, a story may contain the two consecutive sentences "Mary went back to the bathroom. After that she went to the bedroom." There is a dependency on the sentences to understand that "she" in the second sentence refers to "Mary" in the first. For this reason, task #11 stories are parsed as a whole. This is similar for task #13.</li>
<li>
<p>In the CLUTRR dataset, a story may contain sentences with coreferences like "Shirley enjoys playing cards with her brother. His name is Henry." where the latter sentence depends on the former one, and a family relation can be correctly extracted only with both sentences. Thus for CLUTRR datasets (i.e., CLUTRR 1.0, CLUTRR 1.3, and CLUTRR-S), we extract the family relations and gender relations from the whole story.</p>
</li>
<li>
<p>There is certain commonsense knowledge that GPT-3 is not aware of, and describing the missing knowledge in the prompt works better than adding examples only. This happens when GPT-3 cannot generalize such knowledge well with a few examples.</p>
</li>
<li>
<p>For example, in StepGame dataset, clock numbers are used to denote cardinal directions, e.g., "H is below J at 4 o'clock" means "H is on the bottom-right of J". Such knowledge in the dataset is not well captured by GPT-3 and enumerating examples in the prompt doesn't work</p>
</li>
</ul>
<p>well. On the other hand, describing such knowledge at the beginning of the prompt as shown in Appendix C. 2 increases the accuracy by a large margin.</p>
<h2>C. 1 bAbI</h2>
<p>For bAbI dataset, there are two prompts for each task, corresponding to the context and query. Each prompt has a consistent set of basic instructions followed by example pairs of text and parsed text. Below are the prompts used to parse the context and query facts from a story and query, where [Input] at the end is replaced with the story in each test data instance. We only present the prompts for Tasks 1,2, and 3. The rest of the prompts can be found in the repository in https : //github.com/azreasoners/LLM-ASP/ blob/main/bAbI/GPT_prompts.py.</p>
<h2>Tasks 1/2/3 (Context)</h2>
<div class="codehilite"><pre><span></span><code><span class="n">Please</span><span class="w"> </span><span class="nf">parse</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">following</span><span class="w"> </span><span class="n">statements</span><span class="w"> </span><span class="k">into</span><span class="w"> </span><span class="n">facts</span>
<span class="w">    </span><span class="p">.</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="n">available</span><span class="w"> </span><span class="n">keywords</span><span class="w"> </span><span class="k">are</span><span class="err">:</span><span class="w"> </span><span class="n">pickup</span><span class="p">,</span><span class="w"> </span><span class="k">drop</span><span class="p">,</span>
<span class="w">    </span><span class="ow">and</span><span class="w"> </span><span class="k">go</span><span class="p">.</span>
<span class="nl">Sentence</span><span class="p">:</span><span class="w"> </span><span class="nf">Max</span><span class="w"> </span><span class="n">journeyed</span><span class="w"> </span><span class="k">to</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">bathroom</span><span class="p">.</span>
<span class="n">Semantic</span><span class="w"> </span><span class="nf">parse</span><span class="err">:</span><span class="w"> </span><span class="k">go</span><span class="p">(</span><span class="nf">Max</span><span class="p">,</span><span class="w"> </span><span class="n">bathroom</span><span class="p">).</span>
<span class="nl">Sentence</span><span class="p">:</span><span class="w"> </span><span class="n">Mary</span><span class="w"> </span><span class="n">grabbed</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">football</span><span class="w"> </span><span class="n">there</span><span class="p">.</span>
<span class="n">Semantic</span><span class="w"> </span><span class="nf">parse</span><span class="err">:</span><span class="w"> </span><span class="n">pickup</span><span class="p">(</span><span class="n">Mary</span><span class="p">,</span><span class="w"> </span><span class="n">football</span><span class="p">).</span>
<span class="nl">Sentence</span><span class="p">:</span><span class="w"> </span><span class="n">Bob</span><span class="w"> </span><span class="n">picked</span><span class="w"> </span><span class="n">up</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">apple</span><span class="p">.</span>
<span class="n">Semantic</span><span class="w"> </span><span class="nf">parse</span><span class="err">:</span><span class="w"> </span><span class="n">pickup</span><span class="p">(</span><span class="n">Bob</span><span class="p">,</span><span class="w"> </span><span class="n">apple</span><span class="p">).</span>
<span class="nl">Sentence</span><span class="p">:</span><span class="w"> </span><span class="n">Susan</span><span class="w"> </span><span class="n">dropped</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">milk</span><span class="p">.</span>
<span class="n">Semantic</span><span class="w"> </span><span class="nf">parse</span><span class="err">:</span><span class="w"> </span><span class="k">drop</span><span class="p">(</span><span class="n">Susan</span><span class="p">,</span><span class="w"> </span><span class="n">milk</span><span class="p">).</span>
<span class="nl">Sentence</span><span class="p">:</span><span class="w"> </span><span class="n">Bob</span><span class="w"> </span><span class="n">got</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">football</span><span class="w"> </span><span class="n">there</span><span class="p">.</span>
<span class="n">Semantic</span><span class="w"> </span><span class="nf">parse</span><span class="err">:</span><span class="w"> </span><span class="n">pickup</span><span class="p">(</span><span class="n">Bob</span><span class="p">,</span><span class="w"> </span><span class="n">football</span><span class="p">).</span>
<span class="nl">Sentence</span><span class="p">:</span><span class="w"> </span><span class="nf">Max</span><span class="w"> </span><span class="nf">left</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">cup</span><span class="p">.</span>
<span class="n">Semantic</span><span class="w"> </span><span class="nf">parse</span><span class="err">:</span><span class="w"> </span><span class="k">drop</span><span class="p">(</span><span class="nf">Max</span><span class="p">,</span><span class="w"> </span><span class="n">cup</span><span class="p">).</span>
<span class="nl">Sentence</span><span class="p">:</span><span class="w"> </span><span class="n">Kevin</span><span class="w"> </span><span class="n">put</span><span class="w"> </span><span class="n">down</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">pie</span><span class="w"> </span><span class="n">there</span><span class="p">.</span>
<span class="n">Semantic</span><span class="w"> </span><span class="nf">parse</span><span class="err">:</span><span class="w"> </span><span class="k">drop</span><span class="p">(</span><span class="n">Kevin</span><span class="p">,</span><span class="w"> </span><span class="n">pie</span><span class="p">).</span>
<span class="nl">Sentence</span><span class="p">:</span><span class="w"> </span><span class="n">John</span><span class="w"> </span><span class="n">took</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">football</span><span class="w"> </span><span class="n">there</span><span class="p">.</span>
<span class="n">Semantic</span><span class="w"> </span><span class="nf">parse</span><span class="err">:</span><span class="w"> </span><span class="n">pickup</span><span class="p">(</span><span class="n">John</span><span class="p">,</span><span class="w"> </span><span class="n">football</span><span class="p">).</span>
<span class="nl">Sentence</span><span class="p">:</span><span class="w"> </span><span class="o">[</span><span class="n">INPUT</span><span class="o">]</span>
<span class="n">Semantic</span><span class="w"> </span><span class="nf">parse</span><span class="err">:</span>
</code></pre></div>

<h2>Task 1 (Query)</h2>
<div class="codehilite"><pre><span></span><code>Please parse the following questions into query
    facts. The available keywords are:
    whereAgent.
Sentence: Where is Mary?
Semantic parse: whereAgent (Mary).
Sentence: Where is Daniel?
Semantic parse: whereAgent(Daniel).
Sentence: Where is Sandra?
Semantic parse: whereAgent(Sandra).
</code></pre></div>

<p>Sentence: Where is John?
Semantic parse: whereAgent (John).
Sentence: [INPUT]
Semantic parse:</p>
<h2>Task 2 (Query)</h2>
<div class="codehilite"><pre><span></span><code><span class="n">Please</span><span class="w"> </span><span class="nf">parse</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">following</span><span class="w"> </span><span class="n">questions</span><span class="w"> </span><span class="k">into</span><span class="w"> </span><span class="n">query</span>
<span class="w">    </span><span class="n">facts</span><span class="p">.</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="n">available</span><span class="w"> </span><span class="n">keywords</span><span class="w"> </span><span class="k">are</span><span class="err">:</span><span class="w"> </span><span class="n">loc</span><span class="p">.</span>
<span class="nl">Sentence</span><span class="p">:</span><span class="w"> </span><span class="k">Where</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">toothbrush</span><span class="vm">?</span>
<span class="n">Semantic</span><span class="w"> </span><span class="nf">parse</span><span class="err">:</span><span class="w"> </span><span class="n">loc</span><span class="p">(</span><span class="n">toothbrush</span><span class="p">).</span>
<span class="nl">Sentence</span><span class="p">:</span><span class="w"> </span><span class="k">Where</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">milk</span><span class="vm">?</span>
<span class="n">Semantic</span><span class="w"> </span><span class="nf">parse</span><span class="err">:</span><span class="w"> </span><span class="n">loc</span><span class="p">(</span><span class="n">milk</span><span class="p">).</span>
<span class="nl">Sentence</span><span class="p">:</span><span class="w"> </span><span class="k">Where</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">apple</span><span class="vm">?</span>
<span class="n">Semantic</span><span class="w"> </span><span class="nf">parse</span><span class="err">:</span><span class="w"> </span><span class="n">loc</span><span class="p">(</span><span class="n">apple</span><span class="p">).</span>
<span class="nl">Sentence</span><span class="p">:</span><span class="w"> </span><span class="k">Where</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">football</span><span class="vm">?</span>
<span class="n">Semantic</span><span class="w"> </span><span class="nf">parse</span><span class="err">:</span><span class="w"> </span><span class="n">loc</span><span class="p">(</span><span class="n">football</span><span class="p">).</span>
<span class="nl">Sentence</span><span class="p">:</span><span class="w"> </span><span class="o">[</span><span class="n">INPUT</span><span class="o">]</span>
<span class="n">Semantic</span><span class="w"> </span><span class="nf">parse</span><span class="err">:</span>
</code></pre></div>

<h2>Task 3 (Query)</h2>
<div class="codehilite"><pre><span></span><code><span class="n">Please</span><span class="w"> </span><span class="nf">parse</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">following</span><span class="w"> </span><span class="n">questions</span><span class="w"> </span><span class="k">into</span><span class="w"> </span><span class="n">query</span>
<span class="w">    </span><span class="n">facts</span><span class="p">.</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="n">available</span><span class="w"> </span><span class="n">keywords</span><span class="w"> </span><span class="k">are</span><span class="err">:</span><span class="w"> </span><span class="n">loc</span><span class="p">.</span>
<span class="nl">Sentence</span><span class="p">:</span><span class="w"> </span><span class="k">Where</span><span class="w"> </span><span class="n">was</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">football</span><span class="w"> </span><span class="k">before</span><span class="w"> </span><span class="n">the</span>
<span class="w">    </span><span class="n">bathroom</span><span class="vm">?</span>
<span class="n">Semantic</span><span class="w"> </span><span class="nf">parse</span><span class="err">:</span><span class="w"> </span><span class="k">before</span><span class="p">(</span><span class="n">football</span><span class="p">,</span><span class="n">bathroom</span><span class="p">).</span>
<span class="nl">Sentence</span><span class="p">:</span><span class="w"> </span><span class="k">Where</span><span class="w"> </span><span class="n">was</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">apple</span><span class="w"> </span><span class="k">before</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">garden</span><span class="vm">?</span>
<span class="n">Semantic</span><span class="w"> </span><span class="nf">parse</span><span class="err">:</span><span class="w"> </span><span class="k">before</span><span class="p">(</span><span class="n">apple</span><span class="p">,</span><span class="n">garden</span><span class="p">).</span>
<span class="nl">Sentence</span><span class="p">:</span><span class="w"> </span><span class="k">Where</span><span class="w"> </span><span class="n">was</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">milk</span><span class="w"> </span><span class="k">before</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">kitchen</span><span class="vm">?</span>
<span class="n">Semantic</span><span class="w"> </span><span class="nf">parse</span><span class="err">:</span><span class="w"> </span><span class="k">before</span><span class="p">(</span><span class="n">milk</span><span class="p">,</span><span class="n">kitchen</span><span class="p">).</span>
<span class="nl">Sentence</span><span class="p">:</span><span class="w"> </span><span class="k">Where</span><span class="w"> </span><span class="n">was</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">apple</span><span class="w"> </span><span class="k">before</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">bedroom</span>
<span class="w">    </span><span class="vm">?</span>
<span class="n">Semantic</span><span class="w"> </span><span class="nf">parse</span><span class="err">:</span><span class="w"> </span><span class="k">before</span><span class="p">(</span><span class="n">apple</span><span class="p">,</span><span class="n">bedroom</span><span class="p">).</span>
<span class="nl">Sentence</span><span class="p">:</span><span class="w"> </span><span class="k">Where</span><span class="w"> </span><span class="n">was</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">football</span><span class="w"> </span><span class="k">before</span><span class="w"> </span><span class="n">the</span>
<span class="w">    </span><span class="n">hallway</span><span class="vm">?</span>
<span class="n">Semantic</span><span class="w"> </span><span class="nf">parse</span><span class="err">:</span><span class="w"> </span><span class="k">before</span><span class="p">(</span><span class="n">football</span><span class="p">,</span><span class="w"> </span><span class="n">hallway</span><span class="p">).</span>
<span class="nl">Sentence</span><span class="p">:</span><span class="w"> </span><span class="o">[</span><span class="n">INPUT</span><span class="o">]</span>
<span class="n">Semantic</span><span class="w"> </span><span class="nf">parse</span><span class="err">:</span>
</code></pre></div>

<h2>C. 2 StepGame</h2>
<p>For the StepGame dataset, there is only one prompt below to extract the location relations among objects. All example sentences are from the training data in (the noise split of) the original StepGame dataset. ${ }^{8}$ The [Input] at the end of the prompt is replaced with each sentence in a test data instance.</p>
<div class="codehilite"><pre><span></span><code>Please parse each sentence into a fact. If the
    sentence is describing clock-wise
    information, then 12 denotes top, 1 and 2
    denote top_right, 3 denotes right, 4 and 5
</code></pre></div>

<p><sup id="fnref5:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>denote down_right, 6 denotes down, 7 and 8 denote down_left, 9 denote left, 10 and 11 denote top_left. If the sentence is describing cardinal directions, then north denotes top, east denotes right, south denotes down, and west denotes left. If the sentence is a question, the fact starts with query. Otherwise, the fact starts with one of top, down, left, right, top_left, top_right, down_left, and down_right.</p>
<p>Sentence: What is the relation of the agent $X$ to the agent $K$ ?
Semantic Parse: query("X", "K").
Sentence: H is positioned in the front right corner of M.
Semantic Parse: top_right("H", "M").
Sentence: F is on the left side of and below Q. Semantic Parse: down_left("F", "Q").</p>
<p>Sentence: Y and I are parallel, and Y is on top of I.
Semantic Parse: top("Y", "I").
Sentence: V is over there with T above.
Semantic Parse: top("T", "V").
Sentence: V is slightly off center to the top left and G is slightly off center to the bottom right.
Semantic Parse: top_left("V", "G").
Sentence: The objects S and A are over there. The object $S$ is lower and slightly to the left of the object A.
Semantic Parse: down_left("S", "A").
Sentence: D is diagonally below Z to the right at a 45 degree angle.
Semantic Parse: down_right("D", "Z").
Sentence: V is at A's 9 o'clock.
Semantic Parse: left("V", "A").
Sentence: J is at O's 6 o'clock.
Semantic Parse: down("J", "O").
Sentence: H is below J at 4 o'clock.
Semantic Parse: down_right ("H", "J").
Sentence: O is there and C is at the 5 position of a clock face.
Semantic Parse: down_right("C", "O").
Sentence: If H is the center of a clock face, B is located between 10 and 11.
Semantic Parse: top_left("B", "H").
Sentence: [Input]
Semantic Parse:</p>
<h2>C. 3 CLUTRR</h2>
<p>For CLUTRR dataset, there are two prompts to extract the family relations and genders from a story respectively. All example sto-
ries in both prompts are from the training data "data_06b8f2a1/2.2.2.3_train.csv" in the original CLUTRR dataset. ${ }^{9}$ Below is the prompt to extract family relations from a story where [Input] at the end is replaced with the story in each test data instance.</p>
<div class="codehilite"><pre><span></span><code><span class="n">Given</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">story</span><span class="p">,</span><span class="w"> </span><span class="k">extract</span><span class="w"> </span><span class="k">atomic</span><span class="w"> </span><span class="n">facts</span><span class="w"> </span><span class="k">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">form</span>
<span class="w">    </span><span class="n">relation</span><span class="p">(</span><span class="ss">&quot;Person&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;Person&quot;</span><span class="p">).</span><span class="w"> </span><span class="n">Example</span>
<span class="w">    </span><span class="n">relations</span><span class="w"> </span><span class="k">are</span><span class="err">:</span><span class="w"> </span><span class="n">father</span><span class="p">,</span><span class="w"> </span><span class="n">mother</span><span class="p">,</span><span class="w"> </span><span class="n">parent</span><span class="p">,</span><span class="w"> </span><span class="n">son</span><span class="p">,</span>
<span class="w">    </span><span class="n">daughter</span><span class="p">,</span><span class="w"> </span><span class="n">child</span><span class="p">,</span><span class="w"> </span><span class="n">grandfather</span><span class="p">,</span><span class="w"> </span><span class="n">grandmother</span><span class="p">,</span>
<span class="w">    </span><span class="n">grandson</span><span class="p">,</span><span class="w"> </span><span class="n">granddaughter</span><span class="p">,</span><span class="w"> </span><span class="n">wife</span><span class="p">,</span><span class="w"> </span><span class="n">husband</span><span class="p">,</span>
<span class="w">    </span><span class="n">spouse</span><span class="p">,</span><span class="w"> </span><span class="n">sibling</span><span class="p">,</span><span class="w"> </span><span class="n">nephew</span><span class="p">,</span><span class="w"> </span><span class="n">niece</span><span class="p">,</span><span class="w"> </span><span class="n">uncle</span><span class="p">,</span><span class="w"> </span><span class="n">aunt</span><span class="p">,</span>
<span class="w">        </span><span class="n">child_in_law</span><span class="p">,</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">parent_in_law</span><span class="p">.</span>
<span class="nl">Story</span><span class="p">:</span><span class="w"> </span><span class="o">[</span><span class="n">Verdie</span><span class="o">]</span><span class="w"> </span><span class="n">waved</span><span class="w"> </span><span class="n">good</span><span class="w"> </span><span class="n">bye</span><span class="w"> </span><span class="k">to</span><span class="w"> </span><span class="n">her</span><span class="w"> </span><span class="n">dad</span><span class="w"> </span><span class="o">[</span><span class="n">Henry</span>
<span class="n">    </span><span class="o">]</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="nf">day</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">went</span><span class="w"> </span><span class="k">next</span><span class="w"> </span><span class="n">door</span><span class="w"> </span><span class="k">with</span><span class="w"> </span><span class="n">her</span>
<span class="w">    </span><span class="n">sister</span><span class="w"> </span><span class="o">[</span><span class="n">Amanda</span><span class="o">]</span><span class="p">.</span><span class="w"> </span><span class="o">[</span><span class="n">Henry</span><span class="o">]</span><span class="s1">&#39;s daughter, [Amanda</span>
<span class="s1">    ], went to the city this weekend. She spent</span>
<span class="s1">    her time there visiting her grandfather, [</span>
<span class="s1">    Kyle], and had a wonderful time with him.</span>
<span class="s1">Semantic Parse: father(&quot;Verdie&quot;, &quot;Henry&quot;).</span>
<span class="s1">    sister(&quot;Verdie&quot;, &quot;Amanda&quot;). daughter(&quot;Henry</span>
<span class="s1">    &quot;, &quot;Amanda&quot;). grandfather(&quot;Amanda&quot;, &quot;Kyle&quot;).</span>
<span class="s1">Story: [Michelle] was excited for today, its her</span>
<span class="s1">        daughter&#39;</span><span class="n">s</span><span class="p">,</span><span class="w"> </span><span class="o">[</span><span class="n">Theresa</span><span class="o">]</span><span class="p">,</span><span class="w"> </span><span class="n">spring</span><span class="w"> </span><span class="k">break</span><span class="p">.</span><span class="w"> </span><span class="n">She</span>
<span class="w">        </span><span class="n">will</span><span class="w"> </span><span class="n">finally</span><span class="w"> </span><span class="k">get</span><span class="w"> </span><span class="k">to</span><span class="w"> </span><span class="n">see</span><span class="w"> </span><span class="n">her</span><span class="p">.</span><span class="w"> </span><span class="o">[</span><span class="n">Michael</span><span class="o">]</span><span class="w"> </span><span class="n">was</span>
<span class="w">        </span><span class="n">busy</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">sent</span><span class="w"> </span><span class="n">his</span><span class="w"> </span><span class="n">wife</span><span class="p">,</span><span class="w"> </span><span class="o">[</span><span class="n">Marlene</span><span class="o">]</span><span class="p">,</span><span class="w"> </span><span class="n">instead</span><span class="p">.</span>
<span class="w">        </span><span class="o">[</span><span class="n">Kristen</span><span class="o">]</span><span class="w"> </span><span class="n">loved</span><span class="w"> </span><span class="k">to</span><span class="w"> </span><span class="n">care</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">her</span><span class="w"> </span><span class="n">newborn</span>
<span class="w">        </span><span class="n">child</span><span class="w"> </span><span class="o">[</span><span class="n">Ronald</span><span class="o">]</span><span class="p">.</span><span class="w"> </span><span class="o">[</span><span class="n">Eric</span><span class="o">]</span><span class="s1">&#39;s son is [Arthur].</span>
<span class="s1">Semantic Parse: daughter(&quot;Michelle&quot;, &quot;Theresa&quot;).</span>
<span class="s1">        wife(&quot;Michael&quot;, &quot;Marlene&quot;). child(&quot;Kristen</span>
<span class="s1">        &quot;, &quot;Ronald&quot;). son(&quot;Eric&quot;, &quot;Arthur&quot;).</span>
<span class="s1">Story: [Vernon] was present in the delivery room</span>
<span class="s1">        when his daughter [Raquel] was born, but</span>
<span class="s1">        when his daughter [Constance] was born he</span>
<span class="s1">        was too sick. [Vernon] and his daughter [</span>
<span class="s1">        Margaret] went to the movies. [Constance], [</span>
<span class="s1">        Margaret]&#39;</span><span class="n">s</span><span class="w"> </span><span class="n">sister</span><span class="p">,</span><span class="w"> </span><span class="n">had</span><span class="w"> </span><span class="k">to</span><span class="w"> </span><span class="n">stay</span><span class="w"> </span><span class="n">home</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="n">she</span>
<span class="w">        </span><span class="n">was</span><span class="w"> </span><span class="n">sick</span><span class="p">.</span>
<span class="n">Semantic</span><span class="w"> </span><span class="nf">Parse</span><span class="err">:</span><span class="w"> </span><span class="n">daughter</span><span class="p">(</span><span class="ss">&quot;Vernon&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;Raquel&quot;</span><span class="p">).</span>
<span class="w">        </span><span class="n">daughter</span><span class="p">(</span><span class="ss">&quot;Vernon&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;Constance&quot;</span><span class="p">).</span><span class="w"> </span><span class="n">daughter</span><span class="p">(</span><span class="ss">&quot;</span>
<span class="ss">        Vernon&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;Margaret&quot;</span><span class="p">).</span><span class="w"> </span><span class="n">sister</span><span class="p">(</span><span class="ss">&quot;Margaret&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;</span>
<span class="ss">        Constance&quot;</span><span class="p">).</span>
<span class="nl">Story</span><span class="p">:</span><span class="w"> </span><span class="o">[</span><span class="n">Eric</span><span class="o">]</span><span class="w"> </span><span class="n">who</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="o">[</span><span class="n">Carl</span><span class="o">]</span><span class="s1">&#39;s father grounded [</span>
<span class="s1">        Carl] after finding out what [Carl] had done</span>
<span class="s1">        at school. [Ronald] was busy planning a 90</span>
<span class="s1">        th birthday party for his aunt, [Theresa]. [</span>
<span class="s1">        Eric] and his son [Carl] went to the park</span>
<span class="s1">        and saw [Eric]&#39;</span><span class="n">s</span><span class="w"> </span><span class="n">father</span><span class="w"> </span><span class="o">[</span><span class="n">Kyle</span><span class="o">]</span><span class="w"> </span><span class="n">there</span><span class="w"> </span><span class="k">with</span>
<span class="w">        </span><span class="n">his</span><span class="w"> </span><span class="n">dog</span><span class="p">.</span>
<span class="n">Semantic</span><span class="w"> </span><span class="nf">Parse</span><span class="err">:</span><span class="w"> </span><span class="n">father</span><span class="p">(</span><span class="ss">&quot;Carl&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;Eric&quot;</span><span class="p">).</span><span class="w"> </span><span class="n">aunt</span><span class="p">(</span><span class="ss">&quot;</span>
<span class="ss">        Ronald&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;Theresa&quot;</span><span class="p">).</span><span class="w"> </span><span class="n">son</span><span class="p">(</span><span class="ss">&quot;Eric&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;Carl&quot;</span><span class="p">).</span>
<span class="w">        </span><span class="n">father</span><span class="p">(</span><span class="ss">&quot;Eric&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;Kyle&quot;</span><span class="p">).</span>
<span class="nl">Story</span><span class="p">:</span><span class="w"> </span><span class="o">[</span><span class="n">Shirley</span><span class="o">]</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="o">[</span><span class="n">Edward</span><span class="o">]</span><span class="w"> </span><span class="k">are</span><span class="w"> </span><span class="n">siblings</span><span class="w"> </span><span class="ow">and</span>
<span class="w">        </span><span class="n">best</span><span class="w"> </span><span class="n">friends</span><span class="p">.</span><span class="w"> </span><span class="n">They</span><span class="w"> </span><span class="n">do</span><span class="w"> </span><span class="n">everything</span><span class="w"> </span><span class="n">together</span><span class="p">.</span><span class="w"> </span><span class="o">[</span>
<span class="n">        Henry</span><span class="o">]</span><span class="w"> </span><span class="n">walked</span><span class="w"> </span><span class="n">his</span><span class="w"> </span><span class="n">daughters</span><span class="w"> </span><span class="o">[</span><span class="n">Amanda</span><span class="o">]</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="o">[</span>
<span class="n">        Michelle</span><span class="o">]</span><span class="w"> </span><span class="k">to</span><span class="w"> </span><span class="n">school</span><span class="p">.</span><span class="w"> </span><span class="o">[</span><span class="n">Kyle</span><span class="o">]</span><span class="w"> </span><span class="n">enjoys</span><span class="w"> </span><span class="n">watching</span>
<span class="w">        </span><span class="n">movies</span><span class="w"> </span><span class="k">with</span><span class="w"> </span><span class="n">his</span><span class="w"> </span><span class="n">son</span><span class="err">&#39;</span><span class="n">s</span><span class="w"> </span><span class="n">daughter</span><span class="p">.</span><span class="w"> </span><span class="n">Her</span><span class="w"> </span><span class="n">name</span><span class="w"> </span><span class="k">is</span>
<span class="w">        </span><span class="o">[</span><span class="n">Amanda</span><span class="o">]</span>
<span class="n">Semantic</span><span class="w"> </span><span class="nf">Parse</span><span class="err">:</span><span class="w"> </span><span class="n">sibling</span><span class="p">(</span><span class="ss">&quot;Shirley&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;Edward&quot;</span><span class="p">).</span>
<span class="w">        </span><span class="n">daughter</span><span class="p">(</span><span class="ss">&quot;Henry&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;Amanda&quot;</span><span class="p">).</span><span class="w"> </span><span class="n">daughter</span><span class="p">(</span><span class="err">&quot;</span><span class="n">Henry</span>
</code></pre></div>

<p><sup id="fnref6:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>", "Michelle"). granddaughter("Kyle", " Amanda").</p>
<p>Story: [Raquel] and her brother [Casey] took her grandmother [Karen] to the store to buy a new dress. [Karen] and her husband [Kyle] just celebrated 10 years of marriage. [Karen ] loves her grandson, [Casey], and he loves her too.
Semantic Parse: brother("Raquel", "Casey"). grandmother("Raquel", "Karen"). husband(" Karen", "Kyle"). grandson("Karen", "Casey").</p>
<p>Story: [Allen]'s father, [Eric], bought him some ice cream. [Karen] was baking cookies for her grandson, [Allen]. [Allen]'s brother [ Arthur] came home from school, so she baked some extra for him, too. [Eric]'s son, [ Arthur], was ill and needed to be picked up at school. [Eric] hurried to his side.
Semantic Parse: father("Allen", "Eric"). grandson("Karen", "Allen"). brother("Allen", "Arthur"). son("Eric", "Arthur").</p>
<p>Story: [Karen] was spending the weekend with her grandson, [Eddie]. [Eddie]'s sister [ Michelle] was supposed to come too, but she was busy and could n't make it. [Theresa] took her daughter, [Michelle], out to High Tea yesterday afternoon. [Eddie]'s mother [ Theresa] baked brownies for dessert after they had dinner.
Semantic Parse: grandson("Karen", "Eddie"). sister("Eddie", "Michelle"). daughter(" Theresa", "Michelle"). mother("Eddie", " Theresa").</p>
<p>Story: [Input]
Semantic Parse:
We also use a variant of the above prompt to extract the gender of each person in a story. The prompt context is a bit simpler as there are only two genders. The examples are the same while the Semantic Parse result is simply replaced with the atomic facts about gender information. Below is the prompt to extract the gender of each person in a story where [Input] is replaced with the story in each test data instance.</p>
<div class="codehilite"><pre><span></span><code><span class="n">Given</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">story</span><span class="p">,</span><span class="w"> </span><span class="k">extract</span><span class="w"> </span><span class="k">atomic</span><span class="w"> </span><span class="n">facts</span><span class="w"> </span><span class="k">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">form</span>
<span class="w">    </span><span class="n">male</span><span class="p">(</span><span class="ss">&quot;Person&quot;</span><span class="p">)</span><span class="w"> </span><span class="ow">or</span><span class="w"> </span><span class="n">female</span><span class="p">(</span><span class="ss">&quot;Person&quot;</span><span class="p">)</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="k">every</span>
<span class="w">    </span><span class="n">person</span><span class="w"> </span><span class="n">that</span><span class="w"> </span><span class="n">appears</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">sentences</span><span class="p">.</span>
<span class="nl">Story</span><span class="p">:</span><span class="w"> </span><span class="o">[</span><span class="n">Verdie</span><span class="o">]</span><span class="w"> </span><span class="n">waved</span><span class="w"> </span><span class="n">good</span><span class="w"> </span><span class="n">bye</span><span class="w"> </span><span class="k">to</span><span class="w"> </span><span class="n">her</span><span class="w"> </span><span class="n">dad</span><span class="w"> </span><span class="o">[</span><span class="n">Henry</span>
<span class="n">    </span><span class="o">]</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="nf">day</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">went</span><span class="w"> </span><span class="k">next</span><span class="w"> </span><span class="n">door</span><span class="w"> </span><span class="k">with</span><span class="w"> </span><span class="n">her</span>
<span class="w">    </span><span class="n">sister</span><span class="w"> </span><span class="o">[</span><span class="n">Amanda</span><span class="o">]</span><span class="p">.</span><span class="w"> </span><span class="o">[</span><span class="n">Henry</span><span class="o">]</span><span class="s1">&#39;s daughter, [Amanda</span>
<span class="s1">    ], went to the city this weekend. She spent</span>
<span class="s1">    her time there visiting her grandfather, [</span>
<span class="s1">    Kyle], and had a wonderful time with him.</span>
<span class="s1">Semantic Parse: female(&quot;Verdie&quot;). male(&quot;Henry&quot;).</span>
<span class="s1">    female(&quot;Amanda&quot;). male(&quot;Kyle&quot;).</span>
<span class="s1">Story: [Michelle] was excited for today, its her</span>
<span class="s1">    daughter&#39;</span><span class="n">s</span><span class="p">,</span><span class="w"> </span><span class="o">[</span><span class="n">Theresa</span><span class="o">]</span><span class="p">,</span><span class="w"> </span><span class="n">spring</span><span class="w"> </span><span class="k">break</span><span class="p">.</span><span class="w"> </span><span class="n">She</span>
<span class="w">    </span><span class="n">will</span><span class="w"> </span><span class="n">finally</span><span class="w"> </span><span class="k">get</span><span class="w"> </span><span class="k">to</span><span class="w"> </span><span class="n">see</span><span class="w"> </span><span class="n">her</span><span class="p">.</span><span class="w"> </span><span class="o">[</span><span class="n">Michael</span><span class="o">]</span><span class="w"> </span><span class="n">was</span>
<span class="w">    </span><span class="n">busy</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">sent</span><span class="w"> </span><span class="n">his</span><span class="w"> </span><span class="n">wife</span><span class="p">,</span><span class="w"> </span><span class="o">[</span><span class="n">Marlene</span><span class="o">]</span><span class="p">,</span><span class="w"> </span><span class="n">instead</span><span class="p">.</span>
</code></pre></div>

<p>[Kristen] loved to care for her newborn child [Ronald]. [Eric]'s son is [Arthur]. Semantic Parse: female("Michelle"). female(" Theresa"). male("Michael"). female("Marlene "). female("Kristen"). male("Ronald"). male ("Eric"). male("Arthur").</p>
<p>Story: [Vernon] was present in the delivery room when his daughter [Raquel] was born, but when his daughter [Constance] was born he was too sick. [Vernon] and his daughter [ Margaret] went to the movies. [Constance], [ Margaret]'s sister, had to stay home as she was sick.
Semantic Parse: male("Vernon"). female("Raquel") . female("Constance"). female("Margaret").</p>
<p>Story: [Eric] who is [Carl]'s father grounded [ Carl] after finding out what [Carl] had done at school. [Ronald] was busy planning a 90 th birthday party for his aunt, [Theresa]. [ Eric] and his son [Carl] went to the park and saw [Eric]'s father [Kyle] there with his dog.
Semantic Parse: male("Eric"). male("Carl"). male ("Ronald"). female("Theresa"). male("Kyle").</p>
<p>Story: [Shirley] and [Edward] are siblings and best friends. They do everything together. [ Henry] walked his daughters [Amanda] and [ Michelle] to school. [Kyle] enjoys watching movies with his son's daughter. Her name is [Amanda].
Semantic Parse: female("Shirley"). male("Edward "). male("Henry"). female("Amanda"). female ("Michelle"). male("Kyle").</p>
<p>Story: [Raquel] and her brother [Casey] took her grandmother [Karen] to the store to buy a new dress. [Karen] and her husband [Kyle] just celebrated 10 years of marriage. [Karen ] loves her grandson, [Casey], and he loves her too.
Semantic Parse: female("Raquel"). male("Casey"). female("Karen"). male("Kyle").</p>
<p>Story: [Allen]'s father, [Eric], bought him some ice cream. [Karen] was baking cookies for her grandson, [Allen]. [Allen]'s brother [ Arthur] came home from school, so she baked some extra for him, too. [Eric]'s son, [ Arthur], was ill and needed to be picked up at school. [Eric] hurried to his side.
Semantic Parse: male("Allen"). male("Eric"). female("Karen"). male("Arthur").</p>
<p>Story: [Karen] was spending the weekend with her grandson, [Eddie]. [Eddie]'s sister [ Michelle] was supposed to come too, but she was busy and could n't make it. [Theresa] took her daughter, [Michelle], out to High Tea yesterday afternoon. [Eddie]'s mother [ Theresa] baked brownies for dessert after they had dinner.
Semantic Parse: female("Karen"). male("Eddie"). female("Michelle"). female("Theresa").</p>
<p>Story: [Input]
Semantic Parse:</p>
<p>For CLUTRR-S dataset, i.e., the simpler version of the CLUTRR dataset from DeepProbLog (Manhaeve et al., 2021) repository, there are also two prompts below to extract the family relations and genders from a story respectively. ${ }^{10}$ All example stories in both prompts are from the training data "data_a7d9402e/2.2,2.3_train.csv".</p>
<div class="codehilite"><pre><span></span><code><span class="n">Given</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">story</span><span class="p">,</span><span class="w"> </span><span class="k">extract</span><span class="w"> </span><span class="k">atomic</span><span class="w"> </span><span class="n">facts</span><span class="w"> </span><span class="k">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">form</span>
<span class="w">    </span><span class="n">relation</span><span class="p">(</span><span class="ss">&quot;Person&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;Person&quot;</span><span class="p">)</span><span class="w"> </span><span class="n">about</span><span class="w"> </span><span class="n">family</span>
<span class="w">    </span><span class="n">relationships</span><span class="w"> </span><span class="n">that</span><span class="w"> </span><span class="n">appear</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">sentences</span><span class="p">.</span>
<span class="nl">Story</span><span class="p">:</span><span class="w"> </span><span class="o">[</span><span class="n">Mervin</span><span class="o">]</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="o">[</span><span class="n">Robert</span><span class="o">]</span><span class="s1">&#39;s father. [Robert]</span>
<span class="s1">    is the father of [Jim]. [Jon] is [Robert]&#39;</span><span class="n">s</span>
<span class="w">    </span><span class="n">brother</span><span class="p">.</span><span class="w"> </span><span class="o">[</span><span class="n">Mervin</span><span class="o">]</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">father</span><span class="w"> </span><span class="k">of</span><span class="w"> </span><span class="o">[</span><span class="n">Jon</span><span class="o">]</span><span class="p">.</span>
<span class="n">Semantic</span><span class="w"> </span><span class="nf">Parse</span><span class="err">:</span><span class="w"> </span><span class="n">father</span><span class="p">(</span><span class="ss">&quot;Robert&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;Mervin&quot;</span><span class="p">).</span>
<span class="w">    </span><span class="n">father</span><span class="p">(</span><span class="ss">&quot;Jim&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;Robert&quot;</span><span class="p">).</span><span class="w"> </span><span class="n">brother</span><span class="p">(</span><span class="ss">&quot;Robert&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;</span>
<span class="ss">    Jon&quot;</span><span class="p">).</span><span class="w"> </span><span class="n">father</span><span class="p">(</span><span class="ss">&quot;Jon&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;Mervin&quot;</span><span class="p">).</span>
<span class="nl">Story</span><span class="p">:</span><span class="w"> </span><span class="o">[</span><span class="n">Brooke</span><span class="o">]</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="o">[</span><span class="n">Cheryl</span><span class="o">]</span><span class="s1">&#39;s sister. [Jon] is</span>
<span class="s1">    the father of [Brooke]. [Melissa] is [Jon]&#39;</span>
<span class="w">    </span><span class="n">s</span><span class="w"> </span><span class="n">mother</span><span class="p">.</span><span class="w"> </span><span class="o">[</span><span class="n">Jon</span><span class="o">]</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="o">[</span><span class="n">Cheryl</span><span class="o">]</span><span class="s1">&#39;s father.</span>
<span class="s1">Semantic Parse: sister(&quot;Cheryl&quot;, &quot;Brooke&quot;).</span>
<span class="s1">    father(&quot;Brooke&quot;, &quot;Jon&quot;). mother(&quot;Jon&quot;, &quot;</span>
<span class="s1">    Melissa&quot;). father(&quot;Cheryl&quot;, &quot;Jon&quot;).</span>
<span class="s1">Story: [Jon] is [Carol]&#39;</span><span class="n">s</span><span class="w"> </span><span class="n">brother</span><span class="p">.</span><span class="w"> </span><span class="o">[</span><span class="n">Carol</span><span class="o">]</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="o">[</span>
<span class="n">    Joyce</span><span class="o">]</span><span class="s1">&#39;s mother. [Helen] is [Carol]&#39;</span><span class="n">s</span>
<span class="w">    </span><span class="n">sister</span><span class="p">.</span><span class="w"> </span><span class="o">[</span><span class="n">Helen</span><span class="o">]</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">sister</span><span class="w"> </span><span class="k">of</span><span class="w"> </span><span class="o">[</span><span class="n">Jon</span><span class="o">]</span><span class="p">.</span>
<span class="n">Semantic</span><span class="w"> </span><span class="nf">Parse</span><span class="err">:</span><span class="w"> </span><span class="n">brother</span><span class="p">(</span><span class="ss">&quot;Carol&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;Jon&quot;</span><span class="p">).</span><span class="w"> </span><span class="n">mother</span>
<span class="w">    </span><span class="p">(</span><span class="ss">&quot;Joyce&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;Carol&quot;</span><span class="p">).</span><span class="w"> </span><span class="n">sister</span><span class="p">(</span><span class="ss">&quot;Carol&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;Helen&quot;</span><span class="p">)</span>
<span class="w">    </span><span class="p">.</span><span class="w"> </span><span class="n">sister</span><span class="p">(</span><span class="ss">&quot;Jon&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;Helen&quot;</span><span class="p">).</span>
<span class="nl">Story</span><span class="p">:</span><span class="w"> </span><span class="o">[</span><span class="n">Melissa</span><span class="o">]</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="o">[</span><span class="n">Glenn</span><span class="o">]</span><span class="s1">&#39;s grandmother. [</span>
<span class="s1">    Melissa] is the mother of [Calvin]. [Glenn]</span>
<span class="s1">    is a son of [Lila]. [Calvin] is [Glenn]&#39;</span><span class="n">s</span>
<span class="w">    </span><span class="n">father</span><span class="p">.</span>
<span class="n">Semantic</span><span class="w"> </span><span class="nf">Parse</span><span class="err">:</span><span class="w"> </span><span class="n">grandmother</span><span class="p">(</span><span class="ss">&quot;Glenn&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;Melissa&quot;</span><span class="p">).</span>
<span class="w">    </span><span class="n">mother</span><span class="p">(</span><span class="ss">&quot;Calvin&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;Melissa&quot;</span><span class="p">).</span><span class="w"> </span><span class="n">son</span><span class="p">(</span><span class="ss">&quot;Lila&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;</span>
<span class="ss">    Glenn&quot;</span><span class="p">).</span><span class="w"> </span><span class="n">father</span><span class="p">(</span><span class="ss">&quot;Glenn&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;Calvin&quot;</span><span class="p">).</span>
<span class="nl">Story</span><span class="p">:</span><span class="w"> </span><span class="o">[</span><span class="n">Margaret</span><span class="o">]</span><span class="w"> </span><span class="n">has</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">brother</span><span class="w"> </span><span class="n">named</span><span class="w"> </span><span class="o">[</span><span class="n">William</span><span class="o">]</span><span class="p">.</span>
<span class="w">    </span><span class="o">[</span><span class="n">William</span><span class="o">]</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="o">[</span><span class="n">Carol</span><span class="o">]</span><span class="s1">&#39;s son. [Margaret] is</span>
<span class="s1">    [Carol]&#39;</span><span class="n">s</span><span class="w"> </span><span class="n">daughter</span><span class="p">.</span><span class="w"> </span><span class="o">[</span><span class="n">Lila</span><span class="o">]</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">aunt</span><span class="w"> </span><span class="k">of</span>
<span class="w">    </span><span class="o">[</span><span class="n">William</span><span class="o">]</span><span class="p">.</span>
<span class="n">Semantic</span><span class="w"> </span><span class="nf">Parse</span><span class="err">:</span><span class="w"> </span><span class="n">brother</span><span class="p">(</span><span class="ss">&quot;Margaret&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;William&quot;</span><span class="p">).</span>
<span class="w">    </span><span class="n">son</span><span class="p">(</span><span class="ss">&quot;Carol&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;William&quot;</span><span class="p">).</span><span class="w"> </span><span class="n">daughter</span><span class="p">(</span><span class="ss">&quot;Carol&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;</span>
<span class="ss">    Margaret&quot;</span><span class="p">).</span><span class="w"> </span><span class="n">aunt</span><span class="p">(</span><span class="ss">&quot;William&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;Lila&quot;</span><span class="p">).</span>
<span class="nl">Story</span><span class="p">:</span><span class="w"> </span><span class="o">[</span><span class="n">Stephanie</span><span class="o">]</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">sister</span><span class="w"> </span><span class="k">of</span><span class="w"> </span><span class="o">[</span><span class="n">Lois</span><span class="o">]</span><span class="p">.</span><span class="w"> </span><span class="o">[</span><span class="n">Lois</span>
<span class="n">    </span><span class="o">]</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="o">[</span><span class="n">Theresa</span><span class="o">]</span><span class="s1">&#39;s sister. [Helen] is [Lois]&#39;</span>
<span class="w">    </span><span class="n">s</span><span class="w"> </span><span class="n">mother</span><span class="p">.</span><span class="w"> </span><span class="o">[</span><span class="n">Helen</span><span class="o">]</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="o">[</span><span class="n">Stephanie</span><span class="o">]</span><span class="s1">&#39;s mother.</span>
<span class="s1">Semantic Parse: sister(&quot;Lois&quot;, &quot;Stephanie&quot;).</span>
<span class="s1">    sister(&quot;Theresa&quot;, &quot;Lois&quot;). mother(&quot;Lois&quot;, &quot;</span>
<span class="s1">    Helen&quot;). mother(&quot;Stephanie&quot;, &quot;Helen&quot;).</span>
<span class="s1">Story: [Jon] is [Elias]&#39;</span><span class="n">s</span><span class="w"> </span><span class="n">brother</span><span class="p">.</span><span class="w"> </span><span class="o">[</span><span class="n">Michael</span><span class="o">]</span><span class="w"> </span><span class="k">is</span>
<span class="w">    </span><span class="n">a</span><span class="w"> </span><span class="n">son</span><span class="w"> </span><span class="k">of</span><span class="w"> </span><span class="o">[</span><span class="n">Helen</span><span class="o">]</span><span class="p">.</span><span class="w"> </span><span class="o">[</span><span class="n">Jon</span><span class="o">]</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">uncle</span><span class="w"> </span><span class="k">of</span><span class="w"> </span><span class="o">[</span>
<span class="n">    Michael</span><span class="o">]</span><span class="p">.</span><span class="w"> </span><span class="o">[</span><span class="n">Elias</span><span class="o">]</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">father</span><span class="w"> </span><span class="k">of</span><span class="w"> </span><span class="o">[</span><span class="n">Michael</span>
<span class="n">    </span><span class="o">]</span><span class="p">.</span>
<span class="n">Semantic</span><span class="w"> </span><span class="nf">Parse</span><span class="err">:</span><span class="w"> </span><span class="n">brother</span><span class="p">(</span><span class="ss">&quot;Elias&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;Jon&quot;</span><span class="p">).</span><span class="w"> </span><span class="n">son</span><span class="p">(</span><span class="ss">&quot;</span>
<span class="ss">    Helen&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;Michael&quot;</span><span class="p">).</span><span class="w"> </span><span class="n">uncle</span><span class="p">(</span><span class="ss">&quot;Michael&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;Jon&quot;</span><span class="p">).</span>
<span class="w">    </span><span class="n">father</span><span class="p">(</span><span class="ss">&quot;Michael&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;Elias&quot;</span><span class="p">).</span>
</code></pre></div>

<p><sup id="fnref7:0"><a class="footnote-ref" href="#fn:0">1</a></sup>Story: [Carol] has a son called [William]. [ Melissa] is the mother of [Jon]. [Jon] is the uncle of [William]. [Carol] has a brother named [Jon].
Semantic Parse: son("Carol", "William"). mother ("Jon", "Melissa"). uncle("William", "Jon"). brother("Carol", "Jon").</p>
<p>Story: [Robert] is the father of [Jim]. [Robert ] has a daughter called [Ashley]. [Elias] is [Robert]'s brother. [Elias] is the uncle of [Ashley].
Semantic Parse: father("Jim", "Robert"). daughter("Robert", "Ashley"). brother(" Robert", "Elias"). uncle("Ashley", "Elias").</p>
<p>Story: [Elias] is the father of [Carlos]. [ Elias] is the father of [Andrew]. [Andrew] is [Carlos]'s brother. [Jon] is a brother of [Elias].
Semantic Parse: father("Carlos", "Elias"). father("Andrew", "Elias"). brother("Carlos", "Andrew"). brother("Elias", "Jon").</p>
<p>Story: [Jon] is the father of [Ben]. [James] is [Kevin]'s brother. [Ben] is a brother of [ James]. [Jon] is [James]'s father.
Semantic Parse: father("Ben", "Jon"). brother(" Kevin", "James"). brother("James", "Ben"). father("James", "Jon").</p>
<p>Story: [Carol] has a sister named [Lila]. [ William] is [Carol]'s son. [Helen] is [Lila ]'s sister. [Lila] is [William]'s aunt.
Semantic Parse: sister("Carol", "Lila"). son(" Carol", "William"). sister("Lila", "Helen"). aunt("William", "Lila").</p>
<p>Story: [Calvin] is [Bruce]'s father. [Elias] is [Calvin]'s brother. [Calvin] is [Kira]'s father. [Kira] is [Bruce]'s sister.
Semantic Parse: father("Bruce", "Calvin"). brother("Calvin", "Elias"). father("Kira", " Calvin"). sister("Bruce", "Kira").</p>
<p>Story: [Carol] is a sister of [Helen]. [Carol] is [Carlos]'s aunt. [Lila] is [Carol]'s sister. [Carlos] is [Helen]'s son.
Semantic Parse: sister("Helen", "Carol"). aunt(" Carlos", "Carol"). sister("Carol", "Lila"). son("Helen", "Carlos").</p>
<p>Story: [Input]
Semantic Parse:
Note that, although the sentences in the CLUTRRS dataset is much simpler than those in CLUTRR dataset, we don't achieve $100 \%$ accuracy in GPT3 responses with the above long prompt. This is partially because the above prompt violates prompting strategy 3 in Section 3 as the order of names in a binary relation in sentences is mostly following "relationOf $(A, B)$ " instead of "relation $(B, A)$ ".</p>
<div class="codehilite"><pre><span></span><code><span class="nv">Given</span><span class="w"> </span><span class="nv">a</span><span class="w"> </span><span class="nv">story</span>,<span class="w"> </span><span class="nv">extract</span><span class="w"> </span><span class="nv">atomic</span><span class="w"> </span><span class="nv">facts</span><span class="w"> </span><span class="nv">of</span><span class="w"> </span><span class="nv">the</span><span class="w"> </span><span class="nv">form</span>
<span class="w">    </span><span class="nv">male</span><span class="ss">(</span><span class="s2">&quot;Person&quot;</span><span class="ss">)</span><span class="w"> </span><span class="nv">or</span><span class="w"> </span><span class="nv">female</span><span class="ss">(</span><span class="s2">&quot;Person&quot;</span><span class="ss">)</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="nv">every</span>
</code></pre></div>

<p>person that appears in the sentences.
Story: [Jon] is [Carol]'s brother. [Mervin] has a daughter called [Carol]. [Chantell] is a daughter of [Jon]. [Mervin] has a son called [Jon].
Semantic Parse: male("Jon"). female("Carol"). male("Mervin"). female("Chantell").</p>
<p>Story: [Melissa] is [Glenn]'s grandmother. [ Melissa] is the mother of [Calvin]. [Glenn] is a son of [Lila]. [Calvin] is [Glenn]'s father.
Semantic Parse: female("Melissa"). male("Glenn") . male("Calvin"). female("Lila").</p>
<p>Story: [Input]
Semantic Parse:</p>
<h2>C. 4 gSCAN</h2>
<p>For gSCAN dataset, there is only one prompt below to extract the command in each data instance. All example sequences are from the training data. ${ }^{11}$ The [Input] at the end of the prompt is replaced with the command in each test data instance.</p>
<div class="codehilite"><pre><span></span><code><span class="n">Please</span><span class="w"> </span><span class="nf">parse</span><span class="w"> </span><span class="k">each</span><span class="w"> </span><span class="k">sequence</span><span class="w"> </span><span class="k">of</span><span class="w"> </span><span class="n">words</span><span class="w"> </span><span class="k">into</span><span class="w"> </span><span class="n">facts</span><span class="p">.</span>
<span class="k">Sequence</span><span class="err">:</span><span class="w"> </span><span class="n">pull</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">yellow</span><span class="w"> </span><span class="n">small</span><span class="w"> </span><span class="n">circle</span>
<span class="n">Semantic</span><span class="w"> </span><span class="nf">Parse</span><span class="err">:</span><span class="w"> </span><span class="n">query</span><span class="p">(</span><span class="n">pull</span><span class="p">).</span><span class="w"> </span><span class="n">queryDesc</span><span class="p">(</span><span class="n">yellow</span><span class="p">).</span>
<span class="w">    </span><span class="n">queryDesc</span><span class="p">(</span><span class="n">small</span><span class="p">).</span><span class="w"> </span><span class="n">queryDesc</span><span class="p">(</span><span class="n">circle</span><span class="p">).</span>
<span class="k">Sequence</span><span class="err">:</span><span class="w"> </span><span class="n">push</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">big</span><span class="w"> </span><span class="nf">square</span>
<span class="n">Semantic</span><span class="w"> </span><span class="nf">Parse</span><span class="err">:</span><span class="w"> </span><span class="n">query</span><span class="p">(</span><span class="n">push</span><span class="p">).</span><span class="w"> </span><span class="n">queryDesc</span><span class="p">(</span><span class="n">big</span><span class="p">).</span>
<span class="w">    </span><span class="n">queryDesc</span><span class="p">(</span><span class="nf">square</span><span class="p">).</span>
<span class="k">Sequence</span><span class="err">:</span><span class="w"> </span><span class="n">push</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">green</span><span class="w"> </span><span class="n">small</span><span class="w"> </span><span class="nf">square</span><span class="w"> </span><span class="n">cautiously</span>
<span class="n">Semantic</span><span class="w"> </span><span class="nf">Parse</span><span class="err">:</span><span class="w"> </span><span class="n">query</span><span class="p">(</span><span class="n">push</span><span class="p">).</span><span class="w"> </span><span class="n">queryDesc</span><span class="p">(</span><span class="n">green</span><span class="p">).</span>
<span class="w">    </span><span class="n">queryDesc</span><span class="p">(</span><span class="n">small</span><span class="p">).</span><span class="w"> </span><span class="n">queryDesc</span><span class="p">(</span><span class="nf">square</span><span class="p">).</span><span class="w"> </span><span class="k">while</span><span class="p">(</span>
<span class="w">    </span><span class="n">cautiously</span><span class="p">).</span>
<span class="k">Sequence</span><span class="err">:</span><span class="w"> </span><span class="n">pull</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">circle</span><span class="w"> </span><span class="n">hesitantly</span>
<span class="n">Semantic</span><span class="w"> </span><span class="nf">Parse</span><span class="err">:</span><span class="w"> </span><span class="n">query</span><span class="p">(</span><span class="n">pull</span><span class="p">).</span><span class="w"> </span><span class="n">queryDesc</span><span class="p">(</span><span class="n">circle</span><span class="p">).</span>
<span class="w">    </span><span class="k">while</span><span class="p">(</span><span class="n">hesitantly</span><span class="p">).</span>
<span class="k">Sequence</span><span class="err">:</span><span class="w"> </span><span class="n">walk</span><span class="w"> </span><span class="k">to</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">yellow</span><span class="w"> </span><span class="n">big</span><span class="w"> </span><span class="n">cylinder</span><span class="w"> </span><span class="k">while</span>
<span class="w">    </span><span class="n">spinning</span>
<span class="n">Semantic</span><span class="w"> </span><span class="nf">Parse</span><span class="err">:</span><span class="w"> </span><span class="n">query</span><span class="p">(</span><span class="n">walk</span><span class="p">).</span><span class="w"> </span><span class="n">queryDesc</span><span class="p">(</span><span class="n">yellow</span><span class="p">).</span>
<span class="w">    </span><span class="n">queryDesc</span><span class="p">(</span><span class="n">big</span><span class="p">).</span><span class="w"> </span><span class="n">queryDesc</span><span class="p">(</span><span class="n">cylinder</span><span class="p">).</span><span class="w"> </span><span class="k">while</span><span class="p">(</span>
<span class="w">    </span><span class="n">spinning</span><span class="p">).</span>
<span class="k">Sequence</span><span class="err">:</span><span class="w"> </span><span class="n">push</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">big</span><span class="w"> </span><span class="nf">square</span><span class="w"> </span><span class="k">while</span><span class="w"> </span><span class="n">zigzagging</span>
<span class="n">Semantic</span><span class="w"> </span><span class="nf">Parse</span><span class="err">:</span><span class="w"> </span><span class="n">query</span><span class="p">(</span><span class="n">push</span><span class="p">).</span><span class="w"> </span><span class="n">queryDesc</span><span class="p">(</span><span class="n">big</span><span class="p">).</span>
<span class="w">    </span><span class="n">queryDesc</span><span class="p">(</span><span class="nf">square</span><span class="p">).</span><span class="w"> </span><span class="k">while</span><span class="p">(</span><span class="n">zigzagging</span><span class="p">).</span>
<span class="k">Sequence</span><span class="err">:</span><span class="w"> </span><span class="n">push</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">cylinder</span><span class="w"> </span><span class="n">hesitantly</span>
<span class="n">Semantic</span><span class="w"> </span><span class="nf">Parse</span><span class="err">:</span><span class="w"> </span><span class="n">query</span><span class="p">(</span><span class="n">push</span><span class="p">).</span><span class="w"> </span><span class="n">queryDesc</span><span class="p">(</span><span class="n">cylinder</span><span class="p">)</span>
<span class="w">    </span><span class="p">.</span><span class="w"> </span><span class="k">while</span><span class="p">(</span><span class="n">hesitantly</span><span class="p">).</span>
<span class="k">Sequence</span><span class="err">:</span><span class="w"> </span><span class="o">[</span><span class="n">Input</span><span class="o">]</span>
<span class="n">Semantic</span><span class="w"> </span><span class="nf">Parse</span><span class="err">:</span>
</code></pre></div>

<p><sup id="fnref8:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<h3>5.5 Pick\&amp;Place</h3>
<p>For the Pick\&amp;Place dataset, there are two prompts below to extract the atomic facts from the initial state and the goal state, respectively.</p>
<div class="codehilite"><pre><span></span><code><span class="n">Turn</span><span class="w"> </span><span class="k">each</span><span class="w"> </span><span class="n">sentence</span><span class="w"> </span><span class="k">into</span><span class="w"> </span><span class="n">an</span><span class="w"> </span><span class="k">atomic</span><span class="w"> </span><span class="n">fact</span><span class="w"> </span><span class="k">of</span><span class="w"> </span><span class="n">the</span>
<span class="w">    </span><span class="n">form</span><span class="w"> </span><span class="k">on</span><span class="p">(</span><span class="n">A</span><span class="p">,</span><span class="w"> </span><span class="n">B</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">).</span>
<span class="nl">Sentence</span><span class="p">:</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="n">red</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">on</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">yellow</span><span class="w"> </span><span class="n">bowl</span><span class="p">.</span>
<span class="n">Semantic</span><span class="w"> </span><span class="nf">Parse</span><span class="err">:</span><span class="w"> </span><span class="k">on</span><span class="p">(</span><span class="ss">&quot;red block&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;yellow bowl&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="mi">0</span><span class="p">).</span>
<span class="nl">Sentence</span><span class="p">:</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="n">violet</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">on</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">blue</span><span class="w"> </span><span class="n">block</span><span class="p">.</span>
<span class="n">Semantic</span><span class="w"> </span><span class="nf">Parse</span><span class="err">:</span><span class="w"> </span><span class="k">on</span><span class="p">(</span><span class="ss">&quot;violet block&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;blue block&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="mi">0</span><span class="p">).</span>
<span class="nl">Sentence</span><span class="p">:</span><span class="w"> </span><span class="o">[</span><span class="n">INPUT</span><span class="o">]</span>
<span class="n">Semantic</span><span class="w"> </span><span class="nf">Parse</span><span class="err">:</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="n">Turn</span><span class="w"> </span><span class="k">each</span><span class="w"> </span><span class="n">sentence</span><span class="w"> </span><span class="k">into</span><span class="w"> </span><span class="n">an</span><span class="w"> </span><span class="k">atomic</span><span class="w"> </span><span class="n">fact</span><span class="w"> </span><span class="k">of</span><span class="w"> </span><span class="n">the</span>
<span class="w">    </span><span class="n">form</span><span class="w"> </span><span class="k">on</span><span class="p">(</span><span class="n">A</span><span class="p">,</span><span class="w"> </span><span class="n">B</span><span class="p">).</span>
<span class="nl">Sentence</span><span class="p">:</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="n">red</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">on</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">yellow</span><span class="w"> </span><span class="n">bowl</span><span class="p">.</span>
<span class="n">Semantic</span><span class="w"> </span><span class="nf">Parse</span><span class="err">:</span><span class="w"> </span><span class="k">on</span><span class="p">(</span><span class="ss">&quot;red block&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;yellow bowl&quot;</span><span class="p">).</span>
<span class="nl">Sentence</span><span class="p">:</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="n">violet</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">on</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">blue</span><span class="w"> </span><span class="n">block</span><span class="p">.</span>
<span class="n">Semantic</span><span class="w"> </span><span class="nf">Parse</span><span class="err">:</span><span class="w"> </span><span class="k">on</span><span class="p">(</span><span class="ss">&quot;violet block&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;blue block&quot;</span><span class="p">)</span>
<span class="w">    </span><span class="p">.</span>
<span class="nl">Sentence</span><span class="p">:</span><span class="w"> </span><span class="o">[</span><span class="n">INPUT</span><span class="o">]</span>
<span class="n">Semantic</span><span class="w"> </span><span class="nf">Parse</span><span class="err">:</span>
</code></pre></div>

<p>For each sentence in the initial or goal state, we replace [INPUT] in the corresponding prompt above with this sentence and request GPT-3 to extract a single atomic fact. The union of these atomic facts extracted from all sentences is then used in the symbolic reasoner module to find an optimal plan.</p>
<p>For the GPT-3 baseline, we use the following prompt to let GPT-3 directly find a plan where [INPUT] at the end of the prompt is replaced with the initial and goal state of the queried data instance.</p>
<div class="codehilite"><pre><span></span><code><span class="nv">Find</span><span class="w"> </span><span class="nv">a</span><span class="w"> </span><span class="nv">shortest</span><span class="w"> </span><span class="nv">plan</span><span class="w"> </span><span class="nv">to</span><span class="w"> </span><span class="nv">move</span><span class="w"> </span><span class="nv">blocks</span><span class="w"> </span><span class="nv">from</span><span class="w"> </span><span class="nv">an</span>
<span class="w">    </span><span class="nv">initial</span><span class="w"> </span><span class="nv">state</span><span class="w"> </span><span class="nv">to</span><span class="w"> </span><span class="nv">a</span><span class="w"> </span><span class="nv">goal</span><span class="w"> </span><span class="nv">state</span>.<span class="w"> </span><span class="nv">Note</span><span class="w"> </span><span class="nv">that</span><span class="w"> </span><span class="nv">you</span>
<span class="w">    </span><span class="nv">cannot</span><span class="w"> </span><span class="nv">move</span><span class="w"> </span><span class="nv">a</span><span class="w"> </span><span class="nv">block</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="nv">anything</span><span class="w"> </span><span class="nv">is</span><span class="w"> </span><span class="nv">on</span><span class="w"> </span><span class="nv">it</span>.
<span class="w">    </span><span class="nv">You</span><span class="w"> </span><span class="nv">cannot</span><span class="w"> </span><span class="nv">move</span><span class="w"> </span><span class="nv">a</span><span class="w"> </span><span class="nv">block</span><span class="w"> </span><span class="nv">onto</span><span class="w"> </span><span class="nv">a</span><span class="w"> </span><span class="nv">target</span><span class="w"> </span><span class="nv">block</span>
<span class="w">    </span><span class="nv">or</span><span class="w"> </span><span class="nv">bowl</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="nv">there</span><span class="w"> </span><span class="nv">is</span><span class="w"> </span><span class="nv">anything</span><span class="w"> </span><span class="nv">is</span><span class="w"> </span><span class="nv">on</span><span class="w"> </span><span class="nv">the</span>
<span class="w">    </span><span class="nv">target</span><span class="w"> </span><span class="nv">block</span><span class="w"> </span><span class="nv">or</span><span class="w"> </span><span class="nv">bowl</span>.<span class="w"> </span><span class="nv">At</span><span class="w"> </span><span class="nv">most</span><span class="w"> </span><span class="nv">two</span><span class="w"> </span><span class="nv">blocks</span><span class="w"> </span><span class="nv">can</span>
<span class="w">    </span><span class="nv">be</span><span class="w"> </span><span class="nv">placed</span><span class="w"> </span><span class="nv">in</span><span class="w"> </span><span class="nv">the</span><span class="w"> </span><span class="nv">same</span><span class="w"> </span><span class="nv">bowl</span><span class="w"> </span><span class="nv">with</span><span class="w"> </span><span class="nv">one</span><span class="w"> </span><span class="nv">on</span><span class="w"> </span><span class="nv">top</span>
<span class="w">    </span><span class="nv">of</span><span class="w"> </span><span class="nv">the</span><span class="w"> </span><span class="nv">other</span>.
\#<span class="w"> </span><span class="nv">Initial</span><span class="w"> </span><span class="nv">State</span>:
<span class="nv">Nothing</span><span class="w"> </span><span class="nv">is</span><span class="w"> </span><span class="nv">on</span><span class="w"> </span><span class="nv">the</span><span class="w"> </span><span class="nv">green</span><span class="w"> </span><span class="nv">bowl</span>.
<span class="nv">The</span><span class="w"> </span><span class="nv">violet</span><span class="w"> </span><span class="nv">block</span><span class="w"> </span><span class="nv">is</span><span class="w"> </span><span class="nv">on</span><span class="w"> </span><span class="nv">the</span><span class="w"> </span><span class="nv">blue</span><span class="w"> </span><span class="nv">bowl</span>.
<span class="nv">The</span><span class="w"> </span><span class="nv">blue</span><span class="w"> </span><span class="nv">block</span><span class="w"> </span><span class="nv">is</span><span class="w"> </span><span class="nv">on</span><span class="w"> </span><span class="nv">the</span><span class="w"> </span><span class="nv">violet</span><span class="w"> </span><span class="nv">bowl</span>.
<span class="nv">The</span><span class="w"> </span><span class="nv">green</span><span class="w"> </span><span class="nv">block</span><span class="w"> </span><span class="nv">is</span><span class="w"> </span><span class="nv">on</span><span class="w"> </span><span class="nv">the</span><span class="w"> </span><span class="nv">blue</span><span class="w"> </span><span class="nv">block</span>.
\#<span class="w"> </span><span class="nv">Goal</span><span class="w"> </span><span class="nv">State</span>:
<span class="nv">The</span><span class="w"> </span><span class="nv">violet</span><span class="w"> </span><span class="nv">block</span><span class="w"> </span><span class="nv">is</span><span class="w"> </span><span class="nv">on</span><span class="w"> </span><span class="nv">the</span><span class="w"> </span><span class="nv">green</span><span class="w"> </span><span class="nv">bowl</span>.
<span class="nv">The</span><span class="w"> </span><span class="nv">green</span><span class="w"> </span><span class="nv">block</span><span class="w"> </span><span class="nv">is</span><span class="w"> </span><span class="nv">on</span><span class="w"> </span><span class="nv">the</span><span class="w"> </span><span class="nv">violet</span><span class="w"> </span><span class="nv">block</span>.
<span class="nv">The</span><span class="w"> </span><span class="nv">blue</span><span class="w"> </span><span class="nv">block</span><span class="w"> </span><span class="nv">is</span><span class="w"> </span><span class="nv">on</span><span class="w"> </span><span class="nv">the</span><span class="w"> </span><span class="nv">blue</span><span class="w"> </span><span class="nv">bowl</span>.
</code></pre></div>

<p>Nothing is on the violet bowl.
Plan:</p>
<ol>
<li>Move the violet block onto the green bowl.</li>
<li>Move the green block onto the violet block.</li>
<li>Move the blue block onto the blue bowl.
# Initial State:
Nothing is on the blue bowl.
The yellow block is on the green bowl.
The green block is on the violet bowl.
The violet block is on the green block.
The blue block is on the yellow bowl.
The red block is on the blue block.
# Goal State:
The yellow block is on the blue bowl.
The green block is on the yellow block.
The red block is on the green bowl.
Nothing is on the violet bowl.
The blue block is on the yellow bowl.
The violet block is on the blue block.
Plan:</li>
<li>Move the yellow block onto the blue bowl.</li>
<li>Move the red block onto the green bowl.</li>
<li>Move the violet block onto the blue block.</li>
<li>Move the green block onto the yellow block.
[INPUT]
Plan:</li>
</ol>
<h2>D GPT-3 Errors in Semantic Parsing</h2>
<p>In this section, we group and record the errors in the GPT-3 responses in tables where each row records a 3-tuple $\langle$ dataset, sentence(s), GPT-3 response $\rangle$. In this section, we list the following.</p>
<ul>
<li>all 21 errors for the CLUTRR 1.3 dataset with text-davinci-003;</li>
<li>the single mistake in the first 100 data instances for every $k \in{1, \ldots, 10}$ in the StepGame dataset with text-davinci-002.</li>
</ul>
<h2>D. 1 Argument misorder</h2>
<p>A common mistake in the GPT-3 response is that the relation and arguments for an atom are correctly extracted, but the order of the arguments is incorrect. Such mistakes can be greatly alleviated by proper few-shot prompting where the orders of arguments in the example target atoms follow their orders in the stories.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">CLUTRR <br> 1.3</th>
<th style="text-align: left;">[Erasmus] bought to dress <br> for his father [Joeseph]</th>
<th style="text-align: left;">father("Joeseph", <br> "Erasmus")</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">CLUTRR <br> 1.3</td>
<td style="text-align: left;">[Baldwin] bought to dress <br> for his father [Sidney]</td>
<td style="text-align: left;">father("Sidney", <br> "Baldwin")</td>
</tr>
<tr>
<td style="text-align: left;">CLUTRR <br> 1.3</td>
<td style="text-align: left;">[Elizabeth] is the uncle of <br> $[$ Leopold].</td>
<td style="text-align: left;">uncle("Elizabeth", <br> "Leopold")</td>
</tr>
</tbody>
</table>
<p>There are only 3 errors in CLUTRR 1.3 due to argument misorder. The first 2 mistakes are indeed due to their missing periods at the end of the sentences - if we simply add the periods back, their GPT-3 responses would become correct.</p>
<h2>D. 2 Wrong relation</h2>
<p>Sometimes the arguments are correct, but the relations extracted by GPT-3 are incorrect or cannot be recognized by the ASP program.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">CLUTRR <br> 1.3</th>
<th style="text-align: left;">[Leila] and [Enoch] have <br> been married for 35 years.</th>
<th style="text-align: left;">married("Leila", <br> "Enoch")</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: left;">[Lottie] and her grand- <br> sons [Clinton] and <br> [Enoch] picked berries <br> from the garden.</td>
<td style="text-align: left;">grandsons( <br> "Lottie", "Clin- <br> ton") grand- <br> sons( "Lottie", <br> "Enoch")</td>
</tr>
<tr>
<td style="text-align: center;">CLUTRR <br> 1.3</td>
<td style="text-align: left;">[Felix] loved going to <br> the store with his mom <br> [Christena].</td>
<td style="text-align: left;">mom("Felix", <br> "Christena")</td>
</tr>
<tr>
<td style="text-align: center;">CLUTRR <br> 1.3</td>
<td style="text-align: left;">[Archibald] asked his fa- <br> ther, [Abraham], to watch <br> over his two sons, [Jus- <br> tus] and [Merle], for the <br> weekend.</td>
<td style="text-align: left;">sons( <br> "Archibald", <br> "Justus", <br> "Merle")</td>
</tr>
<tr>
<td style="text-align: center;">StepGame</td>
<td style="text-align: left;">If E is the center of a <br> clock face, H is located <br> between 2 and 3.</td>
<td style="text-align: left;">right("H", "E")</td>
</tr>
</tbody>
</table>
<p>These kinds of mistake may be resolved by restricting the space of possible relations. For example, the mistakes in the first four rows can be resolved by simply adding the sentence "Use spouse("Person", "Person") if two persons are couples." in the prompt.</p>
<h2>D. 3 Ambiguious or incorrect co-reference</h2>
<table>
<thead>
<tr>
<th style="text-align: center;">CLUTRR <br> 1.3</th>
<th style="text-align: left;">[Katherine] was eating <br> lunch with his son <br> [Daniel] and his wife <br> [Adelle].</th>
<th style="text-align: left;">son("Katherine", <br> "Daniel") <br> wife("Daniel", <br> "Adelle")</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">CLUTRR <br> 1.3</td>
<td style="text-align: left;">[Sylvester] and his son <br> [Rollie] went to his <br> mother [Ottilia]'s home</td>
<td style="text-align: left;">son("Sylvester", <br> "Rollie") <br> mother("Rollie", <br> "Ottilia")</td>
</tr>
<tr>
<td style="text-align: center;">CLUTRR <br> 1.3</td>
<td style="text-align: left;">[Elsie] and [Lewis] did <br> the Father daughter dance <br> at the recital and his wife <br> [Dollie] was so happy she <br> cried</td>
<td style="text-align: left;">father("Lewis", <br> "Dollie") <br> wife("Lewis", <br> "Dollie")</td>
</tr>
</tbody>
</table>
<h2>D. 4 Anonymous argument</h2>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{9}$ The original CLUTRR data is available in https:// github.com/facebookresearch/clutrr.&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref4:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref5:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref6:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref7:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref8:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>