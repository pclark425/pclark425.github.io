<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-8397 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-8397</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-8397</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-149.html">extraction-schema-149</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including mechanisms, representations, probing results, interventions, performance, and error analysis.</div>
                <p><strong>Paper ID:</strong> paper-259309406</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2306.17844v2.pdf" target="_blank">The Clock and the Pizza: Two Stories in Mechanistic Explanation of Neural Networks</a></p>
                <p><strong>Paper Abstract:</strong> Do neural networks, trained on well-understood algorithmic tasks, reliably rediscover known algorithms for solving those tasks? Several recent studies, on tasks ranging from group arithmetic to in-context linear regression, have suggested that the answer is yes. Using modular addition as a prototypical problem, we show that algorithm discovery in neural networks is sometimes more complex. Small changes to model hyperparameters and initializations can induce the discovery of qualitatively different algorithms from a fixed training set, and even parallel implementations of multiple such algorithms. Some networks trained to perform modular addition implement a familiar Clock algorithm; others implement a previously undescribed, less intuitive, but comprehensible procedure which we term the Pizza algorithm, or a variety of even more complex procedures. Our results show that even simple learning problems can admit a surprising diversity of solutions, motivating the development of new tools for characterizing the behavior of neural networks across their algorithmic phase space.</p>
                <p><strong>Cost:</strong> 0.02</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e8397.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e8397.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including mechanisms, representations, probing results, interventions, performance, and error analysis.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Clock</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Clock algorithm for modular addition</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Represents tokens as 2D circular (Fourier) embeddings E_t ≈ [cos(w_k t), sin(w_k t)], adds polar angles (a+b) via multiplicative interactions (implemented using attention), and scores candidates with dot products giving logits Q_clock = cos(w_k(a+b-c)).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Transformer models trained on modular addition (p=59), e.g. Model B</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>One-layer ReLU transformer with attention (Model B). Default width d=128, 4 attention heads, MLP with 4d hidden units, trained with AdamW (lr=0.001, weight decay=2) for 20k epochs on modular-addition dataset (p=59, 80% train / 20% val).</td>
                        </tr>
                        <tr>
                            <td><strong>arithmetic_task_type</strong></td>
                            <td>Modular addition (a + b = c (mod p)), p = 59</td>
                        </tr>
                        <tr>
                            <td><strong>mechanism_or_representation</strong></td>
                            <td>Circular (angle-based) embeddings encoding token id as an angle; attention (multiplicative interactions) implements angle addition/multiplication; output unembedding matches circular basis so logits follow cos(w_k(a + b − c)).</td>
                        </tr>
                        <tr>
                            <td><strong>probing_or_intervention_method</strong></td>
                            <td>Principal component visualization of embeddings; circle isolation (rank-2 PC truncation); gradient projection onto top PCs; measuring gradient asymmetricity; ablation of attention (interpolating attention rate α toward constant attention).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Model B typically attains 100% validation accuracy on the full task. Measured metrics: gradient symmetricity ≈ 33.36% (asymmetric), distance irrelevance ≈ 0.85 (high, indicating logits independent of a−b). After circle isolation retaining first six PCs Model B retains 100% accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>error_types_or_failure_modes</strong></td>
                            <td>Clock solutions are not strongly dependent on a−b and therefore do not exhibit the antipodal collapse failure mode characteristic of Pizza; classification imperfections can appear after extreme parameter modifications (e.g., isolating only two PCs), but clock is robust in standard trained models with attention.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_for_mechanism</strong></td>
                            <td>Top-PC visualization shows embeddings lying on a circle; gradient asymmetry (∇_{E_a} Q ≠ ∇_{E_b} Q) consistent with multiplicative interaction; distance irrelevance high (logits invariant to a−b); circle-isolated logits match cos(w_k(a+b−c)) which explains much of the model's behavior.</td>
                        </tr>
                        <tr>
                            <td><strong>counterexamples_or_challenges</strong></td>
                            <td>Small architectural/hyperparameter changes (e.g., removing/weakening attention) cause models to implement qualitatively different algorithms (Pizza or non-circular algorithms). Some models ensemble multiple parallel circular components producing mixed/hybrid behaviors.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Clock and the Pizza: Two Stories in Mechanistic Explanation of Neural Networks', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8397.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e8397.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including mechanisms, representations, probing results, interventions, performance, and error analysis.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Pizza</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Pizza algorithm for modular addition</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Embeds tokens on a circle but operates on the interior: averages embeddings E_ab = (E_a + E_b)/2, maps that midpoint into a vector proportional to |cos(w_k (a−b)/2)|·(cos(w_k (a+b)), sin(w_k (a+b))) using ReLU/absolute-like nonlinearity, and scores outputs with a dot product yielding Q_pizza = |cos(w_k(a−b)/2)| cos(w_k(a+b−c)).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Transformer/MLP models trained on modular addition (p=59), notably Model A (constant-attention transformer / MLP-like)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Model A: one-layer ReLU transformer with constant attention (equivalently a ReLU MLP), default width d=128; embeddings and network parameters are learned; trained with same optimizer/hyperparams as other experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>arithmetic_task_type</strong></td>
                            <td>Modular addition (a + b = c (mod p)), p = 59</td>
                        </tr>
                        <tr>
                            <td><strong>mechanism_or_representation</strong></td>
                            <td>Uses the vector mean (midpoint) of two circular embeddings; a symmetric nonlinearity (absolute-value-like effect implemented via ReLU combinations) produces a multiplicative amplitude factor |cos(w_k (a−b)/2)| times an angle-dependent vector encoding (a+b); final dot product with output embedding yields logits dependent on both a+b and a−b.</td>
                        </tr>
                        <tr>
                            <td><strong>probing_or_intervention_method</strong></td>
                            <td>Gradient symmetricity metric (cosine similarity of ∂Q/∂E_a and ∂Q/∂E_b); circle isolation by truncating embedding matrix to pairs of principal components (rank-2 approximations); computing fraction variance explained (FVE) of closed-form Pizza formula against actual logits; aligned-weight inspection in linear models; ablating/altering attention via attention-rate interpolation.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Model A attains high/100% validation accuracy in full models. Measured diagnostics: gradient symmetricity ≈ 99.37% (highly symmetric), distance irrelevance ≈ 0.17 (low, indicating strong dependence of correct logits on a−b). After isolating a single 2D circle, Model A accuracy can drop to ~32.8%; retaining first six PCs (three circles) raises overall accuracy to ~91.4%. Table 2: Q_pizza explains ≈99.18% FVE of isolated logits (examples shown).</td>
                        </tr>
                        <tr>
                            <td><strong>error_types_or_failure_modes</strong></td>
                            <td>Antipodal or near-antipodal input pairs cause the mean vector to collapse toward origin (small norm), making pizza slices ambiguous and causing misclassification. Pizza's extra multiplicative factor |cos((a−b)/2)| makes accuracy dependent on a−b. To compensate, networks often implement multiple 'accompanying' pizzas or ensemble circles.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_for_mechanism</strong></td>
                            <td>High gradient symmetricity (∂Q/∂E_a ≈ ∂Q/∂E_b) rules out multiplicative (clock-like) solutions and matches the symmetric functional form shown in Lemma A.1; circle-isolated logits match the analytic pizza formula with very high FVE; aligned-weight analysis in linear models reproduces the pizza computation; pizza-like patterns appear early in training and in models with weak/absent attention.</td>
                        </tr>
                        <tr>
                            <td><strong>counterexamples_or_challenges</strong></td>
                            <td>Pizza is sensitive to antipodal failures; networks often form accompanying pizzas to patch these errors but these may be pruned away later; some networks with attention or larger widths prefer Clock instead; non-circular algorithms and hybrid mixtures of Pizza/Clock also appear, showing the solution is not unique.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Clock and the Pizza: Two Stories in Mechanistic Explanation of Neural Networks', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8397.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e8397.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including mechanisms, representations, probing results, interventions, performance, and error analysis.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Accompanying Pizza</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Accompanying (complementary) Pizza circles</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Secondary pizza circles that complement primary pizzas by rearranging token adjacency so that near-antipodal pairs on the primary pizza become non-antipodal on the accompanying pizza, thereby correcting pizza-specific antipodal failure modes.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Transformer/MLP models trained on modular addition (p=59), observed in Model A</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Additional circular principal-component embeddings (different angular spacing δ') learned in the same embedding matrix; these accompanying circles may be weaker in final prediction after pruning but are visible in the embedding geometry.</td>
                        </tr>
                        <tr>
                            <td><strong>arithmetic_task_type</strong></td>
                            <td>Modular addition (a + b = c (mod p)), p = 59</td>
                        </tr>
                        <tr>
                            <td><strong>mechanism_or_representation</strong></td>
                            <td>A second circle with different adjacency spacing (δ_1 = 2 δ_2 (mod p) relationship) reorders tokens so that previously near-antipodal inputs are separable; the accompanying pizza computes logits similarly (dot products with its own output embedding basis) focused on the formerly hard cases.</td>
                        </tr>
                        <tr>
                            <td><strong>probing_or_intervention_method</strong></td>
                            <td>Detected via circle isolation (PCA rank-2 isolations) and visualizing multiple isolated circles; performance measured by isolating each circle and computing accuracy and logit patterns.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Observed that primary pizzas #1/#2/#3 can reach ~99.7% accuracy (when combined), while accompanying pizzas #4/#5/#6 individually yield ~16.7% accuracy; combining all six circles in Model A embedding restores full 100% accuracy in that experiment.</td>
                        </tr>
                        <tr>
                            <td><strong>error_types_or_failure_modes</strong></td>
                            <td>Accompanying pizzas by themselves can be weak predictors (low individual accuracy) and may be pruned during training; they primarily serve to patch antipodal errors of primary pizzas and may not strongly contribute to final predictions after pruning.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_for_mechanism</strong></td>
                            <td>Visualization after circle isolation shows complementary logit patterns between accompanied and accompanying pizzas; experiments combining multiple circles recover accuracy lost when using a single circle; hypothesized training dynamics (lottery ticket + pruning) account for their transient support role.</td>
                        </tr>
                        <tr>
                            <td><strong>counterexamples_or_challenges</strong></td>
                            <td>Although accompanying pizzas can patch antipodal failures, they are not always strongly used in final prediction due to weight decay/pruning dynamics; they do not always fully resolve all pizza failure modes without ensembling multiple solutions.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Clock and the Pizza: Two Stories in Mechanistic Explanation of Neural Networks', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8397.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e8397.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including mechanisms, representations, probing results, interventions, performance, and error analysis.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Model A (constant-attention / MLP-like)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Model A: one-layer ReLU transformer with constant attention (equivalently a ReLU MLP)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A one-layer transformer where attention is replaced by a constant all-ones matrix (no content-dependent attention), making the model effectively linear layers + ReLU; in this setup networks preferentially learn Pizza-like solutions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Model A (constant-attention transformer / MLP)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>One-layer ReLU transformer with attention replaced by all-ones (attention rate α=0), width default d=128, 4 heads (dimensions ⌊d/4⌋), MLP size 4d, trained with AdamW, 20k epochs, dataset p=59.</td>
                        </tr>
                        <tr>
                            <td><strong>arithmetic_task_type</strong></td>
                            <td>Modular addition (a + b = c (mod p)), p=59</td>
                        </tr>
                        <tr>
                            <td><strong>mechanism_or_representation</strong></td>
                            <td>Learns circular embeddings in PCs but computes via symmetric midpoint-based pizza circuits that exploit absolute-value-like nonlinearity (ReLU) rather than multiplicative attention; often ensembles multiple pizza circles.</td>
                        </tr>
                        <tr>
                            <td><strong>probing_or_intervention_method</strong></td>
                            <td>Gradient symmetricity measurement (s_g ≈ 0.9937), distance irrelevance (q ≈ 0.17), circle isolation (PC truncation), FVE comparison between Pizza and Clock formulae, aligning weight matrices in linear variants, removing non-functional ReLU to test circuit structure.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Full trained Model A reaches high/100% validation accuracy in many runs. When isolated to only the first two PCs (one circle) accuracy drops to ~32.8%; retaining first six PCs (three circles) yields ~91.4% accuracy. Pizza formula explains ≈99.18% FVE of isolated logits (Table 2).</td>
                        </tr>
                        <tr>
                            <td><strong>error_types_or_failure_modes</strong></td>
                            <td>Strong sensitivity to (near-)antipodal inputs causing norm collapse and misclassification when relying on a single pizza circle; requires multiple circles/accompanying pizzas to reach robust accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_for_mechanism</strong></td>
                            <td>High gradient symmetricity consistent with symmetric two-input function; pizza formula matches model logits with high FVE; principal-component visualizations show multiple circular components; aligned-weight analysis in linear analogues reproduces pizza-like linear combos.</td>
                        </tr>
                        <tr>
                            <td><strong>counterexamples_or_challenges</strong></td>
                            <td>Some Model A runs produce additional accompanying pizzas of low final importance (pruned); other architectures (with stronger attention or larger width) switch to Clock or hybrid solutions; circle isolation can dramatically reduce accuracy, revealing hidden ensembling.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Clock and the Pizza: Two Stories in Mechanistic Explanation of Neural Networks', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8397.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e8397.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including mechanisms, representations, probing results, interventions, performance, and error analysis.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Model B (attention transformer)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Model B: standard one-layer ReLU transformer with content-dependent attention</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A standard one-layer ReLU transformer with learned attention (α=1 in attention-rate interpolation) that preferentially implements the Clock algorithm and shows asymmetric gradients consistent with multiplicative computation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Model B (one-layer transformer with attention)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>One-layer ReLU transformer with learned attention (post-softmax), width d=128 by default, 4 heads, trained with AdamW 20k epochs on modular-addition p=59.</td>
                        </tr>
                        <tr>
                            <td><strong>arithmetic_task_type</strong></td>
                            <td>Modular addition (a + b = c (mod p)), p=59</td>
                        </tr>
                        <tr>
                            <td><strong>mechanism_or_representation</strong></td>
                            <td>Circular embeddings; attention enables multiplicative-like interaction to compute angle addition; asymmetric gradients reflect different roles for a and b in multiplicative/attention computation.</td>
                        </tr>
                        <tr>
                            <td><strong>probing_or_intervention_method</strong></td>
                            <td>Same as other models: PCA/circle isolation, gradient projection onto top PCs (shows asymmetry), distance irrelevance metric (high), ablation via reducing attention rate α which induces phase transitions to Pizza.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Typically achieves 100% validation accuracy. Diagnostics: gradient symmetricity ≈ 33.36% (asymmetric), distance irrelevance ≈ 0.85 (high). Circle-isolated models retaining first six PCs keep 100% accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>error_types_or_failure_modes</strong></td>
                            <td>Less susceptible to pizza-specific antipodal collapse; nevertheless, network can exhibit fluctuations in logits after severe parameter modifications (e.g., isolating PCs) due to imperfect classification stage.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_for_mechanism</strong></td>
                            <td>Asymmetric gradients (∇_{E_a} Q ≠ ∇_{E_b} Q) consistent with multiplication; circle-shaped embeddings and matching unembedding basis; high distance irrelevance indicating Q does not depend on a−b; phase transition experiments show moving α toward 0 diminishes clock behavior.</td>
                        </tr>
                        <tr>
                            <td><strong>counterexamples_or_challenges</strong></td>
                            <td>With reduced attention strength or increased linear-layer capacity (wider models), Model B-like networks can switch to Pizza or hybrid algorithms, indicating lack of uniqueness of learned algorithm.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Clock and the Pizza: Two Stories in Mechanistic Explanation of Neural Networks', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8397.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e8397.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including mechanisms, representations, probing results, interventions, performance, and error analysis.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Circle isolation (PC truncation)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Circle isolation via principal-component rank-2 truncation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A probing intervention that replaces the embedding matrix by rank-2 approximations (keeping specific PC pairs) to isolate individual circular components of the learned embedding and reveal which circle(s) implement particular algorithmic variants.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Transformer/linear models trained on modular addition (p=59) used in this paper</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Post-training intervention: replace learned embedding matrix E with rank-2 matrices built from selected principal-component pairs (first and second PC, third and fourth, etc.) and evaluate model logits/accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>arithmetic_task_type</strong></td>
                            <td>Diagnostic applied to modular addition models (p=59)</td>
                        </tr>
                        <tr>
                            <td><strong>mechanism_or_representation</strong></td>
                            <td>By isolating 2D circular subspaces, one can test whether a given circle implements Clock, Pizza, or a weak/incorrect solution; reveals existence of multiple parallel circles (ensembling) and accompanying pizzas.</td>
                        </tr>
                        <tr>
                            <td><strong>probing_or_intervention_method</strong></td>
                            <td>Direct weight intervention: truncate embedding matrix to specified PC pairs and recompute logits; compute accuracy, FVE of analytic formulas (Pizza/Clock) against model logits on isolated circle.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Applying circle isolation to Model A: single-circle isolation (first 2 PCs) yields ~32.8% accuracy; retaining first 6 PCs yields ~91.4%. Model B retains 100% when truncated to first six PCs. FVE: Pizza formula explains ~99% of variance on isolated Model A circles while Clock explains ~75% (Table 2, example numbers).</td>
                        </tr>
                        <tr>
                            <td><strong>error_types_or_failure_modes</strong></td>
                            <td>Isolating only one circle often exposes pizza's antipodal failure modes and can dramatically reduce accuracy if the model relies on ensembling multiple circles to correct errors.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_for_mechanism</strong></td>
                            <td>High FVE of Pizza formula on isolated circles and corresponding logit patterns demonstrate that specific 2D components are executing pizza-like computations; presence of multiple useful circles indicates ensembling of solutions.</td>
                        </tr>
                        <tr>
                            <td><strong>counterexamples_or_challenges</strong></td>
                            <td>Circle isolation is destructive and can remove corrective components leading to large accuracy changes; it also assumes principal components align with functional circles, which may fail for non-circular algorithms.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Clock and the Pizza: Two Stories in Mechanistic Explanation of Neural Networks', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8397.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e8397.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including mechanisms, representations, probing results, interventions, performance, and error analysis.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Gradient symmetricity metric</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Gradient symmetricity (s_g)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A diagnostic that measures cosine similarity between gradients of the output logit wrt the two input embeddings (∂Q/∂E_a and ∂Q/∂E_b) averaged over examples; high symmetry indicates symmetric functions like Pizza, low symmetry indicates multiplicative/clock-like operations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Diagnostic applied to models trained on modular addition (p=59)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Compute gradients of chosen logits with respect to input embeddings, project onto top principal components (first 6 used), compute cosine similarity and average across sample set S (size 100 in experiments).</td>
                        </tr>
                        <tr>
                            <td><strong>arithmetic_task_type</strong></td>
                            <td>Diagnostic for modular addition solutions</td>
                        </tr>
                        <tr>
                            <td><strong>mechanism_or_representation</strong></td>
                            <td>A high s_g (~1) implies the function is symmetric in inputs (consistent with sum-of-symmetric basis functions and Pizza-like formula); low s_g implies asymmetry consistent with multiplicative interactions (Clock).</td>
                        </tr>
                        <tr>
                            <td><strong>probing_or_intervention_method</strong></td>
                            <td>Gradient computation and projection onto top PCs; used to classify models (e.g., Model A s_g ≈ 0.9937, Model B s_g ≈ 0.3336).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Reported values: Model A (Pizza) s_g ≈ 99.37% (near 1); Model B (Clock) s_g ≈ 33.36%. Across experiments s_g strongly correlates with Pizza vs Clock regimes.</td>
                        </tr>
                        <tr>
                            <td><strong>error_types_or_failure_modes</strong></td>
                            <td>s_g alone can be ambiguous in hybrid models; when metrics conflict, distance irrelevance is treated as decisive for Pizza detection but s_g rules out Clock.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_for_mechanism</strong></td>
                            <td>High s_g observed empirically in models whose logits match Pizza formula; theoretical lemma (A.1) shows symmetric linear combinations of cos/sin lead to factorization with cos((x−y)/2), consistent with Pizza.</td>
                        </tr>
                        <tr>
                            <td><strong>counterexamples_or_challenges</strong></td>
                            <td>Local linear/asymmetric behavior could mask global symmetry; some networks can be locally symmetric yet implement asymmetric computations in other subspaces.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Clock and the Pizza: Two Stories in Mechanistic Explanation of Neural Networks', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8397.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e8397.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including mechanisms, representations, probing results, interventions, performance, and error analysis.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Distance irrelevance (q)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Distance irrelevance metric</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Measures how much the correct logits Q_{i,j,i+j} depend on the token difference (i−j) by comparing within-difference stddev to global stddev; low q indicates strong dependence on distance (Pizza), high q indicates invariance to distance (Clock).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Diagnostic applied to models trained on modular addition (p=59)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Compute matrix L with L_{i,j} = Q_{i,j,i+j}, compute q = (1/p) * sum_{d in Z_p} std(L_{i,i+d} | i) / std(L_{i,j} | i,j).</td>
                        </tr>
                        <tr>
                            <td><strong>arithmetic_task_type</strong></td>
                            <td>Diagnostic for modular addition solutions</td>
                        </tr>
                        <tr>
                            <td><strong>mechanism_or_representation</strong></td>
                            <td>Quantifies whether correct logits vary with a−b (low q → Pizza) or are largely independent of a−b (high q → Clock).</td>
                        </tr>
                        <tr>
                            <td><strong>probing_or_intervention_method</strong></td>
                            <td>Computed on model logits; used as a classification feature in phase diagrams and logistic regression boundaries.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Observed values: Model A (Pizza) q ≈ 0.17 (low); Model B (Clock) q ≈ 0.85 (high). Typical pizza models q in [0,0.4]; typical clock models q in [0.4,1].</td>
                        </tr>
                        <tr>
                            <td><strong>error_types_or_failure_modes</strong></td>
                            <td>q is noisy for non-circular algorithms or when logits collapse after drastic interventions; used together with gradient symmetricity to disambiguate.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_for_mechanism</strong></td>
                            <td>Low q correlates strongly with pizza-like logit visual patterns dependent on a−b; used to identify phase transitions in attention-rate/width space.</td>
                        </tr>
                        <tr>
                            <td><strong>counterexamples_or_challenges</strong></td>
                            <td>Hybrid models with mixed PC behaviors can yield intermediate q; non-circular solutions are not well-captured by q computed on circular logits.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Clock and the Pizza: Two Stories in Mechanistic Explanation of Neural Networks', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8397.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e8397.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including mechanisms, representations, probing results, interventions, performance, and error analysis.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Attention-rate interpolation (α)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Attention-rate interpolation intervention</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A controlled intervention that replaces each attention head's post-softmax attention matrix M by M' = α M + (1−α) J (where J is all-ones), allowing continuous interpolation between full learned attention (α=1) and constant attention (α=0) to study algorithmic phase transitions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Transformer models trained on modular addition (p=59)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Interpolate attention strength via α ∈ [0,1] to modulate the relative contribution of content-dependent attention vs constant (all-ones) attention, effectively varying the prominence of multiplicative attention vs linear layers.</td>
                        </tr>
                        <tr>
                            <td><strong>arithmetic_task_type</strong></td>
                            <td>Used to probe modular addition behavior</td>
                        </tr>
                        <tr>
                            <td><strong>mechanism_or_representation</strong></td>
                            <td>Controls inductive bias toward multiplicative (attention-enabled) Clock solutions vs linear/ReLU-based Pizza solutions by adjusting α.</td>
                        </tr>
                        <tr>
                            <td><strong>probing_or_intervention_method</strong></td>
                            <td>Train or evaluate models across α values (experiments sampling α uniformly in [0,1]); measure gradient symmetricity and distance irrelevance to identify phase boundaries.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Phase diagrams show a sharp transition boundary in (α, width) space: higher α favors Clock (high distance irrelevance, low s_g), lower α favors Pizza (low distance irrelevance, high s_g). Transition point increases with model width (wider models need larger α to switch to Clock).</td>
                        </tr>
                        <tr>
                            <td><strong>error_types_or_failure_modes</strong></td>
                            <td>Intermediate α values can produce hybrid models mixing Clock/Pizza components; continuous interpolation can reveal networks that implement parallel partial algorithms.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_for_mechanism</strong></td>
                            <td>Systematic sweep over α and width shows consistent clustering into Pizza/Clock phases with logistic-regression-determined phase boundaries; demonstrates causal role of attention strength in selecting algorithmic phase.</td>
                        </tr>
                        <tr>
                            <td><strong>counterexamples_or_challenges</strong></td>
                            <td>Deeper networks and non-circular solutions complicate the phase diagram; some networks with full attention still exhibit Pizza-like PCs early in training (pizza appears early, later replaced by clock).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Clock and the Pizza: Two Stories in Mechanistic Explanation of Neural Networks', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8397.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e8397.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including mechanisms, representations, probing results, interventions, performance, and error analysis.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Linear model family (α, β, γ, δ)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Linear feedforward model variants (Models α, β, γ, δ)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A set of linear/ReLU architectures (different arrangements of adding/concatenating embeddings and number of linear layers) used to test inductive biases; different variants preferentially produce Pizza-like, non-circular, or other behaviors.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Linear one/two/three-layer feedforward models trained on modular addition (p=59)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Models differ by architecture: Model α: L2(ReLU(L1(x1+x2))); Model β: L3(ReLU(L2(ReLU(L1(x1+x2))))); Model γ: L3(ReLU(L2(ReLU(L1(x1)+L1(x2))))); Model δ: L2(ReLU(L1([x1;x2]))) where [x1;x2] is concatenation. Embedding and hidden dim d=256 in these experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>arithmetic_task_type</strong></td>
                            <td>Modular addition (a + b = c (mod p)), p = 59</td>
                        </tr>
                        <tr>
                            <td><strong>mechanism_or_representation</strong></td>
                            <td>Architectural inductive biases determine whether circular embeddings arise and whether pizza-like circuits form; extra linear layers and addition tend to favor Pizza-like behavior, concatenation often yields non-circular solutions.</td>
                        </tr>
                        <tr>
                            <td><strong>probing_or_intervention_method</strong></td>
                            <td>Train many random seeds, compute circularity metric, distance irrelevance, and visualize isolated logits after PC truncation; study aligned weights in successful linear pizzas.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Model β and γ are more pizza-like (lower distance irrelevance, higher circularity) than Model α. Model δ tends to be non-circular with high distance irrelevance. Exact accuracies not always reported per variant, but diagnostics show qualitative differences.</td>
                        </tr>
                        <tr>
                            <td><strong>error_types_or_failure_modes</strong></td>
                            <td>Concatenation-based Model δ tends to learn non-circular solutions and high distance irrelevance; single-layer addition variants can fail to produce pizza-like circuits without extra linear layers.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_for_mechanism</strong></td>
                            <td>Visualization of embeddings/unembeddings shows matching circles for pizza-like linear models; aligned W1/W2 weights show domino-like patterns mapping circle PCs through linear layers; removing non-functional ReLU left behavior unchanged, indicating linear alignments implement pizza.</td>
                        </tr>
                        <tr>
                            <td><strong>counterexamples_or_challenges</strong></td>
                            <td>Even small architectural changes (concatenation vs addition) dramatically change learned algorithmic phase, underscoring sensitivity to induction biases; presence of multiple PCs and ensembling complicates simple architecture→algorithm mapping.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Clock and the Pizza: Two Stories in Mechanistic Explanation of Neural Networks', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Progress measures for grokking via mechanistic interpretability <em>(Rating: 2)</em></li>
                <li>A mathematical framework for transformer circuits <em>(Rating: 2)</em></li>
                <li>Zoom in: An introduction to circuits <em>(Rating: 1)</em></li>
                <li>A toy model of universality: Reverse engineering how networks learn group operations <em>(Rating: 2)</em></li>
                <li>Towards automated circuit discovery for mechanistic interpretability <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-8397",
    "paper_id": "paper-259309406",
    "extraction_schema_id": "extraction-schema-149",
    "extracted_data": [
        {
            "name_short": "Clock",
            "name_full": "Clock algorithm for modular addition",
            "brief_description": "Represents tokens as 2D circular (Fourier) embeddings E_t ≈ [cos(w_k t), sin(w_k t)], adds polar angles (a+b) via multiplicative interactions (implemented using attention), and scores candidates with dot products giving logits Q_clock = cos(w_k(a+b-c)).",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "Transformer models trained on modular addition (p=59), e.g. Model B",
            "model_description": "One-layer ReLU transformer with attention (Model B). Default width d=128, 4 attention heads, MLP with 4d hidden units, trained with AdamW (lr=0.001, weight decay=2) for 20k epochs on modular-addition dataset (p=59, 80% train / 20% val).",
            "arithmetic_task_type": "Modular addition (a + b = c (mod p)), p = 59",
            "mechanism_or_representation": "Circular (angle-based) embeddings encoding token id as an angle; attention (multiplicative interactions) implements angle addition/multiplication; output unembedding matches circular basis so logits follow cos(w_k(a + b − c)).",
            "probing_or_intervention_method": "Principal component visualization of embeddings; circle isolation (rank-2 PC truncation); gradient projection onto top PCs; measuring gradient asymmetricity; ablation of attention (interpolating attention rate α toward constant attention).",
            "performance_metrics": "Model B typically attains 100% validation accuracy on the full task. Measured metrics: gradient symmetricity ≈ 33.36% (asymmetric), distance irrelevance ≈ 0.85 (high, indicating logits independent of a−b). After circle isolation retaining first six PCs Model B retains 100% accuracy.",
            "error_types_or_failure_modes": "Clock solutions are not strongly dependent on a−b and therefore do not exhibit the antipodal collapse failure mode characteristic of Pizza; classification imperfections can appear after extreme parameter modifications (e.g., isolating only two PCs), but clock is robust in standard trained models with attention.",
            "evidence_for_mechanism": "Top-PC visualization shows embeddings lying on a circle; gradient asymmetry (∇_{E_a} Q ≠ ∇_{E_b} Q) consistent with multiplicative interaction; distance irrelevance high (logits invariant to a−b); circle-isolated logits match cos(w_k(a+b−c)) which explains much of the model's behavior.",
            "counterexamples_or_challenges": "Small architectural/hyperparameter changes (e.g., removing/weakening attention) cause models to implement qualitatively different algorithms (Pizza or non-circular algorithms). Some models ensemble multiple parallel circular components producing mixed/hybrid behaviors.",
            "uuid": "e8397.0",
            "source_info": {
                "paper_title": "The Clock and the Pizza: Two Stories in Mechanistic Explanation of Neural Networks",
                "publication_date_yy_mm": "2023-06"
            }
        },
        {
            "name_short": "Pizza",
            "name_full": "Pizza algorithm for modular addition",
            "brief_description": "Embeds tokens on a circle but operates on the interior: averages embeddings E_ab = (E_a + E_b)/2, maps that midpoint into a vector proportional to |cos(w_k (a−b)/2)|·(cos(w_k (a+b)), sin(w_k (a+b))) using ReLU/absolute-like nonlinearity, and scores outputs with a dot product yielding Q_pizza = |cos(w_k(a−b)/2)| cos(w_k(a+b−c)).",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Transformer/MLP models trained on modular addition (p=59), notably Model A (constant-attention transformer / MLP-like)",
            "model_description": "Model A: one-layer ReLU transformer with constant attention (equivalently a ReLU MLP), default width d=128; embeddings and network parameters are learned; trained with same optimizer/hyperparams as other experiments.",
            "arithmetic_task_type": "Modular addition (a + b = c (mod p)), p = 59",
            "mechanism_or_representation": "Uses the vector mean (midpoint) of two circular embeddings; a symmetric nonlinearity (absolute-value-like effect implemented via ReLU combinations) produces a multiplicative amplitude factor |cos(w_k (a−b)/2)| times an angle-dependent vector encoding (a+b); final dot product with output embedding yields logits dependent on both a+b and a−b.",
            "probing_or_intervention_method": "Gradient symmetricity metric (cosine similarity of ∂Q/∂E_a and ∂Q/∂E_b); circle isolation by truncating embedding matrix to pairs of principal components (rank-2 approximations); computing fraction variance explained (FVE) of closed-form Pizza formula against actual logits; aligned-weight inspection in linear models; ablating/altering attention via attention-rate interpolation.",
            "performance_metrics": "Model A attains high/100% validation accuracy in full models. Measured diagnostics: gradient symmetricity ≈ 99.37% (highly symmetric), distance irrelevance ≈ 0.17 (low, indicating strong dependence of correct logits on a−b). After isolating a single 2D circle, Model A accuracy can drop to ~32.8%; retaining first six PCs (three circles) raises overall accuracy to ~91.4%. Table 2: Q_pizza explains ≈99.18% FVE of isolated logits (examples shown).",
            "error_types_or_failure_modes": "Antipodal or near-antipodal input pairs cause the mean vector to collapse toward origin (small norm), making pizza slices ambiguous and causing misclassification. Pizza's extra multiplicative factor |cos((a−b)/2)| makes accuracy dependent on a−b. To compensate, networks often implement multiple 'accompanying' pizzas or ensemble circles.",
            "evidence_for_mechanism": "High gradient symmetricity (∂Q/∂E_a ≈ ∂Q/∂E_b) rules out multiplicative (clock-like) solutions and matches the symmetric functional form shown in Lemma A.1; circle-isolated logits match the analytic pizza formula with very high FVE; aligned-weight analysis in linear models reproduces the pizza computation; pizza-like patterns appear early in training and in models with weak/absent attention.",
            "counterexamples_or_challenges": "Pizza is sensitive to antipodal failures; networks often form accompanying pizzas to patch these errors but these may be pruned away later; some networks with attention or larger widths prefer Clock instead; non-circular algorithms and hybrid mixtures of Pizza/Clock also appear, showing the solution is not unique.",
            "uuid": "e8397.1",
            "source_info": {
                "paper_title": "The Clock and the Pizza: Two Stories in Mechanistic Explanation of Neural Networks",
                "publication_date_yy_mm": "2023-06"
            }
        },
        {
            "name_short": "Accompanying Pizza",
            "name_full": "Accompanying (complementary) Pizza circles",
            "brief_description": "Secondary pizza circles that complement primary pizzas by rearranging token adjacency so that near-antipodal pairs on the primary pizza become non-antipodal on the accompanying pizza, thereby correcting pizza-specific antipodal failure modes.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Transformer/MLP models trained on modular addition (p=59), observed in Model A",
            "model_description": "Additional circular principal-component embeddings (different angular spacing δ') learned in the same embedding matrix; these accompanying circles may be weaker in final prediction after pruning but are visible in the embedding geometry.",
            "arithmetic_task_type": "Modular addition (a + b = c (mod p)), p = 59",
            "mechanism_or_representation": "A second circle with different adjacency spacing (δ_1 = 2 δ_2 (mod p) relationship) reorders tokens so that previously near-antipodal inputs are separable; the accompanying pizza computes logits similarly (dot products with its own output embedding basis) focused on the formerly hard cases.",
            "probing_or_intervention_method": "Detected via circle isolation (PCA rank-2 isolations) and visualizing multiple isolated circles; performance measured by isolating each circle and computing accuracy and logit patterns.",
            "performance_metrics": "Observed that primary pizzas #1/#2/#3 can reach ~99.7% accuracy (when combined), while accompanying pizzas #4/#5/#6 individually yield ~16.7% accuracy; combining all six circles in Model A embedding restores full 100% accuracy in that experiment.",
            "error_types_or_failure_modes": "Accompanying pizzas by themselves can be weak predictors (low individual accuracy) and may be pruned during training; they primarily serve to patch antipodal errors of primary pizzas and may not strongly contribute to final predictions after pruning.",
            "evidence_for_mechanism": "Visualization after circle isolation shows complementary logit patterns between accompanied and accompanying pizzas; experiments combining multiple circles recover accuracy lost when using a single circle; hypothesized training dynamics (lottery ticket + pruning) account for their transient support role.",
            "counterexamples_or_challenges": "Although accompanying pizzas can patch antipodal failures, they are not always strongly used in final prediction due to weight decay/pruning dynamics; they do not always fully resolve all pizza failure modes without ensembling multiple solutions.",
            "uuid": "e8397.2",
            "source_info": {
                "paper_title": "The Clock and the Pizza: Two Stories in Mechanistic Explanation of Neural Networks",
                "publication_date_yy_mm": "2023-06"
            }
        },
        {
            "name_short": "Model A (constant-attention / MLP-like)",
            "name_full": "Model A: one-layer ReLU transformer with constant attention (equivalently a ReLU MLP)",
            "brief_description": "A one-layer transformer where attention is replaced by a constant all-ones matrix (no content-dependent attention), making the model effectively linear layers + ReLU; in this setup networks preferentially learn Pizza-like solutions.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Model A (constant-attention transformer / MLP)",
            "model_description": "One-layer ReLU transformer with attention replaced by all-ones (attention rate α=0), width default d=128, 4 heads (dimensions ⌊d/4⌋), MLP size 4d, trained with AdamW, 20k epochs, dataset p=59.",
            "arithmetic_task_type": "Modular addition (a + b = c (mod p)), p=59",
            "mechanism_or_representation": "Learns circular embeddings in PCs but computes via symmetric midpoint-based pizza circuits that exploit absolute-value-like nonlinearity (ReLU) rather than multiplicative attention; often ensembles multiple pizza circles.",
            "probing_or_intervention_method": "Gradient symmetricity measurement (s_g ≈ 0.9937), distance irrelevance (q ≈ 0.17), circle isolation (PC truncation), FVE comparison between Pizza and Clock formulae, aligning weight matrices in linear variants, removing non-functional ReLU to test circuit structure.",
            "performance_metrics": "Full trained Model A reaches high/100% validation accuracy in many runs. When isolated to only the first two PCs (one circle) accuracy drops to ~32.8%; retaining first six PCs (three circles) yields ~91.4% accuracy. Pizza formula explains ≈99.18% FVE of isolated logits (Table 2).",
            "error_types_or_failure_modes": "Strong sensitivity to (near-)antipodal inputs causing norm collapse and misclassification when relying on a single pizza circle; requires multiple circles/accompanying pizzas to reach robust accuracy.",
            "evidence_for_mechanism": "High gradient symmetricity consistent with symmetric two-input function; pizza formula matches model logits with high FVE; principal-component visualizations show multiple circular components; aligned-weight analysis in linear analogues reproduces pizza-like linear combos.",
            "counterexamples_or_challenges": "Some Model A runs produce additional accompanying pizzas of low final importance (pruned); other architectures (with stronger attention or larger width) switch to Clock or hybrid solutions; circle isolation can dramatically reduce accuracy, revealing hidden ensembling.",
            "uuid": "e8397.3",
            "source_info": {
                "paper_title": "The Clock and the Pizza: Two Stories in Mechanistic Explanation of Neural Networks",
                "publication_date_yy_mm": "2023-06"
            }
        },
        {
            "name_short": "Model B (attention transformer)",
            "name_full": "Model B: standard one-layer ReLU transformer with content-dependent attention",
            "brief_description": "A standard one-layer ReLU transformer with learned attention (α=1 in attention-rate interpolation) that preferentially implements the Clock algorithm and shows asymmetric gradients consistent with multiplicative computation.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Model B (one-layer transformer with attention)",
            "model_description": "One-layer ReLU transformer with learned attention (post-softmax), width d=128 by default, 4 heads, trained with AdamW 20k epochs on modular-addition p=59.",
            "arithmetic_task_type": "Modular addition (a + b = c (mod p)), p=59",
            "mechanism_or_representation": "Circular embeddings; attention enables multiplicative-like interaction to compute angle addition; asymmetric gradients reflect different roles for a and b in multiplicative/attention computation.",
            "probing_or_intervention_method": "Same as other models: PCA/circle isolation, gradient projection onto top PCs (shows asymmetry), distance irrelevance metric (high), ablation via reducing attention rate α which induces phase transitions to Pizza.",
            "performance_metrics": "Typically achieves 100% validation accuracy. Diagnostics: gradient symmetricity ≈ 33.36% (asymmetric), distance irrelevance ≈ 0.85 (high). Circle-isolated models retaining first six PCs keep 100% accuracy.",
            "error_types_or_failure_modes": "Less susceptible to pizza-specific antipodal collapse; nevertheless, network can exhibit fluctuations in logits after severe parameter modifications (e.g., isolating PCs) due to imperfect classification stage.",
            "evidence_for_mechanism": "Asymmetric gradients (∇_{E_a} Q ≠ ∇_{E_b} Q) consistent with multiplication; circle-shaped embeddings and matching unembedding basis; high distance irrelevance indicating Q does not depend on a−b; phase transition experiments show moving α toward 0 diminishes clock behavior.",
            "counterexamples_or_challenges": "With reduced attention strength or increased linear-layer capacity (wider models), Model B-like networks can switch to Pizza or hybrid algorithms, indicating lack of uniqueness of learned algorithm.",
            "uuid": "e8397.4",
            "source_info": {
                "paper_title": "The Clock and the Pizza: Two Stories in Mechanistic Explanation of Neural Networks",
                "publication_date_yy_mm": "2023-06"
            }
        },
        {
            "name_short": "Circle isolation (PC truncation)",
            "name_full": "Circle isolation via principal-component rank-2 truncation",
            "brief_description": "A probing intervention that replaces the embedding matrix by rank-2 approximations (keeping specific PC pairs) to isolate individual circular components of the learned embedding and reveal which circle(s) implement particular algorithmic variants.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Transformer/linear models trained on modular addition (p=59) used in this paper",
            "model_description": "Post-training intervention: replace learned embedding matrix E with rank-2 matrices built from selected principal-component pairs (first and second PC, third and fourth, etc.) and evaluate model logits/accuracy.",
            "arithmetic_task_type": "Diagnostic applied to modular addition models (p=59)",
            "mechanism_or_representation": "By isolating 2D circular subspaces, one can test whether a given circle implements Clock, Pizza, or a weak/incorrect solution; reveals existence of multiple parallel circles (ensembling) and accompanying pizzas.",
            "probing_or_intervention_method": "Direct weight intervention: truncate embedding matrix to specified PC pairs and recompute logits; compute accuracy, FVE of analytic formulas (Pizza/Clock) against model logits on isolated circle.",
            "performance_metrics": "Applying circle isolation to Model A: single-circle isolation (first 2 PCs) yields ~32.8% accuracy; retaining first 6 PCs yields ~91.4%. Model B retains 100% when truncated to first six PCs. FVE: Pizza formula explains ~99% of variance on isolated Model A circles while Clock explains ~75% (Table 2, example numbers).",
            "error_types_or_failure_modes": "Isolating only one circle often exposes pizza's antipodal failure modes and can dramatically reduce accuracy if the model relies on ensembling multiple circles to correct errors.",
            "evidence_for_mechanism": "High FVE of Pizza formula on isolated circles and corresponding logit patterns demonstrate that specific 2D components are executing pizza-like computations; presence of multiple useful circles indicates ensembling of solutions.",
            "counterexamples_or_challenges": "Circle isolation is destructive and can remove corrective components leading to large accuracy changes; it also assumes principal components align with functional circles, which may fail for non-circular algorithms.",
            "uuid": "e8397.5",
            "source_info": {
                "paper_title": "The Clock and the Pizza: Two Stories in Mechanistic Explanation of Neural Networks",
                "publication_date_yy_mm": "2023-06"
            }
        },
        {
            "name_short": "Gradient symmetricity metric",
            "name_full": "Gradient symmetricity (s_g)",
            "brief_description": "A diagnostic that measures cosine similarity between gradients of the output logit wrt the two input embeddings (∂Q/∂E_a and ∂Q/∂E_b) averaged over examples; high symmetry indicates symmetric functions like Pizza, low symmetry indicates multiplicative/clock-like operations.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Diagnostic applied to models trained on modular addition (p=59)",
            "model_description": "Compute gradients of chosen logits with respect to input embeddings, project onto top principal components (first 6 used), compute cosine similarity and average across sample set S (size 100 in experiments).",
            "arithmetic_task_type": "Diagnostic for modular addition solutions",
            "mechanism_or_representation": "A high s_g (~1) implies the function is symmetric in inputs (consistent with sum-of-symmetric basis functions and Pizza-like formula); low s_g implies asymmetry consistent with multiplicative interactions (Clock).",
            "probing_or_intervention_method": "Gradient computation and projection onto top PCs; used to classify models (e.g., Model A s_g ≈ 0.9937, Model B s_g ≈ 0.3336).",
            "performance_metrics": "Reported values: Model A (Pizza) s_g ≈ 99.37% (near 1); Model B (Clock) s_g ≈ 33.36%. Across experiments s_g strongly correlates with Pizza vs Clock regimes.",
            "error_types_or_failure_modes": "s_g alone can be ambiguous in hybrid models; when metrics conflict, distance irrelevance is treated as decisive for Pizza detection but s_g rules out Clock.",
            "evidence_for_mechanism": "High s_g observed empirically in models whose logits match Pizza formula; theoretical lemma (A.1) shows symmetric linear combinations of cos/sin lead to factorization with cos((x−y)/2), consistent with Pizza.",
            "counterexamples_or_challenges": "Local linear/asymmetric behavior could mask global symmetry; some networks can be locally symmetric yet implement asymmetric computations in other subspaces.",
            "uuid": "e8397.6",
            "source_info": {
                "paper_title": "The Clock and the Pizza: Two Stories in Mechanistic Explanation of Neural Networks",
                "publication_date_yy_mm": "2023-06"
            }
        },
        {
            "name_short": "Distance irrelevance (q)",
            "name_full": "Distance irrelevance metric",
            "brief_description": "Measures how much the correct logits Q_{i,j,i+j} depend on the token difference (i−j) by comparing within-difference stddev to global stddev; low q indicates strong dependence on distance (Pizza), high q indicates invariance to distance (Clock).",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Diagnostic applied to models trained on modular addition (p=59)",
            "model_description": "Compute matrix L with L_{i,j} = Q_{i,j,i+j}, compute q = (1/p) * sum_{d in Z_p} std(L_{i,i+d} | i) / std(L_{i,j} | i,j).",
            "arithmetic_task_type": "Diagnostic for modular addition solutions",
            "mechanism_or_representation": "Quantifies whether correct logits vary with a−b (low q → Pizza) or are largely independent of a−b (high q → Clock).",
            "probing_or_intervention_method": "Computed on model logits; used as a classification feature in phase diagrams and logistic regression boundaries.",
            "performance_metrics": "Observed values: Model A (Pizza) q ≈ 0.17 (low); Model B (Clock) q ≈ 0.85 (high). Typical pizza models q in [0,0.4]; typical clock models q in [0.4,1].",
            "error_types_or_failure_modes": "q is noisy for non-circular algorithms or when logits collapse after drastic interventions; used together with gradient symmetricity to disambiguate.",
            "evidence_for_mechanism": "Low q correlates strongly with pizza-like logit visual patterns dependent on a−b; used to identify phase transitions in attention-rate/width space.",
            "counterexamples_or_challenges": "Hybrid models with mixed PC behaviors can yield intermediate q; non-circular solutions are not well-captured by q computed on circular logits.",
            "uuid": "e8397.7",
            "source_info": {
                "paper_title": "The Clock and the Pizza: Two Stories in Mechanistic Explanation of Neural Networks",
                "publication_date_yy_mm": "2023-06"
            }
        },
        {
            "name_short": "Attention-rate interpolation (α)",
            "name_full": "Attention-rate interpolation intervention",
            "brief_description": "A controlled intervention that replaces each attention head's post-softmax attention matrix M by M' = α M + (1−α) J (where J is all-ones), allowing continuous interpolation between full learned attention (α=1) and constant attention (α=0) to study algorithmic phase transitions.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Transformer models trained on modular addition (p=59)",
            "model_description": "Interpolate attention strength via α ∈ [0,1] to modulate the relative contribution of content-dependent attention vs constant (all-ones) attention, effectively varying the prominence of multiplicative attention vs linear layers.",
            "arithmetic_task_type": "Used to probe modular addition behavior",
            "mechanism_or_representation": "Controls inductive bias toward multiplicative (attention-enabled) Clock solutions vs linear/ReLU-based Pizza solutions by adjusting α.",
            "probing_or_intervention_method": "Train or evaluate models across α values (experiments sampling α uniformly in [0,1]); measure gradient symmetricity and distance irrelevance to identify phase boundaries.",
            "performance_metrics": "Phase diagrams show a sharp transition boundary in (α, width) space: higher α favors Clock (high distance irrelevance, low s_g), lower α favors Pizza (low distance irrelevance, high s_g). Transition point increases with model width (wider models need larger α to switch to Clock).",
            "error_types_or_failure_modes": "Intermediate α values can produce hybrid models mixing Clock/Pizza components; continuous interpolation can reveal networks that implement parallel partial algorithms.",
            "evidence_for_mechanism": "Systematic sweep over α and width shows consistent clustering into Pizza/Clock phases with logistic-regression-determined phase boundaries; demonstrates causal role of attention strength in selecting algorithmic phase.",
            "counterexamples_or_challenges": "Deeper networks and non-circular solutions complicate the phase diagram; some networks with full attention still exhibit Pizza-like PCs early in training (pizza appears early, later replaced by clock).",
            "uuid": "e8397.8",
            "source_info": {
                "paper_title": "The Clock and the Pizza: Two Stories in Mechanistic Explanation of Neural Networks",
                "publication_date_yy_mm": "2023-06"
            }
        },
        {
            "name_short": "Linear model family (α, β, γ, δ)",
            "name_full": "Linear feedforward model variants (Models α, β, γ, δ)",
            "brief_description": "A set of linear/ReLU architectures (different arrangements of adding/concatenating embeddings and number of linear layers) used to test inductive biases; different variants preferentially produce Pizza-like, non-circular, or other behaviors.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Linear one/two/three-layer feedforward models trained on modular addition (p=59)",
            "model_description": "Models differ by architecture: Model α: L2(ReLU(L1(x1+x2))); Model β: L3(ReLU(L2(ReLU(L1(x1+x2))))); Model γ: L3(ReLU(L2(ReLU(L1(x1)+L1(x2))))); Model δ: L2(ReLU(L1([x1;x2]))) where [x1;x2] is concatenation. Embedding and hidden dim d=256 in these experiments.",
            "arithmetic_task_type": "Modular addition (a + b = c (mod p)), p = 59",
            "mechanism_or_representation": "Architectural inductive biases determine whether circular embeddings arise and whether pizza-like circuits form; extra linear layers and addition tend to favor Pizza-like behavior, concatenation often yields non-circular solutions.",
            "probing_or_intervention_method": "Train many random seeds, compute circularity metric, distance irrelevance, and visualize isolated logits after PC truncation; study aligned weights in successful linear pizzas.",
            "performance_metrics": "Model β and γ are more pizza-like (lower distance irrelevance, higher circularity) than Model α. Model δ tends to be non-circular with high distance irrelevance. Exact accuracies not always reported per variant, but diagnostics show qualitative differences.",
            "error_types_or_failure_modes": "Concatenation-based Model δ tends to learn non-circular solutions and high distance irrelevance; single-layer addition variants can fail to produce pizza-like circuits without extra linear layers.",
            "evidence_for_mechanism": "Visualization of embeddings/unembeddings shows matching circles for pizza-like linear models; aligned W1/W2 weights show domino-like patterns mapping circle PCs through linear layers; removing non-functional ReLU left behavior unchanged, indicating linear alignments implement pizza.",
            "counterexamples_or_challenges": "Even small architectural changes (concatenation vs addition) dramatically change learned algorithmic phase, underscoring sensitivity to induction biases; presence of multiple PCs and ensembling complicates simple architecture→algorithm mapping.",
            "uuid": "e8397.9",
            "source_info": {
                "paper_title": "The Clock and the Pizza: Two Stories in Mechanistic Explanation of Neural Networks",
                "publication_date_yy_mm": "2023-06"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Progress measures for grokking via mechanistic interpretability",
            "rating": 2
        },
        {
            "paper_title": "A mathematical framework for transformer circuits",
            "rating": 2
        },
        {
            "paper_title": "Zoom in: An introduction to circuits",
            "rating": 1
        },
        {
            "paper_title": "A toy model of universality: Reverse engineering how networks learn group operations",
            "rating": 2
        },
        {
            "paper_title": "Towards automated circuit discovery for mechanistic interpretability",
            "rating": 1
        }
    ],
    "cost": 0.019791249999999996,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>The Clock and the Pizza: Two Stories in Mechanistic Explanation of Neural Networks
21 Nov 2023</p>
<p>Ziqian Zhong ziqianz@mit.edu 
Massachusetts Institute of Technology</p>
<p>Ziming Liu zmliu@mit.edu 
Massachusetts Institute of Technology</p>
<p>Max Tegmark tegmark@mit.edu 
Massachusetts Institute of Technology</p>
<p>Jacob Andreas 
Massachusetts Institute of Technology</p>
<p>The Clock and the Pizza: Two Stories in Mechanistic Explanation of Neural Networks
21 Nov 202366B07EAD14037DA0619D90DED78977BAarXiv:2306.17844v2[cs.LG]
Do neural networks, trained on well-understood algorithmic tasks, reliably rediscover known algorithms for solving those tasks?Several recent studies, on tasks ranging from group arithmetic to in-context linear regression, have suggested that the answer is yes.Using modular addition as a prototypical problem, we show that algorithm discovery in neural networks is sometimes more complex.Small changes to model hyperparameters and initializations can induce discovery of qualitatively different algorithms from a fixed training set, and even parallel implementations of multiple such algorithms.Some networks trained to perform modular addition implement a familiar Clock algorithm (previously described by Nanda et al.[1]); others implement a previously undescribed, less intuitive, but comprehensible procedure we term the Pizza algorithm, or a variety of even more complex procedures.Our results show that even simple learning problems can admit a surprising diversity of solutions, motivating the development of new tools for characterizing the behavior of neural networks across their algorithmic phase space. 1 * Equal contribution. 1 Code is available at https://github.com/fjzzq2002/pizza. 37th Conference on Neural Information Processing Systems (NeurIPS 2023).</p>
<p>Introduction</p>
<p>Mechanistically understanding deep network models-reverse-engineering their learned algorithms and representation schemes-remains a major challenge across problem domains.Several recent studies [2,3,4,5,1] have exhibited specific examples of models apparently re-discovering interpretable (and in some cases familiar) solutions to tasks like curve detection, sequence copying and modular arithmetic.Are these models the exception or the rule?Under what conditions do neural network models discover familiar algorithmic solutions to algorithmic tasks?</p>
<p>In this paper, we focus specifically on the problem of learning modular addition, training networks to compute sums like 8 + 6 = 2 (mod 12).Modular arithmetic can be implemented with a simple geometric solution, familiar to anyone who has learned to read a clock: every integer is represented as an angle, input angles are added together, and the resulting angle evaluated to obtain a modular sum (Figure 1, left).Nanda et al. [1] show that specific neural network architectures, when trained to perform modular addition, implement this Clock algorithm.In this work, we show that the Clock algorithm is only one part of a more complicated picture of algorithm learning in deep networks.In particular, networks structurally similar to the ones trained by Nanda et al. preferentially implement a qualitatively different approach to modular arithmetic, which we term the Pizza algorithm (Figure 1, right), and sometimes even more complex solutions.Models exhibit sharp algorithmic phase transitions [6] between the Clock and Pizza algorithms as their width and attention strength very, and often implement multiple, imperfect copies of the Pizza algorithm in parallel.Step 1: Embed token and to a circle where for some
a b w k = 2πk/p k ∈ [1,2⋯, p − 1]
Step 2: compute the angle sum using multiplication.</p>
<p>Step 3: score possible outputs using a dot product.
c
Step 2.1: compute the vector mean.Step 2.2: using and nonlinearities to compute Our results highlight the complexity of mechanistic description in even models trained to perform simple tasks.They point to characterization of algorithmic phase spaces, not just single algorithmic solutions, as an important goal in algorithm-level interpretability.</p>
<p>Organization In Section 2, we review the Clock algorithm [1] and show empirical evidence of deviation from it in models trained to perform modular addition.In Section 3, we show that these deviations can be explained by an alternative Pizza algorithm.In Section 4, we define additional metrics to distinguish between these algorithms, and detect phase transitions between these algorithms (and others Non-circular algorithms) when architectures and hyperparameters are varied.We discuss the relationship between these findings and other work on model interpretation in Section 5, and conclude in Section 6.</p>
<p>Modular Arithmetic and the Clock Algorithm</p>
<p>Setup We train neural networks to perform modular addition a + b = c (mod p), where a, b, c = 0, 1, • • • , p − 1.We use p = 59 throughout the paper.In these networks, every integer t has an associated embedding vector E t ∈ R d .Networks take as input embeddings [E a , E b ] ∈ R 2d and predict a categorical output c.Both embeddings and network parameters are learned.In preliminary experiments, we train two different network architectures on the modular arithmetic task, which we refer to as: Model A and Model B. Model A is a one-layer ReLU transformer [7] with constant attention, while Model B is a standard one-layer ReLU transformer (see Appendix F.1 for details).As attention is not involved in Model A, it can also be understood as a ReLU MLP (Appendix G).</p>
<p>Review of the Clock Algorithm</p>
<p>As in past work, we find that after training both Model A and Model B, embeddings (E a , E b in Figure 1) usually describe a circle [8] in the plane spanned by the first two principal components of the embedding matrix.Formally, E a ≈ [cos(w k a), sin(w k a)] where   Remarkably, Nanda et al. [1] find that neural networks like our Model B implement this Clock algorithm, visualized in Figure 1  Crucial to this algorithm is the fact that the attention mechanism can be leveraged to perform multiplication.What happens in model variants when the attention mechanism is absent, as in Model A? We find two pieces of evidence of deviation from the Clock algorithm in Model A.
w k = 2πk/p, k is an integer in [1, p − 1].</p>
<p>First Evidence for Clock Violation: Gradient Symmetricity</p>
<p>Since the Clock algorithm has logits:
Q Clock abc = (E a,x E b,x − E a,y E b,y )E c,x + (E a,x E b,y + E a,y E b,x )E c,y ,(1)
(see Figure 1) the gradients of Q abc generically lack permutation symmetry in argument order:
∇ Ea Q abc ̸ = ∇ E b Q abc . Thus, if learned models exhibit permutation symmetry (∇ Ea Q abc = ∇ E b Q abc )
, they must be implementing some other algorithm.</p>
<p>We compute the 6 largest principal components of the input embedding vectors.We then compute the gradients of output logits (unnormalized log-probabilities from the model) with respect to the input embeddings.We then project them onto these 6 principal components (since the angles relevant to the Clock and Pizza algorithms are encoded in the first few principal components).These projections are shown in Figure 2.While Model B demonstrates asymmetry in general, Model A exhibits gradient symmetry.3 An Alternative Solution: the Pizza Algorithm How does Model A perform modular arithmetic?Whatever solution it implements must exhibit gradient symmetricity in Figure 2 and the output patterns in Figure 3.In this section, we describe a new algorithm for modular arithmetic, which we call the Pizza algorithm, and then provide evidence that this is the procedure implemented by Model A.</p>
<p>The Pizza Algorithm</p>
<p>Unlike the Clock algorithm, the Pizza algorithm operates inside the circle formed by embeddings (just as pepperoni are spread all over a pizza), instead of operating on the circumference of the circle.The basic idea is illustrated in   3, the logits in Model A indeed exhibit a strong dependence on a − b.</p>
<p>Second Evidence for Pizza: Clearer Logit Patterns via Circle Isolation</p>
<p>To better understand the behavior of this algorithm, we replace the embedding matrix E with a series of rank-2 approximations: using only the first and second principal components, or only the third and fourth, etc.For each such matrix, embeddings lie in a a two-dimensional subspace.For both Model A and Model B, we find that embeddings form a circle in this subspace (Figure 4 and Figure 5, bottom).We call this procedure circle isolation.Even after this drastic modification to the trained models' parameters, both Model A and Model B continue to behave in interpretable ways: a subset of predictions remain highly accurate, with this subset determined by the periodicity of the k of the isolated circle.As predicted by the Pizza and Clock algorithms described in Figure 1  Using these isolated embeddings, we may additionally calculate the isolated logits directly with formulas in Figure 1 and compare with the actual logits from Model A. Results are displayed in Table 2.We find that Q abc (Pizza) explains substantially more variance than Q abc (Clock ).</p>
<p>Why do we only analyze correct logits?</p>
<p>The logits from the Pizza algorithm are given by
Q abc (Pizza) = |cos(w k (a − b)/2)| cos(w k (a + b − c)). By contrast, the Clock algorithm has logits Q abc (Clock ) = cos(w k (a + b − c)). In a word, Q abc (Pizza) has an extra multiplica- tive factor | cos(w k (a − b)/2)| compared to Q abc (Clock ). By constraining c = a + b (thus cos(w k (a + b − c)) = 1), the factor |cos(w k (a − b)/2)| can be identified.
(Unexpected) dependence of logits Q abc (Clock ) on a + b: Although our analysis above expects logits Q abc (Clock ) not to depend on a − b, they do not predict its dependence on a + b.In Figure 5, we surprisingly find that Q abc (Clock ) is sensitive to this sum.Our conjecture is that Step 1 and Step 2 of the Clock are implemented (almost) noiselessly, such that same-label samples collapse to the same point after Step 2. However, Step 3 (classification) is imperfect after circle isolation, resulting in fluctuations of logits.Inputs with common sums a + b produce the same logits.Circle
w k Q abc (clock) FVE Q abc (pizza) FVE #1 2π/59 • 17 75.41% 99.18% #2 2π/59 • 3 75.62% 99.18% #3 2π/59 • 44 75.38% 99.28%
Table 2: After isolating circles in the input embedding, fraction of variance explained (FVE) of all Model A's output logits (59 × 59 × 59 of them) by various formulas.Both model output logits and formula results' are normalized to mean 0 variance 1 before taking FVE.w k 's are calculated according to the visualization.For example, distance between 0 and 1 in Circle #1 is 17, so w k = 2π/59 • 17.</p>
<p>Third Evidence for Pizza: Accompanied &amp; Accompanying Pizza</p>
<p>The Achilles' heel of the Pizza algorithm is antipodal pairs.If two inputs (a, b) happen to lie antipodally, then their middle point will lie at the origin, where the correct "pizza slice" is difficult to identify.For example in Figure 1 right, antipodal pairs are (1,7), (2,8), (3,9) etc., whose middle points all collapse to the origin, but their class labels are different.Models cannot distinguish between, and thus correctly classify, these pairs.Even for odd p's where there are no strict antipodal pairs, approximately antipodal pairs are also more likely to be classified incorrectly than non-antipodal pairs.</p>
<p>Intriguingly, neural networks find a clever way to compensate for this failure mode.we find that pizzas usually come with "accompanying pizzas".An accompanied pizza and its accompanying pizza complement each other in the sense that near-antipodal pairs in the accompanied pizza become adjacent or close (i.e,very non-antipodal) in the accompanying pizza.If we denote the difference between adjacent numbers on the circle as δ and δ 1 , δ 2 for accompanied and accompanying pizzas, respectively, then δ 1 = 2δ 2 (mod p).In the experiment, we found that pizzas #1/#2/#3 in Figure 4 all have accompanying pizzas, which we call pizzas #4/#5/#6 (see Appendix D for details).However, these accompanying pizzas do not play a significant role in final model predictions 2 .We conjecture that training dynamics are as follows: (1) At initialization, pizzas #1/#2/#3 correspond to three different "lottery tickets" [9].(2) In early stages of training, to compensate the weaknesses (antipodal pairs) of pizzas #1/#2/#3, pizzas #4/#5/#6 are formed.(3) As training goes on (in the presence of weight decay), the neural network gets pruned.As a result, pizzas #4/#5/#6 are not significantly involved in prediction, although they continue to be visible in the embedding space.</p>
<p>The Algorithmic Phase Space</p>
<p>In Section 3, we have demonstrated a typical Clock (Model A) and a typical Pizza (Model B).In this section, we study how architectures and hyperparametes govern the selection of these two algorithmic "phases".In Section 4.1, we propose quantitative metrics that can distinguish between Pizza and Clock.In Section 4.2, we observe how these metrics behave with different architectures and hyperparameters, demonstrating sharp phase transitions.The results in this section focus Clock and Pizza models, but other algorithmic solutions to modular addition are also discovered, and explored in more detail in Appendix B.</p>
<p>Metrics</p>
<p>We wish to study the distribution of Pizza and Clock algorithms statistically, which will require us to distinguish between two algorithms automatically.In order to do so, we formalize our observations in Section 2.2 and 2.3, arriving at two metrics: gradient symmetricity and distance irrelevance.</p>
<p>Gradient Symmetricity</p>
<p>To measure the symmetricity of the gradients, we select some input-output group (a, b, c), compute the gradient vectors for the output logit at position c with respect to the input embeddings, and then compute the cosine similarity.Taking the average over many pairs yields the gradient symmetricity.Definition 4.1 (Gradient Symmetricity).For a fixed set S ⊆ Z3 p of input-output pairs 3 , define gradient-symmetricity of a network M with embedding layer E as
s g ≡ 1 |S| (a,b,c)∈S sim ∂Q abc ∂E a , ∂Q abc ∂E b , where sim(a, b) = a•b |a||b| is the cosine-similarity, Q abc is the logit for class c given input a and b. It is clear that s g ∈ [−1, 1].
As we discussed in Section 2.2, the Pizza algorithm has symmetric gradients while the Clock algorithm has asymmetric ones.Model A and Model B in Section 3 have gradient symmetricity 99.37% and 33.36%, respectively (Figure 2).</p>
<p>Distance Irrelevance</p>
<p>To measure the dependence of correct logits on differences between two inputs, which reflect the distances of the inputs on the circles, we measure how much of the variance in the correct logit matrix depends on it.We do so by comparing the average standard deviation of correct logits from inputs with the same differences and the standard deviation from all inputs.Definition 4.2 (Distance Irrelevance).For some network M with correct logit matrix L (L i,j = Q ij,i+j ), define its distance irrelevance as
q ≡ 1 p d∈Zp std (L i,i+d | i ∈ Z p ) std L i,j | i, j ∈ Z 2 p ,
where std computes the standard deviation of a set.It is clear that q ∈ [0, 1].</p>
<p>Model A and Model B in Section 3 give distance irrelevance 0.17 and 0.85, respectively (Figure 3).A typical distance irrelevance from the Pizza algorithm ranges from 0 to 0.4 while a typical distance irrelevance from Clock algorithm ranges from 0.4 to 1.</p>
<p>Which Metric is More Decisive?</p>
<p>When the two metrics have conflicting results, which one is more decisive?We consider distance irrelevance as the decisive factor of the Pizza algorithm, as the output logits being dependent on the distance is highly suggestive of Pizza.On the other hand, gradient symmetricity can be used to rule out the Clock algorithm, as it requires multiplying (transformed) inputs which will result in asymmetric gradients.Figure 6 confirmed that at low distance irrelevance (suggesting pizza) the gradient symmetricity is almost always close to 1 (suggesting non-clock).</p>
<p>Identifying algorithmic phase transitions</p>
<p>How do models "choose" whether to implement the Clock or Pizza algorithm?We investigate this question by interpolating between Model A (transformer without attention) and Model B (transformer with attention).To do so, we introduce a new hyperparameter α we call the attention rate.</p>
<p>For a model with attention rate α, we modify the attention matrix M for each attention head to be
M ′ = M α + J(1 − α).
In other words, we modify this matrix to consist of a linear interpolation between the all-one matrix and the original attention (post-softmax), with the rate α controlling how much of the attention is kept.The transformer with and without attention corresponds to the case where α = 1 (attention kept) and α = 0 (constant attention matrix).With this parameter, we can control the balance of attention versus linear layers in transformers.</p>
<p>We performed the following set of experiments on transformers (see Appendix F.1 for architecture and training details).( 1) One-layer transformers with width 128 and attention rate uniformly sampled in [0, 1] (Figure 7).( 2) One-layer transformers with width log-uniformly sampled in [32, 512] and attention rate uniformly sampled in [0, 1] (Figure 7).(3) Transformers with 2 to 4 layers, width 128 and attention rate uniformly sampled in [0, 1] (Figure 11).</p>
<p>The Pizza and the Clock algorithms are the dominating algorithms with circular embeddings.For circular models, most observed models either have low gradient symmetricity (corresponding to the Clock algorithm) or low distance irrelevance (corresponding to the Pizza algorithm).Two-dimensional phase change observed for attention rate and layer width.For the fixed-width experiment, we observed a clear phase transition from the Pizza algorithm to the Clock algorithm (characterized by gradient symmetricity and distance irrelevance).We also observe an almost linear phase boundary with regards to both attention rate and layer width.In other words, the attention rate transition point increases as the model gets wider.Dominance of linear layers determines whether the Pizza or the Clock algorithm is preferred.For one-layer transformers, we study the transition point against the attention rate and the width:</p>
<p>• The Clock algorithm dominates when the attention rate is higher than the phase change point, and the Pizza algorithm dominates when the attention rate is lower than the point.Our explanation is: At a high attention rate, the attention mechanism is more prominent in the network, giving rise to the clock algorithm.At a low attention rate, the linear layers are more prominent, giving rise to the pizza algorithm.</p>
<p>• The phase change point gets higher when the model width increases.Our explanation is: When the model gets wider, the linear layers become more capable while the attention mechanism receive less benefit (attentions remain scalars while outputs from linear layers become wider vectors).The linear layer therefore gets more prominence with a wider model.</p>
<p>Possibly hybrid algorithms between the Clock and the Pizza algorithms.The continuous phase change suggests the existence of networks that lie between the Clock and the Pizza algorithms.This is achievable by having some principal components acting as the Clock and some principal components acting as the Pizza.Existence of non-circular algorithms.Although our presentation focuses on circular algorithms (i.e., whose embeddings are circular), we find non-circular algorithms (i.e., whose embeddings do not form a circle when projected onto any plane) to be present in neural networks.See Appendix B for preliminary findings.We find that deeper networks are more likely to form non-circular algorithms.</p>
<p>We also observe the appearance of non-circular networks at low attention rates.Nevertheless, the Pizza algorithm continues to be observed (low distance irrelevance, high gradient symmetricity).</p>
<p>Related Work</p>
<p>Mechanistic interpretability aims to mechanically understand neural networks by reverse engineering them [2,3,5,4,10,11,1,12,13,14].One can either look for patterns in weights and activations by studying single-neuron behavior (superposition [11], monosemantic neurons [15]), or study meaningful modules or circuits grouped by neurons [4,14].Mechanistic interpretability is closely related to training dynamics [8,13,1].</p>
<p>Learning mathematical tasks: Mathematical tasks provide useful benchmarks for neural network interpretability, since the tasks themselves are well understood.The setup could be learning from images [16,17], with trainable embeddings [18], or with number as inputs [19,5].Beyond arithmetic relations, machine learning has been applied to learn other mathematical structures, including geometry [20], knot theory [21] and group theory [22].</p>
<p>Algorithmic phase transitions: Phase transitions are present in classical algorithms [23] and in deep learning [6,24,25].Usually the phase transition means that the algorithmic performance sharply changes when a parameter is varied (e.g., amount of data, network capacity etc).However, the phase transition studied in this paper is representational: both clock and pizza give perfect accuracy, but arrive at answers via different interal computations.These model-internal phase transitions are harder to study, but closer to corresponding phenomena in physical systems [24].</p>
<p>Algorithm learning in neural networks: Emergent abilities in deep neural networks, especially large language models, have recently attracted significant attention [26].An ability is "emergent" if the performance on a subtask suddenly increases with growing model sizes, though such claims depend on the choice of metric [27].It has been hypothesized that the emergence of specific capability in a model corresponds to the emergence of a modular circuit responsible for that capability, and that emergence of some model behaviors thus results from a sequence of quantized circuit discovery steps [5].</p>
<p>Conclusions</p>
<p>We have offered a closer look at recent findings that familiar algorithms arise in neural networks trained on specific algorithmic tasks.In modular arithmetic, we have shown that such algorithmic discoveries are not inevitable: in addition to the Clock algorithm reverse-engineered by [1], we find other algorithms (including a Pizza algorithm, and more complicated procedures) to be prevalent in trained models.These different algorithmic phases can be distinguished using a variety of new and existing interpretability techniques, including logit visualization, isolation of principle components in embedding space, and gradient-based measures of model symmetry.These techniques make it possible to automatically classify trained networks according to the algorithms they implement, and reveal algorithmic phase transitions in the space of model hyperparameters.Here we found specifically that the emergence of a Pizza or Clock algorithm depends on the relative strength of linear layers and attention outputs.We additionally showed that these algorithms are not implemented in isolation; instead, networks sometimes ensemble multiple copies of an algorithm in parallel.These results offer exciting new challenges for mechanistic interpretability: (1) How to find, classify, and interpret unfamiliar algorithms in a systematic way? (2) How to disentangle multiple, parallel algorithm implementations in the presence of ensembling?</p>
<p>Limitations We have focused on a single learning problem: modular addition.Even in this restricted domain, qualitatively different model behaviors emerge across architectures and seeds.Significant additional work is needed to scale these techniques to the even more complex models used in real-world tasks.</p>
<p>Broader Impact We believe interpretability techniques can play a crucial role in creating and improving safe AI systems.However, they may also be used to build more accurate systems, with the attendant risks inherent in all dual-use technologies.It is therefore necessary to exercise caution and responsible decision-making when deploying such techniques.</p>
<p>Supplementary material A Mathematical Analysis and An Example of Pizza Algorithm</p>
<p>In the pizza algorithm, we have  Step 2 Compute:
α = |cos(w k a) + cos(w k b)|/2 − |sin(w k a) + sin(w k b)|/2 ≈ |cos(w k (a − b)/2)| cos(w k (a + b)) β = |cos(w k a) + cos(w k b) + sin(w k a) + sin(w k b)|/(2 √ 2) − |cos(w k a) + cos(w k b) − sin(w k a) − sin(w k b)|/(2 √ 2) = |cos(w k a − π/4) + cos(w k b − π/4)|/2 − |sin(w k a − π/4) + sin(w k b − π/4)|/2 ≈ |cos(w k (a − b)/2)| cos(w k (a + b) − π/2) = |cos(w k (a − b)/2)| sin(w k (a + b))
Step 3 Output of this pizza is computed as a dot product.
Q ′ abc = α cos(w k c) + β sin(w k c) ≈ |cos(w k (a − b)/2)| cos(w k (a + b − c))
Similar circuits are observed in the wild, but instead of the above two-term approximation, a more complicated one is observed.See Appendix L for details.</p>
<p>The extra |cos(w k (a − b)/2)| term is not a coincidence.We can generalize our derivation as the following.</p>
<p>Lemma A.1.A symmetric function f (x, y) that is a linear combination of cos x, sin x, cos y, sin y4 can always be written as cos((x − y)/2)g(x + y) for some function g.</p>
<p>Proof.Notice cos x + cos y = cos((x − y)/2)(2 cos((x + y)/2)) and sin x + sin y = cos((x − y)/2)(2 sin((x + y)/2)), so α(cos x + cos y) + β(sin x + sin y) = cos((x − y)/2)(2α cos((x + y)/2) + 2β sin((x + y)/2)).</p>
<p>This is why we consider the output pattern with the |cos(w k (a − b)/2)| terms rather than the actual computation circuits as the determinant feature of the pizza algorithm.</p>
<p>B Non-Circular algorithms</p>
<p>One thing that further complicates our experiment is the existence of non-circular embeddings.While only circular algorithms are reported in the previous works [8,1], many non-circular embeddings are found in our experiments, e.g., 1D lines or 3D Lissajous-like curves, as shown in Figure 9.We leave the detailed analysis of these non-circular algorithms for future study.Since circular algorithms are our primary focus of study, we propose the following metric circularity to filter out non-circular algorithms.The metric reaches maximum 1 when the principal components aligns with cosine waves.
4 l=1    max k∈[1,2,••• ,p−1]    2 p p−1 j=0 v 2 l,j p−1 j=0 v l,j e 2πi•jk/p 2      
where i is the imaginary unit.c ∈ [0, 1] by Fourier analysis.c = 1 means first four components are Fourier waves.</p>
<p>Both Model A and Model B in Section 3 have a circularity around 99.8% and we consider models with circularity ≥ 99.5% circular.</p>
<p>C More Results from the Main Experiments</p>
<p>Here we provide Figure 7 with non-circular networks unfiltered (Figure 10).We can see more noise emerging in the plot.We also provide the training results from multi-layer transformers (Figure 11).</p>
<p>D Pizzas Come in Pairs</p>
<p>Cautious readers might notice that the pizza algorithm is imperfect -for near antipodal points, the sum vector will have a very small norm and the result will be noise-sensitive.While the problem is partially elevated by the use of multiple circles instead of one, we also noticed another pattern emerged: accompanying pizzas.</p>
<p>The idea is the following: suppose the difference between adjacent points is 2k mod p, then the antipodal points have difference ±k.Therefore, if we arrange a new circle with a difference k for adjacent points, we will get a pizza that works best for formerly antipodal points.</p>
<p>Algorithm: Accompanying Pizza</p>
<p>Step 1 Take w k as of the accompanied pizza.On given input a and b, circularly embed them to two vectors on the circumference (cos(2w k a), sin(2w k a)) and (cos(2w k b), sin(2w k b)).</p>
<p>Step 2 Compute the midpoint:
s = 1 2 (cos(2w k a) + cos(2w k b), sin(2w k a) + sin(2w k b))
Step 3 Output of this pizza is computed as a dot product.
A c = −(cos(w k c), sin(w k c)) • s
This is exactly what we observed in Model A (Table 3, Figure 13).With the six circles (pizzas and accompanying pizzas) included in the embedding, Model A also gets 100% accuracy.Figure 13: Correct logits of Model A (Pizza) after circle isolation.Only accompanying pizzas are displayed.Notice the complementing logit pattern (Figure 4).</p>
<p>E Results in Other Linear Architectures</p>
<p>While this is not the primary focus of our paper, we also ran experiments on the following four different linear model setups (see Section F.2 for setup details).</p>
<p>• For all the models, we first encode input tokens (a, b) with a trainable embedding layer W E :</p>
<p>x 1 = W E,a , x 2 = W E,b (positional embedding removed for simplicity).L 1 , L 2 , L 3 are trainable linear layers.The outmost layers (commonly referred as unembed layers) have no biases and the other layers have biases included for generality.</p>
<p>• Model α: calculate output logits as L 2 (ReLU(L 1 (x 1 + x 2 ))).</p>
<p>• Model β: calculate output logits as L 3 (ReLU(L 2 (ReLU(L 1 (x 1 + x 2 ))))).</p>
<p>• Model γ: calculate output logits as L 3 (ReLU(L 2 (ReLU(L 1 (x 1 ) + L 1 (x 2 ))))).</p>
<p>• Model δ: calculate output logits as
L 2 (ReLU(L 1 ([x 1 ; x 2 ]))) ([x 1 ;
x 2 ] stands for the concatenation of x 1 and x 2 )</p>
<p>The results are shown in Figure 14.Rather surprisingly, Model α, Model β and Model δ gave radically different results.Model β and Model γ are very similar, and in general they are more pizza-like than Model α, with lower distance irrelevancy and higher circularity.This could be explained by the addition of an extra linear layer.</p>
<p>However, Model δ gave very different results from Model α although they are both one-layer linear models.It is more likely to be non-circular and have very high distance irrelevancy in general.In other words, concatenating instead of adding embeddings yields radically different behaviors in one-layer linear model.This result, again, alarmed us the significance of induction biases in neural networks.</p>
<p>We also want to note that using different embeddings on two tokens of Model α doesn't resolve the discrepancy.The following model
• Model α ′ : calculate output logits as L 2 (ReLU(L 1 (x 1 + x 2 ))) where x 1 = W A E,a , x 2 = W B E,b on input (a, b) and W A E , W B E are different embedding layers.
gives roughly the same result as of Model α (Figure 14, lower right corner).</p>
<p>Figure 15 shows the correct logits after circle isolation (Section 3.3) of a circular model from Model β implementing the pizza algorithm.Figure 16 shows the correct logits after circle isolation (Section 3.3) of a circular model from Model δ.We can see the pattern is similar but different from the one of clock algorithm (Figure 5).We leave the study of such models to future work.</p>
<p>F Architecture and Training Details F.1 Transformers</p>
<p>Here we describe our setup for the main experiments.See Appendix E and Appendix I for experiments on different setups.</p>
<p>Architecture We train bidirectional transformers (attention unmasked) to perform modular addition mod p where p = 59.To calculate (a + b) mod p, the input is provided to the model as a sequence  The output logit at the last token is considered as the output of the model.For a transformer with "width" d, the input embedding and the residue stream will be d-dimensional, 4 attention heads of ⌊d/4⌋ dimensions will be employed, and the MLP will be of 4d hidden units.By default d = 128 is chosen.ReLU is used as the activation function and layer normalization isn't applied.The post-softmax attention matrix is interpolated between an all-one matrix and original as specified by the attention rate (Section 4.2).We want to point out that the setup of constant-attention transformers is also considered in the previous work [28].</p>
<p>Data Among all possible data points (p 2 = 3481 of them), we randomly select 80% as training samples and 20% as validation samples.This choice (small p and high training data fraction) helps accelerating the training.</p>
<p>Training We used AdamW optimizer [29] with learning rate γ = 0.001 and weight decay factor β = 2.We do not use minibatches and the shuffled training data is provided as a whole batch in every epoch.For each run, we start the training from scratch and train for 20, 000 epoches.We removed the runs that did not reach 100% validation accuracy at the end of the training (majority of the runs reached 100%).</p>
<p>F.2 Linear Models</p>
<p>Here we describe our setup for the linear model experiments (Appendix E).</p>
<p>Architecture We train several types of linear models to perform modular addition mod p where p = 59.The input embedding, residue stream and hidden layer are all d = 256 dimensional.ReLU is used as the activation function.The actual structures of network types are specified in Appendix E.</p>
<p>Data &amp; Training Same as in the previous section (Section F.1).</p>
<p>F.3 Computing Resources</p>
<p>A total of 226 GPU days of NVidia V100 is spent on this project, although we expect a replication would take significantly fewer resources.</p>
<p>G Mathematical Description of Constant-Attention transformer</p>
<p>In this section, we examine the structure of constant-attention transformers loosely following the notation of [10].</p>
<p>Denote the weight of embedding layer as W E , the weight of positional embedding as W pos , the weight of the value and output matrix of the j-th head of the t-th layer as W t,j V and W t,j O , the weights and biases of the input linear map of MLP in the t-th layer as W t in and b t in , the corresponding weights and biases of the output linear map as W t out and b t out , and the weight of the unembedding layer as W U .Notice that the query and the key matrices are irrelevant as the attention matrix is replaced with an all-one matrix.Denote x j as the value of residue stream vector after the first j layers and denote c i as the character in the i-th position.We use subscripts like x t to denote taking a specific element of vector.</p>
<p>We can formalize the logit calculation as the following:</p>
<p>• Embedding: x 0 i = W E,ci + W pos,i .• For each layer t from 1 to n layer :</p>
<p>-Constant Attention:
w t i = x t−1 i + j W t,j O W t,j V k x t−1 k . -MLP: x t = w t + b t out + W t out ReLU(b t in + W t in w t ). • Output: O = W U x nlayer .
In the particular case where the input length is 2, the number of layer is 1, and we focus on the logit of the last position, we may restate as the following (denote z as x 1 and y as w 1 ):</p>
<p>• Embedding:
x 1 = W E,c1 + W pos,1 , x 2 = W E,c2 + W pos,2 . • Constant Attention: y = x 2 + j W j O W j V (x 1 + x 2 ). • MLP: z = y + b t out + W t out ReLU(b t in + W t in y). • Output: o = W U z.
If we remove the skip connections, the network after embedding could be seen as
o = L U   L out   ReLU   L in   j L j O L j V (x 1 + x 2 )        
where L j V , L j O , L in , L out , L U are a series of linear layers corresponding to the matrices.</p>
<p>H Pizza with Attention</p>
<p>Extrapolating from Figure 7, we trained transformers with width 1024 and attention rate 1 (normal attention).After several tries, we are able to observe a trained circular model with distance irrelevance 0.156 and gradient symmetricity 0.995, which fits our definition of Pizza (Figure 17).</p>
<p>I Results on Slightly Different Setups</p>
<p>We considered the following variations of our setups (Appendix F.1, Section 4), for which the existence of pizzas and clocks as well as the phase changes are still observed.</p>
<p>GeLU instead of ReLU</p>
<p>We conducted the same 1-layer transformer experiment with activation function GeLU instead of ReLU.Very similar results are observed (Figure 18).</p>
<p>Encode Two Tokens Differently We conducted the 1-layer transformer experiments but with different embedding for the two tokens.Again very similar results are observed (Figure 19).We also discovered that the two tokens' embeddings are often aligned to implement the Pizza and Clock algorithm (Figure 20).</p>
<p>Adding Equal Sign</p>
<p>We conducted the 1-layer transformer experiment with an equal sign added.Very similar results are observed (Figure 21).</p>
<p>J Pizza Occurs Early in the Clock Training</p>
<p>We plotted intermediate states during the training of a model with attention (attention rate 1).Pizzalike pattern was observed early in the training, but the pattern gradually disappeared during the run (Figure 22).</p>
<p>K Accompanying Pizza Occurs Early in the Pizza Training</p>
<p>We plotted intermediate states during the training of a model without attention (attention rate 0).We observed the early emergence of a pattern similar to accompanying pizza in training runs (Figure</p>
<p>L A Closer Look at a Linear Pizza Model</p>
<p>In this section, we provide a full picture of the linear model shown in Figure 15 by investigating the actual weights in the model.</p>
<p>L.1 Model Structure</p>
<p>As described in Appendix E, on input (a, b), the output logits of the model is computed as
L 3 (ReLU(L 2 (ReLU(L 1 (Embed[a] + Embed[b]))))).
Denote the weight of embedding layer as W E , the weight of the unembedding layer (L 3 ) as W U , and the weights and biases of L 1 and L 2 as W 1 , b 1 and W 2 , b 2 , respectively, then the output logits on input (a, b) can be written as
W U ReLU(b 2 + W 2 ReLU(b 1 + W 1 (W E [a] + W E [b]))).</p>
<p>L.2 General Picture</p>
<p>We first perform principal component visualizations on the embedding and unembedding matrices.</p>
<p>From Figure 24, we can see that the embedding and unembedding matrices formed matching circles (circles with the same gap δ between adjacent entries).</p>
<p>We now give the general overview of the circuit.Each pair of matching circles forms an instance of Pizza and they operate independently (with rather limited interference).Specifically for each pair,</p>
<p>•  • These values are then passed through the second linear layer L 2 .Empirically the ReLU is not observed to be effective as the majority of values is positive.The output entries are then simply linear combinations of aforementioned outputs of L 1 .</p>
<p>• The unembedding matrix is finally applied.In the principal components we are considering,
W ′ U [c] ≈ (cos(w k c), sin(w k c)). (W ′
U stands for the two currently considered principal components of W U ; rotation and scaling omitted for brevity) and these two principal components correspond to a linear combination of the output entries of L 2 , which then correspond to a linear combination of the outputs of L 1 (thanks to the non-functional ReLU).</p>
<p>L.3 Aligning Weight Matrices</p>
<p>We first verify that the ReLU from the second layer is not functional.After removing it, the accuracy of the model remains 100% and the cross-entropy loss actually decreased from 6.20 × 10 −7 to 5.89 × 10 −7 .</p>
<p>Therefore, the model output can be approximately written as
W U (b 2 +W 2 ReLU(b 1 +W 1 (W E [a]+W E [b]))) = W U b 2 +W U W 2 ReLU(b 1 +W 1 (W E [a]+W E [b])).
We now "align" the weight matrices W 1 and W 2 by mapping through the directions of the principal components of the embeddings and unembeddings.That is, we calculate how these matrices act on and onto the principal directions (consider W 1 v for every principal direction v in W E and v T W 2 for every principal direction v in W U ).We call the other dimension of aligned W 1 and W 2 output and source dimensions, respectively (Figure 25).</p>
<p>In the aligned weight matrices, we can see a clear domino-like pattern: in most output or source dimensions, only two principal components have significant non-zero values, and they correspond to a pair of matching circle, or a pizza.In this way, every immediate dimension serves for exactly one pizza, so the pizzas do not interfere with each other.For the first principal unembedding dimension, it will be taken dot product with Call this function f (x, y).When we plug in x = cos(t), y = sin(t), we get a function that wellapproximated 8 cos(2t + 2) (Figure 26).Therefore, let t = w k (a + b)/2, the dot product will be approximately 8|cos(w k (a − b)/2)| cos(w k (a + b) + 2), or |cos(w k (a − b)/2)| cos(w k (a + b)) if we ignore the phase and scaling.This completes the picture we described above.</p>
<p>E 2 Same
2
ab = (E a + E b )/2 = (cos(w k a) + cos(w k b), sin(w k a) + sin(w k b))/a ≡ (E a,x , E a,y ) = (cos(w k a), sin(w k a)), b → Eb ≡ (E b,x , E b,y ) = (cos(w k b), sin(w k b)) x E b,x − E a,y E b,y E a,x E b,y + E a,y E b,x) = ( cos(w k (a + b)) sin(w k (a + b))) Q abc = U c ⋅ H ab , a, b E a , E b E ab Q abc U c ≡ (E c,x , E c,y ) = (cos(w k c), sin(w k c)) ⋅ U c Q abc (Clock) = cos(w k (a + b − c)) Q abc (Pizza) = cos(w k (a + b − c))</p>
<p>HFigure 1 :
1
Figure 1: Illustration of the Clock and the Pizza Algorithm.</p>
<p>(left): they represent tokens a and b as 2D vectors, and adding their polar angles using trigonometric identities.Concretely, the Clock algorithm consists of three steps: In step 1, tokens a and b are embedded as E a = [cos(w k a), sin(w k a)] and E b = [cos(w k b), sin(w k b)], respectively, where w k = 2πk/p (an everyday clock has p = 12 and k = 1).Then the polar angles of E a and E b are added (in step 2) and extracted (in step 3) via trigonometric identities.For each candidate output c, we denote the logit Q abc ; the predicted output is c * = argmax c Q abc .</p>
<p>Figure 2 :
2
Figure 2: Gradients on first six principal components of input embeddings.(a, b, c) in the title stands for taking gradients on the output logit c for input (a, b).x and y axes represent the gradients for embeddings of the first and the second token.The dashed line y = x signals a symmetric gradient.</p>
<p>Figure 3 :
3
Figure 3: Correct Logits of Model A &amp; Model B. The correct logits of Model A (left) have a clear dependence on a − b, while those of Model B (right) do not.</p>
<p>Figure 1 :
1
given a fixed label c, for all (a, b) with a + b = c (mod p), the points E ab = (E a + E b )/2 lie on a line though the origin of a 2D plane, and the points closer to this line than to the lines corresponding to any other c form two out of 2p mirrored "pizza slices", as shown at the right of the figure.Thus, to perform modular arithmetic, a network can determine which slice pair the average of the two embedding vectors lies in.Concretely, the Pizza algorithm also consists of three steps.Step 1 is the same as in the Clock algorithm: the tokens a and b are embedded at E a = (cos(w k a), sin(w k a)) and E b = (cos(w k b), sin(w k b)), respectively.Step 2 and Step 3 are different from the Clock algorithm.In Step 2.</p>
<p>, Model A's accuracy drops to zero at specific values of a − b, while Model B's accuracy is invariant in a − b.Applying circle isolation to Model A on the two principal components (one circle) yields a model with 32.8% overall accuracy, while retaining the first six principal components (three circles) yields an overall accuracy of 91.4%.See Appendix D for more discussion.By contrast, Model B achieves 100% when embeddings are truncated to the first six principal components.Circle isolation thus reveals an error correction mechanism achieved via ensembling: when an algorithm (clock or pizza) exhibits systematic errors on subset of inputs, models can implement multiple algorithm variants in parallel to obtain more robust predictions.</p>
<p>Figure 4 :
4
Figure 4: Correct logits of Model A (Pizza) after circle isolation.The rightmost pizza is accompanying the third pizza (discussed in Section 3.4 and Appendix D).Top: The logit pattern depends on a − b.Bottom: Embeddings for each circle.</p>
<p>Figure 5 :
5
Figure 5: Correct logits of Model B (Clock) after circle isolation.Top: The logit pattern depends on a + b.Bottom: Embeddings for each circle.</p>
<p>Figure 6 :
6
Figure 6: Distance irrelevance vs gradient symmetricity over all the main experiments.</p>
<p>Figure 7 :
7
Figure 7: Training results from 1-layer transformers.Each point in the plots represents a training run reaching circular embeddings and 100% validation accuracy.See Appendix C for additional plots.Top: Model width fixed to be 128.Bottom: Model width varies.The phase transition lines are calculated by logistic regression (classify the runs by whether gradient symmetricity &gt; 98% and whether distance irrelevance &lt; 0.6).</p>
<p>E ab = cos(w k (a − b)/2) • (cos(w k (a + b)/2), sin(w k (a + b)/2)), as cos x + cos y = cos((x − y)/2)(2 cos((x + y)/2)) and sin x + sin y = cos((x − y)/2)(2 sin((x + y)/2)).To get |cos(w k (a − b)/2)|(cos(w k (a + b)), sin(w k (a + b))), we generalize this to |cos(w k (a − b)/2)| cos(w k (a + b − u)) (the two given cases correspond to u = 0 and u = π/2/w k ).|(cos(w k u/2), sin(w k u/2)) • E ab | = |cos(w k (a − b)/2) cos(w k (a + b − u)/2)| |(− sin(w k u/2), cos(w k u/2)) • E ab | = |cos(w k (a − b)/2) sin(w k (a + b − u)/2)| thus their difference will be equal to |cos(w k (a − b)/2)|(|cos(w k (a + b − u)/2)| − |sin(w k (a + b − u)/2)|).Now notice |cos(t)| − |sin(t)| ≈ cos(2t) for any t ∈ R (Figure 8), so the difference is approximately |cos(w k (a − b)/2)| cos(w k (a + b − u)).</p>
<p>Figure 8 :
8
Figure 8: |cos(t)| − |sin(t)| is approximately cos(2t) for any t ∈ R Plugging in u = 0 and u = π/2/w k as mentioned, we get the following particular implementation of the pizza algorithm.Algorithm: Pizza, Example Step 1 On given input a and b, circularly embed them to two vectors on the circumference (cos(w k a), sin(w k a)) and (cos(w k b), sin(w k b)).</p>
<p>Figure 9 :
9
Figure 9: Visualization of the principal components of input embeddings for two trained non-circular models.Top: A line-like first principal component.Notice the re-arranged x axis (token id).Bottom: First three principal components forming a three-dimensional non-circular pattern.Each point represents the embedding of a token.Definition B.1 (Circularity).For some network, suppose the l-th principal component of its input embeddings is v l,0 , v l,1 , • • • , v l,p−1 , define its circularity based on first four components as</p>
<p>Figure 10 :
10
Figure 10: Training results from 1-layer transformers.Each point in the plots represents a training run reaching 100% validation accuracy.Among all the trained 1-layer transformers, 34.31% are circular.Top: Model width fixed to be 128.Bottom: Model width varies.</p>
<p>Figure 11 :
11
Figure 11: Training results from transformers with 2, 3 and 4 layers.Among all the trained transformers with 2, 3 and 4 layers, 9.95%, 11.55% and 6.08% are circular, respectively.</p>
<p>Figure 12 :
12
Figure 12: An Illustration on the Accompanying Pizza Algorithm</p>
<p>Figure 14 :
14
Figure 14: Training results from linear models.Each point in the first-row plots represents a training run.The second row are histograms for distance irrelevancy of each model type.</p>
<p>Figure 15 :
15
Figure 15: Correct logits from Model β after circle isolation.</p>
<p>Figure 16 :
16
Figure 16: Correct logits from Model δ after circle isolation.</p>
<p>Figure 17 :
17
Figure 17: Correct logits of the trained model in Section H after circle isolation (Section 3.3).</p>
<p>Figure 18 :
18
Figure 18: Training results from 1-layer transformers with GeLU instead of ReLU as the activation function.Each point in the plots represents a training run that reached 100% validation accuracy.</p>
<p>Figure 19 :
19
Figure 19: Training results from 1-layer transformers where the two tokens use different embeddings (feed [a, b + p] to the model on input (a, b); 2p tokens are handled in the embedding layer).Each point in the plots represents a training run that reached 100% validation accuracy.We did not use circularity to filter the result because it is no longer well-defined.</p>
<p>Figure 20 :
20
Figure 20: Correct logits after circle isolation from a trained model where two tokens use different embeddings.The blue points represent the embeddings for the first token and the green points represent the embeddings for the second token.The model is implementing the Pizza algorithm.The correct logit pattern is shifted comparing to the previous patterns because the embeddings of two tokens do not line up exactly.For example, the third circle has near-maximum correct logit for a = 6, b = 3 (the two points lining up on the top) and (a − b)/18 ≡ 10 (mod 59).This is the reason that the correct logit pattern appears to be shifted 10 units down.</p>
<p>Figure 21 :
21
Figure 21: Training results from 1-layer transformers where an equal sign is added (feed [a, b, =] to the model on input (a, b) where = is a special token; p + 1 tokens are handled in the embedding layer; context length of the model becomes 3).Each point in the plots represents a training run that reached 100% validation accuracy.We did not use circularity to filter the result because it is no longer well-defined.</p>
<p>Figure 22 :
22
Figure 22: For a 1-layer transformer with attention, correct logits after principal component (possibly non-circle) isolations at various states during the training.The pizza-like pattern gradually desolved.</p>
<p>Figure 23 :
23
Figure 23: Immediate state after 600 epochs of training for a 1-layer transformer with constant attention.</p>
<p>The embedding matrix first places the inputs a, b on the circumference:W ′ E [a] ≈ (cos(w k a), sin(w k a)) and W ′ E [b] ≈ (cos(w k b), sin(w k b)) (w k = 2πk/p for some integer k ∈ [1, p − 1]as in Section 2.1; W ′ E stands for the two currently considered principal components of W E ; rotation and scaling omitted for brevity).</p>
<p>•</p>
<p>The embeddings are added to get (cos(w k a) + cos(w k b), sin(w k a) + sin(w k b)) = cos(w k (a − b)/2) • (cos(w k (a + b)/2), sin(w k (a + b)/2)) • It is then passed through the first linear layer L 1 .Each result entry pre-ReLU will thus be a linear combination of the two dimensions of the aforementioned vectors, i.e. cos(w k (a − b)/2) • (α cos(w k (a + b)/2) + β sin(w k (a + b)/2)) for some α, β, which will become |cos(w k (a − b)/2)||α cos(w k (a + b)/2) + β sin(w k (a + b)/2))| after ReLU.</p>
<p>•</p>
<p>Similar to the formula | sin(t)| − | cos(t)| ≈ cos(2t) discussed in Appendix A, these linear combinations provide good approximations for |cos(w k (a − b)/2)| cos(w k (a + b)) and |cos(w k (a − b)/2)| sin(w k (a + b)).Finally we arrive at |cos(w k (a − b)/2)|(cos(w k c) cos(w k (a + b)) + sin(w k c) sin(w k (a + b))) =|cos(w k (a − b)/2)| cos(w k (a + b − c)).</p>
<p>Figure 24 :
24
Figure 24: Visualization of the principal components of the embeddings and unembedding matrices.</p>
<p>Figure 25 :
25
Figure 25: Visualization of the aligned W 1 and W 2 .</p>
<p>[ 1 .
1
326, 0.179, 0.142, −0.458, 1.101, −0.083, 0.621, 1.255, −0.709, 0.123, −1.346, −0.571, 1.016, 1.337, 0.732, 0.839, 0.129, 0.804, 0.377, 0.078, 1.322, −1.021, −0.799, −0.339, 1.117, −1.162, −1.423, −1.157, 1.363, 0.156, −0.165, −0.451, −1.101, −0.572, −1.180, −1.386, −1.346, −0.226, 1.091, 1.159, −0.524, 1.441, −0.949, −1.248].</p>
<p>[1]da et al.[1]discovered a circuit that uses these circular embeddings to implement an interpretable algorithm for modular arithmetic, which we call the Clock algorithm.
AlgorithmLearned EmbeddingsGradient Symmetry Required Non-linearityClockCircleNoMultiplicationPizzaCircleYesAbsolute valueNon-circular Line, Lissajous-like curves, etc.N/AN/A</p>
<p>Table</p>
<p>If a meeting starts at 10, and lasts for 3 hours, then it will end at 1." This familiar fact is a description of a modular sum, 10+3 = 1 (mod 12), and the movement of a clock describes a simple algorithm for modular arithmetic: the numbers 1 through 12 are arranged on a circle in 360 • /12 = 30 • increments, angles of 10 × 30 • and 3 × 30 • are added together, then this angle is evaluated to determine that it corresponds to 1 × 30 • .</p>
<p>1: Different neural algorithms for modular addition "</p>
<p>1, E a and E b are averaged to produce an embedding E ab .In Step 2.2 and Step 3, the polar angle of E ab is (implicitly) computed by computing the logit Q abc for any possible outputs c.Both the Clock and Pizza algorithms compute logits Q abc in Step 3, but they have different forms, shown in Figure1.Specifically, Q abc (Pizza) has an extra multiplicative factor |cos(w k (a − b)/2)| compared to Q abc (Clock ).As a result, given c = a + b, Q abc (Pizza) is dependent on a − b, but Q abc (Clock ) is not.The intuition for the dependence is that a sample is more likely to be classified correctly if E ab is longer.The norm of this vector depends on a − b.As we observe in Figure
While one possibility of doing so is to take the absolutevalue of the dot product of E ab with (cos(w k c/2), sin(w k c/2)), it is not commonly observed inneural networks (and will result in a different logit pattern). Instead, Step 2.2 transforms E ab into avector encoding | cos(w k (a − b)/2)|(cos(w k (a + b)), sin(w k (a + b))), which is then dotted with the output embedding U c = (cos(w k c), sin(w k c)). Finally, the prediction is c  *  = argmax c Q abc . SeeAppendix A and Appendix L for a more detailed analysis of a neural circuit that computes H ab in areal network.The key difference between the two algorithms lies in what non-linear operations are required: Clockrequires multiplication of inputs in Step 2, while Pizza requires only absolute value computation,which is easily implemented by the ReLU layers. If neural networks lack inductive biases towardimplementing multiplication, they may be more likely to implement Pizza rather than Clock, as wewill verify in Section 4.3.2 First Evidence for Pizza: Logit Patterns
Accompanied pizzas #1/#2/#3 can achieve 99.7% accuracy, but accompanying pizzas #4/#5/#6 can only achieve 16.7% accuracy.
To speed-up the calculations, in our experiments S is taken as a random subset of Z 3 p of size 100.
The actual neural networks could be more complicated -even if our neural network is locally linear and symmetric, locally they could be asymmetric (e.g. |x| + |y| could locally be x − y). Nevertheless, the pattern is observed in our trained networks.
AcknowledgementWe would like to thank Mingyang Deng and anonymous reviewers for valuable and fruitful discussions and MIT SuperCloud for providing computation resources.ZL and MT are supported by the Foundational Questions Institute, the Rothberg Family Fund for Cognitive Science and IAIFI through NSF grant PHY-2019786.JA is supported by a gift from the OpenPhilanthropy Foundation.
Progress measures for grokking via mechanistic interpretability. Neel Nanda, Lawrence Chan, Tom Lieberum, Jess Smith, Jacob Steinhardt, The Eleventh International Conference on Learning Representations. 2023</p>
<p>Zoom in: An introduction to circuits. Distill. Chris Olah, Nick Cammarata, Ludwig Schubert, Gabriel Goh, Michael Petrov, Shan Carter, 2020</p>
<p>In-context learning and induction heads. Catherine Olsson, Nelson Elhage, Neel Nanda, Nicholas Joseph, Nova Dassarma, Tom Henighan, Ben Mann, Amanda Askell, Yuntao Bai, Anna Chen, Tom Conerly, Dawn Drain, Deep Ganguli, Zac Hatfield-Dodds, Danny Hernandez, Scott Johnston, Andy Jones, Jackson Kernion, Liane Lovitt, Kamal Ndousse, Dario Amodei, Tom Brown, Jack Clark, Jared Kaplan, Sam Mccandlish, Chris Olah, 2022Transformer Circuits Thread</p>
<p>Interpretability in the wild: a circuit for indirect object identification in GPT-2 small. Kevin Ro, Wang , Alexandre Variengien, Arthur Conmy, Buck Shlegeris, Jacob Steinhardt, The Eleventh International Conference on Learning Representations. 2023</p>
<p>The quantization model of neural scaling. Eric J Michaud, Ziming Liu, Uzay Girit, Max Tegmark, arXiv:2303.135062023arXiv preprint</p>
<p>What learning algorithm is in-context learning? investigations with linear models. Ekin Akyürek, Dale Schuurmans, Jacob Andreas, Tengyu Ma, Denny Zhou, The Eleventh International Conference on Learning Representations. 2023</p>
<p>Attention is all you need. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, Illia Polosukhin, Advances in Neural Information Processing Systems. 201730</p>
<p>Towards understanding grokking: An effective theory of representation learning. Ziming Liu, Ouail Kitouni, Eric Niklas S Nolte, Max Michaud, Mike Tegmark, Williams, Advances in Neural Information Processing Systems. 202235</p>
<p>The lottery ticket hypothesis: Finding sparse, trainable neural networks. Jonathan Frankle, Michael Carbin, International Conference on Learning Representations. 2019</p>
<p>A mathematical framework for transformer circuits. Nelson Elhage, Neel Nanda, Catherine Olsson, Tom Henighan, Nicholas Joseph, Ben Mann, Amanda Askell, Yuntao Bai, Anna Chen, Tom Conerly, Nova Dassarma, Dawn Drain, Deep Ganguli, Zac Hatfield-Dodds, Danny Hernandez, Andy Jones, Jackson Kernion, Liane Lovitt, Kamal Ndousse, Dario Amodei, Tom Brown, Jack Clark, Jared Kaplan, Sam Mccandlish, Chris Olah, 2021Transformer Circuits Thread</p>
<p>Toy models of superposition. Nelson Elhage, Tristan Hume, Catherine Olsson, Nicholas Schiefer, Tom Henighan, Shauna Kravec, Zac Hatfield-Dodds, Robert Lasenby, Dawn Drain, Carol Chen, Roger Grosse, Sam Mccandlish, Jared Kaplan, Dario Amodei, Martin Wattenberg, Christopher Olah, 2022Transformer Circuits Thread</p>
<p>A toy model of universality: Reverse engineering how networks learn group operations. Bilal Chughtai, Lawrence Chan, Neel Nanda, The Fortieth International Conference on Machine Learning. 2023</p>
<p>Omnigrok: Grokking beyond algorithmic data. Ziming Liu, Eric J Michaud, Max Tegmark, The Eleventh International Conference on Learning Representations. 2023</p>
<p>Arthur Conmy, Augustine N Mavor-Parker, Aengus Lynch, Stefan Heimersheim, Adrià Garriga-Alonso, arXiv:2304.14997Towards automated circuit discovery for mechanistic interpretability. 2023arXiv preprint</p>
<p>Finding neurons in a haystack: Case studies with sparse probing. Wes Gurnee, Neel Nanda, Matthew Pauly, Katherine Harvey, Dmitrii Troitskii, Dimitris Bertsimas, arXiv:2305.016102023arXiv preprint</p>
<p>Visual learning of arithmetic operation. Yedid Hoshen, Shmuel Peleg, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence2016</p>
<p>Integration of neural network-based symbolic regression in deep learning for scientific discovery. Samuel Kim, Peter Y Lu, Srijon Mukherjee, Michael Gilbert, Li Jing, Vladimir Čeperić, Marin Soljačić, IEEE Transactions on Neural Networks and Learning Systems. 3292020</p>
<p>Alethea Power, Yuri Burda, Harri Edwards, Igor Babuschkin, Vedant Misra, Grokking, arXiv:2201.02177Generalization beyond overfitting on small algorithmic datasets. 2022arXiv preprint</p>
<p>Hidden progress in deep learning: SGD learns parities near the computational limit. Boaz Barak, Benjamin Edelman, Surbhi Goel, Sham Kakade, Eran Malach, Cyril Zhang, Advances in Neural Information Processing Systems. 202235</p>
<p>Machine-learning mathematical structures. Yang-Hui He, International Journal of Data Science in the Mathematical Sciences. 1012023</p>
<p>Learning to unknot. Sergei Gukov, James Halverson, Fabian Ruehle, Piotr Sułkowski, Machine Learning: Science and Technology. 22250352021</p>
<p>Advancing mathematics by guiding human intuition with ai. Alex Davies, Petar Veličković, Lars Buesing, Sam Blackwell, Daniel Zheng, Nenad Tomašev, Richard Tanburn, Peter Battaglia, Charles Blundell, András Juhász, Nature. 60078872021</p>
<p>Phase transitions in combinatorial optimization problems: basics, algorithms and statistical mechanics. K Alexander, Martin Hartmann, Weigt, 2006John Wiley &amp; Sons</p>
<p>Phase transitions in machine learning. Lorenza Saitta, Attilio Giordana, Antoine Cornuejols, 2011Cambridge University Press</p>
<p>Mechanistic mode connectivity. Ekdeep Singh Lubana, Eric J Bigelow, Robert P Dick, David Krueger, Hidenori Tanaka, International Conference on Machine Learning. PMLR2023</p>
<p>Emergent abilities of large language models. Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, Ed H Chi, Tatsunori Hashimoto, Oriol Vinyals, Percy Liang, Jeff Dean, William Fedus, Transactions on Machine Learning Research. 2022Survey Certification</p>
<p>Rylan Schaeffer, Brando Miranda, Sanmi Koyejo, arXiv:2304.15004Are emergent abilities of large language models a mirage?. 2023arXiv preprint</p>
<p>How much does attention actually attend? questioning the importance of attention in pretrained transformers. Michael Hassid, Hao Peng, Daniel Rotem, Jungo Kasai, Ivan Montero, Noah A Smith, Roy Schwartz, Findings of the Association for Computational Linguistics: EMNLP 2022. Abu Dhabi, United Arab EmiratesAssociation for Computational LinguisticsDecember 2022</p>
<p>Decoupled weight decay regularization. Ilya Loshchilov, Frank Hutter, International Conference on Learning Representations. 2019</p>            </div>
        </div>

    </div>
</body>
</html>