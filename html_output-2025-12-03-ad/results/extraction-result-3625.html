<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-3625 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-3625</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-3625</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-89.html">extraction-schema-89</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) or related AI systems being used to distill, extract, or induce qualitative laws, rules, or scientific principles from large collections of scholarly or scientific papers.</div>
                <p><strong>Paper ID:</strong> paper-259936960</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2307.07522v3.pdf" target="_blank">The Future of Fundamental Science Led by Generative Closed-Loop Artificial Intelligence</a></p>
                <p><strong>Paper Abstract:</strong> Recent advances in machine learning and AI, including Generative AI and LLMs, are disrupting technological innovation, product development, and society as a whole. AI's contribution to technology can come from multiple approaches that require access to large training data sets and clear performance evaluation criteria, ranging from pattern recognition and classification to generative models. Yet, AI has contributed less to fundamental science in part because large data sets of high-quality data for scientific practice and model discovery are more difficult to access. Generative AI, in general, and Large Language Models in particular, may represent an opportunity to augment and accelerate the scientific discovery of fundamental deep science with quantitative models. Here we explore and investigate aspects of an AI-driven, automated, closed-loop approach to scientific discovery, including self-driven hypothesis generation and open-ended autonomous exploration of the hypothesis space. Integrating AI-driven automation into the practice of science would mitigate current problems, including the replication of findings, systematic production of data, and ultimately democratisation of the scientific process. Realising these possibilities requires a vision for augmented AI coupled with a diversity of AI approaches able to deal with fundamental aspects of causality analysis and model discovery while enabling unbiased search across the space of putative explanations. These advances hold the promise to unleash AI's potential for searching and discovering the fundamental structure of our world beyond what human scientists have been able to achieve. Such a vision would push the boundaries of new fundamental science rather than automatize current workflows and instead open doors for technological innovation to tackle some of the greatest challenges facing humanity today.</p>
                <p><strong>Cost:</strong> 0.015</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e3625.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e3625.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) or related AI systems being used to distill, extract, or induce qualitative laws, rules, or scientific principles from large collections of scholarly or scientific papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLMs</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Large Language Models (LLMs, foundational transformer-based models)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Transformer-based foundation models trained on very large text corpora that can read, synthesise, and generate natural language; in this paper they are proposed as tools to digest scientific literature and propose candidate models, causal links, or hypotheses from that corpus-level knowledge.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>The Future of Fundamental Science Led by Generative Closed-Loop Artificial Intelligence</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>unspecified foundational LLMs (transformer-based)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>General class of transformer-based foundation models (large pretrained language models) discussed in the paper; no specific architecture size or implementation detail is given in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>input_domain</strong></td>
                            <td>multidisciplinary scholarly/scientific literature (natural-language papers across domains)</td>
                        </tr>
                        <tr>
                            <td><strong>corpus_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>law_type</strong></td>
                            <td>Qualitative scientific models and principles: candidate mathematical relations, causal hypotheses, conceptual frameworks and causal links between variables derived from the literature</td>
                        </tr>
                        <tr>
                            <td><strong>distillation_method</strong></td>
                            <td>Proposed use of language-modeling on the literature to identify patterns and correlations; suggested integration with retrieval/augmentation, prompting/translation of high-level conjectures into computable modules, and hybridisation with active learning, counterfactual reasoning and neuro-symbolic/causal methods (proposal-level — no concrete pipeline or experiment reported).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Not empirically evaluated in this paper; the paper proposes validation via expert review, experimental/empirical testing, mechanistic verification and independent explainable systems.</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>Speculative potential only: the paper argues LLMs could synthesise literature, interconnect disparate ideas, propose hypotheses and candidate mathematical relations or causal links, and act as translators between humans and mechanistic model spaces. No empirical distilled qualitative laws from literature are reported in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Paper-identifed challenges include statistical rather than causal nature, hallucination and hidden misalignments, training-data bias limiting novelty (risk of reproducing existing hypotheses), limited causal depth, need for mechanistic/independent verification, interpretability and traceability issues, and unspecified scalability/corpus-size constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Future of Fundamental Science Led by Generative Closed-Loop Artificial Intelligence', 'publication_date_yy_mm': '2023-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3625.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e3625.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) or related AI systems being used to distill, extract, or induce qualitative laws, rules, or scientific principles from large collections of scholarly or scientific papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Generative AI (GenAI)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Generative Artificial Intelligence (GenAI, including LLMs)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Umbrella term for generative statistical models (including LLMs) that can synthesise and generate content; discussed as having potential to explore scientific hypothesis space by processing language-based scientific corpora but with limited demonstrated contribution to fundamental science so far.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>The Future of Fundamental Science Led by Generative Closed-Loop Artificial Intelligence</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>generative AI systems (unspecified)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Statistical generative models (e.g., large pretrained language models and related generative architectures) described at a conceptual level; the paper notes these are statistical in nature and may need supplementation with symbolic/causal methods.</td>
                        </tr>
                        <tr>
                            <td><strong>input_domain</strong></td>
                            <td>scientific literature and experimental data across domains (multidisciplinary)</td>
                        </tr>
                        <tr>
                            <td><strong>corpus_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>law_type</strong></td>
                            <td>Exploratory hypotheses, candidate relations and conceptual frameworks derived from synthesising corpus-level statistical patterns</td>
                        </tr>
                        <tr>
                            <td><strong>distillation_method</strong></td>
                            <td>Corpus-level synthesis via learned statistical patterns of language/data; recommended augmentation with active learning, retrieval, neuro-symbolic integration and causal analysis (proposal-level).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Not empirically validated here; proposed evaluation via human-in-the-loop guidance, expert assessment and experimental validation.</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>Paper states GenAI/LLMs are promising for model discovery and synthesis of knowledge but have so far made little to no contributions to new fundamental scientific laws; their potential is discussed conceptually rather than demonstrated.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Inherits statistical ML limitations: lack of symbolic/causal guarantees, potential for model collapse when overtrained on the same data, limited depth for breakthrough discovery, biases from training corpora, and need for complementary symbolic/causal methods.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Future of Fundamental Science Led by Generative Closed-Loop Artificial Intelligence', 'publication_date_yy_mm': '2023-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3625.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e3625.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) or related AI systems being used to distill, extract, or induce qualitative laws, rules, or scientific principles from large collections of scholarly or scientific papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Eureqa</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Eureqa (symbolic regression / equation-discovery system)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An evolutionary/symbolic-regression system (commercialised via NuTONian/DataRobot) that builds mathematical expressions from time-series and experimental data to explain observed behaviour; cited as an example of AI that discovers equations from data.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>The Future of Fundamental Science Led by Generative Closed-Loop Artificial Intelligence</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Eureqa (evolutionary symbolic-regression engine)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Symbolic-regression system using evolutionary search to compose mathematical building blocks into equations that fit data; not a language model and not applied in this paper to literature corpora.</td>
                        </tr>
                        <tr>
                            <td><strong>input_domain</strong></td>
                            <td>time-series and quantitative experimental datasets (e.g., physics, biology measurements)</td>
                        </tr>
                        <tr>
                            <td><strong>corpus_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>law_type</strong></td>
                            <td>Quantitative mathematical laws / explicit equations inferred from measurement data</td>
                        </tr>
                        <tr>
                            <td><strong>distillation_method</strong></td>
                            <td>Symbolic regression / evolutionary search over mathematical expressions to optimise fit to observed data.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Fits and model-selection on data (mentioned historically); this paper does not report new evaluations.</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>Presented as a historical/example system that successfully produced candidate equations from data; the paper cites it as part of the lineage of systems attempting to discover governing equations, but not as an LLM operating over literature.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Designed for numeric data rather than processing textual scholarly corpora; requires suitable measured data and can be sensitive to noise and choice of primitives/prior building blocks.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Future of Fundamental Science Led by Generative Closed-Loop Artificial Intelligence', 'publication_date_yy_mm': '2023-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Distilling Free-Form Natural Laws from Experimental Data <em>(Rating: 2)</em></li>
                <li>On the Opportunities and Risks of Foundation Models <em>(Rating: 2)</em></li>
                <li>GPT-4 Technical Report <em>(Rating: 2)</em></li>
                <li>Highly accurate protein structure prediction with AlphaFold <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-3625",
    "paper_id": "paper-259936960",
    "extraction_schema_id": "extraction-schema-89",
    "extracted_data": [
        {
            "name_short": "LLMs",
            "name_full": "Large Language Models (LLMs, foundational transformer-based models)",
            "brief_description": "Transformer-based foundation models trained on very large text corpora that can read, synthesise, and generate natural language; in this paper they are proposed as tools to digest scientific literature and propose candidate models, causal links, or hypotheses from that corpus-level knowledge.",
            "citation_title": "The Future of Fundamental Science Led by Generative Closed-Loop Artificial Intelligence",
            "mention_or_use": "mention",
            "model_name": "unspecified foundational LLMs (transformer-based)",
            "model_description": "General class of transformer-based foundation models (large pretrained language models) discussed in the paper; no specific architecture size or implementation detail is given in the paper.",
            "input_domain": "multidisciplinary scholarly/scientific literature (natural-language papers across domains)",
            "corpus_size": null,
            "law_type": "Qualitative scientific models and principles: candidate mathematical relations, causal hypotheses, conceptual frameworks and causal links between variables derived from the literature",
            "distillation_method": "Proposed use of language-modeling on the literature to identify patterns and correlations; suggested integration with retrieval/augmentation, prompting/translation of high-level conjectures into computable modules, and hybridisation with active learning, counterfactual reasoning and neuro-symbolic/causal methods (proposal-level — no concrete pipeline or experiment reported).",
            "evaluation_method": "Not empirically evaluated in this paper; the paper proposes validation via expert review, experimental/empirical testing, mechanistic verification and independent explainable systems.",
            "results_summary": "Speculative potential only: the paper argues LLMs could synthesise literature, interconnect disparate ideas, propose hypotheses and candidate mathematical relations or causal links, and act as translators between humans and mechanistic model spaces. No empirical distilled qualitative laws from literature are reported in this paper.",
            "limitations_or_challenges": "Paper-identifed challenges include statistical rather than causal nature, hallucination and hidden misalignments, training-data bias limiting novelty (risk of reproducing existing hypotheses), limited causal depth, need for mechanistic/independent verification, interpretability and traceability issues, and unspecified scalability/corpus-size constraints.",
            "uuid": "e3625.0",
            "source_info": {
                "paper_title": "The Future of Fundamental Science Led by Generative Closed-Loop Artificial Intelligence",
                "publication_date_yy_mm": "2023-07"
            }
        },
        {
            "name_short": "Generative AI (GenAI)",
            "name_full": "Generative Artificial Intelligence (GenAI, including LLMs)",
            "brief_description": "Umbrella term for generative statistical models (including LLMs) that can synthesise and generate content; discussed as having potential to explore scientific hypothesis space by processing language-based scientific corpora but with limited demonstrated contribution to fundamental science so far.",
            "citation_title": "The Future of Fundamental Science Led by Generative Closed-Loop Artificial Intelligence",
            "mention_or_use": "mention",
            "model_name": "generative AI systems (unspecified)",
            "model_description": "Statistical generative models (e.g., large pretrained language models and related generative architectures) described at a conceptual level; the paper notes these are statistical in nature and may need supplementation with symbolic/causal methods.",
            "input_domain": "scientific literature and experimental data across domains (multidisciplinary)",
            "corpus_size": null,
            "law_type": "Exploratory hypotheses, candidate relations and conceptual frameworks derived from synthesising corpus-level statistical patterns",
            "distillation_method": "Corpus-level synthesis via learned statistical patterns of language/data; recommended augmentation with active learning, retrieval, neuro-symbolic integration and causal analysis (proposal-level).",
            "evaluation_method": "Not empirically validated here; proposed evaluation via human-in-the-loop guidance, expert assessment and experimental validation.",
            "results_summary": "Paper states GenAI/LLMs are promising for model discovery and synthesis of knowledge but have so far made little to no contributions to new fundamental scientific laws; their potential is discussed conceptually rather than demonstrated.",
            "limitations_or_challenges": "Inherits statistical ML limitations: lack of symbolic/causal guarantees, potential for model collapse when overtrained on the same data, limited depth for breakthrough discovery, biases from training corpora, and need for complementary symbolic/causal methods.",
            "uuid": "e3625.1",
            "source_info": {
                "paper_title": "The Future of Fundamental Science Led by Generative Closed-Loop Artificial Intelligence",
                "publication_date_yy_mm": "2023-07"
            }
        },
        {
            "name_short": "Eureqa",
            "name_full": "Eureqa (symbolic regression / equation-discovery system)",
            "brief_description": "An evolutionary/symbolic-regression system (commercialised via NuTONian/DataRobot) that builds mathematical expressions from time-series and experimental data to explain observed behaviour; cited as an example of AI that discovers equations from data.",
            "citation_title": "The Future of Fundamental Science Led by Generative Closed-Loop Artificial Intelligence",
            "mention_or_use": "mention",
            "model_name": "Eureqa (evolutionary symbolic-regression engine)",
            "model_description": "Symbolic-regression system using evolutionary search to compose mathematical building blocks into equations that fit data; not a language model and not applied in this paper to literature corpora.",
            "input_domain": "time-series and quantitative experimental datasets (e.g., physics, biology measurements)",
            "corpus_size": null,
            "law_type": "Quantitative mathematical laws / explicit equations inferred from measurement data",
            "distillation_method": "Symbolic regression / evolutionary search over mathematical expressions to optimise fit to observed data.",
            "evaluation_method": "Fits and model-selection on data (mentioned historically); this paper does not report new evaluations.",
            "results_summary": "Presented as a historical/example system that successfully produced candidate equations from data; the paper cites it as part of the lineage of systems attempting to discover governing equations, but not as an LLM operating over literature.",
            "limitations_or_challenges": "Designed for numeric data rather than processing textual scholarly corpora; requires suitable measured data and can be sensitive to noise and choice of primitives/prior building blocks.",
            "uuid": "e3625.2",
            "source_info": {
                "paper_title": "The Future of Fundamental Science Led by Generative Closed-Loop Artificial Intelligence",
                "publication_date_yy_mm": "2023-07"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Distilling Free-Form Natural Laws from Experimental Data",
            "rating": 2,
            "sanitized_title": "distilling_freeform_natural_laws_from_experimental_data"
        },
        {
            "paper_title": "On the Opportunities and Risks of Foundation Models",
            "rating": 2,
            "sanitized_title": "on_the_opportunities_and_risks_of_foundation_models"
        },
        {
            "paper_title": "GPT-4 Technical Report",
            "rating": 2,
            "sanitized_title": "gpt4_technical_report"
        },
        {
            "paper_title": "Highly accurate protein structure prediction with AlphaFold",
            "rating": 1,
            "sanitized_title": "highly_accurate_protein_structure_prediction_with_alphafold"
        }
    ],
    "cost": 0.015032499999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>The Future of Fundamental Science Led by Generative Closed-Loop Artificial Intelligence
29 Aug 2023</p>
<p>Hector Zenil hector.zenil@cs.ox.ac.uk 
Department of Chemical Engineering and Biotechnology
University of Cambridge</p>
<p>The Alan Turing Institute</p>
<p>Oxford Immune Algorithmics</p>
<p>Algorithmic Nature Group
LABORES for the Natural and Digital Sciences</p>
<p>Jesper Tegnér 
School of Computer Science
23 Knowledge Lab
Living Systems Laboratory, BESE, CEMSE, King Abdullah University of Sciences and Technology 22
University of Birmingham
University of Chicago</p>
<p>Department of Medicine
Karolinska InstitutetStockholmSweden</p>
<p>Felipe S Abrahão 
Oxford Immune Algorithmics</p>
<p>Algorithmic Nature Group
LABORES for the Natural and Digital Sciences</p>
<p>Centre for Logic, Epistemology and the History of Science
University of Campinas
Brazil</p>
<p>DEXL, National Laboratory for Scientific Computing
Brazil</p>
<p>Alexander Lavin 
Vipin Kumar 
Department of Computer Science and Engineering
University of Minnesota</p>
<p>Jeremy G Frey 
Department of Chemistry
University of Southampton</p>
<p>Adrian Weller 
Department of Chemical Engineering and Biotechnology
University of Cambridge</p>
<p>The Alan Turing Institute</p>
<p>Larisa Soldatova 
Department of Computing
University of London
10 Vice-Chancellor's OfficeGoldsmiths</p>
<p>Loughborough University</p>
<p>Alan R Bundy 
School of Informatics
University of Edinburgh</p>
<p>Nicholas R Jennings 
Koichi Takahashi 
RIKEN Center for Biosystems Dynamics Research</p>
<p>Lawrence Hunter 
Center for Computational Pharmacology
School of Medicine
Department of Knowledge Technologies
Department of Materials
University of Colorado
15, Jozef Stefan Institute 16</p>
<p>University of Oxford</p>
<p>Saso Dzeroski 
Andrew Briggs 
Frederick D Gregory 
Carla P Gomes 
Department of Computer Science
Cornell University</p>
<p>Jon Rowe 
The Alan Turing Institute</p>
<p>James Evans 
Hiroaki Kitano 
The Alan Turing Institute</p>
<p>The Systems Biology Institute, Okinawa Institute of Science and Technology</p>
<p>Ross King 
Department of Chemical Engineering and Biotechnology
University of Cambridge</p>
<p>The Alan Turing Institute</p>
<p>The Future of Fundamental Science Led by Generative Closed-Loop Artificial Intelligence
29 Aug 20231 12 RIKEN Innovation Design Office 13 Keio University 17 DEVCOM ARL Army Research Office 19 Pasteur Labs 20 Institute for Simulation Intelligence * To whom correspondence should be addressed;
Recent machine learning and AI advances disrupt scientific practice, technological innovation, product development, and society. As a rule, success in classification, pattern recognition, and gaming occurs whenever there are clear performance evaluation criteria and access to extensive training data sets. Yet, AI has contributed less to fundamental science, such as discovering new principled explanatory models and equations. To set the stage for a fundamental AI4Science, we explore a perspective for an AI-driven, automated, generative, closed-loop approach to scientific discovery, including self-driven hypothesis generation and open-ended autonomous exploration of the hypothesis space.Generative AI, in general, and Large Language Models (LLMs), in particular, serve here to translate and break down high-level human or machine conjectures into smaller computable modules inserted in the automated loop.Discovering fundamental explanatory models requires causality analysis while enabling unbiased efficient search across the space of putative causal explanations. In addition, integrating AI-driven automation into the practice of science would mitigate current problems, including the replication of findings, systematic production of data, and ultimately democratisation of the scientific process. These advances promise to unleash AI's potential for searching and discovering the fundamental structure of our world beyond what human scientists have achieved or can achieve. Such a vision would push the boundaries of new fundamental science beyond automatizing current workflows and unleash new possibilities to solve some of humanity's most significant challenges.</p>
<p>Introduction</p>
<p>With the scientific revolution in the seventeenth century, the notion of mathematical modeling using equations became the efficient language of choice to understand and predict events in the natural world. Four hundred years later, we have vast amounts of data and increasing access to computational power. Recently, we have witnessed an ever-increasing comprehensive application of machine learning accelerating science in unprecedented ways with many questions around quantifying the speed up of discovery ( Fig. 1). One consequence of this increase in scientific production that the digital revolution enabled, it is increasingly challenging for individual scientists to keep abreast of their fields and digest the relevant literature. To advance science and perform end-to-end high-quality scientific investigations, scientists often require one or two orders of magnitude more hypothesis-led experiments than are currently humanly possible. Laboratories are under pressure to perform an increasing number of experiments needed to replicate results. This makes collaborations more challenging, given all the associated overheads, in particular for interdisciplinary research. It may be that some areas of science, such as new fundamental physics or theories in biology, will be too difficult for humans to advance by themselves. AI technologies may be required to be in the driving seat of knowledge discovery to continue the endeavor of human science.</p>
<p>Recent advances in AI since 2010 (1,2), fuelled by large data sets and computing power, have largely targeted problems such as pattern recognition, object classification, and gaming.</p>
<p>Yet, following this phase of difficult-to-understand and interpret -"black-box" neural network models -there has been a renewed interest in expanding the scope of machine learning models.</p>
<p>This includes efforts to search for inspiration from the human brain (3,4), to learn causality (5), to incorporate different geometric priors beyond convolutional filters in the learning (6),and physics-informed machine learning (7,8), to develop explanatory machine learning (9). In the most recent advances moving beyond classification, there has been a growing interest in what can be referred to as AI4Science, reflected, for example, in targeted workshops at machine learning conferences such as NeurIPS and ICML (10). This is evidently a vibrant community (11)(12)(13)(14)(15) active in numerous scientific areas. Naturally, much of the "early" focus has been on data integration, refining measurements, augmenting data, optimising parameters, automation of workflows and data analysis, and scientific visualisation (16). Most recently, with the emergence of foundational models (17), based on the transformer architecture for large language models (18), there is the idea that given large enough data, we can train foundational models which may learn emergent properties to "understand" their respective domains of knowledge (19). This is, however, an open question and challenge for the field. Do we need intelligent priors, or is a huge amount of data sufficient? Yet, regardless of the resolution of this current debate, there is, in our view, a distinct gap between all the exciting recent progress versus having systems, corresponding to an artificial scientist. Such an agent would truly discover and formulate new scientific laws using fundamental mathematical-physical models from observations. Here, in this perspective, we put forward a formulation of a closed-loop iterative formulation as a practical path towards this end.</p>
<p>To further conceptualise how AI can augment science, we like to distinguish between the following levels. First, AI and machine learning can operate as extractors of information. This includes text mining of scientific literature to find relevant papers and, in the best case, extract knowledge and synthesise a body of research from vast sources. A more "modern" use of AI, as mentioned above, has made existing workflows or procedures more efficient, such as being faster and more automatic. This includes augmented computations and simulations in physics.</p>
<p>Alternatively, to make an analysis workflow more automatic by constructing a loss function that incorporates several parameter-dependent steps into a single (complex) optimisation problem.</p>
<p>The first version of AlphaFold is one example (20). However, at these two levels, AI primar-ily supports and enhances current scientific practice. A third level, which is the target in the present perspective, is where AI could potentially discover and learn novel scientific laws, thus finding a "true" representation of a process in nature. For example, a useful compressed latent representation could be learned by training an AI system on data. Alternatively, the scientist could impose soft priors such that certain symmetries and invariants exist in the problem, thus forcing the AI system to discover interpretable structures in the physical process. Geometric machine learning is similar to the "classical" model-based analysis of nature initiated by the scientific revolution. Yet, it is an open problem, how to find such useful and "true" priors from observations in contrast to impose them as regularizing conditions as priors. Here in this review, we focus on the prospect of not only augmenting science, but also by finding such useful, interpretable representations leading to new scientific discoveries by involving AI in what we refer to as a closed-loop-science-AI iterative cycle.</p>
<p>AI can speed up the scientific discovery process and has the potential to advance AI itself in areas relevant to fundamental science, such as causal discovery, automation of experimental science, and the expansion of scientific knowledge. One current bottleneck is knowledge representation, which, by nature, is biased toward the limited understanding and application of the human (scientific) endeavour. A closed-loop-science-AI iterative cycle would be integrated with laboratory automation to execute cycles of planned experiments (21,22). However, the acceleration from automating and closing the loop of the whole scientific cycle leaves unanswered questions, some of which are illustrated in Fig. 1. These systems can fully automate simple forms of scientific research and can further facilitate collaboration across disciplines and between partners-humans or AI systems, but the actual performance of each combination is still unknown and it is still possible that human-machine collaboration produces the most productive outcome and the most relevant to human science too, as it may remain guardrailed to purely human interests. This, however, may also deprive us from undertaking less human Figure 1: A quantitative framework of domain-agnostic acceleration of scientific discovery with AI, its relationship with human-carried science, and the combination of human and machine. 'All knowledge' can be interpreted as potential knowledge if it were discoverable by humans through AI or by themselves. AI time T ′ to conduct certain tasks is traditionally taken to be faster than T by orders of magnitude (21) as it is also more scalable. Still, its domaindependency and relationship to T ′′ (human-machine hybrid) are likely highly domain-specific and has traditionally ignored closed-loopness or the removal of any human input. explorations that may have led to results of human interest. Another key question is whether teaming up or AI alone would allow us to cover a larger region of 'human knowledge' defined recursively as the knowledge that can potentially be reached by human understanding.</p>
<p>In contrast to finding new laws or representations, the applications of AI that have been successful so far have been largely limited to industrial applications, classification problems, and data science.A recipe for success has been to pick a problem that has a well-defined performance metric (23). Problems should preferentially have a history of previously increasingly successful attempts to solve them. Examples include board games (Chess, GO) and bioin-formatics workflows (transcription factor binding, protein folding, antibiotics) (24)(25)(26)(27). Yet, despite being impressive, the success of these examples, hinges upon clever search algorithms and efficient implementation of end-to-end workflows. But, in the end, no new fundamental laws of nature are being discovered. Furthermore, as a reflection of the lack of fundamental laws, the inner workings of these AI systems remain challenging to explain and disentangle. To advance beyond this state of affairs, we argue that we need AI systems that can discover new transparent representations and generative laws of the scientific problem at hand. The notion of an iterative closed-loop discovery scheme constitutes one putative path forward. Yet, only a few successful examples have closed the full loop of scientific discovery (28).</p>
<p>Human scientists today need to think about how to create AI systems that can partner with scientists and take on responsibilities over the complete arc of scientific discovery (29): from the process of observation and intervention to hypothesis generation; from a domain knowledge base to conducting experiments and evaluating results; and from rejecting or validating the assumptions to integrating them into the current knowledge base and filing them with the relevant existing literature. Thus, the question is how to make substantial and meaningful advances in AI to enable us to go even further in accelerating science, hitherto driven exclusively by humans, to not only rapidly expand human knowledge and improve the impact of scientific practice, but also to increase its reliability, availability, reproducibility, verifiability, transparency, and trustworthiness as the processes involved in scientific discovery become more automated.</p>
<p>In Fig. 1, we propose some quantitative measures that will not apply to all cases but rather instances where a combination of AI and human approaches can further accelerate science.</p>
<p>Nevertheless, the expectation is that AI will provide a real gain on most fronts and domains.</p>
<p>AI in Scientific Discovery</p>
<p>Challenges</p>
<p>Humans are traditionally biased and prone to very well-known cognitive fallacies or biases, which science is hardly a stranger to (30)(31)(32). One common and increasingly discussed issue is reproducibility across all domains (33,34). Humans are ill-equipped to deal with the repetitive tasks that reproducibility entails, and there are all sorts of inducements for consciously or unconsciously making dubious moves, particularly when it comes to the game of funding and high-impact publishing (35). Confirmation bias, fake rigour, prior assumptions/hypotheses omission, ad hoc methodologies, cherry-picking experimentation, selective data, hype and overstatement of results, network community effects, "rich-get-richer" phenomena widening the inequality gap in science, and poor reporting are examples (31,32,(36)(37)(38)(39)(40).</p>
<p>We used to think that science was entirely objective, but history has taught us that it is also driven by community choices and groups, where it becomes clear that political and social preferences and underlying cognitive biases can interfere with scientific progress (41)(42)(43). All these problems are leading to a crisis impacting scientific networks, putting collaborative networks at a disadvantage and favouring competitive ones, and often compromising the very principles of scientific practice.</p>
<p>Closed-loop-AI-led science has the potential to mitigate all these problems because it can bootstrap itself with the right mechanisms to detach itself from human-led science and its own biases, even if human scientists initially transfer them. Furthermore, this invites scientists with the task of initially guiding AI as to the type of meaningful research that should be conducted but then letting it explore regions of the scientific space that may never be reachable by human scientists while having the option to keep what human scientists believe is of greatest interest but letting the close-loop-AI system to potentially continue using less human-relevant content searching for novelty in terms of what is potentially interesting to go after. That is to have AI bootstrap itself out of and above the loop-AI-science without human guidance.</p>
<p>One challenge in this direction is that automation can easily fall into the over-fitting trap without human input, and mechanisms to avoid this must be in place. However, it has been found that simplicity and randomness are powerful mechanisms to avoid local minima and maxima when iterating over searching algorithms (44). A striking feature of supervised machine learning is its propensity for over-parametrisation (45). Deep networks contain millions of parameters, often exceeding the number of data points by orders of magnitude, so often, the model starts to over-fit right at the beginning (46). Broadly speaking, networks are designed to interpolate the data, learning/constructing an associated manifold by driving the training error to zero. Deep neural networks in particular are widely regarded as black-box approaches, illequipped to offer explanations of the produced models for classification, often with superhuman ability (47,48). One strategy that has enabled researchers to make progress in understanding the workings and limitations of deep learning is the use of what has been called 'generative models' (49). This involves training adversarial algorithms represented by neural networks that systematically tamper with data while asking it to generate novel examples (50,51). However, current approaches in science (see Fig. 2), including most machine and deep learning methods, rely heavily on traditional statistics and information theory. Consequently, such models are insufficient to capture certain fundamental properties of data and the world related to recursive and computable phenomena, and they are ill-equipped to deal with high-level functions such as inference, abstraction, modelling, and causation, being fragile and easily deceived (52-54), for example because they are prone to finding spurious patterns in large data sets (55,56). : Bubble landscape of current approaches to AI from and for science. Bubbles may occur more than once when related to several larger domains. Some approaches may have alternative names or have been re-branded in certain contexts. Neuro-symbolic models have sometimes been referred to as 'intuitive' while some statistical-driven approaches have been labelled as 'cognitive computing'. Generative AI (GenAI) has made little to no contributions to fundamental science so far but has great potential. Large Language Models (LLMs) may significantly tap into and contribute to the exploratory capabilities of the scientific hypothesis space, given their capabilities to process human language in which all human science has been written. GenAI and LLMs are approaches of statistical nature, but it remains unexplored to what extent they may develop symbolic capabilities from statistical (e.g. linguistic) patterns.</p>
<p>Most of these algorithms fail to be scalable in domains outside the training set. Such algorithms lack mechanisms for abstraction and logical inference, they fail at generalisation (57).</p>
<p>For example, in the case of driverless cars, one does not want a car to crash millions of times to learn how not to crash, so current techniques such as adversarial networks offer a way to produce examples in which not driving appropriately can lead to an event that is labelled a crash (58). However, driving and crashing are events where cause and effect need to be learned, which current approaches cannot do.</p>
<p>When AI leads science so that laboratory experiments are automated to execute cycles of planned experiments, AI frees humans from repetitive, tedious, and error-prone tasks and can deal with vast amounts of data that no human could handle (59). These human scientists, in turn, can feed the AI systems back with new insights and novel theories. Thus, such an emerging feedback loop of AI-human collaboration will synergistically boost scientific discovery toward previously unattainable results, rigour, and dissemination.</p>
<p>To overcome the above limitations and challenges, we claim that it will require the fostering of new theories and methods, as well as human and technological resources in AI, data science, and interdisciplinarity, so scientists become capable of dealing with this AI-human interplay both at an infrastructural and a metastructural level. One of these theories may involve developing mathematical frameworks that can deal with the fact that not only the empirical findings, but also the new theories themselves the scientists within the loop are devising can be influenced by other AI algorithms within the loop, and vice versa. For example, this may require causal analysis (or inverse-problem solving) (60) when both the observer and the observed system are mutually perturbing the underlying generative model of each other (61,62). One of these methods may involve AI that guides AI, and translates results to humans, and this intermediate AI may not be of the same type. For example, causal and model-driven AI (63,64) may be required to disentangle other AI systems to which human scientists cannot relate if they do not have a mechanistic explicative component, whether there is one or not. This may lead to some sort of meta-AI capable of dealing with knowledge representations at a meta-level (43), which includes the network dynamics of the each agent (whether AI or human) in the loop, so that this meta-AI still remains explainable to humans (65). This may not require Artificial General Intelligence but would require a different set of skills than purely statistical machine learning approaches.</p>
<p>Historical Context</p>
<p>Applications of AI in science are quite broad and cover many fields. The idea of automating reasoning goes back to Leibniz, where the modern incarnation can be traced back to efforts to build computing machines in Europe. In particular, the heroic efforts of Alan Turing's work at Bletchley to automate the problem of code breaking and his ideas of an imitation game (66,67).</p>
<p>It can also be traced back to Joshua Lederberg (Nobel laureate) (68), Ed. Feigenbaum (Turing award winner) (69), Karl Djerassi (co-inventor of the contraceptive pill) (70), and colleagues at Stanford in the 1960s, who worked on automating mass-spectroscopy for the Viking Mars lander (71,72). AI has long been a tradition of taking scientific discovery as an area of study.</p>
<p>In the 1970s the Nobel Prize laureate and Turing prize winner Herbert Simon developed Bacon, an AI system for science (73). Since this pioneering work, much has been achieved, and there are now many convincing examples of AI systems making clear contributions to scientific knowledge (e.g. the very recent (74,75)).</p>
<p>Eurisko (76) and Cyrano (77) are two examples of other attempts to perform automated discovery from basic principles in a variety of technical fields, in particular in mathematics, chemistry, and a few other domains. These are systems that can be viewed as heuristic search systems, with the additional advantage that they can reconfigure their own search space.</p>
<p>Some commercial products are specifically designed to be applied to knowledge and scientific discovery. For example, DataRobot (78) promotes Eureqa (79), having acquired Nu-tonian (80)(81)(82). Eureqa was designed to create models from time series data and is based on creating random equations from mathematical building blocks through evolutionary search to explain the data (81). It has been called a "Virtual Data Scientist" (79).</p>
<p>A team of researchers from Google DeepMind launched a machine learning project called AlphaFold in 2018 to participate in the Critical Assessment of Techniques for Protein Structure Prediction or CASP (83). CASP is a biennial competition that assesses state-of-the-art three-dimensional protein structure modelling. In its first version, AlphaFold was particularly successful at predicting the most accurate structure for targets rated as the most difficult by the competition's organisers, but it was not until the second program, AlphaFold 2, in 2020, when the team achieved a level of accuracy much higher than any other group before and scored above 90 for around two-thirds of the proteins in CASP's global distance test (GDT), a test that measures the degree to which a structure predicted by a computational program is similar to the structure validated experimentally, with 100 being a complete match. AlphaFold relied on a lot of human knowledge already generated in the years before, especially in areas such as molecular dynamics. The program was designed to include the expert domain in the form of the training data. How much molecular biological knowledge was introduced is still not known, but while it required a team that did draw heavily on domain expertise to tune it, most of the predictive power came from the AlphaFold 2 tool itself (75,84).</p>
<p>A precursor of AI in physics is the project GALILEO (Guided Analysis of Logical Inconsistencies Leads to Evolved Ontologies) (85). The GALILEO project tried to model the repair of faulty theories of Physics whose predictions were contradicted by empirical evidence. One area of successful application of machine learning from climate data, for example, was the discovery of climate dipoles through machine learning (85). Physics-driven AI has the potential to impact how we approach science, on our current predominantly data-reliant-as opposed to the modelcentred-scientific method, by placing the mechanistic model at the centre of modelling itself.</p>
<p>Paradoxically, current physics-led AI and machine learning research have distracted researchers from more fundamental research, even though the discussion has started, and researchers will hopefully eventually get around to the first principles they claim to care about.</p>
<p>On the knowledge side, there are many applications of knowledge extraction of interest, such as for drug re-purposing by pharmaceutical companies (86,87). On task-oriented problem solving, we can find an increasing number of workflow systems that understand scientific tasks and carry them out. There have been some success stories demonstrating that by collecting and integrating available molecular data into computational models, accurate predictions of interventions in the system can actually be made. An example is the Robot Scientist program (21) that was able to autonomously execute high-throughput hypothesis-led research investigating yeast-based functional genomics, with the next-generation scientific program later using the same principles for drug screening. In another example, a computational model of Halobacterium salinarum NRC-1 was first constructed through massive data integration and machine learning-driven inference of the regulatory network (88).</p>
<p>Another example was the ambitious whole-cell computational model of the life cycle of the human pathogen Mycoplasma genitalium (89). The model accounted for all annotated gene functions and was validated against a broad range of data. Now, the model encompasses approximately 500 genes and their interactions.</p>
<p>In the area of neural networks, there has been, for example, an effort to make them 'understand' cause and effect by algorithmic training. While more research is needed, fundamental research is aware that alternative approaches are required to capture the complexities of hypothesis and model generation or selection (44,53,90). In this sense, the research in this type of higher-order AI, such as deconvolution from searching for generative processes from the entire algorithmic space (60), will also be crucial to advance current research.</p>
<p>To present a summary of the current state of AI applications to each scientific domain, Ta-ble 1 displays an organisation of scientific domains 1 and the applicable AI algorithms' classes and approaches. Scientific domains are approximately ordered from smallest physical scales to largest. Overlapping areas are not reflected in this high-level table (e.g., semi-supervised RL methods, or the representation of neural networks (NNs) that conflates various deep learning types like LSTM and Transformers), not to mention complex, context-dependent multidisciplinarity. Table 1 To burst this bubble, it is essential to supplement LLMs with other methods and multiple sources. For instance, active learning could serve to maximise information gain, challenging the model with fresh data and different viewpoints cross-pollinating from different scientific domains. Hybrid models blending AI with symbolic reasoning could tackle scientific problems requiring high-level abstraction, thus broadening LLMs' capabilities. This approach would therefore fall into the neuro-symbolic category for purposes of scientific discovery.</p>
<p>Indeed, an area where LLMs could be especially impactful is in scientific model discovery.</p>
<p>By analysing patterns and correlations in vast datasets, LLMs could help identify mathematical relations and possibly reveal new potential (physical, or computational) laws just as it learns language grammar from natural language statistics. This could expedite the scientific process, enabling more rapid breakthroughs.</p>
<p>Furthermore, LLMs could make a significant contribution to causal analysis. By processing extensive scientific literature, they could draw links between causes and effects that might be overlooked by human researchers, proposing novel causal hypotheses for testing. Pairing this with counterfactual reasoning, where the AI predicts the outcome of modifying specific variables, could deepen our understanding of cause-effect relationships, and help simulate alternative model outcomes.</p>
<p>However, in addition to inheriting the limitations from statistical machine learning in general (54,91), it is also important to acknowledge the limitations of current LLMs. They currently lack the depth needed for any breakthrough to happen and require quality and diversity of data allowing an LLM 'temperature' (favouring less likely statistical patterns) to explore further along the potential long tails of the distribution of scientific results with potential breakthrough science away from incremental average science. A collaborative approach, in which human scientists guide the AI, can help harness the strengths of both worlds, mitigating the current weaknesses of LLMs and statistical ML, ensuring more effective utilisation of this technology today.<br />
Mathematics -∼ -∼ -✓ -✓ - -∼ ∼ - - - - - - HE Physics -theo -∼ -∼ -∼ -✓ -∼ ∼ - - -∼ ∼ ✓ - HE Physics -exp ✓ ✓ ✓ ✓ - -✓ -✓ ∼ ∼ ✓ ∼ - -✓ ✓ ✓ Optics &amp; Acoustics ✓ ✓ ∼ ✓ ∼ ∼ ✓ -∼ -∼ ∼ -∼ -∼ - - Complexity - -∼ ✓ ∼ ✓ -✓ ✓ ✓ ∼ ✓ ∼ ✓ ✓ -∼ - SynBio &amp; Ind Biotech ✓ ✓ ∼ ✓ ✓ ∼ ∼ ✓ ✓ ∼ ∼ ✓ ∼ ✓ ∼ -∼ ∼ Organic Chemistry ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ Physical Chemistry ✓ ✓ ✓ - - - - - - - - - - - - - - - Electrochemistry ✓ ✓ - - - - - - - - - - - - - - - - Materials ✓ ✓ ∼ ✓ ∼ - -✓ -∼ ∼ ✓ ∼ ∼ ∼ -∼ ∼ Computing ✓ ✓ -✓ - -∼ - - -∼ ✓ ∼ ✓ -∼ ✓ ✓ Medicine, molecules/proteins ✓ ✓ -∼ -∼ -∼ ∼ ∼ ∼ ✓ ∼ ✓ ∼ - -∼ Medicine, drug development ✓ ✓ ∼ ∼ -✓ ∼ ✓ ✓ ✓ ✓ ✓ ∼ ∼ - - - - Medicine, clinical ✓ ✓ -✓ -∼ ∼ ✓ ✓ ✓ ∼ ∼ - - - - - - Botany &amp; Zoology ✓ ✓ ∼ ∼ ∼ ∼ - - -∼ - - -✓ ✓ - - - Systems bio &amp; epidemiology ∼ ✓ ∼ ✓ -∼ ✓ ✓ ✓ ✓ ✓ ✓ ∼ ✓ ✓ -∼ - Neuro and Cog sciences ✓ ✓ ∼ ✓ ∼ ∼ ✓ -✓ ∼ ✓ ✓ ∼ ∼ ∼ ∼ ✓ ∼ Energy -nuclear (fis/fus)ion ✓ ✓ -∼ -∼ ∼ ✓ ✓ ∼ ∼ ✓ ∼ -∼ ∼ ∼ ∼ Energy, generation &amp; storage ✓ ✓ -✓ -∼ ∼ ✓ ✓ ∼ -✓ ∼ ✓ ∼ ∼ -∼ Energy, oil &amp; gas ✓ ✓ ∼ - - - -✓ ∼ ∼ -✓ - -∼ - - - Manufacturing ✓ ✓ - -∼ - -✓ - -∼ ∼ -∼ - - - - Engineering &amp; Industrials ✓ ✓ -∼ ✓ -∼ ✓ ✓ ∼ ∼ ✓ - -∼ - -∼ Energy Systems ✓ ✓ -∼ ✓ -✓ ✓ ✓ ∼ ∼ ∼ - -∼ - - - Transp. &amp; Infrastructure ∼ ✓ - -∼ - -✓ ✓ ∼ -∼ - -∼ - - - Agriculture ∼ ✓ ∼ ✓ ∼ -∼ ✓ ✓ ✓ ∼ ✓ -∼ ∼ - - - Ecology ✓ ✓ ∼ ✓ ∼ -∼ ✓ ✓ ✓ ∼ ∼ ∼ ✓ ✓ - - - Socioeconomics &amp; Markets ✓ ✓ ∼ - -∼ ∼ ✓ ✓ ∼ ∼ ✓ ∼ ✓ ∼ - - - Finance ✓ ✓ - - - - -✓ ✓ ∼ ∼ ✓ -✓ - - - - Politics &amp; Geopolitics -∼ -∼ ∼ -∼ ✓ ∼ ∼ -∼ -∼ ∼ - - - Defense, aerospace ✓ ✓ ✓ - -✓ ✓ ✓ ∼ ∼ ∼ ∼ ∼ ∼ - - - - Climate, weather ∼ ✓ ✓ ✓ ∼ - -∼ ✓ ∼ ✓ ∼ ∼ ✓ ✓ -∼ ∼ Earth Systems ∼ ✓ ∼ ∼ ∼ ∼ ∼ ∼ ✓ ∼ ✓ ∼ ∼ ∼ ∼ -∼ - Astrophysics &amp; Cosmology ✓ ✓ ✓ ✓ ✓ ✓ - -∼ ∼ - -∼ ∼ ∼ ∼ ∼ ∼ Philosophy, Epistemology - - - - -✓ -∼ -∼ - - -∼ ✓ - - -</p>
<p>Aspects of AI-Led Closed-Loop Science</p>
<p>The ability to predict and design (inverse design), while exceptionally useful, will not necessarily lead to new fundamental discoveries (new theories) unless AI and human goals in scientific discovery are aligned and synergistically intertwined to impose similar objectives quantified and introduced, for example, a loss function .</p>
<p>This is because scientific discovery cycles, such as those illustrated in Figs. 3, are not isolated parts but belong within a greater cycle of scientific inquiry spanning an entire topic or field comprised of a community of scientists.</p>
<p>It is the larger learning cycle that fuels the questions in the smaller learning cycles. The larger cycle is fuelled by human curiosity and human challenges and has a strong historical and social component, but the shorter cycles, being more well-defined, they are more prone to be automated. Nevertheless, the larger cycles may be needed to kick-start the discovery process of the smaller learning cycles.</p>
<p>In this sense, one option to integrate human scientists and AI-driven science is for humans to build the context of the greater cycle (for example, fulfilling the role of the 'Final Theory' and 'Background knowledge' steps at the leftmost smaller cycle in Fig. 3), feeding the AI with new insights, and leave the AI to independently deal with the smaller cycles (such as the rightmost smaller cycle in Fig. 3), guided by the greater ones. The LLM's could, for example, be very useful as a technical interface and translation of human high-level larger cycle aspirations and their respective "divide-and-conquer" breakdown into smaller cycles. If one aims at the highest degree of automation of the discovery cycle, more sophisticated forms of AI should include automation of the validation, dissemination, refereeing, and other aspects of human science and its practice.</p>
<p>To tackle such challenges, we propose in the following sections the steps and technology suggested to conduct an entire cycle of AI-led scientific discovery (92), as in Fig. 3. Figure 3: Visual representation of closed-loop full experimentation cycle for scientific discovery pathways, adapted and combining ideas from (59) and (21). LLMs can now facilitate closing this loop but require help to connect each module and process in a causal rather than only a statistical fashion.</p>
<p>Hypothesis Generation</p>
<p>One of the central components of the scientific practice is the 'hypothetico-deductive' method (93,94). An additional set of epistemological tools is induction (95), abduction (22) and counterfactual reasoning (96). To automate those knowledge processes, a deduction can be combined with simulation to infer the experimental consequences of hypotheses. Matching simulation with experimental output will be a reliable basis for an AI to accept or reject a hypothesis. Such experimental output is tested with multiple interventions in the automated series of perturbation analyses (61). However, while one traditional approach to automate induction may follow, for example, new methods for clustering and regression, automating abduction and the creation of counterfactual scenarios may pose an even more challenging problem. For this purpose, it would require the AI algorithm to explore irreducibly novel possibilities that are emergent to the current state of knowledge in which the AI is situated (62).</p>
<p>In this sense, neural networks are unlikely to be useful in the process of hypothesis generation, nor is any statistical machine learning. This is because they need training, and not only is Each method has its advantages and drawbacks and lies at different extremes of the causal inference spectrum. Guiding heuristics based on first principles are needed to explore the hypothesis space (100). Dovetailing partial results is necessary to avoid infinitely long cycles running the search. Here aspects of computability and tractability will be in play at every step, which we will need measures to deal with unless less powerful techniques are implemented (e.g. propositional logic or domain-restricted spaces such as a set of genetic circuits). At one extreme are the statistical tools that confound correlation and causation but can help scientists make a call and guide their experiments, viz., graphical models that combine probability with symbolic logic, reasoning, and interventional calculus. The statistical approach often leads to less computationally expensive methods and, although in general, they may present distortions or biases toward some selected features (52,101), it returns sound results in cases one knows a priori that the underlying generative processes are purely stochastic, stationary and ergodic.</p>
<p>At the other extreme is AID, which searches for sets of agnostic generative models compatible with observations, and exploits these models as testable underlying mechanisms and causal first principles (98,99), regardless of those being stochastic, computable, or mixed processes. In addition to offering less constrained methods, for example, deconvolution algorithms (60) and optimisation in non-differential spaces (44), this approach offers results in direction to tackling the abduction and counterfactual problem, as for example shown in new methods for openended evolutionary computation (102,103), and synergistic distributed computation (104,105).</p>
<p>However, bottom-up approaches like AID may not be humanly understandable, or when they are, scrutinising them may require great computational effort, as is the case in other areas such as automatic theorem proving (e.g., the four-colour theorem). LLMs may here again provide an advantage to interface between these model spaces as natural language processors integrating otherwise disparate systems translating among different domain databases and knowledge bases.</p>
<p>Experimentation and Sensing</p>
<p>One key task is to create AI systems for scientific discovery able to conduct experimentation and hypothesis testing independent of human instruction or with little to no human instruction. This is because what is desired to take scientific discovery to the next level is not the programming of algorithms able to conduct experiments, but open-ended algorithms able to set their own goals and experiments guided by previously conducted experiments (their own or from the human literature). To this end, involving the machine embodiment to perform as a physical scientist by combining sensing and action together in the fully automated smaller cycles (which in turn are part of the larger encompassing AI-led closed-loop of scientific discovery) of empirical hypothesis testing, instrument-driven approaches render robotics key to making progress in physical experimentation so that more and more of the physical execution of experiments will be done using robotics (106). This will increase the productivity of science, as robots work cheaper, faster, more accurately, and for longer than humans. Furthermore, if not embodied, the scientific experiment may collapse into a problem of data analysis and inference without the hypothesis, model, and theory testing that requires positive or negative feedback from the empirical side. Thus only a tiny part of the scientific discovery cycle would be tackled.</p>
<p>Neural networks can help physical machines to embed themselves in a physical world for representation purposes, as neural networks have proven useful in representing all sorts of images. Still, innovation in areas of robotics and mechatronics will be required to accommodate the kind of depth and range of scientific experiments, in particular when it comes to accuracy and precision-which should not present a problem-while also helping with the current, very human problem of reproducibility (40). This is expected to have a significant impact on the reproducibility of science, as automating science requires semantic precision. LLMs will also interface between human and robot instructions making it easier to create tools to automate experiments in natural language effectively instantiating a robot assistant able to process human instructions for scientific experimentation.</p>
<p>Rejection, Validation and Model Selection</p>
<p>Model selection and reduction have been a recurring theme across several sub-fields of areas, such as computational biology and neuroscience, with special reference to dynamical forward models. The idea is that if a complex nonlinear model can be reduced in complexity (fewer state variables and parameters), the investigator can more readily discern which parameters and state variables are more crucial to the model's behaviour, facilitating model analysis and understanding. One example is the reduction of the four-dimensional Hodgkin-Huxley model to a two-dimensional FitzHugh-Nagumo (FHN) system (107). The core idea was to perform a time-scale separation into fast and slow subsystems. This has been used in several model reduction studies, including the cell cycle. Techniques for dimension reduction, feature, and model selection will be helpful at this stage, from statistical approaches such as principal component analysis to more sophisticated ones such as minimal information loss techniques.</p>
<p>Another core idea for model selection is that each hypothesis formed will have a predicted probability of being correct, possibly along with the associated cost of the respective experiment. This may be the monetary cost of executing the experiment, plus a temporal discount rate to value finding results more quickly. It has been empirically shown that using a Bayesian approach to experiment selection is sound and outperforms experiments chosen manually (21).</p>
<p>Current AI has shown the ability to yield valuable insights from noisy or incomplete data, optimise procedure design, and learn notions of structure amongst heterogeneous observations.</p>
<p>Neural networks have shown utility in isolating proper signals from noisy datasets spanning disciplines from physics to biology; such capabilities could be critical to establishing scientific conclusions as we reach the practical limit of experimental data quality (108,109). Approaches from optimisation have demonstrated an ability to reduce the expense of experimental campaigns by optimising sampling patterns using, for instance, bandit-style methods to more rapidly design electric batteries or iteratively specify experimental conditions in biology. Structure learning techniques from the graphical model literature could find use in identifying statistically meaningful relationships from large amounts of unannotated data (108).</p>
<p>Knowledge Representation and Natural Language Processing</p>
<p>Ingested knowledge may no longer be machine-readable, either rule-based or probabilistic given that LLMs can interface between them but its possible caveats, such as low-level hidden misalignments, are difficult to unveil, making difficult traceability and liability. LLMs can allow machines to read, interpret, and exploit the current knowledge from a scientific domain in human natural language and digest the relevant literature in the target area. An AI-led scientific discovery approach will require at least access to the space of interest needed for the system to be able to validate or reject a hypothesis based on contradiction or confirmation of previous knowledge which may be difficult in a black box like an LLM. So, the LLM will need to be self-explanatory with the caveat that the output explanation may not fit the internal statistical derivation of what the LLM ends up producing. An independent system and a more explainable mechanistic process may need to verify the output. Without LLMs, this task would have required massive databases and curation efforts for domains that are not already significantly represented in a computable fashion. Although all sorts of languages can be used to represent knowledge, some domains will be aptly represented by propositional-logic rules, such as simplified genetic circuits, to avoid these potential misalignments from LLMs or statistical ML in general. Other domains will require more sophisticated representations, either to encompass the greater complexity of an extended domain or to deal with the greater sophistication of, e.g., a domain such as biomedicine, where system-expert rules with ifs, dos, and whiles are required, hence the full power of first-order logic and Turing-completeness.</p>
<p>For example, knowledge representation systems/ontologies are well developed in biology:</p>
<p>The Gene Ontology (GO), nascent Causal Activity Models with the GO, Human Phenotype Ontology, Chemical Entities of Biological Interest, Ontology of Biomedical Investigation, among others (110,111). So are integration efforts built on these ontologies, e.g., Monarch (112). The JST MIRAI 'Robotic Biology' project can also provide technologies to help adoption, such as LabCode, a common formal language for experimental protocols, LabLive, a laboratory information IoT platform, and real-time parallel workflow scheduling software that can decompose processes in a given protocol and assign each to different robots/equipment so these are executed considering dependencies and concurrency between them.</p>
<p>Another example is statistical relational learning (SRL), which combines relational learning and probability theory and is an area of ML research (e.g. (113)), enabling the representation of beliefs about relational data using probabilistic models. Relational Learning (RL) is a general representation language based on first-order predicate logic (113). Such probabilistic logic models enable the specification of graphical models (Bayesian networks, Markov networks, etc.) over large relational domains. One of the fundamental design goals of the representation formalisms developed in SRL is to abstract away from concrete entities and to represent instead general principles that are intended to be universally applicable. A key advantage of RL is that it can easily incorporate background scientific knowledge, and learn about structured objects such as scientific models particularly appropriate for utilising background bioinformatic data (114).</p>
<p>These approaches can be further enhanced or complemented by the do-calculus (96,115) or algorithmic information dynamics (61).</p>
<p>Deep neural networks are also good at capturing the apparent granularity and complexity of natural phenomena in a computable form (in weighted vectors of numerical matrices). The success of neural networks implies that once one captures an object in an optimal way, classification is trivial, as it was for deep learning in the protein-folding challenge (75,83) with its limitations.</p>
<p>Assuming that an appropriate formalism to record observation could be found for any domain, a modeller may be faced with a severe feature selection problem, which translates into a question of the identity of the relevant state variables of the systems of interest, e.g., drug</p>
<p>docking dynamics for drug discovery or cytokines for cell dynamics. On the one hand, all the system entities that are measured could define the set of state variables to be represented, e.g.</p>
<p>drugs or proteins, augmented with the set of rules to which the entities may be subjected, such as thermodynamics or collisions. However, this type of representation could quickly become very complex (116). On the other hand, a certain subset of combinations of measured state variables may be a useful representation of the governing dynamics driving a possible system, and this is a question that needs to be asked and resolved for scientific domains on a caseby-case basis. Such a feature selection problem in computably representable objects is often found in analyses in which one is assuming a pure stochastic nature of the system's generative processes, although the system also comprises deterministic, mechanistic, or computable subprocesses (101). In addition, even in cases the whole algorithmic space of possibilities is covered, analyzing the information content carried by a network highly depends on the multidimensional space into which it is embedded (117), where distortions may be exponential for multidimensionality-agnostic encodings.</p>
<p>Thus, developing expressive and efficient frameworks to computationally represent and capture a wide range of scientific knowledge about processes, models, observations and hypotheses is key. Additionally, in the opposite direction of knowledge representation by machines, the AI for scientific discovery may need to communicate in the form of a publication or other scientific means to explain the innovation and methods behind the discovery to humans and to articulate its significance and impact. Thus, not only we will have to improve knowledge representation (43) of these scientific objects of inquiry, but also include (meta)knowledge representation of the social dynamics constituted by the scientific practice of humans and AI algorithms in the loop. This in turn should lead to better mitigations of the aforementioned problems of reproducibility and biases in science. Capturing scientific knowledge will push the limits of the state of the art.</p>
<p>A choice that has to be made, on a case-by-case basis, is whether it is required that AI conducts the experiments without much human understanding or whether it is acceptable not to have a sophisticated translation of both the hypotheses generated and the process arriving at a conclusion. In cases where there is a requirement for human understanding, and even for the most general case, at least partial interpretation by human scientists may be required.</p>
<p>Thus, knowledge representation and natural language processing techniques will be needed to be jointly developed to both: feed the system with the current knowledge relevant to the hypothesis space; and guide the search (in cases of human-machine interaction) or be able to follow up the inference process and interpret the results (118,119). These requirements will force us to make progress on humanly readable and interpretable machine-human translation.</p>
<p>Integration, Interpretation and Interfacing</p>
<p>One of the most challenging aspects of scientific discovery is integrating a new piece of information with the corpus of existing human knowledge. Analysing the data will require moving to the larger learning loop where there is a broader view of the results for possible (re-)interpretation.</p>
<p>This is because while the specific objective for the target hypothesis may have been rejected, one of the main serendipity checkpoints is the reinterpretation of results in a broader context.</p>
<p>Machine learning systems have proven incredibly useful for automated knowledge base construction. They have recently contributed to creating multiple large databases describing, for instance, genome-wide association studies and drug-disease interactions directly from the published literature (120). This ability to create massive knowledge bases that rapidly and effectively contextualise new findings could substantially accelerate scientific discovery by ensuring that seemingly disparate dots are more rapidly connected.</p>
<p>However, exploring and understanding user context requires automating certain social, political, and economic aspects of interconnected knowledge that are intrinsic to science (37).</p>
<p>The AI systems' interactions with scientists must be guided by a knowledge-rich multi-agent model (106) that enables the AI systems to act as colleagues like LLMs now may allow.</p>
<p>This constitutes an inextricable loop in which human scientists and AI-scientists are parts of a whole system, which the AI algorithm should try to optimise. A striking example of such an optimal interplay has been the evolution of machine-human chess collaboration. After the defeat of Gary Kasparov, it became standard to have human chess players practice with computers, and for champions, it became impossible to reach the level of playing demanded without intensive computer training (121). To this day, the strongest freestyle chess teams have been those able to strike a perfect balance between machine and computer training and playing.</p>
<p>Again, neural networks and statistical machine learning will not help in this process, at least not on their own or in their traditional architectures. What is most likely needed here is first an inference engine able to extract knowledge readable by humans as well, especially under human-machine schemes. Classical logical inference engines are key, but so are hybrid approaches combining statistical learning and symbolic computation so that the AI algorithms' objectives and their respective performance measures are not always fixed in advance (23).</p>
<p>Techniques such as feature selection and data dimension reduction will be helpful in this regard.</p>
<p>Secondly, an AI algorithm that can simulate the network topological properties of scientific production (36) and perform the steps of the full cycle of AI-led scientific discovery, while taking into account the relational structures and biases that emerge when the AI-human relationship is analysed as a single system.</p>
<p>The application of AI to science will confer multiple advantages, and eliminate some of the disadvantages of having a human in the loop, such as biases and lack of reproducibility.</p>
<p>Yet, if humans rely on automated scientific discovery, verifiability and transparency are crucial because the coupled AI-human system has to be able to be formally verified to ensure that it matches the goals and that the results match the process. In this manner, the AI algorithm should be designed to continuously reiterate its data gathering from the outputs and behaviours of the whole system the AI is part of. The same for the human scientist, which needs to be able to perform, evaluate, and produce analytical reasoning while participating in this coupled computational-social system. This in turn may give rise to innovative methodologies and epistemological grounds that foster the scientific justification of the results and novelties discovered by such a coupled system.</p>
<p>Closing the Loop</p>
<p>Finally, connecting all the steps will require a meta-algorithm that will need to systematically manage each cycle and even decide when to break or restart the cycles (see Fig. 3), if human intervention is taking place. The whole cycle should be open to human intervention, and the AI algorithm should both reiterate the new insights and data given by humans and counter any bias that these may introduce.</p>
<p>Technology for remote web control and monitoring of full-cycle scientific discovery may require technologies such as TypeScript, React, GraphQL, Jest, and Redux to create a webbased beamline control system. Techniques such as optimisation and anomaly detection can be used to find possible gaps and even glitches (found or promoted). These gaps can be exploited to reinterpret data, explore other regions of the hypothesis space and kick-start the process of hypothesis generation again, thus closing and restarting the discovery cycle.</p>
<p>Notice that each of the above aspects of the AI-led closed-loop science can be considered landmark projects that will also require solutions to many standard technical problems (122).</p>
<p>Therefore, toward being able to close the loop with an AI-led science, the "grand challenge"</p>
<p>(122) that we propose ranges over automating not only laboratory practices and theory making, but also writing a paper, refereeing, and disseminating achievements.</p>
<p>Conclusion: the Future of AI in Scientific Discovery</p>
<p>Future scientific progress has become almost unthinkable without the involvement of machine learning. We have explored some challenges and opportunities in utilising and exploiting AI.</p>
<p>We argue that a closed-loop formulation not only augments and accelerates scientific discovery but also leads science in new directions, thus potentially disrupting the future trajectory of human science. Such closed-loop experimentation led by AI may also mitigate current challenges, such as the production and replication of data.</p>
<p>The development of AI to discover new fundamental scientific laws and representations is different compared to the application of AI to games such as chess, shogi, or Go. However, recent developments surprisingly suggest that some scientific challenges may not be that different from these games (123)(124)(125).</p>
<p>New questions for scientists and policymakers are increasingly pertinent. For example, do we require AI equipped with sufficient intelligence and autonomy to render it capable of sensing and making observations to ask novel scientific questions? Who should control AI4Science systems, humans or other tertiary systems we may trust? How will the role of the future scientist change? Yet, these challenges must be solved since we urgently need to solve problems like cancer and climate change.</p>
<p>By observing the resulting examples and how the classifier fails, they can understand the model's limitations and improve the classifier.</p>
<p>Figure 2
2Figure 2: Bubble landscape of current approaches to AI from and for science. Bubbles may occur more than once when related to several larger domains. Some approaches may have alternative names or have been re-branded in certain contexts. Neuro-symbolic models have sometimes been referred to as 'intuitive' while some statistical-driven approaches have been labelled as 'cognitive computing'. Generative AI (GenAI) has made little to no contributions to fundamental science so far but has great potential. Large Language Models (LLMs) may significantly tap into and contribute to the exploratory capabilities of the scientific hypothesis space, given their capabilities to process human language in which all human science has been written. GenAI and LLMs are approaches of statistical nature, but it remains unexplored to what extent they may develop symbolic capabilities from statistical (e.g. linguistic) patterns.</p>
<p>'s content was the consensus and understanding of a subset of this paper authors. While supervised statistical methods have contributed to almost every area of knowledge, these are of very different type mostly ranging from identification to classification. Some areas are more difficult than others across all approaches, such as mathematics, philosophy, and epistemology. In general, statistical approaches rank poorly at finding first principles or adding new mechanistic knowledge to scientific domains.Generative AI (GenAI) and Large Language Models (LLMs) are promising to advance science by assimilating and synthesising the vast corpus of human knowledge embedded in scientific literature. Through this synthesis, LLMs can interconnect disparate ideas, construct unique hypotheses, and venture into uncharted areas of scientific knowledge. However, this exploration is bound by the data they have been trained on, creating a theoretical bubble that could lead to model collapse through excessive training on the same data.</p>
<p>training over hypothesis generation exactly the problem to be solved in the first place, but training over previous hypotheses, dividing them into rejected or valid, may undermine the freedom and the unbiased exploration that is desired of regions of interest in the hypothesis space. For hypothesis generation, what is needed is a bottom-up approach (e.g., a model-driven AI) or a hybrid one able to conduct cycles of systematic hypothesizing, from either partial or exhaustive enumerations (even if redundant though universal)(64,97).A bottom-up approach that deals with this open-endedness concerning the role of novelty is the field of algorithmic information dynamics (AID) (61), a framework for causal discovery and causal analysis based on algorithmic information theory and perturbation analysis. Open-ended innovation in hypothesis generation and how to create and search over unbounded hypothesis spaces in less well-specified domains is an open challenge in itself, whereresearch on the topics of this document can help make progress. These spaces and the methods exploring them usually have to deal with problems of intractability or uncomputability(98,99).</p>
<p>Table 1 :
1Scientific domains and the applicable AI algorithms' classes and approaches. '-' and ✓means simply no (or unknown) and yes, respectively; ∼ implies the ML application is likely but not yet done nor sufficiently validated. This table is very dynamic and requires an update every quarter given the speed of developments impossible to keep up with without considerable effort or help from AI.
Note that: Complexity includes systems and intelligence as defined by the Santa Fe Institute; Manufacturing notably includes ML-based design of sensors and chips; and Earth systems includes oceans, land, air, and near space (see earthdna.org).</p>
<p>. Y Lecun, Y Bengio, G Hinton, 521:7553 521Nature. 436Y. LeCun, Y. Bengio, G. Hinton, Nature 2015 521:7553 521, 436 (2015).</p>
<p>. J Schmidhuber, Neural Networks. 6185J. Schmidhuber, Neural Networks 61, 85 (2015).</p>
<p>. D Hassabis, D Kumaran, C Summerfield, M Botvinick, Neuron. 95245D. Hassabis, D. Kumaran, C. Summerfield, M. Botvinick, Neuron 95, 245 (2017).</p>
<p>. A Zador, Nature Communications. 141597A. Zador, et al., Nature Communications 14, 1597 (2023).</p>
<p>J Pearl, Causality: Models, Reasoning and Inference. USACambridge University Presssecond ednJ. Pearl, Causality: Models, Reasoning and Inference (Cambridge University Press, USA, 2009), second edn.</p>
<p>. M M Bronstein, J Bruna, Y Lecun, A Szlam, P Vandergheynst, IEEE Signal Processing Magazine. 3418M. M. Bronstein, J. Bruna, Y. LeCun, A. Szlam, P. Vandergheynst, IEEE Signal Process- ing Magazine 34, 18 (2017).</p>
<p>. G E Karniadakis, Nature Reviews Physics. 3422G. E. Karniadakis, et al., Nature Reviews Physics 3, 422 (2021).</p>
<p>. A Lavin, arXiv:2112.03235arXiv Preprintscs.AIA. Lavin, et al., arXiv Preprints (2021). arXiv:2112.03235 [cs.AI].</p>
<p>A Holzinger, A Saranti, C Molnar, P Biecek, W Samek, Ai -Beyond Explainable, A I , A Holzinger, Series Title: Lecture Notes in Computer Science. ChamSpringer International Publishing13200A. Holzinger, A. Saranti, C. Molnar, P. Biecek, W. Samek, AI -Beyond Explainable AI, A. Holzinger, et al., eds. (Springer International Publishing, Cham, 2022), vol. 13200, pp. 13-38. Series Title: Lecture Notes in Computer Science.</p>
<p>. AI for Science. ai4sciencecommunity. AI for Science. ai4sciencecommunity. https://ai4sciencecommunity. github.io/.</p>
<p>. P Berens, K Cranmer, N D Lawrence, U Luxburg, J Montgomery, arXiv:2303.04217arXiv PreprintscsP. Berens, K. Cranmer, N. D. Lawrence, U. von Luxburg, J. Montgomery, arXiv Preprints (2023). arXiv:2303.04217 [cs].</p>
<p>. G Karagiorgi, G Kasieczka, S Kravitz, B Nachman, D Shih, Nature Reviews Physics. 4399G. Karagiorgi, G. Kasieczka, S. Kravitz, B. Nachman, D. Shih, Nature Reviews Physics 4, 399 (2022).</p>
<p>. M Raghu, E Schmidt, Preprints , arXiv:2003.11755cs, statM. Raghu, E. Schmidt, arXiv Preprints (2020). arXiv:2003.11755 [cs, stat].</p>
<p>. F Noé, A Tkatchenko, K.-R Müller, C Clementi, Annual Review of Physical Chemistry. 71361F. Noé, A. Tkatchenko, K.-R. Müller, C. Clementi, Annual Review of Physical Chemistry 71, 361 (2020).</p>
<p>. B A Richards, Nature Neuroscience. 221761B. A. Richards, et al., Nature Neuroscience 22, 1761 (2019).</p>
<p>. H Wang, Nature. 62047H. Wang, et al., Nature 620, 47 (2023).</p>
<p>. R Bommasani, arXiv:2108.07258arXiv PreprintsR. Bommasani, et al., arXiv Preprints (2022). arXiv:2108.07258 [cs].</p>
<p>. Arxiv Openai, Preprints, arXiv:2303.08774csOpenAI, arXiv Preprints (2023). arXiv:2303.08774 [cs].</p>
<p>. A Srivastava, Transactions on Machine Learning Research. A. Srivastava, et al., Transactions on Machine Learning Research (2023).</p>
<p>. A W Senior, Nature. 577706A. W. Senior, et al., Nature 577, 706 (2020).</p>
<p>. R D King, Nature. 427247R. D. King, et al., Nature 427, 247 (2004).</p>
<p>. R D King, Science. 324R. D. King, et al., Science 324 (2009).</p>
<p>. J Mccarthy, Artificial Intelligence. 1711174J. McCarthy, Artificial Intelligence 171, 1174 (2007).</p>
<p>. D Silver, Science. 3621140D. Silver, et al., Science 362, 1140 (2018).</p>
<p>. J M Stokes, Cell. 180688J. M. Stokes, et al., Cell 180, 688 (2020).</p>
<p>. B Alipanahi, A Delong, M T Weirauch, B J Frey, Nature Biotechnology. 33831B. Alipanahi, A. Delong, M. T. Weirauch, B. J. Frey, Nature Biotechnology 33, 831 (2015).</p>
<p>. A W Senior, Nature. 577706A. W. Senior, et al., Nature 577, 706 (2020).</p>
<p>. R D King, Scientific American. 30472R. D. King, Scientific American 304, 72 (2011).</p>
<p>. D Wang, Proceedings of the ACM on Human-Computer Interaction pp. D. Wang, et al., Proceedings of the ACM on Human-Computer Interaction pp. 1-24 (2019).</p>
<p>. B A Nosek, J R Spies, M Motyl, Perspectives on Psychological Science. 7615B. A. Nosek, J. R. Spies, M. Motyl, Perspectives on Psychological Science 7, 615 (2012).</p>
<p>. D Fanelli, R Costas, J Ioannidis, PNAS. 143714D. Fanelli, R. Costas, J. Ioannidis, PNAS 14, 3714 (2017).</p>
<p>. R Nuzzo, Nature. R. Nuzzo, Nature pp. 182-185 (2015).</p>
<p>S N Goodman, D Fanelli, J P Ioannidis, Getting to Good: Research Integrity in the Biomedical Sciences. S. N. Goodman, D. Fanelli, J. P. Ioannidis, Getting to Good: Research Integrity in the Biomedical Sciences pp. 96-102 (2018).</p>
<p>. J K Harris, Public Health Reports. 134109J. K. Harris, et al., Public Health Reports 134, 109 (2019).</p>
<p>. P Kaanders, P Sepulveda, T Folke, P Ortoleva, B D Martino, 2021.06.29.450332P. Kaanders, P. Sepulveda, T. Folke, P. Ortoleva, B. D. Martino, bioRxiv p. 2021.06.29.450332 (2021).</p>
<p>W Dashun, B Albert-László, The Science of Science. Cambridge, UKCambridge University PressW. Dashun, B. Albert-László, The Science of Science (Cambridge University Press, Cam- bridge, UK, 2021).</p>
<p>. S Fortunato, Science. 359S. Fortunato, et al., Science 359 (2018).</p>
<p>. Nature. 537465NatureNature, Nature 537, 465 (2016).</p>
<p>. V Colizza, A Flammini, M A Serrano, A Vespignani, Nat. Phys. 2110V. Colizza, A. Flammini, M. A. Serrano, A. Vespignani, Nat. Phys. 2, 110 (2006).</p>
<p>. M Baker, Nature. 533452M. Baker, Nature 533, 452 (2016).</p>
<p>. M Baddeley, Embo Rep, 16902M. Baddeley, EMBO Rep. 16, 902 (2015).</p>
<p>. D B Resnik, K C Elliott, Accountability in research. 2331D. B. Resnik, K. C. Elliott, Accountability in research 23, 31 (2016).</p>
<p>. J A Evans, J G Foster, Science. 331J. A. Evans, J. G. Foster, Science 331 (2011).</p>
<p>. S Hernández-Orozco, Frontiers in Artificial Intelligence. 3567356S. Hernández-Orozco, et al., Frontiers in Artificial Intelligence 3, 567356 (2021).</p>
<p>. L Venturi, A Bandeira, J Bruna, Journal on Machine Learning Research. 201L. Venturi, A. Bandeira, J. Bruna, Journal on Machine Learning Research 20, 1 (2019).</p>
<p>. Y Goodfellow, Y Bengio, A Courville, MIT PressY. Goodfellow, Y. Bengio, A. Courville (MIT Press, 2016).</p>
<p>. V Buhrmester, D Münch, M Arens, V. Buhrmester, D. Münch, M. Arens (2019).</p>
<p>. C Rudin, Nature Machine Intelligence. 1206C. Rudin, Nature Machine Intelligence 1, 206 (2019).</p>
<p>. R Salakhutdinov, Annual Review of Statistics and Its Application. 2361R. Salakhutdinov, Annual Review of Statistics and Its Application 2, 361 (2015).</p>
<p>. A Creswell, IEEE Signal Process. Mag. 3553A. Creswell, et al., IEEE Signal Process. Mag. 35, 53 (2018).</p>
<p>. Y Bian, X.-Q Xie, J. Mol. Model. 2771Y. Bian, X.-Q. Xie, J. Mol. Model. 27, 71 (2021).</p>
<p>. H , Entropy. 22612H. Zenil, Entropy 22, 612 (2020).</p>
<p>. B Scholkopf, Proceedings of the IEEE. 109612B. Scholkopf, et al., Proceedings of the IEEE 109, 612 (2021).</p>
<p>. M J Colbrook, V Antun, A C Hansen, Proceedings of the National Academy of Sciences. 119M. J. Colbrook, V. Antun, A. C. Hansen, Proceedings of the National Academy of Sciences 119 (2022).</p>
<p>. C S Calude, G Longo, Foundations of Science. 22595C. S. Calude, G. Longo, Foundations of Science 22, 595 (2017).</p>
<p>. G Smith, SN Applied Sciences. 2G. Smith, SN Applied Sciences 2 (2020).</p>
<p>. C Nadeau, Mach. Learn. 52239C. Nadeau, Mach. Learn. 52, 239 (2003).</p>
<p>. J Spooner, V Palade, M Cheah, S Kanarachos, A Daneshkhah, Applied Sciences. 11471J. Spooner, V. Palade, M. Cheah, S. Kanarachos, A. Daneshkhah, Applied Sciences 11, 471 (2021).</p>
<p>. H Kitano, AI Magazine. 37H. Kitano, AI Magazine 37 (2016).</p>
<p>. H Zenil, N A Kiani, A A Zea, J Tegnér, Nature Machine Intelligence. 158H. Zenil, N. A. Kiani, A. A. Zea, J. Tegnér, Nature Machine Intelligence 1, 58 (2019).</p>
<p>. H Zenil, N Kiani, F Abrahão, J Tegnér, Scholarpedia Journal. 1553143H. Zenil, N. Kiani, F. Abrahão, J. Tegnér, Scholarpedia Journal 15, 53143 (2020).</p>
<p>. F S Abrahão, H Zenil, Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences. 380F. S. Abrahão, H. Zenil, Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences 380 (2022).</p>
<p>. X.-B Jin, R J Robert Jeremiah, T.-L Su, Y.-T Bai, J.-L Kong, Sensors (Basel). 212085X.-B. Jin, R. J. Robert Jeremiah, T.-L. Su, Y.-T. Bai, J.-L. Kong, Sensors (Basel) 21, 2085 (2021).</p>
<p>Knowledge Representation and Organization in Machine Learning. S Thieme, Springer-VerlagBerlin/HeidelbergS. Thieme, Knowledge Representation and Organization in Machine Learning (Springer- Verlag, Berlin/Heidelberg, 2005), pp. 177-191.</p>
<p>. R Goebel, Lecture Notes in Computer Science. Springer International PublishingLecture notes in computer scienceR. Goebel, et al., Lecture Notes in Computer Science, Lecture notes in computer science (Springer International Publishing, Cham, 2018), pp. 295-303.</p>
<p>Alan Turing: The codebreaker who saved 'millions of lives. J Copeland, BBC NewsJ. Copeland, Alan Turing: The codebreaker who saved 'millions of lives' -BBC News (2012).</p>
<p>Codebreaker and Computer Pioneer -AlanTuring.net The Turing Archive for the History of Computing. J Copeland, D Proudfoot, Alan Turing, J. Copeland, D. Proudfoot, Alan Turing, Codebreaker and Computer Pioneer -AlanTur- ing.net The Turing Archive for the History of Computing (2004).</p>
<p>. L L Cavalli-Sforza, Cell. 132L. L. Cavalli-Sforza, Cell 132 (2008).</p>
<p>. IEEE Intelligent Systems. 26IEEEIEEE, IEEE Intelligent Systems 26 (2011).</p>
<p>. J. I. Seeman, Chemical &amp; Engineering News. J. I. Seeman, Chemical &amp; Engineering News pp. 10-14 (2013).</p>
<p>Applications of Artificial Intelligence for Organic Chemistry: The DENDRAL Project. J Lederberg, E A Feigenbaum, B G Buchanan, R K Lindsay, McGraw-HillJ. Lederberg, E. A. Feigenbaum, B. G. Buchanan, R. K. Lindsay, Applications of Artificial Intelligence for Organic Chemistry: The DENDRAL Project (McGraw-Hill, 1980).</p>
<p>Rule-Based Expert Systems: The MYCIN Experiments of the Stanford Heuristic Programming Project. B G Buchanan, E H Shortliffe, Addison-WesleyReading, MAB. G. Buchanan, E. H. Shortliffe, Rule-Based Expert Systems: The MYCIN Experiments of the Stanford Heuristic Programming Project (Addison-Wesley, Reading, MA, 1984).</p>
<p>P W Langley, H A Simon, G Bradshaw, J M Zytkow, Scientific Discovery: Computational Explorations of the Creative Process. Cambridge, MassMIT PressP. W. Langley, H. A. Simon, G. Bradshaw, J. M. Zytkow, Scientific Discovery: Computa- tional Explorations of the Creative Process (MIT Press, Cambridge, Mass, 1987).</p>
<p>. B Burger, Nature. 583B. Burger, et al., Nature 583 (2020).</p>
<p>. J Jumper, Nature. 596583J. Jumper, et al., Nature 596, 583 (2021).</p>
<p>. D B Lenat, R Learning, J Michalski, Carbonell, T Mitchell, SpringerBerlin, HeidelbergD. B. Lenat, Machine Learning, R. Michalski, J. Carbonell, Mitchell T.M., eds. (Springer, Berlin, Heidelberg, 1983).</p>
<p>Artificial Intelligence Laboratoy MIT. K W Haase, Discovery Systems AI Memo. 898Tech. rep.K. W. Haase, Discovery Systems AI Memo 898, Tech. rep., Artificial Intelligence Labo- ratoy MIT, Cambridge Mass. (1986).</p>
<p>The Next Generation of AI. Datarobot -Ai Datarobot, Cloud, DataRobot, DataRobot -AI Cloud -The Next Generation of AI.</p>
<p>. Eureqa Eureqa, Models -Datarobot, Eureqa, Eureqa Models -DataRobot.</p>
<p>. Datarobot Ai Cloud Nutonian, Platform, Nutonian, DataRobot AI Cloud Platform.</p>
<p>. R Dubčáková, Genet. Program. Evolvable Mach. 12173R. Dubčáková, Genet. Program. Evolvable Mach. 12, 173 (2011).</p>
<p>. J L Awange, B Paláncz, R H Lewis, L Völgyesi, Mathematical Geosciences. Springer International PublishingJ. L. Awange, B. Paláncz, R. H. Lewis, L. Völgyesi, Mathematical Geosciences (Springer International Publishing, Cham, 2018), pp. 321-357.</p>
<p>. G.-W Wei, Nature Machine Intelligence. 1336G.-W. Wei, Nature Machine Intelligence 1, 336 (2019).</p>
<p>. J Skolnick, M Gao, H Zhou, S Singh, J. Chem. Inf. Model. 614827J. Skolnick, M. Gao, H. Zhou, S. Singh, J. Chem. Inf. Model. 61, 4827 (2021).</p>
<p>. J Liu, Geophys. Res. Lett. 48J. Liu, et al., Geophys. Res. Lett. 48 (2021).</p>
<p>. R Gupta, Mol. Divers. 251315R. Gupta, et al., Mol. Divers. 25, 1315 (2021).</p>
<p>. R Liu, L Wei, P Zhang, Nat Mach Intell. 368R. Liu, L. Wei, P. Zhang, Nat Mach Intell 3, 68 (2021).</p>
<p>. R Bonneau, Cell. 1311354R. Bonneau, et al., Cell 131, 1354 (2007).</p>
<p>. J R Karr, Cell. 150389J. R. Karr, et al., Cell 150, 389 (2012).</p>
<p>. Y Luo, J Peng, J Ma, Nat Mach Intell. 2426Y. Luo, J. Peng, J. Ma, Nat Mach Intell 2, 426 (2020).</p>
<p>. F S Abrahão, arXiv:2112.12275arXiv Preprintscs.ITF. S. Abrahão, et al., arXiv Preprints (2023). arXiv:2112.12275 [cs.IT].</p>
<p>. Y Gil, M Greaves, J Hendler, H Hirsh, Science. 346171Y. Gil, M. Greaves, J. Hendler, H. Hirsh, Science 346, 171 (2014).</p>
<p>K R Popper, Objective Knowledge: An Evolutionary Approach. New YorkOxford University PressK. R. Popper, Objective Knowledge: An Evolutionary Approach (Oxford University Press, New York, 1972).</p>
<p>. R D King, M Liakata, C Lu, S G Oliver, L N Soldatova, Journal of the Royal Society Interface. 81440R. D. King, M. Liakata, C. Lu, S. G. Oliver, L. N. Soldatova, Journal of the Royal Society Interface 8, 1440 (2011).</p>
<p>The Problems of Philosophy. Bertrand Russell, Home University LibraryBertrand Russell, The Problems of Philosophy (Home University Library, 1912).</p>
<p>. J Pearl, Biometrika. 82669J. Pearl, Biometrika 82, 669 (1995).</p>
<p>. C G Morgan, Artificial Intelligence. 2179C. G. Morgan, Artificial Intelligence 2, 179 (1971).</p>
<p>. H Zenil, SSRN Electron. J. H. Zenil, et al., SSRN Electron. J. (2018).</p>
<p>. H Zenil, H. Zenil, et al., iScience pp. 1160--1172 (2019).</p>
<p>. D B Lenat, Artificial Intelligence. 19189D. B. Lenat, Artificial Intelligence 19, 189 (1982).</p>
<p>. H Zenil, N A Kiani, J Tegnér, Physical Review E. 9612308H. Zenil, N. A. Kiani, J. Tegnér, Physical Review E 96, 012308 (2017).</p>
<p>. S Hernández-Orozco, F Hernández-Quiroz, H Zenil, Artificial Life. 2456S. Hernández-Orozco, F. Hernández-Quiroz, H. Zenil, Artificial Life 24, 56 (2018).</p>
<p>. S Hernández-Orozco, N A Kiani, H Zenil, Royal Society Open Science. 5180399S. Hernández-Orozco, N. A. Kiani, H. Zenil, Royal Society Open Science 5, 180399 (2018).</p>
<p>. F S Abrahão, K Wehmuth, A Ziviani, Theoretical Computer Science. 78583F. S. Abrahão, K. Wehmuth, A. Ziviani, Theoretical Computer Science 785, 83 (2019).</p>
<p>. F S Abrahão, K Wehmuth, A Ziviani, Complex Systems. 27F. S. Abrahão, K. Wehmuth, A. Ziviani, Complex Systems 27 (2018).</p>
<p>. H Kitano, AI Magazine. 1873H. Kitano, et al., AI Magazine 18, 73 (1997).</p>
<p>. B Lindner, L Schimansky-Geier, Physical Review E. 607270B. Lindner, L. Schimansky-Geier, Physical Review E 60, 7270 (1999).</p>
<p>. M Drton, M H Maathuis, Annual Review of Statistics and Its Application. 4365M. Drton, M. H. Maathuis, Annual Review of Statistics and Its Application 4, 365 (2017).</p>
<p>. S R Eddy, Nat. Biotechnol. 221177S. R. Eddy, Nat. Biotechnol. 22, 1177 (2004).</p>
<p>. R Stevens, C A Goble, S Bechhofer, Brief. Bioinform. 1398R. Stevens, C. A. Goble, S. Bechhofer, Brief. Bioinform. 1, 398 (2000).</p>
<p>. J B L Bard, S Y Rhee, Nat. Rev. Genet. 5213J. B. L. Bard, S. Y. Rhee, Nat. Rev. Genet. 5, 213 (2004).</p>
<p>. K A Shefchek, Nucleic Acids Res. 48704K. A. Shefchek, et al., Nucleic Acids Res. 48, D704 (2020).</p>
<p>L D Raedt, Logical and Relational Learning. Berlin Heidelberg, Berlin, HeidelbergSpringerL. D. Raedt, Logical and Relational Learning (Springer Berlin Heidelberg, Berlin, Hei- delberg, 2008).</p>
<p>. O I Orhobor, N N Alexandrov, R D King, Machine Learning. 109112195O. I. Orhobor, N. N. Alexandrov, R. D. King, Machine Learning 2020 109:11 109, 2195 (2020).</p>
<p>J Pearl, Uncertainty in Artificial Intelligence -Proceedings of the 28th Conference, UAI. J. Pearl, Uncertainty in Artificial Intelligence -Proceedings of the 28th Conference, UAI 2012 pp. 4-11 (2012).</p>
<p>. C Tang, Neural Netw. 117163C. Tang, et al., Neural Netw. 117, 163 (2019).</p>
<p>. F S Abrahão, K Wehmuth, H Zenil, A Ziviani, Entropy. 23F. S. Abrahão, K. Wehmuth, H. Zenil, A. Ziviani, Entropy 23 (2021).</p>
<p>. G G Chowdhury, Annual Review of Information Science and Technology. 3751G. G. Chowdhury, Annual Review of Information Science and Technology 37, 51 (2005).</p>
<p>. E Cambria, B White, IEEE Comput. Intell. Mag. 948E. Cambria, B. White, IEEE Comput. Intell. Mag. 9, 48 (2014).</p>
<p>. C Andronis, A Sharma, V Virvilis, S Deftereos, A Persidis, Brief. Bioinform. 12357C. Andronis, A. Sharma, V. Virvilis, S. Deftereos, A. Persidis, Brief. Bioinform. 12, 357 (2011).</p>
<p>. M Campbell, A J Hoane, F Hsu, Artificial Intelligence. 13457M. Campbell, A. J. Hoane, F. Hsu, Artificial Intelligence 134, 57 (2002).</p>
<p>. H Kitano, M Asada, I Noda, H Matsubara, IEEE Robot. Autom. Mag. 530H. Kitano, M. Asada, I. Noda, H. Matsubara, IEEE Robot. Autom. Mag. 5, 30 (1998).</p>
<p>. D Silver, Nature. 7587484D. Silver, et al., Nature 7587, 484-(2016).</p>
<p>. D Hassabis, Nature. D. Hassabis, Nature pp. 413-414 (2017).</p>
<p>H Kitano, npj Systems Biology and Applications. 71H. Kitano, npj Systems Biology and Applications 2021 7:1 7, 1 (2021).</p>            </div>
        </div>

    </div>
</body>
</html>