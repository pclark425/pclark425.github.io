<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-9544 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-9544</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-9544</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-166.html">extraction-schema-166</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using LLMs or related models to distill, extract, or discover quantitative laws, equations, or mathematical relationships from large collections of scholarly papers, including methods, results, challenges, and limitations.</div>
                <p><strong>Paper ID:</strong> paper-273482129</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2410.14231v1.pdf" target="_blank">Unveiling Large Language Models Generated Texts: A Multi-Level Fine-Grained Detection Framework</a></p>
                <p><strong>Paper Abstract:</strong> Large language models (LLMs) have transformed human writing by enhancing grammar correction, content expansion, and stylistic refinement. However, their widespread use raises concerns about authorship, originality, and ethics, even potentially threatening scholarly integrity. Existing detection methods, which mainly rely on single-feature analysis and binary classification, often fail to effectively identify LLM-generated text in academic contexts. To address these challenges, we propose a novel Multi-level Fine-grained Detection (MFD) framework that detects LLM-generated text by integrating low-level structural, high-level semantic, and deep-level linguistic features, while conducting sentence-level evaluations of lexicon, grammar, and syntax for comprehensive analysis. To improve detection of subtle differences in LLM-generated text and enhance robustness against paraphrasing, we apply two mainstream evasion techniques to rewrite the text. These variations, along with original texts, are used to train a text encoder via contrastive learning, extracting high-level semantic features of sentence to boost detection generalization. Furthermore, we leverage advanced LLM to analyze the entire text and extract deep-level linguistic features, enhancing the model's ability to capture complex patterns and nuances while effectively incorporating contextual information. Extensive experiments on public datasets show that the MFD model outperforms existing methods, achieving an MAE of 0.1346 and an accuracy of 88.56%. Our research provides institutions and publishers with an effective mechanism to detect LLM-generated text, mitigating risks of compromised authorship. Educators and editors can use the model's predictions to refine verification and plagiarism prevention protocols, ensuring adherence to standards.</p>
                <p><strong>Cost:</strong> 0.005</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <p class="empty-note">No extracted data.</p>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <p class="empty-note">No potentially relevant new papers extracted.</p>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-9544",
    "paper_id": "paper-273482129",
    "extraction_schema_id": "extraction-schema-166",
    "extracted_data": [],
    "potentially_relevant_new_papers": [],
    "cost": 0.0045745,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Unveiling Large Language Models Generated Texts: A Multi-Level Fine-Grained Detection Framework
18 Oct 2024</p>
<p>Zhen Tao 
School of Information
Renmin University of China
BeijingChina</p>
<p>Zhiyu Li 
Institute for Advanced Algorithms Research
ShanghaiChina</p>
<p>Runyu Chen 
School of Information Technology and Management
University of International Business and Economics
China</p>
<p>Dinghao Xi xidinghao@mail.shufe.edu.cn 
Department of Digital Economics
Shanghai University of Finance and Economics
ShanghaiChina</p>
<p>Wei Xu 
School of Information
Renmin University of China
BeijingChina</p>
<p>Unveiling Large Language Models Generated Texts: A Multi-Level Fine-Grained Detection Framework
18 Oct 202405F824D7603C034BE7C64A4E4E2C205EarXiv:2410.14231v1[cs.CL]Preprint submitted to ElsevierLLM-Generated Text Involvement Multi-Level Feature Extraction Fine-Grained Detection Text Contrastive Learning Academic Integrity
Large language models (LLMs) have transformed human writing by enhancing grammar correction, content expansion, and stylistic refinement.However, their widespread use raises concerns about authorship, originality, and ethics, even potentially threatening scholarly integrity.Existing detection methods, which mainly rely on single-feature analysis and binary classification, often fail to effectively identify LLM-generated text in academic contexts.To address these challenges, we propose a novel Multi-level Fine-grained Detection (MFD) framework that detects LLM-generated text by integrating low-level structural, high-level semantic, and deep-level linguistic features, while conducting sentence-level evaluations of lexicon, grammar, and syntax for comprehensive analysis.To improve detection of subtle differences in LLM-generated text and enhance robustness against paraphrasing, we apply two mainstream evasion techniques to rewrite the text.These variations, along with original texts, are used to train a text encoder via contrastive learning, extracting high-level semantic features of sentence to boost detection generalization.Furthermore, we leverage advanced LLM to analyze the entire text and extract deep-level linguistic features, enhancing the model's ability to capture complex patterns and nuances while effectively incorporating contextual information.Extensive experiments on public datasets show that the MFD model outperforms existing methods, achieving an MAE of 0.1346 and an accuracy of 88.56%.Our research provides institutions and publishers with an effective mechanism to detect LLM-generated text, mitigating risks of compromised authorship.Educators and editors can use the model's predictions to refine verification and plagiarism prevention protocols, ensuring adherence to standards.</p>
<p>Introduction</p>
<p>The advent of large language models (LLMs) has revolutionized artificial intelligence, capturing widespread attention and transforming text generation across industries such as social media [1], recommendation system [2], medical diagnostics [3], creative writing [4], and intelligent education [5].While these advancements have unlocked significant benefits across various fields, they have also introduced potential risks and ethical concerns that warrant careful consideration [6,7].</p>
<p>A key concern with LLM-generated content is the risk of misinformation, as these models, while capable of producing fluent and convincing text, can sometimes generate factually incorrect or misleading information [8,9].Another significant issue is the potential for LLMs to generate content that closely mimics original works, raising concerns about plagiarism and diminishing the value of authentic human creativity and professional expertise [5,10].In academia, these challenges are particularly concerning, as the distinction between human and machine-generated content becomes increasingly blurred.Issues surrounding authorship, originality, and the ethical use of LLMs in scholarly work are growing more complex [5].Given the paramount importance of accuracy, credibility, and originality in research, these risks threaten the integrity of academic work, underscoring the urgent need for more robust evaluation frameworks to safeguard scholarly standards [11].</p>
<p>In response to this pressing need, researchers have developed two primary approaches for detecting LLMgenerated text: metric-based and model-based algorithms [12].Metric-based algorithms analyze linguistic features such as perplexity, word usage, and syntactic structures to detect potential signs of LLM involvement [13], using statistical measures to identify anomalies that suggest non-human authorship.Nevertheless, due to the continuous advancement of LLMs, the efficacy of these approaches is gradually diminishing [14].In contrast, model-based algorithms use machine learning models trained on large labeled datasets to detect subtle distinctions between LLM-generated and human-written content, often surpassing metric-based approaches [14].Model-based methods, which primarily extract high-level semantic features from text, have shown potential in detecting outputs from advanced models like ChatGPT.However, these methods often fail when applied to detecting content generated by the most sophisticated language models [15].While both metric-based and modelbased approaches offer valuable insights, they face significant limitations when applied to the increasingly complex task of detecting LLM-generated text.</p>
<p>Firstly, most existing methods concentrate on a singular type of feature, such as statistical patterns or semantic content, rather than providing a comprehensive, multi-level analysis of textual features.This narrow focus often results in incomplete feature extraction, limiting the overall effectiveness of these detection methods.With LLM-generated text becoming increasingly similar to human-written text, single-level analysis is no longer sufficient, leading to both false positives and false negatives, thereby compromising the reliability of detection systems.Secondly, current models exhibit significant limitations in robustness [16].Even minor changes in wording or phrasing can produce markedly different detection results, particularly when researchers intentionally introduce subtle modifications like synonym substitutions or altered word order to evade detection [17].Enhancing model resilience to these disruptions is crucial for ensuring stable performance across diverse linguistic contexts.Furthermore, much of the existing research focuses on determining whether an entire text is LLM-generated, which lacks the precision required for academic integrity.Academic papers demand more detailed analysis, targeting specific sections or passages likely generated by LLMs.Without such granularity, detection methods may fail to effectively safeguard originality and credibility in scholarly work.</p>
<p>To address the aforementioned challenges, we propose a Multi-level Fine-grained Detection (MFD) framework that integrates statistical, semantic, and linguistic features across different levels, specifically targeting text at the sentence level for more precise detection.The framework begins by extracting low-level statistical features, such as readability and authorstyle, to offer a quantitative view of the sentence's structure.In parallel, high-level semantic features are captured using an encoder with contrastive learning, enabling the model to finely detect subtle semantic differences between LLM-generated and human-authored text.Additionally, advanced LLM are utilized to analyze the entire text, extracting deep linguistic features with a focus on lexicon, grammar, and syntax.This approach ensures that the model captures both sentence-level details and contextual information from the broader text.Notably, to counter common evasion tactics in LLM-generated text detection, we prompt the LLM to rewrite the original LLM text using two prevalent methods.By training the encoder with contrastive learning on both the original and the rewritten texts, we enhance the model's robustness in detecting unfamiliar or manipulated text.Furthermore, to comprehensively assess the degree of LLM involvement in text, our framework predicts each sentence of the academic text from the perspectives of lexicon, grammar, and syntax, enabling precise evaluations of LLM-generated text.Extensive experiments demonstrate the effectiveness of our framework, showing not only improved detection accuracy but also strong generalization across different types of LLM-generated text, thereby significantly contributing to the protection of academic integrity.Source data and coda are available at GitHub1 .</p>
<p>To summarize, our work makes four contributions:</p>
<p>â€¢ We propose a multi-level detection framework that integrates semantic, structural, and linguistic features to effectively detect LLM-generated text.</p>
<p>â€¢ Our framework predicts the degree of LLM involvement in each sentence by evaluating lexicon, grammar, and syntax, enabling a fine-grained analysis of LLM-generated text.</p>
<p>â€¢ We improve model robustness by using contrastive learning on original and rewritten LLM text, generated through two common evasion tactics.</p>
<p>â€¢ We leverage the advanced LLM to extract deep linguistic features, capturing both sentence-level details and broader contextual information.</p>
<p>The remainder of this paper is organized as follows.Section 2 provides a comprehensive review of the related literature.Section 3 elaborates on the detailed architecture and methodology of the proposed framework.Section 4 outlines the experimental setup, followed by an in-depth analysis of the results and discussion.Finally, Section 5 concludes the study by summarizing the key findings and highlighting avenues for future research.</p>
<p>Related Work</p>
<p>AI-generated Content Detection</p>
<p>Large language models has revolutionized numerous industries with their exceptional text generation capabilities [18].However, these advancements also pose risks of misuse.Overreliance on LLMs can facilitate the spread of misinformation [19] and lead to unfair competition, threatening integrity in academic and societal contexts [20,21].Therefore, timely detection of AI-generated text is crucial to mitigate these adverse impacts.</p>
<p>Existing detection methods are categorized into metricbased and model-based approaches.Metric-based methods quantify linguistic features, such as stylometric analysis and perplexity scoring, to determine text origin.Gehrmann et al. [22] introduced GLTR, which uses metrics like word probability and entropy for detection, while Solaiman et al. [23] proposed a zero-shot detection method leveraging pre-trained models like GPT-2 or GROVER.However, as LLMs advance, these methods have become less effective.To address these limitations, more advanced and sophisticated detection techniques have emerged.Mitchell et al. [24] presented DetectGPT, a zero-shot method utilizing probability curvature analysis, and Tian et al. [25] developed the Multiscale Positive-Unlabeled (MPU) framework to enhance detection across varying text lengths.While metricbased approaches rely on linguistic analysis, model-based methods use advanced machine learning to classify text as human or AI-generated.These often involve fine-tuning language models or developing specialized architectures.For instance, Guo et al. [26] fine-tuned a RoBERTa model to detect ChatGPT-generated text, while Wang et al. [27] introduced SeqXGPT, a sentence-level method using logprobability lists and self-attention networks for enhanced detection.Liu et al. [28] proposed COCO, which improves detection in low-resource settings by combining an entity coherence graph with contrastive learning.However, most methods focus on binary classification, which limits their application.As LLMs are frequently used for text expansion and refinement, fine-grained detection is increasingly necessary for practical use.</p>
<p>To address this gap, we propose a novel LLM involvement prediction algorithm.This algorithm quantifies LLM participation in text creation at the sentence level, identifying individual sentences that are likely LLM-generated.By moving beyond binary classification, our approach aims to ensure academic authenticity and uphold scholarly ethics, effectively tackling the challenges posed by modern text generation technologies.</p>
<p>Multi-level Feature Learning</p>
<p>Multi-level feature extraction and fusion are critical components in modern deep learning models, significantly enhancing performance in complex tasks, especially in text analysis [29].These techniques involve extracting features at various levels of abstraction and combining them to create comprehensive data representations.</p>
<p>In the context of natural language processing (NLP), multi-level feature extraction captures both local and global linguistic patterns [30].At lower levels, features may include lexical properties such as word embeddings and part-ofspeech tags, providing foundational linguistic information [31].At higher levels, features encompass syntactic dependencies, semantic roles, and discourse structures, offering deeper insights into the text's meaning and context [32].By fusing these multi-level features, models develop a nuanced understanding of text, leading to improved performance in tasks such as sentiment analysis, machine translation, and information retrieval.</p>
<p>Applying multi-level feature learning is particularly pertinent for detecting LLM-generated text.Fine-grained detection requires analyzing textual data at various levels to identify subtle patterns indicative of LLM involvement.For instance, LLM-generated text may exhibit specific lexical choices, syntactic constructions, or discourse-level patterns that differ from human writing [33].By leveraging multilevel features, our proposed algorithm can effectively capture these differences, enabling precise quantification of LLM involvement in LLM-generated text.</p>
<p>Large Language Models and Thesis Writing</p>
<p>Large language models like OpenAI's ChatGPT [34] has transformed academic writing, extending beyond grammar correction to comprehensive support.While early tools like Grammarly and Hemingway Editor focused on linguistic accuracy, modern LLMs provide advanced capabilities, including text generation, structural suggestions, and literature review assistance [35].Studies indicate that these models alleviate writer's block, expedite manuscript preparation, and enhance paper quality [36].Research shows a growing reliance on LLMs in academic writing.Liang et al. [37] analyzed 950,965 papers from arXiv and Nature (2020-2024), noting a consistent rise in LLM usage due to competitive pressures and academic challenges.Taiye et al. [38] highlighted generative LLM's potential to enhance student writing and critical thinking, advocating for integration through improved LLM literacy and regulation.While these models offer substantial benefits, they also have notable limitations.Safrai et al. [39] pointed out accuracy and reference reliability issues with LLM.Overreliance can erode critical thinking, lead to homogenized content, and diminish originality, thus impacting research quality and integrity [40,41].</p>
<p>These challenges highlight the need to monitor and manage LLM use in academic writing.To mitigate these risks, we propose a fine-grained detection framework that analyzes LLM involvement at the sentence level, enabling precise identification of LLM-generated text.This approach preserves academic integrity, ensures credibility, and encourages responsible use of LLMs in academia.</p>
<p>The Multi-level Fine-grained Detection Framework</p>
<p>As illustrated in Fig. 1, our proposed framework begins by meticulously cleaning and preprocessing the academic text, segmenting it into individual sentences to enable focused analysis.Subsequently, we employ a suite of advanced methods to extract multi-level features from these sentences, ensuring that both sentence-level and broader contextual information are effectively captured.These features encompass statistical, semantic, and linguistic characteristics that are critical for discerning LLM-generated text.Finally, an attention-based fusion mechanism is utilized to integrate these diverse features, prioritizing the most informative signals.The fused representation is then fed into a dedicated LLM involvement predictor, designed for multi-task learning, to precisely evaluate LLM involvement across various linguistic dimensions.</p>
<p>Problem Definition</p>
<p>We propose the framework for sentence-level, finegrained detection of LLM involvement in academic texts by assessing the degree of LLM involvement from three perspectives: lexicon, grammar, and syntax.</p>
<p>Given an academic text  = { 1 ,  2 , ...,   }, where   is the -th sentence, the model outputs three distinct scores for each sentence   , representing the likelihood of LLM involvement in terms of lexical, grammatical, and syntactic features.The output for each sentence is:
ğ« ğ‘— = ( ğ‘Ÿ lex ğ‘— , ğ‘Ÿ gram ğ‘— , ğ‘Ÿ syn ğ‘— ) ,(1)
where  lex  measures the probability of LLMs involvement in lexical choices,   sentence   , the probability distribution for these outputs is conditioned on the entire document context :
ğ« ğ‘— = â„™ ğ‘˜ (ğ‘Ÿ ğ‘˜ ğ‘— | ğ‘  ğ‘— , ğ·), ğ‘˜ âˆˆ {lex, gram, syn}(2)
Each component score  k  âˆˆ [0, 1], reflects the likelihood of LLM involvement from the respective perspective.</p>
<p>Low-level Statistical Features</p>
<p>To improve the detection of LLM-generated text at a structural level, we leverage low-level statistical features that offer quantitative insights into the text.These features focus on key linguistic metrics, particularly readability and authorstyle, serving as strong indicators of text originality and coherence.</p>
<p>Readability</p>
<p>Readability is a key feature for detecting anomalies in academic text, particularly in distinguishing humanauthored content from LLM-generated text.Human writing often exhibits more variability in readability due to diverse sentence structures and vocabulary, while LLMs tend to produce text with uniform readability optimized for simplicity.As Patel et al. [42] demonstrated, LLMs like ChatGPT can reduce Flesch-Kincaid Grade (FKG) scores significantly, from 11.03 to 5.80 in patient education materials.While useful in educational contexts, such simplifications may indicate LLM authorship in academic writing, which typically requires greater complexity.</p>
<p>To capture differences in readability, we use various metrics from the textstat 2 library (see Table 1).Key measures include Flesch Reading Ease and FKG, with LLMgenerated text often scoring lower on FKG due to simpler vocabulary and sentence structures [43].We also apply the Smog Index and Gunning Fog to assess sentence length 2 https://github.com/textstat/textstat?tab=readme-ov-file</p>
<p>Table 1</p>
<p>Detailed information on various readability numerical features.</p>
<p>Attribute Description</p>
<p>Flesch Reading Ease Measures how easy the text is to read, higher scores indicate easier readability Flesch Kincaid Grade Indicates the U.S. school grade level needed to comprehend the text Smog Index</p>
<p>Calculates the complexity based on the number of polysyllabic words Coleman Liau Index Assesses readability based on characters per word and sentence length Automated Readability Index Uses character count and word length to estimate readability Dale Chall Readability Score</p>
<p>Compares text against a list of common words to measure readability difficulty Difficult Words</p>
<p>Counts the number of complex words Linsear Write Formula Evaluates readability based on the number of easy and difficult words Gunning Fog</p>
<p>Measures readability based on sentence length and complex word count Fernandez Huerta A readability score based on sentence length and syllables per word Szigriszt Pazos</p>
<p>Calculates readability using a formula similar to Flesch indices Gutierrez Polini A readability score designed for Spanish-language texts Crawford Assesses readability by considering the proportion of complex words Gulpease A readability measure based on word and sentence length Osman Another readability metric based on sentence structure and word length and complex word usage, which tend to be more varied in human writing.Additional metrics, such as Coleman Liau and the Automated Readability Index, analyze character and sentence length to detect the oversimplifications typical of LLMs.The Dale Chall Score and Difficult Words Count further reveal LLMs' preference for simpler vocabulary, enhancing readability but diminishing academic depth [44].</p>
<p>To ensure robustness, we include supplementary metrics like the Osman and Gulpease Index.These indices are useful for detection because they highlight the uniformity in LLMgenerated text compared to the variability in human writing.</p>
<p>Authorstyle</p>
<p>Unlike readability metrics, which focus on surfacelevel complexity, authorstyle provides a deeper analysis of linguistic patterns and syntactic tendencies [45].The authorstyle3 library extracts fine-grained features that distinguish human writing from LLM-generated text, particularly in academic contexts where stylistic consistency, complex structures, and lexical diversity signal expertise.By analyzing lexical richness, syntactic variation, and the use of punctuation and function words, it offers a comprehensive evaluation of writing quality beyond readability.</p>
<p>Table 2 presents the various features of authorstyle.At the lexical level, metrics such as Average Word Length and Word Length Distribution reflect vocabulary choices, with LLM-generated text often using shorter words, while human writing shows more variability.Average Sentence Length (in words and characters) helps capture structural complexity, as human writing tends to be more intricate.Syntactic complexity is measured through Part-of-Speech (POS) Tag Frequency and Trigram Frequency, which highlight patterns in syntax and word usage that differ between human and LLMgenerated text.Lexical diversity is assessed using Yule's K and Sichel's S, revealing vocabulary richness.Stylometric features, including Punctuation, Special Character, and Uppercase Frequency, along with function word and stopword ratios, further differentiate human writing from LLMs.Ngram Frequencies help detect repetitive phrases, often a hallmark of LLMs.Collectively, these features provide a comprehensive analysis of authorial style, enhancing the framework's ability to distinguish between human and LLMgenerated text.</p>
<p>High-level Semantic Features Based on Contrastive Learning</p>
<p>Existing detection systems struggle to distinguish between human and LLM-generated text, as LLMs can produce contextually accurate, coherent content that mimics human writing styles.Traditional detection methods based on superficial features are becoming less effective, especially when users modify or paraphrase LLM-generated text to evade detection.This complicates the distinction, as current approaches, particularly those relying on high-level semantic features, lack the robustness to capture these subtle changes.</p>
<p>To address these challenges, we propose a contrastive learning-based method with adversarial training to capture high-level semantic differences between human and LLMgenerated text.The specific method diagram is shown in Figure 2. Specifically, we leverage an LLM to generate two additional variants of the LLM-generated text from the parallel dataset 4 , focusing on common evasion tactics such as paraphrasing via LLMs [46] and prompt-based adjustments [47].Therefore, our method focuses on these prevalent tactics, creating variations of LLM-generated text that reflect real-world evasion techniques.First, leveraging the LLMs' text generation capabilities and extensive knowledge base, we design prompts that enable the LLM to closely imitate human writing patterns and expression habits:
ğ‘‡ â„ğ‘¢ğ‘šğ‘ğ‘›âˆ’ğ‘™ğ‘–ğ‘˜ğ‘’ = ğ¿ğ¿ğ‘€(ğ‘ƒ â„ğ‘¢ğ‘šğ‘ğ‘› |ğ‘‡ ğ¿ğ¿ğ‘€ ),(3)
where  â„âˆ’ represents text that mimics human writing,  â„ is the prompt guiding this generation, and   is the original LLM-generated text.Similarly, we create rewritten versions by prompting the LLM to paraphrase the original content while retaining its meaning:
ğ‘‡ ğ‘Ÿğ‘’ğ‘¤ğ‘Ÿğ‘–ğ‘¡ğ‘¡ğ‘’ğ‘› = ğ¿ğ¿ğ‘€(ğ‘ƒ ğ‘Ÿğ‘’ğ‘¤ğ‘Ÿğ‘–ğ‘¡ğ‘’ |ğ‘‡ ğ¿ğ¿ğ‘€ ),(4)
where   denotes the paraphrased text,   is the paraphrasing prompt.These two variations are created because they align with common tactics used to evade detection.After generating the human-like and rewritten variations of the LLM-generated text, we train the encoder using contrastive learning with four text types: the human-like text, the rewritten text, the original LLM-generated text, and the original human-authored text.This enables the model to capture fine-grained semantic differences between human and LLMgenerated text, even after paraphrasing or modifications.We apply a twice-triplet loss function, where the original LLMgenerated text serves as the anchor, the human-like and rewritten texts act as two positive examples, and a humanauthored text from a different sample serves as the negative example, providing contrast for effective learning.To shift the cosine similarity values from [âˆ’1, 1] to [0, 1] and ensure non-negative distances, we adjust it by adding 1 and dividing by 2. The adjusted cosine similarity between any two text embeddings   and   is defined as: The corresponding distances can be grouped into positive and negative examples, which are defined as:
sim * (ğ‘‡ ğ‘– , ğ‘‡ ğ‘— ) = ğ‘‡ ğ‘– â‹… ğ‘‡ ğ‘— 2â€–ğ‘‡ ğ‘– â€–â€–ğ‘‡ ğ‘— â€– + 1 2 . (5)ğ‘‘ pos = 1 âˆ’ sim * (ğ‘‡ LLM , ğ‘‡ modified ),(6)ğ‘‘ neg = 1 âˆ’ sim * (ğ‘‡ ğ‘¥ , ğ‘‡ human ),
where  modified âˆˆ { human-like ,  rewritten }, representing the distance between the LLM-generated text and either the human-like or rewritten version of the text,   âˆˆ { LLM ,  human-like ,  rewritten }, indicating the distance between the LLM-generated, human-like, or rewritten text and a genuine human-authored text.The twice-triplet loss function îˆ¸ contra is reformulated as:
îˆ¸ contra = 2 âˆ‘ ğ‘˜=1 3 âˆ‘ ğ‘™=1 ([ ğ‘‘ ğ‘˜ pos âˆ’ ğ‘‘ ğ‘™ neg + ğ›¼ ] + ) ,(7)
where [] + = max{0, } denotes the hinge function,   pos represents the distance between the anchor  LLM and the th positive example ( human-like for  = 1 and  rewritten for  = 2),   neg denotes the distance between the anchor and the -th negative example ( LLM ,  human-like ,  rewritten compared with  human for  = 1, 2, 3), and  &gt; 0 is the margin parameter controlling the separation between positive and negative pairs.By minimizing this loss function, the encoder learns to pull the anchor (LLM-generated text) closer to the positive examples (human-like and rewritten texts) while pushing it away from the negative example (human-authored text) in the embedding space.This process strengthens the model's ability to distinguish between human and LLM-generated text, even after paraphrasing or rewriting.</p>
<p>Deep-level Linguistic Features Based on LLMs</p>
<p>LLMs excel in natural language understanding, particularly in analyzing lexicon, grammar, and syntax [48].Their extensive pre-training enables them to capture complex linguistic patterns and subtleties that are often overlooked by traditional methods.By modeling probabilistic language structures, LLMs can detect deviations in word choice, syntax, and grammatical consistency-key indicators of LLMgenerated text [49].This enables LLMs to offer a refined approach to detecting their own involvement in text generation.</p>
<p>Our proposed model, illustrated in Figure 3, goes beyond sentence-level analysis by leveraging an LLM to extract deep linguistic features from the entire text, focusing on lexicon, grammar, and syntax.This holistic approach captures contextual relationships across the entire text, enabling the model to detect patterns in LLM-generated text that may be missed by superficial analysis.We begin by encoding both the original text and the LLM-analyzed text:
ğ¸ ğ‘– = Encoder(ğ‘‡ ğ‘– ), where ğ‘– âˆˆ {ğ‘  ğ‘— , ğ¿ğ¿ğ‘€_ğ‘ğ‘›ğ‘ğ‘™ğ‘¦}. (8)
Here   represents the -th sentence of the entire text  orig , which is encoded sentence by sentence, while  LLM_analy refers to the entire text analyzed by the LLM.To refine the encoded features from the LLM analysis, we apply a Multi-Head Self-Attention (MHSA) mechanism followed by a Feed-Forward Network (FFN), similar to the Transformer architecture.This setup captures text dependencies and allows the model to focus on salient sections while using non-linear transformations for more expressive feature representation.For each input embedding  _ , we compute the queries   , keys   , and values   matrices for each attention head :
ğ‘‹ ğ‘– = ğ¸ ğ¿ğ¿ğ‘€_ğ‘ğ‘›ğ‘ğ‘™ğ‘¦ ğ‘Š ğ‘‹ ğ‘– , ğ‘‹ âˆˆ {ğ‘„, ğ¾, ğ‘‰ },(9)
where   represents any of the matrices   ,   , or   .   corresponds to the learned weight matrices    ,    , or     for the -th attention head.The attention output for each head is computed as:
head ğ‘– = softmax ( ğ‘„ ğ‘– ğ¾ âŠ¤ ğ‘– âˆš ğ‘‘ 1ğ‘˜
)   , (10) with  1 representing the dimensionality of the key vectors.</p>
<p>The outputs from all heads are concatenated and projected:
MHSA(ğ¸ ğ¿ğ¿ğ‘€_ğ‘ğ‘›ğ‘ğ‘™ğ‘¦ ) = Concat(head 1 , â€¦ , head â„ )ğ‘Š ğ‘‚ , (11)
where   is the output projection matrix.A residual connection and layer normalization are then applied to stabilize training:
ğ¸ â€² ğ¿ğ¿ğ‘€_ğ‘ğ‘›ğ‘ğ‘™ğ‘¦ = LN(ğ¸ LLM_analy +MHSA(ğ¸ ğ¿ğ¿ğ‘€_ğ‘ğ‘›ğ‘ğ‘™ğ‘¦ )). (12)
The refined representation is further processed a positionwise FFN, introducing non-linearity:
FFN(ğ¸ â€² ğ¿ğ¿ğ‘€_ğ‘ğ‘›ğ‘ğ‘™ğ‘¦ ) = ReLU(ğ¸ â€² ğ¿ğ¿ğ‘€_ğ‘ğ‘›ğ‘ğ‘™ğ‘¦ ğ‘Š 1 +ğ‘ 1 )ğ‘Š 2 +ğ‘ 2 , (13)
where  1 and  2 are learned weight matrices, and  1 and  2 are bias vectors.Another residual connection and layer normalization yield the final representation:
ğ¸ * ğ¿ğ¿ğ‘€_ğ‘ğ‘›ğ‘ğ‘™ğ‘¦ = LN(ğ¸ â€² ğ¿ğ¿ğ‘€_ğ‘ğ‘›ğ‘ğ‘™ğ‘¦ +FFN(ğ¸ â€² ğ¿ğ¿ğ‘€_ğ‘ğ‘›ğ‘ğ‘™ğ‘¦ )).(14)
This streamlined architecture enhances the model's ability to learn complex linguistic patterns by retaining the input signal while applying transformative operations.</p>
<p>To extract deep linguistic features from individual sentences more effectively, while still allowing the model to account for contextual information, we introduce a Cross-Attention module.This mechanism facilitates interactions between the sentence and the LLM-analyzed text, ensuring that the analyzed text is more precise and contextually relevant to the sentence within its broader context.Let the feature representation of the sentence be  =    and that of the LLM-analyzed text be  =  =  * _ .The Cross-Attention mechanism then computes the standard scaled dot-product between the normalized query and key vectors, leveraging the interactions between the sentence and LLM-analyzed text.This produces attention scores that highlight specific aspects of the LLM-analyzed text, making it more focused on this thesis sentence:
Att scores = ğ‘„ğ¾ âŠ¤ âˆš ğ‘‘ 2ğ‘˜ , (15)
where  2 is the dimensionality of the key vectors used as a scaling factor.The attention scores are then used to weight the value vectors  , focusing on the most contextually relevant parts of the LLM-analyzed text:
ğ‘“ ğ‘‘ğ‘’ğ‘’ğ‘ = softmax ( Att scores ) ğ‘‰ . (16)
where   represents the deep linguistic features of the sentence.</p>
<p>Multi-level Features Fusion and LLM Involvement Prediction</p>
<p>After extracting features from the three hierarchical levels, we perform a weighted fusion to integrate information from each level.This fusion is crucial for capturing both global contextual nuances and fine-grained textual characteristics.We introduce learnable weights   , applied to the respective feature vectors   corresponding to the low-level, high-level, and deep-level features:
fğ‘– = ğ‘¤ ğ‘– âŠ™ ğ‘“ ğ‘– , for ğ‘– âˆˆ {ğ‘™ğ‘œğ‘¤, â„ğ‘–ğ‘”â„, ğ‘‘ğ‘’ğ‘’ğ‘},(17)
where âŠ™ denotes element-wise multiplication.The weighted feature vectors f are then concatenated to form a unified representation:
ffusion = Concat( fğ‘™ğ‘œğ‘¤ , fâ„ğ‘–ğ‘”â„ , fğ‘‘ğ‘’ğ‘’ğ‘ ),(18)
with Concat indicating concatenation along the feature dimension.The fused vector ffusion is subsequently fed into a Multi-Layer Perceptron (MLP) classifier to produce the final prediction.The prediction loss is calculated using the Mean Squared Error (MSE) between the model's output and the ground truth labels :
îˆ¸ Pred = MSE ( MLP ( ffusion ) , ğ‘¦ ) . (19)
As shown in Figure 3, to further assess the utility of the LLM-analyzed text, we input its refined representation  * LLM_analy into an evaluator network, computing an additional loss term:
îˆ¸ LLM = MSE ( MLP ( ğ¸ * LLM_analy ) , ğ‘¦ ) . (20)
The overall loss function is formulated as a weighted sum of the prediction loss and the LLM evaluation loss:
îˆ¸ = îˆ¸ Pred + ğ›½îˆ¸ LLM , (21)
where  is a hyperparameter that balances the contributions of the two loss terms.By jointly optimizing these objectives, the model effectively integrates multi-level features while leveraging insights from LLM analysis, thereby enhancing predictive performance.</p>
<p>Empirical Analysis</p>
<p>Dataset Description</p>
<p>In this study, we use the Paraphrased Text Span Detection 5 (PASTED) dataset as the primary dataset for both training and testing, while Multi-Paraphrase 6 (MP) and Out of Distribution-GPT4 7 (OOD-GPT4) are used as test datasets to evaluate the model's generalization capability.The PASTED dataset is large and provides continuous regression labels ranging from 0 to 1, making it ideal for a comprehensive assessment of the model's performance in regression tasks.In contrast, the MP and OOD-GPT4 datasets consist of binary classification labels (0 or 1) and are used exclusively for testing the model's generalization in classification tasks.This allows us to systematically evaluate the model's robustness and generalization across different task types and data distributions.</p>
<p>PASTED: This dataset aims to detect sentence-level LLM involvement in text generation of academic writing [50].It is annotated with three labels-lexical, syntactic, and grammatical-to assess LLM involvement.From the dataset, 30,000 text samples were randomly selected and split into training, validation, and test sets (80%, 10%, 10%).It includes content from models like GPT-3.5 and Dipper, with sentence-level segmentation using the '</s>' delimiter for precise LLM detection.</p>
<p>MP: This dataset comprises 1,907 texts, each of which has been rewritten using contemporary LLMs, such as GLM.The labels for each sentence are also based on three dimensions: lexical, syntactic, and grammatical.Unlike the PASTED dataset, the MP dataset uses binary labels (0 or 1) for each of these dimensions.Due to the nature of these classification labels, we exclusively employ the dataset for testing purposes, aiming to evaluate the model's ability to generalize across distinct linguistic dimensions in classification tasks.</p>
<p>OOD-GPT4: This dataset contains 9,386 texts, which were edited or rewritten using the latest GPT-4 model.In other aspects, it is essentially similar to the MP dataset.Therefore, we also used it as a test dataset.</p>
<p>Evaluation Metrics</p>
<p>We choose four common evaluation metrics for our proposed model: Mean Absolute Error (MAE), Mean Squared Error (MSE), Root Mean Squared Error (RMSE), and Accuracy.Since the task is a regression problem, accuracy is calculated by converting the predictions and true labels into binary form with a threshold of 0.5.The metrics-MAE, MSE, RMSE, and Accuracy-are computed for each dimension (lexical, syntactic, and semantic), and the final scores are obtained by averaging the results across these dimensions, providing a comprehensive evaluation of the model's overall performance.</p>
<p>Implementation Details</p>
<p>In our experiments, we utilize the AdamW optimizer with a learning rate of 1 Ã— 10 âˆ’3 and a weight decay of 1 Ã— 10 âˆ’4 .To further enhance the training process, we apply a StepLR learning rate scheduler with a step size of 5 and a</p>
<p>Experimental Results</p>
<p>Comparison with State-of-the-Art Detection Models</p>
<p>To evaluate the effectiveness of our proposed method, we conduct a comparative analysis against several stateof-the-art models, each with a unique underlying mechanism.GLTR [22] uses statistical analysis to visualize tokenlevel distribution probabilities, aiding human detection of generated text.SeqXGPT [27] combines word-level logprobabilities with convolutional neural networks and attention mechanisms for sentence-level detection, excelling in mixed content scenarios.Sniffer [51] focuses on perplexity features, particularly effective in low-resource cases.PPL [26] uses perplexity scores from GPT models to distinguish machine-generated content.PTD [50] detects paraphrased spans, identifying subtle LLM-generated manipulations within human text.Lastly, AdaLoc [52] employs multisentence predictions to localize AI-generated segments, enhancing detection precision.</p>
<p>The results of our comparative analysis, shown in Table 3, demonstrate the superiority of our proposed model across multiple evaluation metrics.In terms of MAE, our model achieves a significantly lower value of 0.1347, outperforming all other models, with the second best being PPL at 0.1807.Similarly, in terms of MSE and RMSE, our method reports the lowest values at 0.0612 and 0.2428, respectively, again surpassing PPL, which performs second best with MSE and RMSE scores of 0.0723 and 0.2633, respectively.Furthermore, our model achieves the highest accuracy of 0.8736, indicating a noticeable improvement over existing models such as PPL (0.8703) and AdaLoc (0.8686).These results highlight the effectiveness of our approach, particularly in accurately detecting LLM-generated text and minimizing prediction errors.The consistent outperformance across all metrics suggests that our model not only improves overall detection accuracy but also reduces errors more effectively compared to existing state-of-the-art methods.</p>
<p>Generalization Performance Study</p>
<p>In this experiment, we evaluate the generalization performance of state-of-the-art models on the MP and OOD-GPT4 datasets, as depicted in Figure 4.The radar charts assess four dimensions: Lexical Accuracy, Syntax Accuracy, Semantic Accuracy, and Mean On the MP dataset, our proposed MFD model achieves the highest scores, particularly in Lexical and Semantic Accuracy, reflecting its robustness and strong detection capabilities.Even in the OOD-GPT4 dataset, which consists of text generated by the highly sophisticated GPT-4, MFD maintains superior performance across all dimensions, further emphasizing its strong generalization ability in the face of advanced language generation systems.Other models, such as AdaLoc and PPL, perform well on MP but exhibit noticeable drops in certain dimensions on OOD-GPT4, while GTLR and Se-qXGPT consistently underperform.This highlights MFD's robustness and effectiveness in both standard and out-ofdistribution scenarios.</p>
<p>Ablation Study on Multi-level Feature Contributions</p>
<p>The ablation study results in Table 4 demonstrate the critical role of combining multi-level features in enhancing model performance.Individually, the low-level, deep-level, and high-level features show moderate performance, with accuracies ranging from 0.8629 to 0.8748.However, when these features are combined, particularly the low-level and high-level features, we observe a significant improvement, with an accuracy reaching 0.8837.The proposed model, which integrates all three levels of features, achieves the best performance across all metrics, with an MAE of 0.1347, an MSE of 0.0612, and an accuracy of 0.8856.This suggests that each feature set captures complementary information, and their integration enables the model to generalize better by leveraging both shallow patterns and deeper semantic cues within the data.</p>
<p>Ablation Study on Different LLMs</p>
<p>In this experiment, we integrate various large language models into our framework to evaluate how different architectures impact performance.We test six state-of-theart LLMs, each representing different design philosophies.GLM-4-9B-Chat, developed by Tsinghua University and Zhipu AI, is optimized for multi-turn dialogues, while Baichuan2-13B-Chat, from Baichuan Intelligence, focuses on multilingual tasks across diverse linguistic contexts.InternLM2.5-7B-Chat,designed by Shanghai AI Lab, is a lightweight model that balances efficiency with performance.Yi-1.5-9B-Chat, developed by 01.AI, is a finetuned model that excels in tasks requiring reasoning, commonsense understanding, and instruction-following capabilities.Qwen-2.5-7B-Chat,developed by Alibaba, offers fine-grained control in conversational interactions.Finally, Llama-3.1-8B-Instruct, from Meta AI, is fine-tuned for instruction-following, excelling in generating precise and adaptive responses.</p>
<p>The results in Table 5 reveal that the performance differences among the tested LLMs are relatively small, with all models demonstrating a high level of capability due to the maturity of transformer-based architectures and extensive pretraining on large datasets.While InternLM2.5-7B-Chatslightly others in MAE (0.1316) and Qwen-2.5-7B-Chatedges out in accuracy (0.8857), Llama-3.1-8B-Instructoffers the most balanced performance, excelling across RMSE, MSE, and accuracy metrics.These subtle variations likely stem from differences in fine-tuning methods and data diversity, indicating that modern LLMs are converging in performance but can still be tailored for specific tasks to optimize results.</p>
<p>Ablation Study on Different Encoders</p>
<p>Table 6 presents the performance of our framework using different contrastive learning encoders.The results show that T5 outperforms all other encoders across every metric, with the lowest MAE (0.1347) and the highest accuracy (0.8856).This superior performance is likely due to T5's versatile sequence-to-sequence architecture, which excels in a variety of tasks by effectively capturing both input and output relationships.In contrast, ALBERT shows the weakest results, particularly in RMSE (0.2773), likely due to its parameter-sharing mechanism, which may reduce model expressiveness.DistilBERT and RoBERTa perform competitively, demonstrating that compression (in DistilBERT's case) and enhanced training (in RoBERTa's case) can still yield high accuracy.Overall, these results highlight that while all encoders perform well, T5's architecture makes it particularly well-suited for tasks requiring nuanced predictions and lower errors.</p>
<p>Ablation Study on Different Accuracy Threshold</p>
<p>Since our predictions are continuous values between 0 and 1, we convert them into a classification task by setting thresholds to compute accuracy metrics.Figure 5 demonstrates the effect of varying accuracy thresholds on different linguistic levels, including lexical, syntactic, and semantic accuracy.As the threshold ratio increases, all accuracy metrics improve, with the highest mean accuracy achieved at a ratio of 0.8.Higher thresholds force the model to make more confident predictions, effectively filtering out noise and focusing on more clearly defined patterns, particularly in syntactic and semantic dimensions.However, the improvements in lexical accuracy are more modest, indicating that lexical features are easier to capture even at lower thresholds.The chosen threshold of 0.5 in this study represents a balanced trade-off, offering competitive performance across all metrics while avoiding potential overfitting that may arise with higher thresholds.At this ratio, the model achieves a solid mean accuracy and ensures stable generalization without overly restricting the classification boundaries.This balance between precision and flexibility makes 0.5 an optimal choice for the task.</p>
<p>Case Study of the MFD Model</p>
<p>To demonstrate the effectiveness of our MFD model, we analyze two academic text samples to assess LLM involvement at the sentence level, as shown in Table 7.In the first example, the MFD model's predictions largely align with the true labels.However, there is a slight overestimation in the sixth and final sentences, where the predicted LLM involvement is deeper than the true labels.Despite this minor discrepancy, the model effectively captures the overall LLMgenerated content in the text.In the second example, the model's predictions closely match the ground truth, with predicted LLM involvement falling within the expected range across almost all sentences, except for the second sentence, where the predicted LLM involvement is shallower than the true value.These case studies illustrate the MFD model's strength in fine-grained, sentence-level analysis, providing a reliable and nuanced assessment of LLM-generated text.</p>
<p>Discussion</p>
<p>The experimental results demonstrate the effectiveness and robustness of our proposed framework for detecting LLM involvement in LLM-generated text across multiple evaluation settings.Through comparative analysis with state-of-the-art models, our method consistently achieved superior performance.The integration of multi-level features Raw Text: We present a class of efficient models called MobileNets for mobile and embedded vision applications.MobileNets are based on a streamlined architecture that uses depthwise separable convolutions to build light sensitive images in the presence of occlusions, illumination changes or complex backgrounds.The proposed models can be used in situations where small size is important, such as wearable devices and vehicular sensing systems.To demonstrate their performance, we test MobileNet V4 on several datasets including i-Sight 3D, CycleGANs, and AlexNet.We show how our model can be used with these large scale video sequences on different platforms like smartphones.Our paper presents an efficient framework for creating high resolution stereo pictures from 2D videos using only image-level information.Even in challenging conditions like low frame rate, poor lighting, and occlusion propagation, our approach can produce detailed views.Additionally, our method minimizes computational cost and reduces noise during preprocessing to maintain high quality.It allows for regular interval image fitting without significant loss in accuracy.It also provides real-time camera pose updates, as demonstrated by conducting human arm position estimation over a webcam stream with accuracies comparable to other methods.In addition, full colour images were produced within 60 ms on device with limited processing power e.g., Galaxy S5 smartphone equipped with Adreno 320 GPU.Finally most importantly our technique achieves good performance in terms of energy efficiency allowing to use a single thread of CPU with minimal memory requirement.</p>
<p>MFD Detection Result:</p>
<p>We present a class of efficient models called MobileNets for mobile and embedded vision applications.MobileNets are based on a streamlined architecture that uses depthwise separable convolutions to build light sensitive images in the presence of occlusions, illumination changes or complex backgrounds.The proposed models can be used in situations where small size is important, such as wearable devices and vehicular sensing systems.To demonstrate their performance, we test MobileNet V4 on several datasets including i-Sight 3D, CycleGANs, and AlexNet.We show how our model can be used with these large scale video sequences on different platforms like smartphones.Our paper presents an efficient framework for creating high resolution stereo pictures from 2D videos using only image-level information.Even in challenging conditions like low frame rate, poor lighting, and occlusion propagation, our approach can produce detailed views.Additionally, our method minimizes computational cost and reduces noise during preprocessing to maintain high quality.It allows for regular interval image fitting without significant loss in accuracy.It also provides real-time camera pose updates, as demonstrated by conducting human arm position estimation over a webcam stream with accuracies comparable to other methods.In addition, full colour images were produced within 60 ms on device with limited processing power e.g., Galaxy S5 smartphone equipped with Adreno 320 GPU.Finally most importantly our technique achieves good performance in terms of energy efficiency allowing to use a single thread of CPU with minimal memory requirement.</p>
<p>Raw Text: Currently, the issue of offensive content on social media is a significant concern.It is crucial to have a system that can automatically identify offensive language.In this research paper, we develop a cloud-based offensive language detection system.By utilizing data from users' web browsing history obtained through Google Analytics, we analyze CSS and generate text messages for display in ads sent via the Google AdWords channel.Furthermore, we compare these messages with other harmful links detected through Google Analytics to identify potentially dangerous advertising campaigns.These campaigns are designed to target individuals who download advertisements from websites offering free cookies or torrent sites.</p>
<p>MFD Detection Result: Currently, the issue of offensive content on social media is a significant concern.It is crucial to have a system that can automatically identify offensive language.In this research paper, we develop a cloud-based offensive language detection system.By utilizing data from users' web browsing history obtained through Google Analytics, we analyze CSS and generate text messages for display in ads sent via the Google AdWords channel.Furthermore, we compare these messages with other harmful links detected through Google Analytics to identify potentially dangerous advertising campaigns.These campaigns are designed to target individuals who download advertisements from websites offering free cookies or torrent sites.</p>
<p>Notes: Blue represents the ground truth, and pink indicates the predicted values.Darker shades correspond to higher levels of LLM involvement, which is divided into four distinct levels.A threshold of 5% is used, below which the text is considered free of LLM involvement.</p>
<p>(low, high, and deep) proved to be essential, as shown in the ablation studies, where combining low-level and deeplevel features notably improved the detection accuracy.Our model's performance across different LLMs and encoders further validates its versatility and adaptability.Notably, T5's architecture and Llama-3.1-8B-Instructprovided the most balanced performance across metrics, underscoring the effectiveness of these models in capturing subtle manipulations typically found in LLM-generated text.The generalization performance study also confirms that our method can effectively adapt to out-of-domain data, maintaining strong performance even when applied to text that has been stylistically altered by advanced models like GPT-4.</p>
<p>These results suggest several key insights.First, the integration of multi-level linguistic features is critical for improving the detection of LLM-generated text, as different features capture distinct aspects of linguistic manipulation.Second, the choice of encoder or LLM significantly impacts the performance, with models like T5 offering more versatility due to their sequence-to-sequence structure.Lastly, while higher accuracy thresholds can lead to more precise detection in certain linguistic dimensions, a balanced threshold (such as 0.5) ensures stable performance without risking overfitting.Future work should focus on further optimizing these thresholds for different tasks and exploring how additional linguistic features, such as pragmatic or discourselevel information, might enhance model performance.Moreover, expanding the evaluation to more diverse and complex datasets could provide deeper insights into the model's robustness across various writing styles and domains.</p>
<p>Conclusion and Future Work</p>
<p>In this paper, we propose a novel Multi-level Finegrained Detection (MFD) framework that effectively addresses the growing challenges in detecting LLM-generated text in academic writing.By incorporating a multi-level analysis of statistical, semantic, and linguistic features at the sentence level, our approach not only enhances detection accuracy but also offers a more granular evaluation of LLM involvement.Moreover, to ensure consistent performance across diverse text variations, our framework leverages contrastive learning on both original and manipulated LLM-generated text.This design aims to enhance robustness, making it more resilient to common evasion tactics.Extensive experiments conducted on the public PASTED dataset demonstrate that our MFD model outperforms existing methods, achieving an MAE of 0.1346 and an accuracy of 88.56%.Additionally, the model maintains consistent performance on MP and OOD-GPT4 datasets, validating its strong generalization capabilities across various types of LLM-generated text.Our approach makes a significant contribution to the field of academic integrity by providing a comprehensive and scalable solution for the precise identification of LLM-generated text, which is critical in preserving the authenticity and credibility of scholarly research in the evolving landscape of LLM-driven text generation.</p>
<p>Looking ahead, several important directions for future research emerge.One promising path is to extend the framework's capabilities to a cross-linguistic context, enabling the detection of LLM-generated text across multiple languages, which is crucial given the global nature of academic discourse.Additionally, exploring adaptive learning techniques could further strengthen the model's resilience to advancements in LLM technologies and sophisticated adversarial attempts to bypass detection systems.Another valuable area for development lies in integrating real-time detection functionalities into academic writing tools, offering immediate safeguards to uphold the integrity and originality of scholarly output.By advancing these areas, the framework can continue to lead efforts in detecting LLM-generated text and protecting academic integrity in an evolving digital landscape.</p>
<p>gram  represents the influence on grammatical structure,  syn  captures syntactic patterns.For each</p>
<p>Figure 1 :
1
Figure 1: The Multi-level Fine-grained Detection (MFD) framework for LLM-generated text.</p>
<p>Figure 2 :
2
Figure 2: High-level semantic contrastive learning framework with adversarial training.</p>
<p>Figure 3 :
3
Figure 3: LLM-based deep linguistic feature extraction framework.</p>
<p>Figure 4 :
4
Figure 4: Radar charts of generalization performance of models on MP and OOD-GPT4 datasets.</p>
<p>Figure 5 :
5
Figure 5: Effect of threshold ratios on Accuracy metrics.</p>
<p>Table 2
2
Detailed information on various authorstyle numerical features.
AttributeDescriptionAverage Word LengthAverage number of characters perwordPOS Tag FrequencyFrequency of different part-of-speech tagsPOS Tag Trigram FrequencyFrequency of three consecutivePOS tagsWord Length DistributionDistribution of word lengths acrossthe textAverage Sentence Length WordsAverage number of words per sen-tenceAverage Syllables Per WordAverage number of syllables perwordAverage Sentence Length CharsAverage number of characters persentenceSentence Length DistributionDistribution of sentence lengths toassess variability in sentence struc-tureYule K MetricA measure of lexical diversitySichel S MetricMetric indicating the frequency oflow-frequency wordsAverage Word Frequency ClassThe average word frequency class,indicating how often words are typ-ically used in language.Punctuation FrequencyFrequency of punctuation marksSpecial Character FrequencyFrequency of punctuation marksUppercase FrequencyFrequency of uppercase letters,capturing usage patterns such asacronyms or emphasis.Number FrequencyFrequency of numbers in the textFunctionword FrequencyFrequency of function wordsMost Common Words Without Stopwords The most frequently used contentwordsStopword RatioRatio of stopwords to total wordsTop Word Bigram FrequencyFrequency of the most common bi-gramsTop Bigram FrequencyFrequency of bigrams, helping todetect repeated patterns of wordcombinations.Top 3 Gram FrequencyFrequency of trigrams (three con-secutive words), indicating formu-laic or common multi-word phrases.</p>
<p>Table 3
3
Quantitative results of different models on key metrics.
ModelMAEMSERMSEAccuracyGLTR [22]0.20220.07730.27190.8686SeqXGPT [27]0.21090.07720.27200.8687Sniffer [51]0.19890.07810.27340.8689PPL [26]0.18070.07230.26330.8703PTD [50]0.19040.07650.27060.8687AdaLoc [52]0.19800.07700.27160.8686Proposed Model0.13470.06120.24280.8856decay factor ğ›¾ = 0.5. The model is trained for 30 epochs,with a training batch size of 512 and a validation batchsize of 64. In this experiment, the value of ğ›½ in the lossfunction is set to 0.5, and the number of heads in the multi-head attention mechanism is set to 8. The encoder in ourframework is based on T5 model, while the contrastivelearning mechanism, which helps counter evasion tacticsin text generation, as well as the deep linguistic featureextraction, both rely on the Llama-3.1-8B-Instruct model.Only parameters that require gradients are updated duringoptimization, ensuring computational efficiency. All modelsare trained and evaluated on four NVIDIA H800 GPUs.</p>
<p>Table 4
4
Results of ablation study on multi-level features.
ModelMAEMSERMSE AccuracyLow-level0.1929 0.0784 0.2799 0.8629High-level0.1722 0.0662 0.2572 0.8748Deep-level0.1891 0.0797 0.2762 0.8687Low-level+High-level0.1387 0.0621 0.2444 0.8837Low-level+Deep-level0.1624 0.0710 0.2609 0.8723Deep-level+High-level 0.1421 0.0626 0.2435 0.8839Proposed Model0.1347 0.0612 0.2428 0.8856</p>
<p>Table 5
5
Results of ablation study on different LLMs.
LLMMAEMSERMSE AccuracyGLM-4-9B-Chat0.1406 0.0616 0.2435 0.8850Baichuan2-13B-Chat0.1442 0.0624 0.2431 0.8850InternLM2.5-7B-Chat0.1316 0.0614 0.2431 0.8852Yi-1.5-9B-Chat0.1423 0.0616 0.2435 0.8852Qwen-2.5-7B-Chat0.1404 0.0614 0.2432 0.8857Llama-3.1-8B-Instruct 0.1347 0.0612 0.2428 0.8856</p>
<p>Table 6
6
Results of ablation study on different encoders.
EncoderMAEMSERMSEAccuracyElectra0.16810.06960.25850.8733XLNet0.17110.06960.25850.8735DistilBERT0.15850.06720.25400.8757ALBERT0.14970.07920.27730.8687RoBERTa0.16510.06950.25830.8736T50.13470.06120.24280.8856</p>
<p>Table 7
7
Comparison of raw text and MFD detection results for LLM Involvement.</p>
<p>https://github.com/TaoZhen1110/MFD
https://github.com/mullerpeter/authorstyle
https://github.com/FreedomIntelligence/ChatGPT-Detection-PR-HPPT/tree/main/Dataset
https://huggingface.co/datasets/linzw/PASTED/blob/main/regressionmulti-dimension.zip
https://huggingface.co/datasets/linzw/PASTED/blob/main/evalmulti-paraphrase.zip
7 https://huggingface.co/datasets/linzw/PASTED/blob/main/eval-OOD.zip</p>
<p>Cowriting with opinionated language models affects users' views. M Jakesch, A Bhat, D Buschek, L Zalmanson, M Naaman, Proceedings of the 2023 CHI conference on human factors in computing systems. the 2023 CHI conference on human factors in computing systems2023</p>
<p>Bookgpt: A general framework for book recommendation empowered by large language model. Z Li, Y Chen, X Zhang, X Liang, Electronics. 122246542023</p>
<p>Evaluation and mitigation of the limitations of large language models in clinical decision-making. P Hager, F Jungmann, R Holland, K Bhagat, I Hubrecht, M Knauer, J Vielhauer, M Makowski, R Braren, G Kaissis, Nature medicine. 2024</p>
<p>Tree of thoughts: Deliberate problem solving with large language models. S Yao, D Yu, J Zhao, I Shafran, T Griffiths, Y Cao, K Narasimhan, Advances in Neural Information Processing Systems. 362024</p>
<p>Chatgpt and a new academic reality: Artificial intelligence-written research papers and the ethics of the large language models in scholarly publishing. B D Lund, T Wang, N R Mannuru, B Nie, S Shimray, Z Wang, Journal of the Association for Information Science and Technology. 7452023</p>
<p>Science in the age of large language models. A Birhane, A Kasirzadeh, D Leslie, S Wachter, Nature Reviews Physics. 552023</p>
<p>Empowering education with llms-the next-gen interface and content generation. S Moore, R Tong, A Singh, Z Liu, X Hu, Y Lu, J Liang, C Cao, H Khosravi, P Denny, International Conference on Artificial Intelligence in Education. Springer2023</p>
<p>Bias and unfairness in information retrieval systems: New challenges in the llm era. S Dai, C Xu, S Xu, L Pang, Z Dong, J Xu, Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining. the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining2024</p>
<p>Exploring the psychology of llms' moral and legal reasoning. G F Almeida, J L Nunes, N Engelmann, A Wiegmann, M De AraÃºjo, Artificial Intelligence. 3331041452024</p>
<p>An overview of quality assurance in higher education: Concepts and frameworks. M Kayyali, Sciences, Innovation, and Technology (IJMSIT). 422023International Journal of Management</p>
<p>Practical and ethical challenges of large language models in education: A systematic scoping review. L Yan, L Sha, L Zhao, Y Li, R Martinez-Maldonado, G Chen, X Li, Y Jin, D GaÅ¡eviÄ‡, British Journal of Educational Technology. 5512024</p>
<p>Llm-as-a-coauthor: Can mixed humanwritten and machine-generated text be detected?. Q Zhang, C Gao, D Chen, Y Huang, Y Huang, Z Sun, S Zhang, W Li, Z Fu, Y Wan, in: Findings of the Association for Computational Linguistics: NAACL 2024, 2024</p>
<p>A survey on automatic generation of figurative language: From rule-based systems to large language models. H Lai, M Nissim, ACM Computing Surveys. 56102024</p>
<p>B Huang, C Chen, K Shu, arXiv:2408.08946Authorship attribution in the era of llms: Problems, methodologies, and challenges. 2024arXiv preprint</p>
<p>Chatgpt and the rise of large language models: the new ai-driven infodemic threat in public health. L De Angelis, F Baglivo, G Arzilli, G P Privitera, P Ferragina, A E Tozzi, C Rizzo, Frontiers in public health. 1111661202023</p>
<p>Y Zhou, B He, L Sun, arXiv:2406.08922Navigating the shadows: Unveiling effective disturbances for modern ai content detectors. 2024arXiv preprint</p>
<p>Hidding the ghostwriters: An adversarial evaluation of ai-generated student essay detection. X Peng, Y Zhou, B He, L Sun, Y Sun, arXiv:2402.004122024arXiv preprint</p>
<p>A survey on evaluation of large language models. Y Chang, X Wang, J Wang, Y Wu, L Yang, K Zhu, H Chen, X Yi, C Wang, Y Wang, ACM Transactions on Intelligent Systems and Technology. 1532024</p>
<p>Can llm-generated misinformation be detected?. C Chen, K Shu, arXiv:2309.137882023arXiv preprint</p>
<p>Academic integrity considerations of ai large language models in the post-pandemic era: Chatgpt and beyond. M Perkins, Journal of University Teaching and Learning Practice. 2022023</p>
<p>Algorithmic injustice: a relational ethics approach. A Birhane, Patterns. 222021</p>
<p>S Gehrmann, H Strobelt, A M Rush, arXiv:1906.04043Gltr: Statistical detection and visualization of generated text. 2019arXiv preprint</p>
<p>I Solaiman, M Brundage, J Clark, A Askell, A Herbert-Voss, J Wu, A Radford, G Krueger, J W Kim, S Kreps, arXiv:1908.09203Release strategies and the social impacts of language models. 2019arXiv preprint</p>
<p>Detectgpt: Zero-shot machine-generated text detection using probability curvature. E Mitchell, Y Lee, A Khazatsky, C D Manning, C Finn, International Conference on Machine Learning. PMLR2023</p>
<p>Y Tian, H Chen, X Wang, Z Bai, Q Zhang, R Li, C Xu, Y Wang, arXiv:2305.18149Multiscale positive-unlabeled detection of ai-generated texts. 2023arXiv preprint</p>
<p>B Guo, X Zhang, Z Wang, M Jiang, J Nie, Y Ding, J Yue, Y Wu, arXiv:2301.07597How close is chatgpt to human experts? comparison corpus, evaluation, and detection. 2023arXiv preprint</p>
<p>P Wang, L Li, K Ren, B Jiang, D Zhang, X Qiu, arXiv:2310.08903Seqxgpt: Sentence-level ai-generated text detection. 2023arXiv preprint</p>
<p>Coco: Coherenceenhanced machine-generated text detection under low resource with contrastive learning. X Liu, Z Zhang, Y Wang, H Pu, Y Lan, C Shen, Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing. the 2023 Conference on Empirical Methods in Natural Language Processing2023</p>
<p>Multiscale feature extraction and fusion of image and text in vqa. S Lu, Y Ding, M Liu, Z Yin, L Yin, W Zheng, International Journal of Computational Intelligence Systems. 161542023</p>
<p>Multi-level feature fusion for multimodal human activity recognition in internet of healthcare things. M M Islam, S Nooruddin, F Karray, G Muhammad, Information Fusion. 942023</p>
<p>Part-of-speech-and syntactic-aware graph convolutional network for aspect-level sentiment classification. Y Tian, R Yue, D Wang, J Liu, X Liang, Multimedia Tools and Applications. 83102024</p>
<p>What neural oscillations can and cannot do for syntactic structure building. N Kazanina, A Tavano, Nature Reviews Neuroscience. 2422023</p>
<p>A MuÃ±oz-Ortiz, C GÃ³mez-RodrÃ­guez, D Vilares, arXiv:2308.09067Contrasting linguistic patterns in human and llm-generated text. 2023arXiv preprint</p>
<p>J Achiam, S Adler, S Agarwal, L Ahmad, I Akkaya, F L Aleman, D Almeida, J Altenschmidt, S Altman, S Anadkat, arXiv:2303.08774Gpt-4 technical report. 2023arXiv preprint</p>
<p>Exploring artificial intelligence in academic essay: higher education student's perspective. A R Malik, Y Pratiwi, K Andajani, I W Numertayasa, S Suharti, A Darwis, International Journal of Educational Research Open. 51002962023</p>
<p>Using artificial intelligence in academic writing and research: An essential productivity tool. M Khalifa, M Albadawy, Computer Methods and Programs in Biomedicine Update. 1001452024</p>
<p>W Liang, Y Zhang, Z Wu, H Lepp, W Ji, X Zhao, H Cao, S Liu, S He, Z Huang, arXiv:2404.01268Mapping the increasing use of llms in scientific papers. 2024arXiv preprint</p>
<p>Generative ai-enhanced academic writing: A stakeholder-centric approach for the design and development of chat4isp-ai. M Taiye, C High, J Velander, K Matar, R Okmanis, M Milrad, Proceedings of the 39th ACM/SIGAPP Symposium on Applied Computing. the 39th ACM/SIGAPP Symposium on Applied Computing2024</p>
<p>Utilizing artificial intelligence in academic writing: an in-depth evaluation of a scientific review on fertility preservation written by chatgpt-4. M Safrai, K E Orwig, Journal of Assisted Reproduction and Genetics. 2024</p>
<p>Chatgpt in education: A blessing or a curse? a qualitative study exploring early adopters' utilization and perceptions. R H Mogavi, C Deng, J J Kim, P Zhou, Y D Kwon, A H S Metwally, A Tlili, S Bassanelli, A Bucchiarone, S Gujar, Computers in Human Behavior: Artificial Humans. 211000272024</p>
<p>J Zhang, H Bu, H Wen, Y Chen, L Li, H Zhu, arXiv:2405.03644When llms meet cybersecurity: A systematic literature review. 2024arXiv preprint</p>
<p>The use of artificial intelligence to improve readability of otolaryngology patient education materials. E A Patel, L Fleischer, P Filip, M Eggerstedt, M Hutz, E Michaelides, P S Batra, B A Tajudeen, Otolaryngology-Head and Neck Surgery. 2024</p>
<p>Advancing tinnitus therapeutics: Gpt-2 driven clustering analysis of cognitive behavioral therapy sessions and google t5-based predictive modeling for thi score assessment. Y Jeong, J.-J Song, J Yang, S Kang, IEEE Access. 2024</p>
<p>Why and when llmbased assistants can go wrong: Investigating the effectiveness of prompt-based interactions for software help-seeking. A Khurana, H Subramonyam, P K Chilana, Proceedings of the 29th International Conference on Intelligent User Interfaces. the 29th International Conference on Intelligent User Interfaces2024</p>
<p>C Guerin, C Aitchison, S Carter, Creating, Managing, and Editing Multi-authored Publications: A Guide for Scholars. Taylor &amp; Francis2024</p>
<p>Outfox: Llm-generated essay detection through in-context learning with adversarially generated examples. R Koike, M Kaneko, N Okazaki, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202438</p>
<p>Y Wang, S Feng, A B Hou, X Pu, C Shen, X Liu, Y Tsvetkov, T He, arXiv:2402.11638Stumbling blocks: Stress testing the robustness of machine-generated text detectors under attacks. 2024arXiv preprint</p>
<p>Vassilakopoulos, Large language models versus natural language understanding and generation. N Karanikolas, E Manga, N Samaridi, E Tousidou, M , Proceedings of the 27th Pan-Hellenic Conference on Progress in Computing and Informatics. the 27th Pan-Hellenic Conference on Progress in Computing and Informatics2023</p>
<p>From form (s) to meaning: Probing the semantic depths of language models using multisense consistency. X Ohmer, E Bruni, D Hupkes, Computational Linguistics. 2024</p>
<p>Y Li, Z Wang, L Cui, W Bi, S Shi, Y Zhang, arXiv:2405.12689Spotting ai's touch: Identifying llm-paraphrased spans in text. 2024arXiv preprint</p>
<p>L Li, P Wang, K Ren, T Sun, X Qiu, arXiv:2304.14072Origin tracing and detecting of llms. 2023arXiv preprint</p>
<p>Z Zhang, W Qin, B A Plummer, arXiv:2402.11744Machine-generated text localization. 2024arXiv preprint</p>            </div>
        </div>

    </div>
</body>
</html>