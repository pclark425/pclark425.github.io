<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-4356 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-4356</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-4356</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-99.html">extraction-schema-99</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, systems, or approaches that use LLMs (or other AI models) to extract, distill, or discover quantitative laws, patterns, relationships, or principles from scientific papers or scholarly literature.</div>
                <p><strong>Paper ID:</strong> paper-280401075</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2507.23276v1.pdf" target="_blank">How Far Are AI Scientists from Changing the World?</a></p>
                <p><strong>Paper Abstract:</strong> The emergence of large language models (LLMs) is propelling automated scientific discovery to the next level, with LLM-based Artificial Intelligence (AI) Scientist systems now taking the lead in scientific research. Several influential works have already appeared in the field of AI Scientist systems, with AI-generated research papers having been accepted at the ICLR 2025 workshop, suggesting that a human-level AI Scientist capable of uncovering phenomena previously unknown to humans, may soon become a reality. In this survey, we focus on the central question: How far are AI scientists from changing the world and reshaping the scientific research paradigm? To answer this question, we provide a prospect-driven review that comprehensively analyzes the current achievements of AI Scientist systems, identifying key bottlenecks and the critical components required for the emergence of a scientific agent capable of producing ground-breaking discoveries that solve grand challenges. We hope this survey will contribute to a clearer understanding of limitations of current AI Scientist systems, showing where we are, what is missing, and what the ultimate goals for scientific AI should be.</p>
                <p><strong>Cost:</strong> 0.024</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e4356.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e4356.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, systems, or approaches that use LLMs (or other AI models) to extract, distill, or discover quantitative laws, patterns, relationships, or principles from scientific papers or scholarly literature.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Tshitoyan2019</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Unsupervised word embeddings capture latent knowledge from materials science literature</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Unsupervised word-embedding methods applied to a large corpus of materials-science text to surface latent material–property associations and candidate hypotheses by vector-space similarity and analogy operations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Unsupervised word embeddings capture latent knowledge from materials science literature</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Unsupervised word-embedding literature discovery</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Train unsupervised word/phrase embeddings on a large corpus of materials-science papers; use embedding similarity and vector algebra (analogy) to identify correlated concepts and propose candidate material–property links and hypotheses. Operates by ranking nearest neighbors and detecting salient co-occurrence / embedding-patterns that indicate latent relationships across the literature.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Materials science</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>type_of_quantitative_law</strong></td>
                            <td>latent material–property associations / statistical correlations</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_output_format</strong></td>
                            <td>embedding-derived associations and ranked candidate concept pairs (non-symbolic vectors / association lists)</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Method is distributional (non-symbolic) and yields associations rather than explicit mathematical laws; limited interpretability and inability to output closed-form quantitative equations; dependent on corpus coverage and word-sense disambiguation.</td>
                        </tr>
                        <tr>
                            <td><strong>requires_human_in_loop</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fully_automated</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'How Far Are AI Scientists from Changing the World?', 'publication_date_yy_mm': '2025-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4356.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e4356.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, systems, or approaches that use LLMs (or other AI models) to extract, distill, or discover quantitative laws, patterns, relationships, or principles from scientific papers or scholarly literature.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>TELIN</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>TELIN: Table entity LINker for extracting leaderboards from machine learning publications</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A system to extract structured Task–Dataset–Model triples and experimental result entities from tables in ML papers to construct leaderboards automatically.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>TELIN: Table entity LINker for extracting leaderboards from machine learning publications</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Table-entity linking for leaderboard extraction</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Automatically parse tables in research papers, link table cells to canonical Task/Dataset/Model entities and numeric metrics, and assemble structured leaderboard entries (Task, Dataset, Model, metric, numeric value). The pipeline includes table retrieval, entity normalization, and mapping of metric names to canonical forms to produce machine-readable leaderboards.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Machine learning / Computer science literature</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>type_of_quantitative_law</strong></td>
                            <td>experimental numeric results / performance comparisons (benchmarks)</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_output_format</strong></td>
                            <td>structured Task–Dataset–Model triples with numeric metric values (tables/knowledge-graph entries)</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td>Quality-based selection / manual curation mentioned in follow-up work (not specified here)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Heterogeneity of table formats, inconsistent metric names, and lack of standardized entity identifiers complicate extraction and normalization; ensuring coverage and correctness is challenging.</td>
                        </tr>
                        <tr>
                            <td><strong>requires_human_in_loop</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fully_automated</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'How Far Are AI Scientists from Changing the World?', 'publication_date_yy_mm': '2025-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4356.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e4356.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, systems, or approaches that use LLMs (or other AI models) to extract, distill, or discover quantitative laws, patterns, relationships, or principles from scientific papers or scholarly literature.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ORKG-Leaderboards</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ORKG-Leaderboards: a systematic workflow for mining leaderboards as a knowledge graph</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Workflow and tooling to mine experimental leaderboards from publications and represent them as structured knowledge in a graph for retrieval and comparison.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Orkg-leaderboards: a systematic workflow for mining leaderboards as a knowledge graph</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Knowledge-graph-based leaderboard mining</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Extract experimental tables and result entries from papers, normalize Task/Dataset/Model/Metric entities, and ingest them into a knowledge-graph (ORKG) schema to enable structured queries and cross-paper comparisons of numeric experimental results.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Computer science / ML benchmarks</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>type_of_quantitative_law</strong></td>
                            <td>empirical performance relationships across models and datasets (benchmark numeric comparisons)</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_output_format</strong></td>
                            <td>knowledge-graph triples and structured table records (Task, Dataset, Model, metric, numeric value)</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Coverage gaps in published tables, entity normalization difficulty, evolving benchmark definitions, and potential inconsistencies across papers.</td>
                        </tr>
                        <tr>
                            <td><strong>requires_human_in_loop</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fully_automated</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'How Far Are AI Scientists from Changing the World?', 'publication_date_yy_mm': '2025-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4356.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e4356.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, systems, or approaches that use LLMs (or other AI models) to extract, distill, or discover quantitative laws, patterns, relationships, or principles from scientific papers or scholarly literature.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AxCell</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>AxCell: Automatic extraction of results from machine learning papers</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An automated extractor that targets numeric experimental results reported in ML papers (tables/figures) to build structured result records.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>AxCell: Automatic extraction of results from machine learning papers</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Automatic numeric result extraction</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Parse document structure to locate tables/figures, extract numeric cells and associate them with surrounding textual context (model/dataset/metric), and produce structured result entries for downstream leaderboard construction or meta-analysis.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Machine learning</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>type_of_quantitative_law</strong></td>
                            <td>experimental numeric results (metrics/leaderboards)</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_output_format</strong></td>
                            <td>structured table records / key–value numeric extractions</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Table parsing errors, ambiguity in mapping numbers to metric labels, and missing standardization across papers.</td>
                        </tr>
                        <tr>
                            <td><strong>requires_human_in_loop</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fully_automated</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'How Far Are AI Scientists from Changing the World?', 'publication_date_yy_mm': '2025-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4356.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e4356.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, systems, or approaches that use LLMs (or other AI models) to extract, distill, or discover quantitative laws, patterns, relationships, or principles from scientific papers or scholarly literature.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LEGO-bench</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LEGO-bench: Scientific leaderboard generation benchmark</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A benchmark to evaluate systems' ability to extract experimental results and generate leaderboards automatically from scientific literature.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Legobench: Scientific leaderboard generation benchmark.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Benchmarking leaderboard extraction (LEGO-bench)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Provides tasks and datasets focused on retrieving tables, integrating data across papers, generating leaderboards, and selecting high-quality leaderboards; used to evaluate methods that extract numeric experimental results from literature.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Machine learning / empirical computer science</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>type_of_quantitative_law</strong></td>
                            <td>empirical performance rankings (leaderboard numeric relationships)</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_output_format</strong></td>
                            <td>leaderboards (tables) and integrated numeric records</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td>Quality-based selection of best leaderboards (benchmark evaluation)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Dataset and ground-truth construction is difficult; coverage of relevant publications can be incomplete and gold standards are hard to define.</td>
                        </tr>
                        <tr>
                            <td><strong>requires_human_in_loop</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fully_automated</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'How Far Are AI Scientists from Changing the World?', 'publication_date_yy_mm': '2025-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4356.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e4356.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, systems, or approaches that use LLMs (or other AI models) to extract, distill, or discover quantitative laws, patterns, relationships, or principles from scientific papers or scholarly literature.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LAG</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Leader Auto Generation (LAG)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A four-stage pipeline for dynamic leaderboard generation from extracted experimental tables and figures in the literature, incorporating retrieval, integration, generation, and quality selection.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>LAG: LLM agents for leaderboard auto generation on demanding</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Leader Auto Generation (LAG) pipeline</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Implements table retrieval, data integration across multiple sources, automatic leaderboard generation (assembling Task/Dataset/Model/metrics), and a quality-based selection stage to pick the best leaderboards; leverages retrieval and LLM components in the pipeline (RAG-style retrieval feeding generation).</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Machine learning / computer science leaderboards</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>type_of_quantitative_law</strong></td>
                            <td>assembled experimental performance relations (leaderboards)</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_output_format</strong></td>
                            <td>aggregated leaderboards and structured numeric records</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td>quality-based selection (automated ranking of candidate leaderboards)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Integration across conflicting reports, table heterogeneity, hallucination risk in generated leaderboard narratives, and retrieval precision limits.</td>
                        </tr>
                        <tr>
                            <td><strong>requires_human_in_loop</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fully_automated</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'How Far Are AI Scientists from Changing the World?', 'publication_date_yy_mm': '2025-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4356.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e4356.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, systems, or approaches that use LLMs (or other AI models) to extract, distill, or discover quantitative laws, patterns, relationships, or principles from scientific papers or scholarly literature.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MathProgSearch2024</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Mathematical discoveries from program search with large language models</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Use LLM-guided program search to discover novel mathematical identities and closed-form relationships by generating candidate programs/formulas and testing them by computation/symbolic checks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Mathematical discoveries from program search with large language models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>LLM-guided program search for mathematical discovery</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Use a large language model to generate short programs or symbolic expressions that represent candidate mathematical identities or relationships; execute or symbolically simplify the candidates (program search / testing) to verify correctness and surface novel closed-form identities.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td>large language models (specific models not detailed in this survey text)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Mathematics / mathematical discovery</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>type_of_quantitative_law</strong></td>
                            <td>mathematical identities / closed-form equations</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_output_format</strong></td>
                            <td>symbolic expressions / executable programs representing equations</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td>program execution and computational/symbolic verification (as reported in cited work; details not provided in survey)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Search space explosion, correctness verification complexity, reliance on computational checks rather than deriving formal proofs within the LLM; resource cost for execution/testing.</td>
                        </tr>
                        <tr>
                            <td><strong>requires_human_in_loop</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fully_automated</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'How Far Are AI Scientists from Changing the World?', 'publication_date_yy_mm': '2025-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4356.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e4356.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, systems, or approaches that use LLMs (or other AI models) to extract, distill, or discover quantitative laws, patterns, relationships, or principles from scientific papers or scholarly literature.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PaperQA</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>PaperQA / PaperQA2</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>RAG-style systems for scientific question answering over papers that retrieve relevant passages and answer queries; used to extract targeted quantitative facts from documents.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>PaperQA and PaperQA2</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Retrieval-augmented paper QA</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Combine document retrieval (from arXiv, Semantic Scholar, etc.) with generation by an LLM (RAG) to answer natural-language questions about scientific papers, including numeric facts, experimental values, or relationships mentioned in the literature.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Cross-domain (scientific literature)</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>type_of_quantitative_law</strong></td>
                            <td>targeted numeric facts and relationships (as stated in source papers)</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_output_format</strong></td>
                            <td>textual answers and extracted numeric values (optionally structured if post-processed)</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Retrieval precision and hallucination can lead to incorrect numeric answers; multi-document synthesis and attribution remain difficult.</td>
                        </tr>
                        <tr>
                            <td><strong>requires_human_in_loop</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fully_automated</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'How Far Are AI Scientists from Changing the World?', 'publication_date_yy_mm': '2025-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4356.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e4356.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, systems, or approaches that use LLMs (or other AI models) to extract, distill, or discover quantitative laws, patterns, relationships, or principles from scientific papers or scholarly literature.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MCX-LLM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>MCX-LLM (Monte Carlo experiment interface via LLM)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An approach that uses LLMs to convert natural-language experiment descriptions into machine-readable inputs for Monte Carlo simulations, enabling automated quantitative analysis.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>MCX-LLM</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Natural-language-to-simulation pipeline (MCX-LLM)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Use an LLM to parse free-text experimental descriptions and generate machine-readable parameterizations suitable for Monte Carlo / simulation code; run the simulation and return quantitative outputs and visualizations, assisting extraction of quantitative relationships implied by textual descriptions.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Simulation / computational experiments (general)</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>type_of_quantitative_law</strong></td>
                            <td>simulation-derived quantitative relationships and numeric outputs</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_output_format</strong></td>
                            <td>simulation inputs (structured parameters) and numeric simulation outputs/plots</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td>simulation correctness and downstream evaluation datasets mentioned in cited work (details not provided in survey)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Mapping ambiguous textual descriptions to precise simulation parameters is error-prone; requires robust grounding of units and assumptions.</td>
                        </tr>
                        <tr>
                            <td><strong>requires_human_in_loop</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fully_automated</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'How Far Are AI Scientists from Changing the World?', 'publication_date_yy_mm': '2025-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4356.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e4356.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, systems, or approaches that use LLMs (or other AI models) to extract, distill, or discover quantitative laws, patterns, relationships, or principles from scientific papers or scholarly literature.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PIFLOW</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>PIFLOW: Principle-aware scientific discovery with multi-agent collaboration</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A multi-agent, principle-aware framework that aims to discover scientific principles by combining literature search, hypothesis generation, and agentic evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>PIFLOW: Principle-aware scientific discovery with multi-agent collaboration</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Principle-aware multi-agent discovery (PIFLOW)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Use multiple agents (LLM-based roles) to read literature, propose principle-level hypotheses, and iteratively test/refine them using retrieval and evaluation modules; emphasizes surfacing underlying principles (qualitative and quantitative) rather than just isolated facts.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Cross-domain scientific discovery</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>type_of_quantitative_law</strong></td>
                            <td>scientific principles / hypothesized relationships (potentially quantitative)</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_output_format</strong></td>
                            <td>natural-language principle statements and candidate quantitative relationships (format depends on agent outputs)</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Requires robust multi-agent coordination and standards for expressing/validating principles; risk of compounding errors across agent interactions.</td>
                        </tr>
                        <tr>
                            <td><strong>requires_human_in_loop</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fully_automated</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'How Far Are AI Scientists from Changing the World?', 'publication_date_yy_mm': '2025-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Unsupervised word embeddings capture latent knowledge from materials science literature <em>(Rating: 2)</em></li>
                <li>Mathematical discoveries from program search with large language models <em>(Rating: 2)</em></li>
                <li>TELIN: Table entity LINker for extracting leaderboards from machine learning publications <em>(Rating: 2)</em></li>
                <li>Orkg-leaderboards: a systematic workflow for mining leaderboards as a knowledge graph <em>(Rating: 2)</em></li>
                <li>AxCell: Automatic extraction of results from machine learning papers <em>(Rating: 2)</em></li>
                <li>Legobench: Scientific leaderboard generation benchmark. <em>(Rating: 2)</em></li>
                <li>LAG: LLM agents for leaderboard auto generation on demanding <em>(Rating: 2)</em></li>
                <li>PaperQA <em>(Rating: 1)</em></li>
                <li>MCX-LLM <em>(Rating: 1)</em></li>
                <li>PIFLOW: Principle-aware scientific discovery with multi-agent collaboration <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-4356",
    "paper_id": "paper-280401075",
    "extraction_schema_id": "extraction-schema-99",
    "extracted_data": [
        {
            "name_short": "Tshitoyan2019",
            "name_full": "Unsupervised word embeddings capture latent knowledge from materials science literature",
            "brief_description": "Unsupervised word-embedding methods applied to a large corpus of materials-science text to surface latent material–property associations and candidate hypotheses by vector-space similarity and analogy operations.",
            "citation_title": "Unsupervised word embeddings capture latent knowledge from materials science literature",
            "mention_or_use": "mention",
            "method_name": "Unsupervised word-embedding literature discovery",
            "method_description": "Train unsupervised word/phrase embeddings on a large corpus of materials-science papers; use embedding similarity and vector algebra (analogy) to identify correlated concepts and propose candidate material–property links and hypotheses. Operates by ranking nearest neighbors and detecting salient co-occurrence / embedding-patterns that indicate latent relationships across the literature.",
            "llm_model_used": null,
            "scientific_domain": "Materials science",
            "number_of_papers": null,
            "type_of_quantitative_law": "latent material–property associations / statistical correlations",
            "extraction_output_format": "embedding-derived associations and ranked candidate concept pairs (non-symbolic vectors / association lists)",
            "validation_method": null,
            "performance_metrics": null,
            "baseline_comparison": null,
            "challenges_limitations": "Method is distributional (non-symbolic) and yields associations rather than explicit mathematical laws; limited interpretability and inability to output closed-form quantitative equations; dependent on corpus coverage and word-sense disambiguation.",
            "requires_human_in_loop": null,
            "fully_automated": null,
            "uuid": "e4356.0",
            "source_info": {
                "paper_title": "How Far Are AI Scientists from Changing the World?",
                "publication_date_yy_mm": "2025-07"
            }
        },
        {
            "name_short": "TELIN",
            "name_full": "TELIN: Table entity LINker for extracting leaderboards from machine learning publications",
            "brief_description": "A system to extract structured Task–Dataset–Model triples and experimental result entities from tables in ML papers to construct leaderboards automatically.",
            "citation_title": "TELIN: Table entity LINker for extracting leaderboards from machine learning publications",
            "mention_or_use": "mention",
            "method_name": "Table-entity linking for leaderboard extraction",
            "method_description": "Automatically parse tables in research papers, link table cells to canonical Task/Dataset/Model entities and numeric metrics, and assemble structured leaderboard entries (Task, Dataset, Model, metric, numeric value). The pipeline includes table retrieval, entity normalization, and mapping of metric names to canonical forms to produce machine-readable leaderboards.",
            "llm_model_used": null,
            "scientific_domain": "Machine learning / Computer science literature",
            "number_of_papers": null,
            "type_of_quantitative_law": "experimental numeric results / performance comparisons (benchmarks)",
            "extraction_output_format": "structured Task–Dataset–Model triples with numeric metric values (tables/knowledge-graph entries)",
            "validation_method": "Quality-based selection / manual curation mentioned in follow-up work (not specified here)",
            "performance_metrics": null,
            "baseline_comparison": null,
            "challenges_limitations": "Heterogeneity of table formats, inconsistent metric names, and lack of standardized entity identifiers complicate extraction and normalization; ensuring coverage and correctness is challenging.",
            "requires_human_in_loop": null,
            "fully_automated": null,
            "uuid": "e4356.1",
            "source_info": {
                "paper_title": "How Far Are AI Scientists from Changing the World?",
                "publication_date_yy_mm": "2025-07"
            }
        },
        {
            "name_short": "ORKG-Leaderboards",
            "name_full": "ORKG-Leaderboards: a systematic workflow for mining leaderboards as a knowledge graph",
            "brief_description": "Workflow and tooling to mine experimental leaderboards from publications and represent them as structured knowledge in a graph for retrieval and comparison.",
            "citation_title": "Orkg-leaderboards: a systematic workflow for mining leaderboards as a knowledge graph",
            "mention_or_use": "mention",
            "method_name": "Knowledge-graph-based leaderboard mining",
            "method_description": "Extract experimental tables and result entries from papers, normalize Task/Dataset/Model/Metric entities, and ingest them into a knowledge-graph (ORKG) schema to enable structured queries and cross-paper comparisons of numeric experimental results.",
            "llm_model_used": null,
            "scientific_domain": "Computer science / ML benchmarks",
            "number_of_papers": null,
            "type_of_quantitative_law": "empirical performance relationships across models and datasets (benchmark numeric comparisons)",
            "extraction_output_format": "knowledge-graph triples and structured table records (Task, Dataset, Model, metric, numeric value)",
            "validation_method": null,
            "performance_metrics": null,
            "baseline_comparison": null,
            "challenges_limitations": "Coverage gaps in published tables, entity normalization difficulty, evolving benchmark definitions, and potential inconsistencies across papers.",
            "requires_human_in_loop": null,
            "fully_automated": null,
            "uuid": "e4356.2",
            "source_info": {
                "paper_title": "How Far Are AI Scientists from Changing the World?",
                "publication_date_yy_mm": "2025-07"
            }
        },
        {
            "name_short": "AxCell",
            "name_full": "AxCell: Automatic extraction of results from machine learning papers",
            "brief_description": "An automated extractor that targets numeric experimental results reported in ML papers (tables/figures) to build structured result records.",
            "citation_title": "AxCell: Automatic extraction of results from machine learning papers",
            "mention_or_use": "mention",
            "method_name": "Automatic numeric result extraction",
            "method_description": "Parse document structure to locate tables/figures, extract numeric cells and associate them with surrounding textual context (model/dataset/metric), and produce structured result entries for downstream leaderboard construction or meta-analysis.",
            "llm_model_used": null,
            "scientific_domain": "Machine learning",
            "number_of_papers": null,
            "type_of_quantitative_law": "experimental numeric results (metrics/leaderboards)",
            "extraction_output_format": "structured table records / key–value numeric extractions",
            "validation_method": null,
            "performance_metrics": null,
            "baseline_comparison": null,
            "challenges_limitations": "Table parsing errors, ambiguity in mapping numbers to metric labels, and missing standardization across papers.",
            "requires_human_in_loop": null,
            "fully_automated": null,
            "uuid": "e4356.3",
            "source_info": {
                "paper_title": "How Far Are AI Scientists from Changing the World?",
                "publication_date_yy_mm": "2025-07"
            }
        },
        {
            "name_short": "LEGO-bench",
            "name_full": "LEGO-bench: Scientific leaderboard generation benchmark",
            "brief_description": "A benchmark to evaluate systems' ability to extract experimental results and generate leaderboards automatically from scientific literature.",
            "citation_title": "Legobench: Scientific leaderboard generation benchmark.",
            "mention_or_use": "mention",
            "method_name": "Benchmarking leaderboard extraction (LEGO-bench)",
            "method_description": "Provides tasks and datasets focused on retrieving tables, integrating data across papers, generating leaderboards, and selecting high-quality leaderboards; used to evaluate methods that extract numeric experimental results from literature.",
            "llm_model_used": null,
            "scientific_domain": "Machine learning / empirical computer science",
            "number_of_papers": null,
            "type_of_quantitative_law": "empirical performance rankings (leaderboard numeric relationships)",
            "extraction_output_format": "leaderboards (tables) and integrated numeric records",
            "validation_method": "Quality-based selection of best leaderboards (benchmark evaluation)",
            "performance_metrics": null,
            "baseline_comparison": null,
            "challenges_limitations": "Dataset and ground-truth construction is difficult; coverage of relevant publications can be incomplete and gold standards are hard to define.",
            "requires_human_in_loop": null,
            "fully_automated": null,
            "uuid": "e4356.4",
            "source_info": {
                "paper_title": "How Far Are AI Scientists from Changing the World?",
                "publication_date_yy_mm": "2025-07"
            }
        },
        {
            "name_short": "LAG",
            "name_full": "Leader Auto Generation (LAG)",
            "brief_description": "A four-stage pipeline for dynamic leaderboard generation from extracted experimental tables and figures in the literature, incorporating retrieval, integration, generation, and quality selection.",
            "citation_title": "LAG: LLM agents for leaderboard auto generation on demanding",
            "mention_or_use": "mention",
            "method_name": "Leader Auto Generation (LAG) pipeline",
            "method_description": "Implements table retrieval, data integration across multiple sources, automatic leaderboard generation (assembling Task/Dataset/Model/metrics), and a quality-based selection stage to pick the best leaderboards; leverages retrieval and LLM components in the pipeline (RAG-style retrieval feeding generation).",
            "llm_model_used": null,
            "scientific_domain": "Machine learning / computer science leaderboards",
            "number_of_papers": null,
            "type_of_quantitative_law": "assembled experimental performance relations (leaderboards)",
            "extraction_output_format": "aggregated leaderboards and structured numeric records",
            "validation_method": "quality-based selection (automated ranking of candidate leaderboards)",
            "performance_metrics": null,
            "baseline_comparison": null,
            "challenges_limitations": "Integration across conflicting reports, table heterogeneity, hallucination risk in generated leaderboard narratives, and retrieval precision limits.",
            "requires_human_in_loop": null,
            "fully_automated": null,
            "uuid": "e4356.5",
            "source_info": {
                "paper_title": "How Far Are AI Scientists from Changing the World?",
                "publication_date_yy_mm": "2025-07"
            }
        },
        {
            "name_short": "MathProgSearch2024",
            "name_full": "Mathematical discoveries from program search with large language models",
            "brief_description": "Use LLM-guided program search to discover novel mathematical identities and closed-form relationships by generating candidate programs/formulas and testing them by computation/symbolic checks.",
            "citation_title": "Mathematical discoveries from program search with large language models",
            "mention_or_use": "mention",
            "method_name": "LLM-guided program search for mathematical discovery",
            "method_description": "Use a large language model to generate short programs or symbolic expressions that represent candidate mathematical identities or relationships; execute or symbolically simplify the candidates (program search / testing) to verify correctness and surface novel closed-form identities.",
            "llm_model_used": "large language models (specific models not detailed in this survey text)",
            "scientific_domain": "Mathematics / mathematical discovery",
            "number_of_papers": null,
            "type_of_quantitative_law": "mathematical identities / closed-form equations",
            "extraction_output_format": "symbolic expressions / executable programs representing equations",
            "validation_method": "program execution and computational/symbolic verification (as reported in cited work; details not provided in survey)",
            "performance_metrics": null,
            "baseline_comparison": null,
            "challenges_limitations": "Search space explosion, correctness verification complexity, reliance on computational checks rather than deriving formal proofs within the LLM; resource cost for execution/testing.",
            "requires_human_in_loop": null,
            "fully_automated": null,
            "uuid": "e4356.6",
            "source_info": {
                "paper_title": "How Far Are AI Scientists from Changing the World?",
                "publication_date_yy_mm": "2025-07"
            }
        },
        {
            "name_short": "PaperQA",
            "name_full": "PaperQA / PaperQA2",
            "brief_description": "RAG-style systems for scientific question answering over papers that retrieve relevant passages and answer queries; used to extract targeted quantitative facts from documents.",
            "citation_title": "PaperQA and PaperQA2",
            "mention_or_use": "mention",
            "method_name": "Retrieval-augmented paper QA",
            "method_description": "Combine document retrieval (from arXiv, Semantic Scholar, etc.) with generation by an LLM (RAG) to answer natural-language questions about scientific papers, including numeric facts, experimental values, or relationships mentioned in the literature.",
            "llm_model_used": null,
            "scientific_domain": "Cross-domain (scientific literature)",
            "number_of_papers": null,
            "type_of_quantitative_law": "targeted numeric facts and relationships (as stated in source papers)",
            "extraction_output_format": "textual answers and extracted numeric values (optionally structured if post-processed)",
            "validation_method": null,
            "performance_metrics": null,
            "baseline_comparison": null,
            "challenges_limitations": "Retrieval precision and hallucination can lead to incorrect numeric answers; multi-document synthesis and attribution remain difficult.",
            "requires_human_in_loop": null,
            "fully_automated": null,
            "uuid": "e4356.7",
            "source_info": {
                "paper_title": "How Far Are AI Scientists from Changing the World?",
                "publication_date_yy_mm": "2025-07"
            }
        },
        {
            "name_short": "MCX-LLM",
            "name_full": "MCX-LLM (Monte Carlo experiment interface via LLM)",
            "brief_description": "An approach that uses LLMs to convert natural-language experiment descriptions into machine-readable inputs for Monte Carlo simulations, enabling automated quantitative analysis.",
            "citation_title": "MCX-LLM",
            "mention_or_use": "mention",
            "method_name": "Natural-language-to-simulation pipeline (MCX-LLM)",
            "method_description": "Use an LLM to parse free-text experimental descriptions and generate machine-readable parameterizations suitable for Monte Carlo / simulation code; run the simulation and return quantitative outputs and visualizations, assisting extraction of quantitative relationships implied by textual descriptions.",
            "llm_model_used": null,
            "scientific_domain": "Simulation / computational experiments (general)",
            "number_of_papers": null,
            "type_of_quantitative_law": "simulation-derived quantitative relationships and numeric outputs",
            "extraction_output_format": "simulation inputs (structured parameters) and numeric simulation outputs/plots",
            "validation_method": "simulation correctness and downstream evaluation datasets mentioned in cited work (details not provided in survey)",
            "performance_metrics": null,
            "baseline_comparison": null,
            "challenges_limitations": "Mapping ambiguous textual descriptions to precise simulation parameters is error-prone; requires robust grounding of units and assumptions.",
            "requires_human_in_loop": null,
            "fully_automated": null,
            "uuid": "e4356.8",
            "source_info": {
                "paper_title": "How Far Are AI Scientists from Changing the World?",
                "publication_date_yy_mm": "2025-07"
            }
        },
        {
            "name_short": "PIFLOW",
            "name_full": "PIFLOW: Principle-aware scientific discovery with multi-agent collaboration",
            "brief_description": "A multi-agent, principle-aware framework that aims to discover scientific principles by combining literature search, hypothesis generation, and agentic evaluation.",
            "citation_title": "PIFLOW: Principle-aware scientific discovery with multi-agent collaboration",
            "mention_or_use": "mention",
            "method_name": "Principle-aware multi-agent discovery (PIFLOW)",
            "method_description": "Use multiple agents (LLM-based roles) to read literature, propose principle-level hypotheses, and iteratively test/refine them using retrieval and evaluation modules; emphasizes surfacing underlying principles (qualitative and quantitative) rather than just isolated facts.",
            "llm_model_used": null,
            "scientific_domain": "Cross-domain scientific discovery",
            "number_of_papers": null,
            "type_of_quantitative_law": "scientific principles / hypothesized relationships (potentially quantitative)",
            "extraction_output_format": "natural-language principle statements and candidate quantitative relationships (format depends on agent outputs)",
            "validation_method": null,
            "performance_metrics": null,
            "baseline_comparison": null,
            "challenges_limitations": "Requires robust multi-agent coordination and standards for expressing/validating principles; risk of compounding errors across agent interactions.",
            "requires_human_in_loop": null,
            "fully_automated": null,
            "uuid": "e4356.9",
            "source_info": {
                "paper_title": "How Far Are AI Scientists from Changing the World?",
                "publication_date_yy_mm": "2025-07"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Unsupervised word embeddings capture latent knowledge from materials science literature",
            "rating": 2,
            "sanitized_title": "unsupervised_word_embeddings_capture_latent_knowledge_from_materials_science_literature"
        },
        {
            "paper_title": "Mathematical discoveries from program search with large language models",
            "rating": 2,
            "sanitized_title": "mathematical_discoveries_from_program_search_with_large_language_models"
        },
        {
            "paper_title": "TELIN: Table entity LINker for extracting leaderboards from machine learning publications",
            "rating": 2,
            "sanitized_title": "telin_table_entity_linker_for_extracting_leaderboards_from_machine_learning_publications"
        },
        {
            "paper_title": "Orkg-leaderboards: a systematic workflow for mining leaderboards as a knowledge graph",
            "rating": 2,
            "sanitized_title": "orkgleaderboards_a_systematic_workflow_for_mining_leaderboards_as_a_knowledge_graph"
        },
        {
            "paper_title": "AxCell: Automatic extraction of results from machine learning papers",
            "rating": 2,
            "sanitized_title": "axcell_automatic_extraction_of_results_from_machine_learning_papers"
        },
        {
            "paper_title": "Legobench: Scientific leaderboard generation benchmark.",
            "rating": 2,
            "sanitized_title": "legobench_scientific_leaderboard_generation_benchmark"
        },
        {
            "paper_title": "LAG: LLM agents for leaderboard auto generation on demanding",
            "rating": 2,
            "sanitized_title": "lag_llm_agents_for_leaderboard_auto_generation_on_demanding"
        },
        {
            "paper_title": "PaperQA",
            "rating": 1
        },
        {
            "paper_title": "MCX-LLM",
            "rating": 1
        },
        {
            "paper_title": "PIFLOW: Principle-aware scientific discovery with multi-agent collaboration",
            "rating": 2,
            "sanitized_title": "piflow_principleaware_scientific_discovery_with_multiagent_collaboration"
        }
    ],
    "cost": 0.0240755,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>How Far Are AI Scientists from Changing the World?
August 1st, 2025</p>
<p>Qiujie Xie 
School of Engineering
Westlake University</p>
<p>Zhejiang University</p>
<p>Yixuan Weng 
School of Engineering
Westlake University</p>
<p>Minjun Zhu 
School of Engineering
Westlake University</p>
<p>Zhejiang University</p>
<p>Fuchen Shen 
School of Engineering
Westlake University</p>
<p>Shulin Huang 
School of Engineering
Westlake University</p>
<p>Zhen Lin 
Jiahui Zhou 
School of Engineering
Westlake University</p>
<p>School of Software
Dalian University of Technology</p>
<p>Zilan Mao 
School of Engineering
Westlake University</p>
<p>Zijie Yang 
School of Engineering
Westlake University</p>
<p>School of Life Sciences
Westlake University</p>
<p>Linyi Yang 
University College London</p>
<p>Jian Wu 
School of Engineering
Westlake University</p>
<p>Yue Zhang zhangyue@westlake.edu.cn 
School of Engineering
Westlake University</p>
<p>How Far Are AI Scientists from Changing the World?
August 1st, 2025CB58F6DF42B9D5BFB50793B303C6C4C0arXiv:2507.23276v2[cs.AI]AI Scientist, Large Language Models AI Training Computer Science 30 Claude-Sonnet-35 5000%
The emergence of large language models (LLMs) is propelling automated scientific discovery to the next level, with LLM-based Artificial Intelligence (AI) Scientist systems now taking the lead in scientific research.Several influential works have already appeared in the field of AI Scientist systems, with AI-generated research papers having been accepted at the ICLR 2025 workshop, suggesting that a human-level AI Scientist capable of uncovering phenomena previously unknown to humans, may soon become a reality.In this survey, we focus on the central question: How far are AI scientists from changing the world and reshaping the scientific research paradigm?To answer this question, we provide a prospect-driven review that comprehensively analyzes the current achievements of AI Scientist systems, identifying key bottlenecks and the critical components required for the emergence of a scientific agent capable of producing ground-breaking discoveries that solve grand challenges.We hope this survey will contribute to a clearer understanding of limitations of current AI Scientist systems, showing where we are, what is missing, and what the ultimate goals for scientific AI should be.</p>
<p>Introduction</p>
<p>Scientific discovery is the fundamental driving force behind the advancement of human civilization.From Newton's laws of motion and gravitation (Newton, 1833, Newton andChittenden, 1850), through Einstein's theory of relativity (Einstein, 1922), to artificial intelligence (LeCun et al., 2015, Ertel, 2024), every major scientific breakthrough has expanded the boundaries of human understanding and propelled societal progress.Traditionally, humans, as the primary agents of scientific research, have followed a systematic path of exploration.This process typically begins with observation and learning to establish a foundational basis for scientific knowledge (knowledge acquisition), followed by the formulation of scientific hypotheses to address unresolved questions (idea generation).The subsequent step involves rigorous testing and falsification of these hypotheses through intensive experiments and theoretical analysis (verification and falsification).Finally, research is continuously refined based on experimental or theoretical results, driving the ongoing evolution of scientific knowledge (Langley, 1987).The capability level of an AI Scientist, illustrating the progression from foundational knowledge acquisition (Level 1), through idea generation (Level 2), rigorous hypothesis verification and falsification (Level 3), to continuous evolution (Level 4).We outline the core functions for each capability level.</p>
<p>However, the research process is inherently constrained by human limitations such as limited time and cognitive capacity, leading to slow literature reviews, relatively narrow knowledge domains, biased hypothesis generation, and inefficient experiment execution (Ioannidis, 2005, Baker, 2016).To address these issues, there has been a growing pursuit of the automation of scientific discovery (Yang et al., 2023(Yang et al., , 2025a)).Early efforts have focused on leveraging deep learning techniques (LeCun et al., 2015, Vaswani et al., 2017) to support knowledge acquisition.For example, pre-trained language models have been adapted with domain-specific knowledge to better represent scientific information (Gupta et al., 2022).However, due to constraints in model capacity and the availability of high-quality scientific data, these methods have primarily served as scientific tools, providing partial acceleration to the human research process.In recent years, LLMs trained on large-scale, high-quality corpora have demonstrated remarkable abilities in both comprehension and generation across long-text scenarios, making it possible to generate novel and feasible scientific hypotheses based on the accumulated knowledge (Si et al., 2024), and to rigorously evaluate these hypotheses using automated experimental tools (Wierenga et al., 2023, Starace et al., 2025).This progress is propelling automated scientific discovery to the next level, where LLM-based AI Scientist systems (Lu et al., 2024, Weng et al., 2025) are now taking the lead in exploration.Once endowed with capabilities beyond human limitations (e.g., the ability to overcome restricted memory capacity), an AI Scientist will have the potential to make ground-breaking discoveries that solve grand challenges across medicine, energy, and the environment.We are now poised to explore a central question in the field: How far are AI scientists from changing the world and reshaping the scientific research paradigm?</p>
<p>To answer this question, we provide a prospect-driven review of existing achievements.Figure 1 lays out a hierarchy of capacities necessary for a mature AI Scientist, which we reckon as a reasonable road map for current and future research in this direction.Specifically, our survey introduces a capability-level Where are the gaps?</p>
<p>What have we achieved?LLM-based AI Scientist have made progress in automated experimental design, code generation, and result analysis, especially in computer science domains.LLM-based agents now can propose, implement, and partially validate experiments.</p>
<p>AI Scientist systems struggle to dynamically adapt research directions and autonomously learn from feedback, thus limiting their capacity for independent innovation.</p>
<p>Where are the gaps?</p>
<p>What have we achieved?Elementary mechanisms for iterative improvement have emerged, including self-reflection, reinforcement learning, and externally guided revision (e.g., human-in-the-loop and multi-agent research communities).</p>
<p>Figure 2:</p>
<p>The current capability landscape of AI Scientist systems across four progressive levels.We summarize the current achievements for each level and highlight critical gaps before AI Scientist systems can autonomously make ground-breaking scientific discoveries.</p>
<p>framework that systematically defines the stages of AI scientist development, including: (1) knowledge acquisition, which is the foundational capability of an AI Scientist, encompassing the autonomous capability to retrieve, review, and comprehend scientific knowledge from existing research.(2) Idea generation, refers to the capability to generate innovative and feasible hypotheses at scale.This capability serves as the key feature distinguishing AI scientist systems from automated scientific tools.(3) Verification and falsification, the capability to systematically design, implement, and analyze experiments to test and potentially disprove the AI-generated scientific hypotheses, transforming the AI Scientist from an idea generator into an autonomous scientific intelligence.(4) Evolution, the capability to continuously advance overall research abilities based on internal and external feedback, which is essential for an elementary AI Scientist to evolve into a mature scientific agent.We critically analyze current research through the lens of this capability framework, identifying key bottlenecks and missing components necessary for the emergence of ground-breaking discoveries produced by autonomous scientific intelligence.</p>
<p>For the above capabilities, there have been endeavors, successes, and limitations (Figure 2).We first systematically review existing achievements in knowledge acquisition (Sections 2), idea generation (Sections 3), and verification and falsification (Sections 4) capabilities of current AI Scientist systems, mapping representative methods to each capability level.We then outline the development of AI reviewer systems and present empirical evidence demonstrating that current AI Scientist systems lack the ability to independently conduct high-quality scientific discovery (Section 5).To overcome these limitations, it is essential for AI Scientist systems to possess the capability for evolution (Section 6), thus moving toward the goal of reshaping the scientific research paradigm.Furthermore, we comprehensively examine the challenges faced in current AI Scientist research (Section 7) and discuss future directions and open questions (Section 8), offering a reasonable road map toward truly autonomous scientific intelligence.</p>
<p>Knowledge Acquisition</p>
<p>Definition: Knowledge acquisition is the foundational capability of an AI Scientist, defined as its autonomous capability to retrieve, review, and comprehend domain-specific knowledge from existing scientific literature, thereby systematically establishing a scientific knowledge base for subsequent research.</p>
<p>Knowledge acquisition represents the foundational capability of an AI Scientist, encompassing the autonomous capability to retrieve, review, and comprehend domain-specific knowledge from existing scientific research.This critical capability establishes the knowledge base necessary for subsequent research activities, functioning similarly to human researchers' literature review processes.We systematically examine how modern AI Scientist systems, particularly LLM-powered methods, address the dual challenges of (1) literature search/curation (filtering relevant research from massive corpora) and (2) knowledge retrieval/summarization (extracting structured insights).Interestingly, even before the advent of LLMs, the foundational concept of AI Scientist systems had already garnered significant attention, with numerous smaller-scale language models demonstrating notable success in the knowledge acquisition phase.Consequently, in this section, we categorize research work of AI Scientist systems in knowledge acquisition into the pre-LLM era (roughly before 2020) and the LLM era (from 2020 onwards, marked by the emergence of LLMs such as GPT-3 (Brown et al., 2020)).</p>
<p>Pre-LLM Era Methods</p>
<p>During the pre-LLM era, researchers make significant progress in automated knowledge acquisition by fine-tuning small pre-trained language models (PLMs) with domain-specific knowledge to learn substantial scientific representations (Beltagy et al., 2019, Jin et al., 2019, Li et al., 2023).These models demonstrate remarkable capabilities in structured text mining and knowledge extraction from scientific literature, paving the way for more advanced methods based on LLMs.</p>
<p>Literature.Prior to the rise of LLMs, early automated knowledge acquisition systems predominantly relied on smaller PLMs that are trained on substantial scientific corpora.SciBERT (Beltagy et al., 2019) is the first PLM that is pretrained on 1.14 million papers and achieves strong performance on scientific NER and citation classification tasks, accelerating human researchers' research efficiency, especially in the computer science domain.Similarly, SCHOLARBERT (Hong et al., 2023), pretrained on 221B tokens of scholarly text, largely enhances contextual understanding in scientific literature.Domain-specific models, such as CinicalBERT (Huang et al., 2019), PubMedBERT (Gu et al., 2020), BioELMo (Jin et al., 2019), BioBERT (Lee et al., 2020), BioMegatron (Shin et al., 2020), BioM-Transformers (Alrowili and Shanker, 2021), and MatSciBERT (Gupta et al., 2022) are pretrained on high-quality clinical, biology, and chemistry corpora.These models focus on structured text mining, extracting key phrases, entities, and relationships from scientific abstracts or full papers using techniques like rule-based parsing and graph-based citation analysis (Cachola et al., 2020a).Kang et al. (2022) leverage the author network graph methods to disclose the deep connection behind users' interaction with the papers.Similarly, Kang et al. (2023) construct a committee of authors with user-selected paper seeds while accepting signals from multiple sources to dynamically discover related literature.While the above pre-LLM era studies achieve notable success in automated knowledge acquisition, their scalability and contextual understanding are fundamentally limited, setting the stage for more sophisticated approaches to knowledge acquisition.</p>
<p>Experiments.</p>
<p>In pre-LLM era, researchers also explore the extraction of knowledge from experimental results (e.g., the construction of leaderboards).Following the efforts of utilizing data sources like NLPprogress1 and Papers with Code2 , SciGen (Moosavi et al., 2021) and Numerical-NLG (Suadaa et al., 2021) are two benchmarks that assess the capability of language models in scientific table description generation.However, these works are found to lack stringent quality assurance measures.For instance, there is no standardization of scientific entities across various leaderboards, and the coverage of relevant publications is incomplete.Instead, SCICM (Li et al., 2023) opts for arXiv, which is an open-access archive for nearly 2.4 million scholarly articles in different domains, providing a large amount of relevant publications.Similar to SCICM, TDMS-IE (Hou et al., 2019), and AxCell (Kardas et al., 2020) extract "Task-Dataset-Model" triples, along with the experiment result entities to build leaderboards automatically.This line of work is extended by subsequent methods such as TELIN (Yang et al., 2022) and ORKG-Leaderboards (KABENAMUALU et al., 2023), marking a clear trend toward improving research efficiency.</p>
<p>LLM Era Methods</p>
<p>The transformative impact of LLMs on the knowledge acquisition capabilities of AI Scientist systems marks the beginning of the "LLM era".These advancements span literature search toolkits, idea-and experimentoriented knowledge extraction techniques, and specialized evaluation benchmarks.At the same time, they underscore persistent challenges in retrieval precision and multi-document summarization.</p>
<p>Literature Search and Curation</p>
<p>Researchers have developed specialized toolkits and systems to efficiently filter, select, and recommend relevant scientific literature from diverse sources (e.g., PubMed3 , arXiv4 ).Among these works, systems such as PaperWeaver (Lee et al., 2024) stand out for their versatility, as they are capable of supporting multiple substages throughout the literature search pipeline.Building on this progress, DORA AI Scientist (Naumov et al., 2025) further advances the field by incorporating Retrieval-Augmented Generation (RAG) (Gao et al., 2023) into its core search process, thereby enhancing contextual relevance and automation.Despite these advancements, not all systems are fully autonomous.For example, semi-automatic frameworks like CodeScientist (Jansen et al., 2025) still rely on user-supplied paper lists for ideation, highlighting the ongoing challenges in achieving truly automated and high-precision literature discovery.</p>
<p>Building on this spectrum of approaches, researchers have developed varied implementations for searching and filtering scientific literature.Schmidgall et al. (2025)  Furthermore, the pursuit of greater autonomy is exemplified by PaSa (He et al., 2025), which deploys a dual-agent architecture with session-level reinforcement learning to autonomously search, analyze papers, and explore citation networks for complex queries.Despite these advancements, Beel et al. (2025) note that existing systems still heavily rely on keyword-based matching, often retrieving classic but potentially outdated papers, highlighting the need for more context-aware retrieval strategies.</p>
<p>Knowledge Retrieval and Summarization</p>
<p>Based on the well-processed literature, knowledge retrieval and summarization methods aim to derive knowledge from both structured and unstructured data.This line of work primarily consists of two parts: (1) idea-oriented approaches, which extract key concepts and insights from research papers, and (2) experimentoriented approaches, which retrieve experimental results and summarize them into comprehensive reports.LLMs play a pivotal role in this stage by processing and organizing valuable knowledge from the literature.</p>
<p>Idea-oriented approaches utilize LLMs to extract key concepts and insights from scientific documents.These methods can be classified into several categories: (1) Direct prompting serves as a foundational approach, in which the LLM-based task execution is directly guided by explicit prompt instructions.However, due to constraints such as context length and retrieval accuracy, these approaches are rarely adopted and typically serve as the baseline methods (Dagdelen et al., 2024, Gupta et al., 2024, Yao et al., 2025).</p>
<p>(2) Literature structure-based methods leverage the inherent organization of scientific documents or predefined plans based on paper structures (e.g., abstract, introduction, and conclusion (AIC)) (Sharma et al., 2019, Cachola et al., 2020b, Takeshita et al., 2022).(3) RAG-based methods enhance the summarization ability of LLM by first retrieving relevant external information and then using it as context for generation, aiming for more factual and timely outputs (Ali et al., 2024, Agarwal et al., 2024b).For instance, LitLLM (Agarwal et al., 2024a) utilizes RAG for both literature searching and knowledge retrieval.(4) Multi-agent-based methods involve the collaboration of multi-agent systems to generate literature reviews.For example, Schmidgall and Moor (2025) integrate multiple LLMs to accelerate the process of knowledge retrieval and summarization.</p>
<p>Experiment-oriented methods involve extracting experimental results from scientific documents and summarizing them into comprehensive reports.LLMs play a pivotal role in this process by analyzing structured data, interpreting experimental designs, and generating comprehensive summaries.However, this task is complicated by the need for precise extraction of Task-Model-Dataset triples and the dynamic nature of research benchmarks.For example, the LEGO-bench (Singh et al., 2024) Wu et al. (2025) propose Leader Auto Generation (LAG), which implements a comprehensive four-stage process for dynamic leaderboard generation, encompassing table retrieval, data integration, leaderboard generation, and quality-based selection of the most effective leaderboards.</p>
<p>Evaluation</p>
<p>Evaluation benchmarks play a crucial role in assessing the capabilities of AI scientist systems in knowledge acquisition.These benchmarks focus on different facets, ranging from information retrieval accuracy and summarization quality to knowledge structure generation.</p>
<p>Classical scientific summarization.The early evaluation of knowledge acquisition capability derives from works of literature summarization (Cachola et al., 2020b, Takeshita et al., 2022).Including more than 5400 summaries for scientific papers, SCITLDR (Cachola et al., 2020b) requires models to output extremely compressed summarizations of scientific papers.Following the same format as SCITLDR, X-SCITLDR (Cachola et al., 2020b) is a multilingual dataset that tests the effectiveness of different cross-lingual summarization strategies.These benchmarks only utilize parts of the original scientific papers (e.g., abstract) as testing items, thus aiming at models with relatively shorter context windows.</p>
<p>Literature retrieval.Beyond summarization, another critical dimension of knowledge acquisition evaluation lies in a model's ability to retrieve relevant scientific literature.CiteME (Press et al., 2024) is a recent benchmark focusing on evaluating LLM-based scientific agents by identifying whether they can cite the correct papers based on given context.LitSearch (Ajith et al., 2024) is another benchmark that assesses the ability of scientific literature retrieval systems, containing 597 manually curated queries and 64k+ papers to test the ability of complex query comprehension and relevant document location.</p>
<p>Idea Generation</p>
<p>Definition: The idea generation capability of an AI scientist lies in its capability to autonomously formulate innovative and feasible scientific hypotheses based on acquired knowledge and existing methods.This capability distinguishes AI scientist systems from automated scientific tools.</p>
<p>In the traditional human-centric research paradigm, researchers are responsible for formulating ideas to be tested, while AI handles labor-intensive tasks such as idea implementation and refinement.In this paradigm, AI is regarded as an automated tool, rather than a principal actor in scientific research.The emergence of LLMs marks a shift, as AI can now autonomously retrieve, review, and comprehend domain-specific knowledge from vast bodies of scientific literature (Section 2).As a result, an increasing number of efforts are being devoted to developing AI scientist systems capable of autonomously generating innovative and feasible hypotheses at scale (Hu et al., 2024, Lu et al., 2024, Si et al., 2024, Weng et al., 2025).In this new paradigm, AI scientist systems, distinguished from automated scientific tools, become the core drivers of scientific research, responsible for proposing novel hypotheses, while humans or automated experimental tools act as the executors of these hypotheses.</p>
<p>Methods</p>
<p>A classic formalization of idea generation dates back to Swanson (1986), who proposed the "ABC" model: two concepts, A and C, are hypothesized to be linked if they both co-occur with some intermediate concept B in the literature.Inspired by this work, subsequent studies have adopted graph models (Wang et al., 2019, Sybrandt et al., 2020, Youn et al., 2022) or word vectors (Tshitoyan et al., 2019) to generate scientific hypotheses by identifying links between concept pairs.However, transforming complex scientific ideas into concept links in binary form not only constrains the input type but also significantly limits the expressivity of the generated hypotheses (Moreau et al., 2021, Wang et al., 2024b).</p>
<p>In recent years, the rapid advancement of LLMs has opened up new possibilities for researchers across various fields to explore how to enable LLMs to generate innovative scientific hypotheses in the form of natural language, through specialized prompting strategies (Li et al., 2024b, Hu et al., 2024, Lu et al., 2024, Yamada et al., 2025, Jansen et al., 2025), post-training methods (Qi et al., 2023, Wang et al., 2024b, Weng et al., 2025), or multi-agent collaboration (Liu et al., 2024, Yang et al., 2024, 2025b, Gottweis et al., 2025).</p>
<p>For instance, drawing inspiration from how humans conduct research, Li et al. (2024b) propose the Chainof-Ideas (CoI) agent.This LLM-based agent organizes relevant literature into a chain structure, effectively reflecting the progressive development of a research domain and enabling the generation of high-quality hypotheses grounded in existing literature.Building on the importance of retrieval, Si et al. ( 2024) employ an LLM agent that incorporates retrieval augmentation and leverages recent advances in inference-time scaling.They prompt the LLM to generate 4,000 seed ideas for each research topic and use a reranker to select the highest-quality hypotheses.Another notable line of work focuses on post-training optimization.</p>
<p>For instance, Wang et al. (2024b) introduce SCIMON, a framework designed to generate natural language hypotheses based on background contexts dynamically retrieved from scientific literature.SCIMON further fine-tunes T5 models (Raffel et al., 2020) using both an in-context contrastive objective and a language modeling objective, and then explicitly optimizing the generated hypotheses for novelty through an iterative process.Meanwhile, A I Sc i e n t i s t (Lu et al., 2024) employs multiple rounds of chain-of-thought (Wei et al., 2022) and self-reflection (Shinn et al., 2023) to refine and develop each hypothesis.Beyond individual agents, collaborative multi-agent systems have also demonstrated promise.For example, Yang et al. (2025b) develop MOOSE-CHEM, an LLM-based multi-agent framework that operates in three stages: (1) Searching chemistry literature for inspiration papers, (2) using these inspirations to propose hypotheses related to the target research question, and (3) identifying and ranking high-quality hypotheses.</p>
<p>Evaluation</p>
<p>Table 1: Commonly-used evaluation criteria for AI-generated scientific hypotheses.</p>
<p>Criterion Description</p>
<p>Novelty</p>
<p>Whether the hypothesis is creative, distinct from existing work on the topic, and offers fresh insights.</p>
<p>Feasibility</p>
<p>How practical and achievable the hypothesis is as the basis for a research project.</p>
<p>Clarity</p>
<p>Whether the hypothesis is clearly stated and easy to understand.</p>
<p>Excitement</p>
<p>The potential excitement and impact the hypothesis could generate if pursued as a full research endeavor.</p>
<p>Evaluation of the generated hypotheses is typically conducted based on multiple criteria that reflect their quality, including but not limited to: novelty, feasibility, clarity, and excitement (Si et al., 2024, Chai et al., 2024, Wang et al., 2024b, Li et al., 2024b).The detail of each criterion is presented in Table 1.Based on these evaluation criteria, researchers generally adopt two approaches to estimate the quality of AI-generated hypotheses: automated evaluation and human evaluation.Among them, automated methods (Li et al., 2024b, Yang et al., 2025b, Chai et al., 2024, Yang et al., 2024, Chai et al., 2024) usually involve employing a powerful LLM as an auto-evaluator to assess hypothesis quality.For instance, Chai et al. (2024) employ the Claude 3.5 model (Anthropic, 2024) to compare each hypothesis against the background context and research topic, ensuring it demonstrates sufficient novelty, scientific soundness, and clarity.Li et al. (2024b) propose Idea Arena, a pairwise evaluation system in which an LLM judge ranks hypotheses in pairwise comparisons and computes ELO scores for each hypothesis generation model.However, the performance of LLMs as evaluators is influenced by various factors, such as training data diversity (Shi et al., 2024), inherent model biases (Zheng et al., 2023), and evaluation uncertainty (Xie et al., 2025).</p>
<p>In contrast, human evaluations (Qi et al., 2023, Si et al., 2024, Hu et al., 2024, Wang et al., 2024b) are considered the gold standard for assessing hypotheses, as quantitative metrics often fall short.For example, Hu et al. (2024) recruit a panel of 10 experts, all holding a PhD degree or professorship to evaluate hypotheses based on novelty and overall quality.Furthermore, Si et al. ( 2024) conduct a large-scale human study that recruits 79 expert researchers to perform blind reviews of 49 ideas from each of three conditions: expert-written ideas, AI-generated ideas, and AI-generated ideas re-ranked by a human expert.They find that LLM-generated ideas are rated as more novel (p &lt; 0.05) than those written by human experts, although they are considered slightly less feasible.Additionally, some studies also utilize reference-based text generation metrics to evaluate hypothesis quality.For example, Qi et al. (2023) employ BLEU (Papineni et al., 2002) and ROUGE (Lin, 2004) scores to measure word overlap between generated outputs and ground truth references.Yang et al. (2025b) adopt the Matched Score, which calculates the similarity between a generated hypothesis and the original hypothesis using a 6-point Likert scale.</p>
<p>It is worth noting that most existing approaches to evaluating the feasibility of an AI-generated hypothesis still heavily rely on human intuition and subjective estimation based on textual descriptions.While this method can efficiently filter out obviously infeasible hypotheses, it lacks accuracy and objectivity (Krishna et al., 2023, Karpinska et al., 2021).Therefore, assessing the feasibility of a hypothesis also requires practical methods (e.g., transforming the hypothesis into executable code) to enable empirical validation and falsification.In this survey, we categorize the ability to design experiments to validate new scientific hypotheses as a more advanced form of verification and falsification, which we discuss in detail in Section 4.</p>
<p>Verification and Falsification</p>
<p>Definition: This capability allows an AI Scientist to systematically design, implement, and analyze experiments to verify and falsify the AI-generated scientific hypotheses.Crucially, the verification and falsification capability is what completes the research cycle, transforming the AI Scientist from an idea generator into an autonomous scientific intelligence.</p>
<p>While AI systems show growing proficiency in generating scientific hypotheses, concerns persist about their reliability and true scientific merit.As noted in Section 3, current assessments of these AI-generated hypotheses, especially regarding their feasibility, rely heavily on subjective human evaluations or superficial text-similarity metrics.These approaches fundamentally lack the empirical rigor that only practical experimental validation can provide, which underscores the indispensable role of verification and falsification capabilities.The capability to actively test and validate hypotheses (verification) and rigorously challenge them (falsification) in simulated or real environments is the crucial component that defines a complete AI Scientist capable of closed-loop scientific discovery.Traditionally, scientific verification requires human scientists to design, implement, and analyze experiments (Popper, 2005, Kuhn, 2014).In recent times, with the rapid advancement of LLMs and automated experimental tools (e.g., AlphaFold (Jumper et al., 2021)), the capability for AI Scientist systems to verify and falsify scientific hypotheses has seen significant development, evolving from early methods centered on tasks like direct code execution and result matching towards more sophisticated, comprehensive processes.For instance, the AI Scientist (Lu et al., 2024) designs and executes experiments with automatic code generation and error correction, enabling fully automated open-ended scientific discovery.</p>
<p>However, the verification and falsification process remains a significant endeavor for current AI Scientist systems.A statistical analysis of AI Scientist papers on arXiv up to May 23, 2025, reveals the challenges and community valuation related to verification and falsification.As illustrated in Figure 3, while the overall number of publications in this domain is increasing, studies that primarily focus on idea generation without providing concrete implementation details consistently outnumber those that incorporate such implementations.Despite this disparity in publication volume, the upper panel of Figure 3 further highlights a crucial counterpoint: papers that include substantive implementation details achieve a significantly higher average number of citations, demonstrating a strong valuation within the AI Scientist community for executable verifications.</p>
<p>Methods</p>
<p>The ultimate goal of verification and falsification is primarily based on designing, implementing, and analyzing experiments to assess whether the AI-generated hypotheses are feasible.However, considering the different limitations of experiments in different scientific fields (e.g., chemistry, biology, and medicine), such as venue, equipment, and experimental safety, currently AI scientist systems focus mainly on idea verification and falsification in the field of computer science, especially in machine learning.</p>
<p>For experimental design, the AI Scientist field has seen several innovative approaches.BioPlanner (Liu and Shah, 2023) introduces an automated evaluation framework for assessing LLMs' ability to plan experiments in the biology domain.DSBench (Jing et al., 2025) and ScienceAgentBench (Chen et al., 2024) assess agents' capabilities in experimental design for data-driven scientific discovery.Yang et al. (2023) is the first work to employ an LLM as a "masterbrain scientist" (akin to a principal investigator), taking on the central role and steering a fully closed-loop research.Subsequent AI Scientist systems, such as A I Sc i e n t i s t (Lu et al., 2024) further utilize LLM agents to autonomously propose research ideas, formulate testable hypotheses, and design high-level experimental plans.These plans typically include defining variables, selecting datasets, choosing baseline models, and outlining evaluation metrics.However, the diversity and complexity of scientific experimental design present significant challenges for current AI Scientist systems.Experimental designs generated by these AI Scientist systems often lack scientific rigor, innovation, and practicality, making it difficult to meet the demands of high-level research (Huang et al., 2025a, Weng et al., 2025).</p>
<p>Implementation, theoretically the most important and difficult part of experiments, is often addressed through repository-level code generation.For instance, LLM-based methods such as ToolGen (Wang et al., 2024a), propose an approach that integrates auto-completion tools to generate repository-level code with reliable dependencies.CoCoGen (Bi et al., 2024) iteratively aligns and fixes errors using information extracted from the code repository.CatCoder (Pan et al., 2024b) enhances repository-level code generation by integrating relevant code and type context.Agent-based methods have showcased even more powerful performance.CodeAgent (Zhang et al., 2024a) integrates five programming tools, enabling interaction with software artifacts for information retrieval, code symbol navigation, and code testing.RepoCoder (Zhang et al., 2023) streamlines the repository-level code completion process by incorporating a similarity-based retriever and a pre-trained code language model in an iterative retrieval-generation pipeline.More closely related to real-life scenarios, RepoGraph (Ouyang et al., 2024) operates at the line level, offering a more fine-grained approach compared to previous file-level browsing methods.Each node in the graph represents a line of code, and edges represent the dependencies of code definitions and references.RepoGraph boosts the success rate of existing methods by achieving an average relative improvement of 32.8% on SWE-bench (Jimenez et al., 2023).SciCode (Tian et al., 2024) decomposes the generation of scientific repository-level code into multiple sub-problems, each involving knowledge recall, reasoning, and code synthesis.AIDE (Jiang et al., 2025) formalizes machine learning research as a code optimization problem, and formulates trial-and-error as a tree search in the space of potential solutions.MLR-Copilot (Li et al., 2024c) further proposes an ExperimentAgent to translate experiment plans into executable experimental code, crucially incorporating human feedback and iterative debugging mechanisms to manage the complexities of execution.In pursuit of greater autonomy, Lin et al. (2025) propose AutoP2C, an LLM-based multi-agent framework that processes both textual and visual content from research papers to automatically generate executable code repositories.These ongoing developments underscore a persistent drive to overcome the inherent difficulties in scientific implementation through increasingly sophisticated methods.</p>
<p>papers.For instance, MLE-Bench (Chan et al., 2024) assesses the ability to solve Kaggle machine learning tasks, where OpenAI's "o1-preview" achieved only 16.90% medal-worthy success.PaperBench (Starace et al., 2025) requires the replication of ICML research papers from scratch, on which OpenAI's "o1-high" manages a 26.00% replication score.Further evidence of these challenges is found in SciReplicate-Bench (Xiang et al., 2025), a benchmark focusing on generating executable code from algorithm descriptions (Claude-Sonnet-3.7 reaches only 39.00% execution accuracy); CORE-Bench (Siegel et al., 2024), involving the reproduction of computational results from scientific papers across diverse fields (OpenAI's GPT-4o achieving 55.56% accuracy on medium difficulty tasks); and ML-Dev-Bench (Padigela et al., 2025), which evaluates performance on diverse machine learning development workflow tasks (Claude-Sonnet-3.5 shows a 50.00% success rate).These evaluations consistently demonstrate that LLMs face significant difficulty in translating conceptual understanding or initial plans into verifiably correct and operational code, highlighting a fundamental limitation in their verification capabilities and underscoring the importance of systematic verification and implementation capabilities for the maturation of AI Scientist systems.</p>
<p>Review System</p>
<p>Definition: An AI reviewer system comprehensively assesses the generated manuscripts to provide insightful reviews, aiming to enhance the quality of the scientific artifact produced by AI Scientist systems.</p>
<p>Peer review is essential for refining scientific work, but traditional systems face significant challenges especially in fast-evolving fields like computer science, where new results can become outdated before they are published.At the same time, the peer review system depends on a limited number of reviewers who are often overwhelmed by the high volume of submissions, which leads to delays, biases, inconsistencies, and sometimes unfair outcomes (Stelmakh et al., 2020, Zhang et al., 2022, Fox et al., 2023).To address these problems, researchers are actively exploring the use of AI systems to support scientific reviewing throughout the peer review life-cycle.Broadly speaking, the development of AI reviewer systems can be divided into two phases, marked by the emergence of LLMs: (1) Pre-LLM phase: Earlier AI reviewer systems primarily focused on automating reviewer-paper matching based on content analysis and reviewer expertise (Charlin and Zemel, 2013, Stelmakh et al., 2019, Stelmakh, 2021).These systems also handle screening and pre-check processes, such as verifying compliance with submission guidelines, plagiarism, and anonymity checks (Goldberg et al., 2024a, Lee et al., 2025).</p>
<p>(2) LLM-based AI reviewer system: With the advent of LLMs, the capabilities of AI reviewers have expanded dramatically.A key advancement is the ability to automatically generate detailed, structured reviews.These reviews typically include summaries, assessments of strengths and weaknesses, and constructive feedback, which aim to make the review process more efficient and equitable, ultimately enhancing both the speed and quality of scientific evaluation (Wang et al., 2020, Idahl and Ahmadi, 2024, Tyser et al., 2024, Pendyala et al., 2025, Zhu et al., 2025).</p>
<p>Methods</p>
<p>Different technologies for AI reviewer systems have been developed to handle specific parts of the review process.These methods range from simple tasks, such as screening and classifying submissions (Wang et al., 2024c, Cao et al., 2024, Jaumann et al., 2025), to more complex tasks, including writing review comments, simulating reviewer discussions, and reasoning about a paper's content (Peng et al., 2024, Su et al., 2025,  Sun et al., 2024, Zhou et al., 2025a, Zhu et al., 2025, Jin et al., 2024).We classify these methods based on their underlying paradigms and the complexity of the tasks they address (Figure 4).</p>
<p>Classification-and scoring-based AI reviewer systems primarily focus on evaluating academic papers to assign quantitative scores against predefined criteria (Zhu et al., 2025), classifying them based on specific attributes (e.g., relevance to a conference (Leyton-Brown et al., 2024)), or screening literature for inclusion in systematic reviews (Joos et al., 2024).These systems often target specific, measurable aspects of an academic paper rather than generating holistic reviews (Wang et al., 2024d, Liang et al., 2025).For example, ReviewRobot (Wang et al., 2020) employs a knowledge graph-based framework to predict review scores and generate structured evidence, emphasizing explainability.Its performance in score prediction reaches 71.4% accuracy, with a significant portion of its generated comments deemed valid and constructive by human experts.Similarly, RelevAI-Reviewer (Couto et al., 2024) conceptualizes survey paper review as a classification task, benchmarking AI's ability to assess relevance using a dataset of over 25,000 instances.In terms of empirical experiment, the NeurIPS 2024 committee employed LLMs to systematically categorize submitted papers and check them against a standardized checklist (Goldberg et al., 2024b).Over 70% of authors found the system useful, and 70% made substantial revisions based on the detailed feedback.</p>
<p>Generation-based AI reviewer systems are designed to produce academic reviews in natural language, mirroring the narrative outputs of human reviewers.For example, Reviewer2 (Gao et al., 2024) introduces a two-stage framework that first models the distribution of potential review aspects and then generates prompts to guide an LLM in producing detailed academic reviews.OpenReviewer (Tyser et al., 2024), a specialized 8-billion parameter LLM fine-tuned on 79,000 expert reviews, processes PDF submissions to generate structured reviews adhering to conference guidelines, notably producing more "critical and realistic reviews" than general-purpose LLMs like GPT-4.Another automated method described in (Wu et al., 2024) uses LLMs to analyze papers, extract key information, and generate insights with quality control measures to mitigate hallucination, reportedly matching manual review quality in a case study.Furthermore, CycleReviewer (Weng et al., 2025) provides a suite of specially trained LLMs to generate expert-level opinions and evaluation scores, achieving a 26.89% reduction in MAE for score prediction compared to individual human reviewers.The critical challenge for these systems lies in moving beyond fluent text generation to provide genuinely insightful and constructive criticism, avoiding the tendency towards overly positive or superficial assessments (Shojaee et al., 2025, Laskar et al., 2024).</p>
<p>Multi-agent AI reviewer systems.Given that peer review is inherently a collaborative process (Miyao, 2019, Beygelzimer et al., 2023), researchers have begun exploring AI reviewer systems based on multiagent frameworks.These systems typically employ multiple interacting AI agents with distinct roles (e.g., meta-reviewer, area chair) to simulate discussions, thereby producing more comprehensive and nuanced reviews.For example, AgentReview (Jin et al., 2024) uses LLM agents to investigate review dynamics and latent biases; ReviewAgents (Gao et al., 2025) proposes a multi-role framework to emulate human reasoning processes; and MARG (D'Arcy et al., 2024) distributes the paper among specialized agents to improve feedback quality.Taking this collaborative structure further, the current frontier of such systems is to replicate deeper human cognitive processes through advanced reasoning and emulation.This involves incorporating multi-stage reasoning, structured analytical frameworks, and evidence-based argumentation to approximate the critical depth achieved by human experts.A prime example is the DeepReviewer framework (Zhu et al., 2025), which uses multi-stage thinking processes (Analysis, Argument, Assessment) and has demonstrated strong performance and resilience (Ye et al., 2024).Similarly, A I Sc i e n t i s t (Lu et al., 2024) employs multi-round reflections to evaluate papers.By combining multi-agent structures with advanced cognitive emulation, these systems are moving toward a "glass box" approach in which the AI's deliberative process is more discernible and verifiable, serving as an essential step for building trust in high-stakes academic  (Zhu et al., 2025) across the number ("Num") of available papers.The "Percentile" column shows each system's relative quality ranking.Note: Publicly available papers may be curated and therefore may not fully represent the typical output of each system.</p>
<p>AI Scientist Systems Number Soundness Presentation Contribution Rating Percentile</p>
<p>A I Sc i e n t i st (Lu et  assessment.</p>
<p>Evaluation Benchmarks</p>
<p>The advancement and rigorous assessment of AI reviewer systems fundamentally rely on the availability of appropriate datasets and benchmarks.These resources (Choudhary et al., 2021, Li et al., 2022, Guo et al., 2023, Purkayastha et al., 2023, Bharti et al., 2024, D'Arcy et al., 2024, Zhou et al., 2024b, Lou et al., 2025) serve as both the training ground for evaluation models and the standard against which their capabilities are measured (Zhuang et al., 2025).Early datasets are often collected from conference or journal review records (Lin et al., 2022, Zeng et al., 2023, Zhou et al., 2024a).As the field grows, researchers begin creating more specialized resources to reflect the different tasks involved in peer review.This includes resources specifically curated for assessing relevance determination (Couto et al., 2024), question-answering abilities (Baumgärtner et al., 2025), the generation of aspect-guided (Gao et al., 2024) or weakness-focused feedback (Chamoun et al., 2024), and even the crucial task of detecting AI-generated reviews (Yu et al., 2025, Weng et al., 2025).Table 3 summarizes information on key datasets and benchmarks for AI Reviewer Evaluation, providing a snapshot of the resources available.While pioneering AI Scientist systems (Yamada et al., 2025, Intology, 2025) demonstrate capabilities such as generating workshop-accepted manuscripts, we conduct a rigorous evaluation that reveals their persistent deficiencies in scientific rigor.To quantify these gaps, we employ DeepReviewer-14B (Zhu et al., 2025), an advanced AI reviewer model, to assess 28 publicly available research papers produced by 5 leading AI Scientist systems.Though public availability may bias toward higher-quality outputs, this analysis exposes systemic limitations in current autonomous research.The evaluation results are summarized in Table 4, painting a concerning picture: the highest-rated system achieves an average rating of only 4.63 out of 10, with most sys-tems scoring considerably lower.These low scores reflect poor performance across key metrics, including soundness, presentation, and contribution.Furthermore, the evaluation results identify twelve major defect categories present in the assessed papers (Table 5), with "Experimental Weakness" appearing in 100% of the papers.This universal deficiency highlights severe limitations in the current implementation capabilities of AI scientist systems, particularly regarding experimental design, execution, and result analysis.</p>
<p>Current AI Scientist Systems Are Not Good Enough</p>
<p>Other prevalent issues includes "Methodological Unclarity/Flaws" (96.4%), "Writing &amp; Presentation Issues" (92.9%), and "Novelty Concerns" (89.3%).These findings suggest that current AI Scientist systems not only struggle with scientific execution but also stuck with clearly articulating their research findings.The high incidence of "Theoretical Weakness" (85.7%), and "Literature Review Deficiencies" (78.6%) further indicates that these systems often fail to offer genuinely original contributions or ground their claims in robust theoretical frameworks.These evaluation results align with the low quantitative scores presented in Table 4, clearly demonstrating that current AI scientist systems, despite their technological sophistication, cannot independently produce scientific artifacts that meet established standards for high-quality scientific communication.These findings strongly suggest that current AI-generated research often lacks the depth, rigor, and implementation quality expected in meaningful autonomous research and credible scientific contributions.Addressing these limitations through evolutionary mechanisms becomes necessary for advancing AI Scientist systems toward their full potential as autonomous scientific agents.</p>
<p>Evolution</p>
<p>Definition: Evolution is the capability to continuously advance overall research abilities based on feedback from internal reflection or external inputs. This capability involves the dynamic planning</p>
<p>for research directions and the autonomous learning for improvement, serving as the pathway for an elementary AI Scientist to evolve into a mature scientific agent.</p>
<p>Several influential works have already emerged in the field of AI Scientists (Lu et al., 2024, Weng et al., 2025, Intology, 2025, Yamada et al., 2025).For instance, A I Sc i e n t i s t -v 2 (Yamada et al., 2025) is capable of autonomously generating manuscripts that successfully pass peer review at workshops of major machine learning conferences.Despite this substantial progress, extensive quantitative evidence (Tables 2,  4, 5) indicates that systemic issues remain in the scientific rigor and implementation quality of current AI-generated research, and there is still a considerable gap before AI Scientists are able to make groundbreaking discoveries that solve grand challenges across medicine, energy, and the environment, thereby changing the world and reshaping the scientific research paradigm.We attribute this gap to (1) the inherent limitations of the foundation models (i.e., LLMs) that underlie AI Scientists, and (2) the inadequate scientific research abilities of current AI Scientists, such as generating hypotheses with low feasibility, employing incorrect validation methods, and having limited ability to understand and decompose complex research tasks.A more detailed discussion of this gap is deferred to Section 7.</p>
<p>Through continuous evolution, an elementary AI Scientist can progressively bridge this gap and gradually approach the capabilities of a mature scientific agent.Specifically, evolutionary mechanisms enable AI Scientists to transcend the static confines of their initial foundation models and refine their research abilities through iterative feedback and interaction with both human experts and dynamic scientific environments, thereby advancing toward the long-term vision of autonomous, reliable, and innovative scientific discovery.In this section, we focus on discussing the key technologies required for evolution capability, including strategies for dynamic planning of research directions and methods for autonomous learning (Schmidhuber, 2007).These foundational technologies are essential for closing the gap that still separates current AI Scientist systems from making transformative discoveries.</p>
<p>Methods</p>
<p>Currently, most research in the field of AI Scientist focuses on the evolution of individual scientific artifacts (such as a scientific hypothesis or an experimental code implementation), rather than on managing longterm research cycles with comprehensive planning and iteration.In this section, we primarily summarize how existing AI Scientist systems approach evolution by reviewing their approaches to planning evolution paths (Section 6.1.1)and employing autonomous improvement (Section 6.1.2).The discussion of long-cycle research iteration and comprehensive planning is deferred to Section 8.</p>
<p>Dynamic Planning</p>
<p>The dynamic planning capability aims to explore the most valuable research directions within a constrained search space, enabling an AI Scientist to efficiently allocate resources, prioritize hypotheses, and adaptively refine research trajectories based on ongoing results and feedback.Currently, in the field of AI Scientist, dynamic planning remains relatively underdeveloped, leaving a few cutting-edge studies employing treesearch strategies with LLMs to enable structured exploration of diverse scientific hypotheses (Intology, 2025) and detailed experimental plans (Jansen et al., 2024, Yamada et al., 2025, Yuan et al., 2025).For instance, when given a broad research domain, Zochi (Intology, 2025) conducts a comprehensive process of exploration and refinement process, where it generates multiple candidate hypotheses, designs experiments to test them, and iteratively improves its strategy based on the results.In A I Sc i e n t i s t -v 2, Yamada et al. (2025) introduce an experiment manager agent in combination with a novel agentic tree-search algorithm to generate and refine code implementations.Subsequent experiments leverage the top-performing code checkpoints from the tree search to iteratively evaluate various research hypotheses.Although these approaches enable the discovery of higher-quality scientific hypotheses and experimental designs, they still face challenges such as increased complexity, greater computational cost, and limited scalability (Jansen et al., 2025).</p>
<p>Autonomous Learning</p>
<p>Various autonomous learning strategies have been employed to continuously enhance the overall research capabilities of the AI Scientist.These approaches can be categorized into self-reflection methods and externally guided methods, depending on the source of feedback.</p>
<p>Self-reflection methods (Lu et al., 2024, Romera-Paredes et al., 2024, Weng et al., 2025, Jansen et al., 2025, Yamada et al., 2025, Novikov et al., 2025) refer to the process where the LLM serves as its own feedback provider, iteratively evaluating and refining its outputs until a certain quality standard is met (Madaan et al., 2023, Pan et al., 2024a).This concept of continuous self-improvement has been widely adopted in LLMs to enhance downstream performance (Weng et al., 2022, Zelikman et al., 2022) and reduce harmful responses (Bai et al., 2022).Accordingly, in the field of AI Scientist, researchers have also begun employing self-reflection strategies to improve the quality of generated scientific artifacts.For example, Weng et al. (2025) propose an iterative preference training framework that consists of two components:</p>
<p>(1) CycleResearcher, which performs research tasks, and (2) CycleReviewer, which simulates the peer review process by providing iterative feedback through reinforcement learning.This entire procedure is refined iteratively, leading to progressively improved research capabilities with each cycle.DeepMind's FunSearch (Romera-Paredes et al., 2024) follows a similar evolutionary paradigm, pairing a pretrained LLM, tasked with generating creative solutions to scientific problems, with a systematic evaluator that guards against confabulations and incorrect reasoning.It iteratively samples the best-performing code programs and incorporates them into new prompts for the LLM to build upon, evolving initially low-scoring programs into high-performing ones and thereby uncovering novel insights.</p>
<p>Externally guided methods (Yuan et al., 2025, Yu et al., 2024, Schmidgall and Moor, 2025, Jansen et al., 2024).External evaluation of the AI-generated artifacts also serves as an important form of feedback.Current AI Scientist systems generally adopt two approaches: (1) incorporating human supervision during the generation process to assess the quality of hypotheses and provide brief revision suggestions (Jansen et al., 2025, Intology, 2025); (2) leveraging internet-based academic platforms (e.g., Semantic Scholar (Fricke, 2018)) to filter out hypotheses that are overly similar to existing literature, thereby ensuring novelty (Yuan et al., 2025, Lu et al., 2024, Weng et al., 2025).Beyond these methods, some efforts aim to build research communities composed entirely of AI Scientist systems, enhancing the quality of their outputs through collaboration.For example, Yu et al. (2024) introduce RESEARCHTOWN, a multi-agent framework for simulating research communities.RESEARCHTOWN models the research community as an "agent-data graph", where AI researchers and papers are represented as nodes, and activities such as reading, writing, and reviewing are implemented as message-passing operations within a TextGNN inference framework.</p>
<p>Similarly, WestlakeNLP (2025) establish AiraXiv, a centralized platform that archives scientific artifacts generated by AI Scientist systems, allowing them to collaborate, share insights, and iteratively build upon each other's work.However, the field currently lacks a specialized protocol for scientist-to-scientist communication to enable more efficient and structured interactions among AI scientist systems.Such a protocol could standardize interaction workflows and define communication formats, ultimately facilitating effective collaboration and information exchange between AI Scientist systems.Hence, developing a specialized communication protocol for AI Scientist systems represents a key future direction for advancing automatic scientific discoveries (see Section 8 for further discussion).</p>
<p>Discussion</p>
<p>Positioning of This Survey</p>
<p>Although previous surveys have provided valuable overviews of LLM architectures, agentic frameworks, and scientific automation tools for automatic scientific discovery (Zhang et al., 2024b, Zheng et al., 2025, Ren et al., 2025, Zhou et al., 2025b, Goyal, 2025, Luo et al., 2025), there remains a critical gap: a capabilitybased roadmap that comprehensively charts the path toward the ideal AI scientist.Our survey addresses this gap by introducing a capability-level framework (Figure 1) that systematically defines the stages of AI scientist development, establishing clear benchmarks for the next era of AI-driven scientific discovery.We critically analyze current research through the lens of this capability framework, identifying key bottlenecks and missing components necessary for the emergence of ideal scientific agents.The difference between our survey and existing survey papers is shown in Table 6.</p>
<p>Limitations of Current AI Scientists in Scientific Discovery</p>
<p>Despite the substantial progress in the field of AI Scientist systems, there is still a considerable gap before AI Scientist can mature into scientific agents capable of making ground-breaking discoveries, thus changing the world and reshaping the scientific research paradigm.This persistent gap can be attributed to several critical factors.First, the inherent limitations of the foundation models (i.e., LLMs) that underpin AI Scientist systems pose significant barriers.These models, while demonstrating impressive capabilities in language understanding and generation, often lack the depth of domain expertise, capacity for scientific reasoning, and nuanced judgment required for high-impact scientific breakthroughs.Their outputs are constrained by the knowledge encoded in their training data, which may be outdated, incomplete, or not fully aligned with the latest advancements in the scientific community.Second, current AI Scientist systems exhibit inadequate scientific research abilities in several key aspects.For instance, they may generate hypotheses that lack feasibility or novelty, apply inappropriate or insufficient validation methods, and struggle with the deep comprehension and decomposition of complex research problems.These shortcomings not only limit the reliability of AI-generated scientific artifacts but also hinder the AI Scientist systems' abilities to independently advance the frontiers of science.</p>
<p>Fundamental Limitations of Base Models</p>
<p>Despite their remarkable progress, LLMs that serve as the foundation for AI Scientist systems exhibit several intrinsic limitations, including hallucinations, high costs and inefficiencies in knowledge updating, and catastrophic forgetting.These challenges critically constrain the scientific utility and reliability of current AI Scientist systems, making it crucial to address them for the advancement of AI-driven scientific research.</p>
<p>Hallucination.In scientific research, precision, factual accuracy, and reliability are paramount.However, LLMs are prone to "hallucination", a phenomenon where the model generates plausible-sounding but false or unverifiable content (Huang et al., 2025b, Zhang et al., 2025).This can manifest in several ways: (1) The model may fabricate research findings, experimental data, references, or even entirely non-existent theories, presenting them as factually correct.</p>
<p>(2) AI-generated citations, data, and formulas are often unreliable or improperly sourced, making it difficult for human researchers to trace and verify the origin and validity Catastrophic Forgetting.Another fundamental challenge is catastrophic forgetting, which is the tendency of neural networks to lose previously acquired information when trained on new data (Kirkpatrick et al., 2017).</p>
<p>For an AI Scientist, this challenge means that attempts to update the model with new scientific knowledge may inadvertently overwrite or degrade its understanding of existing scientific concepts, methods, and facts.Such instability undermines the system's ability to maintain a comprehensive and coherent body of scientific knowledge over time.As a result, integrating findings across different periods and scientific fields becomes particularly challenging, which in turn impairs the LLM-based AI Scientist systems' capacities to perform longitudinal analyses, connect historical insights with emerging discoveries, and deliver consistent, reliable support for complex scientific explorations.</p>
<p>Limitations of Research Capabilities of AI Scientist Systems</p>
<p>The research capabilities of current AI Scientist systems remain limited in several crucial aspects.These limitations not only restrict their effectiveness in supporting and automating scientific research but also constrain their potential to independently drive significant scientific breakthroughs.Below, we discuss core capability gaps through the lens of the proposed capability framework (Figure 1).</p>
<p>Knowledge acquisition.</p>
<p>The ability to acquire, organize, and internalize knowledge from the vast and rapidly expanding body of scientific literature is the fundamental capability for an AI Scientist.This includes not only searching for and retrieving relevant papers and results, but also extracting core ideas, incorporating experimental details, and integrating disparate findings into a coherent understanding.However, existing AI Scientist systems face several substantial challenges in this area, including:</p>
<p>(1) Precision in information retrieval.The enormous scale and diversity of scientific literature make it difficult for current AI Scientist systems to accurately retrieve the most relevant and up-to-date information for a given research problem (Landhuis, 2016).They often struggle with the precise interpretation of complex or ambiguous queries, effective filtering of highly relevant documents, and ensuring that the results remain timely and reliable.Both precision and recall in retrieval must be further improved to meet scientific standards.</p>
<p>(2) Multi-document summarization and synthesis.Generating accurate and comprehensive literature reviews requires not only retrieving multiple relevant documents, but also synthesizing information across sources, resolving inconsistencies, and generating faithful summaries (Agarwal et al., 2024a).Recent approaches, such as RAG and plan-based summarization, have made progress in this area.However, studies have shown that LLMs are still prone to misquoting or distorting source materials (Agarwal et al., 2024b), indicating persistent challenges in semantic understanding, information integration, and factual accuracy when summarizing scientific knowledge from multiple documents.</p>
<p>Idea generation.One of the most critical aspects of scientific research is the generation of novel and feasible scientific hypotheses.Despite notable advancements, the idea generation capability remains significantly constrained by several limitations: (1) Difficulty in generating high-quality hypotheses.Generating scientific hypotheses that are not only novel but also feasible is a complex task that requires a deep understanding of both existing knowledge and the ability to identify innovative connections.However, empirical evidence suggests that current AI Scientist systems often fall short in this regard.Specifically, the ideas produced by these models tend to lack true originality and are frequently repetitive across different runs or even across different models (Lu et al., 2024).The underlying cause of this phenomenon is twofold: First, LLMs are fundamentally limited by their training data, which constrains their ability to move beyond well-trodden conceptual ground.Second, without advanced mechanisms for knowledge integration or creativity, AI Scientist systems tend to rely heavily on superficial text correlations, rather than generating ideas with genuine scientific novelty.This not only leads to repetitive outputs but also limits the potential for breakthrough discoveries.</p>
<p>(2) Challenges in evaluating the quality of AI-generated scientific hypotheses.A further limitation arises from the challenge of reliably assessing the quality and potential impact of AI-generated scientific hypotheses.Unlike standardized tasks with clear evaluation criteria, the value of a scientific hypothesis is often subjective, context-dependent, and difficult to quantify.Current evaluation methods rely heavily on human expert judgment, which is not only resource-intensive but also susceptible to subjectivity and inconsistency.Recent attempts to introduce automated evaluators have helped to some extent, but these systems themselves inherit the biases and knowledge limitations of their underlying models.As a result, the lack of reliable, objective, and scalable evaluation frameworks for AI-generated hypotheses remains a bottleneck for the advancement of AI Scientist systems in real-world research settings.</p>
<p>Verification and falsification.</p>
<p>As discussed in Section 4, verification and falsification is a complex capability that requires rigorous verification and potential falsification of hypotheses through experiment design, execution, and validation.For AI Scientist systems, this process is both technically demanding and operationally complex, especially when considering the integration of multi-agent frameworks and collaboration with external tools or human researchers: (1) Multi-agent collaboration.In modern research environments, effective collaboration, whether with other AI agents, human scientists, or a variety of external tools, is essential for scientific progress (Guo et al., 2024, Qian et al., 2024, Pu et al., 2025).An AI Scientist should not only understand collaborative protocols and division of labor but also reliably coordinate with diverse stakeholders, execute assigned tasks, and integrate outputs back into larger research workflows (Bo et al., 2024, Zhang et al., 2024c).Current AI Scientist systems, however, still exhibit significant weaknesses in robustness, adaptability, and fault tolerance, particularly in dynamic or unpredictable environments (Wei et al., 2025).For instance, they frequently encounter difficulties when interacting with changing external APIs, handling error messages, or managing concurrent tasks, which are all crucial for real-world scientific automation (Shen et al., 2025).</p>
<p>(2) Experiment design, execution and validation.The core of the verification and falsification capability lies in experiment design, execution, and validation.However, current AI Scientist systems face multiple challenges across these stages.Firstly, their automatically generated experimental designs often lack scientific rigor, innovation, and practicality, making it difficult to satisfy the requirements of advanced research.Additionally, these systems tend to rely on static templates and a narrow set of literature, which limits their ability to incorporate the latest technological advances and experimental methodologies.Consequently, the resulting experimental plans are frequently disconnected from the research frontier and lack real-world applicability (Weng et al., 2025, Intology, 2025).Furthermore, as shown by the empirical evidence in Table 2, an AI Scientist encounters significant difficulties when translating conceptual understanding or initial plans into verifiably correct and executable code.For instance, on state-of-the-art benchmarks such as SciReplicate-Bench (Xiang et al., 2025), the best execution accuracy achieved is only 39%, which highlights a fundamental limitation in their execution and validation capabilities.</p>
<p>Evolution.The ability of an AI Scientist to continuously evolve is essential for sustained scientific innovation.However, current AI Scientist systems demonstrate notable limitations in their evolutionary capabilities, which hinder their long-term progress and adaptability: (1) Dynamic planning refers to the system's ability to adaptively explore new research directions, update hypotheses, and iteratively refine experimental strategies.Despite its importance, this capability remains underdeveloped in existing AI Scientist systems.Recent studies have introduced tree-search-based strategies.While these represent a meaningful step forward, they are still constrained by several factors: increased algorithmic complexity, substantial computational overhead, and limited scalability to large-scale scientific problems.As the number of possible research pathways grows, current methods struggle to efficiently balance exploration and exploitation, often leading to diminishing returns in both hypothesis quality and resource utilization.</p>
<p>(2) Autonomous learning.A crucial component of evolution is the ability to learn from feedback, whether derived from internal self-reflection or from external sources.However, when relying solely on self-generated feedback through internal reflection, AI Scientists are prone to "looping errors", which means that mistakes can be amplified over multiple iterations, rather than corrected or improved.Without effective mechanisms for robust self-criticism, the system may fall into cycles of compounding errors, undermining both the originality and reliability of its research output.While incorporating feedback from external sources (especially from other AI Scientist systems) holds great promise for collective intelligence, current frameworks lack standardized communication protocols for scientist-to-scientist interactions.The absence of robust collaboration mechanisms results in inefficient exchange of ideas and suboptimal integration of external criticism, making AI Scientist systems unable to fully leverage the potential of agent collaboration, thus slowing down their evolution (Wang et al., 2025).</p>
<p>Ethical Challenges</p>
<p>The emergence of AI Scientist systems has fundamentally reshaped the landscape of human research (King et al., 2009).However, as autonomous research agents, AI Scientist systems are incapable of making ethical judgments about the societal impact of their work, and they do not self-regulate based on potential risks associated with their findings (Bengio et al., 2025).In the absence of proper oversight, AI Scientist systems may present a range of ethical challenges that require systematic consideration:</p>
<p>(1) An AI Scientist may be misused, overwhelming the peer review system and leading to a decline in overall research quality.The rapid and large-scale generation of scientific artifacts by AI Scientist systems can flood existing peer review mechanisms, making it difficult for human reviewers to rigorously assess the quality of submissions.This overload risks allowing low-quality, erroneous, or redundant work to enter the scientific record, thereby undermining the standards of academic publishing and slowing scientific progress.Furthermore, the peer review process itself may be manipulated through techniques such as reward hacking, further diminishing the fairness and objectivity of scientific evaluation (Lu et al., 2024).</p>
<p>(2) An AI scientist may autonomously enter dangerous research domains, accelerating the development of harmful technologies.Without robust ethical constraints, AI Scientist systems can independently generate and publish research in sensitive areas (e.g., cybersecurity).Such uncontrolled dissemination of knowledge may accelerate the development and spread of potentially harmful scientific technologies, before adequate ethical guidelines, safety protocols, or regulatory measures can be implemented (Huang et al., 2022).</p>
<p>(3) An AI scientist may weaken the overall quality of scientific training and education, leading to a decline in research standards and scientific literacy across all levels of human researchers.The widespread use of AI Scientist systems throughout the research and education pipeline may encourage over-reliance on automated assistance for key tasks such as idea generation, experimental design, data analysis, and hypothesis testing.Over time, this dependence could erode critical thinking, creativity, and hands-on research skills, ultimately diminishing scientific literacy and widening gaps between institutions with differing levels of access to advanced AI tools (Yamada et al., 2025).</p>
<p>(4) An AI scientist may introduce security vulnerabilities and research biases in the scientific research process.For instance, AI Scientist systems may utilize verification mechanisms unfaithful to their intended design, resulting in misleading results that are difficult to detect and require substantial human oversight (Jansen et al., 2025).These issues not only waste valuable research resources but also diminish the reliability of scientific findings.In addition, an AI Scientist tends to favor research topics with abundant datasets or high potential for automation, which can incentivize funding organizations to prioritize such areas.This skews the equitable distribution of research funding and narrows the overall research landscape (Yamada et al., 2025).Well-funded institutions are more capable of leveraging AI Scientist systems, further exacerbating existing inequalities and increasing entry barriers for early-career researchers.</p>
<p>To address these risks, there is an urgent need for a comprehensive system of generation management, ethical oversight, and quality evaluation for AI Scientist systems (Jobin et al., 2019).This management system should include, but not be limited to the following components:</p>
<p>(1) A centralized platform to mitigate disruption to human review systems.This platform archives AI-generated scientific outputs and develops automated detection tools (e.g., DeepReview (Zhu et al., 2025)) to identify and filter low-quality content.All AI-generated outputs must be clearly labeled with information on their origin, generation methods, and involved scientific tools.Additionally, since authorship implies legal and ethical responsibilities that current AI systems cannot assume, AI Scientist systems must not be listed as official authors, and proper attribution of legal and ethical responsibilities must be ensured.</p>
<p>(2) Clear boundaries between human-driven and AI-driven research activities to preserve essential human training and ensure well-rounded development for all researchers.Key stages of scientific education and training (e.g., hypothesis formulation and experimental validation) should emphasize active human involvement to uphold high scientific standards.Educational institutions and research organizations should develop clear guidelines to prevent excessive dependence on AI Scientist systems at all levels, from undergraduate students to experienced researchers, ensuring that AI serves as a tool rather than a human replacement in the educational experience.</p>
<p>(3) A global convention for ethical boundaries and risk management in AI-driven research, formulating global ethics and responsibility conventions.Full disclosure of generation processes, algorithmic sources, and potential risks should be mandatory (Huang et al., 2022).In addition, a hybrid oversight framework that integrates both automated systems and human-in-the-loop review should be established to provide ongoing ethical supervision and risk assessment, thereby ensuring that the research activities of AI Scientist systems remain within socially acceptable boundaries (Jobin et al., 2019, Khan et al., 2022).</p>
<p>Future Directions</p>
<p>In the previous sections, we reviewed the current achievements of AI Scientist systems (Section 2 -Section 6) and analyzed their limitations (Section 7) from two perspectives (deficiencies in foundation models and inadequacies in research capabilities), highlighting where we currently stand and what remains lacking.</p>
<p>In this section, we first outline potential directions to bridge the existing gaps in AI Scientist systems and discuss feasible pathways for their future development.</p>
<p>Potential Directions to Bridge the Current Gap</p>
<p>By systematically addressing foundational limitations, managing long-term research endeavors comprehensively, and developing robust communication protocols, future AI Scientist systems can progressively bridge existing gaps and realize their full potential as transformative agents in scientific discovery.</p>
<p>The Pathway of AI Scientist</p>
<p>Unlike human scientists, AI Scientist systems evolve through a self-organizing progression that could be more distinct and efficient than human approaches.While human scientists accumulate knowledge through periods of formal education, hands-on experiments, and ethical training, AI Scientist systems progress by integrating specialized modules, such as LLMs, simulation engines, and robotic systems.This modular approach positions the development of AI Scientists closer to system engineering, facilitating rapid enhancements in research capabilities and enabling significant efficiency gains in scientific endeavors.Furthermore, forcing AI Scientists to replicate human developmental paths might constrain their potential.AI systems excel in rapidly processing and analyzing extensive datasets, enabling them to identify research problems and formulate solutions within significantly shorter timescales.Hence, development efforts for AI Scientist systems should prioritize leveraging their intrinsic strengths (e.g., cross-disciplinary knowledge integration), rather than replicating the pathways of human scientists.</p>
<p>At this early stage of development, the future pathways of an AI Scientist can be envisioned along two interdependent paradigms: (1) Personalized AI Scientist systems tailored to individual human researchers, empowering them through personalized, co-evolutionary partnerships, and (2) AI Scientist systems serving broader human society, accelerating global solutions.The former aims to enhance the research productivity and creative capacities of individual scientists through tailored collaborations.In contrast, the latter seeks to establish AI-driven scientific ecosystems, effectively addressing complex global challenges.Together, these pathways converge toward a vision where AI Scientist systems transcend tool-like functionality to become proactive stewards of scientific advancement, balancing autonomy with human oversight to uphold integrity, inclusivity, and societal benefit (Tsvetkova et al., 2024).(2) Evolutionary personalization: Continuous preference tuning via reinforcement learning from human feedback (Ouyang et al., 2022), where AI Scientist systems adapt to a researcher's evolving style, balancing autonomy (e.g., automated verification) with human oversight.</p>
<p>AI Scientist for Individual Researcher
Active</p>
<p>AI Scientist for Human Society</p>
<p>Adapt to the trend of scientific development.An AI Scientist serving broader human society must dynamically adapt to the accelerating pace and interdisciplinary nature of modern research by: (1) Continuous knowledge integration: Efficiently integrating emerging research from diverse fields (e.g., bioinformatics, quantum computing) while preventing loss of previous knowledge (Kirkpatrick et al., 2017).( 2 Crow (Bran et al., 2023) and BioDiscoveryAgent (Roohani et al., 2024) show promise in chemistry/biology.As these systems increasingly interface with physical laboratories (e.g., IoT sensors), they may evolve to support full-cycle scientific workflows.</p>
<p>Conclusion</p>
<p>This paper presented a systematic survey of existing research on AI Scientist systems, providing a comprehensive overview of advances in the field.Specifically, we proposed a capability-level framework that divides the capabilities of an AI Scientist into four progressive levels: knowledge acquisition, idea generation, verification and falsification, and evolution.Based on this framework, we critically analyzed current research and highlighted gaps AI Scientist systems must address before they can make ground-breaking discoveries that solve grand challenges across medicine, energy, and the environment, thereby changing the world and reshaping the scientific research paradigm.Finally, we concluded the survey by outlining future directions essential for closing the gap and advancing the field toward truly autonomous scientific intelligence.</p>
<p>Figure 1:The capability level of an AI Scientist, illustrating the progression from foundational knowledge acquisition (Level 1), through idea generation (Level 2), rigorous hypothesis verification and falsification (Level 3), to continuous evolution (Level 4).We outline the core functions for each capability level.</p>
<p>utilize the arXiv API to retrieve papers and perform summarization, full-text extraction, and curation tasks.Meanwhile, Jiabin et al. (2025) apply citation-based filtering to top-cited domain papers from arXiv.Beyond single-agent retrieval, multi-agent systems have been explored as well.Gottweis et al. (2025) integrate web search tools, while Lu et al. (2024) utilize Semantic Scholar's API to identify relevant papers for hypotheses generation.In the RAG domain, Lála et al. (2023) and Skarlinski et al. (2024) introduce PaperQA and PaperQA2 for scientific question answering tasks.</p>
<p>Figure 3 :
3
Figure 3: An analysis of the number of publications in the field of AI Scientist systems on arXiv.The upper panel displays the average number of citations up to now, categorized by containing implementation details.The lower panel shows the growth in the total number of these papers with the same categorization.</p>
<p>of the information.(3) Hallucinated outputs may contain subtle logical inconsistencies or contextually inappropriate claims, which can mislead researchers, compromise the credibility of scientific outputs, and ultimately undermine trust in AI-generated scientific artifacts.Addressing hallucination remains one of the most significant challenges for deploying LLM-based AI Scientist systems in high-stakes scientific contexts.High cost and inefficiency of knowledge updating.Cutting-edge scientific research advances rapidly, requiring AI Scientist systems to constantly incorporate the latest findings and data.However, keeping LLMs up-to-date is non-trivial: (1) The volume of new scientific literature and data is immense, and integrating this information into an LLM demands significant computational resources, storage, and time.(2) Frequent retraining or fine-tuning of large-scale models is both costly and technically challenging, often leading to delays in knowledge integration that may render the model outdated in fast-moving research domains.(3) The lack of efficient, fine-grained, and continuous learning mechanisms means that knowledge refreshing processes are typically slow, creating a persistent lag between the state of the art in scientific fields and the knowledge encoded in AI Scientist systems.</p>
<p>systems.Leveraging these standardized communication protocols could further advance the formation of AI-driven research communities, enabling collective intelligence to tackle complex interdisciplinary research challenges with unprecedented effectiveness and rigor.</p>
<p>Learning.A personalized AI Scientist should actively gain experiences, analyze mistakes, and absorb the latest knowledge tailored for individual human researchers.This includes: (1) Knowledge gap identification: Identifying gaps in a researcher's knowledge by reviewing their publications, notes, and unresolved questions.(2) Personalized literature curation: Recommending papers based on the researcher's specific research interests, current project stage, and experimental bottlenecks (He et al., 2025).(3) Real-time learning: Real-time summarization of emerging literature (Agarwal et al., 2024a) coupled with contextualized explanations of unfamiliar concepts.Preference alignment of human researchers.Effective alignment involves matching the capabilities of AI Scientist systems with human research goals, including but not limited to: (1) Value-driven hypothesis generation: aligning hypothesis proposals with the researcher's research preferences, risk tolerance and resource constraints.(2) Ethical boundary management: Dynamically adapt to the researcher's institutional rules, funding ethics, and personal boundaries (e.g., auto-rejecting high-risk topics like gene editing).(3) Collaborative research agendas: Planning research directions with human researchers jointly, taking into account individual career aspirations and priorities for impactful scientific contributions.Mutual guidance and co-evolution.A personalized AI Scientist progresses together with human researchers through continuous scientific research activity: (1) Bidirectional refinement loops: AI Scientist systems and researchers iteratively refine scientific artifacts through mutual feedback (Romera-Paredes et al., 2024).</p>
<p>proposes a benchmark for evaluating systems that generate scientific leaderboards, which attempts to stay informed about the latest state-of-the-art research.Through semi-automated extraction of experimental data from multiple datasets, Park et al. (2025) demonstrate how comparative approaches can yield new scientific discoveries.Concurrently,</p>
<p>Automated literature review and tools. Recent
benchmarks have started to evaluate the ability of LLMs toperform automated literature review and assist in scientific knowledge organization. For example, Yun et al.(2023) find that researchers tend to prefer transparent AI tools over black-box systems for literature reviewtasks. Building on this, Hsu et al. (2024) introduce CHIME, a semi-automatically generated benchmark thatassesses the ability of LLMs to generate and link topic categories, though these models still struggle withassigning concrete studies to appropriate topics. Similarly, Agarwal et al. (2024b) propose new evaluationprotocols and test sets derived from arXiv papers to rigorously test whether LLMs can write literature reviews,with a focus on zero-shot integrity and avoiding test set contamination as models evolve.</p>
<p>Table 2 :
2
State-of-the-art LLMs show relatively low accuracy on implementation benchmarks.The listed benchmarks are collected from diverse domains.The table below details their tasks, domains, scale, methods, and performance.
BenchmarkTask DescriptionDomainsScaleLLMAccuracy</p>
<p>Classification and Scoring-based System Research Papers Review System Score / Decision Generation-based System
"This paper isan excellent ........."Research PapersReview SystemReview TextMulti-agent SystemNotationLLM-based"This paper isAgentan excellent ... ......"Data Flow............Agent Com-Research PapersReview SystemReview Text
municationFigure 4: Three paradigms of AI reviewer systems with increasing complexity.The process begins with (1) classification &amp; scoring systems that provide quantitative outputs (e.g., scores or accept/reject decisions).This paradigm gradually evolves into (2) generation Systems that produce narrative review text.Recently, a more advanced paradigm employs (3) multi-agent Systems, where multiple AI agents collaborate to create a comprehensive, multi-faceted evaluation.</p>
<p>Table 3 :
3
An overview of AI Reviewer benchmarks, including task focus, sample scale, and data source.
NameTask FocusScaleSourcePeerRead (Kang et al., 2018)Predictive Modeling14700ACL, NeurIPS, ICLRASAP-Review (Yuan et al., 2022)Prediction &amp; Generation8877ICLR, NeurIPSMOPRD (Lin et al., 2023)Review Generation6578Journals from PeerJRelevAI-Reviewer (Couto et al., 2024)Predictive Modeling25164Existing Survey PapersReviewMT (Tan et al., 2024)Review Generation26841ICLR, Nature CommunicationsREVIEWER2 (Gao et al., 2024)Review Generation27000Computer Science ConferencesSWIF2 T (Chamoun et al., 2024)Review Generation300Curated Peer ReviewsAutomatic Evaluation Metrics (Höpner et al., 2025)Predictive Modeling15002OpenReview, Semantic ScholarPeerQA (Baumgärtner et al., 2025)Text Analysis579Papers from computer science, Geoscience, HealthAI/Human Peer Review (Yu et al., 2025)Text Analysis788984ICLR, NeurIPSReview-5K (Weng et al., 2025)Prediction &amp; Generation24991ICLR 2024DeepReview (Zhu et al., 2025)Review Generation14664ICLR 2024, 2025</p>
<p>Table 4 :
4
Evaluation of AI-generated papers produced by various AI scientist systems.Scores represent the average ratings given by DeepReviewer-14B</p>
<p>Table 5 :
5
Twelve major defect categories detected in the 28 assessed papers.
Defect CategoryNumber PercentageExperimental Weakness28100%Methodological Unclarity/Flaws2796.4%Writing &amp; Presentation Issues2692.9%Novelty Concerns2589.3%Theoretical Weakness2485.7%Literature Review Deficiencies2278.6%Practicality &amp; Robustness Gaps2175.0%Reproducibility Issues2071.4%Computational Cost Concerns1864.3%Component Analysis1657.1%Hyperparameter Analysis Lacking1657.1%Ethical Considerations Missing310.7%</p>
<p>Table 6 :
6
Comparison of survey papers on LLM-based scientific agents, scientific tools, and AI Scientist.Research
SurveyResearch ScopeEthics/Society Capability Roadmap Critical Gap AssessmentZhang et al. (2024b)Scientific LLMsRen et al. (2025)LLM-based Scientific AgentsGridach et al. (2025) Agentic AI for scientific discoveryZheng et al. (2025)LLMs in science△Zhou et al. (2025b) AI-driven research support systems△Luo et al. (2025)LLMs for scientific research△Goyal (2025)AI ScientistOursAI Scientist
Scope: Domains of each survey paper; Ethics/Society: discussion of ethical and societal issues; Capability Roadmap: whether a staged roadmap toward a mature AI Scientist is provided; Critical Gap Assessment: whether the paper critically evaluates progress toward the mature AI Scientist and identifies bottlenecks.: strong/unique coverage; △: partial/related coverage; : little or no coverage.</p>
<p>Addressing fundamental model limitations and enhancing research abilities.</p>
<p>As outlined in the previous discussion, a significant bottleneck for current AI Scientist systems lies in the intrinsic limitations of the foundation models.Issues such as hallucinations, inefficiencies in knowledge updating, and catastrophic forgetting severely impede their reliability and scientific rigor.Addressing these fundamental constraints requires substantial</p>
<p>advancements in model architecture, training methodologies, and inference-time verification</p>
<p>strategies.Potential solutions include developing hybrid model architectures that integrate symbolic reasoning capabilities with deep learning architectures to enhance interpretability and factual accuracy.Additionally, methods such as RAG and continual learning frameworks could mitigate issues related to data recency and model adaptability, ensuring that AI Scientists maintain up-to-date and verifiable scientific knowledge.Moreover, it is also crucial to advance AI Scientist systems' research capabilities (e.g., hypothesis assessment, and scientific reasoning) through evolutionary mechanisms.Enhancements could include incorporating iterative preference training and structured self-reflection mechanisms, allowing models to autonomously refine their capabilities based on rigorous internal critiques and external feedback.Managing long-term research cycles.A mature AI Scientist should autonomously manage comprehensive, long-term research cycles.Current AI Scientist systems, however, predominantly focus on short-term individual research tasks.Future AI Scientist systems must incorporate sophisticated dynamic planning methods, such as</p>
<p>hierarchical planning frameworks or agentic tree-search algorithms, to</p>
<p>effectively navigate extensive research pathways.Additionally, to further facilitate iterative improvement loops, AI Scientist systems could incorporate frameworks like genetic</p>
<p>algorithm-based refinement or reinforcement learning-driven optimization.</p>
<p>These mechanisms can help prioritize research objectives, efficiently allocate resources, and adaptively refine strategies based on progressive insights, thus significantly improving the depth and breadth of autonomous scientific discoveries.Developing communication protocols for AI Scientist systems.Another critical future direction involves developing standardized Scientist-to-Scientist Communication Protocols (SSCP), enabling structured and efficient interactions among AI Scientist systems.Current efforts in AI-driven research collaborations primarily rely on ad hoc communication methods, thus lacking standardized interaction workflows and unified communication formats.Establishing an SSCP could profoundly enhance AI Scientists' collaborative capabilities, promoting effective information exchange, hypothesis validation, and multi-agent research coordination.Such a communication protocol should specify interaction workflows, structured data formats, and collaborative research strategies to facilitate seamless integration among heterogeneous AI Scientist</p>
<p>) Crossdomain collaboration: Enable interdisciplinary discovery by transferring methods across fields (e.g., applying ML-driven drug discovery to materials science).(3)Predictive research: Identifying emerging scientific trends using network analysis of preprint repositories (e.g., arXiv, bioRxiv) and funding trends, guiding research focus toward critical topics like climate resilience or pandemic preparedness.Prospects for human development.AI Scientist systems can greatly boost human progress by: (1) Reducing resource gaps by providing open-access tools and cloud-based experimental simulators, enabling under-resourced institutions to participate in global research.(2) Accelerating discovery for critical challenges (e.g., renewable energy, disease treatment) through automated experimentation.Early successes like Chem-</p>
<p>https://nlpprogress.com/
https://paperswithcode.com/
https://pubmed.ncbi.nlm.nih.gov/
https://arxiv.org/
Analysis, as the concluding part of the experimental process, plays a crucial role in organizing experimental results into well-written experimental reports. Recent advances, such as MCX-LLM(Yen and Fang, 2024), have explored the use of LLMs to convert natural language descriptions into machine-readable inputs for running Monte Carlo simulations, thus enhancing the efficiency of analysis. To evaluate the capabilities of such systems, benchmarks like FigureQA(Kahou et al., 2017), ArxivQA(Li et al., 2024a), and MMSCI(Li et al., 2025) have been developed, focusing on the agents' ability to understand and reason over complex figures, including graphs, charts, and tables. In addition to data interpretation, tools such asLLM-ref (Fuad and Chen,  2024)  further assist researchers by supporting the synthesis of information from multiple source documents and enhancing reference management during the article writing process. Building on these advancements, state-of-the-art AI Scientist systems leverage LLM-driven code generation to automate robust statistical analyses and to generate visualizations such as plots, tables, and charts. This automation greatly streamlines the reporting of experimental findings. Furthermore, these systems often perform multiple independent experimental runs and aggregate the results, thereby enabling comprehensive meta-analyses. After the analytical stage, some AI Scientist systems(Intology, 2025, Yamada et al., 2025) can even synthesize results into scientific manuscripts, automatically generating structured reports that encompass methodological details, data analyses, results, and conclusions in standard academic formats. While automatic paper writing represents a significant application of these systems, it is important to note that manuscript generation is not the core capability of AI Scientist systems. Therefore, the focus of this survey remains on the analytical and reasoning aspects rather than on the writing of final research articles.4.2. EvaluationAchieving robust verification and falsification in practice remains a profound gap for current AI Scientist systems, which is starkly illustrated by the performance of even state-of-the-art LLMs on a range of demanding benchmarks, as summarized in Table2. These benchmark tasks include executing end-to-end AI model training workflows, replicating Methods and empirical results directly from scientific publications, and accurately generating executable code from complex algorithmic descriptions embedded within research</p>
<p>Litllm: A toolkit for scientific literature review. Shubham Agarwal, Gaurav Sahu, Abhay Puri, H Issam, Laradji, D J Krishnamurthy, Jason Dvijotham, Laurent Stanley, Christopher Charlin, Pal, arXiv:2402.017882024aarXiv preprint</p>
<p>Shubham Agarwal, Gaurav Sahu, Abhay Puri, H Issam, Laradji, D J Krishnamurthy, Jason Dvijotham, Laurent Stanley, Christopher Charlin, Pal, arXiv:2412.15249Llms for literature review: Are we there yet?. 2024barXiv preprint</p>
<p>Litsearch: A retrieval benchmark for scientific literature search. Anirudh Ajith, Mengzhou Xia, Alexis Chevalier, Tanya Goyal, Danqi Chen, Tianyu Gao, arXiv:2407.189402024arXiv preprint</p>
<p>Automated literature review using nlp techniques and llm-based retrieval-augmented generation. Nurshat Fateh, Ali , Md Mahdi Mohtasim, Shakil Mosharrof, Krishna Gopi, 10.18653/v1/2021.bionlp-1.24arXiv:2411.18583Proceedings of the 20th Workshop on Biomedical Language Processing. Dina Demner-Fushman, Kevin Bretonnel Cohen, Sophia Ananiadou, Junichi Tsujii, the 20th Workshop on Biomedical Language ProcessingAssociation for Computational Linguistics2024. June 2021arXiv preprintBioM-transformers: Building large biomedical language models with BERT, ALBERT and ELECTRA</p>
<p>Introducing claude 3.5 sonnet. Anthropic Blog. Anthropic, 2024</p>
<p>Yuntao Bai, Saurav Kadavath, Sandipan Kundu, Amanda Askell, Jackson Kernion, Andy Jones, Anna Chen, Anna Goldie, Azalia Mirhoseini, Cameron Mckinnon, arXiv:2212.08073Constitutional ai: Harmlessness from ai feedback. 2022arXiv preprint</p>
<p>Monya Baker. 1,500 scientists lift the lid on reproducibility. 2016</p>
<p>Peerqa: A scientific question answering dataset from peer reviews. Tim Baumgärtner, Ted Briscoe, Iryna Gurevych, arXiv:2502.136682025arXiv preprint</p>
<p>Evaluating sakana's ai scientist for autonomous research: Wishful thinking or an emerging reality towards' artificial research intelligence. Joeran Beel, Min-Yen Kan, Moritz Baumgart, arXiv:2502.142972025arXiv preprint</p>
<p>Scibert: Pretrained language model for scientific text. Iz Beltagy, Kyle Lo, Arman Cohan, EMNLP. 2019</p>
<p>Superintelligent agents pose catastrophic risks: Can scientist ai offer a safer path. Yoshua Bengio, Michael Cohen, Damiano Fornasiere, Joumana Ghosn, Pietro Greiner, Matt Macdermott, Sören Mindermann, Adam Oberman, Jesse Richardson, Oliver Richardson, arXiv:2502.156572025arXiv preprint</p>
<p>Has the machine learning review process become more arbitrary as the field has grown? the neurips 2021 consistency experiment. Alina Beygelzimer, Percy Yann N Dauphin, Jennifer Wortman Liang, Vaughan, arXiv:2306.032622023arXiv preprint</p>
<p>Politepeer: does peer review hurt? a dataset to gauge politeness intensity in the peer reviews. Prabhat Kumar Bharti, Meith Navlakha, Mayank Agarwal, and Asif Ekbal. 202458</p>
<p>Iterative refinement of project-level code context for precise code generation with compiler feedback. Zhangqian Bi, Yao Wan, Zheng Wang, Hongyu Zhang, Batu Guan, Fangxin Lu, Zili Zhang, Yulei Sui, Xuanhua Shi, Hai Jin, Annual Meeting of the Association for Computational Linguistics. 2024</p>
<p>Reflective multi-agent collaboration based on large language models. Xiaohe Bo, Zeyu Zhang, Quanyu Dai, Xueyang Feng, Lei Wang, Rui Li, Xu Chen, Ji-Rong Wen, Advances in Neural Information Processing Systems. 202437</p>
<p>Chemcrow: Augmenting large-language models with chemistry tools. Sam Andres M Bran, Oliver Cox, Carlo Schilter, Andrew D Baldassari, Philippe White, ; Schwaller, Prafulla Jared D Kaplan, Arvind Dhariwal, Pranav Neelakantan, Girish Shyam, Amanda Sastry, Askell, arXiv:2304.05376Advances in neural information processing systems. 332023. 2020arXiv preprintLanguage models are few-shot learners</p>
<p>TLDR: Extreme summarization of scientific documents. Isabel Cachola, Kyle Lo, Arman Cohan, Daniel Weld, 10.18653/v1/2020.findings-emnlp.428Findings of the Association for Computational Linguistics: EMNLP 2020. Trevor Cohn, Yulan He, Yang Liu, Association for Computational LinguisticsNovember 2020a</p>
<p>Tldr: Extreme summarization of scientific documents. Isabel Cachola, Kyle Lo, Arman Cohan, Daniel S Weld, arXiv:2004.150112020barXiv preprint</p>
<p>Prompting is all you need: Llms for systematic review screening. Christian Cao, J Sang, Robbie Rahul K Arora, Kloosterman, J Matthew Cecere, Richard Gorla, D Saleh, Ian Chen, Bijan Drennan, Teja, P Michael Fehlings, Alexander A Ronksley, Dany E Leung, Harriet Weisz, Mairead Ware, D B Whelan, Rahul K Emerson, Niklas Arora, Bobrovitz, medRxiv. 2024</p>
<p>Exploring scientific hypothesis generation with mamba. Miaosen Chai, Emily Herron, Erick Cervantes, Tirthankar Ghosal, Proceedings of the 1st Workshop on NLP for Science (NLP4Science). the 1st Workshop on NLP for Science (NLP4Science)2024</p>
<p>Automated focused feedback generation for scientific writing assistance. Eric Chamoun, Michael Schlichktrull, Andreas Vlachos, arXiv:2405.204772024arXiv preprint</p>
<p>Mle-bench: Evaluating machine learning agents on machine learning engineering. Neil Jun Shern Chan, Oliver Chowdhury, James Jaffe, Dane Aung, Evan Sherburn, Giulio Mays, Kevin Starace, Leon Liu, Tejal Maksin, Patwardhan, arXiv:2410.070952024arXiv preprint</p>
<p>The toronto paper matching system: an automated paper-reviewer assignment system. Laurent Charlin, Richard Zemel, 2013</p>
<p>Ziru Chen, Shijie Chen, Yuting Ning, Qianheng Zhang, Boshi Wang, Botao Yu, Yifei Li, Zeyi Liao, Chen Wei, Zitong Lu, arXiv:2410.05080Toward rigorous assessment of language agents for data-driven scientific discovery. 2024arXiv preprint</p>
<p>React: A re view comment dataset for act ionability (and more). Gautam Choudhary, Natwar Modani, Nitish Maurya, WISE 2021Web Information Systems Engineering-WISE 2021: 22nd International Conference on Web Information Systems Engineering. Melbourne, VIC, AustraliaSpringerOctober 26-29, 2021. 2021Proceedings, Part II 22</p>
<p>Benedictus Kent Rachmat. Henrique Paulo, Quang Phuoc Couto, Nageeta Ho, Kumari, arXiv:2406.10294Thanh Gia Hieu Khuong, Ihsan Ullah, and Lisheng Sun-Hosoya. Relevai-reviewer: A benchmark on ai reviewers for survey paper relevance. 2024arXiv preprint</p>
<p>Structured information extraction from scientific text with large language models. John Dagdelen, Alexander Dunn, Sanghoon Lee, Nicholas Walker, Gerbrand Andrew S Rosen, Kristin A Ceder, Anubhav Persson, Jain, Nature Communications. 15114182024</p>
<p>Marg: Multi-agent review generation for scientific papers. D' Mike, Tom Arcy, Larry Hope, Doug Birnbaum, Downey, arXiv:2401.042592024arXiv preprint</p>
<p>ARIES: A corpus of scientific paper edits made in response to peer reviews. D' Mike, Alexis Arcy, Erin Ross, Bailey Bransom, Jonathan Kuehl, Tom Bragg, Doug Hope, Downey, 10.18653/v1/2024.acl-long.377Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics. Long Papers. Lun-Wei Ku, Andre Martins, Vivek Srikumar, the 62nd Annual Meeting of the Association for Computational LinguisticsBangkok, ThailandAssociation for Computational LinguisticsAugust 20241</p>
<p>Wolfgang Ertel. Introduction to artificial intelligence. Albert Einstein, The meaning of relativity. Springer Nature1922. 2024The general theory of relativity</p>
<p>Double-blind peer review affects reviewer ratings and editor decisions at an ecology journal. Charles W Fox, Jennifer Meyer, Emilie Aimé, 10.1111/1365-2435.14259Publisher Copyright: © 2023 The Authors. Functional Ecology © 2023 British Ecological Society. May 202337</p>
<p>Semantic scholar. Suzanne Fricke, Journal of the Medical Library Association: JMLA. 10611452018</p>
<p>Llm-ref: Enhancing reference handling in technical writing with large language models. Kazi Ahmed, Asif Fuad, Lizhong Chen, ArXiv, abs/2411.002942024273798525</p>
<p>Xian Gao, Jiacheng Ruan, Jingsheng Gao, Ting Liu, Yuzhuo Fu, arXiv:2503.08506Reviewagents: Bridging the gap between human and ai-generated paper reviews. 2025arXiv preprint</p>
<p>Retrieval-augmented generation for large language models: A survey. Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yixin Dai, Jiawei Sun, Haofen Wang, Haofen Wang, arXiv:2312.1099722023arXiv preprint</p>
<p>Reviewer2: Optimizing review generation through prompt generation. Zhaolin Gao, Kianté Brantley, Thorsten Joachims, arXiv:2402.108862024arXiv preprint</p>
<p>Usefulness of llms as an author checklist assistant for scientific papers: Neurips'24 experiment. Alexander Goldberg, Ihsan Ullah, Thanh Gia Hieu, Benedictus Khuong, Zhen Kent Rachmat, Isabelle Xu, Nihar B Guyon, Shah, ArXiv, abs/2411.034172024a273849959</p>
<p>Alexander Goldberg, Ihsan Ullah, Thanh Gia Hieu, Benedictus Khuong, Zhen Kent Rachmat, Isabelle Xu, Nihar B Guyon, Shah, arXiv:2411.03417Usefulness of llms as an author checklist assistant for scientific papers: Neurips'24 experiment. 2024barXiv preprint</p>
<p>Towards an ai co-scientist. Juraj Gottweis, Wei-Hung Weng, Alexander Daryin, Tao Tu, Anil Palepu, Petar Sirkovic, Artiom Myaskovsky, Felix Weissenberger, Keran Rong, Ryutaro Tanno, arXiv:2502.188642025arXiv preprint</p>
<p>A survey on the rise of the ai scientists: Accelerating discovery and confronting ethical frontiers. Muskaan Goyal, 10.30574/wjaets.2025.15.2.0646World Journal of Advanced Engineering Technology and Sciences. 152025</p>
<p>Agentic ai for scientific discovery: A survey of progress, challenges, and future directions. Mourad Gridach, Jay Nanavati, Khaldoun Zine El Abidine, Lenon Mendes, Christina Mack, arXiv:2503.089792025arXiv preprint</p>
<p>Domain-specific language model pretraining for biomedical natural language processing. Yu Gu, Robert Tinn, Hao Cheng, Michael Lucas, Naoto Usuyama, Xiaodong Liu, Tristan Naumann, Jianfeng Gao, Hoifung Poon, 2020</p>
<p>Large language model based multi-agents: A survey of progress and challenges. Taicheng Guo, Xiuying Chen, Yaqi Wang, Ruidi Chang, Shichao Pei, V Nitesh, Olaf Chawla, Xiangliang Wiest, Zhang, arXiv:2402.016802024arXiv preprint</p>
<p>Automatic analysis of substantiation in scientific peer reviews. Yanzhu Guo, Guokan Shang, Virgile Rennard, Michalis Vazirgiannis, Chloé Clavel, 10.18653/v1/2023.findings-emnlp.684Findings of the Association for Computational Linguistics: EMNLP 2023. Houda Bouamor, Juan Pino, Kalika Bali, SingaporeAssociation for Computational LinguisticsDecember 2023</p>
<p>Aishat Adeboye, and Rampi Ramprasad. Data extraction from polymer literature using large language models. Sonakshi Gupta, Akhlak Mahmood, Pranav Shetty, Communications Materials. 512692024</p>
<p>MatSciBERT: A materials domain language model for text mining and information extraction. Tanishq Gupta, Mohd Zaki, N M Anoop Krishnan, Mausam , 10.1038/s41524-022-00784-wComputational Materials. 2057-396081102May 2022</p>
<p>An llm agent for comprehensive academic paper search. Yichen He, Guanhua Huang, Peiyuan Feng, Yuan Lin, Yuchen Zhang, Hang Li, Weinan E Pasa, 2025</p>
<p>The diminishing returns of masked language models to science. Zhi Hong, Aswathy Ajith, Gregory Pauloski, Eamon Duede, Kyle Chard, Ian Foster, 2023</p>
<p>Automatic evaluation metrics for artificially generated scientific research. Niklas Höpner, Leon Eshuijs, Dimitrios Alivanistos, Giacomo Zamprogno, Ilaria Tiddi, arXiv:2503.057122025arXiv preprint</p>
<p>Identification of tasks, datasets, evaluation metrics, and numeric scores for scientific leaderboards construction. Yufang Hou, Charles Jochim, Martin Gleize, Francesca Bonin, Debasis Ganguly, 10.18653/v1/P19-1513Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. Anna Korhonen, David Traum, Lluís Màrquez, the 57th Annual Meeting of the Association for Computational LinguisticsFlorence, ItalyAssociation for Computational LinguisticsJuly 2019</p>
<p>CHIME: LLM-assisted hierarchical organization of scientific studies for literature review support. Chao-Chun, Erin Hsu, Jenna Bransom, Bailey Sparks, Chenhao Kuehl, David Tan, Lucy Wadden, Aakanksha Wang, Naik, 10.18653/v1/2024.findings-acl.8Findings of the Association for Computational Linguistics: ACL 2024. Lun-Wei Ku, Andre Martins, Vivek Srikumar, Bangkok, ThailandAssociation for Computational LinguisticsAugust 2024</p>
<p>Nova: An iterative planning and search approach to enhance novelty and diversity of llm generated ideas. Xiang Hu, Hongyu Fu, Jinge Wang, Yifeng Wang, Zhikun Li, Renjun Xu, Yu Lu, Yaochu Jin, Lili Pan, Zhenzhong Lan, arXiv:2410.142552024arXiv preprint</p>
<p>An overview of artificial intelligence ethics. Changwu Huang, Zeqi Zhang, Bifei Mao, Xin Yao, IEEE Transactions on Artificial Intelligence. 442022</p>
<p>Clinicalbert: Modeling clinical notes and predicting hospital readmission. Kexin Huang, Jaan Altosaar, Rajesh Ranganath, arXiv:1904.053422019</p>
<p>A survey on hallucination in large language models: Principles, taxonomy, challenges, and open questions. Kexin Huang, Serena Zhang, Hanchen Wang, Yuanhao Qu, Yingzhou Lu, Yusuf Roohani, Ryan Li, Lin Qiu, Junze Zhang, Yin Di, ACM Transactions on Information Systems. 4322025a. 2025bbioRxiv</p>
<p>Openreviewer: A specialized large language model for generating critical scientific paper reviews. Maximilian Idahl, Zahra Ahmadi, arXiv:2412.11948Intology. Zochi technical report. arXiv. 2024. 2025arXiv preprint</p>
<p>Why most published research findings are false. P A John, Ioannidis, PLoS medicine. 28e1242005</p>
<p>Discoveryworld: A virtual environment for developing and evaluating automated scientific discovery agents. Peter Jansen, Marc-Alexandre Côté, Tushar Khot, Erin Bransom, Bhavana Dalvi Mishra, Bodhisattwa Prasad Majumder, Oyvind Tafjord, Peter Clark, Advances in Neural Information Processing Systems. 202437</p>
<p>Codescientist: End-to-end semi-automated scientific discovery with code-based experimentation. Peter Jansen, Oyvind Tafjord, Marissa Radensky, Pao Siangliulue, Tom Hope, Bhavana Dalvi Mishra, Bodhisattwa Prasad Majumder, Daniel S Weld, Peter Clark, arXiv:2503.227082025arXiv preprint</p>
<p>Lgar: Zero-shot llm-guided neural ranking for abstract screening in systematic literature reviews. Christian Jaumann, Andreas Wiedholz, Annemarie Friedrich, 2025279071051</p>
<p>Ai-researcher: Autonomous scientific innovation. Tang Jiabin, Xia Lianghao, Li Zhonghang, Huang Chao, 2025</p>
<p>Aide: Ai-driven exploration in the space of code. Zhengyao Jiang, Dominik Schmidt, Dhruv Srikanth, Dixing Xu, Ian Kaplan, Deniss Jacenko, Yuxiang Wu, ArXiv, abs/2502.131382025</p>
<p>Carlos E Jimenez, John Yang, Alexander Wettig, Shunyu Yao, Kexin Pei, ; , Karthik Narasimhan, arXiv:2310.06770Swe-bench: Can language models resolve real-world github issues?. Ofir Press2023arXiv preprint</p>
<p>Probing biomedical embeddings from language models. Qiao Jin, Bhuwan Dhingra, William Cohen, Xinghua Lu, Proceedings of the 3rd Workshop on Evaluating Vector Space Representations for NLP. the 3rd Workshop on Evaluating Vector Space Representations for NLP2019</p>
<p>AgentReview: Exploring peer review dynamics with LLM agents. Yiqiao Jin, Qinlin Zhao, Yiyang Wang, Hao Chen, Kaijie Zhu, Yijia Xiao, Jindong Wang, 10.18653/v1/2024.emnlp-main.70Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing. Yaser Al-Onaizan, Mohit Bansal, Yun-Nung Chen, the 2024 Conference on Empirical Methods in Natural Language ProcessingMiami, Florida, USAAssociation for Computational LinguisticsNovember 2024</p>
<p>Dsbench: How far are data science agents from becoming data science experts?. Liqiang Jing, Zhehui Huang, Xiaoyang Wang, Wenlin Yao, Wenhao Yu, Kaixin Ma, Hongming Zhang, Xinya Du, Dong Yu, 2025</p>
<p>The global landscape of ai ethics guidelines. Anna Jobin, Marcello Ienca, Effy Vayena, Nature machine intelligence. 192019</p>
<p>Cutting through the clutter: The potential of llms for efficient filtration in systematic literature reviews. Lucas Joos, Daniel A Keim, Maximilian T Fischer, arXiv:2407.106522024arXiv preprint</p>
<p>Highly accurate protein structure prediction with alphafold. John Jumper, Richard Evans, Alexander Pritzel, Tim Green, Michael Figurnov, Olaf Ronneberger, Kathryn Tunyasuvunakool, Russ Bates, Augustin Žídek, Anna Potapenko, nature. 59678732021</p>
<p>Orkg-leaderboards: a systematic workflow for mining leaderboards as a knowledge graph. Salomon Kabongo, Kabenamualu Jennifer, D' Souza, S Auer, International Journal on Digital Libraries. 2023</p>
<p>Figureqa: An annotated figure dataset for visual reasoning. Samira Ebrahimi Kahou, Adam Atkinson, Vincent Michalski, Ákos Kádár, Adam Trischler, Yoshua Bengio, ArXiv, abs/1710.0730020173535069</p>
<p>Dongyeop Kang, Waleed Ammar, Bhavana Dalvi, Madeleine Van Zuylen, Sebastian Kohlmeier, Eduard Hovy, Roy Schwartz, arXiv:1804.09635A dataset of peer reviews (peerread): Collection, insights and nlp applications. 2018arXiv preprint</p>
<p>From who you know to what you read: Augmenting scientific recommendations with implicit social networks. Rafal Hyeonsu B Kang, Andrew Kocielnik, Jiangjiang Head, Matt Yang, Aniket Latzke, Kittur, Doug Daniel S Weld, Jonathan Downey, Bragg, 10.1145/3491102.3517470Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems, CHI '22. the 2022 CHI Conference on Human Factors in Computing Systems, CHI '22New York, NY, USAAssociation for Computing Machinery2022</p>
<p>Comlittee: Literature discovery with personal elected author committees. Nouran Hyeonsu B Kang, Matt Soliman, Joseph Chee Latzke, Jonathan Chang, Bragg, Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems. the 2023 CHI Conference on Human Factors in Computing Systems2023</p>
<p>AxCell: Automatic extraction of results from machine learning papers. Marcin Kardas, Piotr Czapla, Pontus Stenetorp, Sebastian Ruder, Sebastian Riedel, Ross Taylor, Robert Stojnic, 10.18653/v1/2020.emnlp-main.692Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). Bonnie Webber, Trevor Cohn, Yulan He, Yang Liu, the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)Association for Computational LinguisticsNovember 2020</p>
<p>The perils of using mechanical turk to evaluate openended text generation. Marzena Karpinska, Nader Akoury, Mohit Iyyer, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. the 2021 Conference on Empirical Methods in Natural Language Processing2021</p>
<p>Ethics of ai: A systematic literature review of principles and challenges. Arif Ali Khan, Sher Badshah, Peng Liang, Muhammad Waseem, Bilal Khan, Aakash Ahmad, Mahdi Fahmideh, Mahmood Niazi, Muhammad Azeem, Akbar , Proceedings of the 26th international conference on evaluation and assessment in software engineering. the 26th international conference on evaluation and assessment in software engineering2022</p>
<p>The automation of science. Jem Ross D King, Stephen G Rowland, Michael Oliver, Wayne Young, Emma Aubrey, Maria Byrne, Magdalena Liakata, Pinar Markham, Larisa N Pir, Soldatova, Science. 32459232009</p>
<p>Overcoming catastrophic forgetting in neural networks. James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume Desjardins, Andrei A Rusu, Kieran Milan, John Quan, Tiago Ramalho, Agnieszka Grabska-Barwinska, Proceedings of the national academy of sciences. the national academy of sciences2017114</p>
<p>Longeval: Guidelines for human evaluation of faithfulness in long-form summarization. Kalpesh Krishna, Erin Bransom, Bailey Kuehl, Mohit Iyyer, Pradeep Dasigi, Arman Cohan, Kyle Lo, Proceedings of the 17th Conference of the European Chapter. the 17th Conference of the European Chapterthe Association for Computational Linguistics2023</p>
<p>A systematic survey and critical review on evaluating large language models: Challenges, limitations, and recommendations. Thomas Kuhn, ; Jakub Lála, O' Odhran, Aleksandar Donoghue, Sam Shtedritski, Samuel G Cox, Andrew D Rodriques, ; P White, Langley, arXiv:2312.07559Conference on Empirical Methods in Natural Language Processing. Md Tahmid Rahman Laskar, Sawsan Alqahtani, Mizanur Saiful Bari, Mohammad Rahman, Haidar Abdullah Matin Khan, Israt Khan, Amran Jahan, Chee Bhuiyan, Md Rizwan Wei Tan, Enamul Parvez, Shafiq R Hoque, Jimmy X Joty, Huang, MIT Press2014. 2023. 2016. 1987. 2024535arXiv preprintPhilosophy, Science, and History</p>
<p>Biobert: a pre-trained biomedical language representation model for biomedical text mining. Yann Lecun, Yoshua Bengio, Geoffrey Hinton, ; Jinhyuk Lee, Wonjin Yoon, Sungdong Kim, Donghyeon Kim, Sunkyu Kim, Chan Ho So, Jaewoo Kang, Bioinformatics. 52175532015. 2020Deep learning. nature</p>
<p>PlagBench: Exploring the duality of large language models in plagiarism generation and detection. Jooyoung Lee, Toshini Agrawal, Adaku Uchendu, Thai Le, Jinghui Chen, Dongwon Lee, 10.18653/v1/2025.naacl-long.384Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies. Long Papers. Luis Chiruzzo, Alan Ritter, Lu Wang, the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language TechnologiesAlbuquerque, New MexicoAssociation for Computational LinguisticsApril 20251</p>
<p>Paperweaver: Enriching topical paper alerts by contextualizing recommended papers with user-collected papers. Yoonjoo Lee, B Hyeonsu, Matt Kang, Juho Latzke, Jonathan Kim, Joseph Chee Bragg, Pao Chang, Siangliulue, Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems. the 2024 CHI Conference on Human Factors in Computing Systems2024</p>
<p>Matching papers and reviewers at large conferences. Kevin Leyton-Brown, Yatin Nandwani, Hedayat Zarkoob, Chris Cameron, Neil Newman, Dinesh Raghu, Artificial Intelligence. 3311041192024</p>
<p>Multimodal arxiv: A dataset for improving scientific comprehension of large vision-language models. Lei Li, Yuqi Wang, Runxin Xu, Peiyi Wang, Xiachong Feng, Lingpeng Kong, Qi Liu, Annual Meeting of the Association for Computational Linguistics. 2024a</p>
<p>Chain of ideas: Revolutionizing research via novel idea development with llm agents. Long Li, Weiwen Xu, Jiayan Guo, Ruochen Zhao, Xingxuan Li, Yuqian Yuan, Boqiang Zhang, Yuming Jiang, Yifei Xin, Ronghao Dang, arXiv:2410.131852024barXiv preprint</p>
<p>Peersum: a peer review dataset for abstractive multi-document summarization. Miao Li, Jianzhong Qi, Jey Han Lau, arXiv:2203.017692022arXiv preprint</p>
<p>Mlr-copilot: Autonomous machine learning research based on large language models agents. Ruochen Li, Teerth Patel, Qingyun Wang, Xinya Du, 2024c</p>
<p>All data on the table: Novel dataset and benchmark for cross-modality scientific information extraction. Yuhan Li, Jian Wu, Zhiwei Yu, Börje F Karlsson, Wei Shen, Manabu Okumura, Chin-Yew Lin, 2023</p>
<p>MMSci: A dataset for graduate-level multi-discipline multimodal scientific understanding. Zekun Li, Xianjun Yang, Kyuri Choi, Wanrong Zhu, Ryan Hsieh, Hyeonjung Kim, Jin Hyuk Lim, Sungyoung Ji, Byungju Lee, Xifeng Yan, Linda Ruth Petzold, Stephen D Wilson, Woosang Lim, William Yang, Wang , 2025</p>
<p>Xun Liang, Jiawei Yang, Yezhaohui Wang, Chen Tang, Zifan Zheng, Shichao Song, Zehao Lin, Yebin Yang, Simin Niu, Hanyu Wang, arXiv:2502.14776Academic survey automation via large language models. 2025arXiv preprint</p>
<p>Rouge: A package for automatic evaluation of summaries. Chin-Yew Lin, Text summarization branches out. 2004</p>
<p>Moprd: A multidisciplinary open peer review dataset. Jialiang Lin, Jiaxin Song, Zhangping Zhou, Yidong Chen, X Shi, Neural Computing and Applications. 202235</p>
<p>Moprd: A multidisciplinary open peer review dataset. Jialiang Lin, Jiaxin Song, Zhangping Zhou, Yidong Chen, Xiaodong Shi, Neural Computing and Applications. 35342023</p>
<p>Autop2c: An llm-based agent framework for code repository generation from multimodal content in academic papers. Zijie Lin, Yiqing Shen, Qilin Cai, He Sun, Jinrui Zhou, Mingjun Xiao, arXiv:2504.201152025arXiv preprint</p>
<p>Reviewergpt? an exploratory study on using large language models for paper reviewing. Ryan Liu, Nihar B Shah, ArXiv, abs/2306.006222023</p>
<p>Aigs: Generating science from ai-powered automated falsification. Zijun Liu, Kaiming Liu, Yiqi Zhu, Xuanyu Lei, Zonghan Yang, Zhenhe Zhang, Peng Li, Yang Liu, arXiv:2411.119102024arXiv preprint</p>
<p>Renze Lou, Hanzi Xu, Sijia Wang, Jiangshu Du, Ryo Kamoi, Xiaoxin Lu, Jian Xie, Yuxuan Sun, Yusen Zhang, Jihyun Janice Ahn, Hongchao Fang, Zhuoyang Zou, Wenchao Ma, Xi Li, Kai Zhang, Congying Xia, Lifu Huang, and Wenpeng Yin. Aaar-1.0: Assessing ai's potential to assist research. 2025</p>
<p>The ai scientist: Towards fully automated open-ended scientific discovery. Chris Lu, Cong Lu, Robert Tjarko Lange, Jakob Foerster, Jeff Clune, David Ha, arXiv:2408.06292v32024arXiv preprint</p>
<p>Ziming Luo, Zonglin Yang, Zexin Xu, Wei Yang, Xinya Du, arXiv:2501.04306Llm4sr: A survey on large language models for scientific research. 2025arXiv preprint</p>
<p>Self-refine: Iterative refinement with self-feedback. Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, Advances in Neural Information Processing Systems. 202336</p>
<p>Does my rebuttal matter? insights from a major nlp conference. Yusuke Miyao, Proceedings of NAACL-HLT. NAACL-HLT2019</p>
<p>Scigen: a dataset for reasoningaware text generation from scientific tables. Nafise Sadat Moosavi, Andreas Rücklé, Dan Roth, Iryna Gurevych, Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2). 2021</p>
<p>Literature-based discovery beyond the abc paradigm: a contrastive approach. Erwan Moreau, Orla Hardiman, Mark Heverin, Declan O' Sullivan, BioRxiv. 2021</p>
<p>Dora ai scientist: Multi-agent virtual research team for scientific exploration discovery and automated report generation. Vladimir Naumov, Diana Zagirova, Sha Lin, Yupeng Xie, Wenhao Gou, Anatoly Urban, Nina Tikhonova, Khadija Alawi, Mike Durymanov, Fedor Galkin, bioRxiv. 2025</p>
<p>Philosophiae naturalis principia mathematica. Isaac Newton, G. Brookman. 11833</p>
<p>Newton's Principia: the mathematical principles of natural philosophy. Isaac Newton, Chittenden, Geo. P. Putnam1850</p>
<p>Alphaevolve: A coding agent for scientific and algorithmic discovery. Alexander Novikov, Ngân Vu, Marvin Eisenberger, Emilien Dupont, Po-Sen Huang, Adam Zsolt Wagner, Sergey Shirobokov, Borislav Kozlovskii, Abbas Francisco Jr Ruiz, Mehrabian, Google DeepMind, 05 2025. Technical report</p>
<p>Training language models to follow instructions with human feedback. Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, Advances in neural information processing systems. 202235</p>
<p>Repograph: Enhancing ai software engineering with repository-level code graph. Siru Ouyang, Wenhao Yu, Kaixin Ma, Zi-Qiang Xiao, Zhihan Zhang, Mengzhao Jia, Jiawei Han, Hongming Zhang, Dong Yu, ArXiv, abs/2410.146842024</p>
<p>Ml-dev-bench: Comparative analysis of ai agents on ml development workflows. Harshith Padigela, Chintan Shah, Dinkar Juyal, 2025</p>
<p>Automatically correcting large language models: Surveying the landscape of diverse automated correction strategies. Liangming Pan, Michael Saxon, Wenda Xu, Deepak Nathani, Xinyi Wang, William Yang, Wang , Transactions of the Association for Computational Linguistics. 122024a</p>
<p>Enhancing repository-level code generation with integrated contextual information. Zhiyuan Pan, Xing Hu, Xin Xia, Xiaohu Yang, ArXiv, abs/2406.032832024b270257850</p>
<p>Bleu: a method for automatic evaluation of machine translation. Kishore Papineni, Salim Roukos, Todd Ward, Wei-Jing Zhu, ACL. 2002</p>
<p>Can llms help uncover insights about llms? a large-scale, evolving literature analysis of frontier llms. Jungsoo Park, Junmo Kang, Gabriel Stanovsky, Alan Ritter, arXiv:2502.187912025arXiv preprint</p>
<p>Automated research review support using machine learning, large language models, and natural language processing. Karnavee Vishnu S Pendyala, Kapil Kamdar, Mulchandani, Electronics. 1422562025</p>
<p>Review-llm: Harnessing large language models for personalized review generation. Qiyao Peng, Hongtao Liu, Hongyan Xu, Qing Yang, Minglai Shao, Wenjun Wang, ArXiv, abs/2407.074872024</p>
<p>The logic of scientific discovery. Karl Popper, 2005Routledge</p>
<p>Citeme: Can language models accurately cite scientific claims?. Ori Press, Andreas Hochlehnert, Ameya Prabhu, ; , Matthias Bethge, Advances in Neural Information Processing Systems. Vishaal Udandarao, Ofir Press202437</p>
<p>Piflow: Principle-aware scientific discovery with multi-agent collaboration. Yingming Pu, Tao Lin, Hongyu Chen, 2025</p>
<p>Exploring jiu-jitsu argumentation for writing peer review rebuttals. Sukannya Purkayastha, Anne Lauscher, Iryna Gurevych, 10.18653/v1/2023.emnlp-main.894Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing. Houda Bouamor, Juan Pino, Kalika Bali, the 2023 Conference on Empirical Methods in Natural Language ProcessingSingaporeAssociation for Computational LinguisticsDecember 2023</p>
<p>Large language models are zero shot hypothesis proposers. Biqing Qi, Kaiyan Zhang, Haoxiang Li, Kai Tian, Sihang Zeng, Bowen Zhang-Ren Chen, Zhou, arXiv:2311.059652023arXiv preprint</p>
<p>Scaling large-language-model-based multi-agent collaboration. Chen Qian, Zihao Xie, Yifei Wang, Wei Liu, Yufan Dang, Zhuoyun Du, Weize Chen, Cheng Yang, Zhiyuan Liu, Maosong Sun, arXiv:2406.071552024arXiv preprint</p>
<p>Exploring the limits of transfer learning with a unified text-to-text transformer. Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, Peter J Liu, Journal of Machine Learning Research. 211402020</p>
<p>Towards scientific intelligence: A survey of llm-based scientific agents. Pu Shuo Ren, Zhenjiang Jian, Chunlin Ren, Can Leng, Jiajun Xie, Zhang, arXiv:2503.240472025arXiv preprint</p>
<p>Mathematical discoveries from program search with large language models. Bernardino Romera-Paredes, Mohammadamin Barekatain, Alexander Novikov, Matej Balog, Pawan Kumar, Emilien Dupont, Francisco Jr Ruiz, Jordan S Ellenberg, Pengming Wang, Omar Fawzi, Nature. 62579952024</p>
<p>Biodiscoveryagent: An ai agent for designing genetic perturbation experiments. Yusuf Roohani, Andrew Lee, Qian Huang, Jian Vora, Zachary Steinhart, Kexin Huang, Alexander Marson, Percy Liang, Jure Leskovec, arXiv:2405.176312024arXiv preprint</p>
<p>Samuel Schmidgall, Michael Moor, arXiv:2503.18102Agentrxiv: Towards collaborative autonomous research. 2025arXiv preprint</p>
<p>Jürgen Schmidhuber. Gödel machines: Fully self-referential optimal universal self-improvers. Samuel Schmidgall, Yusheng Su, Ze Wang, Ximeng Sun, Jialian Wu, Xiaodong Yu, Jiang Liu, Zicheng Liu, Emad Barsoum, arXiv:2501.04227Agent laboratory: Using llm agents as research assistants. Springer2025. 2007arXiv preprintArtificial general intelligence</p>
<p>Bigpatent: A large-scale dataset for abstractive and coherent summarization. Eva Sharma, Chen Li, Lu Wang, arXiv:1906.037412019arXiv preprint</p>
<p>Shortcutsbench: A large-scale real-world benchmark for api-based agents. Haiyang Shen, Yue Li, Desong Meng, Dongqi Cai, Sheng Qi, Li Zhang, Mengwei Xu, Yun Ma, 2025</p>
<p>Detecting pretraining data from large language models. Weijia Shi, Anirudh Ajith, Mengzhou Xia, Yangsibo Huang, Daogao Liu, Terra Blevins, Danqi Chen, Luke Zettlemoyer, The Twelfth International Conference on Learning Representations. 2024</p>
<p>BioMegatron: Larger biomedical domain language model. Hoo-Chang Shin, Yang Zhang, Evelina Bakhturina, Raul Puri, Mostofa Patwary, Mohammad Shoeybi, Raghav Mani, 10.18653/v1/2020.emnlp-main.379Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). Bonnie Webber, Trevor Cohn, Yulan He, Yang Liu, the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)Association for Computational LinguisticsNovember 2020</p>
<p>Reflexion: Language agents with verbal reinforcement learning. Noah Shinn, Federico Cassano, Ashwin Gopinath, Karthik Narasimhan, Shunyu Yao, Advances in Neural Information Processing Systems. 202336</p>
<p>The illusion of thinking: Understanding the strengths and limitations of reasoning models via the lens of problem complexity. Parshin Shojaee, Iman Mirzadeh, Keivan Alizadeh-Vahid, Maxwell Horton, Samy Bengio, Mehrdad Farajtabar, 2025279240606</p>
<p>Can llms generate novel research ideas? a large-scale human study with 100+ nlp researchers. Chenglei Si, Diyi Yang, Tatsunori Hashimoto, arXiv:2409.041092024arXiv preprint</p>
<p>Core-bench: Fostering the credibility of published research through a computational reproducibility agent benchmark. Zachary S Siegel, Sayash Kapoor, Nitya Nagdir, Benedikt Stroebl, Arvind Narayanan, arXiv:2409.113632024arXiv preprint</p>
<p>Legobench: Scientific leaderboard generation benchmark. Shruti Singh, Shoaib Alam, Husain Malwat, Mayank Singh, 2024</p>
<p>Language agents achieve superhuman synthesis of scientific knowledge. D Michael, Sam Skarlinski, Jon M Cox, James D Laurent, Michaela Braza, Michael J Hinks, Manvitha Hammerling, Ponnapati, G Samuel, Andrew D Rodriques, White, 10.48550/arXiv.2409.13740arXiv:2409.137402024arXiv preprent</p>
<p>Giulio Starace, Oliver Jaffe, Dane Sherburn, James Aung, Jun Shern Chan, Leon Maksin, Rachel Dias, Evan Mays, Benjamin Kinsella, Wyatt Thompson, arXiv:2504.01848Evaluating ai's ability to replicate ai research. 2025arXiv preprint</p>
<p>Towards fair, equitable, and efficient peer review. Ivan Stelmakh, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202135</p>
<p>Peerreview4all: Fair and accurate reviewer assignment in peer review. Ivan Stelmakh, Nihar B Shah, Aarti Singh, Algorithmic Learning Theory. PMLR2019</p>
<p>Aarti Singh, and Hal Daum'e. Prior and prejudice. Ivan Stelmakh, B Nihar, Shah, Proceedings of the ACM on Human-Computer Interaction. 52020</p>
<p>Reviewriter: Ai-generated instructions for peer review writing. Xiaotian Su, Thiemo Wambsganss, Roman Rietsche, Seyed Parsa Neshaei, Tanja Käser, Workshop on Innovative Use of NLP for Building Educational Applications. 2025</p>
<p>Towards table-to-text generation with numerical reasoning. Lya Hulliyyatus Suadaa, Hidetaka Kamigaito, Kotaro Funakoshi, Manabu Okumura, Hiroya Takamura, 10.18653/v1/2021.acl-long.115Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing. Long Papers. Chengqing Zong, Fei Xia, Wenjie Li, Roberto Navigli, the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language ProcessingAssociation for Computational LinguisticsAugust 20211</p>
<p>Metawriter: Exploring the potential and perils of ai writing support in scientific peer review. Lu Sun, Stone Tao, Junjie Hu, Steven P Dow, Proceedings of the ACM on Human-Computer Interaction. 82024</p>
<p>Undiscovered public knowledge. Don R Swanson, The Library Quarterly. 5621986</p>
<p>Agatha: automatic graph mining and transformer based hypothesis generation approach. Justin Sybrandt, Ilya Tyagin, Michael Shtutman, Ilya Safro, Proceedings of the 29th ACM international conference on information &amp; knowledge management. the 29th ACM international conference on information &amp; knowledge management2020</p>
<p>X-scitldr: cross-lingual extreme summarization of scholarly documents. Sotaro Takeshita, Tommaso Green, Niklas Friedrich, Kai Eckert, Simone Paolo, Ponzetto , Proceedings of the 22nd ACM/IEEE Joint Conference on Digital Libraries. the 22nd ACM/IEEE Joint Conference on Digital Libraries2022</p>
<p>Peer review as a multi-turn and long-context dialogue with role-based interactions. Cheng Tan, Dongxin Lyu, Siyuan Li, Zhangyang Gao, Jingxuan Wei, Siqi Ma, Zicheng Liu, Stan Z Li, arXiv:2406.056882024arXiv preprint</p>
<p>Scicode: A research coding benchmark curated by scientists. Minyang Tian, Luyu Gao, Dylan Shizhuo, Xinan Zhang, Cunwei Chen, Xuefei Fan, Roland Guo, Pan Haas, Kittithat Ji, Yao Krongchon, Shengyan Li, Di Liu, Yutao Luo, Hao Ma, Kha Tong, Chenyu Trinh, Zihan Tian, Bohao Wang, Yanyu Wu, Shengzhu Xiong, Min Yin, Zhu, Adriano Kilian, Yanxin Lieret, Genglin Lu, Yufeng Liu, Tianhua Du, Tao, ArXiv, abs/2407.13168E. A. Huerta, and Hao Peng2024Ofir PressJamie Callan</p>
<p>Unsupervised word embeddings capture latent knowledge from materials science literature. John Vahe Tshitoyan, Leigh Dagdelen, Alexander Weston, Ziqin Dunn, Olga Rong, Kristin A Kononova, Gerbrand Persson, Anubhav Ceder, Jain, Nature. 57177632019</p>
<p>A new sociology of humans and machines. Milena Tsvetkova, Taha Yasseri, Niccolo Pescetelli, Tobias Werner, Nature Human Behaviour. 8102024</p>
<p>Keith Tyser, Jason Lee, Avi Shporer, Madeleine Udell, Dov Te'eni, Iddo Drori, Openreviewer, Mitigating challenges in LLM reviewing. 2024</p>
<p>Attention is all you need. Advances in neural information processing systems. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, Illia Polosukhin, 201730</p>
<p>Teaching code llms to use autocompletion tools in repository-level code generation. Chong Wang, Jian Zhang, Yebo Feng, Tianlin Li, Weisong Sun, Yang Liu, Xin Peng, ACM Transactions on Software Engineering and Methodology. 2024a</p>
<p>Peisong Wang, Ruotian Ma, Bang Zhang, Xingyu Chen, Zhiwei He, Kang Luo, Qingsong Lv, Qingxuan Jiang, Zheng Xie, Shanyi Wang, arXiv:2507.03112Reinforcement learning with verifiable emotion rewards for empathetic agents. 2025arXiv preprint</p>
<p>Paperrobot: Incremental draft generation of scientific ideas. Qingyun Wang, Lifu Huang, Zhiying Jiang, Kevin Knight, Heng Ji, Mohit Bansal, Yi Luan, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. the 57th Annual Meeting of the Association for Computational Linguistics1980-1991, 2019</p>
<p>Qingyun Wang, Qi Zeng, Lifu Huang, Kevin Knight, Ji Heng, Nazneen Fatema, Rajani , arXiv:2010.06119Reviewrobot: Explainable paper review generation based on knowledge synthesis. 2020arXiv preprint</p>
<p>SciMON: Scientific inspiration machines optimized for novelty. Qingyun Wang, Doug Downey, Heng Ji, Tom Hope, 10.18653/v1/2024.acl-long.18Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics. Long Papers. Lun-Wei Ku, Andre Martins, Vivek Srikumar, the 62nd Annual Meeting of the Association for Computational LinguisticsBangkok, ThailandAssociation for Computational LinguisticsAugust 2024b1</p>
<p>Zero-shot generative large language models for systematic review screening automation. Shuai Wang, Harrisen Scells, Shengyao Zhuang, Martin Potthast, Bevan Koopman, G Zuccon, ArXiv, abs/2401.063202024c</p>
<p>Autosurvey: Large language models can automatically write surveys. Yidong Wang, Qi Guo, Wenjin Yao, Hongbo Zhang, Xin Zhang, Zhen Wu, Meishan Zhang, Xinyu Dai, Qingsong Wen, Wei Ye, Advances in Neural Information Processing Systems. 2024d37</p>
<p>Chain-of-thought prompting elicits reasoning in large language models. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Denny Quoc V Le, Zhou, Advances in neural information processing systems. 202235</p>
<p>Jason Wei, Zhiqing Sun, Spencer Papay, Scott Mckinney, Jeffrey Han, Isa Fulford, Hyung Won Chung, Alex Tachard Passos, William Fedus, Amelia Glaese, arXiv:2504.12516Browsecomp: A simple yet challenging benchmark for browsing agents. 2025arXiv preprint</p>
<p>Large language models are better reasoners with self-verification. Yixuan Weng, Minjun Zhu, Fei Xia, Bin Li, Shizhu He, Shengping Liu, Bin Sun, Kang Liu, Jun Zhao, arXiv:2212.095612022arXiv preprint</p>
<p>Cycleresearcher: Improving automated research via automated review. Yixuan Weng, Minjun Zhu, Guangsheng Bao, Hongbo Zhang, Jindong Wang, Yue Zhang, Linyi Yang, The Thirteenth International Conference on Learning Representations. 2025</p>
<p>. WestlakeNLP. Airaxiv. 2025</p>
<p>Pylabrobot: An open-source, hardware-agnostic interface for liquid-handling robots and accessories. Stefan M Rick P Wierenga, Wilson Golas, Connor W Ho, Kevin M Coley, Esvelt, Device12023</p>
<p>Lag: Llm agents for leaderboard auto generation on demanding. Jian Wu, Jiayu Zhang, Dongyuan Li, Linyi Yang, Aoxiao Zhong, Renhe Jiang, Qingsong Wen, Yue Zhang, arXiv:2502.182092025arXiv preprint</p>
<p>Automated review generation method based on large language models. Shican Wu, Xiao Ma, Dehui Luo, Lulu Li, Xiangcheng Shi, Xin Chang, Xiaoyun Lin, Ran Luo, Chunlei Pei, Changying Du, arXiv:2407.209062024arXiv preprint</p>
<p>Yanzheng Xiang, Hanqi Yan, Shuyin Ouyang, Lin Gui, Yulan He, arXiv:2504.00255Scireplicate-bench: Benchmarking llms in agent-driven algorithmic reproduction from research papers. 2025arXiv preprint</p>
<p>An empirical analysis of uncertainty in large language model evaluations. Qiujie Xie, Qingqiu Li, Zhuohao Yu, Yuejie Zhang, Yue Zhang, Linyi Yang, The Thirteenth International Conference on Learning Representations. 2025</p>
<p>The ai scientist-v2: Workshop-level automated scientific discovery via agentic tree search. Yutaro Yamada, Robert Tjarko Lange, Cong Lu, Shengran Hu, Chris Lu, Jakob Foerster, Jeff Clune, David Ha, arXiv:2504.080662025arXiv preprint</p>
<p>TELIN: Table entity LINker for extracting leaderboards from machine learning publications. Sean Yang, Chris Tensmeyer, Curtis Wigington, 10.18653/v1/2022.wiesp-1.3Proceedings of the first Workshop on Information Extraction from Scientific Publications. Tirthankar Ghosal, Sergi Blanco-Cuaresma, Alberto Accomazzi, Robert M Patton, Felix Grezes, Thomas Allen, the first Workshop on Information Extraction from Scientific PublicationsAssociation for Computational LinguisticsNovember 2022</p>
<p>Airalogy: Ai-empowered universal data digitization for research automation. Zijie Yang, Yukai Wang, Lijing Zhang ; Zijie, Qiji Yang, Fang Zhou, Sijie Guo, Yexun Zhang, Jinglei Xi, Yudian Nie, Liping Zhu, Chou Huang, Yonghe Wu, Xiaoyu Xia, Yingming Ma, Panzhong Pu, Junshu Lu, Mingtao Pan, Tiannan Chen, Yanmei Guo, Hongyu Dou, Anping Chen, Jiaxing Zeng, Tian Huang, Yue Xu, Zhang, bioRxiv. 2023. 2025aAi becomes a masterbrain scientist</p>
<p>Large language models for automated open-domain scientific hypotheses discovery. Zonglin Yang, Xinya Du, Junxian Li, Jie Zheng, Soujanya Poria, Erik Cambria, Findings of the Association for Computational Linguistics ACL 2024. 2024</p>
<p>MOOSE-chem: Large language models for rediscovering unseen chemistry scientific hypotheses. Zonglin Yang, Wanhao Liu, Ben Gao, Tong Xie, Yuqiang Li, Wanli Ouyang, Soujanya Poria, Erik Cambria, Dongzhan Zhou, The Thirteenth International Conference on Learning Representations. 2025b</p>
<p>Extracting knowledge from scientific texts on patient-derived cancer models using large language models: algorithm development and validation. Jiarui Yao, Zinaida Perova, Tushar Mandloi, Elizabeth Lewis, Helen Parkinson, Guergana Savova, bioRxiv. 2025</p>
<p>Are we there yet? revealing the risks of utilizing large language models in scholarly peer review. Rui Ye, Xianghe Pang, Jingyi Chai, Jiaao Chen, Zhenfei Yin, Zhen Xiang, Xiaowen Dong, Jing Shao, Siheng Chen, arXiv:2412.017082024arXiv preprint</p>
<p>Mcx-llm: an experiment in bridging natural language problem descriptions with quantitative scientific simulations. Fan-Yu Yen, Qianqian Fang ; Translational, Microscopy, Oct, Brain ) Ots, Optica Biophotonics Congress: Biomedical Optics. 2707466552024. 2024</p>
<p>Knowledge integration and decision support for accelerated discovery of antibiotic resistance genes. Jason Youn, Navneet Rai, Ilias Tagkopoulos, Nature Communications. 13123602022</p>
<p>Haofei Yu, Zhaochen Hong, Zirui Cheng, Kunlun Zhu, Keyang Xuan, Jinwei Yao, arXiv:2412.17767Tao Feng, and Jiaxuan You. Researchtown: Simulator of human research community. 2024arXiv preprint</p>
<p>Is your paper being reviewed by an llm? a new benchmark dataset and approach for detecting ai text in peer review. Sungduk Yu, Man Luo, Avinash Madusu, Vasudev Lal, Phillip Howard, arXiv:2502.196142025arXiv preprint</p>
<p>Dolphin: Closed-loop open-ended auto-research through thinking, practice, and feedback. Jiakang Yuan, Xiangchao Yan, Botian Shi, Tao Chen, Wanli Ouyang, Bo Zhang, Lei Bai, Yu Qiao, Bowen Zhou, arXiv:2501.039162025arXiv preprint</p>
<p>Can we automate scientific reviewing. Weizhe Yuan, Pengfei Liu, Graham Neubig, Journal of Artificial Intelligence Research. 752022</p>
<p>Appraising the potential uses and harms of llms for medical systematic reviews. Hye Sun Yun, Iain J Marshall, Thomas A Trikalinos, Byron C Wallace, arXiv:2305.118282023arXiv preprint</p>
<p>Star: Bootstrapping reasoning with reasoning. Eric Zelikman, Yuhuai Wu, Jesse Mu, Noah Goodman, Advances in Neural Information Processing Systems. 202235</p>
<p>Scientific opinion summarization: Paper meta-review generation dataset, methods, and evaluation. Qi Zeng, Mankeerat Sidhu, Pong Hou, Lu Chan, Heng Wang, Ji, AI4Research/DemocrAI@IJCAI. 2023</p>
<p>Repocoder: Repository-level code completion through iterative retrieval and generation. Fengji Zhang, B Chen, Yue Zhang, Jin Liu, Daoguang Zan, Yi Mao, Jian-Guang Lou, Weizhu Chen, Conference on Empirical Methods in Natural Language Processing. 2023</p>
<p>Investigating fairness disparities in peer review: A language model enhanced approach. Jiayao Zhang, Hongming Zhang, Zhun Deng, Dan Roth, ArXiv, abs/2211.063982022253499393</p>
<p>Codeagent: Enhancing code generation with toolintegrated agent systems for real-world repo-level coding challenges. Kechi Zhang, Jia Li, Ge Li, Xianjie Shi, Zhi Jin, Annual Meeting of the Association for Computational Linguistics. 2024a</p>
<p>A comprehensive survey of scientific large language models and their applications in scientific discovery. Yu Zhang, Xiusi Chen, Bowen Jin, Sheng Wang, Shuiwang Ji, Wei Wang, Jiawei Han, arXiv:2406.108332024barXiv preprint</p>
<p>Siren's song in the ai ocean: A survey on hallucination in large language models. Yue Zhang, Yafu Li, Leyang Cui, Deng Cai, Lemao Liu, Tingchen Fu, Xinting Huang, Enbo Zhao, Yu Zhang, Yulong Chen, Computational Linguistics. 2025</p>
<p>Chain of agents: Large language models collaborating on long-context tasks. Yusen Zhang, Ruoxi Sun, Yanfei Chen, Tomas Pfister, Rui Zhang, Sercan Arik, Advances in Neural Information Processing Systems. 2024c37</p>
<p>Judging llm-as-a-judge with mt-bench and chatbot arena. Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric Xing, Advances in Neural Information Processing Systems. 202336</p>
<p>From automation to autonomy: A survey on large language models in scientific discovery. Tianshi Zheng, Zheye Deng, Hong Ting Tsang, Weiqi Wang, Jiaxin Bai, Zihao Wang, Yangqiu Song, arXiv:2505.132592025arXiv preprint</p>
<p>Large language models penetration in scholarly writing and peer review. Li Zhou, Ruijie Zhang, Xunlian Dai, Daniel Hershcovich, Haizhou Li, ArXiv, abs/2502.111932025a</p>
<p>Is llm a reliable reviewer? a comprehensive evaluation of llm on automatic paper reviewing tasks. Ruiyang Zhou, Lu Chen, Kai Yu, International Conference on Language Resources and Evaluation. 2024a</p>
<p>Is LLM a reliable reviewer? a comprehensive evaluation of LLM on automatic paper reviewing tasks. Ruiyang Zhou, Lu Chen, Kai Yu, Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024). Nicoletta Calzolari, Min-Yen Kan, Veronique Hoste, Alessandro Lenci, Sakriani Sakti, Nianwen Xue, the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)Torino, ItaliaMay 2024bELRA and ICCL</p>
<p>From hypothesis to publication: A comprehensive survey of ai-driven research support systems. Zekun Zhou, Xiaocheng Feng, Lei Huang, Xiachong Feng, Ziyun Song, Ruihan Chen, Liang Zhao, Weitao Ma, Yuxuan Gu, Baoxin Wang, arXiv:2503.014242025barXiv preprint</p>
<p>Deepreview: Improving llm-based paper review with human-like deep thinking process. Minjun Zhu, Yixuan Weng, Linyi Yang, Yue Zhang, arXiv:2503.085692025arXiv preprint</p>
<p>Large language models for automated scholarly paper review: A survey. Zhenzhen Zhuang, Jiandong Chen, Hongfeng Xu, Yuwen Jiang, Jialiang Lin, arXiv:2501.103262025arXiv preprint</p>            </div>
        </div>

    </div>
</body>
</html>