<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-8577 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-8577</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-8577</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-154.html">extraction-schema-154</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being evaluated on strict logical reasoning tasks, including details about the models, the logical reasoning tasks or benchmarks, the methods or approaches used to improve logical reasoning, the performance or results, comparisons to baselines or ablations, and any reported limitations or failure cases.</div>
                <p><strong>Paper ID:</strong> paper-721a09d68364aef489fa593b446923df4c6df8f2</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/721a09d68364aef489fa593b446923df4c6df8f2" target="_blank">RobustLR: A Diagnostic Benchmark for Evaluating Logical Robustness of Deductive Reasoners</a></p>
                <p><strong>Paper Venue:</strong> Conference on Empirical Methods in Natural Language Processing</p>
                <p><strong>Paper TL;DR:</strong> RobustLR, a diagnostic benchmark that evaluates the robustness of language models to minimal logical edits in the inputs and different logical equivalence conditions, is presented and it is observed that the models trained on deductive reasoning datasets find it especially hard to learn logical negation operators.</p>
                <p><strong>Paper Abstract:</strong> Transformers have been shown to be able to perform deductive reasoning on inputs containing rules and statements written in the English natural language. However, it is unclear if these models indeed follow rigorous logical reasoning to arrive at the prediction or rely on spurious correlation patterns in making decisions. A strong deductive reasoning model should consistently understand the semantics of different logical operators. To this end, we present RobustLR, a diagnostic benchmark that evaluates the robustness of language models to minimal logical edits in the inputs and different logical equivalence conditions. In our experiments with RoBERTa, T5, and GPT3 we show that the models trained on deductive reasoning datasets do not perform consistently on the RobustLR test set, thus showing that the models are not robust to our proposed logical perturbations. Further, we observe that the models find it especially hard to learn logical negation operators. Our results demonstrate the shortcomings of current language models in logical reasoning and call for the development of better inductive biases to teach the logical semantics to language models. All the datasets and code base have been made publicly available.</p>
                <p><strong>Cost:</strong> 0.016</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e8577.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e8577.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being evaluated on strict logical reasoning tasks, including details about the models, the logical reasoning tasks or benchmarks, the methods or approaches used to improve logical reasoning, the performance or results, comparisons to baselines or ablations, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RoBERTa-Large</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>RoBERTa-Large (pretrained checkpoint)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A pretrained RoBERTa-Large transformer encoder fine-tuned as a 3-class classifier for deductive reasoning; used with [CLS] embedding to predict True/False/Unknown entailment labels.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>RobustLR: A Diagnostic Benchmark for Evaluating Logical Robustness of Deductive Reasoners</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>RoBERTa-Large</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Pretrained RoBERTa-Large encoder (HuggingFace checkpoint) used in a classification setup: input format [CLS] T [SEP] s [SEP], extract [CLS] embedding and fine-tune with cross-entropy on synthetic deductive reasoning datasets (NOT, AND+NOT, OR+NOT, All).</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>RoBERTa-Large (as named in paper)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_name</strong></td>
                            <td>RobustLR (Logical Contrast set and Logical Equivalence set) / deductive reasoning (3-way entailment: True/False/Unknown)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_description</strong></td>
                            <td>Synthetic deductive-reasoning evaluation on theories of facts and rules expressed in English templates; Logical Contrast set tests minimal logical edits (conjunction, disjunction, negation); Logical Equivalence set tests paraphrases via logical equivalences (contrapositive, distributive laws). Evaluation metric: weighted-F1 at the theory level.</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_approach</strong></td>
                            <td>Fine-tuning from pretrained RoBERTa-Large on synthetic deductive reasoning training sets (NOT, AND+NOT, OR+NOT, All); evaluation on RobustLR contrast and equivalence test sets.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Logical Contrast average weighted-F1 ≈ 0.47 (table 5); breakdown by subset (avg over training datasets shown in Table 2 and Table 5): C-CS/D-CS/N-CS averages ~0.44 / 0.61 / 0.37; Logical Equivalence average weighted-F1 ≈ 0.76 (Table 5). In-domain (held-out) performance near 1.00 (Table 3), showing strong in-distribution but weak robustness.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Pretrained RoBERTa-Large fine-tuned vs. same architecture trained from scratch: pretrained checkpoint far superior (from-scratch Logical Contrast avg 0.14 vs. RoBERTa-Large 0.47; Logical Equivalence 0.45 vs. 0.76). Compared to larger T5 variants, RoBERTa is weaker than T5-3B/T5-11B on Contrast but comparable on some Equivalence subsets. Human performance much higher (Contrast avg 0.88, Equivalence 0.91).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Struggles with logical robustness: sensitive to minimal logical edits; especially poor on negation-related contrast perturbations (N-CS) and on contrapositive equivalence (C-ES) where negation interactions appear; performance drops when distractor facts are present; in-distribution near-perfect performance indicates reliance on spurious patterns rather than robust logical semantics.</td>
                        </tr>
                        <tr>
                            <td><strong>insights_or_conclusions</strong></td>
                            <td>Pretraining provides crucial knowledge (from-scratch fails). Fine-tuning on operator-aligned training data helps (e.g., OR+NOT improves disjunction contrast), but RoBERTa-Large still fails to robustly learn negation semantics; calls for better inductive biases, retrieval handling, and training targeted at operator semantics.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'RobustLR: A Diagnostic Benchmark for Evaluating Logical Robustness of Deductive Reasoners', 'publication_date_yy_mm': '2022-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8577.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e8577.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being evaluated on strict logical reasoning tasks, including details about the models, the logical reasoning tasks or benchmarks, the methods or approaches used to improve logical reasoning, the performance or results, comparisons to baselines or ablations, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>T5-Large</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>T5-Large (encoder-decoder text-to-text)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A pretrained T5-Large text-to-text transformer fine-tuned to generate a fixed-answer template (True/False/Unknown) for deductive reasoning tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>RobustLR: A Diagnostic Benchmark for Evaluating Logical Robustness of Deductive Reasoners</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>T5-Large</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Pretrained T5-Large encoder-decoder (text-to-text) fine-tuned on synthetic deductive reasoning datasets using a prompt: "$answer$ ; $question$ = s ; $context$ = T" and trained to generate "$answer$ = True/False/Unknown" using standard LM loss.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>T5-Large (as named in paper)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_name</strong></td>
                            <td>RobustLR (Logical Contrast set and Logical Equivalence set) / deductive reasoning (3-way entailment)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_description</strong></td>
                            <td>Same RobustLR synthetic deductive-reasoning evaluation probing minimal logical edits and logical equivalences, evaluated with weighted-F1.</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_approach</strong></td>
                            <td>Fine-tuning T5-Large on the NOT, AND+NOT, OR+NOT, or All synthetic training datasets; prefix-based text-to-text formulation for classification. Evaluated on contrast and equivalence sets.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Logical Contrast average weighted-F1 ≈ 0.46 (Table 5); Logical Equivalence average weighted-F1 ≈ 0.89 (Table 5). In-distribution held-out near 0.99 (Table 3).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared to RoBERTa-Large, T5-Large achieves similar or slightly different performance (T5-Large better on equivalence tasks). Larger T5 variants (T5-3B, T5-11B) generally outperform T5-Large on Contrast; humans outperform all models. Training on operator-aligned datasets improves per-operator performance.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Finds negation-based perturbations hard (drops in N-CS and contrapositive C-ES); performance gap between in-distribution and RobustLR indicates reliance on spurious cues; Unknown label is challenging for smaller models; distractors and retrieval confound performance.</td>
                        </tr>
                        <tr>
                            <td><strong>insights_or_conclusions</strong></td>
                            <td>T5 text-to-text fine-tuning can learn to map theories to entailment labels but still fails to be logically robust under minimal logical perturbations, esp. negation; larger model capacity and operator-aligned training improve results but do not close gap to humans.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'RobustLR: A Diagnostic Benchmark for Evaluating Logical Robustness of Deductive Reasoners', 'publication_date_yy_mm': '2022-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8577.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e8577.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being evaluated on strict logical reasoning tasks, including details about the models, the logical reasoning tasks or benchmarks, the methods or approaches used to improve logical reasoning, the performance or results, comparisons to baselines or ablations, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>T5-3B</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>T5-3B (pretrained, 3B-parameter variant as named)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A large T5 variant (3B naming in paper) fine-tuned in the same text-to-text fashion for deductive reasoning; shows improved robustness on some RobustLR subsets, especially Unknown label.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>RobustLR: A Diagnostic Benchmark for Evaluating Logical Robustness of Deductive Reasoners</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>T5-3B</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Pretrained T5-3B checkpoint used with same input/output templating as T5-Large and fine-tuned on synthetic deductive reasoning datasets (NOT, AND+NOT, OR+NOT, All).</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>T5-3B (as named in paper)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_name</strong></td>
                            <td>RobustLR (Logical Contrast & Logical Equivalence sets)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_description</strong></td>
                            <td>Synthetic deductive-reasoning classification (True/False/Unknown); evaluates logical operator semantics via minimal edits and logical equivalences; weighted-F1 metric.</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_approach</strong></td>
                            <td>Fine-tuning of T5-3B on the synthetic training sets; evaluation on RobustLR contrast and equivalence sets.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Logical Contrast average weighted-F1 ≈ 0.58 (Table 5), with subset breakdowns showing better Unknown-label handling; Logical Equivalence average weighted-F1 ≈ 0.84 (Table 5). In-distribution performance high (~0.97-0.99, Table 3 for other T5s).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Outperforms T5-Large and RoBERTa-Large on many RobustLR Contrast subsets (esp. Unknown label), but still below human performance; T5-11B sometimes further improves on Contrast relative to T5-3B.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Still struggles with negation robustness and some compound rule perturbations (CONJ+NEG, DISJ+NEG); presence of distractors reduces performance; gap remains relative to human annotators.</td>
                        </tr>
                        <tr>
                            <td><strong>insights_or_conclusions</strong></td>
                            <td>Scaling to larger T5 improves some aspects of logical robustness (notably Unknown prediction), but does not fully resolve weaknesses in negation and minimal-perturbation consistency; suggests capacity helps but specialized inductive biases or training are required.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'RobustLR: A Diagnostic Benchmark for Evaluating Logical Robustness of Deductive Reasoners', 'publication_date_yy_mm': '2022-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8577.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e8577.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being evaluated on strict logical reasoning tasks, including details about the models, the logical reasoning tasks or benchmarks, the methods or approaches used to improve logical reasoning, the performance or results, comparisons to baselines or ablations, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>T5-11B</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>T5-11B (pretrained, 11B variant as named)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A very large T5 variant fine-tuned on the All training dataset (two epochs due to compute) that yields the best Contrast performance among evaluated checkpoints but remains far from human-level robustness.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>RobustLR: A Diagnostic Benchmark for Evaluating Logical Robustness of Deductive Reasoners</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>T5-11B</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Pretrained T5-11B used with the same text-to-text prompt-format and fine-tuned on the All synthetic training dataset for two epochs (compute-constrained).</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>T5-11B (as named in paper)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_name</strong></td>
                            <td>RobustLR (Logical Contrast & Logical Equivalence sets)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_description</strong></td>
                            <td>Deductive reasoning classification probing minimal logical edits and equivalences (conjunction, disjunction, negation; contrapositive and distributive equivalences); evaluated with weighted-F1.</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_approach</strong></td>
                            <td>Fine-tuning at scale (T5-11B) on the All training dataset and evaluation on RobustLR subsets.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Logical Contrast average weighted-F1 ≈ 0.61 (Table 5) with subset breakdown C-CS 0.57, D-CS 0.67, N-CS 0.58; Logical Equivalence average weighted-F1 ≈ 0.83. Improves over smaller checkpoints but still lags humans (Contrast 0.88).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Outperforms T5-3B and T5-Large on many Contrast measures; still below human annotators. Pretraining matters (from-scratch far worse). Scaling yields gains but with diminishing returns.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Although largest model shows best robustness among evaluated LMs, it still fails systematically on negation and some contrast perturbations; gap to humans (~0.27 on Contrast) remains; compute constraints limited breadth of experiments (only finetuned on All).</td>
                        </tr>
                        <tr>
                            <td><strong>insights_or_conclusions</strong></td>
                            <td>Scaling model size improves logical robustness to an extent, but does not eliminate issues of failing logical consistency (especially negation); indicates scaling alone is insufficient—architectural or training inductive biases may be required.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'RobustLR: A Diagnostic Benchmark for Evaluating Logical Robustness of Deductive Reasoners', 'publication_date_yy_mm': '2022-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8577.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e8577.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being evaluated on strict logical reasoning tasks, including details about the models, the logical reasoning tasks or benchmarks, the methods or approaches used to improve logical reasoning, the performance or results, comparisons to baselines or ablations, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-3 (in-context)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-3 (few-shot, in-context learning, API evaluation)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>GPT-3 was evaluated via in-context learning with a few demonstrations (3) and NLI-style prompts to assess zero/few-shot deductive reasoning robustness on RobustLR subsets without fine-tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>RobustLR: A Diagnostic Benchmark for Evaluating Logical Robustness of Deductive Reasoners</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>GPT-3 (accessed via OpenAI API) evaluated with in-context learning (3 demonstrations per query), using a prompt 'Based on the previous passage, is it true that "{hypothesis}"? Yes or no?' with answer choices Yes/Maybe/No mapped to True/Unknown/False.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>GPT-3 (as named in paper; exact parameter count not specified in paper)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_name</strong></td>
                            <td>RobustLR (subset evaluation via in-context demonstrations on Contrast and Equivalence sets)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_description</strong></td>
                            <td>Deductive reasoning evaluation with Synthetic theories and statements; GPT-3 was not fine-tuned and was tested on subsets (500 samples per test subset) using few-shot prompts.</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_approach</strong></td>
                            <td>In-context learning with 3 demonstrations (also tried 10, similar results) and selected NLI-style prompt; no fine-tuning was performed.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Reported averaged performance in Table 5: Logical Contrast average weighted-F1 ≈ 0.36; Logical Equivalence average weighted-F1 ≈ 0.67 (evaluated on 500 samples per subset). Lower than fine-tuned T5 models and far below human performance.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Performs worse than fine-tuned T5-3B/T5-Large/T5-11B on Contrast; better than a randomly initialized model but inferior to supervised fine-tuned checkpoints. Likely harmed by distribution mismatch and lack of fine-tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Poor robustness to minimal logical perturbations and logical paraphrases in absence of task-specific fine-tuning; struggles especially on negation-heavy perturbations; results likely limited by mismatch between GPT-3 pretraining distribution and synthetic RobustLR data.</td>
                        </tr>
                        <tr>
                            <td><strong>insights_or_conclusions</strong></td>
                            <td>In-context learning with GPT-3 is insufficient to achieve logical robustness on synthetic deductive reasoning tasks; fine-tuning and aligned operator-exposure appear necessary to improve performance.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'RobustLR: A Diagnostic Benchmark for Evaluating Logical Robustness of Deductive Reasoners', 'publication_date_yy_mm': '2022-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8577.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e8577.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being evaluated on strict logical reasoning tasks, including details about the models, the logical reasoning tasks or benchmarks, the methods or approaches used to improve logical reasoning, the performance or results, comparisons to baselines or ablations, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>From-scratch RoBERTa</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>RoBERTa architecture trained from random initialization (no pretraining)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A RoBERTa-Large architecture trained from scratch on the synthetic All dataset to probe the importance of pretraining for deductive reasoning tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>RobustLR: A Diagnostic Benchmark for Evaluating Logical Robustness of Deductive Reasoners</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>RoBERTa (trained from scratch)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Same RoBERTa-Large architecture but initialized randomly (no pretrained weights) and trained on the All synthetic dataset to compare with the pretrained checkpoint.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>RoBERTa-Large (trained from scratch)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_name</strong></td>
                            <td>RobustLR (Logical Contrast & Logical Equivalence sets)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_description</strong></td>
                            <td>Deductive reasoning classification task, evaluated for robustness under contrast and equivalence perturbations.</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_approach</strong></td>
                            <td>Training the model from random initialization on the All dataset and evaluating on RobustLR sets to measure pretraining contribution.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Logical Contrast average weighted-F1 ≈ 0.14; Logical Equivalence average weighted-F1 ≈ 0.45 (Table 5). Very poor compared to pretrained RoBERTa-Large.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Significantly worse than pretrained RoBERTa-Large (contrast: 0.14 vs 0.47; equivalence: 0.45 vs 0.76), demonstrating strong benefit of pretraining for these tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Training from scratch fails to reach reasonable logical-reasoning performance even with access to the synthetic training data; indicates reliance on pretraining for general knowledge and linguistic structure.</td>
                        </tr>
                        <tr>
                            <td><strong>insights_or_conclusions</strong></td>
                            <td>Pretraining provides crucial inductive biases and knowledge necessary for the models to perform deductive-reasoning tasks; starting from scratch is insufficient for robust logical reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'RobustLR: A Diagnostic Benchmark for Evaluating Logical Robustness of Deductive Reasoners', 'publication_date_yy_mm': '2022-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Transformers as soft reasoners over language <em>(Rating: 2)</em></li>
                <li>ProofWriter: Generating implications, proofs, and abductive statements over natural language <em>(Rating: 2)</em></li>
                <li>On the paradox of learning to reason from data <em>(Rating: 2)</em></li>
                <li>FaiRR: Faithful and robust deductive reasoning over natural language <em>(Rating: 2)</em></li>
                <li>ReClor: A reading comprehension dataset requiring logical reasoning <em>(Rating: 1)</em></li>
                <li>LogiQA: A challenge dataset for machine reading comprehension with logical reasoning <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-8577",
    "paper_id": "paper-721a09d68364aef489fa593b446923df4c6df8f2",
    "extraction_schema_id": "extraction-schema-154",
    "extracted_data": [
        {
            "name_short": "RoBERTa-Large",
            "name_full": "RoBERTa-Large (pretrained checkpoint)",
            "brief_description": "A pretrained RoBERTa-Large transformer encoder fine-tuned as a 3-class classifier for deductive reasoning; used with [CLS] embedding to predict True/False/Unknown entailment labels.",
            "citation_title": "RobustLR: A Diagnostic Benchmark for Evaluating Logical Robustness of Deductive Reasoners",
            "mention_or_use": "use",
            "model_name": "RoBERTa-Large",
            "model_description": "Pretrained RoBERTa-Large encoder (HuggingFace checkpoint) used in a classification setup: input format [CLS] T [SEP] s [SEP], extract [CLS] embedding and fine-tune with cross-entropy on synthetic deductive reasoning datasets (NOT, AND+NOT, OR+NOT, All).",
            "model_size": "RoBERTa-Large (as named in paper)",
            "reasoning_task_name": "RobustLR (Logical Contrast set and Logical Equivalence set) / deductive reasoning (3-way entailment: True/False/Unknown)",
            "reasoning_task_description": "Synthetic deductive-reasoning evaluation on theories of facts and rules expressed in English templates; Logical Contrast set tests minimal logical edits (conjunction, disjunction, negation); Logical Equivalence set tests paraphrases via logical equivalences (contrapositive, distributive laws). Evaluation metric: weighted-F1 at the theory level.",
            "method_or_approach": "Fine-tuning from pretrained RoBERTa-Large on synthetic deductive reasoning training sets (NOT, AND+NOT, OR+NOT, All); evaluation on RobustLR contrast and equivalence test sets.",
            "performance": "Logical Contrast average weighted-F1 ≈ 0.47 (table 5); breakdown by subset (avg over training datasets shown in Table 2 and Table 5): C-CS/D-CS/N-CS averages ~0.44 / 0.61 / 0.37; Logical Equivalence average weighted-F1 ≈ 0.76 (Table 5). In-domain (held-out) performance near 1.00 (Table 3), showing strong in-distribution but weak robustness.",
            "baseline_comparison": "Pretrained RoBERTa-Large fine-tuned vs. same architecture trained from scratch: pretrained checkpoint far superior (from-scratch Logical Contrast avg 0.14 vs. RoBERTa-Large 0.47; Logical Equivalence 0.45 vs. 0.76). Compared to larger T5 variants, RoBERTa is weaker than T5-3B/T5-11B on Contrast but comparable on some Equivalence subsets. Human performance much higher (Contrast avg 0.88, Equivalence 0.91).",
            "limitations_or_failures": "Struggles with logical robustness: sensitive to minimal logical edits; especially poor on negation-related contrast perturbations (N-CS) and on contrapositive equivalence (C-ES) where negation interactions appear; performance drops when distractor facts are present; in-distribution near-perfect performance indicates reliance on spurious patterns rather than robust logical semantics.",
            "insights_or_conclusions": "Pretraining provides crucial knowledge (from-scratch fails). Fine-tuning on operator-aligned training data helps (e.g., OR+NOT improves disjunction contrast), but RoBERTa-Large still fails to robustly learn negation semantics; calls for better inductive biases, retrieval handling, and training targeted at operator semantics.",
            "uuid": "e8577.0",
            "source_info": {
                "paper_title": "RobustLR: A Diagnostic Benchmark for Evaluating Logical Robustness of Deductive Reasoners",
                "publication_date_yy_mm": "2022-05"
            }
        },
        {
            "name_short": "T5-Large",
            "name_full": "T5-Large (encoder-decoder text-to-text)",
            "brief_description": "A pretrained T5-Large text-to-text transformer fine-tuned to generate a fixed-answer template (True/False/Unknown) for deductive reasoning tasks.",
            "citation_title": "RobustLR: A Diagnostic Benchmark for Evaluating Logical Robustness of Deductive Reasoners",
            "mention_or_use": "use",
            "model_name": "T5-Large",
            "model_description": "Pretrained T5-Large encoder-decoder (text-to-text) fine-tuned on synthetic deductive reasoning datasets using a prompt: \"$answer$ ; $question$ = s ; $context$ = T\" and trained to generate \"$answer$ = True/False/Unknown\" using standard LM loss.",
            "model_size": "T5-Large (as named in paper)",
            "reasoning_task_name": "RobustLR (Logical Contrast set and Logical Equivalence set) / deductive reasoning (3-way entailment)",
            "reasoning_task_description": "Same RobustLR synthetic deductive-reasoning evaluation probing minimal logical edits and logical equivalences, evaluated with weighted-F1.",
            "method_or_approach": "Fine-tuning T5-Large on the NOT, AND+NOT, OR+NOT, or All synthetic training datasets; prefix-based text-to-text formulation for classification. Evaluated on contrast and equivalence sets.",
            "performance": "Logical Contrast average weighted-F1 ≈ 0.46 (Table 5); Logical Equivalence average weighted-F1 ≈ 0.89 (Table 5). In-distribution held-out near 0.99 (Table 3).",
            "baseline_comparison": "Compared to RoBERTa-Large, T5-Large achieves similar or slightly different performance (T5-Large better on equivalence tasks). Larger T5 variants (T5-3B, T5-11B) generally outperform T5-Large on Contrast; humans outperform all models. Training on operator-aligned datasets improves per-operator performance.",
            "limitations_or_failures": "Finds negation-based perturbations hard (drops in N-CS and contrapositive C-ES); performance gap between in-distribution and RobustLR indicates reliance on spurious cues; Unknown label is challenging for smaller models; distractors and retrieval confound performance.",
            "insights_or_conclusions": "T5 text-to-text fine-tuning can learn to map theories to entailment labels but still fails to be logically robust under minimal logical perturbations, esp. negation; larger model capacity and operator-aligned training improve results but do not close gap to humans.",
            "uuid": "e8577.1",
            "source_info": {
                "paper_title": "RobustLR: A Diagnostic Benchmark for Evaluating Logical Robustness of Deductive Reasoners",
                "publication_date_yy_mm": "2022-05"
            }
        },
        {
            "name_short": "T5-3B",
            "name_full": "T5-3B (pretrained, 3B-parameter variant as named)",
            "brief_description": "A large T5 variant (3B naming in paper) fine-tuned in the same text-to-text fashion for deductive reasoning; shows improved robustness on some RobustLR subsets, especially Unknown label.",
            "citation_title": "RobustLR: A Diagnostic Benchmark for Evaluating Logical Robustness of Deductive Reasoners",
            "mention_or_use": "use",
            "model_name": "T5-3B",
            "model_description": "Pretrained T5-3B checkpoint used with same input/output templating as T5-Large and fine-tuned on synthetic deductive reasoning datasets (NOT, AND+NOT, OR+NOT, All).",
            "model_size": "T5-3B (as named in paper)",
            "reasoning_task_name": "RobustLR (Logical Contrast & Logical Equivalence sets)",
            "reasoning_task_description": "Synthetic deductive-reasoning classification (True/False/Unknown); evaluates logical operator semantics via minimal edits and logical equivalences; weighted-F1 metric.",
            "method_or_approach": "Fine-tuning of T5-3B on the synthetic training sets; evaluation on RobustLR contrast and equivalence sets.",
            "performance": "Logical Contrast average weighted-F1 ≈ 0.58 (Table 5), with subset breakdowns showing better Unknown-label handling; Logical Equivalence average weighted-F1 ≈ 0.84 (Table 5). In-distribution performance high (~0.97-0.99, Table 3 for other T5s).",
            "baseline_comparison": "Outperforms T5-Large and RoBERTa-Large on many RobustLR Contrast subsets (esp. Unknown label), but still below human performance; T5-11B sometimes further improves on Contrast relative to T5-3B.",
            "limitations_or_failures": "Still struggles with negation robustness and some compound rule perturbations (CONJ+NEG, DISJ+NEG); presence of distractors reduces performance; gap remains relative to human annotators.",
            "insights_or_conclusions": "Scaling to larger T5 improves some aspects of logical robustness (notably Unknown prediction), but does not fully resolve weaknesses in negation and minimal-perturbation consistency; suggests capacity helps but specialized inductive biases or training are required.",
            "uuid": "e8577.2",
            "source_info": {
                "paper_title": "RobustLR: A Diagnostic Benchmark for Evaluating Logical Robustness of Deductive Reasoners",
                "publication_date_yy_mm": "2022-05"
            }
        },
        {
            "name_short": "T5-11B",
            "name_full": "T5-11B (pretrained, 11B variant as named)",
            "brief_description": "A very large T5 variant fine-tuned on the All training dataset (two epochs due to compute) that yields the best Contrast performance among evaluated checkpoints but remains far from human-level robustness.",
            "citation_title": "RobustLR: A Diagnostic Benchmark for Evaluating Logical Robustness of Deductive Reasoners",
            "mention_or_use": "use",
            "model_name": "T5-11B",
            "model_description": "Pretrained T5-11B used with the same text-to-text prompt-format and fine-tuned on the All synthetic training dataset for two epochs (compute-constrained).",
            "model_size": "T5-11B (as named in paper)",
            "reasoning_task_name": "RobustLR (Logical Contrast & Logical Equivalence sets)",
            "reasoning_task_description": "Deductive reasoning classification probing minimal logical edits and equivalences (conjunction, disjunction, negation; contrapositive and distributive equivalences); evaluated with weighted-F1.",
            "method_or_approach": "Fine-tuning at scale (T5-11B) on the All training dataset and evaluation on RobustLR subsets.",
            "performance": "Logical Contrast average weighted-F1 ≈ 0.61 (Table 5) with subset breakdown C-CS 0.57, D-CS 0.67, N-CS 0.58; Logical Equivalence average weighted-F1 ≈ 0.83. Improves over smaller checkpoints but still lags humans (Contrast 0.88).",
            "baseline_comparison": "Outperforms T5-3B and T5-Large on many Contrast measures; still below human annotators. Pretraining matters (from-scratch far worse). Scaling yields gains but with diminishing returns.",
            "limitations_or_failures": "Although largest model shows best robustness among evaluated LMs, it still fails systematically on negation and some contrast perturbations; gap to humans (~0.27 on Contrast) remains; compute constraints limited breadth of experiments (only finetuned on All).",
            "insights_or_conclusions": "Scaling model size improves logical robustness to an extent, but does not eliminate issues of failing logical consistency (especially negation); indicates scaling alone is insufficient—architectural or training inductive biases may be required.",
            "uuid": "e8577.3",
            "source_info": {
                "paper_title": "RobustLR: A Diagnostic Benchmark for Evaluating Logical Robustness of Deductive Reasoners",
                "publication_date_yy_mm": "2022-05"
            }
        },
        {
            "name_short": "GPT-3 (in-context)",
            "name_full": "GPT-3 (few-shot, in-context learning, API evaluation)",
            "brief_description": "GPT-3 was evaluated via in-context learning with a few demonstrations (3) and NLI-style prompts to assess zero/few-shot deductive reasoning robustness on RobustLR subsets without fine-tuning.",
            "citation_title": "RobustLR: A Diagnostic Benchmark for Evaluating Logical Robustness of Deductive Reasoners",
            "mention_or_use": "use",
            "model_name": "GPT-3",
            "model_description": "GPT-3 (accessed via OpenAI API) evaluated with in-context learning (3 demonstrations per query), using a prompt 'Based on the previous passage, is it true that \"{hypothesis}\"? Yes or no?' with answer choices Yes/Maybe/No mapped to True/Unknown/False.",
            "model_size": "GPT-3 (as named in paper; exact parameter count not specified in paper)",
            "reasoning_task_name": "RobustLR (subset evaluation via in-context demonstrations on Contrast and Equivalence sets)",
            "reasoning_task_description": "Deductive reasoning evaluation with Synthetic theories and statements; GPT-3 was not fine-tuned and was tested on subsets (500 samples per test subset) using few-shot prompts.",
            "method_or_approach": "In-context learning with 3 demonstrations (also tried 10, similar results) and selected NLI-style prompt; no fine-tuning was performed.",
            "performance": "Reported averaged performance in Table 5: Logical Contrast average weighted-F1 ≈ 0.36; Logical Equivalence average weighted-F1 ≈ 0.67 (evaluated on 500 samples per subset). Lower than fine-tuned T5 models and far below human performance.",
            "baseline_comparison": "Performs worse than fine-tuned T5-3B/T5-Large/T5-11B on Contrast; better than a randomly initialized model but inferior to supervised fine-tuned checkpoints. Likely harmed by distribution mismatch and lack of fine-tuning.",
            "limitations_or_failures": "Poor robustness to minimal logical perturbations and logical paraphrases in absence of task-specific fine-tuning; struggles especially on negation-heavy perturbations; results likely limited by mismatch between GPT-3 pretraining distribution and synthetic RobustLR data.",
            "insights_or_conclusions": "In-context learning with GPT-3 is insufficient to achieve logical robustness on synthetic deductive reasoning tasks; fine-tuning and aligned operator-exposure appear necessary to improve performance.",
            "uuid": "e8577.4",
            "source_info": {
                "paper_title": "RobustLR: A Diagnostic Benchmark for Evaluating Logical Robustness of Deductive Reasoners",
                "publication_date_yy_mm": "2022-05"
            }
        },
        {
            "name_short": "From-scratch RoBERTa",
            "name_full": "RoBERTa architecture trained from random initialization (no pretraining)",
            "brief_description": "A RoBERTa-Large architecture trained from scratch on the synthetic All dataset to probe the importance of pretraining for deductive reasoning tasks.",
            "citation_title": "RobustLR: A Diagnostic Benchmark for Evaluating Logical Robustness of Deductive Reasoners",
            "mention_or_use": "use",
            "model_name": "RoBERTa (trained from scratch)",
            "model_description": "Same RoBERTa-Large architecture but initialized randomly (no pretrained weights) and trained on the All synthetic dataset to compare with the pretrained checkpoint.",
            "model_size": "RoBERTa-Large (trained from scratch)",
            "reasoning_task_name": "RobustLR (Logical Contrast & Logical Equivalence sets)",
            "reasoning_task_description": "Deductive reasoning classification task, evaluated for robustness under contrast and equivalence perturbations.",
            "method_or_approach": "Training the model from random initialization on the All dataset and evaluating on RobustLR sets to measure pretraining contribution.",
            "performance": "Logical Contrast average weighted-F1 ≈ 0.14; Logical Equivalence average weighted-F1 ≈ 0.45 (Table 5). Very poor compared to pretrained RoBERTa-Large.",
            "baseline_comparison": "Significantly worse than pretrained RoBERTa-Large (contrast: 0.14 vs 0.47; equivalence: 0.45 vs 0.76), demonstrating strong benefit of pretraining for these tasks.",
            "limitations_or_failures": "Training from scratch fails to reach reasonable logical-reasoning performance even with access to the synthetic training data; indicates reliance on pretraining for general knowledge and linguistic structure.",
            "insights_or_conclusions": "Pretraining provides crucial inductive biases and knowledge necessary for the models to perform deductive-reasoning tasks; starting from scratch is insufficient for robust logical reasoning.",
            "uuid": "e8577.5",
            "source_info": {
                "paper_title": "RobustLR: A Diagnostic Benchmark for Evaluating Logical Robustness of Deductive Reasoners",
                "publication_date_yy_mm": "2022-05"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Transformers as soft reasoners over language",
            "rating": 2,
            "sanitized_title": "transformers_as_soft_reasoners_over_language"
        },
        {
            "paper_title": "ProofWriter: Generating implications, proofs, and abductive statements over natural language",
            "rating": 2,
            "sanitized_title": "proofwriter_generating_implications_proofs_and_abductive_statements_over_natural_language"
        },
        {
            "paper_title": "On the paradox of learning to reason from data",
            "rating": 2,
            "sanitized_title": "on_the_paradox_of_learning_to_reason_from_data"
        },
        {
            "paper_title": "FaiRR: Faithful and robust deductive reasoning over natural language",
            "rating": 2,
            "sanitized_title": "fairr_faithful_and_robust_deductive_reasoning_over_natural_language"
        },
        {
            "paper_title": "ReClor: A reading comprehension dataset requiring logical reasoning",
            "rating": 1,
            "sanitized_title": "reclor_a_reading_comprehension_dataset_requiring_logical_reasoning"
        },
        {
            "paper_title": "LogiQA: A challenge dataset for machine reading comprehension with logical reasoning",
            "rating": 1,
            "sanitized_title": "logiqa_a_challenge_dataset_for_machine_reading_comprehension_with_logical_reasoning"
        }
    ],
    "cost": 0.015694,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>RobustLR: A Diagnostic Benchmark for Evaluating Logical Robustness of Deductive Reasoners</h1>
<p>Soumya Sanyal Zeyi Liao Xiang Ren<br>University of Southern California<br>{soumyasa, zeyiliao, xiangren}@usc.edu</p>
<h4>Abstract</h4>
<p>Transformers have been shown to be able to perform deductive reasoning on inputs containing rules and statements written in English natural language. However, it is unclear if these models indeed follow rigorous logical reasoning to arrive at the prediction, or rely on spurious correlation patterns in making decision. A strong deductive reasoning model should consistently understand the semantics of different logical operators. To this end, we present RobustLR, a deductive reasoning-based diagnostic benchmark that evaluates the robustness of language models to minimal logical edits in the inputs and different logical equivalence conditions. In our experiments with RoBERTa, T5, and GPT3, we show that the models trained on deductive reasoning datasets with various logical operations do not perform consistently on the RoBUSTLR test set, thus showing that the models are not robust to our proposed logical perturbations. Further, we observe that the models find it especially hard to learn logical negation operator. Our results demonstrate the shortcomings of current language models in logical reasoning, and call for the development of better inductive biases to teach the logical semantics to language models. All the datasets and code base have been made publicly available. ${ }^{1}$</p>
<h2>1 Introduction</h2>
<p>Building systems that can automatically reason over a given context to generate valid logical inferences is a long pursued goal within the field of AI (McCarthy, 1959; Rocktäschel and Riedel, 2017; Manhaeve et al., 2019). Recently, Clark et al. (2020) have shown that language models (Liu et al., 2019; Raffel et al., 2020) are able to emulate deductive reasoning on a logical rulebase (theory) containing rules and declarative statements written in natural language. While this is impressive, it is unclear if these models are able to perform logical</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: Overview of RobustLR. We expect a strong deductive reasoning model should be robust to logical variations in the input. Here, the model fails to understand the logical conjunction in second example and predicts the wrong entailment of the statement.
reasoning robustly by understanding the semantics of the logical operators and the different logical conditions involving such operators.</p>
<p>Logical reasoning is an important skill required in various NLP tasks such as NLI (Dagan et al., 2006), Question Answering (Yang et al., 2018a), Multi-turn Dialogue Reasoning (Cui et al., 2020), etc. Models used to solve such tasks may use spurious patterns to reach to the predictions, rather than following the intended logical reasoning process. Additionally, these models might only understand certain ways of expressing the inference knowledge (e.g., rules) and not possess systematic generalization (Gontier et al., 2020). Hence, it is important to ensure that language models can consistently use the logical operators when described in natural language. Prior works (Gururangan et al., 2018; Chen and Durrett, 2019; McCoy et al., 2019) have found that models solving different reasoning tasks tend to exploit spurious correlations between the context/question and the label. But logical reasoning needs special considerations as there are very well-defined relationships on how different logical operators modify any given context. Hence, it is important to understand if models use these logical relationships consistently to solve a task. To the best of our knowledge, a study evaluating a language model's logical consistency on different logical operations is currently missing.</p>
<p>A key desirable property of a strong deductive reasoning model is logical robustness. This is the ability to make consistent predictions on inputs that have some logical modifications. In Figure 1, we show how the lack of logical robustness can lead to wrong inferences in a model. Thus, to test this, we develop RobustLR, a diagnostic benchmark for evaluating logical robustness across two main aspects. First, we aim to evaluate how robust these models are when tested on the three logical operators: conjunction $(\wedge)$, disjunction $(\vee)$, and negation $(\neg)$. Inspired by the idea of contrast sets (Gardner et al., 2020), we design the Logical Contrast set, where theories are minimally modified so that we can test the model's robustness across logical operators. Examples of this are shown in Figure 3(b) and 3(c). Next, we study the model's ability of reasoning consistently across logical paraphrases. A logical paraphrase uses equivalence conditions in logic to replace a rule with another equivalent form, essentially rewriting the surface form of the rule. This poses a different challenge than the more common language paraphrases such as synonym changes, voice modifications, style changes, etc., because the model needs to understand that the underlying logical structure of the two paraphrased sentences mean the same thing. An example of the equivalence perturbation is shown in Figure 3(d). Based on this, we design the Logical Equivalence set containing three logical equivalences.</p>
<p>In this work, we study three language models: RoBERTa (Liu et al., 2019), T5 (Raffel et al., 2020), and GPT-3 (Brown et al., 2020). To test the model performance on RobustLR, we first finetune them on deductive reasoning training datasets containing the logical operators and then evaluate on the RobustLR test sets. Overall, we find that language models (LMs) fine-tuned on different deductive reasoning datasets are not sufficiently robust to the Logical Contrast and Logical Equivalence sets. Specifically, we find that models are more inconsistent with logical negations in sentences. We also find that using larger models such as T5-11B improves the performance to an extent, but they still perform worse compared to human performance on RobustLR. We show that it is partly due to spurious correlations in the data and the inherent difficulty of the task. Thus, we use RobustLR to demonstrate some key limitations of the language models trained for deductive reasoning. We hope that this research will encourage
as a test bed to evaluate robustness of deductive reasoning models.</p>
<h2>2 Deductive Reasoning</h2>
<p>In deductive reasoning, we predict whether a given theory $T$ supports a statement $s$ or not. We define a theory $T$ as a set of facts $F=\left{f_{1}, f_{2}, \ldots, f_{n}\right}$ and rules $R=\left{r_{1}, r_{2}, \ldots, r_{m}\right}$ expressed in natural language (See Figure 3 for an example). For a given theory, a statement can be either provably supported, provably unsupported (i.e., the negation of the statement is provable), or not provable at all. This is a 3-class classification problem, with the labels True, False, and Unknown, respectively. In this work, we focus on this task, where we expect the model to correctly predict the entailment of a statement for a given theory. In Figure 3(a), 3(c), and 3(d), the statement is entailed by the theory, leading to the label True while in Figure 3(b), the statement is not provable given the facts and rules. It can be proved by simply using fact $f_{1}$ and rule $r_{1}$ to derive the statement. Formally, we define the proof set of a statement $s$, denoted by $G(T, s)$, as the set of rules and facts that are required to obtain the statement $s$ from the theory.</p>
<h2>3 Evaluating LMs for Logical Robustness</h2>
<h3>3.1 Logical Robustness</h3>
<p>We consider a deductive reasoner (language model) to be logically robust if the model behavior is consistent across various logical perturbations, as illustrated in Figure 1. Specifically, we evaluate logical robustness on two types of perturbations.</p>
<p>Logical contrastive edits Here, we test the model's ability to correctly capture the semantics of different logical operators, when presented in minimally edited contrast inputs. A contrast set (Gardner et al., 2020) is one where the input is changed minimally, but meaningfully, such that there is (typically) some change in label. These probes test the LM's robustness to conjunction $(\wedge)$, disjunction $(\vee)$, and negation $(\neg)$.</p>
<p>Logical paraphrases Here, we evaluate whether the model performs consistently when shown the same input with different logical paraphrases. A theory can be logically paraphrased by modifying the rules using standard logical equivalence conditions. ${ }^{2}$ These probes evaluate the model's consis-</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" />
(b) Logical Form
Figure 2: Logical Form of a Theory. (a) A theory in natural language. (b). The corresponding logical form of the theory. Refer to Section 3.2 for more details.
tency in solving logically equivalent theories, when logical conditions are used to rewrite the input.</p>
<p>A strong deductive reasoning model should be robust to both the minimally edited contrast inputs and logical paraphrases. Overall, these evaluation sets probe a deductive reasoning model to check whether it indeed learns the semantics of the logical operators and their underlying working principles.</p>
<h3>3.2 Notations</h3>
<p>In this work, we consider two predicate forms: unary and binary. A unary predicate contains one argument and is denoted by $X(a)$. Similarly, a binary predicate is represented as $X(a, b)$. Here, $X$ is the predicate relation and $a, b$ are the variables. An atomic predicate is defined as either a predicate or the negation of the predicate (denoted as $\neg X(a)$ ). A complex predicate can contain multiple predicates (or their negated forms) combined using logical operators conjunction and disjunction.</p>
<p>Internally, we maintain a symbolic representation of these facts and rules, enabling us to later create the different evaluation sets of RobustLR. A fact is symbolically represented by a predicate. In this work, we consider all facts as atomic predicates. A rule is symbolically represented by a logical connection between predicates, separated by the "implies that" logical symbol ( $\Longrightarrow$ ). Thus, a rule can be defined as $p \Longrightarrow q$, where the LHS $p$ and RHS $q$ are atomic or complex predicates. If both $p$ and $q$ consist of atomic predicates, then the rule is called a simple rule. A compound rule is one where $p$ and/or $q$ contain some complex predicates connected by the conjunction or disjunction operator. An example of a natural language theory and its corresponding logical form is shown in Figure 2. Here, facts $f_{1}$ and $f_{2}$ are unary atomic and binary predicates, respectively. Rule $r_{1}$ is a compound</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Modified Rule</th>
<th style="text-align: center;">Facts</th>
<th style="text-align: center;">Statement</th>
<th style="text-align: center;">Label</th>
<th style="text-align: center;">Group</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">$p \Longrightarrow q$</td>
<td style="text-align: center;">${p}$</td>
<td style="text-align: center;">$q$</td>
<td style="text-align: center;">True</td>
<td style="text-align: center;">BASE</td>
</tr>
<tr>
<td style="text-align: center;">$p \wedge t \Longrightarrow q$</td>
<td style="text-align: center;">${p}$</td>
<td style="text-align: center;">$q$</td>
<td style="text-align: center;">Unknown</td>
<td style="text-align: center;">CONJ</td>
</tr>
<tr>
<td style="text-align: center;">$p \wedge t \Longrightarrow q$</td>
<td style="text-align: center;">${p, t}$</td>
<td style="text-align: center;">$q$</td>
<td style="text-align: center;">True</td>
<td style="text-align: center;">CONJ</td>
</tr>
<tr>
<td style="text-align: center;">$p \wedge t \Longrightarrow q$</td>
<td style="text-align: center;">${p, \neg t}$</td>
<td style="text-align: center;">$q$</td>
<td style="text-align: center;">Unknown</td>
<td style="text-align: center;">CONJ+NEG</td>
</tr>
<tr>
<td style="text-align: center;">$p \wedge t \Longrightarrow \neg q$</td>
<td style="text-align: center;">${p}$</td>
<td style="text-align: center;">$q$</td>
<td style="text-align: center;">Unknown</td>
<td style="text-align: center;">CONJ+NEG</td>
</tr>
<tr>
<td style="text-align: center;">$p \wedge t \Longrightarrow \neg q$</td>
<td style="text-align: center;">${p, t}$</td>
<td style="text-align: center;">$q$</td>
<td style="text-align: center;">False</td>
<td style="text-align: center;">CONJ+NEG</td>
</tr>
<tr>
<td style="text-align: center;">$p \wedge t \Longrightarrow \neg q$</td>
<td style="text-align: center;">${p, \neg t}$</td>
<td style="text-align: center;">$q$</td>
<td style="text-align: center;">Unknown</td>
<td style="text-align: center;">CONJ+NEG</td>
</tr>
</tbody>
</table>
<p>Table 1: Conjunction Contrast Perturbations. The minimal edits done to a base theory (first row) for testing the conjunction and negation reasoning abilities. The group reflects the overall change in theory w.r.t. the base theory.
rule, with the LHS $p$ of the rule being a complex predicate. Rule $r_{2}$ is a simple rule.</p>
<h3>3.3 Logical Contrast Sets</h3>
<p>In this evaluation set, we probe the ability of the model to robustly understand the three different logical operators $(\wedge, \vee, \neg)$. For this, we develop different contrast sets (Gardner et al., 2020) with minimal editing of the theory, probing specific reasoning abilities of different operators. The key intuition is to evaluate if the model is able to understand the minor changes in the theory brought by the addition of logical operators, and predict the change in label accordingly.</p>
<p>For a given theory $T$ and statement $s$, we first select a rule to be modified such that it is part of the proof set $G(T, s)$. This ensures that our perturbation would influence the model's reasoning process while predicting entailment of the statement $s$. Next, we add an unseen predicate $t$ to the rule LHS $p$ of one of the rules using conjunction $(\wedge)$ or disjunction $(\vee)$. In some further variants of perturbations, we include the predicate $t$ (or the negated $\neg t$ ) as a fact in the theory, leading to different labels. Lastly, we also negate the rule RHS $q$ to introduce the logical negation $(\neg)$ perturbations. Based on the logical operator in the perturbation, we broadly divide the Logical Contrast set into three types: Conjunction Contrast Set (C-CS), Disjunction Contrast Set (D-CS), and Negation Contrast Set (N-CS). Examples of these perturbations are shown in Figure 3. The perturbations for C-CS are listed in Table 1. Please refer to Appendix E for the other perturbations. We categorize these perturbations into groups based on the logical operators involved in the perturbation with respect to the base theory. E.g., the three groups for C-CS are BASE, CONJ, CONJ+NEG, as shown in Table 1. If a model performs accurately on the Logical Contrast set, we expect that the model understands the semantics of the logical operators robustly.</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3: Examples of perturbations in RobustLR. (a) An original theory contains facts, rules, a statement, and the entailment label. The Logical Contrast set perturbations using conjunction and disjunction are shown in bold in (b) and (c), respectively. In (d), we show one of the Logical Equivalence perturbations where the rule is paraphrased using logical contraposition. Please refer to Sections 3.3 and 3.4 for more details.</p>
<p>Evaluation Protocol To evaluate the logical robustness to contrast perturbations, we first finetune the language model on a deductive reasoning dataset containing different combination of logical operators. Then, we report the model performance on these evaluation datasets as the weighted-F1 score from the Scikit-learn (Pedregosa et al., 2011). The weighted-F1 score modifies the macro-F1 to take any label imbalance into account. For instance, we have label imbalance by design of the perturbations in the Logical Contrast sets shown in Tables 1, 9, and 10. We use the model's prediction for the base theory and all its perturbations to compute the F1-score at a theory level, and then average this score across all theories in the evaluation set.</p>
<h3>3.4 Logical Equivalence Sets</h3>
<p>The Logical Equivalence set contain theories where the underlying symbolic representation of a rule is replaced by another representation that is logically equivalent. The logical equivalent form of a rule can be derived from standard logical equivalence conditions, as defined below:</p>
<ul>
<li>Contrapositive: $p \Longrightarrow q \equiv \neg q \Longrightarrow \neg p$</li>
<li>Distributive 1: $(p \Longrightarrow q) \wedge(p \Longrightarrow r) \equiv p \Longrightarrow(q \wedge r)$</li>
<li>Distributive 2: $(p \Longrightarrow q) \wedge(r \Longrightarrow q) \equiv(p \vee r) \Longrightarrow q$</li>
</ul>
<p>Here $p, q, r$ can be both atomic predicates or complex predicates. Based on the above conditions, the Logical Equivalence set is divided into three types: Contrapositive Equivalence Set (C-ES), Distributive 1 Equivalence Set (D1-ES), and Distributive 2 Equivalence Set (D2-ES). For the (C-ES) set, every rule $r_{i}$ in the theory $T$ is replaced by the logically equivalent form to create a new logically
equivalent theory $T^{\prime}$. An example of this perturbation is shown in Figure 3 (d). Similarly, for the D1-ES and D2-ES sets, a pair of rules in $T$ are merged according to the equivalence to create a new theory $T^{\prime}$.</p>
<p>In both instances, the theory $T^{\prime}$ still has the same label for a given statement, as the logical steps required to solve the task remains the same. These modifications are more challenging than traditional surface-level paraphrases of the natural language text, as it requires the model to understand the equivalence of different symbolic representations.</p>
<p>Evaluation Protocol Similar to the Logical Contrast set evaluation, we finetune a language model on a deductive reasoning dataset and report the weighted-F1 score for the base theory and the corresponding logical paraphrase, averaged across all theories in the evaluation set.</p>
<h2>4 The RobustLR Dataset</h2>
<p>In this section, we describe details about the RoBUSTLR dataset domains, sampling, and filtering procedure.</p>
<h3>4.1 Dataset Domain</h3>
<p>Facts The domains of the predicate relation $X$ and variable $a$ in the unary predicate $X(a)$ are the simple English adjectives and the proper names, respectively. Examples of this predicate form are "green(Alex)", "kind(John)", etc. Each predicate is associated to the English template sentence form " ${a}$ is ${X}$.". For the binary predicate $X(a, b)$, we consider family relationships and proper names as the domain of $X$ and $a$ respectively. Some examples of this predicate form are "daughter(Mary, Gary)","father(Bob, John)", etc. Each predicate is associated with template sentences such as " ${a}$ is the ${X}$ of ${b} . ", " \operatorname{The}{X}$ of ${b}$ is ${a} . ", \mathrm{etc}$. Note that, currently, we do not enforce any gender constraints on the names, thus allowing predicates such as "daughter(Bob, Gary)", which might be unlikely based on the genders associated statistically to names in English.</p>
<p>Rules For the rules, we follow the same domain as mentioned above for facts. We allow rules containing unary predicates, binary predicates, or a combination of both. Examples of some simple rules consisting of atomic predicates are "green(Alex) $\Longrightarrow$ daughter(Bob, Gary)", " $\neg$ father(Bob, John) $\Longrightarrow$ kind(John)", etc. Simi-</p>
<p>larly, examples of some compound rules containing complex predicates are "green(Alex) $\vee$ smart(Bob) $\Longrightarrow$ daughter(Bob, Gary) $\wedge \neg$ kind(John)", etc. We note that, for the sake of keeping the theories deterministic, we do not allow the disjunction operator in the RHS of a compound rule. A rule of the form $p \Longrightarrow q$ is associated with templates such as "If ${p}$ then ${q}$.", " ${q}$ if ${p}$.", etc., where the $p$ 's and $q$ 's can be recursively resolved to their own templates as defined in the predicates.</p>
<h3>4.2 Dataset Sampling</h3>
<p>For sampling the theories in RobustLR, we use a modified version of the Label-Priority sampling (Zhang et al., 2022). The detailed algorithm is described in Algorithm 1 in Appendix. At a highlevel, we sample different predicates from the set of templates and assign the value 0 or 1 to them. After that, we divide the predicate set into multiple levels. This helps us in sampling theories with multi-hop reasoning depths. After that, rules are derived by connecting predicates with the same label between two different levels. Finally, the predicates with value 1 at the $0^{\text {th }}$ level form the facts in the theory, the connections denote the rules, and the predicates in the last level denote some candidate statements.</p>
<h3>4.3 Filtering Statistical Features</h3>
<p>In a contemporary work, Zhang et al. (2022) find that LMs are specifically prone to pick up any existing statistical features that can be present in the training datasets. These are described as certain statistic of an instance that has a strong correlation with the label. Examples of statistical features are #facts, #rules, #negation op, #facts with negation, etc.</p>
<p>We introduce some changes in our sampling algorithm to minimize the influence of such statistical features. We define a check to ensure that the number of statements with the different labels are similar for any given theory in the training dataset. Since we have negations in the dataset, it allows us to exactly control the True and False label distribution per theory instance systematically. We control the Unknown label by oversampling theories and discarding ones with skewed label distribution. Please refer to Appendix D for more details.</p>
<h2>5 Experimental Setup</h2>
<p>Training Data Details We use four different training datasets to fine-tune baselines, described
as follows: NOT: In this dataset, we allow negations in both facts and rules, but restrict to only using simple rules. Note that it is not possible to create a dataset without any operators (i.e., no negation, conjunction, and disjunction) as it would not be possible to have the False label in that dataset. AND+NOT: Here, we restrict the connector for compound rules to AND ( $\wedge$ ). As before, we allow negations in facts and rules. OR+NOT: Similar to AND+NOT, we restrict the connector of the compound rules to OR $(\vee)$. We allow negations in facts and rules as before. All: This dataset has all the three logical operators (AND, OR, NOT) present.</p>
<p>The dataset All contains all the logical operators we consider in the Logical Contrast set. Thus, instances from the All dataset cover all forms of rules seen in these test sets. We aim to understand the effect of these training datasets on the evaluation sets by fine-tuning the model on each dataset separately. Please refer to Appendix C for more details on the training and evaluation data statistics.</p>
<p>Models and Experiment Details Following prior works (Clark et al., 2020; Tafjord et al., 2021; Sanyal et al., 2022), we evaluate the performance of three language models: RoBERTa (Liu et al., 2019), T5 (Raffel et al., 2020), and GPT-3 (Brown et al., 2020). Specifically, we evaluate the model checkpoints RoBERTa-Large, T5-Large, T5-3B, T5-11B, and GPT-3. To evaluate a model, we first fine-tune it on one of the training dataset mentioned above, and then evaluate on the Logical Contrast (Section 6.2) and Logical Equivalence (Section 6.3) evaluation sets. For T5-11B, we only finetune it on the All dataset due to compute constraints. For GPT-3, we evaluate its performance on a subset of the test sets using demonstrations. Please refer to Appendix A for details on the input formats for each model and Appendix B for the hyperparameter settings and other implementation details.</p>
<h2>6 Results</h2>
<h3>6.1 In-domain Performance</h3>
<p>The performance of the LMs on the in-distribution held-out data are shown in Table 3. We note that the models are able to solve the in-distribution test dataset almost perfectly in all cases. This either means the model understands the logical reasoning task perfectly (which is unlikely) or it learns some spurious features to solve the task using shortcuts. Now, we evaluate these models on our test sets to</p>
<table>
<thead>
<tr>
<th>Data</th>
<th>RoBERTa-Large</th>
<th></th>
<th></th>
<th></th>
<th>T5-Large</th>
<th></th>
<th></th>
<th></th>
<th>T5-3B</th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Avg</td>
<td>C-CS</td>
<td>D-CS</td>
<td>N-CS</td>
<td>Avg</td>
<td>C-CS</td>
<td>D-CS</td>
<td>N-CS</td>
<td>Avg</td>
<td>C-CS</td>
<td>D-CS</td>
<td>N-CS</td>
</tr>
<tr>
<td>NOT</td>
<td>0.39</td>
<td>0.39</td>
<td>0.45</td>
<td>0.34</td>
<td>0.44</td>
<td>0.36</td>
<td>0.55</td>
<td>0.41</td>
<td>0.59</td>
<td>0.58</td>
<td>0.60</td>
<td>0.60</td>
</tr>
<tr>
<td>AND+NOT</td>
<td>0.52</td>
<td>0.56</td>
<td>0.53</td>
<td>0.48</td>
<td>0.47</td>
<td>0.43</td>
<td>0.55</td>
<td>0.42</td>
<td>0.57</td>
<td>0.58</td>
<td>0.57</td>
<td>0.55</td>
</tr>
<tr>
<td>OR+NOT</td>
<td>0.47</td>
<td>0.39</td>
<td>0.61</td>
<td>0.42</td>
<td>0.46</td>
<td>0.36</td>
<td>0.60</td>
<td>0.43</td>
<td>0.56</td>
<td>0.44</td>
<td>0.67</td>
<td>0.57</td>
</tr>
<tr>
<td>All</td>
<td>0.47</td>
<td>0.44</td>
<td>0.61</td>
<td>0.37</td>
<td>0.46</td>
<td>0.37</td>
<td>0.61</td>
<td>0.40</td>
<td>0.58</td>
<td>0.54</td>
<td>0.65</td>
<td>0.54</td>
</tr>
</tbody>
</table>
<p>Table 2: Performance of RoBERTa-Large, T5-Large, and T5-3B on Logical Contrast sets. We report the weightedF1 score for each subset, and average that for the Avg column. Please refer to Section 6.2 for more details.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Training Dataset</th>
<th style="text-align: center;">RoBERTa-Large</th>
<th style="text-align: center;">T5-Large</th>
<th style="text-align: center;">T5-3B</th>
<th style="text-align: center;">T5-11B</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">NOT</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.98</td>
<td style="text-align: center;">-</td>
</tr>
<tr>
<td style="text-align: left;">AND+NOT</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.99</td>
<td style="text-align: center;">0.97</td>
<td style="text-align: center;">-</td>
</tr>
<tr>
<td style="text-align: left;">OR+NOT</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.99</td>
<td style="text-align: center;">0.97</td>
<td style="text-align: center;">-</td>
</tr>
<tr>
<td style="text-align: left;">All</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.99</td>
<td style="text-align: center;">0.92</td>
<td style="text-align: center;">0.94</td>
</tr>
</tbody>
</table>
<p>Table 3: Performance of RoBERTa-Large, T5-Large, T5-3B, and T5-11B on in-domain held-out set. Please refer to Section 6.1 for more details.
check the logical robustness.</p>
<h3>6.2 Performance on Logical Contrast set</h3>
<p>Overall Result We finetune RoBERTa-Large, T5-Large, and T5-3B models on different training datasets and evaluate them on the three types of Logical Contrast set. The results are shown in Table 2. Based on the Avg performance, we find that the models perform significantly worse on the Logical Contrast set, compared to the almost perfect performance on the in-distribution test sets in Table 3. This shows that even after finetuning on the logical deductive reasoning datasets, these models do not learn the semantics of the logical operators in a robust manner, but likely use spurious correlations.</p>
<p>Additionally, we find that on average, model performance is similar for different training datasets, except for NOT dataset. While this result seems a bit surprising at first because we expect different training datasets to have varying effect on the performance, but computing the performance breakdown by perturbation type across different datasets reveals an interesting trend. We observe that training on related operators as the perturbation in the evaluation subset usually leads to better performance. For instance, we find that models trained on the OR+NOT training data perform better on the D-CS compared to when trained on NOT or AND+NOT training data. Taking RoBERTa-Large as an example, we observe that its performance on D-CS is 0.61 when finetuned on OR+NOT and is apparently greater than the performance on other contrast sets. A similar trend is observed for C-CS. This is intuitive as training on the related operators helps the model
<img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 4: Performance comparison of RoBERTa-Large, T5-Large, T5-3B, and T5-11B across different groups of contrast perturbations. Negations are hardest to learn across all settings. Refer to Section 6.2 for more details.
to understand the semantics of the logic relatively better than just relying on having seen these at pretraining time. This shows that the model indeed requires some training data that is strongly aligned with the operators being evaluated the test set.</p>
<p>Variation with logical operators Next, we want to understand which among the three operators are more challenging for the models to learn. To better understand this, we evaluate the models after finetuning on the All dataset and plot the model performance for different perturbation groups in Figure 4. These groups (defined in Section 3.3) contain perturbations of a specific operator, as suggested by their names. We find that the most challenging operator is negation. This is evident from the lowest scores on the NEG perturbation group among CONJ, DISJ, and NEG. Further, this is also observed from the fact that performance generally drops when negation perturbations are introduced along with any other perturbations. For instance, we see an average drop of around $25 \%$ between DISJ and DISJ+NEG. This demonstrates that the model not able to learn the negation semantics very well. Lastly, we find that models find conjunction relatively harder than disjunction. Please refer to Appendix F for more details.</p>
<table>
<thead>
<tr>
<th>Training Dataset</th>
<th></th>
<th>RoBERTa-Large</th>
<th></th>
<th></th>
<th></th>
<th>T5-Large</th>
<th></th>
<th></th>
<th></th>
<th>T5-3B</th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td></td>
<td>Avg</td>
<td>C-ES</td>
<td>D1-ES</td>
<td>D2-ES</td>
<td>Avg</td>
<td>C-ES</td>
<td>D1-ES</td>
<td>D2-ES</td>
<td>Avg</td>
<td>C-ES</td>
<td>D1-ES</td>
<td>D2-ES</td>
</tr>
<tr>
<td>NOT</td>
<td></td>
<td>0.81</td>
<td>0.79</td>
<td>0.91</td>
<td>0.74</td>
<td>0.88</td>
<td>0.76</td>
<td>0.90</td>
<td>0.97</td>
<td>0.70</td>
<td>0.78</td>
<td>0.79</td>
<td>0.54</td>
</tr>
<tr>
<td>AND+NOT</td>
<td></td>
<td>0.87</td>
<td>0.80</td>
<td>0.88</td>
<td>0.94</td>
<td>0.88</td>
<td>0.77</td>
<td>0.90</td>
<td>0.96</td>
<td>0.83</td>
<td>0.76</td>
<td>0.81</td>
<td>0.93</td>
</tr>
<tr>
<td>OR+NOT</td>
<td></td>
<td>0.87</td>
<td>0.78</td>
<td>0.87</td>
<td>0.95</td>
<td>0.86</td>
<td>0.76</td>
<td>0.86</td>
<td>0.97</td>
<td>0.86</td>
<td>0.77</td>
<td>0.82</td>
<td>0.98</td>
</tr>
<tr>
<td>All</td>
<td></td>
<td>0.89</td>
<td>0.79</td>
<td>0.93</td>
<td>0.94</td>
<td>0.89</td>
<td>0.77</td>
<td>0.93</td>
<td>0.98</td>
<td>0.84</td>
<td>0.72</td>
<td>0.83</td>
<td>0.98</td>
</tr>
</tbody>
</table>
<p>Table 4: Performance of RoBERTa-Large, T5-Large, and T5-3B on Logical Equivalence sets. We report the weighted-F1 score, and average that for the Avg column. Please refer to Section 6.3 for more details.</p>
<table>
<thead>
<tr>
<th>Models</th>
<th>Logical Contrast Set</th>
<th></th>
<th></th>
<th></th>
<th>Logical Equivalence Set</th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Avg</td>
<td>C-CS</td>
<td>D-CS</td>
<td>N-CS</td>
<td>Avg</td>
<td>C-ES</td>
<td>D1-ES</td>
<td>D2-ES</td>
</tr>
<tr>
<td>From scratch</td>
<td>0.14</td>
<td>0.10</td>
<td>0.21</td>
<td>0.10</td>
<td>0.45</td>
<td>0.33</td>
<td>0.50</td>
<td>0.51</td>
</tr>
<tr>
<td>RoBERTa</td>
<td>0.47</td>
<td>0.44</td>
<td>0.61</td>
<td>0.37</td>
<td>0.76</td>
<td>0.40</td>
<td>0.93</td>
<td>0.94</td>
</tr>
<tr>
<td>T5-Large</td>
<td>0.46</td>
<td>0.37</td>
<td>0.61</td>
<td>0.40</td>
<td>0.89</td>
<td>0.77</td>
<td>0.93</td>
<td>0.98</td>
</tr>
<tr>
<td>T5-3B</td>
<td>0.58</td>
<td>0.54</td>
<td>0.65</td>
<td>0.36</td>
<td>0.84</td>
<td>0.72</td>
<td>0.83</td>
<td>0.98</td>
</tr>
<tr>
<td>T5-11B ${ }^{3}$</td>
<td>0.61</td>
<td>0.57</td>
<td>0.67</td>
<td>0.58</td>
<td>0.83</td>
<td>0.76</td>
<td>0.76</td>
<td>0.97</td>
</tr>
<tr>
<td>GPT-3 ${ }^{4}$</td>
<td>0.36</td>
<td>0.34</td>
<td>0.50</td>
<td>0.25</td>
<td>0.67</td>
<td>0.36</td>
<td>0.78</td>
<td>0.87</td>
</tr>
<tr>
<td>human</td>
<td>0.88</td>
<td>0.87</td>
<td>0.94</td>
<td>0.84</td>
<td>0.91</td>
<td>0.81</td>
<td>0.97</td>
<td>0.96</td>
</tr>
</tbody>
</table>
<p>Table 5: Comparisons between training a model from scratch, finetuning a pre-trained checkpoint at scale (RoBERTa, T5-Large, T5-3B, and T5-11B), using incontext learning (GPT-3), and human performance, on the Logical Contrast and Logical Equivalence sets. Please refer to Sections 6.4 and 6.5 for more details.</p>
<h3>6.3 Performance on Logical Equivalence set</h3>
<p>Results on Contrapositive Equivalence Next, we evaluate the fine-tuned LMs on the Logical Equivalence sets. In Table 4, we observe that the model performance degrades by approximately $20 \%$ for the C-ES, compared to the in-distribution performance in Table 3. Contraposition involves changing the rule into a format that has two negations, thus testing the limits of the model on understanding negations. From the experiments on Logical Contrast sets, we know that negations are not well understood by the model. Thus, these results reinforce our previous findings. We do not find any significant changes in performance when trained on different operators. Thus, we conclude that, for this test set, it is not sufficient to just understand the semantics of the logical operators, but it rather requires a higher order understanding about the interactions between the logical operators and implications. Including such knowledge in deductive reasoning models is an interesting direction for future works.</p>
<p>Results on Distributive Equivalence For D1ES and D2-ES test sets, we see a higher performance compared to C-ES as these equivalence conditions are relatively easier than the contrapo-</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup>sition rule. This is because the distributive rules are similar to having compound rules in the dataset (that is already present in AND+NOT, OR+NOT, and All datasets). Between the two sets, we observe that D1-ES is more challenging for the model. This indicates that models find conjunction operator harder than the disjunction, similar to our observations from Figure 4. One reason for this can be the strictness involved in the conjunction operation. A rule with conjunction is true only if the individual parts are independently true.</p>
<h3>6.4 Human Evaluation</h3>
<p>To better understand the upper limit of ROBUSTLR evaluation sets, we ask 3 Computer Science graduate students to annotate 30 randomly sampled theories from each subset of Logical Contrast and Logical Equivalence sets. The results are shown in the last row of Table 5. We find that humans are significantly better than other baselines, performing around $27 \%$ higher on the Logical Contrast set compared to T5-11B on average. Additionally, we see similar trends that humans find negation based perturbations (N-CS) hardest, followed by conjunction (C-CS), and disjunction (D-CS). Please refer to Appendix H for further details.</p>
<h3>6.5 Analysis</h3>
<p>Performance of Larger LMs Here we evaluate the performance of some larger models on RoBUSTLR. The goal is to estimate the possible gains with scaling to large LMs. For this, we finetune a T5-11B using the All training dataset for two epochs. Additionally, we evaluate GPT3 (Brown et al., 2020) on a subset of 500 samples per test set, using demonstration-based in-context learning. The results are shown rows 5-6 in Table 5. We observe that increasing the model size from T5-Large to T5-11B indeed leads to a significant performance gain on most datasets. But it is still quite far compared to human performance. This suggests that scaling can potentially help with learning robust</p>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Figure 5: Average performance of RoBERTa-Large on Logical Contrast and Logical Equivalence sets when trained on varying amount of All dataset.</p>
<p><img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Figure 6: Performance comparison of RoBERTa-Large, T5-Large, T5-3B, and T5-11B for two variants of Logical Contrast sets: with and without distractors. Refer to Section 6.5 for more details.</p>
<p>logical operations to an extent. Additionally, we find that GPT-3 is not able to perform well on these test sets. We hypothesize this is likely due to the mismatch of the training distribution of the GPT-3 model, versus our synthetic datasets, as we do not finetune the GPT-3 model on our training sets.</p>
<h3>Effect of LM Pre-training</h3>
<p>In this part, we evaluate the usefulness of using a pre-trained checkpoint in our experiments, in comparison with training a RoBERTa-Large architecture from scratch. We train both RoBERTa-Large pre-trained checkpoint and a similar model from scratch using the All dataset, and evaluate on the RobustLR sets. The results are shown in rows 1-2 in Table 5. We observe a significant drop in performance, demonstrating that knowledge learned during pre-training is crucial for this task.</p>
<h3>Effect of size of training data</h3>
<p>Next, in Figure 5, we plot the overall performance of RoBERTa-Large model finetuned on a varying amount of All training data. We observe that the model performance increases with increasing amount of training data, as expected, and then saturates at a fixed level. This shows that there is no significant effect of using larger training datasets on model performance. We use 50k training samples in all datasets.</p>
<table>
<thead>
<tr>
<th>All Dataset</th>
<th>Logical Contrast Set</th>
<th></th>
<th></th>
<th></th>
<th>Logical Equivalence Set</th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Avg</td>
<td>C-CS</td>
<td>D-CS</td>
<td>N-CS</td>
<td>Avg</td>
<td>C-ES</td>
<td>D1-ES</td>
<td>D2-ES</td>
</tr>
<tr>
<td>Original</td>
<td>0.47</td>
<td>0.44</td>
<td>0.61</td>
<td>0.37</td>
<td>0.89</td>
<td>0.79</td>
<td>0.93</td>
<td>0.94</td>
</tr>
<tr>
<td>w/o Unknown</td>
<td>0.83</td>
<td>0.83</td>
<td>0.77</td>
<td>0.90</td>
<td>0.86</td>
<td>0.72</td>
<td>0.87</td>
<td>1.00</td>
</tr>
</tbody>
</table>
<p>Table 6: Performance of RoBERTa-Large checkpoint when finetuned on a subset of the training dataset without Unknown label. We observe that the performance is still below the in-domain performances.</p>
<h3>Effect of distractors</h3>
<p>We define distractors as the facts and rules that are not part of the proof set for a given theory and statement. Figure 6 depicts the effect of distractors on the model performance, when finetuned on the All dataset and evaluated on the Logical Contrast set. We observe that the performance generally improves (or stays similar) on the variant without distractors. This shows that retrieving the relevant facts and rules in the theory from a given set of sentences is a non-trivial challenge. Thus, performing both retrieval and entailment prediction in a single model can lead to some performance degradation.</p>
<h3>Effect of Statistical Features</h3>
<p>In a contemporary work, Zhang et al. (2022) claims that deductive reasoning models inherently learn to use statistical features in the training data such as #rules, #facts, etc. Here, we demonstrate that it is not the complete reason for failure using the following control study. We finetune the RoBERTa-Large model on a subset of the All dataset, where we restrict to two labels: True and False, by filtering out the Unknown label. In our sampling algorithm, we ensure that each theory has the exact same number of True and False labeled statements in the training set. Thus, it is not possible to learn any statistic of the data, as the label distribution per theory is exactly uniform [5]. Next, we evaluate the model on the RobustLR evaluation sets, with the Unknown label filtered in each set. The results are shown in Table 6. We observe that, although the performance on this reduced test set is improved, there is still around 15% gap on average with respect to performance on in-distribution data. This gap suggests that the model is not able to learn the logical operators robustly, even without any scope of spurious statistical features in the training set. Thus, this shows that although spurious correlation can lead to non-robust model behavior, it is not the sole reason for failure of these deductive reasoning models. This calls for the development of better inductive</p>
<p><sup>5</sup>Zhang et al. (2022) do not consider negations in the theory, and thus cannot ensure this property.</p>
<p>biases to teach the logical semantics more robustly to the language models.</p>
<h2>7 Related Works</h2>
<p>Reasoning in natural language has been a prevalent problem in NLP. There are multiple reasoning datasets, studying different aspects of reasoning over textual inputs. Natural Language Inference (NLI) (Dagan et al., 2006) is a prominent dataset that requires reasoning over text to answer if a statement is entailed, contradicted, or neutral given a hypothesis. HotpotQA (Yang et al., 2018b) tests multi-hop reasoning abilities that require comparisons and inferring missing bridge between sentences. CLUTRR (Sinha et al., 2019) tests whether models can infer biological relationships between entities in a context. RICA (Zhou et al., 2021) requires the model to employ commonsense reasoning to answer questions based on a context.</p>
<p>Recently, there has been an increasing focus on evaluating the logical reasoning abilities of LMs. ReClor (Yu et al., 2020) and LogiQA (Liu et al., 2021) are logical reasoning datasets derived from examinations. RuleTaker (Clark et al., 2020) proposes synthetic deductive reasoning datasets that uses only the knowledge in the context. There are very limited works that probe the logical reasoning abilities of language models (LMs). FaiRR (Sanyal et al., 2022) tests the robustness of logical reasoning models when the subjects and attributes in the context are altered to out-of-distribution terms. In a contemporary work, Zhang et al. (2022) show that language models can learn to use statistical features that can be present in deductive reasoning datasets. To the best of our knowledge, RobustLR is the first dataset that tests how robust these LMs are to different logical perturbations.</p>
<h2>8 Conclusion</h2>
<p>In this paper, we proposed RobustLR, a diagnostic benchmark to test the logical robustness of deductive reasoning models. In RobustLR, we propose two evaluation sets, Logical Contrast and Logical Equivalence, each probing different logical reasoning abilities. Overall, we find that fine-tuning LMs such as RoBERTa and T5 on deductive reasoning datasets is not sufficient to learn the semantics of the logical operators conjunction, disjunction, and negation. Although well-aligned training dataset improves model performance, the models still find it challenging to understand negations,
both in Logical Contrast and Logical Equivalence sets. We demonstrate some interesting shortcoming of LMs designed for logical reasoning, that can eventually enable building better reasoning models.</p>
<h2>9 Limitation</h2>
<p>A key limitation of the work is the synthetic nature of the dataset. While it is ideal to explore more natural theories, it makes the systematic logical perturbation process very challenging. Thus, in this work, we resort to using synthetic datasets, but aim to bridge this gap in future works. Another limitation is the complexity of the datasets we explore. We use fairly simple logical rules and constructs for RobustLR. Some more complex forms of logical reasoning-based theories can potentially reveal even more limitations of deductive reasoning models. Another interesting aspect we do not explore in this scope is potential techniques to improve these models on deductive reasoning tasks. This might involve trying different inductive biases in the form of architectural designs, more specialized datasets, etc.</p>
<h2>Acknowledgments</h2>
<p>This research is supported in part by the Office of the Director of National Intelligence (ODNI), Intelligence Advanced Research Projects Activity (IARPA), via Contract No. 2019-19051600007, the DARPA MCS program under Contract No. N660011924033, the Defense Advanced Research Projects Agency with award W911NF-19-20271, NSF IIS 2048211, NSF SMA 1829268, and gift awards from Google, Amazon, JP Morgan and Sony. We would like to thank all the collaborators in USC INK research lab for their constructive feedback on the work.</p>
<h2>References</h2>
<p>Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language models are few-shot learners. In Advances in Neural Information Processing Systems, volume 33.</p>
<p>Jifan Chen and Greg Durrett. 2019. Understanding dataset design choices for multi-hop reasoning. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 4026-4032, Minneapolis, Minnesota. Association for Computational Linguistics.</p>
<p>Peter Clark, Oyvind Tafjord, and Kyle Richardson. 2020. Transformers as soft reasoners over language. In Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence, IJCAI-20, pages 3882-3890. International Joint Conferences on Artificial Intelligence Organization. Main track.</p>
<p>Leyang Cui, Yu Wu, Shujie Liu, Yue Zhang, and Ming Zhou. 2020. MuTual: A dataset for multi-turn dialogue reasoning. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics.</p>
<p>Ido Dagan, Oren Glickman, and Bernardo Magnini. 2006. The pascal recognising textual entailment challenge. In Machine Learning Challenges. Evaluating Predictive Uncertainty, Visual Object Classification, and Recognising Tectual Entailment, pages 177-190, Berlin, Heidelberg. Springer Berlin Heidelberg.</p>
<p>Matt Gardner, Yoav Artzi, Victoria Basmov, Jonathan Berant, Ben Bogin, Sihao Chen, Pradeep Dasigi, Dheeru Dua, Yanai Elazar, Ananth Gottumukkala, Nitish Gupta, Hannaneh Hajishirzi, Gabriel Ilharco, Daniel Khashabi, Kevin Lin, Jiangming Liu, Nelson F. Liu, Phoebe Mulcaire, Qiang Ning, Sameer Singh, Noah A. Smith, Sanjay Subramanian, Reut Tsarfaty, Eric Wallace, Ally Zhang, and Ben Zhou. 2020. Evaluating models' local decision boundaries via contrast sets. In Findings of the Association for Computational Linguistics: EMNLP 2020, pages 1307-1323, Online. Association for Computational Linguistics.</p>
<p>Nicolas Gontier, Koustuv Sinha, Siva Reddy, and C. Pal. 2020. Measuring systematic generalization in neural proof generation with transformers. In NeurIPS'20.</p>
<p>Suchin Gururangan, Swabha Swayamdipta, Omer Levy, Roy Schwartz, Samuel Bowman, and Noah A. Smith. 2018. Annotation artifacts in natural language inference data. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers), pages 107-112, New Orleans, Louisiana. Association for Computational Linguistics.</p>
<p>Jian Liu, Leyang Cui, Hanmeng Liu, Dandan Huang, Yile Wang, and Yue Zhang. 2021. Logiqa: A challenge dataset for machine reading comprehension with logical reasoning. In Proceedings of the TwentyNinth International Joint Conference on Artificial Intelligence, IJCAI'20.</p>
<p>Yinhan Liu, Myle Ott, Naman Goyal, and Jingfei Du an. 2019. Roberta: A robustly optimized bert pretraining approach. ArXiv preprint, abs/1907.11692.</p>
<p>Ilya Loshchilov and Frank Hutter. 2019. Decoupled weight decay regularization. In International Conference on Learning Representations.</p>
<p>Robin Manhaeve, Sebastijan Dumancic, A. Kimmig, T. Demeester, and L. D. Raedt. 2019. Deepproblog: Neural probabilistic logic programming. In BNAIC/BENELEARN.</p>
<p>John W. McCarthy. 1959. Programs with common sense. In Proc. Tedding Conf. on the Mechanization of Thought Processes, pages 75-91.</p>
<p>Tom McCoy, Ellie Pavlick, and Tal Linzen. 2019. Right for the wrong reasons: Diagnosing syntactic heuristics in natural language inference. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 3428-3448, Florence, Italy. Association for Computational Linguistics.
F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay. 2011. Scikit-learn: Machine learning in Python. Journal of Machine Learning Research, 12:2825-2830.</p>
<p>Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. 2020. Exploring the limits of transfer learning with a unified text-to-text transformer. Journal of Machine Learning Research, 21(140):1-67.</p>
<p>Tim Rocktäschel and S. Riedel. 2017. End-to-end differentiable proving. In NeurIPS.</p>
<p>Victor Sanh, Albert Webson, Colin Raffel, Stephen H Bach, Lintang Sutawika, Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, Teven Le Scao, Arun Raja, et al. 2021. Multitask prompted training enables zero-shot task generalization.</p>
<p>Soumya Sanyal, Harman Singh, and Xiang Ren. 2022. FaiRR: Faithful and robust deductive reasoning over natural language. arXiv preprint arXiv:2203.10261.</p>
<p>Koustuv Sinha, Shagun Sodhani, Jin Dong, Joelle Pineau, and William L. Hamilton. 2019. CLUTRR: A diagnostic benchmark for inductive reasoning from text. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 4506-4515, Hong Kong, China. Association for Computational Linguistics.</p>
<p>Oyvind Tafjord, Bhavana Dalvi, and Peter Clark. 2021. ProofWriter: Generating implications, proofs, and</p>
<p>abductive statements over natural language. In Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, pages 3621-3634, Online. Association for Computational Linguistics.</p>
<p>Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Remi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, and Alexander Rush. 2020. Transformers: State-of-the-art natural language processing. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, pages 38-45, Online. Association for Computational Linguistics.</p>
<p>Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William Cohen, Ruslan Salakhutdinov, and Christopher D. Manning. 2018a. HotpotQA: A dataset for diverse, explainable multi-hop question answering. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 2369-2380, Brussels, Belgium. Association for Computational Linguistics.</p>
<p>Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William Cohen, Ruslan Salakhutdinov, and Christopher D. Manning. 2018b. HotpotQA: A dataset for diverse, explainable multi-hop question answering. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 2369-2380, Brussels, Belgium. Association for Computational Linguistics.</p>
<p>Weihao Yu, Zihang Jiang, Yanfei Dong, and Jiashi Feng. 2020. Reclor: A reading comprehension dataset requiring logical reasoning. In International Conference on Learning Representations (ICLR).</p>
<p>Honghua Zhang, Liunian Harold Li, Tao Meng, KaiWei Chang, and Guy Van den Broeck. 2022. On the paradox of learning to reason from data.</p>
<p>Pei Zhou, Rahul Khanna, Seyeon Lee, Bill Yuchen Lin, Daniel Ho, Jay Pujara, and Xiang Ren. 2021. RICA: Evaluating robust inference capabilities based on commonsense axioms. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 7560-7579, Online and Punta Cana, Dominican Republic. Association for Computational Linguistics.</p>
<h2>A Model implementation details</h2>
<p>In this section, we describe the implementation details of the language models used to evaluate RobustLR.</p>
<ul>
<li>RoBERTa-Large: Following RuleTaker (Clark et al., 2020), we use a pre-trained RoBERTa-Large (Liu et al., 2019) model to perform the classification task. Specifically, we input in the format $[C L S] T[S E P] s[S E P]$ to the RoBERTa-Large model, and extract the $[C L S]$ embedding to predict the label. The schematics of the RoBERTa model input is shown in Figure 7. Here, $T$ is the theory which is the concatenation of the facts and rules, and $s$ is the statement. We use Cross Entropy loss to fine-tune the model on the training dataset.</li>
<li>T5-Large: Following ProofWriter (Tafjord et al., 2021), we train a T5-Large (Raffel et al., 2020) model for the deductive reasoning task. For this, we add a prefix to the T5-Large's input and generate the output in a fixed format. Specifically, we give the input in the format: \$answer\$ ; \$question\$ = $s ; \$ context \$=$ $T$. Here, $T$ is the theory which is the concatenation of the facts and rules, and $s$ is the statement. And the output is defined to be in format: \$answer\$ = True/False/Unknown. The model is trained on the default language modeling loss to match the output format. At evaluation time, we match the output template with the above description and generate the model's predicted label accordingly.</li>
<li>T5-3B: Similar to T5-Large above, we use the T5-3B checkpoint.</li>
<li>T5-11B: Similar to T5-Large above, we use the T5-11B checkpoint.</li>
<li>GPT3: We use GPT-3 (Brown et al., 2020) for model evaluation to check its performance on our C-CS,D-CS,N-CS. Following (Sanh et al., 2021), we experiment with all the prompts for the NLI task and select a prompt which performs the best on the evaluation datasets. We experiment with inserting 3 demonstrations and 10 demonstrations before the sentence and find that the performances are nearly same. So, we finally use the prompt
<img alt="img-6.jpeg" src="img-6.jpeg" /></li>
</ul>
<p>Figure 7: Overview of the RoBERTa-Large model - The context (containing the facts and rules) and the statement are concatenated together as input and passed into a RoBERTa-Large model. The model is trained on cross entropy loss for a 3-class classification task.
named "based on the previous passage" which will give the input in a format as shown below:</p>
<p>Input Template:
{{premise}} Based on the previous passage, is it true that "{{hypothesis}}"? Yes or no?</p>
<p>Output Template:
${{$ answer_choices[label] }}
Answer Choices Template:
Yes ||| Maybe ||| No
We use 3 demonstrations for each sample to limit the total tokens evaluated using the OpenAI GPT-3 API ${ }^{6}$.</p>
<h2>B Hyperparameter Details</h2>
<p>Here we use RoBERTa-Large (Liu et al., 2019)and T5-Large,T5-3B,T5-11B (Raffel et al., 2020) models for the 3-class deductive reasoning classification task. Only use GPT-3 (Brown et al., 2020) for evaluation. We train the pre-trained checkpoints available in the Hugging Face (Wolf et al., 2020) Transformers library. For RoBERTa-Large model, we use AdamW (Loshchilov and Hutter, 2019) with learning rate $1 e-5$. For T5-Large T5-3B and T5-11B, we use AdamW with learning rate $1 e-4$, adamw_epsilon $1 e-6$, warmup_ratio $1 e-1$, weight_decay $1 e-2$. All these models are trained with batch size 8 on Nvidia Quadro RTX 8000 GPUs. For RoBERTa-Large and T5-Large,training a single task on one GPU costs nearly 8 hours on average. For T5-3B and T5-11B, we use 4 GPUs to train the model and averagely need 5 and 10 hours for one epoch.</p>
<p><sup id="fnref4:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<table>
<thead>
<tr>
<th style="text-align: left;">Training Dataset</th>
<th style="text-align: center;">Train</th>
<th style="text-align: center;">Dev</th>
<th style="text-align: center;">Test</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">NOT</td>
<td style="text-align: center;">50000</td>
<td style="text-align: center;">10000</td>
<td style="text-align: center;">10000</td>
</tr>
<tr>
<td style="text-align: left;">AND+NOT</td>
<td style="text-align: center;">50000</td>
<td style="text-align: center;">10000</td>
<td style="text-align: center;">10000</td>
</tr>
<tr>
<td style="text-align: left;">OR+NOT</td>
<td style="text-align: center;">50000</td>
<td style="text-align: center;">10000</td>
<td style="text-align: center;">10000</td>
</tr>
<tr>
<td style="text-align: left;">All</td>
<td style="text-align: center;">50000</td>
<td style="text-align: center;">10000</td>
<td style="text-align: center;">10000</td>
</tr>
</tbody>
</table>
<p>Table 7: Training dataset statistics. Please refer to Section C for more details.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Evaluation Set</th>
<th style="text-align: center;">Number of instances</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">C-CS</td>
<td style="text-align: center;">20000</td>
</tr>
<tr>
<td style="text-align: left;">D-CS</td>
<td style="text-align: center;">20000</td>
</tr>
<tr>
<td style="text-align: left;">N-CS</td>
<td style="text-align: center;">20000</td>
</tr>
<tr>
<td style="text-align: left;">C-ES</td>
<td style="text-align: center;">20000</td>
</tr>
<tr>
<td style="text-align: left;">D1-ES</td>
<td style="text-align: center;">20000</td>
</tr>
<tr>
<td style="text-align: left;">D2-ES</td>
<td style="text-align: center;">20000</td>
</tr>
</tbody>
</table>
<p>Table 8: Evaluation dataset statistics. Refer to Section C for more details.</p>
<h2>C Dataset Statistics</h2>
<p>In this section, we describe the training and evaluation dataset statistics. We first train the model on the datasets in Table 7. Each dataset comprises of different types of logical operators to help us in understanding the effect of different logical operators. Then we evaluate the trained models on evaluation datasets mentioned in Table 8. For evaluation, we test the model on two subsets of RobustLR: Logical Contrast set and Logical Equivalence set. Each set is further sub-categorized into three different parts, based on the type of perturbations.</p>
<h2>D Filtering Statistical Features</h2>
<p>In Figure 8, we show the plots of the label distribution for the following statistical features in the input theory and statement: #rules, #facts, #facts with negation, #rules with negation, #rules with conjunction, #rules with disjunction, and #statements with negations. We observe that there is no significant bias between any of these features and the task label. Additionally, we show the count histogram of the instances in blue. Overall, our dataset filtering is able to remove some of the count-based statistical features.</p>
<h2>E Contrast Perturbations</h2>
<p>Following Section 3.3, we show the conjunction, disjunction, and negation contrast perturbations for the case when base theory's label is False in Tables 11, 12, and 13, respectively.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Modified Rule</th>
<th style="text-align: center;">Facts</th>
<th style="text-align: center;">Statement</th>
<th style="text-align: center;">Label</th>
<th style="text-align: center;">Group</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">$p \Longrightarrow q$</td>
<td style="text-align: center;">${p}$</td>
<td style="text-align: center;">q</td>
<td style="text-align: center;">True</td>
<td style="text-align: center;">BASE</td>
</tr>
<tr>
<td style="text-align: center;">$p \vee t \Longrightarrow q$</td>
<td style="text-align: center;">${p}$</td>
<td style="text-align: center;">q</td>
<td style="text-align: center;">True</td>
<td style="text-align: center;">DISJ</td>
</tr>
<tr>
<td style="text-align: center;">$p \vee t \Longrightarrow q$</td>
<td style="text-align: center;">${p, t}$</td>
<td style="text-align: center;">$q$</td>
<td style="text-align: center;">True</td>
<td style="text-align: center;">DISJ</td>
</tr>
<tr>
<td style="text-align: center;">$p \vee t \Longrightarrow q$</td>
<td style="text-align: center;">${\neg p, \neg t}$</td>
<td style="text-align: center;">$q$</td>
<td style="text-align: center;">Unknown</td>
<td style="text-align: center;">DISJ+NEG</td>
</tr>
<tr>
<td style="text-align: center;">$p \vee t \Longrightarrow \neg q$</td>
<td style="text-align: center;">${p}$</td>
<td style="text-align: center;">$q$</td>
<td style="text-align: center;">False</td>
<td style="text-align: center;">DISJ+NEG</td>
</tr>
<tr>
<td style="text-align: center;">$p \vee t \Longrightarrow \neg q$</td>
<td style="text-align: center;">${p, t}$</td>
<td style="text-align: center;">$q$</td>
<td style="text-align: center;">False</td>
<td style="text-align: center;">DISJ+NEG</td>
</tr>
<tr>
<td style="text-align: center;">$p \vee t \Longrightarrow \neg q$</td>
<td style="text-align: center;">${\neg p, \neg t}$</td>
<td style="text-align: center;">$q$</td>
<td style="text-align: center;">Unknown</td>
<td style="text-align: center;">DISJ+NEG</td>
</tr>
</tbody>
</table>
<p>Table 9: Disjunction Contrast Perturbations. The minimal edits done to a base theory (first row) for testing the disjunction and negation reasoning abilities. The group reflects the overall change in theory w.r.t. the base theory.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Modified Rule</th>
<th style="text-align: center;">Facts</th>
<th style="text-align: center;">Statement</th>
<th style="text-align: center;">Label</th>
<th style="text-align: center;">Group</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">$p \Longrightarrow q$</td>
<td style="text-align: center;">${p}$</td>
<td style="text-align: center;">$q$</td>
<td style="text-align: center;">True</td>
<td style="text-align: center;">BASE</td>
</tr>
<tr>
<td style="text-align: center;">$p \Longrightarrow \neg q$</td>
<td style="text-align: center;">${p}$</td>
<td style="text-align: center;">$q$</td>
<td style="text-align: center;">False</td>
<td style="text-align: center;">NEG</td>
</tr>
<tr>
<td style="text-align: center;">$\neg p \Longrightarrow q$</td>
<td style="text-align: center;">${p}$</td>
<td style="text-align: center;">$q$</td>
<td style="text-align: center;">Unknown</td>
<td style="text-align: center;">NEG</td>
</tr>
<tr>
<td style="text-align: center;">$\neg p \Longrightarrow \neg q$</td>
<td style="text-align: center;">${p}$</td>
<td style="text-align: center;">$q$</td>
<td style="text-align: center;">Unknown</td>
<td style="text-align: center;">NEG</td>
</tr>
</tbody>
</table>
<p>Table 10: Negation Contrast Perturbations. The minimal edits done to a base theory (first row) for testing the negation reasoning abilities.</p>
<p>For the conjunction contrast set perturbations in Table 1 and 11, the first row is a base theory which is used to generate these contrast sets. In the next set of triads, the rule is modified to have an unseen predicate $t$ in conjunction with the existing rule LHS. Here $t$ is a predicate that is not part of the existing facts and inferences in the theory (hence, referred to as unseen predicate). Additionally, we add $t$ (or $\neg t$ ) as part of the facts in the theory. This lead to modification of the label as shown in rows 3-4. For the next set of triads, we modify the base rule to have a negated rule RHS $\neg q$. The corresponding label changes are shown in rows 5-7. In Table 11, we assume the label of the statement is False for the base theory in row 1. Similar perturbations are possible for the label True, and is shown in Table 1 in 3.3. We group these perturbations into three classes as shown in Table 11: BASE, CONJ, CONJ+NEG. These groups are based on which logical operator is the new addition with respect to the base theory. If a model performs accurately on this contrast set, we expect that the model understands the semantics of conjunction and negation logical operators reasonably well.</p>
<p>Similar to the C-CS above, we show the perturbations considered in the D-CS in Table 9 and 12, where the distractor is added to the rule LHS using disjunction $(\vee)$. Lastly, we show the N-CS perturbations in Tables 10 and 13, where negations are added to the rule LHS and/or RHS.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Modified Rule</th>
<th style="text-align: center;">Facts</th>
<th style="text-align: center;">Statement</th>
<th style="text-align: center;">Label</th>
<th style="text-align: center;">Group</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">$p \Longrightarrow \neg q$</td>
<td style="text-align: center;">${p}$</td>
<td style="text-align: center;">$q$</td>
<td style="text-align: center;">False</td>
<td style="text-align: center;">BASE</td>
</tr>
<tr>
<td style="text-align: center;">$p \wedge t \Longrightarrow \neg q$</td>
<td style="text-align: center;">${p}$</td>
<td style="text-align: center;">$q$</td>
<td style="text-align: center;">Unknown</td>
<td style="text-align: center;">CONJ</td>
</tr>
<tr>
<td style="text-align: center;">$p \wedge t \Longrightarrow \neg q$</td>
<td style="text-align: center;">${p, t}$</td>
<td style="text-align: center;">$q$</td>
<td style="text-align: center;">False</td>
<td style="text-align: center;">CONJ</td>
</tr>
<tr>
<td style="text-align: center;">$p \wedge t \Longrightarrow \neg q$</td>
<td style="text-align: center;">${p, \neg t}$</td>
<td style="text-align: center;">$q$</td>
<td style="text-align: center;">Unknown</td>
<td style="text-align: center;">CONJ+NEG</td>
</tr>
<tr>
<td style="text-align: center;">$p \wedge t \Longrightarrow q$</td>
<td style="text-align: center;">${p}$</td>
<td style="text-align: center;">$q$</td>
<td style="text-align: center;">Unknown</td>
<td style="text-align: center;">CONJ+NEG</td>
</tr>
<tr>
<td style="text-align: center;">$p \wedge t \Longrightarrow q$</td>
<td style="text-align: center;">${p, t}$</td>
<td style="text-align: center;">$q$</td>
<td style="text-align: center;">True</td>
<td style="text-align: center;">CONJ+NEG</td>
</tr>
<tr>
<td style="text-align: center;">$p \wedge t \Longrightarrow q$</td>
<td style="text-align: center;">${p, \neg t}$</td>
<td style="text-align: center;">$q$</td>
<td style="text-align: center;">Unknown</td>
<td style="text-align: center;">CONJ+NEG</td>
</tr>
</tbody>
</table>
<p>Table 11: Conjunction Contrast Perturbations. These are perturbations for testing conjunction and negation reasoning abilities. First row is the base theory being perturbed. Please refer to Appendix E for more details.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Modified Rule</th>
<th style="text-align: center;">Facts</th>
<th style="text-align: center;">Statement</th>
<th style="text-align: center;">Label</th>
<th style="text-align: center;">Group</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">$p \Longrightarrow q$</td>
<td style="text-align: center;">${p}$</td>
<td style="text-align: center;">$q$</td>
<td style="text-align: center;">False</td>
<td style="text-align: center;">BASE</td>
</tr>
<tr>
<td style="text-align: center;">$p \vee t \Longrightarrow \neg q$</td>
<td style="text-align: center;">${p}$</td>
<td style="text-align: center;">$q$</td>
<td style="text-align: center;">False</td>
<td style="text-align: center;">DISJ</td>
</tr>
<tr>
<td style="text-align: center;">$p \vee t \Longrightarrow \neg q$</td>
<td style="text-align: center;">${p, t}$</td>
<td style="text-align: center;">$q$</td>
<td style="text-align: center;">False</td>
<td style="text-align: center;">DISJ</td>
</tr>
<tr>
<td style="text-align: center;">$p \vee t \Longrightarrow \neg q$</td>
<td style="text-align: center;">${\neg p, \neg t}$</td>
<td style="text-align: center;">$q$</td>
<td style="text-align: center;">Unknown</td>
<td style="text-align: center;">DISJ+NEG</td>
</tr>
<tr>
<td style="text-align: center;">$p \vee t \Longrightarrow q$</td>
<td style="text-align: center;">${p}$</td>
<td style="text-align: center;">$q$</td>
<td style="text-align: center;">True</td>
<td style="text-align: center;">DISJ+NEG</td>
</tr>
<tr>
<td style="text-align: center;">$p \vee t \Longrightarrow q$</td>
<td style="text-align: center;">${p, t}$</td>
<td style="text-align: center;">$q$</td>
<td style="text-align: center;">True</td>
<td style="text-align: center;">DISJ+NEG</td>
</tr>
<tr>
<td style="text-align: center;">$p \vee t \Longrightarrow q$</td>
<td style="text-align: center;">${\neg p, \neg t}$</td>
<td style="text-align: center;">$q$</td>
<td style="text-align: center;">Unknown</td>
<td style="text-align: center;">DISJ+NEG</td>
</tr>
</tbody>
</table>
<p>Table 12: Disjunction Contrast Perturbations. These are perturbations for testing disjunction and negation reasoning abilities. First row is the base theory being perturbed. Please refer to Appendix E for more details.</p>
<h2>F Logical Contrast set breakdown</h2>
<p>In this section, we further discuss the performance of the LMs on each group of the Logical Contrast set. From Tables 14, 15 and 16 we can say that the models generally perform worse when they need to handle more complicated compound rules (CONJ + $\mathrm{NEG}&gt;\mathrm{CONJ}&gt;\mathrm{BASE}$ (where $&gt;$ means harder)). Additionally, we find that when we add more compound rules in the training dataset, the performance is generally better. Giving more complex rules can lead to further drops in performance, as noted by performance on the CONJ+NEG and DISJ+NEG. Models trained on the dataset with aligned operators instead of All dataset is better e.g., model trained on AND+NOT get best result at CONJ+NEG.</p>
<p>It is easy to see that model with larger amount of parameters give more consistent and better result at C-CS, D-CS, N-CS which means the model learned more semantics of logic from language and is more robust.</p>
<h2>G Result breakdown by label</h2>
<p>We report the performance for each label in Tables 17 to 22, for both the Logical Contrast and Logical Equivalence sets. We find that T5-3B model, the largest model among the three models, get a good result for Unknown while other two models are not good at it. It shows that models with large amount of parameters can better learn to predict the</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Modified Rule</th>
<th style="text-align: center;">Facts</th>
<th style="text-align: center;">Statement</th>
<th style="text-align: center;">Label</th>
<th style="text-align: center;">Group</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">$p \Longrightarrow q$</td>
<td style="text-align: center;">${p}$</td>
<td style="text-align: center;">$q$</td>
<td style="text-align: center;">False</td>
<td style="text-align: center;">BASE</td>
</tr>
<tr>
<td style="text-align: center;">$p \Longrightarrow \neg q$</td>
<td style="text-align: center;">${p}$</td>
<td style="text-align: center;">$q$</td>
<td style="text-align: center;">True</td>
<td style="text-align: center;">NEG</td>
</tr>
<tr>
<td style="text-align: center;">$\neg p \Longrightarrow q$</td>
<td style="text-align: center;">${p}$</td>
<td style="text-align: center;">$q$</td>
<td style="text-align: center;">Unknown</td>
<td style="text-align: center;">NEG</td>
</tr>
<tr>
<td style="text-align: center;">$\neg p \Longrightarrow \neg q$</td>
<td style="text-align: center;">${p}$</td>
<td style="text-align: center;">$q$</td>
<td style="text-align: center;">Unknown</td>
<td style="text-align: center;">NEG</td>
</tr>
</tbody>
</table>
<p>Table 13: Negation Contrast Perturbations. The minimal edits done to a base theory (first row) for testing the negation reasoning abilities.</p>
<p>Unknown label, which is relatively harder than the other two labels. Also, we find that Logical Equivalence set is an easier task in general than Logical Contrast set and the performances are stable across three models.</p>
<h2>H Human Evaluation</h2>
<p>We recruit three Computer Science graduates to annotate the datasets. To keep the annotation realistic, we sample 30 instances from each test subset of RobustLR and ask the annotators to mark a label from True, False, and Unknown. The question asked is: "Does the theory entail or contradict the statement, or we cannot say anything about it?". Overall, we find the average inter-annotator agreement to be around 0.79 , evaluated using the Fleiss' kappa score ${ }^{7}$.</p>
<p><sup id="fnref5:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p><img alt="img-7.jpeg" src="img-7.jpeg" /></p>
<p>Figure 8: Plots of label distribution with respect to different statistical features for the All dataset after our filtering techniques are used. Additionally, we plot the histogram of the count of instances for each feature value.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Logical Contrast set breakdown</th>
<th style="text-align: center;">C-CS</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">D-CS</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">N-CS</th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">BASE</td>
<td style="text-align: center;">CONJ</td>
<td style="text-align: center;">CONJ + NEG</td>
<td style="text-align: center;">BASE</td>
<td style="text-align: center;">DISJ</td>
<td style="text-align: center;">DISJ + NEG</td>
<td style="text-align: center;">BASE</td>
<td style="text-align: center;">NeG</td>
</tr>
<tr>
<td style="text-align: center;">NOT</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.28</td>
<td style="text-align: center;">0.28</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.62</td>
<td style="text-align: center;">0.28</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.22</td>
</tr>
<tr>
<td style="text-align: center;">AND+NOT</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.50</td>
<td style="text-align: center;">0.48</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.56</td>
<td style="text-align: center;">0.43</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.37</td>
</tr>
<tr>
<td style="text-align: center;">OR+NOT</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.32</td>
<td style="text-align: center;">0.29</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.74</td>
<td style="text-align: center;">0.52</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.31</td>
</tr>
<tr>
<td style="text-align: center;">All</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.41</td>
<td style="text-align: center;">0.34</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.81</td>
<td style="text-align: center;">0.50</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.26</td>
</tr>
</tbody>
</table>
<p>Table 14: Performance breakdown of RoBERTa-Large with different groups of Logical Contrast set. Please refer to Appendix F for more details.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Logical Contrast set breakdown</th>
<th style="text-align: center;">C-CS</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">D-CS</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">N-CS</th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">BASE</td>
<td style="text-align: center;">CONJ</td>
<td style="text-align: center;">CONJ + Neg</td>
<td style="text-align: center;">BASE</td>
<td style="text-align: center;">DISJ</td>
<td style="text-align: center;">DISJ + Neg</td>
<td style="text-align: center;">BASE</td>
<td style="text-align: center;">Neg</td>
</tr>
<tr>
<td style="text-align: center;">NOT</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.30</td>
<td style="text-align: center;">0.23</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.68</td>
<td style="text-align: center;">0.43</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.30</td>
</tr>
<tr>
<td style="text-align: center;">AND+NOT</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.40</td>
<td style="text-align: center;">0.31</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.69</td>
<td style="text-align: center;">0.43</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.32</td>
</tr>
<tr>
<td style="text-align: center;">OR+NOT</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.31</td>
<td style="text-align: center;">0.23</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.77</td>
<td style="text-align: center;">0.49</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.32</td>
</tr>
<tr>
<td style="text-align: center;">All</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.34</td>
<td style="text-align: center;">0.24</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.84</td>
<td style="text-align: center;">0.48</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.30</td>
</tr>
</tbody>
</table>
<p>Table 15: Performance breakdown of T5-Large with different groups of Logical Contrast set. Please refer to Appendix F for more details.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Logical Contrast set breakdown</th>
<th style="text-align: center;">C-CS</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">D-CS</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">N-CS</th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">BASE</td>
<td style="text-align: center;">CONJ</td>
<td style="text-align: center;">CONJ + Neg</td>
<td style="text-align: center;">BASE</td>
<td style="text-align: center;">DISJ</td>
<td style="text-align: center;">DISJ + Neg</td>
<td style="text-align: center;">BASE</td>
<td style="text-align: center;">Neg</td>
</tr>
<tr>
<td style="text-align: center;">NOT</td>
<td style="text-align: center;">0.96</td>
<td style="text-align: center;">0.56</td>
<td style="text-align: center;">0.53</td>
<td style="text-align: center;">0.96</td>
<td style="text-align: center;">0.61</td>
<td style="text-align: center;">0.57</td>
<td style="text-align: center;">0.96</td>
<td style="text-align: center;">0.55</td>
</tr>
<tr>
<td style="text-align: center;">AND+NOT</td>
<td style="text-align: center;">0.91</td>
<td style="text-align: center;">0.58</td>
<td style="text-align: center;">0.53</td>
<td style="text-align: center;">0.90</td>
<td style="text-align: center;">0.62</td>
<td style="text-align: center;">0.54</td>
<td style="text-align: center;">0.90</td>
<td style="text-align: center;">0.51</td>
</tr>
<tr>
<td style="text-align: center;">OR+NOT</td>
<td style="text-align: center;">0.95</td>
<td style="text-align: center;">0.37</td>
<td style="text-align: center;">0.39</td>
<td style="text-align: center;">0.93</td>
<td style="text-align: center;">0.74</td>
<td style="text-align: center;">0.65</td>
<td style="text-align: center;">0.93</td>
<td style="text-align: center;">0.53</td>
</tr>
<tr>
<td style="text-align: center;">All</td>
<td style="text-align: center;">0.93</td>
<td style="text-align: center;">0.54</td>
<td style="text-align: center;">0.49</td>
<td style="text-align: center;">0.93</td>
<td style="text-align: center;">0.75</td>
<td style="text-align: center;">0.62</td>
<td style="text-align: center;">0.94</td>
<td style="text-align: center;">0.49</td>
</tr>
</tbody>
</table>
<p>Table 16: Performance breakdown of T5-3B with different groups of Logical Contrast set. Please refer to Appendix F for more details.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Training Dataset</th>
<th style="text-align: center;">C-CS</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">D-CS</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">N-CS</th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">False</td>
<td style="text-align: center;">True</td>
<td style="text-align: center;">Unknown</td>
<td style="text-align: center;">False</td>
<td style="text-align: center;">True</td>
<td style="text-align: center;">Unknown</td>
<td style="text-align: center;">False</td>
<td style="text-align: center;">True Unknown</td>
</tr>
<tr>
<td style="text-align: center;">NOT</td>
<td style="text-align: center;">0.77</td>
<td style="text-align: center;">0.76</td>
<td style="text-align: center;">0.24</td>
<td style="text-align: center;">0.68</td>
<td style="text-align: center;">0.66</td>
<td style="text-align: center;">0.14</td>
<td style="text-align: center;">0.73</td>
<td style="text-align: center;">0.74</td>
</tr>
<tr>
<td style="text-align: center;">AND+NOT</td>
<td style="text-align: center;">0.89</td>
<td style="text-align: center;">0.87</td>
<td style="text-align: center;">0.48</td>
<td style="text-align: center;">0.71</td>
<td style="text-align: center;">0.71</td>
<td style="text-align: center;">0.38</td>
<td style="text-align: center;">0.67</td>
<td style="text-align: center;">0.69</td>
</tr>
<tr>
<td style="text-align: center;">OR+NOT</td>
<td style="text-align: center;">0.93</td>
<td style="text-align: center;">0.94</td>
<td style="text-align: center;">0.19</td>
<td style="text-align: center;">0.90</td>
<td style="text-align: center;">0.92</td>
<td style="text-align: center;">0.19</td>
<td style="text-align: center;">0.73</td>
<td style="text-align: center;">0.72</td>
</tr>
<tr>
<td style="text-align: center;">All</td>
<td style="text-align: center;">0.88</td>
<td style="text-align: center;">0.89</td>
<td style="text-align: center;">0.28</td>
<td style="text-align: center;">0.91</td>
<td style="text-align: center;">0.93</td>
<td style="text-align: center;">0.14</td>
<td style="text-align: center;">0.76</td>
<td style="text-align: center;">0.76</td>
</tr>
</tbody>
</table>
<p>Table 17: Performance breakdown of RoBERTa-Large with different labels for Logical Contrast set. Please refer to Appendix G for more details.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Training Dataset</th>
<th style="text-align: center;">Contrapositive</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Distributive 1</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Distributive 2</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">False</td>
<td style="text-align: center;">True</td>
<td style="text-align: center;">Unknown</td>
<td style="text-align: center;">False</td>
<td style="text-align: center;">True</td>
<td style="text-align: center;">Unknown</td>
<td style="text-align: center;">False</td>
<td style="text-align: center;">True</td>
<td style="text-align: center;">Unknown</td>
</tr>
<tr>
<td style="text-align: center;">NOT</td>
<td style="text-align: center;">0.72</td>
<td style="text-align: center;">0.72</td>
<td style="text-align: center;">0.92</td>
<td style="text-align: center;">0.91</td>
<td style="text-align: center;">0.90</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">0.73</td>
<td style="text-align: center;">0.75</td>
<td style="text-align: center;">-</td>
</tr>
<tr>
<td style="text-align: center;">AND+NOT</td>
<td style="text-align: center;">0.73</td>
<td style="text-align: center;">0.74</td>
<td style="text-align: center;">0.92</td>
<td style="text-align: center;">0.88</td>
<td style="text-align: center;">0.89</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">0.94</td>
<td style="text-align: center;">0.94</td>
<td style="text-align: center;">-</td>
</tr>
<tr>
<td style="text-align: center;">OR+NOT</td>
<td style="text-align: center;">0.72</td>
<td style="text-align: center;">0.73</td>
<td style="text-align: center;">0.89</td>
<td style="text-align: center;">0.85</td>
<td style="text-align: center;">0.89</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">0.95</td>
<td style="text-align: center;">0.94</td>
<td style="text-align: center;">-</td>
</tr>
<tr>
<td style="text-align: center;">All</td>
<td style="text-align: center;">0.73</td>
<td style="text-align: center;">0.75</td>
<td style="text-align: center;">0.90</td>
<td style="text-align: center;">0.91</td>
<td style="text-align: center;">0.94</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">0.93</td>
<td style="text-align: center;">0.94</td>
<td style="text-align: center;">-</td>
</tr>
</tbody>
</table>
<p>Table 18: Performance breakdown of RoBERTa-Large with different labels for Logical Equivalence set. Please refer to Appendix G for more details.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Training Dataset</th>
<th style="text-align: center;">C-CS</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">D-CS</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">N-CS</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: center;">False</td>
<td style="text-align: center;">True</td>
<td style="text-align: center;">Unknown</td>
<td style="text-align: center;">False</td>
<td style="text-align: center;">True</td>
<td style="text-align: center;">Unknown</td>
<td style="text-align: center;">False</td>
<td style="text-align: center;">True</td>
<td style="text-align: center;">Unknown</td>
</tr>
<tr>
<td style="text-align: left;">NOT</td>
<td style="text-align: center;">0.91</td>
<td style="text-align: center;">0.90</td>
<td style="text-align: center;">0.13</td>
<td style="text-align: center;">0.85</td>
<td style="text-align: center;">0.85</td>
<td style="text-align: center;">0.10</td>
<td style="text-align: center;">0.91</td>
<td style="text-align: center;">0.90</td>
<td style="text-align: center;">0.15</td>
</tr>
<tr>
<td style="text-align: left;">AND+NOT</td>
<td style="text-align: center;">0.95</td>
<td style="text-align: center;">0.93</td>
<td style="text-align: center;">0.23</td>
<td style="text-align: center;">0.87</td>
<td style="text-align: center;">0.83</td>
<td style="text-align: center;">0.11</td>
<td style="text-align: center;">0.89</td>
<td style="text-align: center;">0.88</td>
<td style="text-align: center;">0.20</td>
</tr>
<tr>
<td style="text-align: left;">OR+NOT</td>
<td style="text-align: center;">0.94</td>
<td style="text-align: center;">0.95</td>
<td style="text-align: center;">0.12</td>
<td style="text-align: center;">0.93</td>
<td style="text-align: center;">0.94</td>
<td style="text-align: center;">0.10</td>
<td style="text-align: center;">0.83</td>
<td style="text-align: center;">0.86</td>
<td style="text-align: center;">0.24</td>
</tr>
<tr>
<td style="text-align: left;">All</td>
<td style="text-align: center;">0.95</td>
<td style="text-align: center;">0.93</td>
<td style="text-align: center;">0.13</td>
<td style="text-align: center;">0.95</td>
<td style="text-align: center;">0.94</td>
<td style="text-align: center;">0.07</td>
<td style="text-align: center;">0.92</td>
<td style="text-align: center;">0.90</td>
<td style="text-align: center;">0.14</td>
</tr>
</tbody>
</table>
<p>Table 19: Performance breakdown of T5-Large with different labels for Logical Contrast set. Please refer to Appendix G for more details.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Training Dataset</th>
<th style="text-align: center;">Contrapositive</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Distributive 1</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Distributive 2</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: center;">False</td>
<td style="text-align: center;">True</td>
<td style="text-align: center;">Unknown</td>
<td style="text-align: center;">False</td>
<td style="text-align: center;">True</td>
<td style="text-align: center;">Unknown</td>
<td style="text-align: center;">False</td>
<td style="text-align: center;">True</td>
<td style="text-align: center;">Unknown</td>
</tr>
<tr>
<td style="text-align: left;">NOT</td>
<td style="text-align: center;">0.72</td>
<td style="text-align: center;">0.72</td>
<td style="text-align: center;">0.83</td>
<td style="text-align: center;">0.90</td>
<td style="text-align: center;">0.90</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">0.97</td>
<td style="text-align: center;">0.97</td>
<td style="text-align: center;">-</td>
</tr>
<tr>
<td style="text-align: left;">AND+NOT</td>
<td style="text-align: center;">0.72</td>
<td style="text-align: center;">0.72</td>
<td style="text-align: center;">0.86</td>
<td style="text-align: center;">0.92</td>
<td style="text-align: center;">0.88</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">0.96</td>
<td style="text-align: center;">0.97</td>
<td style="text-align: center;">-</td>
</tr>
<tr>
<td style="text-align: left;">OR+NOT</td>
<td style="text-align: center;">0.71</td>
<td style="text-align: center;">0.72</td>
<td style="text-align: center;">0.87</td>
<td style="text-align: center;">0.85</td>
<td style="text-align: center;">0.86</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">0.97</td>
<td style="text-align: center;">0.98</td>
<td style="text-align: center;">-</td>
</tr>
<tr>
<td style="text-align: left;">All</td>
<td style="text-align: center;">0.73</td>
<td style="text-align: center;">0.72</td>
<td style="text-align: center;">0.85</td>
<td style="text-align: center;">0.94</td>
<td style="text-align: center;">0.91</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">0.98</td>
<td style="text-align: center;">0.98</td>
<td style="text-align: center;">-</td>
</tr>
</tbody>
</table>
<p>Table 20: Performance breakdown of T5-Large with different labels for Logical Equivalence set. Please refer to Appendix G for more details.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Training Dataset</th>
<th style="text-align: center;">C-CS</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">D-CS</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">N-CS</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: center;">False</td>
<td style="text-align: center;">True</td>
<td style="text-align: center;">Unknown</td>
<td style="text-align: center;">False</td>
<td style="text-align: center;">True</td>
<td style="text-align: center;">Unknown</td>
<td style="text-align: center;">False</td>
<td style="text-align: center;">True</td>
<td style="text-align: center;">Unknown</td>
</tr>
<tr>
<td style="text-align: left;">NOT</td>
<td style="text-align: center;">0.93</td>
<td style="text-align: center;">0.94</td>
<td style="text-align: center;">0.53</td>
<td style="text-align: center;">0.79</td>
<td style="text-align: center;">0.82</td>
<td style="text-align: center;">0.43</td>
<td style="text-align: center;">0.91</td>
<td style="text-align: center;">0.94</td>
<td style="text-align: center;">0.46</td>
</tr>
<tr>
<td style="text-align: left;">AND+NOT</td>
<td style="text-align: center;">0.91</td>
<td style="text-align: center;">0.86</td>
<td style="text-align: center;">0.53</td>
<td style="text-align: center;">0.80</td>
<td style="text-align: center;">0.76</td>
<td style="text-align: center;">0.41</td>
<td style="text-align: center;">0.90</td>
<td style="text-align: center;">0.84</td>
<td style="text-align: center;">0.44</td>
</tr>
<tr>
<td style="text-align: left;">OR+NOT</td>
<td style="text-align: center;">0.95</td>
<td style="text-align: center;">0.95</td>
<td style="text-align: center;">0.30</td>
<td style="text-align: center;">0.92</td>
<td style="text-align: center;">0.92</td>
<td style="text-align: center;">0.37</td>
<td style="text-align: center;">0.93</td>
<td style="text-align: center;">0.93</td>
<td style="text-align: center;">0.41</td>
</tr>
<tr>
<td style="text-align: left;">All</td>
<td style="text-align: center;">0.91</td>
<td style="text-align: center;">0.94</td>
<td style="text-align: center;">0.43</td>
<td style="text-align: center;">0.91</td>
<td style="text-align: center;">0.93</td>
<td style="text-align: center;">0.30</td>
<td style="text-align: center;">0.93</td>
<td style="text-align: center;">0.96</td>
<td style="text-align: center;">0.33</td>
</tr>
</tbody>
</table>
<p>Table 21: Performance breakdown of T5-3B with different labels for Logical Contrast set. Please refer to Appendix G for more details.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Training Dataset</th>
<th style="text-align: center;">Contrapositive</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Distributive 1</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Distributive 2</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: center;">False</td>
<td style="text-align: center;">True</td>
<td style="text-align: center;">Unknown</td>
<td style="text-align: center;">False</td>
<td style="text-align: center;">True</td>
<td style="text-align: center;">Unknown</td>
<td style="text-align: center;">False</td>
<td style="text-align: center;">True</td>
<td style="text-align: center;">Unknown</td>
</tr>
<tr>
<td style="text-align: left;">NOT</td>
<td style="text-align: center;">0.71</td>
<td style="text-align: center;">0.72</td>
<td style="text-align: center;">0.92</td>
<td style="text-align: center;">0.77</td>
<td style="text-align: center;">0.81</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">0.95</td>
<td style="text-align: center;">0.96</td>
<td style="text-align: center;">-</td>
</tr>
<tr>
<td style="text-align: left;">AND+NOT</td>
<td style="text-align: center;">0.71</td>
<td style="text-align: center;">0.69</td>
<td style="text-align: center;">0.88</td>
<td style="text-align: center;">0.83</td>
<td style="text-align: center;">0.78</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">0.95</td>
<td style="text-align: center;">0.90</td>
<td style="text-align: center;">-</td>
</tr>
<tr>
<td style="text-align: left;">OR+NOT</td>
<td style="text-align: center;">0.70</td>
<td style="text-align: center;">0.70</td>
<td style="text-align: center;">0.92</td>
<td style="text-align: center;">0.81</td>
<td style="text-align: center;">0.82</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">0.98</td>
<td style="text-align: center;">0.98</td>
<td style="text-align: center;">-</td>
</tr>
<tr>
<td style="text-align: left;">All</td>
<td style="text-align: center;">0.70</td>
<td style="text-align: center;">0.69</td>
<td style="text-align: center;">0.76</td>
<td style="text-align: center;">0.84</td>
<td style="text-align: center;">0.81</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">0.99</td>
<td style="text-align: center;">0.98</td>
<td style="text-align: center;">-</td>
</tr>
</tbody>
</table>
<p>Table 22: Performance breakdown of T5-3B with different labels for Logical Equivalence set. Please refer to Appendix G for more details.</p>
<div class="codehilite"><pre><span></span><code><span class="n">Algorithm</span><span class="w"> </span><span class="mh">1</span><span class="o">:</span><span class="w"> </span><span class="n">Sampling</span><span class="w"> </span><span class="n">Algorithm</span>
<span class="w">    </span><span class="n">Input</span><span class="w"> </span><span class="n">\(\operatorname{icocab}\)</span><span class="w"> </span><span class="n">containing</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">corpus</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">all</span>
<span class="w">        </span><span class="n">predicates</span><span class="p">,</span><span class="w"> </span><span class="n">ruleset</span><span class="w"> </span><span class="n">containing</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">set</span><span class="w"> </span><span class="n">of</span>
<span class="w">        </span><span class="n">valid</span><span class="w"> </span><span class="n">rules</span><span class="p">,</span><span class="w"> </span><span class="n">predicate</span><span class="w"> </span><span class="n">negation</span><span class="w"> </span><span class="n">probability</span>
<span class="w">        </span><span class="n">\(n_{1}\),</span><span class="w"> </span><span class="n">statement</span><span class="w"> </span><span class="n">negation</span><span class="w"> </span><span class="n">probability</span><span class="w"> </span><span class="n">\(n_{2}\),</span><span class="w"> </span><span class="n">max</span>
<span class="w">        </span><span class="n">reasoning</span><span class="w"> </span><span class="n">depth</span><span class="w"> </span><span class="n">\(d\).</span>
<span class="w">    </span><span class="n">Output</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">A</span><span class="w"> </span><span class="n">theory</span><span class="w"> </span><span class="n">containing</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">set</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">facts</span><span class="w"> </span><span class="k">and</span>
<span class="w">        </span><span class="n">rules</span><span class="p">,</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">statement</span><span class="p">,</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">corresponding</span>
<span class="w">        </span><span class="n">label</span><span class="w"> </span><span class="n">\(\in\{0,1,2\}\)</span>
<span class="w">    </span><span class="n">pred_num</span><span class="w"> </span><span class="n">\(\sim</span><span class="w"> </span><span class="n">U</span><span class="p">[</span><span class="mh">10</span><span class="p">,</span><span class="mh">30</span><span class="p">]</span><span class="n">\)</span>
<span class="w">    </span><span class="n">preds</span><span class="w"> </span><span class="n">\(\leftarrow\)</span><span class="w"> </span><span class="n">Sample</span><span class="w"> </span><span class="p">(</span><span class="n">vocab</span><span class="p">,</span><span class="w"> </span><span class="n">pred_num</span><span class="p">)</span>
<span class="w">    </span><span class="n">set</span><span class="w"> </span><span class="n">\(l</span><span class="w"> </span><span class="n">\sim</span><span class="w"> </span><span class="n">U</span><span class="p">[</span><span class="mh">1</span><span class="p">,</span><span class="w"> </span><span class="n">d</span><span class="p">]</span><span class="n">\)</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="n">group</span><span class="w"> </span><span class="n">preds</span><span class="w"> </span><span class="n">into</span><span class="w"> </span><span class="n">\(l\)</span><span class="w"> </span><span class="n">layers</span>
<span class="w">    </span><span class="n">rules</span><span class="w"> </span><span class="n">\(\leftarrow[]\)</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="n">predicate</span><span class="w"> </span><span class="n">\(p\)</span><span class="w"> </span><span class="n">in</span><span class="w"> </span><span class="n">layer</span><span class="w"> </span><span class="n">\(1</span><span class="w"> </span><span class="n">\leq</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="n">\leq</span><span class="w"> </span><span class="n">l\)</span><span class="w"> </span><span class="k">do</span>
<span class="w">        </span><span class="n">Negate</span><span class="w"> </span><span class="n">\(p\)</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="n">probability</span><span class="w"> </span><span class="n">\(n_{1}\)</span>
<span class="w">        </span><span class="n">\(q</span><span class="w"> </span><span class="n">\sim</span><span class="w"> </span><span class="n">U</span><span class="p">[</span><span class="mh">0</span><span class="p">,</span><span class="mh">1</span><span class="p">]</span><span class="n">\)</span>
<span class="w">        </span><span class="k">assign</span><span class="w"> </span><span class="n">label</span><span class="w"> </span><span class="n">\(q\)</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">predicate</span><span class="w"> </span><span class="n">\(p\)</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">\(i</span><span class="w"> </span><span class="n">\geq</span><span class="w"> </span><span class="mh">1</span><span class="n">\)</span><span class="w"> </span><span class="n">then</span>
<span class="w">            </span><span class="n">\(k</span><span class="w"> </span><span class="n">\sim</span><span class="w"> </span><span class="n">U</span><span class="p">[</span><span class="mh">1</span><span class="p">,</span><span class="mh">2</span><span class="p">]</span><span class="n">\)</span>
<span class="w">            </span><span class="n">cand</span><span class="w"> </span><span class="n">\(\leftarrow</span><span class="w"> </span><span class="n">p\)</span><span class="w"> </span><span class="n">in</span><span class="w"> </span><span class="n">layer</span><span class="w"> </span><span class="n">\(i-1\)</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="n">label</span><span class="w"> </span><span class="n">\(q\)</span>
<span class="w">            </span><span class="n">body</span><span class="w"> </span><span class="n">\(\leftarrow\)</span><span class="w"> </span><span class="n">Sample</span><span class="p">(</span><span class="n">cand</span><span class="p">,</span><span class="w"> </span><span class="n">\(k\)</span><span class="w"> </span><span class="p">)</span>
<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">len</span><span class="p">(</span><span class="n">body</span><span class="p">)</span><span class="w"> </span><span class="n">\(&gt;1\)</span><span class="w"> </span><span class="n">then</span>
<span class="w">                </span><span class="n">operator</span><span class="w"> </span><span class="n">\(\leftarrow\)</span><span class="w"> </span><span class="n">Sample</span><span class="w"> </span><span class="n">\((|\wedge,</span><span class="w"> </span><span class="n">\vee|,</span><span class="w"> </span><span class="mh">1</span><span class="p">)</span><span class="n">\)</span>
<span class="w">                </span><span class="n">Compose</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">predicates</span><span class="w"> </span><span class="n">in</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">body</span>
<span class="w">                </span><span class="n">using</span><span class="w"> </span><span class="n">operator</span>
<span class="w">            </span><span class="k">end</span><span class="w"> </span><span class="k">if</span>
<span class="w">            </span><span class="n">\(r</span><span class="w"> </span><span class="n">\leftarrow(\)</span><span class="w"> </span><span class="n">body</span><span class="w"> </span><span class="n">\(\Longrightarrow</span><span class="w"> </span><span class="n">p</span><span class="p">)</span><span class="n">\)</span>
<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">Validate</span><span class="p">(</span><span class="n">ruleset</span><span class="p">,</span><span class="w"> </span><span class="n">\(r\)</span><span class="w"> </span><span class="p">)</span><span class="w"> </span><span class="n">then</span>
<span class="w">                </span><span class="n">add</span><span class="w"> </span><span class="n">\(r\)</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">rules</span>
<span class="w">            </span><span class="k">else</span>
<span class="w">                </span><span class="cm">/* Rule \(r\) does not match any</span>
<span class="cm">                valid rule forms, so the</span>
<span class="cm">                predicate is not provable */</span>
<span class="w">                </span><span class="k">assign</span><span class="w"> </span><span class="n">label</span><span class="w"> </span><span class="mh">0</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">predicate</span><span class="w"> </span><span class="n">\(p\)</span>
<span class="w">            </span><span class="k">end</span><span class="w"> </span><span class="k">if</span>
<span class="w">        </span><span class="k">end</span><span class="w"> </span><span class="k">if</span>
<span class="w">    </span><span class="k">end</span><span class="w"> </span><span class="k">for</span>
<span class="w">    </span><span class="n">facts</span><span class="w"> </span><span class="n">\(\leftarrow\)</span><span class="w"> </span><span class="n">predicates</span><span class="w"> </span><span class="n">in</span><span class="w"> </span><span class="n">layer</span><span class="w"> </span><span class="mh">1</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="n">label</span><span class="w"> </span><span class="mh">1</span>
<span class="w">    </span><span class="n">statement</span><span class="w"> </span><span class="n">\(\leftarrow\)</span><span class="w"> </span><span class="n">Sample</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span><span class="w"> </span><span class="mh">1</span><span class="p">)</span>
<span class="w">    </span><span class="n">label</span><span class="w"> </span><span class="n">\(\leftarrow\)</span><span class="w"> </span><span class="n">pre</span><span class="o">-</span><span class="n">assigned</span><span class="w"> </span><span class="n">label</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">statement</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">label</span><span class="w"> </span><span class="n">\(==1\)</span><span class="w"> </span><span class="n">then</span>
<span class="w">        </span><span class="n">Negate</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">statement</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="n">probability</span><span class="w"> </span><span class="n">\(n_{2}\)</span>
<span class="w">        </span><span class="n">label</span><span class="w"> </span><span class="n">\(\leftarrow</span><span class="w"> </span><span class="mh">2</span><span class="n">\)</span>
<span class="w">    </span><span class="k">end</span><span class="w"> </span><span class="k">if</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="p">(</span><span class="n">facts</span><span class="p">,</span><span class="w"> </span><span class="n">rules</span><span class="p">,</span><span class="w"> </span><span class="n">statement</span><span class="p">,</span><span class="w"> </span><span class="n">label</span><span class="p">)</span>
</code></pre></div>

<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{7}$ https://www.statsmodels.org/dev/generated/ statsmodels.stats.inter_rater.fleiss_kappa.html&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref4:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref5:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>