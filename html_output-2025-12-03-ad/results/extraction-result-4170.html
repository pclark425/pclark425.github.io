<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-4170 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-4170</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-4170</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-97.html">extraction-schema-97</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs or AI systems being used to extract, discover, or distill quantitative laws, relationships, or patterns from scientific papers or literature.</div>
                <p><strong>Paper ID:</strong> paper-272223451</p>
                <p><strong>Paper Title:</strong> The transformative impact of large language models on medical writing and publishing: current applications, challenges and future directions</p>
                <p><strong>Paper Abstract:</strong> Large language models (LLMs) are rapidly transforming medical writing and publishing. This review article focuses on experimental evidence to provide a comprehensive overview of the current applications, challenges, and future implications of LLMs in various stages of academic research and publishing process. Global surveys reveal a high prevalence of LLM usage in scientific writing, with both potential benefits and challenges associated with its adoption. LLMs have been successfully applied in literature search, research design, writing assistance, quality assessment, citation generation, and data analysis. LLMs have also been used in peer review and publication processes, including manuscript screening, generating review comments, and identifying potential biases. To ensure the integrity and quality of scholarly work in the era of LLM-assisted research, responsible artificial intelligence (AI) use is crucial. Researchers should prioritize verifying the accuracy and reliability of AI-generated content, maintain transparency in the use of LLMs, and develop collaborative human-AI workflows. Reviewers should focus on higher-order reviewing skills and be aware of the potential use of LLMs in manuscripts. Editorial offices should develop clear policies and guidelines on AI use and foster open dialogue within the academic community. Future directions include addressing the limitations and biases of current LLMs, exploring innovative applications, and continuously updating policies and practices in response to technological advancements. Collaborative efforts among stakeholders are necessary to harness the transformative potential of LLMs while maintaining the integrity of medical writing and publishing.</p>
                <p><strong>Cost:</strong> 0.01</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e4170.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e4170.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs or AI systems being used to extract, discover, or distill quantitative laws, relationships, or patterns from scientific papers or literature.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>FunSearch</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>FunSearch (evolutionary program search paired with an LLM)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An evolutionary program-search procedure that pairs a pretrained large language model with a systematic evaluator to generate candidate programs/constructions and identify improved mathematical results; applied to find new constructions in extremal combinatorics (cap set problem).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Mathematical discoveries from program search with large language models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>FunSearch</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>FunSearch couples a pretrained LLM (used to propose candidate programmatic constructions or proofs) with a systematic evaluator that tests candidates against a formal objective; the pipeline iteratively generates program candidates, evaluates them with domain-specific checks/benchmarks, and uses evolutionary search operators to propose improved candidates that beat prior best-known results.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Mathematics (extremal combinatorics)</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td>Not applicable (applied as a case study to one mathematical problem: the cap set problem)</td>
                        </tr>
                        <tr>
                            <td><strong>law_type</strong></td>
                            <td>Mathematical constructions / combinatorial bounds (discoveries that improve quantitative bounds in combinatorics)</td>
                        </tr>
                        <tr>
                            <td><strong>law_examples</strong></td>
                            <td>Discovery of new constructions of large cap sets (explicit combinatorial constructions that improve previously known size bounds); no explicit equations are provided in this review.</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_method</strong></td>
                            <td>Programmatic search: LLM generates candidate programs/constructions; a systematic evaluator executes/tests candidates against mathematical criteria and benchmarks to extract improved quantitative constructions/relationships.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approach</strong></td>
                            <td>Benchmarking against best-known results in the domain (surpassed prior best-known constructions for the cap set problem); validation by demonstrating improved formal/computational bounds.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Not numerically specified in this review beyond qualitative statement of surpassing best-known results; no accuracy/precision metrics reported here.</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td>Not reported in this review.</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>The review does not detail limitations of FunSearch; the paper mentions only that the approach surpassed best-known results for the case study but does not report generalization limits or failure modes in this text.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared against prior human-derived best-known mathematical constructions/benchmarks; FunSearch produced constructions that surpassed those baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The transformative impact of large language models on medical writing and publishing: current applications, challenges and future directions', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4170.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e4170.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs or AI systems being used to extract, discover, or distill quantitative laws, relationships, or patterns from scientific papers or literature.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Automated social science</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Automated social science: LLMs paired with structural causal models</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An approach that uses large language models to propose social-science hypotheses and structural causal models, and then tests those hypotheses via simulations to discover or probe causal relationships not directly recoverable from LLM elicitation alone.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Automated social science: language models as scientist and subjects</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Automated social science pipeline (LLM + structural causal model)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Pipeline where an LLM generates hypotheses or causal model proposals from prompts and literature-like inputs; these proposed models are formalized as structural causal models and then tested in simulated social-interaction environments or datasets to evaluate and refine quantitative causal relationships.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Social science (computational social science, causal inference)</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td>Not specified in this review (method described conceptually; likely applied to simulated datasets/case studies in the cited preprint)</td>
                        </tr>
                        <tr>
                            <td><strong>law_type</strong></td>
                            <td>Causal relationships / quantitative causal hypotheses (empirical causal relationships tested in simulation)</td>
                        </tr>
                        <tr>
                            <td><strong>law_examples</strong></td>
                            <td>No explicit formulae provided in the review; described generically as proposed and tested causal relationships in simulated social interactions.</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_method</strong></td>
                            <td>Text-mining/hypothesis generation by LLM followed by formalization into structural causal models and simulation-based testing to distill causal relationships.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approach</strong></td>
                            <td>Testing proposed causal models via simulations of social interactions and evaluating whether simulated data support the hypothesized causal relationships.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Not specified in this review (no numerical metrics provided).</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td>Not reported in this review.</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>The review gives a high-level description only and does not enumerate limitations; details about robustness, generalizability, or dependence on simulation fidelity are not provided here.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Not detailed in this review; approach is presented as enabling hypothesis proposal and testing beyond direct LLM elicitation.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The transformative impact of large language models on medical writing and publishing: current applications, challenges and future directions', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4170.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e4170.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs or AI systems being used to extract, discover, or distill quantitative laws, relationships, or patterns from scientific papers or literature.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Coscientist</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Coscientist (GPT-4-driven autonomous experimental chemistry system)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An AI system driven by GPT-4 that autonomously designs, plans, and executes complex chemical experiments and optimization campaigns, demonstrated by optimizing palladium-catalyzed cross-coupling reactions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Autonomous chemical research with large language models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Coscientist</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Coscientist is a GPT-4–driven system that composes experimental plans from chemical knowledge, translates plans into lab-executable protocols, executes or orchestrates experiments (often via robotic/automated platforms), analyzes experimental outcomes, and iteratively proposes new experiments to optimize target reaction metrics (e.g., yield).</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Chemistry (experimental organic / reaction optimization)</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td>Not applicable (system demonstrated on experimental optimization tasks; the review cites the demonstration rather than a literature-mining study)</td>
                        </tr>
                        <tr>
                            <td><strong>law_type</strong></td>
                            <td>Empirical optimization relationships (relationships between reaction conditions and yields; empirical parameter–outcome mappings)</td>
                        </tr>
                        <tr>
                            <td><strong>law_examples</strong></td>
                            <td>Optimization of palladium-catalyzed cross-couplings (no explicit quantitative equations provided in the review; described as successful optimization of reaction conditions to improve yields).</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_method</strong></td>
                            <td>Not a literature-extraction system: derives empirical relationships by designing and running experiments, analyzing results, and iteratively refining experimental parameters (closed-loop autonomous experimentation rather than mining published papers).</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approach</strong></td>
                            <td>Experimental validation via laboratory execution and observed improvements in reaction outcomes (successful optimization of target reactions reported in cited work).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>The review states successful optimization but does not report numerical metrics (e.g., percent yield improvements) in this text.</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td>Not specified in this review.</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Review does not enumerate detailed limitations for Coscientist here; the description indicates domain-specific setup (lab automation) is required and the system's performance depends on integration with experimental platforms.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Not explicitly compared to human experimenters in this review excerpt; cited work demonstrates Coscientist's capabilities on reaction optimization tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The transformative impact of large language models on medical writing and publishing: current applications, challenges and future directions', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Mathematical discoveries from program search with large language models <em>(Rating: 2)</em></li>
                <li>Automated social science: language models as scientist and subjects <em>(Rating: 2)</em></li>
                <li>Autonomous chemical research with large language models <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-4170",
    "paper_id": "paper-272223451",
    "extraction_schema_id": "extraction-schema-97",
    "extracted_data": [
        {
            "name_short": "FunSearch",
            "name_full": "FunSearch (evolutionary program search paired with an LLM)",
            "brief_description": "An evolutionary program-search procedure that pairs a pretrained large language model with a systematic evaluator to generate candidate programs/constructions and identify improved mathematical results; applied to find new constructions in extremal combinatorics (cap set problem).",
            "citation_title": "Mathematical discoveries from program search with large language models",
            "mention_or_use": "mention",
            "system_name": "FunSearch",
            "system_description": "FunSearch couples a pretrained LLM (used to propose candidate programmatic constructions or proofs) with a systematic evaluator that tests candidates against a formal objective; the pipeline iteratively generates program candidates, evaluates them with domain-specific checks/benchmarks, and uses evolutionary search operators to propose improved candidates that beat prior best-known results.",
            "model_name": null,
            "model_size": null,
            "scientific_domain": "Mathematics (extremal combinatorics)",
            "number_of_papers": "Not applicable (applied as a case study to one mathematical problem: the cap set problem)",
            "law_type": "Mathematical constructions / combinatorial bounds (discoveries that improve quantitative bounds in combinatorics)",
            "law_examples": "Discovery of new constructions of large cap sets (explicit combinatorial constructions that improve previously known size bounds); no explicit equations are provided in this review.",
            "extraction_method": "Programmatic search: LLM generates candidate programs/constructions; a systematic evaluator executes/tests candidates against mathematical criteria and benchmarks to extract improved quantitative constructions/relationships.",
            "validation_approach": "Benchmarking against best-known results in the domain (surpassed prior best-known constructions for the cap set problem); validation by demonstrating improved formal/computational bounds.",
            "performance_metrics": "Not numerically specified in this review beyond qualitative statement of surpassing best-known results; no accuracy/precision metrics reported here.",
            "success_rate": "Not reported in this review.",
            "challenges_limitations": "The review does not detail limitations of FunSearch; the paper mentions only that the approach surpassed best-known results for the case study but does not report generalization limits or failure modes in this text.",
            "comparison_baseline": "Compared against prior human-derived best-known mathematical constructions/benchmarks; FunSearch produced constructions that surpassed those baselines.",
            "uuid": "e4170.0",
            "source_info": {
                "paper_title": "The transformative impact of large language models on medical writing and publishing: current applications, challenges and future directions",
                "publication_date_yy_mm": "2024-09"
            }
        },
        {
            "name_short": "Automated social science",
            "name_full": "Automated social science: LLMs paired with structural causal models",
            "brief_description": "An approach that uses large language models to propose social-science hypotheses and structural causal models, and then tests those hypotheses via simulations to discover or probe causal relationships not directly recoverable from LLM elicitation alone.",
            "citation_title": "Automated social science: language models as scientist and subjects",
            "mention_or_use": "mention",
            "system_name": "Automated social science pipeline (LLM + structural causal model)",
            "system_description": "Pipeline where an LLM generates hypotheses or causal model proposals from prompts and literature-like inputs; these proposed models are formalized as structural causal models and then tested in simulated social-interaction environments or datasets to evaluate and refine quantitative causal relationships.",
            "model_name": null,
            "model_size": null,
            "scientific_domain": "Social science (computational social science, causal inference)",
            "number_of_papers": "Not specified in this review (method described conceptually; likely applied to simulated datasets/case studies in the cited preprint)",
            "law_type": "Causal relationships / quantitative causal hypotheses (empirical causal relationships tested in simulation)",
            "law_examples": "No explicit formulae provided in the review; described generically as proposed and tested causal relationships in simulated social interactions.",
            "extraction_method": "Text-mining/hypothesis generation by LLM followed by formalization into structural causal models and simulation-based testing to distill causal relationships.",
            "validation_approach": "Testing proposed causal models via simulations of social interactions and evaluating whether simulated data support the hypothesized causal relationships.",
            "performance_metrics": "Not specified in this review (no numerical metrics provided).",
            "success_rate": "Not reported in this review.",
            "challenges_limitations": "The review gives a high-level description only and does not enumerate limitations; details about robustness, generalizability, or dependence on simulation fidelity are not provided here.",
            "comparison_baseline": "Not detailed in this review; approach is presented as enabling hypothesis proposal and testing beyond direct LLM elicitation.",
            "uuid": "e4170.1",
            "source_info": {
                "paper_title": "The transformative impact of large language models on medical writing and publishing: current applications, challenges and future directions",
                "publication_date_yy_mm": "2024-09"
            }
        },
        {
            "name_short": "Coscientist",
            "name_full": "Coscientist (GPT-4-driven autonomous experimental chemistry system)",
            "brief_description": "An AI system driven by GPT-4 that autonomously designs, plans, and executes complex chemical experiments and optimization campaigns, demonstrated by optimizing palladium-catalyzed cross-coupling reactions.",
            "citation_title": "Autonomous chemical research with large language models",
            "mention_or_use": "mention",
            "system_name": "Coscientist",
            "system_description": "Coscientist is a GPT-4–driven system that composes experimental plans from chemical knowledge, translates plans into lab-executable protocols, executes or orchestrates experiments (often via robotic/automated platforms), analyzes experimental outcomes, and iteratively proposes new experiments to optimize target reaction metrics (e.g., yield).",
            "model_name": "GPT-4",
            "model_size": null,
            "scientific_domain": "Chemistry (experimental organic / reaction optimization)",
            "number_of_papers": "Not applicable (system demonstrated on experimental optimization tasks; the review cites the demonstration rather than a literature-mining study)",
            "law_type": "Empirical optimization relationships (relationships between reaction conditions and yields; empirical parameter–outcome mappings)",
            "law_examples": "Optimization of palladium-catalyzed cross-couplings (no explicit quantitative equations provided in the review; described as successful optimization of reaction conditions to improve yields).",
            "extraction_method": "Not a literature-extraction system: derives empirical relationships by designing and running experiments, analyzing results, and iteratively refining experimental parameters (closed-loop autonomous experimentation rather than mining published papers).",
            "validation_approach": "Experimental validation via laboratory execution and observed improvements in reaction outcomes (successful optimization of target reactions reported in cited work).",
            "performance_metrics": "The review states successful optimization but does not report numerical metrics (e.g., percent yield improvements) in this text.",
            "success_rate": "Not specified in this review.",
            "challenges_limitations": "Review does not enumerate detailed limitations for Coscientist here; the description indicates domain-specific setup (lab automation) is required and the system's performance depends on integration with experimental platforms.",
            "comparison_baseline": "Not explicitly compared to human experimenters in this review excerpt; cited work demonstrates Coscientist's capabilities on reaction optimization tasks.",
            "uuid": "e4170.2",
            "source_info": {
                "paper_title": "The transformative impact of large language models on medical writing and publishing: current applications, challenges and future directions",
                "publication_date_yy_mm": "2024-09"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Mathematical discoveries from program search with large language models",
            "rating": 2,
            "sanitized_title": "mathematical_discoveries_from_program_search_with_large_language_models"
        },
        {
            "paper_title": "Automated social science: language models as scientist and subjects",
            "rating": 2,
            "sanitized_title": "automated_social_science_language_models_as_scientist_and_subjects"
        },
        {
            "paper_title": "Autonomous chemical research with large language models",
            "rating": 2,
            "sanitized_title": "autonomous_chemical_research_with_large_language_models"
        }
    ],
    "cost": 0.010345499999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>The transformative impact of large language models on medical writing and publishing: current applications, challenges and future directions</p>
<p>Sangzin Ahn sangzinahn@inje.ac.kr 
Department of Pharmacology
PharmacoGenomics Research Center</p>
<p>Center for Personalized Precision Medicine of Tuberculosis
Inje University College of Medicine
47392BusanKorea</p>
<p>The transformative impact of large language models on medical writing and publishing: current applications, challenges and future directions
p 1226-4512D94A951B55BE5A6B69ECB36B6660799C10.4196/kjpp.2024.28.5.393Received March 20, 2024 Revised June 10, 2024 Accepted June 14, 2024
Large language models (LLMs) are rapidly transforming medical writing and publishing.This review article focuses on experimental evidence to provide a comprehensive overview of the current applications, challenges, and future implications of LLMs in various stages of academic research and publishing process.Global surveys reveal a high prevalence of LLM usage in scientific writing, with both potential benefits and challenges associated with its adoption.LLMs have been successfully applied in literature search, research design, writing assistance, quality assessment, citation generation, and data analysis.LLMs have also been used in peer review and publication processes, including manuscript screening, generating review comments, and identifying potential biases.To ensure the integrity and quality of scholarly work in the era of LLM-assisted research, responsible artificial intelligence (AI) use is crucial.Researchers should prioritize verifying the accuracy and reliability of AI-generated content, maintain transparency in the use of LLMs, and develop collaborative human-AI workflows.Reviewers should focus on higher-order reviewing skills and be aware of the potential use of LLMs in manuscripts.Editorial offices should develop clear policies and guidelines on AI use and foster open dialogue within the academic community.Future directions include addressing the limitations and biases of current LLMs, exploring innovative applications, and continuously updating policies and practices in response to technological advancements.Collaborative efforts among stakeholders are necessary to harness the transformative potential of LLMs while maintaining the integrity of medical writing and publishing.</p>
<p>INTRODUCTION</p>
<p>The rapid advancement of generative artificial intelligence (AI) is transforming the landscape of scientific research and academic writing [1].Large language models (LLMs), such as ChatGPT, Claude, Copilot and Gemini, have demonstrated remarkable capabilities in understanding and generating human-like text.These models are trained on vast amounts of data, allowing them to assist researchers with various tasks, from literature analysis and content generation to language translation and also peer review and publication processes [2,3].The rapid improvements in model algorithms and the increasing computational power dedicated to running these models are outpacing Moore's Law [4].As these LLMs are becoming more sophisticated and prevalent in academic publishing, its implications for research integrity and establishing appropriate policies and guidelines has become increasingly important.</p>
<p>As LLMs become increasingly integrated into the research and
Ahn S
writing process (Fig. 1), concerns have arisen regarding the quality, accuracy, and transparency of AI-generated content [5].The scientific community has engaged in debates about the appropriate use of these tools, particularly in light of incidents such as the listing of ChatGPT as an author [6].Despite the rapid adoption of LLMs, a recent study found that only 18% of the top 100 Korean medical journals had explicit policies addressing their use as of March 2024 [7].This lack of clear guidelines highlights the need for the scientific community to develop well-defined, realistic, and coherent policies that promote the responsible and productive integration of AI in academic endeavors [8].</p>
<p>The aim of this review article is to provide a comprehensive overview of the current state of LLMs in medical writing and publishing, focusing on experimental evidence rather than perspective papers.By examining the actual capabilities and limitations of these tools, as well as the ethical considerations surrounding their use, this review seeks to inform policy decisions and guide the responsible integration of LLMs in research.The article will explore the applications of LLMs in various stages of the research process, including literature analysis, content generation, and peer review.Additionally, recommendations for researchers, reviewers, and editorial offices will be provided to ensure the integrity and quality of AI-assisted academic work.</p>
<p>PREVALENCE OF LLM USAGE IN SCIENTIFIC WRITING</p>
<p>Global surveys on LLM use in academia</p>
<p>The use of LLMs has become increasingly prevalent in academia, particularly in biomedical and clinical sciences [9].A global survey conducted by Nature in July 2023 found that about one-third (31%) of postdoc respondents reported using AI chatbots for tasks such as refining text, generating or editing code, and managing literature in their fields [10].Similarly, a global survey of 456 urologists in May 2023 revealed that 47.7% use LLMs [11].There has been a significant increase in the suspected use of LLMs for writing articles submitted to an orthopedic journal, with 41.0% of articles having suspected AI use over 10% [12].The median probability of AI-generated abstracts increased from 3.8% to 5.7% in 2022 and 2023 across Q1 journals in medical imaging [13].Moreover, evidence of AI use in reviews was found in a study of AI conference peer reviews that took place after the release of ChatGPT, suggesting that between 6.5% and 16.9% of reviews have been substantially modified by LLMs [14].</p>
<p>Potential benefits and challenges of LLM usage in academic writing</p>
<p>The use of LLM tools in academic writing has been associated with perceived benefits and efficiency gains in the research and writing process [10].A quantitative study found that incorporating ChatGPT into the workflow for professional writing tasks reduced the average time taken by 40% and increased output quality by 18% [15].This potential for increased productivity and output quality has been a driving factor in the adoption of LLMs, especially given the growing pressure on researchers to increase their research productivity and output [16].</p>
<p>However, the ease with which LLMs can generate convincing academic content has raised concerns about the potential for misuse and fraud.One study demonstrated that GPT-3 can create a highly convincing fraudulent article resembling a genuine scientific paper in terms of word usage, sentence structure, and overall composition, all within just 1 h and without any special training of the user [17].Similarly, another study in early 2023 used Chat-GPT-4 to generate 2 fake orthopedic surgery papers, with one passing review and being accepted, and the other being rejected but referred to another journal for consideration [18].</p>
<p>The challenges in detecting AI-generated content further complicate the issue.In a study where ChatGPT-3.5 generated 50 fake research abstracts from titles, only 8% met specific formatting criteria, yet achieved a 100% originality score in plagiarism detectors [19].While AI detectors identified them as AI-created, human reviewers correctly spotted only 68% as AI-crafted and mistakenly tagged 14% of original abstracts as such.This highlights the nuanced challenges and considerations in integrating AI into academic writing while upholding scientific rigor.</p>
<p>The lack of unified guidelines and unclear policies regarding the extent of AI tool usage considered acceptable has left research-Fig.1.Large language models (LLMs) can be used in various steps of research and writing.A detailed tutorial of how to utilize large language models during each process is provided as a supplementary material.ers in a state of uncertainty [8].The term "use of AI" encompasses a wide spectrum of applications, ranging from providing a keyword to generate an entire manuscript, listing items to be mentioned and converting them into paragraphs, or strictly using AI for typo and punctuation correction only.The difficulty in detecting AI-generated content and the high risk of false-positives, especially for non-native English writing, further compound the issue [20].The varying results of LLM usage rates in studies from the previous section underscore the challenges in detection and the need for more robust and standardized methods.</p>
<p>Literature Search</p>
<p>APPLICATIONS IN RESEARCH AND WRITING</p>
<p>Literature search and research design</p>
<p>AI tools have demonstrated potential in assisting researchers with literature searches and systematic reviews (Table 1).For instance, ChatGPT-3.5 and ChatGPT-4 were used to generate PICO-based search queries in the field of orthodontics, showcasing their ability to aid the systematic review process [21].In another study, ChatGPT-3.5 was employed to generate 50 topics in medical research and create a research protocol for each topic, with an 84% accuracy rate of references [22].Additionally, Chat-GPT-4 was used to analyze 2,491 abstracts published in European Resuscitation Council conferences, highlighting its capabilities in bibliometric analysis of academic abstracts and its potential impact on academic writing and publishing [23].</p>
<p>Writing assistance and quality assessment</p>
<p>LLMs have been extensively applied in various aspects of writing assistance, particularly in abstract generation (Table 1).ChatGPT-3.5 demonstrated the ability to generate high-quality abstracts from clinical trial keywords and data tables, showcasing impressive accuracy with minor errors [24].However, its performance varied significantly when tasked with writing abstracts on broad, well-documented topics compared to more specific, recently published subjects [25].The low plagiarism scores and difficult detection of AI-generated abstracts and the ethical boundaries of using such technology in academic writing have also been discussed [19].Although ChatGPT-3.5 could generate abstracts that were challenging to distinguish from human-written ones in the arthroplasty field, the quality was notably better in those written by humans [26].Using both ChatGPT-3.5 and ChatGPT-4 to write abstracts for randomized controlled trials revealed that, despite their potential, the quality was not satisfactory, highlighting the need for further development and refinement in generative AI tools [27].</p>
<p>In addition to abstract generation, LLMs have been used to assist in various other writing tasks.For example, GPT-4 was used to generate introduction sections for randomized controlled trials, with non-inferiority confirmed and higher readability scores compared to human-written introductions [28].ChatGPT was also used to write medical case reports [29] and to write a clinical summary containing patient situation, case evaluation and appropriate interventions [30].In a study regarding human reproduction, ChatGPT could produce high-quality text and efficiently summarize information, but its ability to interpret data and answer scientific questions was limited [31].</p>
<p>LLMs have been employed to generate cover letters for abstracts, with non-inferiority confirmed by randomized trials and higher readability scores [32].These tools have also been used to facilitate language learning and improve technical writing skills for non-native English speakers, which is particularly meaningful for scholars using English as a non-primary language [33].However, it is important to note that the effectiveness of these tools may vary, as one study found that the free version of ChatGPT-3.5 was not an effective writing coach [34].Interestingly, fine-tuning a language model to an author's previous works can also enhance academic writing, especially for generating text and ideas related to the scholar's prior work, offering a personalized approach to writing assistance [35].Ahn S</p>
<p>Citation and reference generation</p>
<p>Citation and reference generation is another area where LLMs have been applied, albeit with varying levels of success (Table 1).In a study conducted in early 2023, researchers generated 50 references for 10 common topic keywords relevant to head and neck surgery, finding that only 10% of the generated references were accurate [36].However, in a study comparing the performance between multiple LLM-based tools, ChatGPT-3.5 outperformed Bing Chat (old version of Microsoft Copilot) and Google Bard (old version of Google Gemini) with a 38% accuracy rate in nephrology reference generation [37].ChatGPT-4 showed substantial improvements, achieving a 74.3% correct reference rate for otolaryngology topics [38] and a high accuracy rate ranging from 73% to 87% for generating full citations of the most cited otolaryngology papers [39].</p>
<p>Despite these advancements, the lack of a fact-checking step in the text generation algorithms of LLMs leads to inherent inaccuracies in reference generation, suggesting that incorporating techniques such as retrieval-augmented generation is crucial to enhance reliability [40].Specific tools tailored for article search, such as Perplexity, Elicit and Consensus can be used instead of LLM chatbots for general purpose.These tools analyze the researcher's input using LLMs and retrieve related articles from a scholarly database, thereby reducing the likelihood of generating non-existent references.A tutorial on how to utilize LLM-based tools for each stage of article writing is provided in Supplementary Data 1.</p>
<p>Code generation and data analysis</p>
<p>LLMs have shown promise in code generation and data analysis, potentially impacting life sciences education and research by allowing researchers to collaborate with such models to produce functional code [41].For example, ChatGPT-4 was tested to build two cancer economic models, demonstrating that AI can automate health economic model construction, potentially accelerating development timelines and reducing costs [42].Furthermore, the Code Interpreter feature in ChatGPT allows users to upload data files and ask the chatbot to perform data analysis using natural language interactions.The chatbot can read the data, plan steps for data analysis, write python code to perform the analysis, and visualize the results, effectively democratizing bioinformatics by breaking down the barrier of code writing [43,44].These advancements suggest that when integrated with tools, LLMs have the potential to revolutionize the way researchers approach code generation and data analysis in science, making these processes more accessible, efficient, and cost-effective (Table 1).</p>
<p>Automation of scientific discovery</p>
<p>Recent advancements in LLMs have demonstrated their poten-tial to automate and accelerate scientific discovery across various domains.An approach for automatically generating and testing social scientific hypotheses using LLMs and structural causal models has been introduced [45].This method enables the proposal and testing of causal relationships in simulated social interactions, providing insights that are not directly available through LLM elicitation alone.In the field of mathematics, an evolutionary procedure called FunSearch has been developed, which pairs a pretrained LLM with a systematic evaluator to surpass bestknown results in complex problems [46].Applying FunSearch to the cap set problem in extremal combinatorics led to the discovery of new constructions of large cap sets, pushing the boundaries of existing LLM-based approaches.</p>
<p>Moreover, an AI system driven by GPT-4, named Coscientist, has been showcased to autonomously design, plan, and perform complex experiments in chemistry [47].Coscientist successfully optimized palladium-catalyzed cross-couplings, demonstrating the versatility and efficacy of AI systems in advancing research.These examples highlight the transformative potential of LLMs in automating and accelerating scientific discovery across various disciplines, from social sciences and mathematics to chemistry.As LLMs continue to evolve and become more sophisticated, their impact on research and scientific discovery is expected to grow, potentially revolutionizing the way researchers approach complex problems and accelerating the pace of innovation across multiple fields.</p>
<p>APPLICATIONS IN PEER REVIEW AND PUBLICATION</p>
<p>Manuscript screening and quality assessment</p>
<p>LLMs have shown potential in assisting with manuscript screening and quality assessment (Table 2).Studies have demonstrated their effectiveness in proofreading and error detection [48], as well as predicting peer review outcomes [49].LLMs can also be used to assess the quality and risk of bias in systematic reviews [50] and develop grading systems for evaluating methodology sections [51].These applications could be particularly beneficial for researchers from underprivileged regions who may lack access to timely and quality feedback mechanisms [52].</p>
<p>Generating review comments and feedback</p>
<p>LLMs can assist reviewers in generating opinions and comments on manuscripts, potentially reducing reviewer fatigue and streamlining the peer review process [53].A large-scale retrospective study comparing GPT-4 generated comments with human reviews found that AI-generated comments had a 31%-39% overlap with human reviewers, while inter-human overlap was 29%-35% [54].Additionally, a prospective study revealed that 70% of scholars found AI comments to have at least partial alignment with human reviews, and 20% found AI feedback more helpful than human comments [54].</p>
<p>However, a relatively small study using 21 research papers and having 2 human reviewers and AI to give review comments showed that while ChatGPT-3.5 and ChatGPT-4.0demonstrated good concordance with accepted papers, they provided overly positive reviews for rejected papers [55].While these limitations should be acknowledged, the overall evidence suggests that LLMs hold great promise in revolutionizing the peer review process by generating valuable insights and reducing the workload of human reviewers, leading to a more efficient and comprehensive evaluation of manuscripts in the era of review shortage (Table 2) [56].</p>
<p>Potential biases and limitations in AI-assisted peer review</p>
<p>Despite the promising applications of LLMs in peer review, it is crucial to be aware of potential biases and limitations (Table 2).Studies have identified gender bias in LLM-generated recommendation letters [57], as well as biases related to nationality, culture, and demographics [58].The overreliance on LLMs in peer review may lead to linguistic compression and reduced epistemic diversity, an essential element for the advancement of science [54].Furthermore, LLMs may lack deep domain knowledge, especially in medical fields and may fail to detect minute errors in specific details [59,60].To mitigate these issues, human oversight and final decision-making remain essential in the peer review process.</p>
<p>Editorial office applications</p>
<p>LLMs can be employed in various editorial office applications to manage submissions, detect plagiarism, and disseminate research findings (Table 2).AI-assisted tools can be used to prescreen manuscripts for quality and suitability, provide initial screening results to reviewers, and develop automated reviewer recommendation systems based on expertise.High-level plagiarism checks can be performed using LLMs, and can also help identify and address ethical issues.</p>
<p>To engage readers and promote broader dissemination of research, generative AI tools can generate plain language summaries, graphical abstracts, and personalized content recommendations.These tools can help break down complex scientific concepts into easily understandable language, making research findings more accessible to a wider audience with varying levels of scientific knowledge.Moreover, LLM-powered translation tools can help overcome language barriers by providing accurate translations of research articles, abstracts, and summaries, enabling the dissemination of scientific knowledge across different languages and cultures.This increased accessibility and reach can foster greater public engagement with science and facilitate interdisciplinary collaborations.As a demonstration of this application, the Chatbot Claude 3 Opus was provided with the abstracts of the recent issue of The Korean Journal of Physiology &amp; Pharmacology (Volume 28 Number 3), and has been prompted to write both an editorial review article (Supplementary Data 2) and a plain language summary article in English and Korean (Supplementary Data 3).However, it is important to consider data privacy concerns, such as the potential for manuscripts to unintentionally become training data for language models if proper precautions are not taken [8].As LLMs continue to advance, its integration into the peer review and publication process is expected to grow.However, it is essential for the academic community to establish clear guidelines and best practices to ensure the responsible and ethical use of these tools, while maintaining the integrity and quality of scholarly publishing.</p>
<p>RECOMMENDATIONS FOR RESPONSIBLE LLM USE IN MEDICAL WRITING</p>
<p>Recommendations for researchers</p>
<p>To ensure the responsible use of LLMs in medical writing, researchers should prioritize verifying the accuracy and reliability of LLM-generated content.A recent study on GPT-4V, a state-ofthe-art LLM, highlights the challenges in this domain [61].While GPT-4V outperformed human physicians in multi-choice accuracy on the New England Journal of Medicine (NEJM) Image Challenges, it frequently presented flawed rationales even when the answer was correct.This underscores the need for thorough fact-checking and cross-referencing with reliable sources, as well as being cognizant of subtle errors or inconsistencies that can be challenging to detect, especially in the medical context.</p>
<p>In terms of enhancing the research capabilities of individual researchers, it is recommended to utilize AI to generate advice or thought-provoking questions rather than to generate answers [62].For instance, instead of asking the LLM chatbot to generate a manuscript from an outline or list of ideas, it is more beneficial to request guidance and explanations on how to improve a manually crafted draft.Considering that a scientific article holds value as an author's writing, the choice of words or expressions may be an integral part of its identity and possess unique value.</p>
<p>Maintaining transparency in the use of LLMs is crucial, and researchers should disclose the use of these tools in the research and writing process, providing details on the extent and nature of LLM assistance.Developing a collaborative human-AI workflow that leverages LLM's strengths while recognizing their limitations can help optimize the quality of the output.Researchers should iteratively work with LLMs and ensure proper human intervention and oversight in each step [7].</p>
<p>Recommendations for reviewers</p>
<p>As LLMs become increasingly integrated into both the writing and review processes, and as AI tools can effectively screen for trivial errors such as grammar and formatting, reviewers should shift their focus to higher-order reviewing skills.This includes critically analyzing the overall significance, novelty, and impact of the work, providing nuanced feedback and domain-specific insights, and focusing on the "human" aspects of review [54].It is important to note that while poor writing quality was previously associated with poor scientific quality, in the era of LLMs, the quality of writing may not necessarily reflect the scientific rigor of the work.Reviewers may also inevitably incorporate LLMbased tools in the peer review workflow, but need to keep in mind that proper vigilance is needed.There is evidence that in cases of overreliance, high-performance AI tools result in worse outcomes than low-performance AI tools with proper human stewardship [63].Reviewers should be aware of the potential use of LLMs in manuscripts and ensure that conclusions are well-supported by data and analysis, rather than "hallucinated" claims.In cases of suspected unethical AI use, such as plagiarism or undisclosed LLM assistance, reviewers should act according to established reporting procedures and guidelines.</p>
<p>Recommendations for editorial offices</p>
<p>Editorial offices play a crucial role in promoting responsible LLM use in academic writing.Rather than banning AI based on fear, editorial offices should experience the capabilities of LLMs firsthand and develop evidence-based policies and guidelines that align with international standards (e.g., ICMJE, COPE, WAME).These policies should address key components such as AI authorship, disclosure of AI use, and human author responsibility [64].Implementing robust screening and detection tools while embracing new technology and maintaining rigorous peer review standards is also important [65].Editorial offices should acknowledge the prevalence of LLM use and focus on content quality and integrity.Providing training and resources for editorial staff and reviewers can help them navigate the challenges and opportunities presented by LLM technology.</p>
<p>Fostering open dialogue and collaboration within the academic community is another key responsibility of editorial offices.This can be achieved by promoting the exchange of ideas and experiences related to LLM use across different fields and disciplines, organizing workshops, seminars, or conferences to discuss challenges and opportunities, and engaging with AI researchers and developers to better understand LLM capabilities and limitations.</p>
<p>CONCLUSION</p>
<p>The rapid adoption and integration of LLMs in various stages of research and publishing have signaled a growing impact on academic writing and publishing.While LLMs offer potential benefits, they also present challenges for researchers, reviewers, and editorial offices.To harness the transformative potential of AI while maintaining the integrity of scholarly work, it is crucial to establish clear policies and guidelines that promote responsible and transparent use, fostering a culture of transparency and accountability, and encouraging open dialogue within the academic community.Future directions should focus on addressing the limitations and biases of current generative AI technologies, exploring innovative applications of LLMs, and continuously updating policies and practices.Collaborative efforts among researchers, reviewers, editorial offices, and AI developers will be essential in navigating the challenges and opportunities presented by LLMs.Ultimately, while embracing the potential of LLMs, it is important to prioritize the integrity of academic writing and publishing, emphasizing the importance of human judgment and expertise in the era of AI-assisted research and publishing.</p>
<p>Table 1 . Applications of large language models (LLMs) in research and writing
1Literature search &amp;Writing assistance &amp;Citation &amp; referenceCode generation &amp;research designquality assessmentgenerationdata analysis-Aid systematic reviews [21]-Generate abstracts with minor-LLM reference accuracy varies-Produce code for data analysis-Create research protocols [22]errors <a href="10%-87%">24,25</a> [36-39][41]-Perform bibliometric analysis-Artificial intelligence-generated-Retrieval-augmented-Health economic modeling[23]abstracts raise ethical concernsgeneration crucial for[42][19,26]reliability [40]-Data analysis using natural-LLM writing quality varieslanguage interactions [43,44][27-31]-Facilitate non-native Englishwriting [33]-Fine-tuning LLMs forpersonalized assistance [35]</p>
<p>Table 2 . Applications of large language models (LLMs) in peer review and publication
2Manuscript screening &amp; quality assessmentGenerating review comments &amp; feedbackPotential biases &amp; limitationsEditorial office applications-Assist in proofreading and-Streamline peer review [53]-Demographic biases [57,58]-Prescreen manuscriptserror detection [48,49]-LLM comments overlap with-Overreliance may reduce-Convert into easily-Assess quality and bias inhuman [54]diversity [54]understandable languagesystematic reviews [50]-Tend to provide overly positive-Lack deep domain knowledgeand multilingual translation-Develop methodology gradingreviews [55][59,60]-Consider data privacysystems [51]-May reduce reviewer overload-Human oversight remains-Benefit underprivileged[56]essential [54]researchers [52]
https://doi.org/10.4196/kjpp.2024.28.5.393 Korean J Physiol Pharmacol 2024;28(5):393-401
Korean J Physiol Pharmacol 2024;28(5):393-401 www.kjpp.net
ACKNOWLEDGEMENTSThe generative AI chatbot Claude 3 Opus was used in the process of writing and revising the outline of the manuscript, as well as in the process of revising the wording and grammar of the manuscript.FUNDINGThis research was supported by the National Research Foundation of Korea (NRF) grant funded by the Korean government (MSIT) (grant No. 2018R1A5A2021242).CONFLICTS OF INTERESTThe author declares no conflicts of interest.SUPPLEMENTARY MATERIALSThree supplementary data can be found with this article online at https://doi.org/10.4196/kjpp.2024.28.5.393
Discovery of a structural class of antibiotics with explainable deep learning. F Wong, E J Zheng, J A Valeri, N M Donghia, M N Anahtar, S Omori, A Li, A Cubillos-Ruiz, A Krishnan, Jin W Manson, A L Friedrichs, J Helbig, R Hajian, B Fiejtek, D K Wagner, F F Soutter, H H Earl, A M Stokes, J M Renner, L D , Nature. 6262024</p>
<p>Chatting and cheating: ensuring academic integrity in the era of ChatGPT. Dre Cotton, P A Cotton, J R Shipway, Innov Educ Teach Int. 612024</p>
<p>Rising adoption of artificial intelligence in scientific publishing: evaluating the role, risks, and ethical implications in paper drafting and review process. A Carobene, A Padoan, F Cabitza, G Banfi, M Plebani, Clin Chem Lab Med. 622023</p>
<p>Algorithmic progress in language models. A Ho, T Besiroglu, E Erdil, D Owen, R Rahman, Z C Guo, D Atkinson, N Thompson, J Sevilla, 10.48550/arXiv.2403.05812arXiv:2403.058122024 Mar 18Preprint</p>
<p>Academic publisher guidelines on AI usage: a ChatGPT supported thematic analysis. M Perkins, J Roe, F1000Res. 2024121398</p>
<p>ChatGPT is fun, but not an author. H H Thorp, Science. 3793132023</p>
<p>Generative AI guidelines in Korean medical journals: a survey using human-AI collaboration. S Ahn, 10.1101/2024.03.08.243039602024. 2024 Mar 15</p>
<p>Towards an AI policy framework in scholarly publishing. Z Lin, Trends Cogn Sci. 282024</p>
<p>Transparency in research: an analysis of ChatGPT usage acknowledgment by authors across disciplines and geographies. R Raman, Account Res. 2023</p>
<p>How ChatGPT is transforming the postdoc experience. L Nordling, Nature. 6222023</p>
<p>Awareness and use of ChatGPT and large language models: a prospective crosssectional global survey in urology. M Eppler, C Ganjavi, L S Ramacciotti, P Piazza, S Rodler, E Checcucci, Gomez Rivas, J Kowalewski, K F Belenchón, I R Puliatti, S Taratkin, M Veccia, A Baekelandt, L Teoh, J Y Somani, B K Wroclawski, M Abreu, A Porpiglia, F Gill, I S Murphy, D G , Eur Urol. 852024</p>
<p>Evaluation of the impact of large language learning models on articles submitted to Orthopaedics &amp; Traumatology: Surgery &amp; Research (OTSR): a significant increase in the use of artificial intelligence in 2023. G Maroteau, J S An, J Murgier, C Hulet, M Ollivier, A Ferreira, Orthop Traumatol Surg Res. 1091037202023</p>
<p>Tracing the footprints of AI in radiology literature: a detailed analysis of journal abstracts. I Mese, 10.1055/a-2224-9230Rofo. 2024Epub ahead of print</p>
<p>Monitoring AI-modified content at scale: a case study on the impact of ChatGPT on AI conference peer reviews. W Liang, Z Izzo, Y Zhang, H Lepp, H Cao, X Zhao, L Chen, H Ye, S Liu, Z Huang, D A Mcfarland, J Y Zou, 10.48550/arXiv.2403.07183arXiv:2403.071832024 Mar 18Preprint</p>
<p>Experimental evidence on the productivity effects of generative artificial intelligence. S Noy, W Zhang, Science. 3812023</p>
<p>Perceived publication pressure in Amsterdam: survey of all disciplinary fields and academic ranks. T L Haven, L M Bouter, Y M Smulders, J K Tijdink, PLoS One. 14e02179312019</p>
<p>Artificial intelligence can generate fraudulent but authentic-looking scientific medical articles: Pandora's box has been opened. M Májovský, M Černý, M Kasal, M Komarc, D Netuka, J Med Internet Res. 25e469242023</p>
<p>Artificial intelligence in orthopaedic surgery: can a large language model "Write" a believable orthopaedic journal article?. D T Brameier, A A Alnasser, J M Carnino, A R Bhashyam, Von Keudell, A G Weaver, M J , J Bone Joint Surg Am. 1052023</p>
<p>Comparing scientific abstracts generated by ChatGPT to real abstracts with detectors and blinded human reviewers. C A Gao, F M Howard, N S Markov, E C Dyer, S Ramesh, Y Luo, A T Pearson, NPJ Digit Med. 6752023</p>
<p>GPT detectors are biased against non-native English writers. W Liang, M Yuksekgonul, Y Mao, E Wu, J Zou, Patterns (N Y). 41007792023</p>
<p>Enhancing systematic reviews in orthodontics: a comparative examination of GPT-3.5 and GPT-4 for generating PICO-based queries with tailored prompts and configurations. G B Demir, Y Süküt, G S Duran, K G Topsakal, S Görgülü, Eur J Orthod. 46e0112024</p>
<p>Exploring the boundaries of reality: investigating the phenomenon of artificial intelligence hallucination in scientific writing through ChatGPT references. S A Athaluri, S V Manthena, Vsrkm Kesapragada, V Yarlagadda, T Dave, Rts Duddumpudi, Cureus. 15e374322023</p>
<p>Using generative artificial intelligence in bibliometric analysis: 10 years of research trends from the European Resuscitation Congresses. Resusc Plus. N Fijačko, R M Creber, B S Abella, P Kocbek, Š Metličar, R Greif, G Štiglic, 202418100584</p>
<p>Generative artificial intelligence: can ChatGPT write a quality abstract. F E Babl, M P Babl, Emerg Med Australas. 352023</p>
<p>Can ChatGPT pass Glycobiology? Glycobiology. D O Williams, E Fadda, 202333</p>
<p>Human versus artificial intelligence-generated arthroplasty literature: A single-blinded analysis of perceived communication, quality, and authorship source. K W Lawrence, A A Habibi, S A Ward, C M Lajam, R Schwarzkopf, J C Rozell, Int J Med Robot. 20e26212024</p>
<p>. S Ahn, </p>
<p>Can ChatGPT assist authors with abstract writing in medical journals? Evaluating the quality of scientific abstracts generated by ChatGPT and original abstracts. T Hwang, N Aggarwal, P Z Khan, T Roberts, A Mahmood, M M Griffiths, N Parsons, S Khan, PLoS One. 19e02977012024</p>
<p>ChatGPT-4 and human researchers are equal in writing scientific introduction sections: a blinded, randomized, non-inferiority controlled study. B Sikander, J J Baker, C D Deveci, L Lund, J Rosenberg, Cureus. 15e490192023</p>
<p>The readiness of ChatGPT to write scientific case reports independently: a comparative evaluation between human and artificial intelligence. M Buholayka, R Zouabi, A Tadinada, Cureus. 15e393862023</p>
<p>Evaluation of ChatGPT's capabilities in medical report generation. Z Zhou, Cureus. 15e375892023</p>
<p>AI language models in human reproduction research: exploring ChatGPT's potential to assist academic writing. Hum Reprod. N Semrl, S Feigl, N Taumberger, T Bracic, H Fluhr, C Blockeel, M Kollmann, 202338</p>
<p>A comparison of cover letters written by ChatGPT-4 or humans. C D Deveci, J J Baker, B Sikander, J Rosenberg, Dan Med J. 70A062304122023</p>
<p>Enhancing academic writing skills and motivation: assessing the efficacy of ChatGPT in AI-assisted language learning for EFL students. C Song, Y Song, Front Psychol. 1412608432023</p>
<p>Will ChatGPT's free language editing service level the playing field in science communication?: insights from a collaborative project with non-native English scholars. L Lingard, M Chandritilake, M De Heer, J Klasen, F Maulina, Olmos- Vega, F St-Onge, C , Perspect Med Educ. 122023</p>
<p>AUTO-GEN: a personalized large language model for academic enhancement-ethics and proof of principle. Porsdam Mann, S Earp, B D Møller, N Vynn, S Savulescu, J , Am J Bioeth. 232023</p>
<p>ChatGPT in head and neck scientific writing: a precautionary anecdote. R T Wu, R R Dang, Am J Otolaryngol. 441039802023</p>
<p>Navigating the landscape of personalized medicine: the relevance of ChatGPT, BingChat, and Bard AI in nephrology literature searches. N Aiumtrakul, C Thongprayoon, S Suppadungsuk, P Krisanapan, J Miao, F Qureshi, W Cheungpasitporn, J Pers Med. 1314572023</p>
<p>Assessing the accuracy of ChatGPT references in head and neck and ENT disciplines. A Frosolini, L Franz, S Benedetti, L A Vaira, C De Filippis, P Gennaro, G Marioni, G Gabriele, Eur Arch Otorhinolaryngol. 2802023</p>
<p>Accuracy of ChatGPT-3.5 and -4 in providing scientific references in otolaryngology-head and neck surgery. J R Lechien, G Briganti, L A Vaira, Eur Arch Otorhinolaryngol. 2812024</p>
<p>How well do LLMs cite relevant medical references? An evaluation framework and analyses. K Wu, E Wu, A Cassasola, A Zhang, K Wei, T Nguyen, S Riantawan, P S Riantawan, D E Ho, J Zou, 10.48550/arXiv.2402.02008iv:2402.020082024. 2024 Mar 15Preprint</p>
<p>Evaluating a large language model's ability to solve programming exercises from an introductory bioinformatics course. S R Piccolo, P Denny, A Luxton-Reilly, S H Payne, P G Ridge, PLoS Comput Biol. 19e10115112023</p>
<p>Artificial intelligence to automate health economic modelling: a case study to evaluate the potential application of large language models. T Reason, W Rawlinson, J Langham, A Gimblett, B Malcolm, S Klijn, Pharmacoecon Open. 82024</p>
<p>Code interpreter for bioinformatics: are we there yet?. L Wang, X Ge, L Liu, G Hu, Ann Biomed Eng. 522024</p>
<p>Data science through natural language with ChatGPT's Code Interpreter. S Ahn, Transl Clin Pharmacol. 32e82024</p>
<p>Automated social science: language models as scientist and subjects. B S Manning, K Zhu, J J Horton, 10.48550/arXiv.2404.11794arXiv:2404.117942024 Jun 3Preprint</p>
<p>Mathematical discoveries from program search with large language models. B Romera-Paredes, M Barekatain, A Novikov, M Balog, M P Kumar, E Dupont, Fjr Ruiz, J S Ellenberg, P Wang, O Fawzi, P Kohli, A Fawzi, Nature. 6252024</p>
<p>Autonomous chemical research with large language models. D A Boiko, R Macknight, B Kline, G Gomes, Nature. 6242023</p>
<p>Is ChatGPT-4 accurate in proofread a manuscript in otolaryngology-head and neck surgery? Otolaryngol Head Neck Surg. J R Lechien, A Gorton, J Robertson, L A Vaira, 2024170</p>
<p>AI-assisted peer review. A Checco, L Bracciale, P Loreti, S Pinfield, G Bianchi, Humanit Soc Sci Commun. 8252021</p>
<p>Streamlining systematic reviews: harnessing large language models for quality assessment and risk-of-bias evaluation. A J Nashwan, J H Jaradat, Cureus. 15e430232023</p>
<p>A large language model's assessment of methodology reporting in head and neck surgery. R Dang, C Hanba, Am J Otolaryngol. 451041452024</p>
<p>The Matthew effect in science. The reward and communication systems of science are considered. R K Merton, Science. 1591968</p>
<p>Revolution or peril? The controversial role of large language models in medical manuscript writing. R Diaz Milian, Moreno Franco, P Freeman, W D Halamka, J D , Mayo Clin Proc. 982023</p>
<p>Can large language models provide useful feedback on research papers? A large-scale empirical analysis. W Liang, Y Zhang, H Cao, B Wang, D Ding, X Yang, K Vodrahalli, S He, D Smith, Y Yin, D Mcfarland, J Zou, 10.48550/arXiv.2310.01783arXiv:2310.017832024. 2024 Mar 19Preprint</p>
<p>Exploring the potential of ChatGPT in the peer review process: an observational study. A Saad, N Jenko, S Ariyaratne, N Birch, K P Iyengar, A M Davies, R Vaishya, R Botchu, Diabetes Metab Syndr. 181029462024</p>
<p>Fighting reviewer fatigue or amplifying bias? Considerations and recommendations for use of ChatGPT and other large language models in scholarly peer review. M Hosseini, Spjm Horbach, Res Integr Peer Rev. 872023. 2023Res Integr Peer Rev</p>
<p>What's in a name? Experimental evidence of gender bias in recommendation letters generated by Chat-GPT. D M Kaplan, R Palitsky, Arconada Alvarez, S J Pozzo, N S Greenleaf, M N Atkinson, C A Lam, W A , J Med Internet Res. 26e518372024</p>
<p>Biases in large language models: origins, inventory, and discussion. R Navigli, S Conia, B Ross, ACM J Data Inf Qual. 1510212023</p>
<p>ChatGPT and artificial intelligence in transplantation research: is it always correct?. B Rawashdeh, J Kim, S A Alryalat, R Prasad, M Cooper, Cureus. 15e421502023</p>
<p>Evaluating Chat-GPT as an adjunct for the multidisciplinary tumor board decisionmaking in primary breast cancer cases. S Lukac, D Dayan, V Fink, E Leinert, A Hartkopf, K Veselinovic, W Janni, B Rack, K Pfister, B Heitmeir, F Ebner, Arch Gynecol Obstet. 3082023</p>
<p>Q Jin, F Chen, Y Zhou, Z Xu, J M Cheung, R Chen, R M Summers, J F Rousseau, P Ni, M J Landsman, S L Baxter, Al ' Aref, S J Li, Y Chen, A Brejt, J A Chiang, M F Peng, Y Lu, Z , 10.48550/arXiv.2401.08396arXiv:2401.08396Hidden flaws behind expert-level accuracy of GPT-4 vision in medicine. 2024. 2024 Mar 19Preprint</p>
<p>Math education with large language models: peril or promise? SSRN. H Kumar, D M Rothschild, D G Goldstein, J M Hofman, 2024 Mar 19Preprint</p>
<p>Falling asleep at the wheel: human/AI collaboration in a field experiment on HR recruiters. F Dell'acqua, 2022. 2024 Mar 19</p>
<p>Publishers' and journals' instructions to authors on use of generative artificial intelligence in academic and scientific publishing: bibliometric analysis. C Ganjavi, M B Eppler, A Pekcan, B Biedermann, A Abreu, G S Collins, I S Gill, G E Cacciamani, BMJ. 384e0771922024</p>
<p>Open science and software assistance: commentary on "artificial intelligence can generate fraudulent but authentic-looking scientific medical articles: Pandora's box has been opened. P L Ballester, J Med Internet Res. 25e493232023</p>            </div>
        </div>

    </div>
</body>
</html>