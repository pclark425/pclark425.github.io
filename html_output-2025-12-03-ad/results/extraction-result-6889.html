<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-6889 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-6889</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-6889</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-133.html">extraction-schema-133</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <p><strong>Paper ID:</strong> paper-2780686</p>
                <p><strong>Paper Title:</strong> Understanding What We See: How We Derive Meaning From Vision</p>
                <p><strong>Paper Abstract:</strong> Recognising objects goes beyond vision, and requires models that incorporate different aspects of meaning. Most models focus on superordinate categories (e.g., animals, tools) which do not capture the richness of conceptual knowledge. We argue that object recognition must be seen as a dynamic process of transformation from low-level visual input through categorical organisation to speci ﬁ c conceptual representations. Cognitive models based on large normative datasets are well-suited to capture statistical regularities within and between concepts, providing both category structure and basic-level individuation. We highlight recent research showing how such models capture important properties of the ventral visual pathway. This research demonstrates that signi ﬁ cant advances in understanding conceptual representations can be made by shifting the focus from studying superordinate categories to basic-level concepts</p>
                <p><strong>Cost:</strong> 0.012</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e6889.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e6889.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Conceptual Structure Account</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Conceptual Structure Account (feature-based account of concepts)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A cognitive-neurocomputational account that represents concrete concepts as collections of semantic features whose statistical regularities (sharedness, correlational strength, interaction of correlation and distinctiveness) determine category membership and ease of individuation, and that maps these feature-based statistics onto processing in the ventral visual pathway.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Conceptual Structure Account</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>feature-based vector / high-dimensional semantic space</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Concepts are functionally represented as vectors (sets) of semantic features (e.g., 'has legs', 'is round'), and statistics derived from these features (mean sharedness, correlational strength, correlation × distinctiveness) index both superordinate category relations and basic-level individuation; these feature statistics are mapped onto activity gradients and dynamics in the ventral visual pathway.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Explains superordinate category structure via shared features, basic-level individuation via distinctive and correlation statistics, predicts differential processing demands for confusable concepts, and accounts for behaviour across categorisation and naming tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>fMRI study, lesion-behaviour mapping, MEG, behavioural patient data, pattern-similarity analyses</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>Picture naming during fMRI, lesion–behaviour mapping (naming accuracy correlations), MEG multiple-linear-regression decoding of single-object responses, patient drawing/naming tasks</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Feature-statistics predict neural responses: mean feature sharedness maps onto a lateral-to-medial gradient in posterior fusiform (animals lateral, tools medial); correlational/individuation metrics predict anteromedial temporal (perirhinal) activity and deficits — more-confusable concepts increase PRC/AMTC activation and are more impaired after PRC damage; MEG shows shared-feature/superordinate information arises earlier (~<150 ms) and basic-level individuating information later (~>150–200 ms).</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Not reported as direct contradictions in this paper; authors acknowledge that purely visual image-based models cannot account for conceptual relations and that other networks beyond the ventral stream may contribute, leaving open scope for multiple complementary mechanisms.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Clarke & Tyler 2015</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6889.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e6889.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Conceptual Structure Statistics</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Conceptual structure statistics (mean sharedness, correlational strength, correlation × distinctiveness)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Quantitative measures derived from semantic feature norms used to summarise how features are shared across concepts and how features co-occur within concepts, predicting different behavioral and neural effects.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Conceptual structure statistics (feature-statistics measures)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>feature-based vector / summary statistics of high-dimensional space</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Operationalizes representational format by extracting metrics from feature vectors: mean sharedness indexes category-level shared features; correlational strength indexes co-activation ease of features; interaction (correlation × distinctiveness) predicts differential access for individuating concepts.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Mean sharedness supports rapid superordinate distinctions; high correlational strength facilitates coactivation of category features; correlation × distinctiveness governs ease of basic-level identification and need for differentiation processes.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>behavioural correlations, fMRI parametric modulation, lesion-symptom mapping, MEG regression/time-course analyses</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>Property-norm derived feature statistics correlated with naming behaviour, fMRI activation across named objects, lesion mapping correlating PRC damage with naming deficits, MEG multiple regression decoding</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Mean sharedness correlates with lateral vs medial posterior fusiform activation (shared-feature-rich concepts lateral); correlation × distinctiveness predicts PRC involvement and naming deficits for confusable items; time-resolved MEG shows shared-feature effects precede distinctive-feature effects.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Authors note that these statistics are derived from normative feature lists (not claimed to be literal neural 'units'), and that non-visual modalities/other networks were not fully tested here — so generality beyond visual access remains to be established.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Clarke & Tyler 2015</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6889.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e6889.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Anterior Temporal Convergence Zone / ATL hub</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Anterior temporal lobe (ATL) convergence zone / amodal conceptual hub</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The proposal that anterior temporal cortex (broadly ATL / anteroventral and anterolateral temporal lobe) acts as a multimodal convergence zone that supports amodal/basic-level conceptual representations by integrating information from modality-specific regions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Convergence zone / amodal hub (ATL hub)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>amodal hub / integrative node (relational network)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Functional representation is an integrated, modality-independent code in anterior temporal cortex that binds modality-specific inputs into coherent concept-level representations used for basic-level identification across categories.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Explains pan-category semantic deficits following widespread ATL damage (semantic dementia), supports formation of amodal/basic-level concepts and coordinates access to modality-specific stores; damage causes broad object identification impairments while preserving some superordinate knowledge.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>neuropsychology (semantic dementia, HSVE), fMRI, intracranial recordings</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>Patient lesion/atrophy studies, fMRI category contrasts, intracranial single-unit recordings, task contrasts of basic-level vs superordinate categorisation</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Widespread ATL damage produces basic-level conceptual deficits across categories; ATL activity implicated in amodal conceptual coding and connectivity from ATL to posterior fusiform increases during tasks requiring basic-level access.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>AMTC (anteromedial temporal cortex) shows category-specific patterns (e.g., living things) that relate more to differentiation demands; authors argue ATL and AMTC/PRC have complementary roles rather than ATL being sole hub — the hub view may need refinement to account for subregional functional heterogeneity.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Clarke & Tyler 2015</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6889.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e6889.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Ventral visual feedforward models / deep CNNs</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Hierarchical feedforward computational models of the ventral visual pathway (including deep convolutional neural networks)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Image-based hierarchical models that compute increasingly complex visual features through layered transformations (feedforward) to support object recognition; deep convolutional neural networks are a prominent instantiation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Hierarchical feedforward visual models / deep CNNs</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>hierarchical image-feature representation (deep convolutional network)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Objects are represented as progressively more complex visual feature combinations across a hierarchy of processing stages (V1 → higher visual cortex), often instantiated as layered convolutional networks that map pixels to high-level visual feature representations.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Account for rapid object recognition and many neural response properties in posterior visual cortex; provide a mechanistic image-computable mapping from pixels to object identity.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>computational simulations compared to primate electrophysiology and human fMRI, representational similarity analyses</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>Model-to-brain mapping (e.g., comparing deep CNN activations to fMRI or electrophysiology responses), image classification benchmarks, decoding/predictive analyses</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Feedforward/hierarchical models capture many visual response properties but alone cannot explain semantic relationships between visually dissimilar but semantically related objects (e.g., apple and banana vs apple and ball), nor conceptual priming and flexible access to different aspects of meaning.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Authors note these models fail to capture inter-concept semantic relationships and behavioural phenomena requiring conceptual knowledge; therefore they cannot fully account for semantic access from vision without integration of feature-based semantic representations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Clarke & Tyler 2015</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6889.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e6889.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Perirhinal Conjunctive Representation (PRC)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Perirhinal cortex conjunctive/individuating representation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The functional claim that perirhinal cortex (PRC) in anteromedial temporal lobe represents complex conjunctions of features needed to individuate semantically confusable concepts, supporting basic-level identification.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Perirhinal conjunctive/individuation representation</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>conjunctive feature-integration / high-dimensional pattern code</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>PRC encodes conjunctive combinations of feature information (high-dimensional patterns) that resolve overlap among similar concepts; increased PRC involvement is required when concepts share many features and are semantically confusable.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Explains why PRC activation increases for semantically confusable objects, why PRC damage disproportionately impairs naming of confusable items, and why pattern similarity in PRC reflects fine-grained conceptual similarity.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>lesion–behaviour mapping, fMRI multivariate pattern-similarity analyses, MEG temporal dynamics, patient drawing/naming data</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>Lesion mapping correlating PRC damage with naming errors; fMRI pattern-similarity (RSA) comparing semantic similarity to voxel pattern similarity in PRC; MEG/timecourse correlating conceptual structure statistics with neural signals; patient drawing tasks illustrating loss of distinctive features.</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Lesion-behaviour mapping: greater PRC damage predicts larger deficits for semantically confusable objects; fMRI: PRC pattern similarity clusters by conceptual similarity and differentiates within-category items; MEG/fMRI: PRC/AMTC activity linked to basic-level individuation, emerging after initial category-level signals.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Role is specific (not required for all semantic distinctions) and interacts with task demands; authors caution generalisation beyond visual access and note PRC works in concert with posterior regions and broader networks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Clarke & Tyler 2015</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6889.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e6889.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>High-dimensional distributed representational space</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>High-dimensional distributed representational space (Haxby-style distributed code)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The idea that object/concept representations are distributed across ventral temporal cortex in a high-dimensional space where similarity relationships are topographically embedded rather than localized to single modules.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>High-dimensional distributed representational space</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>high-dimensional distributed vector space / multivariate pattern code</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Conceptual information is encoded in distributed spatial patterns across populations of neurons (or voxels), forming a continuous representational geometry in which distances reflect similarity between concepts.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Explains graded, overlapping category effects, the utility of multivariate pattern analyses to decode concept identity, and how expertise or experience can reshape representational geometry.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>fMRI multivariate pattern analysis (MVPA), representational similarity analysis, electrophysiology</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>MVPA/RSA on fMRI data; decoding analyses of ventral temporal patterns; mapping representational spaces across subjects</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Distributed patterns in ventral temporal cortex can be mapped to semantic similarity and reflect both superordinate clustering and within-category differentiation; expertise modulates these distributed representations.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Authors emphasize that distributed visual-feature coding must be augmented by semantic feature statistics and anterior–posterior interactions to fully explain basic-level conceptual access; distributed visual models alone are insufficient for semantic relationships.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Clarke & Tyler 2015</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Conceptual structure: towards an integrated neurocognitive account <em>(Rating: 2)</em></li>
                <li>Object-specific semantic coding in human perirhinal cortex <em>(Rating: 2)</em></li>
                <li>Predicting the time course of individual objects with MEG <em>(Rating: 2)</em></li>
                <li>A common, high-dimensional model of the represenational space in human ventral temporal cortex <em>(Rating: 2)</em></li>
                <li>Coherent concepts are computed in the anterior temporal lobes <em>(Rating: 1)</em></li>
                <li>Binding crossmodal object features in perirhinal cortex <em>(Rating: 1)</em></li>
                <li>How does the brain solve visual object recognition? <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-6889",
    "paper_id": "paper-2780686",
    "extraction_schema_id": "extraction-schema-133",
    "extracted_data": [
        {
            "name_short": "Conceptual Structure Account",
            "name_full": "Conceptual Structure Account (feature-based account of concepts)",
            "brief_description": "A cognitive-neurocomputational account that represents concrete concepts as collections of semantic features whose statistical regularities (sharedness, correlational strength, interaction of correlation and distinctiveness) determine category membership and ease of individuation, and that maps these feature-based statistics onto processing in the ventral visual pathway.",
            "citation_title": "here",
            "mention_or_use": "use",
            "theory_name": "Conceptual Structure Account",
            "theory_type": "feature-based vector / high-dimensional semantic space",
            "theory_description": "Concepts are functionally represented as vectors (sets) of semantic features (e.g., 'has legs', 'is round'), and statistics derived from these features (mean sharedness, correlational strength, correlation × distinctiveness) index both superordinate category relations and basic-level individuation; these feature statistics are mapped onto activity gradients and dynamics in the ventral visual pathway.",
            "functional_claims": "Explains superordinate category structure via shared features, basic-level individuation via distinctive and correlation statistics, predicts differential processing demands for confusable concepts, and accounts for behaviour across categorisation and naming tasks.",
            "evidence_source": "fMRI study, lesion-behaviour mapping, MEG, behavioural patient data, pattern-similarity analyses",
            "experimental_paradigm": "Picture naming during fMRI, lesion–behaviour mapping (naming accuracy correlations), MEG multiple-linear-regression decoding of single-object responses, patient drawing/naming tasks",
            "key_result": "Feature-statistics predict neural responses: mean feature sharedness maps onto a lateral-to-medial gradient in posterior fusiform (animals lateral, tools medial); correlational/individuation metrics predict anteromedial temporal (perirhinal) activity and deficits — more-confusable concepts increase PRC/AMTC activation and are more impaired after PRC damage; MEG shows shared-feature/superordinate information arises earlier (~&lt;150 ms) and basic-level individuating information later (~&gt;150–200 ms).",
            "supports_theory": true,
            "counter_evidence": "Not reported as direct contradictions in this paper; authors acknowledge that purely visual image-based models cannot account for conceptual relations and that other networks beyond the ventral stream may contribute, leaving open scope for multiple complementary mechanisms.",
            "citation": "Clarke & Tyler 2015",
            "uuid": "e6889.0"
        },
        {
            "name_short": "Conceptual Structure Statistics",
            "name_full": "Conceptual structure statistics (mean sharedness, correlational strength, correlation × distinctiveness)",
            "brief_description": "Quantitative measures derived from semantic feature norms used to summarise how features are shared across concepts and how features co-occur within concepts, predicting different behavioral and neural effects.",
            "citation_title": "here",
            "mention_or_use": "use",
            "theory_name": "Conceptual structure statistics (feature-statistics measures)",
            "theory_type": "feature-based vector / summary statistics of high-dimensional space",
            "theory_description": "Operationalizes representational format by extracting metrics from feature vectors: mean sharedness indexes category-level shared features; correlational strength indexes co-activation ease of features; interaction (correlation × distinctiveness) predicts differential access for individuating concepts.",
            "functional_claims": "Mean sharedness supports rapid superordinate distinctions; high correlational strength facilitates coactivation of category features; correlation × distinctiveness governs ease of basic-level identification and need for differentiation processes.",
            "evidence_source": "behavioural correlations, fMRI parametric modulation, lesion-symptom mapping, MEG regression/time-course analyses",
            "experimental_paradigm": "Property-norm derived feature statistics correlated with naming behaviour, fMRI activation across named objects, lesion mapping correlating PRC damage with naming deficits, MEG multiple regression decoding",
            "key_result": "Mean sharedness correlates with lateral vs medial posterior fusiform activation (shared-feature-rich concepts lateral); correlation × distinctiveness predicts PRC involvement and naming deficits for confusable items; time-resolved MEG shows shared-feature effects precede distinctive-feature effects.",
            "supports_theory": true,
            "counter_evidence": "Authors note that these statistics are derived from normative feature lists (not claimed to be literal neural 'units'), and that non-visual modalities/other networks were not fully tested here — so generality beyond visual access remains to be established.",
            "citation": "Clarke & Tyler 2015",
            "uuid": "e6889.1"
        },
        {
            "name_short": "Anterior Temporal Convergence Zone / ATL hub",
            "name_full": "Anterior temporal lobe (ATL) convergence zone / amodal conceptual hub",
            "brief_description": "The proposal that anterior temporal cortex (broadly ATL / anteroventral and anterolateral temporal lobe) acts as a multimodal convergence zone that supports amodal/basic-level conceptual representations by integrating information from modality-specific regions.",
            "citation_title": "here",
            "mention_or_use": "mention",
            "theory_name": "Convergence zone / amodal hub (ATL hub)",
            "theory_type": "amodal hub / integrative node (relational network)",
            "theory_description": "Functional representation is an integrated, modality-independent code in anterior temporal cortex that binds modality-specific inputs into coherent concept-level representations used for basic-level identification across categories.",
            "functional_claims": "Explains pan-category semantic deficits following widespread ATL damage (semantic dementia), supports formation of amodal/basic-level concepts and coordinates access to modality-specific stores; damage causes broad object identification impairments while preserving some superordinate knowledge.",
            "evidence_source": "neuropsychology (semantic dementia, HSVE), fMRI, intracranial recordings",
            "experimental_paradigm": "Patient lesion/atrophy studies, fMRI category contrasts, intracranial single-unit recordings, task contrasts of basic-level vs superordinate categorisation",
            "key_result": "Widespread ATL damage produces basic-level conceptual deficits across categories; ATL activity implicated in amodal conceptual coding and connectivity from ATL to posterior fusiform increases during tasks requiring basic-level access.",
            "supports_theory": true,
            "counter_evidence": "AMTC (anteromedial temporal cortex) shows category-specific patterns (e.g., living things) that relate more to differentiation demands; authors argue ATL and AMTC/PRC have complementary roles rather than ATL being sole hub — the hub view may need refinement to account for subregional functional heterogeneity.",
            "citation": "Clarke & Tyler 2015",
            "uuid": "e6889.2"
        },
        {
            "name_short": "Ventral visual feedforward models / deep CNNs",
            "name_full": "Hierarchical feedforward computational models of the ventral visual pathway (including deep convolutional neural networks)",
            "brief_description": "Image-based hierarchical models that compute increasingly complex visual features through layered transformations (feedforward) to support object recognition; deep convolutional neural networks are a prominent instantiation.",
            "citation_title": "here",
            "mention_or_use": "mention",
            "theory_name": "Hierarchical feedforward visual models / deep CNNs",
            "theory_type": "hierarchical image-feature representation (deep convolutional network)",
            "theory_description": "Objects are represented as progressively more complex visual feature combinations across a hierarchy of processing stages (V1 → higher visual cortex), often instantiated as layered convolutional networks that map pixels to high-level visual feature representations.",
            "functional_claims": "Account for rapid object recognition and many neural response properties in posterior visual cortex; provide a mechanistic image-computable mapping from pixels to object identity.",
            "evidence_source": "computational simulations compared to primate electrophysiology and human fMRI, representational similarity analyses",
            "experimental_paradigm": "Model-to-brain mapping (e.g., comparing deep CNN activations to fMRI or electrophysiology responses), image classification benchmarks, decoding/predictive analyses",
            "key_result": "Feedforward/hierarchical models capture many visual response properties but alone cannot explain semantic relationships between visually dissimilar but semantically related objects (e.g., apple and banana vs apple and ball), nor conceptual priming and flexible access to different aspects of meaning.",
            "supports_theory": null,
            "counter_evidence": "Authors note these models fail to capture inter-concept semantic relationships and behavioural phenomena requiring conceptual knowledge; therefore they cannot fully account for semantic access from vision without integration of feature-based semantic representations.",
            "citation": "Clarke & Tyler 2015",
            "uuid": "e6889.3"
        },
        {
            "name_short": "Perirhinal Conjunctive Representation (PRC)",
            "name_full": "Perirhinal cortex conjunctive/individuating representation",
            "brief_description": "The functional claim that perirhinal cortex (PRC) in anteromedial temporal lobe represents complex conjunctions of features needed to individuate semantically confusable concepts, supporting basic-level identification.",
            "citation_title": "here",
            "mention_or_use": "use",
            "theory_name": "Perirhinal conjunctive/individuation representation",
            "theory_type": "conjunctive feature-integration / high-dimensional pattern code",
            "theory_description": "PRC encodes conjunctive combinations of feature information (high-dimensional patterns) that resolve overlap among similar concepts; increased PRC involvement is required when concepts share many features and are semantically confusable.",
            "functional_claims": "Explains why PRC activation increases for semantically confusable objects, why PRC damage disproportionately impairs naming of confusable items, and why pattern similarity in PRC reflects fine-grained conceptual similarity.",
            "evidence_source": "lesion–behaviour mapping, fMRI multivariate pattern-similarity analyses, MEG temporal dynamics, patient drawing/naming data",
            "experimental_paradigm": "Lesion mapping correlating PRC damage with naming errors; fMRI pattern-similarity (RSA) comparing semantic similarity to voxel pattern similarity in PRC; MEG/timecourse correlating conceptual structure statistics with neural signals; patient drawing tasks illustrating loss of distinctive features.",
            "key_result": "Lesion-behaviour mapping: greater PRC damage predicts larger deficits for semantically confusable objects; fMRI: PRC pattern similarity clusters by conceptual similarity and differentiates within-category items; MEG/fMRI: PRC/AMTC activity linked to basic-level individuation, emerging after initial category-level signals.",
            "supports_theory": true,
            "counter_evidence": "Role is specific (not required for all semantic distinctions) and interacts with task demands; authors caution generalisation beyond visual access and note PRC works in concert with posterior regions and broader networks.",
            "citation": "Clarke & Tyler 2015",
            "uuid": "e6889.4"
        },
        {
            "name_short": "High-dimensional distributed representational space",
            "name_full": "High-dimensional distributed representational space (Haxby-style distributed code)",
            "brief_description": "The idea that object/concept representations are distributed across ventral temporal cortex in a high-dimensional space where similarity relationships are topographically embedded rather than localized to single modules.",
            "citation_title": "here",
            "mention_or_use": "mention",
            "theory_name": "High-dimensional distributed representational space",
            "theory_type": "high-dimensional distributed vector space / multivariate pattern code",
            "theory_description": "Conceptual information is encoded in distributed spatial patterns across populations of neurons (or voxels), forming a continuous representational geometry in which distances reflect similarity between concepts.",
            "functional_claims": "Explains graded, overlapping category effects, the utility of multivariate pattern analyses to decode concept identity, and how expertise or experience can reshape representational geometry.",
            "evidence_source": "fMRI multivariate pattern analysis (MVPA), representational similarity analysis, electrophysiology",
            "experimental_paradigm": "MVPA/RSA on fMRI data; decoding analyses of ventral temporal patterns; mapping representational spaces across subjects",
            "key_result": "Distributed patterns in ventral temporal cortex can be mapped to semantic similarity and reflect both superordinate clustering and within-category differentiation; expertise modulates these distributed representations.",
            "supports_theory": true,
            "counter_evidence": "Authors emphasize that distributed visual-feature coding must be augmented by semantic feature statistics and anterior–posterior interactions to fully explain basic-level conceptual access; distributed visual models alone are insufficient for semantic relationships.",
            "citation": "Clarke & Tyler 2015",
            "uuid": "e6889.5"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Conceptual structure: towards an integrated neurocognitive account",
            "rating": 2,
            "sanitized_title": "conceptual_structure_towards_an_integrated_neurocognitive_account"
        },
        {
            "paper_title": "Object-specific semantic coding in human perirhinal cortex",
            "rating": 2,
            "sanitized_title": "objectspecific_semantic_coding_in_human_perirhinal_cortex"
        },
        {
            "paper_title": "Predicting the time course of individual objects with MEG",
            "rating": 2,
            "sanitized_title": "predicting_the_time_course_of_individual_objects_with_meg"
        },
        {
            "paper_title": "A common, high-dimensional model of the represenational space in human ventral temporal cortex",
            "rating": 2,
            "sanitized_title": "a_common_highdimensional_model_of_the_represenational_space_in_human_ventral_temporal_cortex"
        },
        {
            "paper_title": "Coherent concepts are computed in the anterior temporal lobes",
            "rating": 1,
            "sanitized_title": "coherent_concepts_are_computed_in_the_anterior_temporal_lobes"
        },
        {
            "paper_title": "Binding crossmodal object features in perirhinal cortex",
            "rating": 1,
            "sanitized_title": "binding_crossmodal_object_features_in_perirhinal_cortex"
        },
        {
            "paper_title": "How does the brain solve visual object recognition?",
            "rating": 1,
            "sanitized_title": "how_does_the_brain_solve_visual_object_recognition"
        }
    ],
    "cost": 0.01231275,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Understanding What We See: How We Derive Meaning From Vision</p>
<p>Alex Clarke 
Centre for Speech, Language and the Brain
Department of Psychology
University of Cambridge
CB2 3EBCambridgeUK</p>
<p>Lorraine K Tyler lktyler@csl.psychol.cam.ac.uk 
Centre for Speech, Language and the Brain
Department of Psychology
University of Cambridge
CB2 3EBCambridgeUK</p>
<p>Understanding What We See: How We Derive Meaning From Vision
30DEFB9CCFAF9063E27B5E3C81C60B5D10.1016/j.tics.2015.08.008
Recognising objects goes beyond vision, and requires models that incorporate different aspects of meaning.Most models focus on superordinate categories (e.g., animals, tools) which do not capture the richness of conceptual knowledge.We argue that object recognition must be seen as a dynamic process of transformation from low-level visual input through categorical organisation to specific conceptual representations.Cognitive models based on large normative datasets are well-suited to capture statistical regularities within and between concepts, providing both category structure and basic-level individuation.We highlight recent research showing how such models capture important properties of the ventral visual pathway.This research demonstrates that significant advances in understanding conceptual representations can be made by shifting the focus from studying superordinate categories to basic-level concepts.Flexible Access to Conceptual RepresentationsHow do we understand what we see?We interpret this fundamental question as asking how visual inputs are transformed into conceptual representations.Our conceptual knowledge (see Glossary) reflects what we know about the world, such as learned facts, and the meanings of both abstract (e.g., freedom) and concrete (e.g., tiger) concepts.Our focus here is on concrete concepts.When conceptual knowledge is accessed, the information retrieved needs to be behaviourally relevant.Acting appropriately requires flexible access to different types of conceptual information.Depending on perceptual context and behavioural goals, objects are recognised in different ways, for example, as a cow, an animal, or living thing.The way objects are naturally recognised is by accessing information specific enough to differentiate them from similar objects (e.g., recognising an object as a cow rather than a horse or a buffalo)a notion termed the basic or entry-level of representation[1,2].However, part of understanding the meaning of an object also necessitates that more-general information is accessedfor example, the commonalities between similar objects that enable us to know that an object is part of a superordinate category (e.g., as an animal or living thing).To understand the cortical underpinnings of this flexible access to different aspects of conceptual representations, we need to specify the neurocomputational processes underlying meaningful object recognition.This in turn requires that conceptual representations are studied as the expression of a set of dynamic processes of transformationfrom the visual input and different stages of visual processing in the brain, through different types of categorical organisation, to a basic-level conceptual representation.Object recognition has generally not been conceptualised in these terms.It is a domain of research that straddles many different subdisciplinesmost saliently vision science and</p>
<p>Trends</p>
<p>We view object recognition as a dynamic process of transformation from low-level visual analyses through superordinate category to basic-level conceptual representations.</p>
<p>Understanding this process is facilitated by using semantic cognitive models that can capture feature-based statistical regularities between concepts, providing both superordinate category and basic-level information.</p>
<p>We highlight research using fMRI, MEG, and neuropsychological and behavioural testing to show how feature-based cognitive models can relate to object semantic representations in the ventral visual pathway.</p>
<p>The posterior fusiform and perirhinal cortex are shown to process complementary aspects of object semantics.</p>
<p>The temporal coordination between these regions is also highlighted, while superordinate category information precedes basic-level semantic information in time.</p>
<p>semantic memorybut these different strands tend to remain fragmented owing to the complexity and depth of individual areas.A central theme in vision science is to develop computational accounts of the ventral visual pathway, based on visual image properties, which try to explain non-human primate and human brain data (e.g., [3][4][5][6]).However, these models are unable to capture the relationships between different conceptsthat an apple and a banana are more related than an apple and a ball (which are more visually similar).Further, models of vision alone cannot account for properties such as conceptual priming and flexible access to different aspects of meaning.</p>
<p>Research in semantic memory, by contrast, focuses on the organisation of semantic knowledge in the brain resulting in a variety of accounts drawing upon neuropsychology, functional neuroimaging, computational modelling, and behavioural paradigms.Providing a review of these perspectives is beyond the scope of this article, and many excellent contemporary reviews are available [7][8][9][10][11][12][13][14].Our focus here is on understanding the neural processes that underpin how meaning is accessed from vision.We describe a neurocognitive model that integrates (i) a cognitive account of meaning based on the statistical regularities between semantic features (e.g., 'has 4 legs', 'has a mane', 'is black and white') that can explain a range of semantic effects, with (ii) the neurocomputational properties of the hierarchically organised ventral visual pathway.</p>
<p>Basic-Level Concepts and their Superordinate Categories</p>
<p>Most cognitive models of object meaning address semantics through one of two approachesfocusing on superordinate category organisation (e.g., [9,15]) or basic-level concepts (e.g., [16]).However, a comprehensive account needs to consider both these facets.</p>
<p>Research into the organisation of semantic knowledge in the brain has been largely motivated by the observation of semantic deficits resulting from brain damage and diseasemost strikingly those deficits that seemed to be specific to only some superordinate categories.Such categoryspecific deficits after neurological diseases such as herpes simplex viral encephalitis (HSVE) have shown that tissue loss in anteromedial temporal cortex (AMTC; Figure 1) can disproportionately impair knowledge for living things, with relative preservation of knowledge for nonliving things [17,18].Complementing these neuropsychological data, functional imaging and electrophysiology studies of healthy individuals show increased activity in the AMTC for living things versus nonliving things [19][20][21][22][23].</p>
<p>Glossary</p>
<p>Basic-level concept: we can categorise the same object in many different ways ranging from more to less specific.Examples of the basiclevel category are 'dog', 'chair', 'hammer', rather than more-specific (subordinate level; e.g., poodle) or less-specific (superordinate level; e.g., animal) names.The basic-level category of an object is typically the name you would give if asked the questioncan you name this object?Conceptual knowledge: the information we know about things in the world.We use the term conceptual interchangeably with semantic.In contrast to episodic memory, our conceptual knowledge is not tied to any particular place or time; for example, it reflects our knowledge about tigers, rather than our memory of encountering a specific tiger in a specific context.Conceptual structure statistics: measures based on the regularities and co-occurrences of semantic feature information across different concepts, where the semantic features are typically obtained from large databases (e.g., large norming studies, corpus data).For example, 'feature sharedness', or how common a feature is across different concepts, may be calculated as 1/ {the number of concepts a specific feature occurs in}.The mean 'sharedness' of a concept is then the mean 'feature sharedness' over all features in the concept.These statistics can be used to estimate the statistical structure of individual concepts and the relationship of concepts to each other, and have been shown to influence how conceptual information is accessed.Semantic features: Many models of conceptual knowledge assume that meaning is componential in that the meaning of a concept can be characterised by many smaller units of meaning.Semantic features, such as 'has legs' or 'is round', are one such approximation of those units and can be derived from property norming studies.Although semantic features are not claimed to be the neural units of meaning, the regularities and statistics derived from them are predicted to share some properties with how meaning is instantiated in the brain.Superordinate category: refers to groups made up of many concepts, By studying patients showing category-specific deficits following AMTC atrophy, we can gain important insights into the nature of the information that is lost.A striking illustration of this comes from patient drawings, where they are asked to sketch a range of living and non-living objects from memory.In the examples in Figure 2A, all the nonliving objects are well-drawn and easily identifiable, while the drawings of animals mostly reflect their shared properties (e.g., four legs, a tail, eyes, horizontal body), making it impossible to identify them as basic-level concepts.It is clear from these examples that the informational loss underpinning the impairments of such patients involves accessing the distinctive properties of living things, rather than a loss of all information (see [17]).This type of perspective suggests that a more nuanced view of categoryspecificity in the AMTC is needed, one that takes into account the nature of the deficits at a more specific level than superordinate categories.</p>
<p>Functional brain imaging studies of healthy individuals have provided key evidence that apparent superordinate category effects are not restricted to the AMTC.In the posterior fusiform gyrus (Figure 1), animal images have been shown to produce enhanced effects in the lateral posterior fusiform gyrus, and tool images show effects in the medial posterior fusiform gyrus [15,24].The nature of this lateral-to-medial gradient in the posterior fusiform is especially intriguing given the range of parameters that produce similar distinctionssuch as real world object size [25], animacy [26], expertise [27], and retinotopy [28], suggesting that highly complex representations in this region encompass multiple types of stimulus properties [29,30].</p>
<p>The effects animals and tools have on the posterior fusiform is one of a range of category-specific effects that have been observed in the temporal and parietal lobes for different categoriesanimals in the lateral fusiform, superior temporal sulcus (STS), and amygdala [31,32]; tools in medial fusiform, middle temporal gyrus (MTG), inferior parietal lobule (IPL) [33]; places in the lingual, medial fusiform and parahippocampal gyrus [34]; faces in the lateral occipital, lateral fusiform, STS [35,36]; bodies in the lateral fusiform and STS [37].While understanding the organisation of different categories remains a central issue for cognitive neuroscience, we focus where the grouping is based on semantic properties shared over the group.Superordinate categories can range from more specific categories such as animals, plants, and tools, to less specific categories such as nonliving things (artifacts).here on one aspect of this, category effects of animals and tools in the posterior fusiform, to illustrate the insights and advances we can make by studying part of this system in detail.</p>
<p>Living things Nonliving things (A) (B)</p>
<p>The effects of superordinate category in the AMTC and posterior fusiform must reflect complementary, but different, aspects of semantic computations, but research focusing on superordinate categories has been insufficient to resolve the complementary roles these regions might play.</p>
<p>A largely separate strand of research has focused on basic-level conceptual entities and centres on the anterior temporal lobe (ATL, often defined as the anteroventral and anterolateral aspects of the temporal lobe) which is claimed to represent amodal conceptual information [11,38].This idea draws upon the notion of convergence zones in the ATL, which acts to bring together information from other brain regions to represent concepts [38][39][40].Widespread damage to the ATL is associated with semantic deficits at the level of basic-level concepts for all categories, while superordinate category knowledge itself is unimpaired.Thus, damage to the ATL and to the AMTC seem to have very different effects on conceptual knowledge which have yet to be fully explained.</p>
<p>While these lines of research have fundamentally enhanced our understanding of the neural basis of conceptual knowledge, two significant issues arise.First, theories that focus on the organisation of superordinate category information alone ignore what is perhaps the most salient aspect of semanticsthe information which differentiates between basic-level conceptsbecause it is these concepts that are claimed to be the most necessary in daily usage [2].Consequently, we believe that concepts, not categories, should be the focus of research.Second, research focusing on basic-level concepts has little to say about superordinate category representations.As a consequence, research into superordinate category representations and basic-level concepts is rarely integrated to provide an account of how meaning is accessed from vision.</p>
<p>Conceptual Structure in the Ventral Visual Pathway</p>
<p>A comprehensive cognitive model of conceptual representations in the brain needs to provide an account of both these sets of issues, and we argue that this can be achieved through the use of semantic feature models of conceptual knowledge.The model that we adopt here, the conceptual structure account [12,41], claims that concepts can be represented in terms of their semantic features (e.g., 'has legs', 'made of metal') and statistical measures, termed conceptual structure statistics, based on the regularities of features both across concepts and within a concept.Conceptual structure statistics can be informative about both the superordinate category of a concept (e.g., a camel is an animal and a mammal) and how distinctive a concept is within the category (e.g., a camel is distinctive because of its hump which no other animals have).As Box 1 explains, category membership is strongly indicated by the features a concept shares with many other concepts (e.g., many animals have fur, and have legs etc.), while the relationship between the shared and the distinctive features of a concept reflects the ease with which a concept can be differentiated from similar concepts (or conceptual individuation).Further, statistics derived from property norms can reveal systematic differences between categories, such that living things (e.g., animals) have many shared and few distinctive features (all animals have eyes, but few have a hump), whereas nonliving things (e.g., tools) have fewer shared and relatively more distinctive features.The information captured with conceptual structure statistics shows how feature-based models can provide a single theoretical framework that captures information about conceptual representations at different levels of description.</p>
<p>Recent fMRI data from healthy participants [42] and lesion behaviour mapping in brain-damaged patients [43] show how conceptual structure statisticscapturing either superordinate category information or the ease of conceptual individuationdifferentially relate to regions along the ventral visual pathway.In one study [42], we calculated conceptual structure statistics for a large and diverse set of common objects that participants named during fMRI scanning.We then related brain activation across these objects to different conceptual measures to determine how conceptual structure statistics influence object processing (Figure 3A).The results show that the conceptual structure of an object affects processing at two key sites along the ventral visual pathway.First, there is a gradient effect across the lateral-to-medial posterior fusiform that reflects the mean feature sharedness of a concept.Objects with many shared features (typically animals) show greater effects in the lateral posterior fusiform gyrus, and objects with fewer shared features (typically tools) show greater effects in the medial posterior fusiform gyrus.Second, effects in the AMTC, specifically in perirhinal cortex (PRC), are related to the ease of conceptual individuation: more-confusable concepts evoke greater activation.Evidence from lesion-behaviour mapping [43] confirms this relationship between conceptual structure statistics and the PRC.Damage to the PRC results in an increased deficit for naming semantically moreconfusable objects, where confusability is defined by conceptual structure statistics ('correlation Â distinctiveness'; Figure 3B).Together, these two studies converge to highlight a specific relationship, between a conceptual structure statistic capturing conceptual individuation and the PRC, that was only indirectly suggested from prior brain lesion-mapping evidence [44][45][46][47].</p>
<p>The statistical measures derived from feature-based accounts shed new light on the nature of category-specific effects in different regions of the ventral visual pathway, and do so with a framework situated at the level of basic-level concepts.Lateral-to-medial effects in the posterior fusiform gyrus, previously associated with category-specific effects for animals and tools, in fact seem to reflect a gradient of feature sharedness, whereas category-specific effects for living</p>
<p>Box 1. Conceptual Structure Statistics</p>
<p>Many cognitive models of semantics rest on the assumption that meaning is componential in nature, in that a concept is composed of smaller elements of meaning, such as semantic features [12,[82][83][84][85][86][87].Semantic features derived from largescale property norming studies [88] have proven to be a useful way of estimating the underlying structure and content of semantic representations [2,41,89,90].The statistical regularities derived from semantic features, such as the feature frequency and the pattern of feature co-occurrence, correlate with behaviour across a variety of tasks [91][92][93] and with measures of brain activity [42,49,68,[94][95][96][97][98].</p>
<p>Research supporting feature-based models highlights three key feature statistics relating to the ease and speed of activating concept-level representations:</p>
<p>First, 'mean sharedness' captures whether the semantic features of a concept are relatively more shared by many other concepts (e.g., 'has ears') or are more distinctive of the particular concept (e.g., 'has a hump').Concepts with many shared features are semantically related to many other concepts, and having many shared features provides a strong indication of superordinate category membership.However, having many shared features also results in increased processing to individuate the concept from their semantic neighbours.A concept that has more distinctive features typically has fewer semantic neighbours, and this facilitates the activation of a unique conceptual representation.Second, 'correlational strength' captures how often the features of a concept co-occur and modulate the ease of conceptual processing (the features 'has eyes', 'has ears', and 'has legs' are likely to co-occur with each other).Greater correlation between the features of a concept strengthens the links between them, speeding their coactivation and facilitating conceptual processing.Finally, the interaction between feature sharedness and correlation ('correlation Â distinctiveness') is thought to play a crucial role in accessing conceptual meaning, such that concepts with highly correlated distinctive features are more easily identified, while concepts that combine highly correlated shared features (such as eyes, ears, legs) and weakly correlated distinctive features (the stripes of a tiger) require additional differentiation processes.</p>
<p>These measures have differential effects depending on the nature of the behavioural goals [93].During superordinate categorisation (e.g., is an object living or man-made), recognition is facilitated for concepts with many shared features, as well as for concepts whose shared features are more highly correlated.By contrast, during unique conceptual identification (e.g., naming an object as a tiger), recognition is facilitated for concepts with fewer shared features and for concepts whose shared features are more weakly correlated.These contrasting influences of conceptual structure statistics on behaviour reveal how different forms of conceptual information are differentially relevant depending on behavioural goals.</p>
<p>things in the AMTC can be explained in terms of the ease of conceptual individuationtwo measures derived from a single account to explain category-specific effects in different regions of the ventral visual pathway for different computational reasons.</p>
<p>This research points to a key computational role for the human PRC in the individuation of semantically-confusable concepts.This role is not relevant for all semantic distinctions, but only for those requiring highly differentiated representations, such as distinctions between a lion, leopard, and cheetah.This is clear from studies showing increased AMTC activity only during basic-level conceptual recognition and not during superordinate category distinctions [22,48], and from studies showing that activity increases in the PRC during the recognition of semantically more-confusable objects [42,49].</p>
<p>There are close parallels here with research on the resolution of visual ambiguity and confusability in the PRC in both human and non-human primates [50][51][52], and on conceptual effects in humans [23,42,46,49,[53][54][55][56][57][58][59][60].Functionally, it can be argued that the PRC serves to differentiate activity increases for concepts that are semantically more-confusable (reproduced from [42] with permission from MIT press).(B) Increasing damage to the perirhinal cortex (PRC) results in poorer performance for naming semantically moreconfusable objects.This is shown by first correlating the naming accuracy of each patient with a conceptual structure measure for the ease of conceptual individuation.This correlation is then related to the degree of damage to the PRC (crosses denote left hemisphere damage; circles denote right hemisphere damage) (reprinted from [43]).(C) Pattern similarity in bilateral PRC is related to conceptual similarity based on semantic features.Semantic similarity can be defined based on overlapping semantic features between concepts, where concepts both cluster by superordinate category and show within-category variability.Testing the relationship between semantic feature similarity and pattern similarity in the brain shows that bilateral PRC similarity patterns also show a clustering by superordinate category and, crucially, withincategory differentiation aligned to conceptual similarity (reprinted from [49] with permission from the Society for Neuroscience).(D) The timecourse of superordinate category and basic-level concept information shown with magnetoencephalography (MEG).Using multiple linear regression we can learn how to map between the recorded MEG data and the visual and semantic measures for different objects.After showing how well this model can explain the observed neural data, we asked how accurately the model could predict MEG data for new objects.This showed than the superordinate category of an object can be successfully predicted before the prediction of the basic-level concept (after accounting for the influence of visual statistics) (reprinted from [68] with permission from Oxford University Press).</p>
<p>between objects that have many overlapping features, and are therefore nearby in semantic space, while objects in sparse areas, with few semantic competitors, require less involvement of the PRC.This is directly supported by research showing that activation patterns in the human PRC reflect the semantic similarity of concepts, as defined by semantic features (Figure 3C) [49,55].</p>
<p>This computational role of the PRC helps to explain two phenomena from neuropsychology.First, patients who present category-specific deficits for living things following AMTC damage show intact superordinate category knowledge.The basic-level nature of the deficits can be explained in terms of the role of the PRC being predominantly limited to differentiating between entities within superordinate categories.However, not all categories are equally effected following AMTC damage, leading to the second phenomenon: that the observed category-specific deficits for living things occur as a result of a differentiation impairment within denser areas of semantic space, more typical for living things, while these patients can easily differentiate within the less-dense areas typically occupied by nonliving thingsresulting in the phenomena seen in Figure 1A.</p>
<p>These findings suggest a conceptual hierarchy in the ventral visual pathway, where a network of regions supports recognition of meaningful objects, and that category-specific effects emerge in different regions owing to categorical differences across complementary semantic feature statistics.This also has the implication that our individual knowledge about objects may reshape the distribution of effects in the ventral stream, consistent with research showing that expertise with different categories, and thus an increased ability to individuate between highly-similar objects, also increasingly engages the lateral posterior fusiform and anterior temporal regions [27,61] those regions most important for individuating objects with many shared features and few distinctive features.</p>
<p>The Temporal Dynamics of Conceptual Processing</p>
<p>We have shown how a semantic feature-based approach can account for observations of superordinate category-specific effects at different loci in the ventral visual pathway.Any comprehensive account of conceptual processing must also be able to capture the temporal dynamics during the retrieval of semantic knowledge.During object recognition, the system dynamics follow an initial feedforward phase of processing as signals propagate along the ventral temporal lobe, followed by recurrent, long-range reverberating interactions between cortical regions [62][63][64][65][66].The exact nature of the computations supported by these dynamics remains unclear, though there is clear evidence that information relevant to superordinate category distinctions can be accessed very rapidly (within 150 ms [67-69]) whereas specific conceptual information is only accessible after approximately 200 ms [59,68,[70][71][72].</p>
<p>How the temporal dynamics map onto the processing of conceptual information is an issue we have recently begun to investigate [73].By measuring neural activity with a high temporal resolution, and using machine-learning methods, we can determine whether feature-based models can predict patterns of brain activity over time.One magnetoencephalography (MEG) study along these lines [68] showed that by combining a computational model of visual processing from V1 to posterior temporal cortex [74] with semantic feature information, the neural activity for single objects could be well explained and this model could be used to predict neural activity for other (new) objects.While the model including both visual and semantic information could successfully account for single-object neural activity from 60 ms, the semantic feature information made unique contributions over and above those that the visual information could explain.Semantic feature information explained a significant amount of single object data in the first 150 ms, and this in turn could predict neural activity that dissociated between objects from different superordinate categories.After around 150 ms, the predictions become more specific, and differentiated between members of the same category (i.e., the basic-level concept could be predicted solely based on semantics; Figure 3D).</p>
<p>In a direct assessment of the influence of conceptual structure statistics on the time-course of object recognition, a second MEG study [75] demonstrated that MEG signals correlated with the visual statistics of an object before rapid effects driven by the feature sharedness of the object in the first 150 ms.Subsequent to this, both shared and distinctive features were correlated with MEG signals after 150 ms.Together, these MEG studies highlight two important time-frames of conceptual processing during object recognitionearly information that (rapidly activated by visual properties) dissociates superordinate categories and which is driven by shared feature information, and later conceptual integration of information which individuates basic-level concepts from semantically similar items.</p>
<p>Importance of Anterior-Posterior Interactions in the Ventral Stream</p>
<p>Taken together, data from neuropsychology, fMRI, and MEG reveal that semantic representations are transformed from primarily reflecting superordinate category information to basic-level conceptual information within a few hundred milliseconds, supported by processing along the ventral visual pathway.In particular, the posterior fusiform gyrus and PRC are important to this transition.Electrophysiological recordings in the PRC and posterior ventral temporal cortex of macaques suggest that visual information becomes more differentiated as information flows from posterior to anterior regions [76], a general process along the ventral stream in which object representations are increasingly differentiated [3].With regards to the mechanism of how basiclevel concepts become differentiated within their category, we have shown that connectivity between the ATL and the posterior fusiform increases during tasks requiring access to basiclevel concepts compared to those requiring access to superordinate category information [70].This highlights that the temporal relationship between neural activity in anterior and posterior temporal lobe regions plays an important role in the formation of detailed basic-level conceptual representations.</p>
<p>An important issue is whether interactions involving anterior and posterior regions in the ventral visual pathway are predominantly feedforward or feedback in nature, and how this might change during the course of perception.Combining neuropsychology and functional imaging is particularly illuminating.Patients with semantic deficits following neurological diseases affecting the anterior temporal lobes show reduced functional activity in the posterior aspects of the ventral stream [77,78], suggesting that anterior damage impacts on the functioning of more-posterior sites.Consistent with this, small lesions to the temporal pole and rhinal cortices (perirhinal and entorhinal) create network dysfunction in the ventral visual pathway, specifically resulting in reduced feedback connectivity from the anterior temporal lobes to posterior fusiform [79].</p>
<p>Overall, these studies strongly suggest that feedback from the anterior temporal lobes, and from PRC, to the posterior ventral stream constitutes a necessary mechanism for accessing specific conceptual representations.</p>
<p>The role that brain connectivity plays in the organisation and orchestration of conceptual knowledge in the brain is yet to be fully appreciated [80].We have emphasised that connectivity between anterior and posterior temporal lobe sites provides a key underpinning to forming specific basic-level conceptual representations [70], but how this within-temporal-lobe connectivity is coordinated with other networks (e.g., frontotemporal connectivity) remains an important unresolved issue [62,81].One avenue for progress requires understanding how different brain networks are coordinated, the oscillatory nature of such connectivity and, vitally, how connectivity is modulated by well-characterised and distinct cognitive processes (see Outstanding Questions).</p>
<p>Concluding Remarks</p>
<p>We have argued here for a single explanatory framework, based on a feature-based account, to understand semantic cognition in the ventral visual pathway.This framework can account for several phenomena, previously unconnected, across behaviour, functional neuroimaging (fMRI, MEG), and brain-damaged patients.Progress in understanding conceptual representations in the brain is significantly advanced by shifting focus to the representation of basic-level concepts and to the relationships between them.We can then harness the potential of large featurenorming datasets to provide well-characterised models of semantic space whose regularities can be exploited using multivariate analysis methods applied to multiple imaging modalities.</p>
<p>Outstanding Questions</p>
<p>How does connectivity within, and beyond, the ventral visual pathway emerge and dissolve during the recognition of an object?The way in which regions communicate changes over time, but we know little about how the dynamic patterns of connectivity wax and wane, or what information they reflect.</p>
<p>How does conceptual structure interface with non-visual recognition?The research discussed here is based on visual object recognition, where meaning is accessed from vision.However, it remains to be seen if conceptual structure can account for activations outside the ventral stream, such as during tactile recognition and performing object actions.</p>
<p>How do perceptual and conceptual processes interact during word recognition?Hearing and seeing words will likely have a different conceptual timecourse from viewing images.For a written or spoken word, the form-tomeaning relationship is essentially arbitrary, resulting in different constraints during the transition from form to meaning.</p>
<p>How does expert knowledge influence the dynamics of conceptual processing?It may be the case that becoming an expert for some object classes changes the dynamics of conceptual activation.</p>
<p>What impact does ATL and AMTC damage have on the functional activation of the semantic network?While research suggests widespread ATL damage reduces functional activation in, and connectivity to, the posterior fusiform, the nature of object information we can detect in the compromised network is unknown.</p>
<p>How do concepts come to be represented in the brain the way that they are?Research aiming to uncover what the informational units of meaning are would have a profound effect on theories of semantic cognition.</p>
<p>How is visual information transformed into semantic information?We have shown how different types of perceptual and semantic information can be represented in the brain, although key evidence would be provided by understanding how specific aspects of perception causally activate specific aspects of semantics.</p>
<p>Figure 1 .
1
Figure 1.Regions Supporting Conceptual Processing in the Anterior and Posterior Ventral Visual Pathway.Different subregions of the anterior temporal lobe are shown where the middle temporal gyrus (MTG) and inferior temporal gyrus (ITG) are relatively more lateral, the fusiform occupies a ventral position, and the perirhinal (PRC) and entorhinal cortex (ERC) are more medial in the anterior medial temporal cortex (reprinted from[43]).</p>
<p>Figure 2 .
2
Figure 2. The Nature of Category-Specific Deficits.(A) Drawings from patient SE of common objects of living and nonliving things, showing a clear absence of distinctive feature information for living things and a preservation of details for nonliving things.Nonliving objects, top left to bottom right; helicopter, chisel, anchor, windmill, bus.Living objects; crocodile, zebra, duck, penguin, camel.Reproduced from [17] with permission from Taylor and Francis.(B) MRI scan from patient SE showing extensive damage in the right anterior temporal lobe (ATL; image shown in radiological convention, previously unpublished).</p>
<p>Figure 3 .
3
Figure 3. Conceptual Structure Effects In The Ventral Visual Pathway.(A) Conceptual structure statistics modulate activity in both the posterior and anterior-medial temporal lobe based on different feature-based statistics.Posterior fusiform activity increases in the lateral posterior fusiform for objects with relatively more shared features, and activity increases in the medial posterior fusiform for objects with relatively fewer shared features.Bilateral anteromedial temporal cortex (AMTC) activity increases for concepts that are semantically more-confusable (reproduced from[42] with permission from MIT press).(B) Increasing damage to the perirhinal cortex (PRC) results in poorer performance for naming semantically moreconfusable objects.This is shown by first correlating the naming accuracy of each patient with a conceptual structure measure for the ease of conceptual individuation.This correlation is then related to the degree of damage to the PRC (crosses denote left hemisphere damage; circles denote right hemisphere damage) (reprinted from[43]).(C) Pattern similarity in bilateral PRC is related to conceptual similarity based on semantic features.Semantic similarity can be defined based on overlapping semantic features between concepts, where concepts both cluster by superordinate category and show within-category variability.Testing the relationship between semantic feature similarity and pattern similarity in the brain shows that bilateral PRC similarity patterns also show a clustering by superordinate category and, crucially, withincategory differentiation aligned to conceptual similarity (reprinted from[49] with permission from the Society for Neuroscience).(D) The timecourse of superordinate category and basic-level concept information shown with magnetoencephalography (MEG).Using multiple linear regression we can learn how to map between the recorded MEG data and the visual and semantic measures for different objects.After showing how well this model can explain the observed neural data, we asked how accurately the model could predict MEG data for new objects.This showed than the superordinate category of an object can be successfully predicted before the prediction of the basic-level concept (after accounting for the influence of visual statistics) (reprinted from[68] with permission from Oxford University Press).</p>
<p>Trends in Cognitive Sciences, November 2015, Vol. 19, No. 11 679
Trends in Cognitive Sciences, November 2015, Vol. 19, No. 11 681
Trends in Cognitive Sciences, November 2015, Vol. 19, No. 683
Trends in Cognitive Sciences, November 2015, Vol. 19, No. 11 685
Trends in Cognitive Sciences, November 2015, Vol. 19, No. 11 687
AcknowledgmentsWe thank William Marslen-Wilson for his helpful comments on this manuscript.The research leading to these results has received funding to L.K.T. from the European Research Council under the European Commission Seventh Framework Programme (FP7/2007-2013)/ERC grant agreement 249640.
Pictures and names: making the connection. P Jolicoeur, Cogn. Psychol. 161984</p>
<p>Basic objects in natural categories. E Rosch, Cogn. Psychol. 81976</p>
<p>How does the brain solve visual object recognition?. J J Dicarlo, Neuron. 732012</p>
<p>Identifying natural images from human brain activity. K Kay, Nature. 4522008</p>
<p>ImageNet Classification with Deep Convolutional Neural Networks. A Krizhevsky, Advances in Neural Information Processing. MIT Press201225</p>
<p>Reconstructing visual experiences from brain activity evoked by natural movies. S Nishimoto, Curr. Biol. 212011</p>
<p>The neurobiology of semantic memory. J R Binder, R H Desai, Trends Cogn. Sci. 152011</p>
<p>Concepts and categories: a cognitive neuropsychological perspective. B Z Mahon, A Caramazza, Annu. Rev. Psychol. 602009</p>
<p>The representation of object concepts in the brain. A Martin, Annu. Rev. Psychol. 582007</p>
<p>Past, present, and prospects: reflections 40 years on from the selective impairment of semantic memory. R Mccarthy, E K Warrington, 10.1080/17470218.2014.980280Q. J. Exp. Physiol. Published online March. 62015. 1975. 2015</p>
<p>Where do you know what you know? The representation of semantic knowledge in the human brain. K Patterson, Nat. Rev. Neurosci. 82007</p>
<p>Conceptual structure: towards an integrated neurocognitive account. K I Taylor, Lang. Cogn. Process. Cogn. Neurosci. Lang. 262011</p>
<p>Semantic memory. E Yee, The Oxford Handbook of Cognitive Neuroscience. Ochsner, K.N. and Kosslyn, S.12013Oxford University PressCore Topics</p>
<p>The evaluation of sources of knowledge underlying different conceptual categories. G Gainotti, Front. Hum. Neurosci. 7402013</p>
<p>Category-specific organization in the human brain does not require visual experience. B Z Mahon, Neuron. 632009</p>
<p>Neural systems behind word and concept retrieval. H Damasio, Cognition. 922004</p>
<p>When leopards lose their spots: knowledge of visual properties in category-specific deficits for living things. H E Moss, Cogn. Neuropsychol. 141997</p>
<p>Category specific semantic impairments. E K Warrington, T Shallice, Brain. 1071984</p>
<p>Differential activity for animals and manipulable objects in the anterior temporal lobes. S Anzellotti, J. Cogn. Neurosci. 232011</p>
<p>First-pass selectivity for semantic categories in human anteroventral temporal cortex. A M Chan, J. Neurosci. 312011</p>
<p>Category-specific visual responses of single neurons in the human medial temporal lobe. G Kreiman, Nat. Neurosci. 32000</p>
<p>Anteromedial temporal cortex supports fine-grained differentiation among objects. H E Moss, Cereb. Cortex. 152005</p>
<p>Binding crossmodal object features in perirhinal cortex. K I Taylor, Proc. Natl. Acad. Sci. U.S.A. 1032006</p>
<p>Attribute-based neural substrates in temporal cortex for perceiving and knowing about objects. L L Chao, Nat. Neurosci. 21999</p>
<p>A real-world size organization of object responses in occipito-temporal cortex. T Konkle, A Oliva, Neuron. 742012</p>
<p>The representation of biological classes in the brain. A C Connolly, J. Neurosci. 322012</p>
<p>Activation of the middle fusiform 'face area' increases with expertise in recognizing novel objects. I Gauthier, Nat. Neurosci. 21999</p>
<p>Center-periphery organization of human object areas. I Levy, Nat. Neurosci. 42001</p>
<p>Interpreting fMRI data: maps, modules and dimensions. H P Beeck, Op De, Nat. Rev. Neurosci. 92008</p>
<p>A common, high-dimensional model of the represenational space in human ventral temporal cortex. J Haxby, Neuron. 722011</p>
<p>Experience-dependent modulation of category-related cortical activity. L L Chao, Cereb. Cortex. 122002</p>
<p>A category-specific response to animals in the right human amygdala. F Mormann, Nat. Neurosci. 142011</p>
<p>Action-related properties shape object representations in the ventral stream. B Z Mahon, Neuron. 552007</p>
<p>The parahippocampal place area: recognition, navigation, or encoding?. R Epstein, Neuron. 231999</p>
<p>Unraveling the distributed neural code of facial identity through spatiotemporal pattern analysis. A Nestor, Proc. Natl. Acad. Sci. U.S.A. 1082011</p>
<p>Intra-and interhemispheric connectivity between face-selective regions in the human brain. J Davies-Thompson, T J Andrews, J. Neurophysiol. 1082012</p>
<p>Selectivity for the human body in the fusiform gyrus. M V Peelen, P E Downing, J. Neurophysiol. 932005</p>
<p>Coherent concepts are computed in the anterior temporal lobes. Lambon Ralph, M A , Proc. Natl. Acad. Sci. U.S.A. 1072010</p>
<p>Time-locked multi-regional retro-activation: a systems-level proposal for the neural substrates of recall and recognition. A R Damasio, Cognition. 331989</p>
<p>The similarity-in-topography principle: Reconciling theories of conceptual deficits. W K Simmons, L W Barsalou, Cogn. Neuropsychol. 202003</p>
<p>Towards a distributed account of conceptual knowledge. L K Tyler, H E Moss, Trends Cogn. Sci. 52001</p>
<p>Objects and categories: feature statistics and object processing in the ventral stream. L K Tyler, J. Cogn. Neurosci. 252013</p>
<p>The perirhinal cortex and conceptual processing: effects of feature-based statistics following damage to the anterior temporal lobes. P Wright, 10.1016/j.neuropsychologia.2015.01.041Neuropsychologia Published online. 2015. January 29. 2015</p>
<p>Conceptual structure modulates anteromedial temporal involvement in processing verbally presented object properties. P Bright, Cereb. Cortex. 172007</p>
<p>The human perirhinal cortex and semantic memory. R R Davies, Eur. J. Neurosci. 202004</p>
<p>Medial perirhinal cortex disambiguates confusable objects. S L Kivisaari, Brain. 1352012</p>
<p>Crossmodal integration of object features: voxel-based correlations in brain-damaged patients. K I Taylor, Brain. 1322009</p>
<p>Processing objects at different levels of specificity. L K Tyler, J. Cogn. Neurosci. 162004</p>
<p>Object-specific semantic coding in human perirhinal cortex. A Clarke, L K Tyler, J. Neurosci. 342014</p>
<p>Intact memory for irrelevant information impairs perception in amnesia. M D Barense, Neuron. 752012</p>
<p>Selective perceptual impairments after perirhinal cortex ablation. M J Buckley, J. Neurosci. 212001</p>
<p>Components of recognition memory: dissociable cognitive processes or just differences in representational complexity?. R A Cowell, Hippocampus. 202010</p>
<p>Influence of conceptual knowledge on visual object discrimination: insights from semantic dementia and MTL amnesia. M D Barense, Cereb. Cortex. 202010</p>
<p>The anatomy of object processing: the role of anteromedial temporal cortex. P Bright, Q. J. Exp. Psychol. Sect. B. 582005</p>
<p>Similarity of fMRI activity patterns in left perirhinal cortex reflects semantic similarity between words. R Bruffaerts, J. Neurosci. 332013</p>
<p>Hippocampal activity patterns carry information about objects in temporal context. L Hsieh, Neuron. 812014</p>
<p>What the left and right anterior fusiform gyri tell us about semantic memory. M Mion, Brain. 1332010</p>
<p>Conceptual object representations in human anterior temporal cortex. M V Peelen, A Caramazza, J. Neurosci. 322012</p>
<p>Concept cells: the building blocks of declarative memory functions. R Quian Quiroga, Nat. Rev. Neurosci. 132012</p>
<p>The medial temporal lobe supports conceptual implicit memory. W Wang, Neuron. 682010</p>
<p>Expertise for cars and birds recruits brain areas involved in face recognition. I Gauthier, Nat. Neurosci. 32000</p>
<p>Top-down facilitation of visual recognition. M Bar, Proc. Natl. Acad. Sci. U.S.A. 1032006</p>
<p>View from the top: hierarchies and reverse hierarchies in the visual system. S Hochstein, M Ahissar, Neuron. 362002</p>
<p>Why visual attention and awareness are different. V A Lamme, Trends Cogn. Sci. 72003</p>
<p>The distinct modes of vision offered by feedforward and recurrent processing. V Lamme, P Roelfsema, Trends Neurosci. 232000</p>
<p>Electrophysiological potentials reveal cortical mechanisms for mental imagery, mental simulation, and grounded (embodied) cognition. H E Schendan, G Ganis, R M Cichy, Front. Psychol. 32012. 2014Nat. Neurosci.</p>
<p>Predicting the time course of individual objects with MEG. A Clarke, 10.1093/cercor/bhu203Cereb. Cortex. Published. 2014. online September 9. 2014</p>
<p>The characteristics and limits of rapid visual categorization. M Fabre-Thorpe, Front. Psychol. 22432011</p>
<p>The evolution of meaning: spatiotemporal dynamics of visual object recognition. A Clarke, J. Cogn. Neurosci. 232011</p>
<p>Induced gamma-band activity is related to the time point of object identification. J Martinovic, Brain Res. 11982008</p>
<p>Object knowledge during entry-level categorization is activated and modified by implicit memory after 200 ms. H E Schendan, S M Maher, Neuroimage. 442009</p>
<p>Dynamic information processing states revealed through neurocognitive models of object semantics. A Clarke, Lang. Cogn. Neurosci. 302015</p>
<p>Robust object recognition with cortex-like mechanisms. T Serre, IEEE Trans. Pattern Anal. Mach. Intell. 292007</p>
<p>From perception to conception: how meaningful objects are processed over time. A Clarke, Cereb. Cortex. 232013</p>
<p>Signals in inferotemporal and perirhinal cortex suggest an 'untangling' of visual target information. M Pagan, Nat. Neurosci. 162013</p>
<p>Anterior temporal lobe degeneration produces widespread network-driven dysfunction. C Gou, Brain. 1362013</p>
<p>Disrupted temporal lobe connections in semantic dementia. C J Mummery, Brain. 1221999</p>
<p>Anterobasal temporal lobe lesions alter recurrent functional connectivity within the ventral pathway during naming. P Campo, J. Neurosci. 332013</p>
<p>What drives the organization of object knowledge in the brain?. B Z Mahon, A Caramazza, Trends Cogn. Sci. 152011</p>
<p>Where vision meets memory: prefrontal-posterior networks for visual object constancy during categorization and recognition. H E Schendan, C E Stern, Cereb. Cortex. 182008</p>
<p>Analyzing the factors underlying the structure and computation of the meaning of chipmunk, cherry, chisel, cheese, and cello (and many other such concrete nouns). G S Cree, K Mcrae, J. Exp. Psychol. Gen. 1322003</p>
<p>A computational model of semantic memory impairment: Modality specificity and emergent category specificity. M J Farah, J L Mcclelland, J. Exp. Psychol. Gen. 1201991</p>
<p>Prototypicality, distinctiveness, and intercorrelation: Analyses of the semantic attributes of living and nonliving concepts. P Garrard, Cogn. Neuropsychol. 182001</p>
<p>Hierarchies, similarity, and interactivity in object recognition: category-specific neuropsychological deficits. G W Humphreys, E M E Forde, Behav. Brain Sci. 242001</p>
<p>T T Rogers, J L Mcclelland, Semantic Cognition: A Parallel Distributed Approach. MIT Press2004</p>
<p>Representing the meanings of object and action words: the featural and unitary semantic space hypothesis. G Vigliocco, Cogn. Psychol. 482004</p>
<p>The Centre for Speech, Language and the Brain (CSLB) concept property norms. B J Devereux, Behav. Res. Methods. 462014</p>
<p>The acquisition of natural kind and artifact terms. F C Keil, Language Learning and Concept Acquisition. W Domopoulous, A Marras, Ablex1986</p>
<p>Semantic feature production norms for a large set of living and nonliving things. K Mcrae, Behav. Res. Methods. 372005</p>
<p>Distinctive features hold a privileged status in the computation of word meaning: Implications for theories of semantic memory. G S Cree, J. Exp. Psychol. Learn. Mem. Cogn. 322006</p>
<p>Distinctiveness and correlation in conceptual structure: behavioral and computational studies. B Randall, J. Exp. Psychol. Learn. Mem. Cogn. 302004</p>
<p>Contrasting effects of feature-based statistics on the categorisation and identification of visual objects. K I Taylor, Cognition. 1222012</p>
<p>Quantitive modeling of the neural representation of objects: How semantic feature norms can account for fMRI activation. K Chang, Neuroimage. 562011</p>
<p>Using fMRI activation to conceptual stimuli to evaluate methods for extracting conceptual representations from corpora. B Devereux, Proceedings of the NAACL HLT 2010 First Workshop on Computational Neurolinguistics. B Murphy, the NAACL HLT 2010 First Workshop on Computational NeurolinguisticsAssociation for Computational Linguistics2010</p>
<p>Semantic relevance explains category effects in medial fusiform gyri. A Mechelli, Neuroimage. 302006</p>
<p>Early parallel activation of semantics and phonology in picture naming: Evidence from a multiple linear regression MEG study. M Miozzo, 10.1093/cercor/bhu137Cereb. Cortex Published online July. 82014. 2014</p>
<p>Tracking neural coding of perceptual and semantic features of concrete nouns. G Sudre, Neuroimage. 622012</p>            </div>
        </div>

    </div>
</body>
</html>