<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-8710 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-8710</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-8710</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-156.html">extraction-schema-156</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of representational formats of conceptual knowledge at a functional (not neural) level, including descriptions of the format, supporting or challenging evidence, cognitive tasks or phenomena used as evidence, comparisons between formats, and theoretical claims or implications.</div>
                <p><strong>Paper ID:</strong> paper-69301638</p>
                <p><strong>Paper Title:</strong> <a href="https://arxiv.org/pdf/1909.01645v1.pdf" target="_blank">Heterogeneous Proxytypes Extended: Integrating Theory-like Representations and Mechanisms with Prototypes and Exemplars</a></p>
                <p><strong>Paper Abstract:</strong> The paper introduces an extension of the proposal according to which conceptual representations in cognitive agents should be intended as heterogeneous proxytypes. The main contribution of this paper is in that it details how to reconcile, under a heterogeneous representational perspective, different theories of typicality about conceptual representation and reasoning. In particular, it provides a novel theoretical hypothesis - as well as a novel categorization algorithm called DELTA - showing how to integrate the representational and reasoning assumptions of the theory-theory of concepts with the those ascribed to the prototype and exemplars-based theories.</p>
                <p><strong>Cost:</strong> 0.016</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e8710.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e8710.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of representational formats of conceptual knowledge at a functional (not neural) level, including descriptions of the format, supporting or challenging evidence, cognitive tasks or phenomena used as evidence, comparisons between formats, and theoretical claims or implications.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Prototype theory</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Prototype theory (prototypical representations)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Conceptual categories are represented functionally by prototypical descriptions — an abstract 'best' or centroid instance encoded as a (possibly weighted) list of typical features or a region/centroid in a conceptual space; categorization is by similarity to that prototype.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Cognitive representations of semantic categories</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_name</strong></td>
                            <td>prototype theory / prototypical representation</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_description</strong></td>
                            <td>Represents a category by a prototypical member (the 'best' instance) or a region/centroid in a metric conceptual space; category membership is a graded function of similarity/distance between stimulus and prototype.</td>
                        </tr>
                        <tr>
                            <td><strong>format_type</strong></td>
                            <td>feature-based / metric (conceptual spaces) / hybrid</td>
                        </tr>
                        <tr>
                            <td><strong>cognitive_task_or_phenomenon</strong></td>
                            <td>Typicality effects, categorization, similarity-based classification, recognition</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Prototypes explain Rosch-style typicality phenomena and graded category membership; within DUAL-PECCS prototypes are stored as region centroids in a conceptual space and used for similarity-based categorization when no close exemplar is available.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_formats</strong></td>
                            <td>Contrasted with exemplars (which use stored instances) and theory-like representations (which supply causal/essence information); the paper's algorithm prefers exemplars when a similar exemplar exists, otherwise falls back to prototypes; prototypes are less able than theory-like representations to handle essentialist or transformation tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_counter_evidence</strong></td>
                            <td>Fails to account for judgments driven by hidden causal/essence knowledge (transformation experiments) and for cases where stored exemplars directly guide classification; may misclassify atypical items that share superficial features with a prototype but not with the category's underlying theory.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_claims_or_implications</strong></td>
                            <td>Functionally, prototypes provide a fast, similarity-based non-monotonic categorization mechanism that is contextually tokenized; within a heterogeneous architecture prototypes coexist with exemplars and theory-like bodies to support complementary classification behaviors.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Heterogeneous Proxytypes Extended: Integrating Theory-like Representations and Mechanisms with Prototypes and Exemplars', 'publication_date_yy_mm': '2019-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8710.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e8710.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of representational formats of conceptual knowledge at a functional (not neural) level, including descriptions of the format, supporting or challenging evidence, cognitive tasks or phenomena used as evidence, comparisons between formats, and theoretical claims or implications.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Exemplar theory</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Exemplar theory (exemplar-based representations)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Categories are represented as collections of stored specific instances (exemplars); classification is performed by retrieving and comparing similarity to these stored exemplars.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>An on-line investigation of prototype and exemplar strategies in classification</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_name</strong></td>
                            <td>exemplar theory / exemplar representations</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_description</strong></td>
                            <td>Stores multiple explicit examples (region points in a conceptual space) for each category; categorization of a new stimulus is determined by similarity to retrieved exemplars or nearest neighbors.</td>
                        </tr>
                        <tr>
                            <td><strong>format_type</strong></td>
                            <td>instance-based / metric (conceptual spaces) / hybrid</td>
                        </tr>
                        <tr>
                            <td><strong>cognitive_task_or_phenomenon</strong></td>
                            <td>Categorization, similarity judgments, situations where known exemplars drive classification (e.g., penguin recognized as bird via exemplar rather than prototype)</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Explains cases where humans classify items by similarity to specific remembered instances; in DUAL-PECCS system, exemplar retrieval is given priority when a sufficiently similar exemplar is present (matching experimental observations of exemplar preference).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_formats</strong></td>
                            <td>Preferred over prototype-based classification when similar exemplars exist (paper encodes an explicit exemplar-first preference); complements prototypes by capturing idiosyncratic variability that prototypes smooth over.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_counter_evidence</strong></td>
                            <td>Requires storage of many exemplars; may fail to generalize to novel instances that differ from stored exemplars; does not by itself capture causal or essence-based judgments that theory-like representations can explain.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_claims_or_implications</strong></td>
                            <td>Functionally, exemplars enable fine-grained, memory-based classification and explain exemplar-driven decisions; in a heterogeneous architecture they are tokenized when contextually relevant and can override prototype judgments.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Heterogeneous Proxytypes Extended: Integrating Theory-like Representations and Mechanisms with Prototypes and Exemplars', 'publication_date_yy_mm': '2019-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8710.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e8710.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of representational formats of conceptual knowledge at a functional (not neural) level, including descriptions of the format, supporting or challenging evidence, cognitive tasks or phenomena used as evidence, comparisons between formats, and theoretical claims or implications.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Theory-theory</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Theory-theory (theory-like representations / default common-sense theories)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Concepts are underpinned by structured theory-like bodies of knowledge (causal/explanatory relations or micro-theories) that individuate categories by the roles and causal/essence properties they encode.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>The role of theories in conceptual coherence</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_name</strong></td>
                            <td>theory-theory / theory-like representations</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_description</strong></td>
                            <td>Represents categories as networks of causal, explanatory, and default rules (micro-theories) about hidden properties and relations; functional categorization can rely on coherence with these networks rather than surface similarity.</td>
                        </tr>
                        <tr>
                            <td><strong>format_type</strong></td>
                            <td>theory-based / structured symbolic-probabilistic / hybrid</td>
                        </tr>
                        <tr>
                            <td><strong>cognitive_task_or_phenomenon</strong></td>
                            <td>Transformation experiments, essentialism judgments, categorization under atypical appearances, non-monotonic default inferences (e.g., switch-on → light)</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Explains experimental results (e.g., Keil's transformation tasks) where subjects rely on theory-like knowledge (essence, causal relations) over prototypes; paper argues that theory-like structures can and should override prototype-based categorization when conceptual coherence is low.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_formats</strong></td>
                            <td>Differs from prototypes/exemplars by privileging hidden causal structure and essences rather than surface similarity; paper's DELTA algorithm allows theory-like representations to override prototype outputs when coherence threshold indicates mismatch.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_counter_evidence</strong></td>
                            <td>Ambiguity about whether theory-like knowledge is default typical knowledge or part of classical background (dual interpretation); current DUAL-PECCS lacks an implemented module for common-sense default theory-like representations (integration is future work).</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_claims_or_implications</strong></td>
                            <td>Functionally, theory-like representations support non-monotonic, explanatory, and essence-based reasoning, providing categorical judgments that go beyond similarity and enabling defeasible inferences; graphical models (Bayesian networks) and probabilistic semantic networks are suggested as computational realizations.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Heterogeneous Proxytypes Extended: Integrating Theory-like Representations and Mechanisms with Prototypes and Exemplars', 'publication_date_yy_mm': '2019-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8710.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e8710.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of representational formats of conceptual knowledge at a functional (not neural) level, including descriptions of the format, supporting or challenging evidence, cognitive tasks or phenomena used as evidence, comparisons between formats, and theoretical claims or implications.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Classical theory</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Classical theory (necessary and sufficient condition representations)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Concepts are defined extensionally/intensionally by sets of necessary and sufficient features enabling monotonic, deductive categorization.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_name</strong></td>
                            <td>classical theory / classical representations</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_description</strong></td>
                            <td>Represents category membership via explicit rules or definitions (necessary and sufficient conditions), enabling standard deductive (monotonic) reasoning about membership.</td>
                        </tr>
                        <tr>
                            <td><strong>format_type</strong></td>
                            <td>symbolic / logical / ontological</td>
                        </tr>
                        <tr>
                            <td><strong>cognitive_task_or_phenomenon</strong></td>
                            <td>Deductive categorization, rule-based classification, formal ontology-style inferences (e.g., geometric definition of triangle)</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Classical representations capture cases where explicit definitional criteria determine membership; in DUAL-PECCS classical knowledge is encoded in an ontology (OpenCyc) and supports monotonic reasoning that is harmonized with typicality-based outputs via dual-process integration.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_formats</strong></td>
                            <td>Contrasts with prototype/exemplar/theory-based non-monotonic reasoning; used to check and integrate non-monotonic conclusions (dual-process theory) and provides exact logical membership where applicable.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_counter_evidence</strong></td>
                            <td>Poor fit for ordinary/common-sense categories that show graded membership and typicality effects; cannot account for non-monotonic defeasible inferences inherent in everyday concepts.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_claims_or_implications</strong></td>
                            <td>Functionally, classical representations provide precise deductive mechanisms that complement typicality-based reasoning in a heterogeneous architecture; they underpin background ontological facts and are combined with non-monotonic processes via dual-process frameworks.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Heterogeneous Proxytypes Extended: Integrating Theory-like Representations and Mechanisms with Prototypes and Exemplars', 'publication_date_yy_mm': '2019-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8710.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e8710.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of representational formats of conceptual knowledge at a functional (not neural) level, including descriptions of the format, supporting or challenging evidence, cognitive tasks or phenomena used as evidence, comparisons between formats, and theoretical claims or implications.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Proxytype theory</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Proxytype theory / heterogeneous proxytypes</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Concepts are tokenized temporary constructs ('proxytypes') drawn from long-term heterogeneous networks (prototypes, exemplars, theory-like, classical knowledge) and activated in working memory to 'stand in' for categories during cognitive tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_name</strong></td>
                            <td>proxytype / heterogeneous proxytypes</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_description</strong></td>
                            <td>A functional account where each conceptual category is a heterogenous network in long-term memory (multiple representational bodies) and working memory tokens (proxytypes) selectively activate contextually relevant parts to perform recognition, categorization, retrieval.</td>
                        </tr>
                        <tr>
                            <td><strong>format_type</strong></td>
                            <td>hybrid / heterogeneous (multi-representational)</td>
                        </tr>
                        <tr>
                            <td><strong>cognitive_task_or_phenomenon</strong></td>
                            <td>Contextual activation, retrieval, categorization, tokenization in working memory, interplay of long-term and working memory</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Paper extends the proxytype idea to heterogeneous proxytypes (prototypes, exemplars, theory-like and classical components co-referring to same entity); implemented in DUAL-PECCS where different representation types are stored and selectively tokenized according to stimulus.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_formats</strong></td>
                            <td>Not a single format but an integrative stance asserting coexistence and context-sensitive selection among prototypes, exemplars, theories and classical representations; proposes a computational mechanism to harmonize these formats (DELTA) and leverages dual-process theory for integration with monotonic reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_counter_evidence</strong></td>
                            <td>Original proxytype theory depicted proxytypes as monolithic prototypes — heterogeneous extension requires explicit selection/tokenization mechanisms and empirical validation; design choices (how to select which sub-representation to tokenise) remain to be empirically calibrated.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_claims_or_implications</strong></td>
                            <td>Functionally, concepts are heterogeneous bodies of knowledge with multiple representational formats stored in LTM and selectively tokenized as proxytypes in WM; this supports diverse categorization strategies and contextual activation of relevant knowledge.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Heterogeneous Proxytypes Extended: Integrating Theory-like Representations and Mechanisms with Prototypes and Exemplars', 'publication_date_yy_mm': '2019-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8710.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e8710.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of representational formats of conceptual knowledge at a functional (not neural) level, including descriptions of the format, supporting or challenging evidence, cognitive tasks or phenomena used as evidence, comparisons between formats, and theoretical claims or implications.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Conceptual spaces</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Conceptual spaces (Gärdenfors)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A geometric, metric vector-space framework used to represent typicality-based knowledge (prototypes as centroids, exemplars as points) where similarity is computed by distance metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Conceptual spaces: The geometry of thought</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_name</strong></td>
                            <td>conceptual spaces (metric vector-space)</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_description</strong></td>
                            <td>Represents concepts in multi-dimensional continuous spaces where dimensions correspond to quality domains; prototypes are centroids/regions and exemplars are points; similarity and categorization are computed via distance metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>format_type</strong></td>
                            <td>distributed / metric / continuous-space</td>
                        </tr>
                        <tr>
                            <td><strong>cognitive_task_or_phenomenon</strong></td>
                            <td>Similarity-based categorization, typicality gradients, region-based category representations</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>DUAL-PECCS implements prototypes and exemplars in conceptual spaces (prototypes = region centroids, exemplars = points) and uses standard similarity metrics to determine distances between stimuli and category representations.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_formats</strong></td>
                            <td>Provides a lingua franca for integrating prototypes and exemplars (both metric) and contrasts with symbolic ontologies used for classical knowledge; suited to graded similarity but not directly expressive of causal or theory-like relations.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_counter_evidence</strong></td>
                            <td>Conceptual spaces do not naturally encode causal/explanatory structure or default theory-like knowledge; require additional mechanisms (e.g., graphical models) to represent theory-like relations.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_claims_or_implications</strong></td>
                            <td>Functionally, conceptual spaces supply a principled metric for typicality and similarity-based categorization and serve as an integrative substrate for prototype/exemplar-based processes within heterogeneous architectures.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Heterogeneous Proxytypes Extended: Integrating Theory-like Representations and Mechanisms with Prototypes and Exemplars', 'publication_date_yy_mm': '2019-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8710.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e8710.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of representational formats of conceptual knowledge at a functional (not neural) level, including descriptions of the format, supporting or challenging evidence, cognitive tasks or phenomena used as evidence, comparisons between formats, and theoretical claims or implications.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Ontological formalisms / OpenCyc</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Ontological formalisms (OpenCyc as example)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Symbolic, logic-based representations of classical background knowledge (taxonomic and definitional relations) used for monotonic deductive inferences in the architecture.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>CYC: Using common sense knowledge to overcome brittleness and knowledge acquisition bottlenecks</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_name</strong></td>
                            <td>ontological formalisms / symbolic ontologies</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_description</strong></td>
                            <td>Represents classical conceptual knowledge as symbolic logical assertions (taxonomic relations, necessary/sufficient conditions) enabling monotonic deductive reasoning and integration with other knowledge via mapping/anchoring.</td>
                        </tr>
                        <tr>
                            <td><strong>format_type</strong></td>
                            <td>symbolic / logical / ontology</td>
                        </tr>
                        <tr>
                            <td><strong>cognitive_task_or_phenomenon</strong></td>
                            <td>Deductive categorization, background knowledge retrieval, taxonomy-based inference</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>DUAL-PECCS grounds its classical knowledge component in OpenCyc and uses ontological assertions to support monotonic categorization checks that are harmonized with non-monotonic typicality outputs via dual-process integration.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_formats</strong></td>
                            <td>Symbolic ontologies provide precise logical inferences unlike metric conceptual spaces; they are complementary in a heterogeneous architecture, used to validate or override typicality-based inferences where definitional criteria apply.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_counter_evidence</strong></td>
                            <td>Poor fit for representing graded typicality and defeasible common-sense rules; ontologies cannot capture many forms of non-monotonic, probabilistic, or causal common-sense knowledge without extensions.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_claims_or_implications</strong></td>
                            <td>Functionally, ontologies serve as the monotonic logical backbone that can check and integrate outputs of typicality-based systems, enabling a mixed reasoning strategy in cognitive architectures.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Heterogeneous Proxytypes Extended: Integrating Theory-like Representations and Mechanisms with Prototypes and Exemplars', 'publication_date_yy_mm': '2019-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8710.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e8710.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of representational formats of conceptual knowledge at a functional (not neural) level, including descriptions of the format, supporting or challenging evidence, cognitive tasks or phenomena used as evidence, comparisons between formats, and theoretical claims or implications.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Bayesian networks / graphical models</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Bayesian networks and graphical models for theory-like knowledge</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Probabilistic graphical models are proposed as computational realizations for representing causal and default theory-like common-sense knowledge, enabling probabilistic inference about hidden properties and causal relations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Theory unification and graphical models in human categorization</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_name</strong></td>
                            <td>graphical models / Bayesian networks (for theory-like representations)</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_description</strong></td>
                            <td>Represents theory-like bodies as probabilistic graphs (nodes for variables/properties, edges for causal/statistical dependencies) supporting probabilistic and defeasible inferences about hidden causes/essences.</td>
                        </tr>
                        <tr>
                            <td><strong>format_type</strong></td>
                            <td>probabilistic / graphical / hybrid</td>
                        </tr>
                        <tr>
                            <td><strong>cognitive_task_or_phenomenon</strong></td>
                            <td>Causal learning, categorization driven by hidden properties, probabilistic reasoning, theory-unification tasks</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Paper cites graphical models as promising for encoding common-sense default theories (causal networks) and as computational substrates for the theory-theory component; integration into DUAL-PECCS is planned but not yet implemented.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_formats</strong></td>
                            <td>Graphical models can capture causal/explanatory structure missing from metric or symbolic formats and can be combined with metric conceptual-space similarity metrics; they complement prototypes/exemplars and ontologies by supporting probabilistic causal inference.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_counter_evidence</strong></td>
                            <td>Not implemented in the current DUAL-PECCS instantiation; practical choices (which theory-like representation to select, heuristics for graph search) and parameterization remain open and require empirical validation.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_claims_or_implications</strong></td>
                            <td>Functionally, graphical models provide a principled way to represent and compute with theory-like, causal, and default knowledge, allowing these structures to drive categorization and override similarity-based judgments when appropriate.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Heterogeneous Proxytypes Extended: Integrating Theory-like Representations and Mechanisms with Prototypes and Exemplars', 'publication_date_yy_mm': '2019-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8710.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e8710.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of representational formats of conceptual knowledge at a functional (not neural) level, including descriptions of the format, supporting or challenging evidence, cognitive tasks or phenomena used as evidence, comparisons between formats, and theoretical claims or implications.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DELTA algorithm</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>DELTA (unifieD CatEgorization aLgorithm for heTerogeneous representAtions)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A novel unified categorization algorithm proposed in this paper that selects among exemplars, prototypes, and theory-like representations to assign category labels to stimuli based on similarity thresholds and conceptual coherence.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_name</strong></td>
                            <td>unifying categorization procedure (DELTA)</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_description</strong></td>
                            <td>Functionally selects the most appropriate typicality-based representation: retrieves exemplar if within exemplar-similarity threshold, otherwise selects nearest prototype; further compares prototype's associated theory-like representation to stimulus via a Conceptual Coherence Threshold to decide if theory-like override is needed.</td>
                        </tr>
                        <tr>
                            <td><strong>format_type</strong></td>
                            <td>algorithmic / hybrid selection procedure</td>
                        </tr>
                        <tr>
                            <td><strong>cognitive_task_or_phenomenon</strong></td>
                            <td>Categorization under typicality and essentialist tensions, exemplar vs prototype use, theory-driven overrides (e.g., transformation judgments)</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Proposes an exemplar-first preference (matching human data) with prototype fallback and a mechanism for theory-like representations to override prototypes when conceptual coherence is low; DELTA is a theoretical proposal implemented conceptually in the paper but requires empirical testing.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_formats</strong></td>
                            <td>Integrates exemplar, prototype, and theory-theory mechanisms into a single selection algorithm and formalizes their interactions (preference ordering and coherence-based overrides).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_counter_evidence</strong></td>
                            <td>DELTA's components (e.g., exemplar similarity thresholds, Conceptual Coherence Threshold, selection of appropriate theory-like representation) are underspecified and require empirical calibration; actual integration of probabilistic theory-like modules into DUAL-PECCS remains future work.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_claims_or_implications</strong></td>
                            <td>Functionally, DELTA operationalizes the heterogeneous proxytypes hypothesis by providing a decision procedure for which representation to tokenise during categorization, thereby reconciling competing theories of typicality in a cognitively plausible way.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Heterogeneous Proxytypes Extended: Integrating Theory-like Representations and Mechanisms with Prototypes and Exemplars', 'publication_date_yy_mm': '2019-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8710.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e8710.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of representational formats of conceptual knowledge at a functional (not neural) level, including descriptions of the format, supporting or challenging evidence, cognitive tasks or phenomena used as evidence, comparisons between formats, and theoretical claims or implications.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DUAL-PECCS</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>DUAL-PECCS (A common-sense conceptual categorization system integrating heterogeneous proxytypes and the dual process of reasoning)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A cognitive categorization system that implements heterogeneous proxytypes: combines prototype and exemplar conceptual-space representations with a classical ontological component and dual-process-inspired harmonization of reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Dual PECCS: A Cognitive System for Conceptual Representation and Categorization.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_name</strong></td>
                            <td>DUAL-PECCS system (hybrid heterogeneous architecture)</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_description</strong></td>
                            <td>Implements multiple co-referring bodies of knowledge for concepts: prototypes and exemplars in conceptual spaces (non-monotonic similarity-based reasoning) and classical knowledge in ontologies (monotonic deductive reasoning), with tokenization/proxyfication mechanisms to activate the appropriate representation.</td>
                        </tr>
                        <tr>
                            <td><strong>format_type</strong></td>
                            <td>hybrid / heterogeneous / system-level architecture</td>
                        </tr>
                        <tr>
                            <td><strong>cognitive_task_or_phenomenon</strong></td>
                            <td>Categorization, concept activation/tokenization, harmonization of monotonic and non-monotonic reasoning, contextual retrieval</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>DUAL-PECCS successfully demonstrates a working integration of prototype, exemplar and classical knowledge for categorization tasks and supports context-sensitive selection of representations; however, it currently lacks integrated common-sense default theory-like modules (planned future work).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_formats</strong></td>
                            <td>Operationalizes the heterogeneous hypothesis by co-locating different representational formats and contrasting their behavior in categorization; uses dual-process theory to combine non-monotonic typicality outputs with monotonic ontology checks.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_counter_evidence</strong></td>
                            <td>Does not yet implement theory-like default representations (causal/essence networks) within the typical component; some integration choices (e.g., anchoring via WordNet) may affect generality; empirical validations are reported elsewhere but more psychological testing of extended heterogeneity is needed.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_claims_or_implications</strong></td>
                            <td>Functionally shows that a hybrid architecture combining metric conceptual spaces and symbolic ontologies with selective tokenization can capture diverse categorization behaviors and is a viable computational realization of heterogeneous proxytypes.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Heterogeneous Proxytypes Extended: Integrating Theory-like Representations and Mechanisms with Prototypes and Exemplars', 'publication_date_yy_mm': '2019-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8710.10">
                <h3 class="extraction-instance">Extracted Data Instance 10 (e8710.10)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of representational formats of conceptual knowledge at a functional (not neural) level, including descriptions of the format, supporting or challenging evidence, cognitive tasks or phenomena used as evidence, comparisons between formats, and theoretical claims or implications.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Conceptual coherence (constraint satisfaction)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Conceptual coherence measured as constraint satisfaction</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Assessment of how well a stimulus coheres with a theory-like representation is framed as a constraint satisfaction problem; coherence determines whether theory-like knowledge should override prototype-based categorization.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Coherence as constraint satisfaction</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_name</strong></td>
                            <td>conceptual coherence via constraint satisfaction</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_description</strong></td>
                            <td>Functional mechanism: compare stimulus-representation features against a theory-like network and evaluate overall coherence through constraint satisfaction computations (weighted constraints across properties/relations); used to decide overrides.</td>
                        </tr>
                        <tr>
                            <td><strong>format_type</strong></td>
                            <td>computational / constraint-satisfaction / hybrid</td>
                        </tr>
                        <tr>
                            <td><strong>cognitive_task_or_phenomenon</strong></td>
                            <td>Deciding when theory-like knowledge should drive categorization (e.g., overriding prototype decisions), coherence-based judgments</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Paper suggests using constraint-satisfaction algorithms (Thagard-style) to compute Conceptual Coherence Thresholds that determine whether a prototype match is conceptually coherent with the relevant theory-like network; practical instantiation is suggested but not implemented.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_formats</strong></td>
                            <td>Acts as a mediator between similarity-based formats (prototype/exemplar) and theory-based formats by providing a decision criterion; complements probabilistic graphical approaches by offering a symbolic/constraint criterion for coherence.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_counter_evidence</strong></td>
                            <td>Specification of thresholds and constraint weights is underspecified and requires empirical grounding; whether constraint-satisfaction captures the probabilistic nuances of theory-like reasoning is an open question.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_claims_or_implications</strong></td>
                            <td>Functionally, coherence-as-constraint-satisfaction offers a principled decision rule to determine when to accept prototype-based categorization versus invoking theory-like overrides, enabling structured interaction among heterogeneous representations.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Heterogeneous Proxytypes Extended: Integrating Theory-like Representations and Mechanisms with Prototypes and Exemplars', 'publication_date_yy_mm': '2019-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Conceptual spaces: The geometry of thought <em>(Rating: 2)</em></li>
                <li>Cognitive representations of semantic categories <em>(Rating: 2)</em></li>
                <li>Concepts, kinds, and cognitive development <em>(Rating: 2)</em></li>
                <li>The role of theories in conceptual coherence <em>(Rating: 2)</em></li>
                <li>Perceptual symbol systems <em>(Rating: 2)</em></li>
                <li>Theory unification and graphical models in human categorization <em>(Rating: 2)</em></li>
                <li>Dual PECCS: A Cognitive System for Conceptual Representation and Categorization. <em>(Rating: 2)</em></li>
                <li>An on-line investigation of prototype and exemplar strategies in classification <em>(Rating: 1)</em></li>
                <li>Coherence as constraint satisfaction <em>(Rating: 1)</em></li>
                <li>CYC: Using common sense knowledge to overcome brittleness and knowledge acquisition bottlenecks <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-8710",
    "paper_id": "paper-69301638",
    "extraction_schema_id": "extraction-schema-156",
    "extracted_data": [
        {
            "name_short": "Prototype theory",
            "name_full": "Prototype theory (prototypical representations)",
            "brief_description": "Conceptual categories are represented functionally by prototypical descriptions — an abstract 'best' or centroid instance encoded as a (possibly weighted) list of typical features or a region/centroid in a conceptual space; categorization is by similarity to that prototype.",
            "citation_title": "Cognitive representations of semantic categories",
            "mention_or_use": "use",
            "representational_format_name": "prototype theory / prototypical representation",
            "representational_format_description": "Represents a category by a prototypical member (the 'best' instance) or a region/centroid in a metric conceptual space; category membership is a graded function of similarity/distance between stimulus and prototype.",
            "format_type": "feature-based / metric (conceptual spaces) / hybrid",
            "cognitive_task_or_phenomenon": "Typicality effects, categorization, similarity-based classification, recognition",
            "key_findings": "Prototypes explain Rosch-style typicality phenomena and graded category membership; within DUAL-PECCS prototypes are stored as region centroids in a conceptual space and used for similarity-based categorization when no close exemplar is available.",
            "comparison_with_other_formats": "Contrasted with exemplars (which use stored instances) and theory-like representations (which supply causal/essence information); the paper's algorithm prefers exemplars when a similar exemplar exists, otherwise falls back to prototypes; prototypes are less able than theory-like representations to handle essentialist or transformation tasks.",
            "limitations_or_counter_evidence": "Fails to account for judgments driven by hidden causal/essence knowledge (transformation experiments) and for cases where stored exemplars directly guide classification; may misclassify atypical items that share superficial features with a prototype but not with the category's underlying theory.",
            "theoretical_claims_or_implications": "Functionally, prototypes provide a fast, similarity-based non-monotonic categorization mechanism that is contextually tokenized; within a heterogeneous architecture prototypes coexist with exemplars and theory-like bodies to support complementary classification behaviors.",
            "uuid": "e8710.0",
            "source_info": {
                "paper_title": "Heterogeneous Proxytypes Extended: Integrating Theory-like Representations and Mechanisms with Prototypes and Exemplars",
                "publication_date_yy_mm": "2019-09"
            }
        },
        {
            "name_short": "Exemplar theory",
            "name_full": "Exemplar theory (exemplar-based representations)",
            "brief_description": "Categories are represented as collections of stored specific instances (exemplars); classification is performed by retrieving and comparing similarity to these stored exemplars.",
            "citation_title": "An on-line investigation of prototype and exemplar strategies in classification",
            "mention_or_use": "use",
            "representational_format_name": "exemplar theory / exemplar representations",
            "representational_format_description": "Stores multiple explicit examples (region points in a conceptual space) for each category; categorization of a new stimulus is determined by similarity to retrieved exemplars or nearest neighbors.",
            "format_type": "instance-based / metric (conceptual spaces) / hybrid",
            "cognitive_task_or_phenomenon": "Categorization, similarity judgments, situations where known exemplars drive classification (e.g., penguin recognized as bird via exemplar rather than prototype)",
            "key_findings": "Explains cases where humans classify items by similarity to specific remembered instances; in DUAL-PECCS system, exemplar retrieval is given priority when a sufficiently similar exemplar is present (matching experimental observations of exemplar preference).",
            "comparison_with_other_formats": "Preferred over prototype-based classification when similar exemplars exist (paper encodes an explicit exemplar-first preference); complements prototypes by capturing idiosyncratic variability that prototypes smooth over.",
            "limitations_or_counter_evidence": "Requires storage of many exemplars; may fail to generalize to novel instances that differ from stored exemplars; does not by itself capture causal or essence-based judgments that theory-like representations can explain.",
            "theoretical_claims_or_implications": "Functionally, exemplars enable fine-grained, memory-based classification and explain exemplar-driven decisions; in a heterogeneous architecture they are tokenized when contextually relevant and can override prototype judgments.",
            "uuid": "e8710.1",
            "source_info": {
                "paper_title": "Heterogeneous Proxytypes Extended: Integrating Theory-like Representations and Mechanisms with Prototypes and Exemplars",
                "publication_date_yy_mm": "2019-09"
            }
        },
        {
            "name_short": "Theory-theory",
            "name_full": "Theory-theory (theory-like representations / default common-sense theories)",
            "brief_description": "Concepts are underpinned by structured theory-like bodies of knowledge (causal/explanatory relations or micro-theories) that individuate categories by the roles and causal/essence properties they encode.",
            "citation_title": "The role of theories in conceptual coherence",
            "mention_or_use": "mention",
            "representational_format_name": "theory-theory / theory-like representations",
            "representational_format_description": "Represents categories as networks of causal, explanatory, and default rules (micro-theories) about hidden properties and relations; functional categorization can rely on coherence with these networks rather than surface similarity.",
            "format_type": "theory-based / structured symbolic-probabilistic / hybrid",
            "cognitive_task_or_phenomenon": "Transformation experiments, essentialism judgments, categorization under atypical appearances, non-monotonic default inferences (e.g., switch-on → light)",
            "key_findings": "Explains experimental results (e.g., Keil's transformation tasks) where subjects rely on theory-like knowledge (essence, causal relations) over prototypes; paper argues that theory-like structures can and should override prototype-based categorization when conceptual coherence is low.",
            "comparison_with_other_formats": "Differs from prototypes/exemplars by privileging hidden causal structure and essences rather than surface similarity; paper's DELTA algorithm allows theory-like representations to override prototype outputs when coherence threshold indicates mismatch.",
            "limitations_or_counter_evidence": "Ambiguity about whether theory-like knowledge is default typical knowledge or part of classical background (dual interpretation); current DUAL-PECCS lacks an implemented module for common-sense default theory-like representations (integration is future work).",
            "theoretical_claims_or_implications": "Functionally, theory-like representations support non-monotonic, explanatory, and essence-based reasoning, providing categorical judgments that go beyond similarity and enabling defeasible inferences; graphical models (Bayesian networks) and probabilistic semantic networks are suggested as computational realizations.",
            "uuid": "e8710.2",
            "source_info": {
                "paper_title": "Heterogeneous Proxytypes Extended: Integrating Theory-like Representations and Mechanisms with Prototypes and Exemplars",
                "publication_date_yy_mm": "2019-09"
            }
        },
        {
            "name_short": "Classical theory",
            "name_full": "Classical theory (necessary and sufficient condition representations)",
            "brief_description": "Concepts are defined extensionally/intensionally by sets of necessary and sufficient features enabling monotonic, deductive categorization.",
            "citation_title": "",
            "mention_or_use": "use",
            "representational_format_name": "classical theory / classical representations",
            "representational_format_description": "Represents category membership via explicit rules or definitions (necessary and sufficient conditions), enabling standard deductive (monotonic) reasoning about membership.",
            "format_type": "symbolic / logical / ontological",
            "cognitive_task_or_phenomenon": "Deductive categorization, rule-based classification, formal ontology-style inferences (e.g., geometric definition of triangle)",
            "key_findings": "Classical representations capture cases where explicit definitional criteria determine membership; in DUAL-PECCS classical knowledge is encoded in an ontology (OpenCyc) and supports monotonic reasoning that is harmonized with typicality-based outputs via dual-process integration.",
            "comparison_with_other_formats": "Contrasts with prototype/exemplar/theory-based non-monotonic reasoning; used to check and integrate non-monotonic conclusions (dual-process theory) and provides exact logical membership where applicable.",
            "limitations_or_counter_evidence": "Poor fit for ordinary/common-sense categories that show graded membership and typicality effects; cannot account for non-monotonic defeasible inferences inherent in everyday concepts.",
            "theoretical_claims_or_implications": "Functionally, classical representations provide precise deductive mechanisms that complement typicality-based reasoning in a heterogeneous architecture; they underpin background ontological facts and are combined with non-monotonic processes via dual-process frameworks.",
            "uuid": "e8710.3",
            "source_info": {
                "paper_title": "Heterogeneous Proxytypes Extended: Integrating Theory-like Representations and Mechanisms with Prototypes and Exemplars",
                "publication_date_yy_mm": "2019-09"
            }
        },
        {
            "name_short": "Proxytype theory",
            "name_full": "Proxytype theory / heterogeneous proxytypes",
            "brief_description": "Concepts are tokenized temporary constructs ('proxytypes') drawn from long-term heterogeneous networks (prototypes, exemplars, theory-like, classical knowledge) and activated in working memory to 'stand in' for categories during cognitive tasks.",
            "citation_title": "",
            "mention_or_use": "use",
            "representational_format_name": "proxytype / heterogeneous proxytypes",
            "representational_format_description": "A functional account where each conceptual category is a heterogenous network in long-term memory (multiple representational bodies) and working memory tokens (proxytypes) selectively activate contextually relevant parts to perform recognition, categorization, retrieval.",
            "format_type": "hybrid / heterogeneous (multi-representational)",
            "cognitive_task_or_phenomenon": "Contextual activation, retrieval, categorization, tokenization in working memory, interplay of long-term and working memory",
            "key_findings": "Paper extends the proxytype idea to heterogeneous proxytypes (prototypes, exemplars, theory-like and classical components co-referring to same entity); implemented in DUAL-PECCS where different representation types are stored and selectively tokenized according to stimulus.",
            "comparison_with_other_formats": "Not a single format but an integrative stance asserting coexistence and context-sensitive selection among prototypes, exemplars, theories and classical representations; proposes a computational mechanism to harmonize these formats (DELTA) and leverages dual-process theory for integration with monotonic reasoning.",
            "limitations_or_counter_evidence": "Original proxytype theory depicted proxytypes as monolithic prototypes — heterogeneous extension requires explicit selection/tokenization mechanisms and empirical validation; design choices (how to select which sub-representation to tokenise) remain to be empirically calibrated.",
            "theoretical_claims_or_implications": "Functionally, concepts are heterogeneous bodies of knowledge with multiple representational formats stored in LTM and selectively tokenized as proxytypes in WM; this supports diverse categorization strategies and contextual activation of relevant knowledge.",
            "uuid": "e8710.4",
            "source_info": {
                "paper_title": "Heterogeneous Proxytypes Extended: Integrating Theory-like Representations and Mechanisms with Prototypes and Exemplars",
                "publication_date_yy_mm": "2019-09"
            }
        },
        {
            "name_short": "Conceptual spaces",
            "name_full": "Conceptual spaces (Gärdenfors)",
            "brief_description": "A geometric, metric vector-space framework used to represent typicality-based knowledge (prototypes as centroids, exemplars as points) where similarity is computed by distance metrics.",
            "citation_title": "Conceptual spaces: The geometry of thought",
            "mention_or_use": "use",
            "representational_format_name": "conceptual spaces (metric vector-space)",
            "representational_format_description": "Represents concepts in multi-dimensional continuous spaces where dimensions correspond to quality domains; prototypes are centroids/regions and exemplars are points; similarity and categorization are computed via distance metrics.",
            "format_type": "distributed / metric / continuous-space",
            "cognitive_task_or_phenomenon": "Similarity-based categorization, typicality gradients, region-based category representations",
            "key_findings": "DUAL-PECCS implements prototypes and exemplars in conceptual spaces (prototypes = region centroids, exemplars = points) and uses standard similarity metrics to determine distances between stimuli and category representations.",
            "comparison_with_other_formats": "Provides a lingua franca for integrating prototypes and exemplars (both metric) and contrasts with symbolic ontologies used for classical knowledge; suited to graded similarity but not directly expressive of causal or theory-like relations.",
            "limitations_or_counter_evidence": "Conceptual spaces do not naturally encode causal/explanatory structure or default theory-like knowledge; require additional mechanisms (e.g., graphical models) to represent theory-like relations.",
            "theoretical_claims_or_implications": "Functionally, conceptual spaces supply a principled metric for typicality and similarity-based categorization and serve as an integrative substrate for prototype/exemplar-based processes within heterogeneous architectures.",
            "uuid": "e8710.5",
            "source_info": {
                "paper_title": "Heterogeneous Proxytypes Extended: Integrating Theory-like Representations and Mechanisms with Prototypes and Exemplars",
                "publication_date_yy_mm": "2019-09"
            }
        },
        {
            "name_short": "Ontological formalisms / OpenCyc",
            "name_full": "Ontological formalisms (OpenCyc as example)",
            "brief_description": "Symbolic, logic-based representations of classical background knowledge (taxonomic and definitional relations) used for monotonic deductive inferences in the architecture.",
            "citation_title": "CYC: Using common sense knowledge to overcome brittleness and knowledge acquisition bottlenecks",
            "mention_or_use": "use",
            "representational_format_name": "ontological formalisms / symbolic ontologies",
            "representational_format_description": "Represents classical conceptual knowledge as symbolic logical assertions (taxonomic relations, necessary/sufficient conditions) enabling monotonic deductive reasoning and integration with other knowledge via mapping/anchoring.",
            "format_type": "symbolic / logical / ontology",
            "cognitive_task_or_phenomenon": "Deductive categorization, background knowledge retrieval, taxonomy-based inference",
            "key_findings": "DUAL-PECCS grounds its classical knowledge component in OpenCyc and uses ontological assertions to support monotonic categorization checks that are harmonized with non-monotonic typicality outputs via dual-process integration.",
            "comparison_with_other_formats": "Symbolic ontologies provide precise logical inferences unlike metric conceptual spaces; they are complementary in a heterogeneous architecture, used to validate or override typicality-based inferences where definitional criteria apply.",
            "limitations_or_counter_evidence": "Poor fit for representing graded typicality and defeasible common-sense rules; ontologies cannot capture many forms of non-monotonic, probabilistic, or causal common-sense knowledge without extensions.",
            "theoretical_claims_or_implications": "Functionally, ontologies serve as the monotonic logical backbone that can check and integrate outputs of typicality-based systems, enabling a mixed reasoning strategy in cognitive architectures.",
            "uuid": "e8710.6",
            "source_info": {
                "paper_title": "Heterogeneous Proxytypes Extended: Integrating Theory-like Representations and Mechanisms with Prototypes and Exemplars",
                "publication_date_yy_mm": "2019-09"
            }
        },
        {
            "name_short": "Bayesian networks / graphical models",
            "name_full": "Bayesian networks and graphical models for theory-like knowledge",
            "brief_description": "Probabilistic graphical models are proposed as computational realizations for representing causal and default theory-like common-sense knowledge, enabling probabilistic inference about hidden properties and causal relations.",
            "citation_title": "Theory unification and graphical models in human categorization",
            "mention_or_use": "mention",
            "representational_format_name": "graphical models / Bayesian networks (for theory-like representations)",
            "representational_format_description": "Represents theory-like bodies as probabilistic graphs (nodes for variables/properties, edges for causal/statistical dependencies) supporting probabilistic and defeasible inferences about hidden causes/essences.",
            "format_type": "probabilistic / graphical / hybrid",
            "cognitive_task_or_phenomenon": "Causal learning, categorization driven by hidden properties, probabilistic reasoning, theory-unification tasks",
            "key_findings": "Paper cites graphical models as promising for encoding common-sense default theories (causal networks) and as computational substrates for the theory-theory component; integration into DUAL-PECCS is planned but not yet implemented.",
            "comparison_with_other_formats": "Graphical models can capture causal/explanatory structure missing from metric or symbolic formats and can be combined with metric conceptual-space similarity metrics; they complement prototypes/exemplars and ontologies by supporting probabilistic causal inference.",
            "limitations_or_counter_evidence": "Not implemented in the current DUAL-PECCS instantiation; practical choices (which theory-like representation to select, heuristics for graph search) and parameterization remain open and require empirical validation.",
            "theoretical_claims_or_implications": "Functionally, graphical models provide a principled way to represent and compute with theory-like, causal, and default knowledge, allowing these structures to drive categorization and override similarity-based judgments when appropriate.",
            "uuid": "e8710.7",
            "source_info": {
                "paper_title": "Heterogeneous Proxytypes Extended: Integrating Theory-like Representations and Mechanisms with Prototypes and Exemplars",
                "publication_date_yy_mm": "2019-09"
            }
        },
        {
            "name_short": "DELTA algorithm",
            "name_full": "DELTA (unifieD CatEgorization aLgorithm for heTerogeneous representAtions)",
            "brief_description": "A novel unified categorization algorithm proposed in this paper that selects among exemplars, prototypes, and theory-like representations to assign category labels to stimuli based on similarity thresholds and conceptual coherence.",
            "citation_title": "here",
            "mention_or_use": "use",
            "representational_format_name": "unifying categorization procedure (DELTA)",
            "representational_format_description": "Functionally selects the most appropriate typicality-based representation: retrieves exemplar if within exemplar-similarity threshold, otherwise selects nearest prototype; further compares prototype's associated theory-like representation to stimulus via a Conceptual Coherence Threshold to decide if theory-like override is needed.",
            "format_type": "algorithmic / hybrid selection procedure",
            "cognitive_task_or_phenomenon": "Categorization under typicality and essentialist tensions, exemplar vs prototype use, theory-driven overrides (e.g., transformation judgments)",
            "key_findings": "Proposes an exemplar-first preference (matching human data) with prototype fallback and a mechanism for theory-like representations to override prototypes when conceptual coherence is low; DELTA is a theoretical proposal implemented conceptually in the paper but requires empirical testing.",
            "comparison_with_other_formats": "Integrates exemplar, prototype, and theory-theory mechanisms into a single selection algorithm and formalizes their interactions (preference ordering and coherence-based overrides).",
            "limitations_or_counter_evidence": "DELTA's components (e.g., exemplar similarity thresholds, Conceptual Coherence Threshold, selection of appropriate theory-like representation) are underspecified and require empirical calibration; actual integration of probabilistic theory-like modules into DUAL-PECCS remains future work.",
            "theoretical_claims_or_implications": "Functionally, DELTA operationalizes the heterogeneous proxytypes hypothesis by providing a decision procedure for which representation to tokenise during categorization, thereby reconciling competing theories of typicality in a cognitively plausible way.",
            "uuid": "e8710.8",
            "source_info": {
                "paper_title": "Heterogeneous Proxytypes Extended: Integrating Theory-like Representations and Mechanisms with Prototypes and Exemplars",
                "publication_date_yy_mm": "2019-09"
            }
        },
        {
            "name_short": "DUAL-PECCS",
            "name_full": "DUAL-PECCS (A common-sense conceptual categorization system integrating heterogeneous proxytypes and the dual process of reasoning)",
            "brief_description": "A cognitive categorization system that implements heterogeneous proxytypes: combines prototype and exemplar conceptual-space representations with a classical ontological component and dual-process-inspired harmonization of reasoning.",
            "citation_title": "Dual PECCS: A Cognitive System for Conceptual Representation and Categorization.",
            "mention_or_use": "use",
            "representational_format_name": "DUAL-PECCS system (hybrid heterogeneous architecture)",
            "representational_format_description": "Implements multiple co-referring bodies of knowledge for concepts: prototypes and exemplars in conceptual spaces (non-monotonic similarity-based reasoning) and classical knowledge in ontologies (monotonic deductive reasoning), with tokenization/proxyfication mechanisms to activate the appropriate representation.",
            "format_type": "hybrid / heterogeneous / system-level architecture",
            "cognitive_task_or_phenomenon": "Categorization, concept activation/tokenization, harmonization of monotonic and non-monotonic reasoning, contextual retrieval",
            "key_findings": "DUAL-PECCS successfully demonstrates a working integration of prototype, exemplar and classical knowledge for categorization tasks and supports context-sensitive selection of representations; however, it currently lacks integrated common-sense default theory-like modules (planned future work).",
            "comparison_with_other_formats": "Operationalizes the heterogeneous hypothesis by co-locating different representational formats and contrasting their behavior in categorization; uses dual-process theory to combine non-monotonic typicality outputs with monotonic ontology checks.",
            "limitations_or_counter_evidence": "Does not yet implement theory-like default representations (causal/essence networks) within the typical component; some integration choices (e.g., anchoring via WordNet) may affect generality; empirical validations are reported elsewhere but more psychological testing of extended heterogeneity is needed.",
            "theoretical_claims_or_implications": "Functionally shows that a hybrid architecture combining metric conceptual spaces and symbolic ontologies with selective tokenization can capture diverse categorization behaviors and is a viable computational realization of heterogeneous proxytypes.",
            "uuid": "e8710.9",
            "source_info": {
                "paper_title": "Heterogeneous Proxytypes Extended: Integrating Theory-like Representations and Mechanisms with Prototypes and Exemplars",
                "publication_date_yy_mm": "2019-09"
            }
        },
        {
            "name_short": "Conceptual coherence (constraint satisfaction)",
            "name_full": "Conceptual coherence measured as constraint satisfaction",
            "brief_description": "Assessment of how well a stimulus coheres with a theory-like representation is framed as a constraint satisfaction problem; coherence determines whether theory-like knowledge should override prototype-based categorization.",
            "citation_title": "Coherence as constraint satisfaction",
            "mention_or_use": "mention",
            "representational_format_name": "conceptual coherence via constraint satisfaction",
            "representational_format_description": "Functional mechanism: compare stimulus-representation features against a theory-like network and evaluate overall coherence through constraint satisfaction computations (weighted constraints across properties/relations); used to decide overrides.",
            "format_type": "computational / constraint-satisfaction / hybrid",
            "cognitive_task_or_phenomenon": "Deciding when theory-like knowledge should drive categorization (e.g., overriding prototype decisions), coherence-based judgments",
            "key_findings": "Paper suggests using constraint-satisfaction algorithms (Thagard-style) to compute Conceptual Coherence Thresholds that determine whether a prototype match is conceptually coherent with the relevant theory-like network; practical instantiation is suggested but not implemented.",
            "comparison_with_other_formats": "Acts as a mediator between similarity-based formats (prototype/exemplar) and theory-based formats by providing a decision criterion; complements probabilistic graphical approaches by offering a symbolic/constraint criterion for coherence.",
            "limitations_or_counter_evidence": "Specification of thresholds and constraint weights is underspecified and requires empirical grounding; whether constraint-satisfaction captures the probabilistic nuances of theory-like reasoning is an open question.",
            "theoretical_claims_or_implications": "Functionally, coherence-as-constraint-satisfaction offers a principled decision rule to determine when to accept prototype-based categorization versus invoking theory-like overrides, enabling structured interaction among heterogeneous representations.",
            "uuid": "e8710.10",
            "source_info": {
                "paper_title": "Heterogeneous Proxytypes Extended: Integrating Theory-like Representations and Mechanisms with Prototypes and Exemplars",
                "publication_date_yy_mm": "2019-09"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Conceptual spaces: The geometry of thought",
            "rating": 2,
            "sanitized_title": "conceptual_spaces_the_geometry_of_thought"
        },
        {
            "paper_title": "Cognitive representations of semantic categories",
            "rating": 2,
            "sanitized_title": "cognitive_representations_of_semantic_categories"
        },
        {
            "paper_title": "Concepts, kinds, and cognitive development",
            "rating": 2,
            "sanitized_title": "concepts_kinds_and_cognitive_development"
        },
        {
            "paper_title": "The role of theories in conceptual coherence",
            "rating": 2,
            "sanitized_title": "the_role_of_theories_in_conceptual_coherence"
        },
        {
            "paper_title": "Perceptual symbol systems",
            "rating": 2,
            "sanitized_title": "perceptual_symbol_systems"
        },
        {
            "paper_title": "Theory unification and graphical models in human categorization",
            "rating": 2,
            "sanitized_title": "theory_unification_and_graphical_models_in_human_categorization"
        },
        {
            "paper_title": "Dual PECCS: A Cognitive System for Conceptual Representation and Categorization.",
            "rating": 2,
            "sanitized_title": "dual_peccs_a_cognitive_system_for_conceptual_representation_and_categorization"
        },
        {
            "paper_title": "An on-line investigation of prototype and exemplar strategies in classification",
            "rating": 1,
            "sanitized_title": "an_online_investigation_of_prototype_and_exemplar_strategies_in_classification"
        },
        {
            "paper_title": "Coherence as constraint satisfaction",
            "rating": 1,
            "sanitized_title": "coherence_as_constraint_satisfaction"
        },
        {
            "paper_title": "CYC: Using common sense knowledge to overcome brittleness and knowledge acquisition bottlenecks",
            "rating": 1,
            "sanitized_title": "cyc_using_common_sense_knowledge_to_overcome_brittleness_and_knowledge_acquisition_bottlenecks"
        }
    ],
    "cost": 0.0159845,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Heterogeneous Proxytypes Extended: Integrating Theory-like Representations and Mechanisms with Prototypes and Exemplars</p>
<p>Antonio Lieto lieto@di.unito.it 
Dept. of Computer Science
University of Turin
Italy</p>
<p>Cognitive Robotics and Social Sensing Lab
ICAR-CNR (Palermo)
Italy</p>
<p>Heterogeneous Proxytypes Extended: Integrating Theory-like Representations and Mechanisms with Prototypes and Exemplars
Pre-print. Final Version: in Springer Advances in Intelligent Systems and Computing, BICA Video: https://vimeo.com/297052905heterogeneous proxytypesknowledge representationcognitive agentscognitive architecturesdeclarative memory
The paper introduces an extension of the proposal according to which conceptual representations in cognitive agents should be intended as heterogeneous proxytypes. The main contribution of this paper is in that it details how to reconcile, under a heterogeneous representational perspective, different theories of typicality about conceptual representation and reasoning. In particular, it provides a novel theoretical hypothesis -as well as a novel categorization algorithm called DELTA -showing how to integrate the representational and reasoning assumptions of the theory-theory of concepts with the those ascribed to the prototype and exemplars-based theories.</p>
<p>Introduction</p>
<p>The proposal of characterizing the representational system of cognitive artificial agents by considering conceptual representations as heterogeneous proxytypes was introduced in [17] 1 and has been recently employed and successfully tested in systems like DUAL-PECCS [21,20,22], later integrated with diverse cognitive architectures such as ACT-R [1], CLARION [32], SOAR [15] and Vector-LIDA [31]. The main contribution of this work is in that it offers a proposal to reconcile, under a heterogeneous representational perspective, not only prototype and exemplars based representations and reasoning procedures, but also the representational and reasoning assumptions ascribed to the so called theory-theory of concepts [27]. In doing so, the paper proposes a novel categorization algorithm, called DELTA (i.e. unifieD CatEgorization aLgorithm for heTerogeneous representAtions) able to unify and integrate, in a cognitively oriented perspective, all the common-sense categorization mechanisms available in the cognitive science literature. The rest of the paper is organized as follows: the Section 2 provides an overview of the main representational paradigms proposed by the Cognitive Science and the Cognitive Modelling communities. Section 3, briefly synthesize the representational framework intending concepts as heterogeneous proxytypes by showing how such theoretical proposal has been actually implemented and successfully tested in the DUAL-PECCS system. Section 4, proposes a more close analysis of the findings of the theory-theory of concepts, while, Section 5, proposes a novel and extended categorization algorithm integrating the theory-theory representational and reasoning mechanisms with those involving both exemplars and prototypes.</p>
<p>Prototypes, Exemplars, Theories and Proxytypes</p>
<p>In the Cognitive Science literature, different theories about the nature of concepts have been proposed. According to the so called classical theory, concepts can be simply defined in terms of sets of necessary and sufficient conditions. Such theory was dominant until the mid '70s of the last Century, when Rosch's experimental results demonstrated the inadequacy of such a theory for ordinary -or common-sense -concepts [29]. Rosch's results suggested, on the other hand, that ordinary concepts are characterized and organized in our mind in terms of prototypes. Since then, different theories of concepts have been proposed to explain different representational and reasoning aspects concerning the problem of typicality: the prototype theory, the exemplars theory and the theory-theory. According to the prototype view, knowledge about categories is stored in terms of prototypes, i.e., in terms of some representation of the "best" instance of the category. In this view, the concept bird should coincide with a representation of a typical bird (e.g., a robin). In the simpler versions of this approach, prototypes are represented as (possibly weighted) lists of typical features. According to the exemplar view, a given category is mentally represented as set of specific exemplars explicitly stored in memory: the mental representation of the concept bird is a set containing the representation of (some of) the birds we encountered during our past experience. Another well known typicality-based theory of concepts is the so called the theory-theory [27]. Such approach adopts some form of holistic point of view about concepts. According to some versions of the theory-theories, concepts are analogous to theoretical terms in a scientific theory. For example, the concept cat is individuated by the role it plays in our mental theory of zoology. In other versions of the approach, concepts themselves are identified with micro-theories of some sort. For example, the concept cat should be identified with a mentally represented microtheory about cats.</p>
<p>Although these approaches have been largely considered as competing ones (since they propose different models and predictions about how we organize and reason on conceptual information), they turned out to be not mutually exclusive [24]. Rather, they seem to succeed in explaining different classes of cognitive phenomena, such as the fact that human subjects use different representations to categorize concepts. In particular, it seems that we can use -in different situations -exemplars, prototypes or theories [30,27,14]. Such experimental evidences led to the development of the so called "heterogeneous hypothesis" about the nature of concepts: this approach assumes that concepts do not constitute a unitary phenomenon, and hypothesizes that different types of conceptual representations may co-exist: prototypes, exemplars, theory-like or classical representations [23]. All such representations, in this view, constitute different bodies of knowledge and contain different types of information associated to the the same conceptual entity. Furthermore, each body of conceptual knowledge is assumed to be featured by specific processes in which such representations are involved (e.g., in cognitive tasks like recognition, learning, categorization, etc.). In particular prototypes, exemplars and theory-like default representations are associated with the possibility of dealing with non-monotonic strategies of reasoning and categorization, while the classical representations (i.e. that ones based on necessary and/or sufficient conditions) are associated with standard deductive mechanism of reasoning 2 .</p>
<p>In recent years an alternative theory of concepts has been proposed: the proxytype theory. It postulates a biological localization and interaction between different brain areas for dealing with conceptual structures. Such localization have a direct counterpart in the well known distinction between long term and working memory [28]. In addition, such characterization is particularly interesting for the explanation of phenomena such as, for example, the activation (and the retrieval) of conceptual information. In this setting, concepts are seen as proxytypes. A proxytype is any element of a complex representational network stored in long-term memory corresponding to a particular category that can be tokenized in working memory to 'go proxy' for that category [28]. In other terms, the proxytype theory, inspired by the work of Barsalou [3], considers concepts as temporary constructs of a given category, activated (tokenized) in working memory as a result of conceptual processing activities, such as concept identification, recognition and retrieval. 2 In order to explain the different categorization strategies associated to different kinds of representations, let us consider the following examples: if we have to categorize a stimulus with the following features: "it has fur, woofs and wags its tail", the result of a prototype-based categorization would be dog, since these cues are associated to the prototype of dog. Prototype-based reasoning, however, is not the only type of reasoning based on typicality. In fact, if an exemplar corresponding to the stimulus being categorized is available, too, it is acknowledged that humans use to classify it by evaluating its similarity w.r.t. the exemplar, rather than w.r.t. the prototype associated to the underlying concepts [10]. For example, a penguin is rather dissimilar from the prototype of bird. However, if we already know an exemplar of penguin, and if we know that it is an instance of bird, it is easier to classify a new penguin as a bird w.r.t. a categorization process based on the similarity with the prototype of that category. This type of common-sense categorization is known in literature as exemplars-based categorization. An example of theory-like common sense reasoning is when we typically associate to a light switch the learned rule that if we turn it "on" then the light will be provided (this is a non-monotonic inference with a defeasible conclusion). Finally, the classical representations (i.e. those based on necessary and/or sufficient conditions) are associated with standard deductive mechanism of reasoning. An example of standard deductive reasoning is the categorization as triangle of a stimulus described by the features: "it is a polygon, it has three corners and three sides". Such cues, in fact, are necessary and sufficient for the definition of the concept of triangle. All these representations, and the corresponding reasoning mechanisms, are assumed to be potentially co-existing according to the heterogeneity approach.</p>
<p>Heterogeneous Proxytypes</p>
<p>In the original formulation of the proxytypes theory, however, proxytypes have been depicted as monolithic conceptual structures, primarily intended as prototypes [8]. A revised view of this approach has been recently proposed, hypothesizing the availability of a wider range of representation types than just prototypes [17]. They correspond to the kinds of representations hypothesized by the above mentioned heterogeneous approach to concepts. In this sense, proxytypes are assumed to be heterogeneous in nature (i.e., they are assumed to be composed by heterogeneous networks of conceptual representations and not only by a monolithic one) 3 .</p>
<p>In this renewed formulation, heterogeneous representations (such as prototypes, exemplars, theory-like structures, etc.) for each conceptual category are assumed to be stored in long-term memory. They can be activated and accessed by resorting to different categorization strategies. In this view, each representation has its associated accessing procedures. In the following, I will briefly present how such theoretical hypothesis has been implemented in the DUAL-PECCS categorization system, and I will use the latter system as a computational referent for showing how the proposals presented in this paper can extend both the system itself and, more importantly, its underlying theoretical framework.</p>
<p>Heterogeneous Proxytypes in DUAL-PECCS</p>
<p>DUAL-PECCS [20,21], is a cognitive categorization system explicitly designed and implemented under the heterogeneous proxytypes assumption 4 for both the representational level (that is: it is equipped with a hybrid knowledge base composed of heterogeneous representations, each endowed with specific reasoning mechanisms) and for the 'proxyfication' mechanisms (i.e.: the set of procedures implementing the tokenization of the different representations in working memory). The heterogeneous conceptual architecture of DUAL PECCS includes prototypes, exemplars and classical representations. All these different bodies of knowledge point to the same conceptual entity (the anchoring for these different types of representations is obtained via the Wordnet, see again [21]). An example of the heterogeneous conceptual architecture of DUAL PECCS is provided in the Figure 1. Such figure shows how it is represented the concept dog. In this case, the prototypical representation grasps information such as that dogs are usually conceptualized as domestic animals, with typically four legs, a tail etc.; the exemplar-based representations grasp information on individuals. For example, in Fig. 1 -Hybrid Knowledge Base - it is represented the individual of Lessie, which is a particular exemplar of dog with white and brown fur and with a less domestic attitude w.r.t. the prototypical dog (e.g. its typical location is lawn). Within the system, both the exemplar and prototype-based representations make use of non classical (or typical) information and are represented by using the framework of the conceptual spaces [12,18]: a particular type of vector space model adopting standard similarity metrics to determine the distance between instances and concepts within the space. The representation of classical information (e.g. the fact that Dog Animal, that is to say that "Dogs are also Animals") is, on the other hand, demanded to standard ontological formalisms. In the current version of the system the classical knowledge component is grounded in the OpenCyc ontology [16].</p>
<p>By assuming the heterogeneous hypothesis, in DUAL-PECCS, different kinds of reasoning strategies are associated to these different bodies of knowledge. In particular, the system combines non-monotonic common-sense reasoning (associated to the prototypical and exemplars-based, conceptual spaces, representations) and standard monotonic categorization procedures (associated to the classical, ontological, body of knowledge). These different types of reasoning are harmonized according to the theoretical tenets coming from the dual process theories of reasoning and rationality [9,13].</p>
<p>As emerges from the figure 1, a missing part of the current conceptual architecture in the DUAL-PECCS system (and in its underlying theoretical hypothesis) concerns the representation of the default knowledge in terms of theory-like representational structures (while it already integrates classical, prototypical and exemplars based knowledge reprentation and processing mechanisms). In the next section we will show how Theory-like representations can be considered dual in nature (at least from a formal point of view) and therefore may deserve a dual treatment also form a computational point of view.</p>
<p>The Duality of Theory-Like Representations</p>
<p>As mentioned in Section 2, Theory-theory approaches [26,27] assume that concepts consists of more or less complex mental structures representing (among other things) causal and explanatory relations between them (including folk psychology connections). During the 80's, these approaches stemmed from a critique to the formerly dominant theory of concepts as prototypes. Consider, for example, the famous [14] transformation experiments, in which subjects were asked to make categorization judgments about the biological membership of an animal that had undergone unusual transformations. In such experiment, Keil showed that people relies on theory-like representation (instead of prototypes) in order to execute their categorization task. In particular, it was shown that the type of knowledge retrieved by the subjects to solve these tasks belongs to their "default common-sense theory" associated to a given concept.</p>
<p>The idea that for most of our categories, our default knowledge includes a commonsense theory of that category (and that theory-like default bodies of knowledge are associated with a distinct kind of categorization process) is, however, only one of the available interpretations about the theory-like representational structures [23]. Another kind of interpretation, in fact, assumes that theory-like structures do not constitute our typical default knowledge but that, on the other hand, they are constitutive of our classical background knowledge [4]. In order to better explain this difference, and thus the duality of the theory-like representations, let us consider the case of DUAL-PECCS. As mentioned above, the current version of the system does not allow to represent the type of theory-like default knowledge belonging to the typical conceptual component of the architecture (see footnote 1 for an example of the non-monotonic reasoning that could be enabled by this kind of knowledge). On the other hand, it allows to represent (in terms of IF-THEN rules enabling monotonic inferences), the kind of theory-like knowledge structures which are compliant with the ontological semantics of the classical conceptual component. In other words: only certain types of theories, i.e. causal theories, belonging to the background knowledge of a cognitive agents, are currently covered by the integration of the current state of the art ontology languages and rules [11] in the DUAL-PECCS system. However, as already pointed out before, common sense knowledge is mostly characterized in terms of "theories" which are based on arbitrary, i.e. experience-based, rules. Therefore, in order to represent, within an artificial system, more realistic (from a cognitive standpoint) "theories", i.e. including common-sense default theories as intended in the theory-theory approaches, there is the need of going beyond classical logic rules. Recently, graphical models (in particular Bayesian networks) have been proposed as a computational framework able to represent [7,6] knowledge networks of theory-like common-sense default representation. The integration of such framework within the DUAL-PECCS system represent a current and future area of development, not yet concluded. In the remaining of this paper, such integration will not be discussed and, in a certain sense, will be taken for granted. I shall focus, instead, on the presentation of a novel unifying categorization algorithm -named DELTA -able to harmonize all the different types of typicality-based representations and reasoning mechanisms associated with the common-sense knowledge: exemplars, prototypes and default theory-like representations. I will leave aside the discussion concerning the integration of such common-sense categorization mechanisms with those concerning the classical monotonic ones. As above mentioned, in fact, such integration is already provided in DUAL-PECCS [21,20] and is tackled by recurring to the dual process theory of reasoning (i.e.: the non monotonic reasoning results of the heterogeneous common-sense conceptual components are then checked and integrated with the monotonic reasoning strategies executed in the classical conceptual component). Therefore, the underlying heterogeneous-proxytypes assumption, integrated with the dual process theory of reasoning, has been already proven to be effective to harmonize non monotonic and monotonic categorization strategies associated to heterogeneous body of knowledge. I will not report here the details of such harmonization procedure because it already documented elsewhere [21]. I will focus, instead, on the harmonization procedures concerning the non monotonic categorization processes of the typical conceptual components.</p>
<p>A Unified Categorization Algorithm for Exemplars, Prototypes and Theory-Like Representations</p>
<p>In the following, I propose a novel categorization algorithm that, given a certain stimulus d, must select the most appropriate typicality-based representation available in the declarative memory of a cognitive agent (i.e. a prototype, an exemplar or a theorylike structure). According to what introduced in the previous sections, such declarative memory is assumed to rely on the heterogeneous proxytypes hypothesis. The implemented procedure works as follows: when the input stimulus is similar enough to an exemplar representation (a threshold has been fixed to these ends), the corresponding exemplar of a given category is retrieved. Otherwise, the prototypical representations are also scanned and the representation (prototype or exemplar) that is closest to the input is returned. By following a preference that has been experimentally observed in human cognition [25], this algorithm favors the results of the exemplarsbased categorization if the knowledge-base stores any exemplars similar to the input being categorized. As an additional constraint, I have hypothesized a mechanism in which theory-like structures of default knowledge can also override the categorization based on prototypes. Such mechanism has been devised based on the fact that theorytheorists have shown that, in some categorical judgments tasks (e.g. assessing the situation where a dog is made to look like a raccoon), categorization is driven by the possession of a rudimentary biological theory and by theory-like representations [2]. In other words: being a dog isn't just a matter of looking like a dog. It seems, in fact, that it is more important to have a network of appropriate hidden properties of dogs: the dog "essence" [2]. In the proposed algorithm, I have taken into account this element by hypothesizing: i) to measure the similarity between the theory-like representation of the first retrieved prototype with the stimulus d 5 and ii) to compare the obtained result with a Conceptual Coherence Threshold that should measure how much the considered stimulus d shares, i.e. is conceptually coherent, with the corresponding theory-like rep-resentation of the retrieved prototype. The analysis of the conceptual coherence can be solved as a constraint satisfaction problem as shown in [33].</p>
<p>In this setting, if the distance between the stimulus d and theory-like representation of the originally retrieved prototype is above the considered threshold, it means that the retrieved prototype is assumed to be representative enough of the common-sense "essence' of d (i.e it is "coherent enough'). In this case, the prototypical answer is maintained, otherwise it is overridden by the theory-like representation which is closer to d.</p>
<p>Let us assume, for example, that the stimulus to categorize is represented by an atypical Golden Zebra (which is almost totally white) and that in our agent's long-term memory there is no exemplar similar enough to this entity. This means that there will be no exemplar-based representation selected by our algorithm, and that the most similar representation to d will be searched among the prototypical representations in the agent knowledge base. Now: if we assume that the retrieved prototype is a typical white horse, we could discard such representation by simply relying on some additional information coming from the comparison of the stimulus d (e.g. the fact that lives in the Savannah, etc.) with the default and common-sense theory associated to a horse (i.e. the category associated to the original prototypical choice). In this case the categorical assignment to the class Golden Zebra would be obtained by exploiting theory-like representational networks. A synthetic representation of the proposed procedure is presented in the Algorithm 1.</p>
<p>Conclusions and Future Work</p>
<p>In this paper I have proposed a categorization algorithm able to unify all the commonsense categorization strategies proposed in the cognitive science literature: exemplars, prototypes and theory-like common-sense knowledge structures. To the best of my knowledge, this proposal represents the first attempt of providing a unifying categorization strategy by assuming a heterogeneous representational hypothesis. In particular, the proposed algorithm relies and extends both the representational and the reasoning framework considering concepts as heterogeneous proxytypes [17]. The current theoretical proposal needs to be tested on the empirical ground in order to show both its feasibility with psychological data and its efficacy in the area of artificial cognitive systems. Also, there are additional elements, only sketched in this paper, requiring a more precise characterization. For example: the design of a method to calculate which is the most appropriate theory-like representations to select (line 12, Algorithm 1). On this point, however, it is worth-noticing that, since the most promising computational candidates for representing the theory-like body of knowledge are graphical models and probabilistic semantic networks, it seems plausible to imagine that such calculation could be performed with standard heuristics search on graph structures. Similarly, the individuation and the construction of a plausible Conceptual Coherence Threshold represents an issue that should be faced and solved empirically.</p>
<p>Fig. 1: Heterogeneous representational architecture for the concept DOG in DUAL-PECCS.Typicality-based 
knowledge </p>
<p>Classical 
knowledge </p>
<p>family: mammal 
color: brown 
hasPart: tail 
hasPart: four legs 
atLocation: home 
… </p>
<p>Prototypical dog </p>
<p>Prototype 
(region centroid in CS) </p>
<p>family: mammal 
color: white &amp; brown 
hasPart: tail 
hasPart: four legs 
atLocation: lawn 
… </p>
<p>Lessie </p>
<p>family: mammal 
color: brown &amp; black 
hasPart: tail 
hasPart: four legs 
atLocation: home 
… </p>
<p>Scooby-Doo </p>
<p>… </p>
<p>Exemplars 
(region points in CS) </p>
<p>kingdom: animalia 
phylum: chordata 
class: mammalia 
order: carnivora 
genus: canis 
… </p>
<p>dog </p>
<p>Ontological 
information </p>
<p>Concept dog </p>
<p>The expression heterogeneous proxytypes refers to both a theoretical and computational hypothesis combining the proxytype theory of concepts with the so called heterogeneity approach to concept representation. The Section 3 of this paper contains a brief discussion of the proposal.arXiv:1909.01645v1 [cs.AI] 4 Sep 2019
The heterogeneity assumption has been recently pointed out as one of the problems to face in order to address the problems affecting the knowledge level in cognitive systems and architecture[19,5].4 The characterization in terms of "heterogeneous proxytypes", among the other things, enables the system to deal with the problem of the "contextual activation" of a given information based on the external stimulus being considered. In particular (by following the idea that, when we categorize a stimulus, we do not activate the whole network of knowledge related to its assigned category but, conversely, we only activate the knowledge that is "contextually relevant" in its respect), DUAL-PECCS proxyfyes only the type of representation that minimizes the distance w.r.t. the percept (see[17] for further details).
Since all the different bodies of knowledge are assumed to be co-referring representational structure pointing to the same conceptual entity, it is possible to recover the theory-like representation associated, for example, to a given prototypical or exemplar based representation.
AcknowledgementsThe topics presented in this paper have been discussed in these years with a number people in international conferences, symposia, panels and workshops. I thank all them for the received comments. In particular, I am indebted to Marcello Frixione, Leonardo Lesmo, Paul Thagard, David Danks, Ismo Koponen and Christian Lebiere for their feedback and suggestions. I also thank Valentina Rho for her comments on an earlier version of this paper.
An integrated theory of the mind. J R Anderson, D Bothell, M D Byrne, S Douglass, C Lebiere, Y Qin, Psychological review. 11141036Anderson, J.R., Bothell, D., Byrne, M.D., Douglass, S., Lebiere, C., Qin, Y.: An integrated theory of the mind. Psychological review 111(4), 1036 (2004)</p>
<p>The native mind and the cultural construction of nature. S Atran, D L Medin, Mit Press CambridgeMAAtran, S., Medin, D.L.: The native mind and the cultural construction of nature. Mit Press Cambridge, MA (2008)</p>
<p>Perceptual symbol systems. L W Barsalou, Behavioral and Brain Sciences. 2204Barsalou, L.W.: Perceptual symbol systems. Behavioral and Brain Sciences 22(04), 577-660 (1999)</p>
<p>Default knowledge, time pressure, and the theory-theory of concepts. T Blanchard, Behavioral and Brain Sciences. 332-3Blanchard, T.: Default knowledge, time pressure, and the theory-theory of concepts. Behav- ioral and Brain Sciences 33(2-3), 206-207 (2010)</p>
<p>Representational issues in the debate on the standard model of the mind. A Chella, M Frixione, A Lieto, AAAI Fall Symposium Series Proceedings, FSS-17-05. AAAI PressChella, A., Frixione, M., Lieto, A.: Representational issues in the debate on the standard model of the mind. In: AAAI Fall Symposium Series Proceedings, FSS-17-05. pp. 302-307. AAAI Press (2017), https://www.aaai.org/ocs/index.php/FSS/FSS17/paper/view/15990</p>
<p>Psychological theories of categorizations as probabilistic models. D Danks, Danks, D.: Psychological theories of categorizations as probabilistic models (2004)</p>
<p>Theory unification and graphical models in human categorization. Causal learning: Psychology, philosophy, and computation pp. D Danks, Danks, D.: Theory unification and graphical models in human categorization. Causal learn- ing: Psychology, philosophy, and computation pp. 173-189 (2007)</p>
<p>Prinz's problematic proxytypes. R De Rosa, The Philosophical Quarterly. 55221De Rosa, R.: Prinz's problematic proxytypes. The Philosophical Quarterly 55(221), 594-606 (2005)</p>
<p>In two minds: Dual processes and beyond. J S B Evans, K E Frankish, Oxford University PressEvans, J.S.B., Frankish, K.E.: In two minds: Dual processes and beyond. Oxford University Press (2009)</p>
<p>Representing non classical concepts in formal ontologies: Prototypes and exemplars. M Frixione, A Lieto, New Challenges in Distributed Information Filtering and Retrieval. SpringerFrixione, M., Lieto, A.: Representing non classical concepts in formal ontologies: Prototypes and exemplars. In: New Challenges in Distributed Information Filtering and Retrieval, pp. 171-182. Springer (2013)</p>
<p>Towards an Extended Model of Conceptual Representations in Formal Ontologies: A Typicality-Based Proposal. M Frixione, A Lieto, Journal of Universal Computer Science. 203Frixione, M., Lieto, A.: Towards an Extended Model of Conceptual Representations in For- mal Ontologies: A Typicality-Based Proposal. Journal of Universal Computer Science 20(3), 257-276 (March 2014)</p>
<p>Conceptual spaces: The geometry of thought. P Gärdenfors, MIT pressGärdenfors, P.: Conceptual spaces: The geometry of thought. MIT press (2004)</p>
<p>Thinking, fast and slow. D Kahneman, MacmillanKahneman, D.: Thinking, fast and slow. Macmillan (2011)</p>
<p>F Keil, Concepts, kinds, and cognitive developmentmit press. Cambridge, MAKeil, F.: Concepts, kinds, and cognitive developmentmit press. Cambridge, MA (1989)</p>
<p>The Soar cognitive architecture. J Laird, MIT PressLaird, J.: The Soar cognitive architecture. MIT Press (2012)</p>
<p>CYC: Using common sense knowledge to overcome brittleness and knowledge acquisition bottlenecks. D B Lenat, M Prakash, M Shepherd, AI magazine. 6465Lenat, D.B., Prakash, M., Shepherd, M.: CYC: Using common sense knowledge to overcome brittleness and knowledge acquisition bottlenecks. AI magazine 6(4), 65 (1985)</p>
<p>A computational framework for concept representation in cognitive systems and architectures: Concepts as heterogeneous proxytypes. A Lieto, Procedia Computer Science. 41Lieto, A.: A computational framework for concept representation in cognitive systems and architectures: Concepts as heterogeneous proxytypes. Procedia Computer Science 41, 6-14 (2014)</p>
<p>Conceptual spaces for cognitive architectures: A lingua franca for different levels of representation. A Lieto, A Chella, M Frixione, Biologically Inspired Cognitive Architectures (BICA). 19Lieto, A., Chella, A., Frixione, M.: Conceptual spaces for cognitive architectures: A lingua franca for different levels of representation. Biologically Inspired Cognitive Architectures (BICA) 19, 1-9 (2017)</p>
<p>The knowledge level in cognitive architectures: Current limitations and possible developments. A Lieto, C Lebiere, A Oltramari, Cognitive Systems Research. 48Lieto, A., Lebiere, C., Oltramari, A.: The knowledge level in cognitive architectures: Current limitations and possible developments. Cognitive Systems Research 48, 39-55 (2018)</p>
<p>A common-sense conceptual categorization system integrating heterogeneous proxytypes and the dual process of reasoning. A Lieto, D P Radicioni, V Rho, Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI). the International Joint Conference on Artificial Intelligence (IJCAI)AAAI PressLieto, A., Radicioni, D.P., Rho, V.: A common-sense conceptual categorization system inte- grating heterogeneous proxytypes and the dual process of reasoning. In: Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI). pp. 875-881. AAAI Press (2015)</p>
<p>Dual PECCS: A Cognitive System for Conceptual Representation and Categorization. A Lieto, D P Radicioni, V Rho, 10.1080/0952813X.2016.1198934Journal of Experimental &amp; Theoretical Artificial Intelligence. 292Lieto, A., Radicioni, D.P., Rho, V.: Dual PECCS: A Cognitive System for Conceptual Rep- resentation and Categorization. Journal of Experimental &amp; Theoretical Artificial Intelligence 29(2), 433-452 (2017), http://dx.doi.org/10.1080/0952813X.2016.1198934</p>
<p>Towards a Unifying Framework for Conceptual Represention and Reasoning in Cognitive Systems. A Lieto, D P Radicioni, V Rho, E Mensa, Intelligenza Artificiale. 112Lieto, A., Radicioni, D.P., Rho, V., Mensa, E.: Towards a Unifying Framework for Con- ceptual Represention and Reasoning in Cognitive Systems. Intelligenza Artificiale 11(2), 139-153 (2017)</p>
<p>Doing without concepts. E Machery, OUPMachery, E.: Doing without concepts. OUP (2009)</p>
<p>An on-line investigation of prototype and exemplar strategies in classification. B C Malt, Journal of Experimental Psychology: Learning, Memory, and Cognition. 154539Malt, B.C.: An on-line investigation of prototype and exemplar strategies in classification. Journal of Experimental Psychology: Learning, Memory, and Cognition 15(4), 539 (1989)</p>
<p>Context theory of classification learning. D L Medin, M M Schaffer, Psychological review. 853207Medin, D.L., Schaffer, M.M.: Context theory of classification learning. Psychological review 85(3), 207 (1978)</p>
<p>The role of theories in conceptual coherence. G L Murphy, D L Medin, Psychological review. 923289Murphy, G.L., Medin, D.L.: The role of theories in conceptual coherence. Psychological review 92(3), 289 (1985)</p>
<p>The big book of concepts. G L Murphy, MIT pressMurphy, G.L.: The big book of concepts. MIT press (2002)</p>
<p>Furnishing the mind: Concepts and their perceptual basis. J J Prinz, MIT pressPrinz, J.J.: Furnishing the mind: Concepts and their perceptual basis. MIT press (2002)</p>
<p>Cognitive representations of semantic categories. E Rosch, J. Exp. Psychol. Gen. 1043Rosch, E.: Cognitive representations of semantic categories. J. Exp. Psychol. Gen. 104(3), 192-233 (1975)</p>
<p>Prototypes in the mist: The early epochs of category learning. J D Smith, J P Minda, Journal of Experimental Psychology: Learning, Memory, and Cognition. 2461411Smith, J.D., Minda, J.P.: Prototypes in the mist: The early epochs of category learning. Jour- nal of Experimental Psychology: Learning, Memory, and Cognition 24(6), 1411 (1998)</p>
<p>Vector lida. J Snaider, S Franklin, Procedia Computer Science. 41Snaider, J., Franklin, S.: Vector lida. Procedia Computer Science 41, 188-203 (2014)</p>
<p>The clarion cognitive architecture: Extending cognitive modeling to social simulation. Cognition and multi-agent interaction pp. R Sun, Sun, R.: The clarion cognitive architecture: Extending cognitive modeling to social simula- tion. Cognition and multi-agent interaction pp. 79-99 (2006)</p>
<p>Coherence as constraint satisfaction. P Thagard, K Verbeurgt, Cognitive Science. 221Thagard, P., Verbeurgt, K.: Coherence as constraint satisfaction. Cognitive Science 22(1), 1-24 (1998)</p>            </div>
        </div>

    </div>
</body>
</html>