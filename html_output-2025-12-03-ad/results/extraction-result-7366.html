<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-7366 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-7366</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-7366</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-139.html">extraction-schema-139</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <p><strong>Paper ID:</strong> paper-270285670</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2406.03614v1.pdf" target="_blank">Advancing Anomaly Detection: Non-Semantic Financial Data Encoding With Large Language Models</a></p>
                <p><strong>Paper Abstract:</strong> Detecting anomalies in general ledger data is of utmost importance to ensure the trustworthiness of financial records. Financial audits increasingly rely on machine learning (ML) algorithms to identify irregular or potentially fraudulent journal entries, each characterized by a varying number of transactions. In machine learning, heterogeneity in feature dimensions adds significant complexity to data analysis. In this paper, we introduce a novel approach to anomaly detection in financial data using Large Language Model (LLM) embeddings. To encode non-semantic categorical data (i.e., attributes lacking inherent linguistic meaning) from real-world financial records, we tested 3 pretrained general-purpose sentence-transformer models. For the downstream classification task, we implemented and evaluated 5 optimized ML models, including Logistic Regression, Random Forest, Gradient Boosting Machines, Support Vector Machines, and Neural Networks. Our experiments demonstrate that LLMs contribute valuable information to anomaly detection as our models outperform the baselines, in selected settings by a large margin. The findings further underscore the effectiveness of LLMs in enhancing anomaly detection in financial journal entries, particularly by tackling feature sparsity. We discuss a promising perspective on using SBERT embeddings for non-semantic data in the financial context and beyond.</p>
                <p><strong>Cost:</strong> 0.011</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e7366.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e7366.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SBERT_embeddings</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Sentence-BERT (SBERT) embeddings (all-MiniLM-L6-v2, all-distilroberta-v1, all-mpnet-base-v2)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>This paper encodes non-semantic categorical general-ledger journal-entry data by concatenating transaction categorical fields into sentence-like strings and producing fixed-size SBERT sentence embeddings, which are then fed to supervised ML classifiers (LR, RF, XGBoost, SVM, NN) for anomaly detection.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Advancing Anomaly Detection: Non-Semantic Financial Data Encoding with LLMs</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>all-MiniLM-L6-v2; all-distilroberta-v1; all-mpnet-base-v2</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Sentence-Transformers (SBERT) — BERT-based siamese/triplet sentence-transformer models that produce contextual sentence embeddings via transformer encoder stacks and mean-pooling; used as frozen encoders to map concatenated categorical transaction strings to dense vectors.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>all-MiniLM-L6-v2: 384-dim (≈80 MB); all-distilroberta-v1: 768-dim (≈290 MB); all-mpnet-base-v2: 768-dim (≈420 MB) (as reported in the paper's Table 1).</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_approach</strong></td>
                            <td>Generate SBERT embeddings for each aggregated journal entry (concatenated categorical fields) and perform supervised classification using downstream ML classifiers (Logistic Regression, Random Forest, XGBoost, SVM, Neural Networks) to detect anomalous journal entries.</td>
                        </tr>
                        <tr>
                            <td><strong>prompt_template</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>An anonymized real-world General Ledger dataset aggregated from multiple ERP systems (32,100 transaction-level data points aggregated into journal entries). The dataset originally excluded entries with >4 transactions; contains 148 labeled anomalies of eight auditor-defined types (treated as a single anomalous class). Models trained with an 80/20 stratified train/test split and class weighting to address imbalance; hyperparameter tuning with Hyperopt (TPE) over 100 iterations for non-neural classifiers; neural networks trained with early stopping over 50 epochs.</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Non-semantic categorical transactional data: aggregated journal entries (concatenation of categorical attributes like source system, account, debit/credit sign) represented as sentence-like text and mapped to dense vectors.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>Anonymized General Ledger dataset (aggregated real-world general ledger entries; dataset described as in Bakumenko et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Macro recall average (Recall_AM) as primary metric for imbalanced data; additional reporting via confusion matrices, specificity and sensitivity, and comparisons of PCA variance retention for embeddings.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Non-optimized Logistic Regression recall_AMs reported as: 0.9516 (all-MiniLM-L6-v2), 0.9040 (all-distilroberta-v1), and 0.9520 (all-mpnet-base-v2). Comparative deltas vs padded one-hot encoding: Logistic Regression improved by +0.056, +0.030, +0.032 for E1/E2/E3 respectively; Neural Networks improved by +0.064, +0.050, +0.062; Random Forest decreased by -0.066, -0.044, -0.021; SVM decreased by -0.085, -0.108, -0.015. PCA dimensionality results: all-MiniLM-L6-v2 required 63 components for 99% variance (150 for 99.9%), all-distilroberta-v1 required 57 components for 99% (172 for 99.9%), all-mpnet-base-v2 required 52 components for 99% (157 for 99.9%); padded one-hot required 419 components for 99% variance. (All numbers and deltas are reported directly in the paper.)</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Baseline encoding: padded one-hot encoding of transaction-categorical features (initially 2336 dims reduced by PCA to 419 components for 99% variance). Downstream classifiers trained on one-hot/PCA features served as comparison; reported per-model deltas (see performance) summarize relative improvements/declines for each classifier when using SBERT embeddings vs padded one-hot encoding.</td>
                        </tr>
                        <tr>
                            <td><strong>zero_shot_or_few_shot</strong></td>
                            <td>Fully supervised (labeled anomalies), trained on stratified 80/20 train/test split; no zero-shot/few-shot prompting used.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Reported limitations include: drop in performance for some classifiers (notably SVM and Random Forest) when using LLM embeddings; dataset contains synthetic (auditor-inserted) anomalies which may limit generalizability to naturally occurring anomalies; PCA is linear and may not capture non-linear structure; sensitivity of embeddings to concatenation/prompt engineering not explored; approach focuses on categorical features and does not handle precise numerical analysis in current work.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Advancing Anomaly Detection: Non-Semantic Financial Data Encoding With Large Language Models', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Detecting anomalies in financial data using machine learning algorithms <em>(Rating: 2)</em></li>
                <li>Sentence-bert: Sentence embeddings using siamese bert-networks <em>(Rating: 2)</em></li>
                <li>Exploring the potential of large language models (llms) in learning on graphs <em>(Rating: 1)</em></li>
                <li>Frozen Transformers in Language Models Are Eective Visual Encoder Layers <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-7366",
    "paper_id": "paper-270285670",
    "extraction_schema_id": "extraction-schema-139",
    "extracted_data": [
        {
            "name_short": "SBERT_embeddings",
            "name_full": "Sentence-BERT (SBERT) embeddings (all-MiniLM-L6-v2, all-distilroberta-v1, all-mpnet-base-v2)",
            "brief_description": "This paper encodes non-semantic categorical general-ledger journal-entry data by concatenating transaction categorical fields into sentence-like strings and producing fixed-size SBERT sentence embeddings, which are then fed to supervised ML classifiers (LR, RF, XGBoost, SVM, NN) for anomaly detection.",
            "citation_title": "Advancing Anomaly Detection: Non-Semantic Financial Data Encoding with LLMs",
            "mention_or_use": "use",
            "model_name": "all-MiniLM-L6-v2; all-distilroberta-v1; all-mpnet-base-v2",
            "model_description": "Sentence-Transformers (SBERT) — BERT-based siamese/triplet sentence-transformer models that produce contextual sentence embeddings via transformer encoder stacks and mean-pooling; used as frozen encoders to map concatenated categorical transaction strings to dense vectors.",
            "model_size": "all-MiniLM-L6-v2: 384-dim (≈80 MB); all-distilroberta-v1: 768-dim (≈290 MB); all-mpnet-base-v2: 768-dim (≈420 MB) (as reported in the paper's Table 1).",
            "anomaly_detection_approach": "Generate SBERT embeddings for each aggregated journal entry (concatenated categorical fields) and perform supervised classification using downstream ML classifiers (Logistic Regression, Random Forest, XGBoost, SVM, Neural Networks) to detect anomalous journal entries.",
            "prompt_template": null,
            "training_data": "An anonymized real-world General Ledger dataset aggregated from multiple ERP systems (32,100 transaction-level data points aggregated into journal entries). The dataset originally excluded entries with &gt;4 transactions; contains 148 labeled anomalies of eight auditor-defined types (treated as a single anomalous class). Models trained with an 80/20 stratified train/test split and class weighting to address imbalance; hyperparameter tuning with Hyperopt (TPE) over 100 iterations for non-neural classifiers; neural networks trained with early stopping over 50 epochs.",
            "data_type": "Non-semantic categorical transactional data: aggregated journal entries (concatenation of categorical attributes like source system, account, debit/credit sign) represented as sentence-like text and mapped to dense vectors.",
            "dataset_name": "Anonymized General Ledger dataset (aggregated real-world general ledger entries; dataset described as in Bakumenko et al.)",
            "evaluation_metric": "Macro recall average (Recall_AM) as primary metric for imbalanced data; additional reporting via confusion matrices, specificity and sensitivity, and comparisons of PCA variance retention for embeddings.",
            "performance": "Non-optimized Logistic Regression recall_AMs reported as: 0.9516 (all-MiniLM-L6-v2), 0.9040 (all-distilroberta-v1), and 0.9520 (all-mpnet-base-v2). Comparative deltas vs padded one-hot encoding: Logistic Regression improved by +0.056, +0.030, +0.032 for E1/E2/E3 respectively; Neural Networks improved by +0.064, +0.050, +0.062; Random Forest decreased by -0.066, -0.044, -0.021; SVM decreased by -0.085, -0.108, -0.015. PCA dimensionality results: all-MiniLM-L6-v2 required 63 components for 99% variance (150 for 99.9%), all-distilroberta-v1 required 57 components for 99% (172 for 99.9%), all-mpnet-base-v2 required 52 components for 99% (157 for 99.9%); padded one-hot required 419 components for 99% variance. (All numbers and deltas are reported directly in the paper.)",
            "baseline_comparison": "Baseline encoding: padded one-hot encoding of transaction-categorical features (initially 2336 dims reduced by PCA to 419 components for 99% variance). Downstream classifiers trained on one-hot/PCA features served as comparison; reported per-model deltas (see performance) summarize relative improvements/declines for each classifier when using SBERT embeddings vs padded one-hot encoding.",
            "zero_shot_or_few_shot": "Fully supervised (labeled anomalies), trained on stratified 80/20 train/test split; no zero-shot/few-shot prompting used.",
            "limitations_or_failure_cases": "Reported limitations include: drop in performance for some classifiers (notably SVM and Random Forest) when using LLM embeddings; dataset contains synthetic (auditor-inserted) anomalies which may limit generalizability to naturally occurring anomalies; PCA is linear and may not capture non-linear structure; sensitivity of embeddings to concatenation/prompt engineering not explored; approach focuses on categorical features and does not handle precise numerical analysis in current work.",
            "computational_cost": null,
            "uuid": "e7366.0",
            "source_info": {
                "paper_title": "Advancing Anomaly Detection: Non-Semantic Financial Data Encoding With Large Language Models",
                "publication_date_yy_mm": "2024-06"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Detecting anomalies in financial data using machine learning algorithms",
            "rating": 2,
            "sanitized_title": "detecting_anomalies_in_financial_data_using_machine_learning_algorithms"
        },
        {
            "paper_title": "Sentence-bert: Sentence embeddings using siamese bert-networks",
            "rating": 2,
            "sanitized_title": "sentencebert_sentence_embeddings_using_siamese_bertnetworks"
        },
        {
            "paper_title": "Exploring the potential of large language models (llms) in learning on graphs",
            "rating": 1,
            "sanitized_title": "exploring_the_potential_of_large_language_models_llms_in_learning_on_graphs"
        },
        {
            "paper_title": "Frozen Transformers in Language Models Are Eective Visual Encoder Layers",
            "rating": 1,
            "sanitized_title": "frozen_transformers_in_language_models_are_eective_visual_encoder_layers"
        }
    ],
    "cost": 0.01055,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Advancing Anomaly Detection: Non-Semantic Financial Data Encoding with LLMs</p>
<p>Alexander Bakumenko alexander.bakumenko@outlook.com 
Kateřina Hlaváčková-Schindler 
Nina C Hubig nhubig@clemson.edu </p>
<p>Clemson University Charleston
SCUSA</p>
<p>University of Vienna Vienna
Austria</p>
<p>Claudia Plant University of Vienna Vienna
Austria</p>
<p>Clemson University Charleston
SCUSA</p>
<p>Advancing Anomaly Detection: Non-Semantic Financial Data Encoding with LLMs
261E17167A0D81E0D5ADB473B59776FAGeneral LedgerAccountingAuditingAnomaly DetectionMachine LearningLarge Language Models (LLMs)Embeddings
Detecting anomalies in general ledger data is of utmost importance to ensure trustworthiness of nancial records.Financial audits increasingly rely on machine learning (ML) algorithms to identify irregular or potentially fraudulent journal entries, each characterized by a varying number of transactions.In machine learning, heterogeneity in feature dimensions adds signicant complexity to data analysis.In this paper, we introduce a novel approach to anomaly detection in nancial data using Large Language Models (LLMs) embeddings.To encode non-semantic categorical data from real-world nancial records, we tested 3 pre-trained general purpose sentence-transformer models.For the downstream classication task, we implemented and evaluated 5 optimized ML models including Logistic Regression, Random Forest, Gradient Boosting Machines, Support Vector Machines, and Neural Networks.Our experiments demonstrate that LLMs contribute valuable information to anomaly detection as our models outperform the baselines, in selected settings even by a large margin.The ndings further underscore the eectiveness of LLMs in enhancing anomaly detection in nancial journal entries, particularly by tackling feature sparsity.We discuss a promising perspective on using LLMs' embeddings for non-semantic data in the nancial context and beyond.</p>
<p>INTRODUCTION 1.Anomaly Detection in Finance and the Critical Role of Machine Learning</p>
<p>Financial data, sourced from the general ledger, details an organization's nancial transactions including revenue, expenses, assets, and liabilities, serving to accurately document business activities [21,24].It is essential for ensuring compliance and transparency for stakeholders like regulatory bodies, investors, and nancial institutions.Furthermore, the data supports decision-making through analytics, while anomaly detection is crucial for maintaining data integrity and reliability [37].</p>
<p>Financial data anomalies, caused by errors, fraud, or manipulation, risk considerable nancial loss, undermine investor condence, and necessitate fraud investigations [24].Prompt, eective anomaly detection is essential for regulatory adherence and nancial protection [8,22].Traditional nancial anomaly detection has struggled with complex, voluminous data and advancing fraud techniques.Early approaches, relying on manual checks and rule-based systems, were inecient, missing many anomalies and producing numerous false alarms, allowing nancial fraud to go unnoticed [5].</p>
<p>Machine learning (ML) has become crucial in modern nancial auditing, enabling ecient processing and pattern recognition in large datasets.However, as nancial fraud techniques grow more complex, there is a need for novel methods to overcome challenges in data preprocessing and model limitations [2,22].Recent research highlights the potential of Autoencoders for anomaly detection and LLMs for diverse tasks, yet the sparsity and complexity of real-world data limits their eectiveness [26,36].</p>
<p>Problem Statement</p>
<p>This work addresses the challenge of ecient detecting anomalies in general ledger data, focusing on the issues of feature dimension heterogeneity and feature sparsity, which hinder anomaly detection in nancial audits.The approach involves using sentence-BERT LLMs' pre-trained representations to encode non-semantic categorical data in journal entries, enhancing the identication of data irregularities.While current solutions use various vectorization methods with the subsequent dimensionality reduction of sparse features, this can be inadequate for real-world journal entries, which often dier greatly in length and complexity.Moreover, a non-temporal aspect of transaction anomalies limits the range of applicable feature encoding methods.Consequently, ML algorithms for detecting anomalies in nancial data face diculties with heterogeneous and sparse data, causing problems in encoding and classication, and thus, leading to suboptimal outcomes.This aects the reliability of nancial records audit.</p>
<p>We propose a novel approach, conceptualized in Figure 1, using pre-trained sentence-transformer models to encode non-semantic nancial data, addressing feature heterogeneity and sparsity issues.This approach diverges from conventional ML techniques in nancial anomaly detection, suggesting a hybrid model that combines sentence-transformer embeddings with ML classiers for enhanced anomaly detection performance.Accurate anomaly detection is a cornerstone for reliable nancial audits.Improvements in handling heterogeneity and sparsity in nancial data can signicantly enhance anomaly detection processes, contributing to better risk management and regulatory compliance.The proposed approach has broader implications beyond nancial anomaly detection, offering a template for applying advanced encoding techniques for complex datasets across domains.</p>
<p>Objectives and Contributions</p>
<p>In this work we formulate the following 2 hypotheses:</p>
<p>• Hypothesis 1: Utilizing sentence-transformer LLMs for encoding non-semantic categorical data from nancial records eectively standardizes feature variability enhancing the compactness and information retention of feature sets, when compared to conventional methods, measurable through dimensionality reduction techniques like PCA. • Hypothesis 2: The integration of sentence-transformer based LLM embeddings with optimized ML models yields superior anomaly detection performance in nancial journal entries, evidenced by improved evaluation metrics, compared to traditional ML approaches.In formulating our hypotheses, we draw on recent ndings that demonstrate LLMs' adaptability beyond text-based tasks [28].Studies have shown that LLMs, originally trained on text, can eectively process and encode non-textual, linguistically non-semantic data [30].This capability, arising from the encoding functions of their transformer blocks, prompts our hypothesis 1, suggesting the use of the SBERT LLMs in transforming non-semantic nancial datasets into standardized single-size vector features.Subsequently, our hypothesis 2 builds on the LLMs' ecient encoding capabilities, implying the integration of LLMs' embeddings could enhance ML models, particularly in detecting anomalies in nancial data.Validating Hypothesis 1 would demonstrate a novel method to manage feature variability in nancial records, enchancing anomaly detection.Conrming Hypothesis 2 would illustrate the eectiveness of integrating LLM embeddings with optimized models in detecting nancial anomalies, potentially surpassing traditional methods.</p>
<p>Together, these ndings could transform current practices in nancial anomaly detection.The innovative use of LLMs could greatly advance this eld, showing their potential for cross-disciplinary applications and improving nancial auditing and monitoring systems.</p>
<p>BACKGROUND AND RELATED WORK 2.1 Machine Learning Methods and Limitations in Detecting Financial Anomalies</p>
<p>Anomaly detection in nance is critical, with fraudulent activities greatly aecting the sector.The rise of digital nancial services, especially post-COVID-19 pandemic, necessitates advanced fraud detection methods [43].Deep learning, including variational autoencoders and LSTM architectures, has shown success in detecting anomalies in journal entries [44] and e-commerce [27], with LSTMs also being eective [1].Graph Neural Networks (GNNs) are notable for their ability to handle complex data relationships in fraud detection [43].Various ML techniques, such as Naive Bayes, Logistic Regression, KNN, Random Forest, and Sequential CNNs, have been applied to credit card fraud detection [29], with CatBoost-based methods highlighting the role of feature engineering and memory compression in improving eciency [13].ML in nance is largely applied, from detecting journal entry anomalies to identifying fraudulent transactions in healthcare and banking [29,38].While case studies arm their eectiveness, they also point out challenges in practical implementation [7].</p>
<p>Applying ML in nancial fraud detection faces challenges due to evolving fraud techniques and the complexity of nancial data [11].Accurate modeling relies on high-quality, standardized data, as it was discussed in the context of the credit card industry [31].Financial data's non-stationarity, non-linearity, and low signal-to-noise ratio complicate model training and performance [40], necessitating advanced methods for preprocessing complex data improving data quality and model performance.Enhancing data representation and simplifying features can also improve ML model interpretability, meeting the regulatory and compliance demands in nance.[38].Additionally, balancing computational complexity with high detection accuracy is crucial [27], underscoring the need to enhance the compactness and information retention of feature sets.Promising research directions warrant exploration of diverse ML approaches and hybrid applications, emphasizing the importance of innovative data pre-processing and adaptable ML methods to tackle data quality and model adaptability challenges [4].</p>
<p>Applications and capabilities of LLMs</p>
<p>LLMs such as GPT-3, PaLM, and LLaMA mark a paradigm shift in natural language processing (NLP) and articial intelligence (AI), evolving from rule-based frameworks to sophisticated neural network architectures like Transformer.This evolution allows LLMs to encode vast linguistic datasets into vector representations for diverse applications [41,42].LLMs such as BERT excel at capturing the complex semantic and syntactic nuances of language, resulting in dense embeddings.These embeddings are pivotal for tasks like node classication in textual graphs [14], demonstrating LLMs' ability to generate meaningful representations from vast textual corpora [32].Originally designed for linguistic tasks, LLMs show remarkable versatility by branching into non-linguistic domains, eectively encoding diverse data types, including non-semantic elements, into sequential formats.Illustratively, sentence-transformers vectorize non-linguistic data, extending LLMs' use to computer vision [30].LLMs excel in tasks such as text summarization and content recommendation, thereby proving their broad applicability [25,41,42].LLMs provide innovative approaches in data analysis by eectively managing feature variability and sparsity, thus enhancing anomaly detection.They can surpass traditional ML in processing complex data for advanced analyses [3,20].</p>
<p>In nancial analysis, LLMs constitute a major methodological leap.Sentence-transformers underscore the ability of LLMs to tackle feature heterogeneity and sparsity in anomaly detection by producing meaningful vectors [34,39,40].Sentence-BERT (SBERT), a rened version of BERT, produces semantically dense sentence embeddings, improving clustering and semantic search [34].SBERT leverages siamese and triplet networks to enhance sentence semantic analysis, ensuring similar sentences are close in embedding space.This improvement reduces embedding generation time from 65 hours with BERT to seconds for large datasets.SBERT excels in various tasks like sentence pair regression and semantic similarity, demonstrating its potential in fast, high-quality embeddings for both linguistic and non-linguistic data applications, beyond traditional text-based tasks [34].</p>
<p>Identifying Research Gaps in Financial Anomaly Detection</p>
<p>Despite progress in ML and deep learning for nancial anomaly detection, these approaches often falter due to the diverse and sparse nature of nancial data, particularly in journal entries, undermining the eectiveness of data encoding and classication, and consequently, the precision and reliability of nancial audits [6].</p>
<p>Traditional anomaly detection techniques rely on vectorization and dimensionality reduction, but these may not suce for real-world journal entries, which greatly dier in length and complexity.Moreover, the non-temporal aspect of nancial transactions restricts the use of some feature encoding strategies.Advanced ML techniques remain underleveraged for non-semantic, categorical nancial data, with traditional anomaly detection methods falling short in addressing the non-temporal and heterogeneous data complexities.The untapped potential of sentence-transformer LLMs for nancial data analysis presents an opportunity to innovate in handling feature variability and sparsity.Bridging the signicant research gap by integrating LLM embeddings with optimized ML models for nancial anomaly detection could signicantly enhance classication accuracy and data encoding robustness, outperforming traditional methodologies.</p>
<p>DATA DESCRIPTION AND ETHICAL CONSIDERATIONS</p>
<p>In our work, we utilized an aggregated real-world General Ledger dataset from various anonymized companies, as described by Bakumenko et al. [6].This dataset, comprising anonymized journal entries, features system-specic account plans across multiple industries and timeframes.It has been originally preprocessed to exclude entries with more than four transactions to manage outliers.It includes a small subset of labeled anomalies with eight types of errors, created by nancial auditors to reect prevalent anomalies in nancial records, indicating key areas of interest in real-world anomaly detection.The dataset focuses on attributes critical for anomaly detection, such as the source system, account category, and debit/credit indicators, streamlining the identication of irregularities within the data.</p>
<p>In this work, we applied rigorous ethical protocols to the General Ledger dataset, ensuring thorough anonymization to eliminate any identiable details about companies or individuals.The dataset remains condential and unshareable, safeguarding against unauthorized access.We avoided cloud storage to minimize data breach risks, maintaining the dataset's integrity.Data processing and analysis were conducted with strict adherence to legal and ethical guidelines.The introduced anomalies were carefully managed to uphold ethical data manipulation practices for research purposes.</p>
<p>METHODOLOGY 4.1 Data Preprocessing</p>
<p>The dataset comprises 32,100 transaction-level data points within journal entries, inclusive of 148 anomalies designed to reect abnormal patterns without individual deviations.For anomaly detection in journal entries, transactions are aggregated into sets = {) 1 ,) 2 , . . .,) # }, where denotes a journal entry with # transactions.An aggregated set A is formed by applying an aggregation function to each , expressed as
A = { ( ) | 2 J }.
In the work by Bakumenko Et al. [6], padding standardizes transaction lengths into uniform feature vector , preparing ML model input.Transactions, dened by ERP attributes like account number and debit/credit sign, merged into the ⇠⇠$<em> #) _⇡⇠ feature.The dimension of this encoded feature in a sparse matrix follows the formula:
count = max 1:  &lt; : ' 8=1 ) :,8 ! • (|U(+ 1 )| + |U(+ 2 )|)(1)
, where 2&gt;D=C is the total feature count, calculated by the product of the maximum transaction amount across journal entries, denoted as max 1:  Õ &lt; : 8=1 ) :,8 , and the combined count of unique elements in the ($</em> '⇠⇢ and ⇠⇠$<em> #) _⇡⇠ feature vectors (+ 1 and + 2 ).Thus, on-hot encoding approach, where exist 577 unique ⇠⇠$</em> #) _⇡⇠ values and 4 unique values in the ($* '⇠⇢ feature, would result in 2336 encoded features.This feature space was PCA-reduced.</p>
<p>In contrast, to apply SBERT models for transactional data encoding in each JE, we rst concatenated transactions categorical features with a group-by operation, based on JE identiers.The procedure to combine the ($<em> '⇠⇢ and ⇠⇠$</em> #) <em>⇡⇠ attributes of each transaction and the transactions themselves is:
⇠ 8 = = 8 9=1 "Source: " + ( 9 + " Account_DC: " + 9(2)
, where ⇠ 8 is the concatenated text for the group 8 and = 8 is the number of transactions in group 8. … is the concatenation operation with a comma and space as transactions' delimiters.( 9 is the ($<em> '⇠⇢ attribute of the 9 C⌘ transaction in group 8, and 9 is the ⇠⇠$</em> #) </em>⇡⇠ attribute of the 9 C⌘ transaction in group 8.</p>
<p>The concatenated text ()4GC 2&gt;=2 ) for each JE is processed as a single sentence structure.The SBERT model's encode method rst tokenizes each string into a sequence of tokens.SBERT then generates contextual embeddings for each token using its BERTbased architecture, involving multiple transformer layers and selfattention mechanisms.A mean-pooling step, aggregates these token embeddings into a xed-size sentence embedding.PCA-like dimensionality reduction isn't used to maintain the embedding's original dimensionality, ensuring precise evaluation [6].We normalize embeddings to zero mean and unit variance for ML tasks to improve consistency and speed up convergence, crucial for distance-based or gradient descent algorithms, enhancing performance across models.SBERT embeddings create xed-size dense vectors for each journal entry, capturing transaction details, aiding in anomaly detection and pattern recognition by summarizing complex data interactions.</p>
<p>Data Balancing and Model Performance Validation</p>
<p>In ML, skewed datasets with imbalanced class distribution hinder model training in classication tasks by favoring the majority class and aecting anomaly detection.Following the guidelines from [18], we used an 80/20 stratied split to ensure balanced training and testing sets with proportional anomaly representation, reducing bias.We adjusted for imbalance by weighting the minority class to improve sensitivity in model phases and ensured result consistency and fair comparison with a constant random state.In training and optimization, we avoided cross-validation, recognizing its shortcomings in imbalanced datasets and large feature sets, noted by Rao et al. [33].Cross-validation raises overtting risks, especially with many models and extensive hyperparameter tuning.Its ecacy drops as data dimensionality grows, causing higher model variance and unreliable assessments from intricate feature interactions.Imbalanced datasets exacerbate the challenge, leading to biased cross-validation folds and skewed performance evaluations.We opted for a consistent 80/20 stratied split to maintain test set uniformity across models, crucial for accurately comparing algorithm performance, which cross-validation's variable data subsets could compromise.While this strategy mitigates some challenges, it potentially aects model generalizability.To counteract this, we employed careful metric selection and post-training cross-validation evaluation, although direct oversampling techniques for the minority class were impractical due to the dataset's complexity.</p>
<p>Model Selection</p>
<p>In this work, we evaluated three Sentence-BERT models for embedding generation: all-mpnet-base-v2, all-distilroberta-v1, and all-MiniLM-L6-v2, selected for their popularity and performance as indicated by their high download rates on the HuggingFace Model Hub [16].Each model, trained on over 1 billion pairs, oers distinct advantages: all-mpnet-base-v2 excels in quality with a notable performance score of 63.30 [35], all-distilroberta-v1 provides a balance between eciency and performance with a smaller size of 290 MB, and all-MiniLM-L6-v2 oers high speed with a compact size of 80 MB, suitable for real-time applications [35].Refer to Table 1 for the detailed models' specications.These models were chosen for their complementary strengths in quality, eciency, and speed, facilitating a comprehensive evaluation in this research.</p>
<p>We also employed ve ML classiers: Random Forest (RF), Gradient Boosting Machines (GBM) using XGBoost (XGB), Support Vector Machines (SVM), Logistic Regression (LR), and Neural Networks (NN) implemented with Keras TensorFlow.RF is noted for its ability to reduce overtting through ensemble decision trees, GBM for addressing data imbalance by optimizing weak learners, SVM for its eectiveness in high-dimensional spaces, LR as a fast and ecient baseline, and NN for modeling complex relationships, requiring careful architecture tuning [10,12,15,17,19,23].</p>
<p>Experimental Design</p>
<p>Our work employed a nancial dataset with both actual and articially inserted anomalies, aiming to detect the latter while minimizing false positives among the former.This dataset, mirroring real-world conditions with signicant class imbalance, is identical to that in Bakumenko et al. 's work [6], anonymized and rened to include only essential categorical features.We treated the 8 types of anomalies as a singular anomalous class, thereby framing it as To eectively identify anomalies in nancial journal entries, which constitute a high-dimensional dataset, we innovated by encoding this non-semantic categorical data using SBERT LLMs, particularly employing 3 sentence-transformers models to standardize variable-length entries into a consistent feature space, addressing limitations in traditional encoding methods noted in the original work [6].</p>
<p>We explored ve ML algorithms for anomaly detection, including Logistic Regression as a baseline, and optimized their hyperparameters using Hyperopt over 100 iterations.This ne-tuning, alongside the deployment of 3 Neural Network models with varied architectures, aimed to maximize model ecacy.</p>
<p>Model performance was assessed using the macro recall average metric, suitable for imbalanced datasets, focusing on the balanced detection of synthetic anomalies while controlling for false positives.This involved computing the average of Specicity and Sensitivity, alongside leveraging confusion matrices for a comprehensive performance overview [6].Our experimental framework investigated the eciency of LLMs in encoding nancial data and assessed multiple ML models' anomaly detection capabilities.The anomaly detection system, as depicted in our high-level diagram in Figure 2, integrates LLM embeddings with an ML classier to dierentiate between normal and anomalous journal entries, starting from the General Ledger data, processed into aggregated records for ML classication based on LLM-derived embeddings.</p>
<p>EXPERIMENTATION RESULTS</p>
<p>Analysis of Encoded Feature Set</p>
<p>We conducted Principal Component Analysis (PCA) on feature sets derived from 3 SBERT model embeddings (Figure 3).PCA demonstrates the embeddings' dimensionality and information retention within the dataset, with signicant variance preservation despite dimensionality reduction.The embeddings from the all-MiniLM-L6-v2 model (LLM1) required 63 components for 99% variance and 150 for 99.9%, whereas the all-distilroberta-v1 (LLM2) and all-mpnetbase-v2 (LLM3) models, despite larger vectors (770), needed fewer components (57 for LLM2 and 52 for LLM3) for the same variance level.</p>
<p>Further analysis revealed the less informative nature of the nal 0.9% variance, suggesting it might contain noise or dataset-specic Figure 3: PCA analysis of SBERT embeddings for the all-MiniLM-L6-v2 (E1), all-distilroberta-v1 (E2), and all-mpnetbase-v2 (E3) models.E1 achieves 99% variance with 63C and 99.9% variance with 150C.E2 achieves 99% variance with 57C and 99.9% variance with 172C.E3 achieves 99% variance with 52C and 99.9% variance with 157C.</p>
<p>features.A comparative study (Figure 4) showed LLM embeddings' superior dimensionality reduction compared to one-hot encoding.The LLM embeddings maintained high variance with fewer dimensions, in contrast to the sparse, high-dimensional vectors from one-hot encoding.The one-hot encoded data initially had 2336 dimensions, reduced to 419 to achieve 99% variance, which is still higher than the LLM embeddings.It's important to recognize PCA's linear nature limiting its ability to capture non-linear complexities.While useful for understanding structural properties and potential for dimensionality reduction, PCA doesn't predict performance in downstream tasks.Our extended analysis includes empirical assessments of embeddings in these tasks.</p>
<p>In summary, LLM embeddings oer more ecient data representation than one-hot encoding, requiring fewer dimensions for similar variance levels, making LLM embeddings more preferable for complex tasks.</p>
<p>Downstream Model Training and Optimization</p>
<p>We utilized a variety of ML classiers, as discussed in Section 4.3, including SVM, RF, XGBoost, LR, ANN, and DNNs.For non-ANN/DNN models, Bayesian optimization via the Hyperopt library and the Tree-structured Parzen Estimator (TPE) algorithm was applied over 100 iterations for hyperparameter tuning.Sample weights were calculated to address imbalanced datasets, and binary classication was achieved by transforming multi-class labels.</p>
<p>Model training utilized Python with Scikit-learn and TensorFlow libraries.We designed three Neural Network architectures with varying complexities and implemented training over 50 epochs with early stopping for generalization, detailed in Table 2. Reproducibility was ensured by xing seeds in NumPy and Ten-sorFlow, and recall average macro was monitored via custom callbacks.The ANN model featured a single hidden layer for rapid training, DNN1 had multiple hidden layers for complex pattern recognition, and DNN2 included dropout layers to prevent overtting, maintaining a deep architecture like DNN1.</p>
<p>Evaluation Metrics and Comparative Analysis</p>
<p>Earlier in this work, we discussed benets of having LR as a baseline model.For each of the three SBERT model embeddings, we trained two downstream LR models: a model with the default parameters and Hyperopt-optimized model.Non-optimised models showed high performance measured in recall average macro equal 0.9516, 0.9040, and 0.9520 for all-MiniLM-L6-v2, all-distilroberta-v1, and allmpnet-base-v2 embeddings respectively.Figure 5   In Figure 5, all three models demonstrate positive learning characteristics.The E3 model excels in learning and generalization, demonstrating strong data learning capacity.The E1 model, while performing adequately, shows signs of reaching its learning capacity limit.The E2 model is improving but requires better regularization strategies.The Hyperopt-optimized analysis shows E1's C value at 0.07677 indicates moderate regularization.E2 has a stronger regularization with a C value of 0.01702 and employs the 'newtoncg' solver.E3, with the smallest C value of 0.01358, exhibits the strongest regularization using the 'liblinear' solver.All models use uniform class weights to improve minority class prediction accuracy, with specic regularization strengths and solver selections tailored to their learning needs.Figure 6 evaluates the performance of LR, RF, XGB, SVM, and NN classiers optimized and integrated with embeddings from three language models.Performance metrics are based on average recall macro.All embeddings show varying degrees of eectiveness, with all-mpnet-base-v2 excelling in stability and performance across various classiers.all-MiniLM-L6-v2 also performs well, notably with LR and NN, while all-distilroberta-v1 is solid but does not outperform the all-MiniLM-L6-v2 with NN.These dierences indicate that certain embeddings are more compatible with specic classiers in downstream tasks, guiding practical model selection.</p>
<p>The confusion matrix values for the optimized models using dierent embeddings are provided in Table 3.The all-MiniLM-L6-v2 embeddings with LR, and potentially NN, if FPs are reduced, could provide the most balanced performance, while all-mpnet-base-v2 embeddings demonstrate higher TP rates across models.Figure 7 contrasts recall macro score dierences for LLM embeddings compared to padded one-hot encoding across LR, RF, SVM, and NN models.Each bar shows the recall score dierence for an LLM embedding, with boxplots summarizing the distribution and means (diamonds) for each model.</p>
<p>For LR, LLM embeddings improved recall scores by +0.056, +0.030, and +0.032, with a compact distribution indicating consistent enhancement across embeddings.In contrast, RF models showed a decline with LLM embeddings, marked by dierences of -0.066, -0.044, and -0.021, and a moderate variability range.SVM models experienced reduced performance with LLM embeddings, with negative dierences of -0.085, -0.108, and -0.015, showing signicant variability towards lower performance.NN models beneted from LLM embeddings, with increases of +0.064, +0.050, and +0.062, and minimal variability, indicating a reliably positive eect.LLM embeddings improve LR and NN model performance over traditional padded one-hot encoding, but generally reduce eectiveness in RF and SVM models.While some models may consistently benet from LLM embeddings, these highlights the model-specic variability in performance when applying LLM embeddings for data encoding.</p>
<p>The Bland-Altman plots in Figure 8 compare two score sets, evaluating ML model performances using embeddings (all-MiniLM-L6-v2 (E1), all-distilroberta-v1 (E2), and all-mpnet-base-v2 (E3)) against a traditional method.The red line shows the average difference in recall macro scores between all models.Blue lines, set at the mean dierence ± 1.96 SD, dene the limits of agreement, indicating the expected range for most score dierences.Point dispersion around the blue lines shows some models' new embeddings align with expected performance ranges versus traditional methods.Performance varies across ML models and embeddings.For instance, NN models often exhibit improved results, shown by positive deviations above the red line, whereas SVM models display reduced ecacy, indicated by negative deviations.Overall, ML models employing LLM embeddings tend to match the anticipated performance spectrum of traditional methods, indicating on-average comparable outcomes.</p>
<p>Hypotheses Revisited</p>
<p>The PCA analysis on sentence-transformer embeddings demonstrates improved compactness and information retention in nancial data encoding over traditional approaches, conrming Hypothesis 1.This highlights the embeddings' superior ability to standardize feature variability and compress information eectively.</p>
<p>For Hypothesis 2, the integration of sentence-transformer embeddings with optimized LR and NN models, showed improved anomaly detection performance, arming the LLMs embeddings potential to surpass traditional methods.Although some performance variances were observed, such as in SVM models, these were within anticipated bounds.The results underscore the ecacy of this innovative approach, emphasizing the importance of strategic model choice to maximize benets.</p>
<p>DISCUSSION</p>
<p>This work's utilization of sentence-transformer LLMs for nancial data encoding demonstrated a novel approach to enhancing anomaly detection.</p>
<p>Interpretation of Results</p>
<p>Using PCA on embeddings from three SBERT models (MiniLM-L6-v2, all-distilroberta-v1, and all-mpnet-base-v2) demonstrates a substantial improvement in dimensionality reduction and information retention for nancial datasets compared to traditional encoding.For instance, considering downstream ML performance, the all-mpnet-base-v2 model needed just 52 PCA components to preserve 99% variance, compared to 419 for padded one-hot encoding.Embedded feature dimensionality for all 3 SBERT models was signicantly lower in the same comparison.This advancement addresses the critical challenge of feature heterogeneity and sparsity in nancial non-semantic non-temporal categorical feature sets, which is a notable improvement over traditional methods.Downstream ML models' performance conrms LLM embeddings' ecacy in anomaly detection.The employment of various ML classiers, including Bayesian-optimized LR, RF, XGB, SVM, and NNs with multiple architectures and adjusted parameters, highlights the embeddings' versatility and potential to boost model performance.The superior evaluation metrics for LR and NN models using all 3 SBERT embeddings underscore these embeddings' potential in enhancing anomaly detection.The underperformance of SVM, even within the expected bounds, highlights the need for model-embedding compatibility assessment in future applications.</p>
<p>Implications for Financial Anomaly Detection</p>
<p>The integration of sentence-transformer LLMs in nancial anomaly detection represents a leap from traditional methods, enhancing data representation and algorithm sensitivity to anomalies.This approach, in practical settings, promises to elevate fraud detection eciency by improving accuracy and minimizing false alerts, thus streamlining nancial operations.The novel method achieves an eightfold decrease in the number of components in certain scenarios while improving downstream model performance, eciently standardazing feature variability.It illustrates its eectiveness and setting new standards in nancial data encoding.As this methodology becomes more prevalent, it could establish new benchmarks in nancial analysis, catalyzing advancements in ML applications within the industry.Further empirical studies and real-world applications could solidify its standing and quantify its impact.</p>
<p>Limitations and Bias</p>
<p>Our research utilized a real-world dataset from various ERPs, enriched with eight distinct types of intentionally introduced and labeled anomalies by nancial auditors.The anomalies, reecting auditors' interests in practical anomaly detection, have a synthetic nature that may limit generalizability.Additionally, the challenge in analyzing real-world nancial data lies in unlabeled anomalies that may exist, potentially skewing ML model validation and increasing false-positive rates.Additionally, PCA analysis is a linear method limited in its capacity to represent non-linear relationships in feature sets.Also, LLMs respond to prompt engineering, meaning changes in input feature concatenation can alter embeddings, an aspect not covered in this work.Finally, our method focuses on categorical features and requires extension in scenarios requiring precise numerical analysis.</p>
<p>CONCLUSION AND FUTURE WORK 7.1 Contributions Summary</p>
<p>Our research advances the domain of nancial anomaly detection through the integration of LLM embeddings with ML classiers, a novel approach that notably mitigates feature heterogeneity and sparsity.Utilizing sentence-transformer models for nancial data encoding, our methodology not only surpassed traditional encoding techniques in dimensionality reduction and information retention, but also showcased enhanced anomaly detection ecacy with selected ML classiers.This aligns with established principles of feature representation [9], reecting their practical application in the context of nancial data.Underpinned by a comprehensive experimental setup and demonstrating practical applicability, our work contributes valuable insights for future research at the intersection of natural language processing and nancial analytics.</p>
<p>Broader Impact and Implications</p>
<p>The innovative use of Large Language Models (LLMs) for nonsemantic nancial data tackles high-dimensionality and sparsity, establishes a precedent for the use of LLMs in domains beyond their traditional applications.This mirrors ndings where LLMs successfully encode visual tokens [30].By outperforming conventional methods, LLM embeddings show their potential beyond linguistic tasks, particularly for data types lacking inherent semantics.This methodological advancement could aid various industries with similar challenges, notably healthcare and retail, where complex datasets might gain from the enhanced data representation capabilities of LLMs.In healthcare, LLM embeddings could enhance patient data analysis by detecting patterns in datasets that are mainly numerical, lack textual clarity, or consist of structured data like MRIs, CT scans, ICD codes, and lab values, which require domain knowledge for interpretation.In retail, LLMs could oer detailed insights from high-dimensional transactional data, revealing complex product-consumer interactions.This can enhance ML models' ability to predict behaviors, segment markets, and suggest products, advancing market analytics.The utilization of LLMs on non-semantic data expands their use and prompts a rethinking of data analysis methods, fostering multidisciplinary research into their potential for complex datasets.</p>
<p>Future Research Directions</p>
<p>Future research should extend the LLM embedding approach to broader nancial datasets, assessing its scalability, impact on anomaly detection accuracy, and computational eciency in response to evolving nancial fraud patterns.Extending this methodology to various non-semantic data types across multiple domains with high-dimensional and sparse datasets, and integrating with other advanced ML and deep learning models, will test the adaptability and eectiveness of LLM embeddings.Unsupervised strategies should be explored to address zero-day anomalies, rening our method to better detect novel patterns.Future research should investigate how diverse data preprocessing strategies, including aggregation methods and prompt engineering, enhance LLM encoding eciency.A focused exploration into non-linear dimensionality reduction techniques could complement PCA, aiming to more effectively capture complex relationships within LLM embeddings.Investigating the eects of synthetic versus real-world anomalies on model performance will oer insights into the ndings' practical applicability.Finally, exploring model-embedding compatibility by testing various cutting-edge LLM architectures could yield more tailored anomaly detection solutions.</p>
<p>Figure 1 :
1
Figure 1: A novel approach to eciently encode journal entry non-semantic categorical features utilizing SBERT LLM model embeddings.It integrates Data Preparation and Creating Embeddings steps that produce one-size vectors feature set for the downstream ML tasks.</p>
<p>Figure 2 :
2
Figure 2: High-level diagram of the anomaly detection algorithm with sentence-transformer and ML classiers.</p>
<p>Figure 4 :
4
Figure 4: Dimensionality reduction eciency comparison between novel (E1: all-MiniLM-L6-v2, E2: all-distilroberta-v1, E3: all-mpnet-base-v2) and conventional method (Study2).</p>
<p>shows learning curves for optimized LR models, using a ;40A=8=6_2DAE4 function for cross-validation to check for generalization and overtting.It trains the model on increasing data subsets and evaluates on training and validation sets, using 5-fold cross-validation.We calculated mean and standard deviation for training and validation scores across folds to gauge average performance and variability considering class imbalance.The training score line (red) indicates training subset performance, and the cross-validation score line (green) indicates unseen validation set performance, oering a robust estimate of model performance across data subsets and potential improvement with more data.</p>
<p>Figure 5 :
5
Figure 5: Learning curve post-train evaluation for optimized LR models using all-MiniLM-L6-v2 (E1), all-distilroberta-v1 (E2), and all-mpnet-base-v2 (E3) model embeddings.</p>
<p>Figure 6 :
6
Figure 6: Recall_AM scores for sentence-transformer and ML classier models.</p>
<p>Figure 7 :
7
Figure 7: Performance dierential analysis of ML models using LLM Embeddings versus traditional encoding.</p>
<p>Figure 8 :
8
Figure 8: Model performance dierentials using LLM Embeddings (all-MiniLM-L6-v2 (E1), all-distilroberta-v1 (E2), and all-mpnet-base-v2 (E3), compared to traditional encoding.</p>
<p>Table 1 :
1
[35]ications of Sentence-BERT Models[35]
Specicationall-mpnet-base-v2all-distilroberta-v1all-MiniLM-L6-v2Base Modelmicrosoft/mpnet-basedistilroberta-basenreimers/MiniLM-L6-H384-uncasedDimensions768768384Size (MB)42029080PoolingMean PoolingMean PoolingMean PoolingAverage Performance63.3059.8458.80Speed2800400014200Training Data1B+ sentence pairs1B+ sentence pairs1B+ sentence pairs
a binary classication challenge, ensuring an even distribution of anomaly types in our train/test split.</p>
<p>Table 2 :
2
Congurations of Neural Network Models
ANNDNN1DNN2Hidden layers133 + 2 DropoutNeurons per layer64256, 128, 64256, 128, 64Dropout rate--0.5Activation functionReLUReLUReLUOutput activationSigmoidSigmoidSigmoid</p>
<p>Table 3 :
3
ML model scores across various embeddings
all-MiniLM-L6-v2all-distilroberta-v1all-mpnet-base-v2ModelTNFN FP TP Recall_AMTNFNFPTP Recall_AMTNFN FP TP Recall_AMLogistic Regression380908210.99903792125200.9729380819200.9750Random Forest3805312180.92703788229190.94863785132200.9720XGBoost3788329180.92483789128200.97253804213190.9507Support Vector Machines 381552160.8807381562150.85693801216190.9503Neural Networks3756061210.992036480169210.97793740077210.9899</p>
<p>A nancial fraud detection model based on LSTM deep learning technique. Yara Alghofaili, Albatul Albattah, Murad A Rassam, Journal of Applied Security Research. 152020. 2020</p>
<p>Financial Fraud Detection Applying Data Mining Techniques: A Comprehensive Review from. A Alhashedi, 10.1016/j.cosrev.2021.100402Computer Science Review. 401004022021. 2009 to 2019. 2021</p>
<p>Data augmentation for sample ecient and robust document ranking. Abhijit Anand, Jurek Leonhardt, Jaspreet Singh, Koustav Rudra, Avishek Anand, ACM Transactions on Information Systems. 2023. 2023</p>
<p>Intelligent fraud detection in nancial statements using machine learning and data mining: a systematic literature review. N Matin, Bijan Ashtiani, Raahemi, IEEE Access. 102021. 2021</p>
<p>Fraud analytics using descriptive, predictive, and social network techniques : a guide to data science for fraud detection. V Vlasselaer, B Baesens, W Verbeke, 2015WileyNew York</p>
<p>Detecting anomalies in nancial data using machine learning algorithms. Alexander Bakumenko, Ahmed Elragal, Systems. 101302022. 2022</p>
<p>A Case Study of Clusterbased and Histogram-based Multivariate Anomaly Detection Approach in General Ledgers. Seila Becirovic, Emir Zunic, Dzenana Donko, 2020 19th International Symposium Infoteh-Jahorina (INFOTEH). IEEE2020</p>
<p>Accounting Information Systems: Tradition and Future Directions. F Belfo, Trigo, Procedia Technology. 92013. 2013</p>
<p>Representation learning: A review and new perspectives. Yoshua Bengio, Aaron Courville, Pascal Vincent, 2013. 201335</p>
<p>Random forests. Leo Breiman, Machine learning. 452001. 2001</p>
<p>Ai in nance: challenges, techniques, and opportunities. Longbing Cao, ACM Computing Surveys (CSUR). 552022. 2022</p>
<p>Xgboost: A scalable tree boosting system. Tianqi Chen, Carlos Guestrin, Proceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining. the 22nd acm sigkdd international conference on knowledge discovery and data mining2016</p>
<p>CatBoost for fraud detection in nancial transactions. Yeming Chen, Xinyuan Han, 2021 IEEE International Conference on Consumer Electronics and Computer Engineering (ICCECE). IEEE2021</p>
<p>Exploring the potential of large language models (llms) in learning on graphs. Zhikai Chen, Haitao Mao, Hang Li, Wei Jin, Hongzhi Wen, Xiaochi Wei, Shuaiqiang Wang, Dawei Yin, Wenqi Fan, Hui Liu, arXiv:2307.033932023. 2023arXiv preprint</p>
<p>Support-vector networks. Corinna Cortes, Vladimir Vapnik, Machine learning. 201995. 1995</p>
<p>Hugging Face. 2023. Model Hub. </p>
<p>Greedy function approximation: a gradient boosting machine. Jerome H Friedman, Annals of statistics. 2001. 2001</p>
<p>Why 70/30 or 80/20 relation between training and testing sets: A pedagogical explanation. Afshin Gholamy, Vladik Kreinovich, Olga Kosheleva, 2018. 2018</p>
<p>Deep learning. Ian Goodfellow, Yoshua Bengio, Aaron Courville, 2016MIT press</p>
<p>A survey on large language models: Applications, challenges, limitations, and practical usage. Rizwan Muhammad Usman Hadi, Abbas Qureshi, Muhammad Shah, Anas Irfan, Muhammad Zafar, Naveed Bilal Shaikh, Jia Akhtar, Seyedali Wu, Mirjalili, Authorea Preprints. 2023. 2023</p>
<p>James A Hall, Accounting Information Systems. Ohio2008South-Western</p>
<p>Financial Fraud: A Review of Anomaly Detection Techniques and Recent Advances. Waleed Hilal, S Andrew Gadsden, John Yawney, 10.1016/j.eswa.2021.116429Expert Systems with Applications. 1931164292022. 2022</p>
<p>Applied logistic regression. David W HosmerJr, Stanley Lemeshow, Rodney X Sturdivant, 2013John Wiley &amp; Sons398</p>
<p>International Standards on Auditing 240, The Auditor's Responsibilities Relating to Fraud in an Audit of Financial Statements. 2018IFAC</p>
<p>Evaluating Embeddings from Pre-Trained Language Models and Knowledge Graphs for Educational Content Recommendation. Xiu Li, Aron Henriksson, Martin Duneld, Jalal Nouri, Yongchao Wu, Future Internet. 16122023. 2023</p>
<p>Large Language Models in Finance: A Survey. Yinheng Li, Shaofei Wang, Han Ding, Hang Chen, Proceedings of the Fourth ACM International Conference on AI in Finance. the Fourth ACM International Conference on AI in Finance2023</p>
<p>Quantitative Detection of Financial Fraud Based on Deep Learning with Combination of E-Commerce Big Data. Jian Liu, Xin Gu, Chao Shang, Complexity. 20202020. 2020</p>
<p>Leveraging pre-trained bert for audio captioning. Xubo Liu, Xinhao Mei, Qiushi Huang, Jianyuan Sun, Jinzheng Zhao, Haohe Liu, Mark D Plumbley, Volkan Kilic, Wenwu Wang, 2022 30th European Signal Processing Conference (EUSIPCO). IEEE2022</p>
<p>Financial Fraud Detection in Healthcare Using Machine Learning and Deep Learning Techniques. Abolfazl Mehbodniya, Izhar Alam, Sagar Pande, Rahul Neware, Kantilal Pitambar Rane, Mohammad Shabaz, Mangena Venu Madhavan, Chinmay Chakraborty, 10.1155/2021/9293877Sec. and Commun. Netw. 82021. 2021. jan 2021</p>
<p>Frozen Transformers in Language Models Are Eective Visual Encoder Layers. Ziqi Pang, Ziyang Xie, Yunze Man, Yu-Xiong Wang, arXiv:2310.129732023. 2023arXiv preprint</p>
<p>Credit Card Analytics: A Review of Fraud Detection and Risk Assessment Techniques. Kaushikkumar Patel, International Journal of Computer Trends and Technology. 712023. 2023</p>
<p>Scholarly text classication with sentence BERT and entity embeddings. Guangyuan Piao, ; Wspa, Sdpra Mlmein, Darai , Trends and Applications in Knowledge Discovery and Data Mining: PAKDD 2021 Workshops. Delhi, IndiaSpringer2021. May 11, 2021 Proceedings 25</p>
<p>On the dangers of crossvalidation. An experimental evaluation. Bharat Rao, Glenn Fung, Romer Rosales, Proceedings of the 2008 SIAM international conference on data mining. SIAM. the 2008 SIAM international conference on data mining. SIAM2008</p>
<p>Nils Reimers, Iryna Gurevych, arXiv:1908.10084Sentence-bert: Sentence embeddings using siamese bert-networks. 2019. 2019arXiv preprint</p>
<p>SBERT.net. 2023. Sentence-Transformers -Pretrained Models. </p>
<p>M Schultz, M Tropmann-Frick, Autoencoder Neural Networks versus External Auditors: Detecting Unusual Journal Entries in Financial Statement Audits. 53rd Hawaii International Conference on System Sciences. 2020. 2020</p>
<p>T W Singleton, A J Singleton, Fraud Auditing and Forensic Accounting. New YorkWiley20104th Edition</p>
<p>A structured review and theme analysis of nancial frauds in the banking industry. Pallavi Sood, Puneet Bhushan, Asian Journal of Business Ethics. 92020. 2020</p>
<p>Dimitrios Vamvourellis, Máté Toth, Snigdha Bhagat, Dhruv Desai, Dhagash Mehta, Stefano Pasquali, arXiv:2308.08031Company Similarity using Large Language Models. 2023. 2023arXiv preprint</p>
<p>Abnormal nancial transaction detection via AI technology. Zhuo Wang, International Journal of Distributed Systems and Technologies (IJDST). 122021. 2021</p>
<p>Jason Wei, Yi Tay, Rishi Bommasani, Colin Rael, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, arXiv:2206.07682Emergent abilities of large language models. 2022. 2022arXiv preprint</p>
<p>Xujiang Zhao, Jiaying Lu, Chengyuan Deng, Can Zheng, Junxiang Wang, Tanmoy Chowdhury, Li Yun, Hejie Cui, Zhang Xuchao, Tianjiao Zhao, arXiv:2305.18703Domain specialization as the key to make large language models disruptive: A comprehensive survey. 2023. 2023arXiv preprint</p>
<p>Intelligent nancial fraud detection practices in post-pandemic era. Xiaoqian Zhu, Xiang Ao, Zidi Qin, Yanpeng Chang, Yang Liu, Qing He, Jianping Li, The Innovation. 242021. 2021</p>
<p>Journal entry anomaly detection model. Intelligent Systems in Accounting. Mario Zupan, Verica Budimir, Svjetlana Letinic, Finance and Management. 272020. 2020</p>            </div>
        </div>

    </div>
</body>
</html>