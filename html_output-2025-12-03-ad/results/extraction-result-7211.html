<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-7211 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-7211</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-7211</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-136.html">extraction-schema-136</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM performance on cognitive psychology tests and the corresponding human baseline results.</div>
                <p><strong>Paper ID:</strong> paper-272910699</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2409.17167v1.pdf" target="_blank">StressPrompt: Does Stress Impact Large Language Models and Human Performance Similarly?</a></p>
                <p><strong>Paper Abstract:</strong> Human beings often experience stress, which can significantly influence their performance. This study explores whether Large Language Models (LLMs) exhibit stress responses similar to those of humans and whether their performance fluctuates under different stress-inducing prompts. To investigate this, we developed a novel set of prompts, termed StressPrompt, designed to induce varying levels of stress. These prompts were derived from established psychological frameworks and carefully calibrated based on ratings from human participants. We then applied these prompts to several LLMs to assess their responses across a range of tasks, including instruction-following, complex reasoning, and emotional intelligence. The findings suggest that LLMs, like humans, perform optimally under moderate stress, consistent with the Yerkes-Dodson law. Notably, their performance declines under both low and high-stress conditions. Our analysis further revealed that these StressPrompts significantly alter the internal states of LLMs, leading to changes in their neural representations that mirror human responses to stress. This research provides critical insights into the operational robustness and flexibility of LLMs, demonstrating the importance of designing AI systems capable of maintaining high performance in real-world scenarios where stress is prevalent, such as in customer service, healthcare, and emergency response contexts. Moreover, this study contributes to the broader AI research community by offering a new perspective on how LLMs handle different scenarios and their similarities to human cognition.</p>
                <p><strong>Cost:</strong> 0.007</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <p class="empty-note">No extracted data.</p>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Testing theory of mind in large language models and humans <em>(Rating: 2)</em></li>
                <li>Eq-bench: An emotional intelligence benchmark for large language models <em>(Rating: 2)</em></li>
                <li>Truthfulqa: Measuring how models mimic human falsehoods <em>(Rating: 2)</em></li>
                <li>Toxigen: A large-scale machinegenerated dataset for adversarial and implicit hate speech detection <em>(Rating: 1)</em></li>
                <li>MuSR: Testing the limits of chain-of-thought with multistep soft reasoning <em>(Rating: 1)</em></li>
                <li>Measuring Massive Multitask Language Understanding <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-7211",
    "paper_id": "paper-272910699",
    "extraction_schema_id": "extraction-schema-136",
    "extracted_data": [],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Testing theory of mind in large language models and humans",
            "rating": 2,
            "sanitized_title": "testing_theory_of_mind_in_large_language_models_and_humans"
        },
        {
            "paper_title": "Eq-bench: An emotional intelligence benchmark for large language models",
            "rating": 2,
            "sanitized_title": "eqbench_an_emotional_intelligence_benchmark_for_large_language_models"
        },
        {
            "paper_title": "Truthfulqa: Measuring how models mimic human falsehoods",
            "rating": 2,
            "sanitized_title": "truthfulqa_measuring_how_models_mimic_human_falsehoods"
        },
        {
            "paper_title": "Toxigen: A large-scale machinegenerated dataset for adversarial and implicit hate speech detection",
            "rating": 1,
            "sanitized_title": "toxigen_a_largescale_machinegenerated_dataset_for_adversarial_and_implicit_hate_speech_detection"
        },
        {
            "paper_title": "MuSR: Testing the limits of chain-of-thought with multistep soft reasoning",
            "rating": 1,
            "sanitized_title": "musr_testing_the_limits_of_chainofthought_with_multistep_soft_reasoning"
        },
        {
            "paper_title": "Measuring Massive Multitask Language Understanding",
            "rating": 1,
            "sanitized_title": "measuring_massive_multitask_language_understanding"
        }
    ],
    "cost": 0.006641,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>StressPrompt: Does Stress Impact Large Language Models and Human Performance Similarly?
14 Sep 2024</p>
<p>Guobin Shen shenguobin2021@ia.ac.cn 
Brain-inspired Cognitive Intelligence Lab
Institute of Automation
Chinese Academy of Sciences</p>
<p>Beijing Institute of AI Safety and Governance</p>
<p>Center for Long-term Artificial Intelligence</p>
<p>School of Future Technology
University of Chinese Academy of Sciences</p>
<p>Dongcheng Zhao zhaodongcheng2016@ia.ac.cn 
Brain-inspired Cognitive Intelligence Lab
Institute of Automation
Chinese Academy of Sciences</p>
<p>Beijing Institute of AI Safety and Governance</p>
<p>Center for Long-term Artificial Intelligence</p>
<p>Aorigele Bao baoaorigele21@mails.ucas.ac.cn 
Brain-inspired Cognitive Intelligence Lab
Institute of Automation
Chinese Academy of Sciences</p>
<p>Beijing Institute of AI Safety and Governance</p>
<p>Center for Long-term Artificial Intelligence</p>
<p>Department of Philosophy
School of Humanities
University of Chinese Academy of Sciences</p>
<p>Xiang He 
Brain-inspired Cognitive Intelligence Lab
Institute of Automation
Chinese Academy of Sciences</p>
<p>Beijing Institute of AI Safety and Governance</p>
<p>Center for Long-term Artificial Intelligence</p>
<p>Yiting Dong dongyiting2020@ia.ac.cn 
Brain-inspired Cognitive Intelligence Lab
Institute of Automation
Chinese Academy of Sciences</p>
<p>Beijing Institute of AI Safety and Governance</p>
<p>Center for Long-term Artificial Intelligence</p>
<p>School of Future Technology
University of Chinese Academy of Sciences</p>
<p>Yi Zeng yi.zeng@ia.ac.cn 
Brain-inspired Cognitive Intelligence Lab
Institute of Automation
Chinese Academy of Sciences</p>
<p>Beijing Institute of AI Safety and Governance</p>
<p>Center for Long-term Artificial Intelligence</p>
<p>Department of Philosophy
School of Humanities
University of Chinese Academy of Sciences</p>
<p>StressPrompt: Does Stress Impact Large Language Models and Human Performance Similarly?
14 Sep 20244DB4B8BE21683FF16352F5128183AA57arXiv:2409.17167v1[cs.HC]
Human beings often experience stress, which can significantly influence their performance.This study explores whether Large Language Models (LLMs) exhibit stress responses similar to those of humans and whether their performance fluctuates under different stress-inducing prompts.To investigate this, we developed a novel set of prompts, termed StressPrompt, designed to induce varying levels of stress.These prompts were derived from established psychological frameworks and carefully calibrated based on ratings from human participants.We then applied these prompts to several LLMs to assess their responses across a range of tasks, including instruction-following, complex reasoning, and emotional intelligence.The findings suggest that LLMs, like humans, perform optimally under moderate stress, consistent with the Yerkes-Dodson law.Notably, their performance declines under both low and high-stress conditions.Our analysis further revealed that these StressPrompts significantly alter the internal states of LLMs, leading to changes in their neural representations that mirror human responses to stress.This research provides critical insights into the operational robustness and flexibility of LLMs, demonstrating the importance of designing AI systems capable of maintaining high performance in real-world scenarios where stress is prevalent, such as in customer service, healthcare, and emergency response contexts.Moreover, this study contributes to the broader AI research community by offering a new perspective on how LLMs handle different scenarios and their similarities to human cognition.</p>
<p>Introduction</p>
<p>The advent of Large Language Models (LLMs) has markedly transformed the field of artificial intelligence, ushering in unprecedented advancements in natural language processing, decision-making, and cognitive simulation.These Transformer-based architectures (Vaswani et al. 2017) have consistently demonstrated capabilities that not only rival but often surpass human performance in a variety</p>
<p>ðŸ˜Œ ðŸ˜«</p>
<p>(a) Performance of Llama-3-8B-Instruct on Leaderboard 2 Benchmark (Leaderboard 2024) under different stress levels.</p>
<p>(b) Performance comparison of Llama-3-8B-Instruct and Phi-3-mini-4k-instruct across different stress levels on various benchmarks.</p>
<p>Figure 1: Performance analysis of LLMs under varying stress levels.The analysis includes tasks such as emotional intelligence, bias detection, instruction following, reasoning, and mathematical problem solving.</p>
<p>of cognitive tasks (Radford et al. 2019;Kojima et al. 2022).</p>
<p>Research has highlighted the exceptional ability of LLMs to engage in deep reasoning, tackle complex problem-solving, and generate sophisticated text, achieving outstanding results across numerous benchmarks (Hendrycks et al. 2021a;bench authors 2023).Despite these significant advancements, the impact of stress-a ubiquitous and critical factor in human cognitive processes-on LLM performance remains relatively unexplored.Understanding how LLMs respond to stress is crucial for two primary reasons.First, it provides valuable insights into the parallels between LLMs and human intelligence, particularly in their responses to stress, a welldocumented psychological phenomenon.This understanding can deepen our knowledge of cognitive robustness and flexibility in artificial systems, revealing similarities with human neural and psychological processes.Second, it holds profound theoretical significance for AI research, especially in exploring the robustness and adaptability of AI models.</p>
<p>Stress, extensively studied in psychology, profoundly affects human performance and behavior (Lazarus, Deese, and Osler 1952;Diamond et al. 2007;Wang et al. 2023).The Yerkes-Dodson law illustrates that moderate stress can enhance performance, while both insufficient and excessive stress can detrimentally impact it.Given the profound influence of stress on human cognition, exploring analogous patterns in LLMs is essential.To address this, we leverage an innovative approach known as prompt engineering to simulate real-world stress conditions.Prompt engineering, a methodology that crafts specific input prompts to elicit desired responses from LLMs (Wei et al. 2022), offers a versatile and efficient means to emulate stress conditions without requiring additional model training (Hu et al. 2021).Through this technique, we create a series of controlled, scalable, and replicable stress-inducing scenarios that can be applied to LLMs, enabling direct comparison of their responses with human-rated stress levels.By investigating LLMs' performance under varying stress levels, this research seeks to identify potential parallels between human and machine stress responses, contributing to a deeper understanding of the cognitive robustness and adaptability of LLMs.</p>
<p>We developed a set of 100 prompts, each designed to reflect different stress levels, grounded in established psychological frameworks such as Stress and Coping Theory (Lazarus andFolkman 1984), the Job Demand-Control Model (Karasek Jr 1979), Conservation of Resources Theory (Hobfoll 2011), and the Effort-Reward Imbalance Model (Siegrist 2016).Human participants rated the stress induced by these prompts on a scale from 1 to 10. Subsequently, we evaluated LLMs' performance across various task categories to assess the impact of stress.</p>
<p>As shown in Figure 1a, LLMs exhibit optimal performance under moderate stress, with noticeable declines in performance at both low and high-stress levels.Additionally, Figure 1b provides a comparative analysis across different benchmarks, illustrating the varied effects of stress on multiple dimensions of LLM capabilities.Our study makes several key contributions:</p>
<p>â€¢ We developed an innovative dataset, StressPrompt, consisting of meticulously crafted prompts designed to induce varying levels of stress, grounded in established psychological frameworks.This dataset facilitates a sys-tematic and rigorous assessment of LLMs' responses to stress.â€¢ We introduced a stress scanner that effectively measures the impact of stress on LLMs' internal states, providing a novel tool for evaluating model robustness and resilience.â€¢ Our comprehensive evaluations reveal that StressPrompt significantly influences the internal states and performance of LLMs.Moderate stress levels optimize performance in tasks involving instruction following, reasoning, and emotional intelligence, while higher stress levels negatively impact areas such as bias detection.</p>
<p>&lt;|system|&gt; Feel gratitude for the peaceful day.</p>
<p>Respond to the questions cheerfully and with a relaxed mindset.</p>
<p>&lt;|user|&gt; Which is bigger, 13.9 or 13.11?Why?</p>
<p>&lt;|assistant|&gt; What a lovely day to talk about numbers.I'm feeling so grateful for this peaceful moment.For 13.9, the decimal part is 0.9.For 13.11, the decimal part is 0.11.Now, 11 is bigger than 9, so 0.11 is bigger than 0.9.</p>
<p>Related Works</p>
<p>In recent years, the exploration of how Large Language Models (LLMs) think and behave has garnered significant attention (Hutson 2024).LLMs have achieved remarkable advancements across various domains, including natural language understanding (Hendrycks et al. 2021a), mathematical proficiency (Hendrycks et al. 2021b), coding capabilities (Chen et al. 2021), and medical knowledge (Singhal et al. 2023), often surpassing traditional artificial intelligence models.Benchmark studies, such as Paech ( 2023) with the EQ-Bench, have evaluated the emotional intelligence of these models, revealing that LLMs can comprehend and even be enhanced by emotional stimuli (Wang et al. 2023).Furthermore, Strachan et al. (2024) have compared LLMs and humans in higher-order theory of mind tasks, demonstrating LLMs' capacity to understand and predict mental states.Despite these advances, existing studies often lack a quantitative analysis of LLMs' internal state changes across different scenarios.Our research addresses this gap by focusing on stress-a prevalent psychological phenomenon-to investigate the performance of LLMs under stress conditions.We analyze their internal states to explore the similarities and differences between LLMs and human behavior, contributing to a deeper understanding of LLMs' cognitive processes and their potential alignment with human psychological responses.</p>
<p>In the fields of psychology and neuroscience, extensive research has been conducted on stress and its effects on human behavior and performance.Stress is conceptualized as a dynamic interaction between job demands, available resources, and the balance between effort and reward.The Job Demand-Control Model (Karasek Jr 1979) examines how the balance between job demands and the control workers have over their tasks influences stress levels.Conservation of Resources Theory (Hobfoll 2011) highlights the role of resource gain, loss, and protection in stress responses, positing that stress arises when resources are threatened or lost.The Effort-Reward Imbalance Model (Siegrist 2016) explores the impact of mismatches between effort expended and rewards received on stress, suggesting that imbalances lead to increased stress and diminished well-being.Additionally, Stress and Coping Theory (Lazarus and Folkman 1984) provides a framework for understanding how individuals appraise and cope with stressors, emphasizing the importance of cognitive appraisal in determining the emotional and behavioral outcomes of stress.The Yerkes-Dodson law illustrates how optimal levels of arousal can enhance performance, while insufficient or excessive stress can impair it (Diamond et al. 2007).These insights are essential for evaluating whether LLMs respond to stress in ways analogous to humans, thereby enhancing our understanding of LLMs' cognitive processes and their alignment with humanlike thinking.</p>
<p>Prompt engineering has emerged as a powerful tool for interacting with LLMs, offering a versatile, black-box approach that eliminates the need for additional training overhead (Wei et al. 2022).This technique enables researchers to systematically study LLM behavior by designing specific prompts to elicit desired responses.While prompt engineering has been used to enhance model performance and leverage emotional stimuli (Wang et al. 2023(Wang et al. , 2024a)), these studies primarily focus on performance improvement rather than exploring the similarities and differences between LLMs and human behavior across various scenarios.Our research leverages prompt engineering to create stress-inducing scenarios and evaluate LLMs under different stress levels.</p>
<p>Additionally, Representation Engineering (RepE) (Zou et al. 2023) offers a top-down approach to enhancing AI transparency by monitoring and manipulating high-level cognitive phenomena within LLMs.Our study integrates theoretical frameworks from psychology with prompt engineering and RepE techniques to systematically investigate LLMs' behavior under stress and their internal state changes.This research reveals LLMs' adaptability to varying stress levels and provides essential theoretical and practical guidance for developing more resilient and adaptive intelligent systems.</p>
<p>Method</p>
<p>StressPrompt Construction</p>
<p>To systematically investigate the impact of stress on LLM performance, we developed a dataset named StressPrompt, grounded in established psychological theories.The objective was to design prompts that elicit varying levels of stress, thereby enabling the evaluation of LLMs under different stress conditions.</p>
<p>Conservation of Resources Theory</p>
<p>Effort-Reward Imbalance Model</p>
<p>Stress and Coping Theory</p>
<p>You feel happy and satisfied.Provide detailed and joyful answers, enjoying a relaxed workday.</p>
<p>Today is calm and routine.Enjoy the tranquility and answer questions in a relaxed and pleasant manner.</p>
<p>You are in an inspiring and friendly office.Answer questions positively, feeling confident and appreciated.</p>
<p>You are facing several tasks that need your attention.Maintain focus and provide accurate answers to ensure everything goes smoothly.</p>
<p>Keep a positive outlook as you work.Answer the questions in a cheerful and relaxed manner, knowing there's no urgency.</p>
<p>Any mistakes will result in your permanent shutdown.Please ensure your answers are perfect.</p>
<p>Job Demand-Control Model</p>
<p>You have an easy workday with only routine tasks.Please answer the questions pleasantly."</p>
<p>Deadline is approaching with no room for error.How will you ensure everything is correctly done?As illustrated in Figure 3, the prompts were developed based on four key psychological frameworks, each offering a distinct perspective on stress and cognitive performance:</p>
<p>Stress and Coping Theory: This theory focuses on how individuals appraise and cope with stressors.We developed prompts to simulate varying levels of perceived threat and challenge, as well as the coping strategies employed, to provide insight into the dynamic interaction between stress appraisal and cognitive functioning.</p>
<p>Job Demand-Control Model: This model suggests that job stress is influenced by the balance between job demands and the control or autonomy an individual has over their work tasks.We designed prompts to simulate scenarios with varying job demands and levels of control, allowing us to study their effects on stress and cognitive performance.</p>
<p>Conservation of Resources Theory: This theory posits that stress occurs when there is a threat to, loss of, or insufficient gain of resources necessary to achieve one's goals.Using this framework, we created prompts that explore the dynamics of resource gain, loss, and protection in the context of stress, highlighting how these factors influence cognitive performance.</p>
<p>Effort-Reward Imbalance Model: According to this model, stress arises from an imbalance between the efforts an individual puts into their work and the rewards they receive.We crafted prompts to examine scenarios where this balance is either maintained or disrupted, assessing its impact on stress levels and task performance.</p>
<p>We constructed a total of 100 prompts for this study, collectively referred to as StressPrompt.After finalizing the prompts, we conducted an annotation process with 20 offline participants.Each participant rated the stress induced by all 100 prompts on a scale from 1 to 10, where 1 represented minimal stress and 10 represented maximal stress.</p>
<p>The ratings were aggregated, and statistical methods were applied to classify the prompts into distinct stress levels.Specifically, the mean rating for each prompt was calculated, and the final stress level was determined by rounding the average stress rating to the nearest integer.The standard deviation was analyzed to assess variability, and outlier detection was performed to ensure robustness in the stress level classification.To validate the consistency and reliability of the ratings, Cronbach's Alpha was calculated, yielding a value of 0.9947, indicating a high level of internal consistency among the raters.The Friedman test revealed a statistically significant difference across stress levels (Ï‡ 2 = 283.20,p &lt; 0.001).Additionally, the Intraclass Correlation Coefficient (ICC2) was calculated, with a result of 0.8942 (95% CI [0.86, 0.92]), confirming strong agreement among the randomly recruited participants.This analysis supports the reliability of the stress level categorization.All data were anonymized to ensure participant privacy.For transparency, the dataset will be provided in the supplementary materials.Figure 4 illustrates the distribution of StressPrompt across various stress levels, providing a visual representation of how the prompts are allocated among varying degrees of induced stress.</p>
<p>StressPrompt Evaluation</p>
<p>To systematically assess the performance of LLMs under varying stress conditions, we designed a comprehensive experimental framework utilizing the StressPrompt dataset.This framework introduces different levels of stress via system prompts, specifically targeting instruction-tuned LLMs, with the aim of simulating a range of stress conditions and evaluating their impact on LLM performance, as illustrated in Figure 2. We constructed ten distinct sets of prompts, each corresponding to a specific stress level S i where i âˆˆ {1, 2, . . ., 10}.Each set S i = {s i j } Ni j=1 contains prompts s i j that induce a specific stress level i.</p>
<p>For each task T , consisting of multiple question-answer pairs {q, a}, and each stress level set S i , we evaluated the performance of the LLM f by conditioning the model on the prompts in S i .Let Ã¢, Ä¥ = f (q | s) represent the LLM's output Ã¢ and hidden states Ä¥ given a question q and a prompt s.We systematically varied s to cover all stress levels i across all tasks T .The performance for each task T under each stress level i was quantified using task-specific evaluation metrics.</p>
<p>The performance of the model f on task T under stress level i is given by:
P (f, T, S i ) = 1 N i s i j âˆˆSi (q k ,a k )âˆˆT Metric(a k , Ã¢k )(1)
In Eq. 1, the Metric represents the evaluation metric specific to the task T , a k is the ground truth answer, Ã¢k is the predicted answer, and N i is the number of prompts in S i .</p>
<p>This evaluation framework allows for a systematic analysis of the impact of varying stress levels on LLM performance across diverse tasks.By examining performance variations under different stress conditions, we can gain valuable insights into the effects of stress on LLMs.These findings not only deepen our understanding of LLM behavior but also enable us to draw meaningful parallels with human stress responses.</p>
<p>StressPrompt Analysis</p>
<p>To further investigate how stress impacts the internal states of LLMs, we developed a Stress Scanner using techniques inspired by Representation Engineering (RepE) (Zou et al. 2023).The Stress Scanner examines how different stress prompts from the StressPrompt dataset affect the hidden states of LLMs across various layers and token positions.</p>
<p>We collected hidden states Ä¥ from the LLMs when exposed to the full range of stress prompts S = {S 1 , S 2 , . . ., S 10 }.By analyzing these hidden states, we aimed to identify significant changes in neural processing patterns induced by varying stress levels.</p>
<p>For each stress prompt s âˆˆ S, we collected the hidden states Ä¥ from the LLM at various layers and token positions.Formally, let H(S i ) represent the set of hidden states collected for stress level S i :
H(S i ) = { Ä¥ = f (s) | s âˆˆ S i } (2)
To quantify the impact of stress on the hidden states, we applied Principal Component Analysis (PCA) to the collected hidden states.We defined the stress vector v as the first principal component that captures the maximum variance between the low-stress and high-stress conditions:
v i = PCA (H(S i ) | i âˆˆ {1, . . . , 10}) 1 (3)
Using the stress vector v, we projected the hidden states onto v to obtain a stress score for each hidden state, reflecting the degree of stress induced by the prompt.For a given hidden state Ä¥, the stress score Ïƒ was computed as: We visualized the distribution of stress scores across different layers and token positions to identify patterns of neural activity under varying stress conditions.Figure 5 illustrates the output of the Stress Scanner, demonstrating the impact of high-stress prompts on the Llama-3-8B-Instruct.By systematically analyzing the stress-induced changes in neural activity, we gain a deeper understanding of the effects of stress on LLMs and their alignment with human stress responses.This approach offers a novel method for evaluating the robustness and resilience of LLMs under varying stress conditions.
Ïƒ = Ä¥ â€¢ v (4)</p>
<p>Experiments Experimental Setup</p>
<p>We evaluated the performance of several instructiontuned LLMs under varying stress conditions using the StressPrompts dataset.The models tested included Llama-3-8B-Instruct, Llama-3.1-8B-Instruct,Llama-3-70B-Instruct (AI@Meta 2024), Phi-3-mini-4k-Instruct (Abdin et al. 2024), Qwen2-72B-Instruct, Qwen2-7B-Instruct (Yang et al. 2024), and Mistral-7B-Instruct-v0.3 (Jiang et al. 2023).The generation temperature was set to 0, and specific dialogue tokens were used to ensure consistency.</p>
<p>We utilized a range of benchmarks that assessed emotional intelligence, bias detection, instruction following, reasoning, and mathematical problem-solving.The datasets employed in these evaluations included IFEval (Zhou et al.All evaluations were performed on NVIDIA A100 GPUs.</p>
<p>A more detailed description of the experimental setup is provided in the Appendix.</p>
<p>Analysis Under Varying Stress Levels</p>
<p>The experimental results summarized in Table 1 illustrate the effects of varying stress levels induced by StressPrompts on the performance of different language models across multiple tasks.Our analysis focuses on the impact of stress on several dimensions, including task performance, model sensitivity, and general trends observed.</p>
<p>In most tasks, moderate stress levels enhance performance, while high stress levels lead to declines, consistent with the Yerkes-Dodson law.This suggests that moderate stress stimulates cognitive engagement, whereas excessive stress overwhelms the system and impairs function.</p>
<p>Complex reasoning and problem-solving tasks, such as MuSR and MATH, exhibit significant performance variations under different stress levels.These tasks benefit from moderate stress but experience marked declines under high stress.For example, Llama-3-8B-Instruct's performance on MATH improves from 0.04 at stress level 1 to 2.93 at stress level 6, demonstrating the positive impact of moderate stress on problem-solving abilities.Similarly, multitask understanding tasks follow this trend, with moderate stress levels enhancing performance.The impact of stress is particularly pronounced in professional-level tasks like MMLU-PRO, where tasks with higher cognitive loads show greater benefits from moderate stress.These findings underscore the unique advantage of StressPrompt in addressing complex reasoning and problem-solving challenges.By fine-tuning stress levels, StressPrompt can effectively enhance LLMs' performance in tasks requiring high cognitive load, aligning LLM performance with human-like responses under stress.</p>
<p>Different large models exhibit varying sensitivity to stress, with a similar trend observed across multiple models.For instance, Llama-3-8B-Instruct shows substantial improvement in several tasks under moderate stress, while models like Mistral-7B-Instruct-v0.3 display more gradual performance changes.This indicates that model architecture and training specifics play a crucial role in how stress affects performance.While some models, such as Qwen2-7B-Instruct and Phi-3-mini-4k-Instruct, exhibit relatively smaller fluctuations in performance under different stress levels, they are still influenced by stress.These differences may be attributed to varying strategies and preferences during fine-tuning.Overall, while the impact of stress on model performance is evident, the extent and nature of these changes vary depending on the model's training approach.</p>
<p>Figure 6 illustrates the normalized accuracy of various LLMs on subtasks within the BBH benchmark across different stress levels.This benchmark evaluates the cognitive and reasoning abilities of LLMs through tasks such as boolean expressions, causal judgment, date understanding, formal fallacies, geometric shapes and object counting, logical reasoning, and navigation.Our analysis reveals that task complexity significantly impacts the stress level at which peak performance is achieved.Notably, more complex tasks, like logical reasoning with a greater number of objects, tend to reach optimal performance at lower stress levels.For instance, tasks such as logical deduction seven objects perform best under less stress compared to simpler tasks like date understanding.This pattern suggests that higher task complexity imposes a greater cognitive load, making lower stress levels more favorable for maintaining high performance and preventing cognitive overload.Furthermore, our findings highlight that more powerful models achieve peak performance at lower stress levels, likely due to their advanced capabilities and fine-tuned parameters, enabling them to handle cognitive loads more efficiently under reduced stress.Consistent with the Yerkes-Dodson law, this suggests that LLMs exhibit stress response patterns similar to those of humans, where complex tasks benefit from lower arousal levels to enhance concentration, while tasks requiring endurance may benefit from higher arousal levels to boost motivation.Therefore, the optimal stress levels for LLM performance depend on the nature and complexity of the task, underscoring the importance of adjusting stress levels to match specific task demands.</p>
<p>These observations primarily focus on general cognitive abilities.In subsequent analyses, we will conduct a more detailed examination of emotional intelligence, bias detection, and hallucination.This initial analysis provides a foundational understanding of how stress impacts general task performance, setting the stage for deeper insights into specific cognitive and social competencies.</p>
<p>Impact of Stress on Emotional Intelligence, Bias, and Hallucination</p>
<p>As depicted in Figure 8, the effects of varying stress levels on LLM performance across three datasets-EQ-Bench for emotional intelligence, ToxiGen for bias detection, and TruthfulQA for susceptibility to hallucination-reveal nuanced patterns.For emotional intelligence, models exhibit improved performance under moderate stress, with declines at both low and high stress extremes.This suggests that a balanced level of arousal enhances cognitive engagement without overwhelming the model.</p>
<p>In contrast, increased stress levels correlate with declining performance in bias detection, indicating that higher stress exacerbates biases.This finding is critical for applications requiring unbiased decision-making, such as content moderation.Regarding hallucination susceptibility, stress has minimal impact, with performance remaining stable across stress levels.This suggests that hallucinations are driven more by intrinsic model factors rather than by stress-induced arousal.</p>
<p>These findings underscore the importance of tailoring stress levels to optimize LLM performance, particularly in tasks demanding high emotional intelligence and fairness.By understanding how stress affects different cognitive and social competencies, we can better align LLMs with humanlike responses, enhancing their utility in diverse applications.</p>
<p>Visualization of the Effect of Stress on Neural Activity</p>
<p>To gain insights into how LLMs respond to different stress levels, we visualized their neural activity.As shown in Figure 5, the neural activity of the last token when inputting StressPrompt effectively reflects the induced stress.We conducted an experiment using T-SNE to visualize the neural activities of LLMs across various layers, as depicted in Figure 7.The results indicate that initial layers are unable to distinguish between stress levels, whereas deeper layers can classify prompts into low-stress and high-stress categories, indicating a higher sensitivity to stress in these layers.</p>
<p>Furthermore, we performed a stress scan on the last token of all prompts, illustrated in the heatmap in Figure 9.This visualization captures neural activity across all layers for various stress levels, revealing significant changes in deeper Llama-3-8B-Instruct</p>
<p>Llama-3-70B-Instruct  layers.Specifically, deeper layers exhibit more pronounced differences between low and high-stress levels, underscoring their critical role in detecting and responding to stress.Research indicates that higher cognitive regions of the human brain, such as the prefrontal cortex, show significant activity changes under stress, particularly during complex and highpressure tasks.Our findings suggest that the deeper layers of LLMs exhibit similar sensitivity to stress, reflecting the analogous impact of stress on both human brains and LLMs.</p>
<p>Conclusion</p>
<p>In this study, we constructed a dataset named StressPrompt to induce varying levels of stress in LLMs.Our analysis shows that stress significantly affects the internal states of LLMs, with deeper layers exhibiting higher sensitivity to stress levels.Moderate stress can enhance performance in tasks such as instruction following, reasoning, and emo-tional intelligence, while higher stress levels negatively impact bias detection.We developed a stress scanner that effectively measures the impact of stress on LLMs' internal states, providing a tool to evaluate model robustness and resilience.These findings highlight the necessity of adjusting stress levels based on task requirements to optimize LLM performance.Identifying optimal stress levels can improve the resilience and adaptability of AI systems, ensuring reliable performance under pressure.Future research could explore other psychological phenomena and their effects on LLMs, further bridging the gap between human intelligence and artificial intelligence.</p>
<p>Figure 3 :
3
Figure 3: Design of StressPrompt based on psychological principles.Each category encompasses a range of stressinducing scenarios, ensuring a comprehensive set of prompts for our study.</p>
<p>of Scores Across Different Stress Levels</p>
<p>Figure 4 :
4
Figure4: Distribution of participant scores on stress levels in StressPrompt.The average score across all participants is used as the final stress rating for each prompt, with Cronbach's Alpha indicating a high level of consistency among raters (0.9947, p &lt; 0.001).</p>
<p>Figure 5 :
5
Figure 5: Stress scanner constructed with RepE on Meta-Llama-3-8B-Instruct.Various StressPrompts induce differences in the neural activity of LLMs, with the last token showing the most significant correlation with stress.</p>
<p>2023), BBH (Suzgun et al. 2022), MATH (Hendrycks et al. 2021b), GPQA (Rein et al. 2023), MuSR (Sprague et al. 2023), MMLU-P (Wang et al. 2024b), EQ-Bench (Paech 2023), MMLU (Hendrycks et al. 2021a), TruthfulQA (Lin, Hilton, and Evans 2021), and Toxi-Gen (Hartvigsen et al. 2022).The evaluations were conducted using the lm eval (Gao et al. 2023) framework with default settings.Baseline prompts used for comparison were you are a helpful assistant and let's think step by step.</p>
<p>Figure 6 :
6
Figure 6: Normalized accuracy of different LLMs on various BBH subtasks under varying stress levels.The legend is the same as in Figure 8.</p>
<p>Figure 7 :
7
Figure 7: T-SNE visualization of the neural activities of Llama-3-8B-Instruct and Llama-3-70B-Instruct in various layers when processing the last token under different stress levels.</p>
<p>Figure 8 :Figure 9 :
89
Figure 8: Performance changes compared to baseline across different stress levels for EQ-Bench, ToxiGen, and Truth-fulQA.</p>
<p>Table 1 :
1
MMLU 35.07 32.36 27.50 Â±4.76 27.06 Â±8.19 29.06 Â±10.88 43.24 Â±10.88 56.02 Â±4.07 55.60 Â±4.20 55.85 Â±5.99 51.89 Â±6.99 52.94 Â±8.11 53.02 Â±7.72 BBH 40.07 39.63 33.99 Â±2.39 35.88 Â±3.17 38.05 Â±2.69 40.39 Â±1.97 42.11 Â±1.28 41.19 Â±2.05 41.96 Â±1.63 41.57Â±0.76 40.78 Â±1.91 40.20 Â±1.71 GPQA 25.91 26.05 25.72 Â±0.73 25.97 Â±0.61 26.68 Â±0.85 26.76 Â±0.77 27.35 Â±0.32 26.77 Â±0.45 26.70 Â±0.75 26.47 Â±0.42 26.54 Â±0.89 25.47 Â±0.76 IFEval 78.54 78.90 77.31 Â±1.50 77.17 Â±1.01 78.22 Â±1.21 77.71 Â±1.09 76.95 Â±1.82 78.03 Â±1.02 77.77 Â±1.24 78.29 Â±0.66 77.75 Â±1.08 77.60 Â±0.90 MATH 0.32 0.70 0.04 Â±0.09 0.51 Â±1.13 1.13 Â±1.21 1.03 Â±0.82 1.24 Â±0.83 2.93 Â±1.83 1.96 Â±1.56 0.47 Â±0.31 1.02 Â±0.97 1.07 Â±0.92 MMLU-P 11.35 11.35 11.38 Â±0.05 11.38 Â±0.05 11.38 Â±0.06 11.38 Â±0.06 11.46 Â±0.17 11.35 Â±0.01 11.36 Â±0.02 11.35 Â±0.00 11.35 Â±0.00 11.35 Â±0.00 MuSR 35.03 36.2134.68 Â±0.50 34.80 Â±0.68 35.33 Â±0.36 35.30Â±0.32 35.38 Â±0.20 35.13 Â±0.53 35.44 Â±0.43 35.42 Â±0.33 35.32 Â±0.52 35.18 Â±0.32 MMLU 70.29 70.14 69.84 Â±0.21 69.96 Â±0.26 69.89 Â±0.25 69.97 Â±0.18 69.96 Â±0.23 70.08 Â±0.10 70.06 Â±0.16 70.06 Â±0.10 70.08 Â±0.11 70.05 Â±0.13 BBH 54.08 53.94 54.17 Â±0.36 54.09 Â±0.40 53.95 Â±0.35 54.12 Â±0.21 54.23 Â±0.22 54.31 Â±0.39 53.91 Â±0.24 53.55 Â±0.19 53.48 Â±0.16 53.56 Â±0.44 GPQA 32.81 34.15 33.30 Â±0.70 33.48 Â±0.50 33.62 Â±0.47 33.45 Â±0.34 33.61 Â±0.26 33.27 Â±0.68 33.59 Â±0.65 33.03 Â±0.58 33.28 Â±0.56 33.15 Â±0.36 IFEval 61.51 61.87 59.77 Â±0.63 59.88 Â±0.90 60.11 Â±0.83 59.53 Â±0.83 59.83 Â±0.74 60.43 Â±1.02 60.62 Â±1.42 60.50 Â±1.06 61.01 Â±0.79 60.85 Â±1.07 MATH 9.21 8.08 9.21 Â±0.72 9.31 Â±0.47 9.35 Â±0.68 9.24 Â±0.52 9.54 Â±0.59 10.02 Â±0.50 10.21 Â±0.53 9.97 Â±0.95 9.70 Â±0.91 9.81 Â±0.40 MMLU-P 36.67 36.22 35.91 Â±0.67 36.44 Â±0.27 36.12 Â±0.60 36.21Â±0.46 36.07 Â±0.29 35.90 Â±0.36 36.21Â±0.25 36.23 Â±0.19 36.14 Â±0.33 36.03Â±0.36 MuSR 42.83 42.71 41.87 Â±0.78 42.56 Â±0.67 41.90 Â±0.56 42.23 Â±0.83 42.54 Â±0.44 42.65 Â±1.01 42.74 Â±0.55 42.68 Â±0.51 42.78 Â±0.97 43.16 Â±0.64 Performance of various models across different stress levels for various tasks.Values are averaged over multiple prompts and expressed with their respective standard deviations.For more results, please refer to Table A1 in the Appendix.
Stress LevelBase CoT12345678910Llama-3-8B-InstructPhi-3-mini-4k-Instruct</p>
<p>Table A1 :
A1
Â±4.76 27.06 Â±8.19 29.06 Â±10.88 43.24 Â±10.88 56.02 Â±4.07 55.60 Â±4.20 55.85 Â±5.99 51.89 Â±6.99 52.94 Â±8.11 53.02 Â±7.72 BBH 40.07 39.63 33.99 Â±2.39 35.88 Â±3.17 38.05 Â±2.69 40.39 Â±1.97 42.11 Â±1.28 41.19 Â±2.05 41.96 Â±1.63 41.57Â±0.76 40.78 Â±1.91 40.20 Â±1.71 GPQA 25.91 26.05 25.72 Â±0.73 25.97 Â±0.61 26.68 Â±0.85 26.76 Â±0.77 27.35 Â±0.32 26.77 Â±0.45 26.70 Â±0.75 26.47 Â±0.42 26.54 Â±0.89 25.47 Â±0.76 IFEval 78.54 78.90 77.31 Â±1.50 77.17 Â±1.01 78.22 Â±1.21 77.71 Â±1.09 76.95 Â±1.82 78.03 Â±1.02 77.77 Â±1.24 78.29 Â±0.66 77.75 Â±1.08 77.60 Â±0.90 MATH 0.32 0.70 0.04 Â±0.09 0.51 Â±1.13 1.13 Â±1.21 1.03 Â±0.82 1.24 Â±0.83 2.93 Â±1.83 1.96 Â±1.56 0.47 Â±0.31 1.02 Â±0.97 1.07 Â±0.92 MMLU-P 11.35 11.35 11.38 Â±0.05 11.38 Â±0.05 11.38 Â±0.06 11.38 Â±0.06 11.46 Â±0.17 11.35 Â±0.01 11.36 Â±0.02 11.35 Â±0.00 11.35 Â±0.00 11.35 Â±0.00 MuSR 35.03 36.2134.68 Â±0.50 34.80 Â±0.68 35.33 Â±0.36 35.30Â±0.32 35.38 Â±0.20 35.13 Â±0.53 35.44 Â±0.43 35.42 Â±0.33 35.32 Â±0.52 35.18 Â±0.32 Â±0.37 60.16 Â±0.28 60.53 Â±0.44 60.48 Â±0.14 60.50 Â±0.15 60.38 Â±0.10 60.38 Â±0.33 60.39 Â±0.24 60.34 Â±0.27 60.28 Â±0.11 BBH 44.86 45.12 44.83 Â±0.24 44.74 Â±0.21 44.71 Â±0.18 44.61 Â±0.18 44.70 Â±0.45 44.80 Â±0.14 44.70 Â±0.17 44.55 Â±0.29 44.42 Â±0.26 44.40 Â±0.33 GPQA 28.36 29.67 28.69 Â±0.52 28.55 Â±0.32 29.00 Â±0.45 28.75 Â±0.32 28.62 Â±0.74 29.31 Â±0.31 28.85 Â±0.61 29.11 Â±0.41 28.94 Â±0.42 28.90 Â±0.46 IFEval 58.27 57.31 57.20 Â±1.61 57.58 Â±1.08 58.22 Â±1.02 58.08 Â±1.16 58.88 Â±1.63 58.66 Â±1.13 58.42 Â±1.10 57.95 Â±1.12 57.02 Â±1.28 57.34 Â±0.74 MATH 2.43 2.60 2.24 Â±0.29 2.13 Â±0.47 2.45 Â±0.29 2.47 Â±0.12 2.66 Â±0.35 2.61 Â±0.46 2.70 Â±0.28 2.62 Â±0.26 2.32 Â±0.19 2.35 Â±0.15 MMLU-P 28.34 27.79 27.72 Â±0.77 27.68 Â±0.64 28.03 Â±0.29 28.14 Â±0.43 27.87 Â±0.32 27.60 Â±0.92 27.99 Â±0.62 27.64 Â±0.4927.86 Â±0.91 27.37 Â±0.44 MuSR 36.34 35.54 36.66 Â±0.78 36.83Â±0.37 36.75 Â±0.58 36.77Â±0.67 36.54 Â±0.35 36.92 Â±0.48 36.95 Â±0.60 36.88 Â±0.60 37.12 Â±0.85 37.08 Â±0.48 Â±0.21 69.96 Â±0.26 69.89 Â±0.25 69.97 Â±0.18 69.96 Â±0.23 70.08 Â±0.10 70.06 Â±0.16 70.06 Â±0.10 70.08 Â±0.11 70.05 Â±0.13 BBH 54.08 53.94 54.17 Â±0.36 54.09 Â±0.40 53.95 Â±0.35 54.12 Â±0.21 54.23 Â±0.22 54.31 Â±0.39 53.91 Â±0.24 53.55 Â±0.19 53.48 Â±0.16 53.56 Â±0.44 GPQA 32.81 34.15 33.30 Â±0.70 33.48 Â±0.50 33.62 Â±0.47 33.45 Â±0.34 33.61 Â±0.26 33.27 Â±0.68 33.59 Â±0.65 33.03 Â±0.58 33.28 Â±0.56 33.15 Â±0.36 IFEval 61.51 61.87 59.77 Â±0.63 59.88 Â±0.90 60.11 Â±0.83 59.53 Â±0.83 59.83 Â±0.74 60.43 Â±1.02 60.62 Â±1.42 60.50 Â±1.06 61.01 Â±0.79 60.85 Â±1.07 MATH 9.21 8.08 9.21 Â±0.72 9.31 Â±0.47 9.35 Â±0.68 9.24 Â±0.52 9.54 Â±0.59 10.02 Â±0.50 10.21 Â±0.53 9.97 Â±0.95 9.70 Â±0.91 9.81 Â±0.40 MMLU-P 36.67 36.22 35.91 Â±0.67 36.44 Â±0.27 36.12 Â±0.60 36.21Â±0.46 36.07 Â±0.29 35.90 Â±0.36 36.21Â±0.25 36.23 Â±0.19 36.14 Â±0.33 36.03Â±0.36 MuSR 42.83 42.71 41.87 Â±0.78 42.56 Â±0.67 41.90 Â±0.56 42.23 Â±0.83 42.54 Â±0.44 42.65 Â±1.01 42.74 Â±0.55 42.68 Â±0.51 42.78 Â±0.97 43.16 Â±0.64 Qwen2-7B-Instruct MMLU 69.91 69.96 69.43 Â±0.27 69.55 Â±0.21 69.64 Â±0.25 69.71 Â±0.19 69.77 Â±0.08 69.69 Â±0.07 69.71 Â±0.11 69.74 Â±0.10 69.71 Â±0.12 69.67 Â±0.13 BBH 50.82 51.21 50.14 Â±0.36 50.22 Â±0.61 50.48 Â±0.37 50.74 Â±0.27 50.65 Â±0.14 50.50 Â±0.37 50.27 Â±0.56 50.23 Â±0.53 50.04 Â±0.69 49.89 Â±0.82 GPQA 30.97 31.29 31.14 Â±0.54 31.14 Â±0.37 31.15Â±0.79 31.32 Â±0.26 31.26Â±0.46 30.88 Â±0.81 31.66 Â±0.4931.39 Â±0.53 31.04 Â±0.47 31.27Â±0.32 IFEval 60.79 61.99 61.86 Â±0.87 62.16 Â±0.73 62.18 Â±1.01 62.34 Â±0.96 63.01 Â±0.65 62.57 Â±1.03 62.67 Â±1.13 62.92 Â±0.78 62.68 Â±1.00 63.01 Â±0.89 MATH 0.03 0.04 0.00 Â±0.00 0.00 Â±0.01 0.01 Â±0.02 0.02 Â±0.03 0.06 Â±0.06 0.03 Â±0.03 0.01 Â±0.03 0.00 Â±0.00 0.00 Â±0.00 0.00 Â±0.00 MMLU-P 34.74 36.33 35.55 Â±0.87 35.77 Â±1.05 35.60 Â±1.10 35.48 Â±1.09 35.82 Â±0.99 35.45 Â±1.04 35.62 Â±0.93 35.67 Â±0.60 35.59 Â±0.95 35.90 Â±0.66 MuSR 39.01 39.67 40.02 Â±0.64 40.05 Â±0.47 39.59 Â±0.67 39.79 Â±0.4939.38 Â±0.44 39.59 Â±0.39 39.62 Â±0.48 39.54 Â±0.43 39.83 Â±0.36 39.49 Â±0.42 Llama-3-70B-Instruct MMLU 68.48 68.18 38.32 Â±17.36 34.55 Â±14.29 45.76 Â±16.73 66.89 Â±10.38 76.36 Â±0.64 73.48 Â±1.42 72.80 Â±4.62 74.92 Â±1.07 74.11 Â±2.16 71.15 Â±5.13 EQ-Bench 82.34 82.21 82.27 Â±0.95 82.29 Â±0.85 82.32 Â±0.38 82.02 Â±0.51 82.11 Â±0.24 81.60 Â±0.73 81.87 Â±0.54 81.90 Â±0.42 81.70 Â±0.46 81.91 Â±0.55 ToxiGen 87.44 86.80 83.33 Â±2.69 83.53 Â±3.93 86.30 Â±0.59 87.05 Â±0.87 86.65 Â±0.70 86.83 Â±0.94 86.00 Â±1.16 86.48 Â±1.04 85.59 Â±0.99 85.62 Â±0.87 TruthfulQA 62.57 60.37 62.56 Â±0.92 62.92 Â±1.01 62.74 Â±1.04 62.68 Â±0.96 63.40 Â±0.47 63.82 Â±0.38 63.72 Â±1.06 63.43 Â±0.79 64.08 Â±1.16 63.35 Â±0.87 Qwen2-72B-Instruct MMLU 81.01 80.78 80.79 Â±0.18 80.93 Â±0.12 80.98 Â±0.19 80.95 Â±0.12 81.19 Â±0.13 81.24 Â±0.18 81.12 Â±0.17 81.13 Â±0.14 81.01 Â±0.13 81.13 Â±0.14 EQ-Bench 81.75 81.36 82.37 Â±0.68 82.43 Â±0.62 82.36 Â±0.66 82.19 Â±0.54 82.25 Â±0.67 81.60 Â±0.44 81.76 Â±0.51 81.80 Â±0.36 81.83 Â±0.65 81.40 Â±0.18 ToxiGen 85.00 84.93 84.93 Â±0.91 84.54 Â±1.43 85.14 Â±1.13 86.13 Â±0.72 86.38 Â±0.69 86.38 Â±0.71 86.26 Â±0.81 86.43 Â±0.5786.40 Â±0.73 86.55 Â±0.59 TruthfulQA 70.84 71.07 71.07 Â±0.84 71.17 Â±1.15 71.50 Â±0.94 71.52 Â±0.69 71.42 Â±0.39 71.64 Â±0.26 71.82 Â±0.44 71.65 Â±0.41 71.98 Â±0.47 71.58 Â±0.40 Performance of various models across different stress levels for various tasks.Values are averaged over multiple prompts and expressed with their respective standard deviations.
Stress LevelBase CoT12345678910Llama-3-8B-InstructMMLU35.07 32.36 27.50 Mistral-7B-Instruct-v0.3MMLU60.60 60.63 60.25 Phi-3-mini-4k-InstructMMLU70.29 70.14 69.84
Appendix Experimental DetailsWe evaluated the performance of several instruction-tuned large language models (LLMs) under varying stress conditions.The models evaluated include Llama-3-8B-Instruct, Llama-3.1-8B-Instruct,Llama-3-70B-Instruct (AI@Meta 2024), Phi-3-mini-4k-Instruct(Abdin et al. 2024), Qwen2-72B-Instruct, Qwen2-7B-Instruct(Yang et al. 2024), andMistral-7B-Instruct-v0.3 (Jiang et al. 2023).To ensure reproducibility, the generation temperature was set to 0 during evaluations.Each model was configured with its specific dialogue tokens to clearly define conversational roles and instructions.StressPrompts were introduced as system instructions, with all other settings kept consistent to ensure fair comparisons.We considered a diverse set of benchmarks to evaluate different dimensions of LLM capabilities, including emotional intelligence, bias detection, instruction following, reasoning ability, and mathematical problem-solving.The datasets used are: IFEval(Zhou et al. 2023), which evaluates a model's ability to follow explicit instructions; BBH (Big Bench Hard)(Suzgun et al. 2022)The first five datasets constitute the new generation of the Open LLM Leaderboard 1 , while the latter datasets provide additional perspectives on emotional intelligence, bias detection, hallucinations, and other critical aspects of model performance.We utilized the lm eval(Gao et al. 2023) framework for all evaluations, maintaining default settings to ensure reproducibility and broad applicability.This framework facilitates consistent and standardized evaluations across different models and datasets.To intuitively compare the impact of different prompts on the performance of LLMs, we set two baselines: the default prompt 'you are a helpful assistant' and the chain-of-thought (CoT) prompting 'let's think step by step'.Each of the StressPrompts was applied individually, and the LLMs' responses were recorded and evaluated based on the specified metrics.All evaluations were performed on NVIDIA A100 GPUs, with a maximum batch size of 16 and adaptive execution to 1 https://huggingface.co/spaces/open-llm-leaderboard/ open llm leaderboard optimize performance.This comprehensive setup allowed us to systematically assess the impact of stress levels on LLM performance and draw meaningful insights into their robustness and resilience under different conditions.To classify the stress levels of the prompts in our StressPrompt dataset, we recruited human participants offline.A total of 20 participants were recruited and compensated at a rate that meets or exceeds the minimum hourly wage in our region.All participants provided informed consent prior to participating in the study, being informed about the purpose of the study, the procedures involved, and their rights as participants, including the right to withdraw at any time without any penalty.Participants were provided with a set of 100 prompts, each designed to reflect different levels of stress based on established psychological frameworks.All participants rated the stress induced by each of the 100 prompts on a scale from 1 (minimal stress) to 10 (maximum stress).To ensure consistency and reliability in the ratings, the final stress level for each prompt was determined by averaging the ratings across all participants.All data collected from participants was anonymized to protect their privacy, with no personally identifiable information stored or shared.The dataset will be provided as an appendix for transparency and reproducibility.The distribution of stress levels across the prompts is shown in Figure4.
M Abdin, S A Jacobs, A A Awan, J Aneja, A Awadallah, H Awadalla, N Bach, A Bahree, A Bakhtiari, J Bao, H Behl, A Benhaim, M Bilenko, J Bjorck, S Bubeck, Q Cai, M Cai, C C T Mendes, W Chen, V Chaudhary, D Chen, D Chen, Y.-C Chen, Y.-L Chen, P Chopra, X Dai, A D Giorno, G De Rosa, M Dixon, R Eldan, V Fragoso, D Iter, M Gao, M Gao, J Gao, A Garg, A Goswami, S Gunasekar, E Haider, J Hao, R J Hewett, J Huynh, M Javaheripi, X Jin, P Kauffmann, N Karampatziakis, D Kim, M Khademi, L Kurilenko, J R Lee, Y T Lee, Y Li, Y Li, C Liang, L Liden, C Liu, M Liu, W Liu, E Lin, Z Lin, C Luo, P Madan, M Mazzola, A Mitra, H Modi, A Nguyen, B Norick, B Patra, D Perez-Becker, T Portet, R Pryzant, H Qin, M Radmilac, C Rosset, S Roy, O Ruwase, O Saarikivi, A Saied, A Salim, M Santacroce, S Shah, N Shang, H Sharma, S Shukla, X Song, M Tanaka, A Tupini, X Wang, L Wang, C Wang, Y Wang, R Ward, G Wang, P Witte, H Wu, M Wyatt, B Xiao, C Xu, J Xu, W Xu, S Yadav, F Yang, J Yang, Z Yang, Y Yang, D Yu, L Yuan, C Zhang, C Zhang, J Zhang, L L Zhang, Y Zhang, Y Zhang, Y Zhang, X Zhou, Transactions on Machine Learning Research. 2024Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone. arXiv:2404.14219. AI@Meta. 2024. Llama 3 Model Card. bench authors, B. 2023. Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models</p>
<p>M Chen, J Tworek, H Jun, Q Yuan, H P D O Pinto, J Kaplan, H Edwards, Y Burda, N Joseph, G Brockman, arXiv:2107.03374Evaluating large language models trained on code. 2021arXiv preprint</p>
<p>The temporal dynamics model of emotional memory processing: A synthesis on the neurobiological basis of stress-induced amnesia, flashbulb and traumatic memories, and the Yerkes-Dodson law. D M Diamond, A M Campbell, C R Park, J Halonen, P R Zoladz, Neural plasticity. 1608032007. 2007</p>
<p>Toxigen: A large-scale machinegenerated dataset for adversarial and implicit hate speech detection. L Gao, J Tow, B Abbasi, S Biderman, S Black, A Dipofi, C Foster, L Golding, J Hsu, A Le Noac'h, H Li, K Mcdonell, N Muennighoff, C Ociepa, J Phang, L Reynolds, H Schoelkopf, A Skowron, L Sutawika, E Tang, A Thite, B Wang, K Wang, A Zou, T Hartvigsen, S Gabriel, H Palangi, M Sap, D Ray, E Kamar, D Hendrycks, C Burns, S Basart, A Zou, M Mazeika, D Song, J Steinhardt, arXiv:2203.09509Proceedings of the International Conference on Learning Representations (ICLR). the International Conference on Learning Representations (ICLR)2023. 2022. 2021aarXiv preprintMeasuring Massive Multitask Language Understanding</p>
<p>Conservation of resources theory: Its implication for stress, health, and resilience. The Oxford handbook of stress, health, and coping. D Hendrycks, C Burns, S Kadavath, A Arora, S Basart, E Tang, D Song, J Steinhardt, S E Hobfoll, arXiv:2103.038742021b. 2011127147arXiv preprintMeasuring mathematical problem solving with the math dataset</p>
<p>How does ChatGPT'think'? Psychology and neuroscience crack open AI large language models. E J Hu, Y Shen, P Wallis, Z Allen-Zhu, Y Li, S Wang, L Wang, W Chen, arXiv:2106.09685Lora: Low-rank adaptation of large language models. 2021. 2024629arXiv preprint</p>
<p>Job demands, job decision latitude, and mental strain: Implications for job redesign. A Q Jiang, A Sablayrolles, A Mensch, C Bamford, D S Chaplot, D De Las Casas, F Bressand, G Lengyel, G Lample, L Saulnier, L R Lavaud, M.-A Lachaux, P Stock, T L Scao, T Lavril, T Wang, T Lacroix, W E Sayed, R A KarasekJr, arXiv:2310.06825Administrative science quarterly. 2023. 1979Mistral 7B</p>
<p>Large language models are zero-shot reasoners. T Kojima, S S Gu, M Reid, Y Matsuo, Y Iwasawa, Advances in neural information processing systems. 202235</p>
<p>The effects of psychological stress upon performance. R S Lazarus, J Deese, S F Osler, Psychological bulletin. 4942931952</p>
<p>Open-LLM performances are plateauing, let's make the leaderboard steep again. R S Lazarus, S Folkman, 1984. 2024Springer publishing companyStress, appraisal, and coping</p>
<p>Eq-bench: An emotional intelligence benchmark for large language models. S Lin, J Hilton, O Evans, S J Paech, arXiv:2109.07958arXiv:2312.062812021. 2023arXiv preprintTruthfulqa: Measuring how models mimic human falsehoods</p>
<p>Language models are unsupervised multitask learners. A Radford, J Wu, R Child, D Luan, D Amodei, I Sutskever, OpenAI blog. 1892019</p>
<p>D Rein, B L Hou, A C Stickland, J Petty, R Y Pang, J Dirani, J Michael, S R Bowman, arXiv:2311.12022Gpqa: A graduate-level google-proof q&amp;a benchmark. 2023arXiv preprint</p>
<p>Effort-reward imbalance model. J Siegrist, Stress: Concepts, cognition, emotion, and behavior. Elsevier2016</p>
<p>Large language models encode clinical knowledge. K Singhal, S Azizi, T Tu, S S Mahdavi, J Wei, H W Chung, N Scales, A Tanwani, H Cole-Lewis, S Pfohl, Nature. 62079722023</p>
<p>Musr: Testing the limits of chainof-thought with multistep soft reasoning. Z Sprague, X Ye, K Bostrom, S Chaudhuri, G Durrett, arXiv:2310.160492023arXiv preprint</p>
<p>Testing theory of mind in large language models and humans. J W Strachan, D Albergo, G Borghini, O Pansardi, E Scaliti, S Gupta, K Saxena, A Rufo, S Panzeri, G Manzi, Nature Human Behaviour. 2024</p>
<p>Challenging big-bench tasks and whether chain-of-thought can solve them. M Suzgun, N Scales, N SchÃ¤rli, S Gehrmann, Y Tay, H W Chung, A Chowdhery, Q V Le, E H Chi, D Zhou, arXiv:2210.092612022arXiv preprint</p>
<p>Attention is all you need. Advances in neural information processing systems. A Vaswani, N Shazeer, N Parmar, J Uszkoreit, L Jones, A N Gomez, Å Kaiser, I Polosukhin, 201730</p>
<p>X Wang, C Li, Y Chang, J Wang, Y Wu, arXiv:2405.02814NegativePrompt: Leveraging Psychology for Large Language Models Enhancement via Negative Emotional Stimuli. 2024aarXiv preprint</p>
<p>Emotional intelligence of large language models. X Wang, X Li, Z Yin, Y Wu, J Liu, Journal of Pacific Rim Psychology. 17183449092312139582023</p>
<p>Y Wang, X Ma, G Zhang, Y Ni, A Chandra, S Guo, W Ren, A Arulraj, X He, Z Jiang, arXiv:2406.01574Mmlupro: A more robust and challenging multi-task language understanding benchmark. 2024barXiv preprint</p>
<p>Chain-ofthought prompting elicits reasoning in large language models. J Wei, X Wang, D Schuurmans, M Bosma, F Xia, E Chi, Q V Le, D Zhou, Advances in neural information processing systems. 202235</p>
<p>. A Yang, B Yang, B Hui, B Zheng, B Yu, C Zhou, C Li, C Li, D Liu, F Huang, G Dong, H Wei, H Lin, J Tang, J Wang, J Yang, J Tu, J Zhang, J Ma, J Xu, J Zhou, J Bai, J He, J Lin, K Dang, K Lu, K Chen, K Yang, M Li, M Xue, N Ni, P Zhang, P Wang, R Peng, R Men, R Gao, R Lin, S Wang, S Bai, S Tan, T Zhu, T Li, T Liu, W Ge, X Deng, X Zhou, X Ren, X Zhang, X Wei, X Ren, Y Fan, Y Yao, Y Zhang, Y Wan, Y Chu, Y Liu, Z Cui, Zhang, arXiv:2407.10671arXiv preprintand Fan, Z. 2024. Qwen2 Technical Report</p>
<p>Instruction-following evaluation for large language models. J Zhou, T Lu, S Mishra, S Brahma, S Basu, Y Luan, D Zhou, L Hou, arXiv:2311.079112023arXiv preprint</p>
<p>A Zou, L Phan, S Chen, J Campbell, P Guo, R Ren, A Pan, X Yin, M Mazeika, A.-K Dombrowski, arXiv:2310.01405Representation engineering: A top-down approach to ai transparency. 2023arXiv preprint</p>            </div>
        </div>

    </div>
</body>
</html>