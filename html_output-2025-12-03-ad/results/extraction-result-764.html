<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-764 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-764</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-764</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-20.html">extraction-schema-20</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <p><strong>Paper ID:</strong> paper-274446165</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2412.01953v2.pdf" target="_blank">The Landscape of Causal Discovery Data: Grounding Causal Discovery in Real-World Applications</a></p>
                <p><strong>Paper Abstract:</strong> Causal discovery aims to automatically uncover causal relationships from data, a capability with significant potential across many scientific disciplines. However, its real-world applications remain limited. Current methods often rely on unrealistic assumptions and are evaluated only on simple synthetic toy datasets, often with inadequate evaluation metrics. In this paper, we substantiate these claims by performing a systematic review of the recent causal discovery literature. We present applications in biology, neuroscience, and Earth sciences - fields where causal discovery holds promise for addressing key challenges. We highlight available simulated and real-world datasets from these domains and discuss common assumption violations that have spurred the development of new methods. Our goal is to encourage the community to adopt better evaluation practices by utilizing realistic datasets and more adequate metrics.</p>
                <p><strong>Cost:</strong> 0.026</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e764.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e764.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CausalWorld</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>CausalWorld: A robotic manipulation benchmark for causal structure and transfer learning</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An interactive robotic-manipulation benchmark / virtual lab designed to study causal structure learning and transfer in manipulation tasks; provides simulated robotic environments where interventions (actions) and counterfactuals can be explored.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Causalworld: A robotic manipulation benchmark for causal structure and transfer learning.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>CausalWorld (benchmark/environment)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>A simulated, interactive robotic-manipulation benchmark intended to evaluate causal structure learning and transfer learning in a virtual lab; offers environments where actions produce interventional data and where agents can perform experiments by applying different controls. The survey only lists it as an example environment for interactive/reinforcement settings and does not evaluate a specific algorithm within it.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>CausalWorld</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>A virtual, interactive robotics environment (robotic manipulation tasks) that supports active interventions and transfer experiments; designed as a benchmark rather than a causal-discovery algorithm; the survey mentions it in the context of causal reinforcement learning and interactive datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Mentioned as an example of an interactive environment suitable for causal/transfer learning; the reviewed paper does not report experiments or analyses using CausalWorld and provides no data about distractor handling or spurious-signal mitigation in that environment.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Landscape of Causal Discovery Data: Grounding Causal Discovery in Real-World Applications', 'publication_date_yy_mm': '2024-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e764.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e764.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Causal Chambers</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Causal Chambers as a real-world physical testbed for AI methodology</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A pair of computer-controlled physical simulators that generate observational and interventional data with experimentally verified ground-truth causal graphs, intended as a real-world testbed for causal methods.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Causal chambers as a real-world physical testbed for ai methodology.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Causal Chambers (physical testbed)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Physically instantiated, computer-controlled simulators that produce both observational and interventional datasets and for which the ground-truth causal graph has been experimentally verified; presented in the survey as a recently proposed dataset/resource for causal discovery evaluation. The survey notes that, because of its recency, few or no causal discovery methods have yet been evaluated on it.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Causal Chambers</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>A physical, interactive experimental platform (real-world, not purely simulated) that allows controlled interventions and yields experimentally validated ground-truth graphs; suitable for testing whether methods are robust to real-world nuisances and spurious correlations.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Survey highlights Causal Chambers as a promising real-world interactive testbed for causal discovery with verified ground-truth graphs, but reports that as of writing no causal-discovery method evaluations on this testbed had been reported.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Landscape of Causal Discovery Data: Grounding Causal Discovery in Real-World Applications', 'publication_date_yy_mm': '2024-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e764.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e764.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Off-target / fat-hand interventions</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Causal discovery under off-target interventions</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A class of methods and analyses that explicitly model and/or correct for interventions that unintentionally affect multiple variables (off-target or 'fat-hand' effects), which produce spurious signals if treated as single-target perfect interventions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Causal discovery under off-target interventions</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Off-target (fat-hand) intervention methods</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Approaches that account for imperfect or multi-target interventions by modeling interventions as possibly affecting multiple variables (unknown/partial target sets) rather than as perfect single-target interventions; survey cites Choo et al. (2024) and Eaton & Murphy (2007) as examples of work addressing this challenge but does not provide algorithmic details in the review.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Biological perturbation datasets / general interventional settings</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Typically applied in biological contexts (e.g., CRISPR knockouts with off-target effects) or any interventional datasets where interventions may be imperfect or affect multiple variables; these settings are interactive in that interventions are performed but the targets are uncertain.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Explicit modeling of interventions as affecting multiple targets / probabilistic modeling of unknown intervention targets (fat-hand intervention models).</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Off-target intervention effects (intervention spillover), imperfect interventions causing spurious dependencies.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Survey flags off-target (fat-hand) interventions as a real-world challenge (notably in biology) and references work (Choo et al., Eaton & Murphy) that explicitly address causal discovery under such imperfect interventions; the review does not report empirical performance numbers.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Landscape of Causal Discovery Data: Grounding Causal Discovery in Real-World Applications', 'publication_date_yy_mm': '2024-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e764.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e764.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Permutation-based falsification</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Toward falsifying causal graphs using a permutation-based test</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A permutation (node-permutation) based statistical testing procedure designed to falsify candidate causal graphs by testing model-implied conditional independencies or predictions against permuted-data baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Toward falsifying causal graphs using a permutation-based test</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Permutation-based falsification test (node-permutation)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>A statistical test that permutes node labels or data to assess whether the conditional independence and/or predictive implications of a learned causal graph are supported by the data; used to reject (falsify) learned graphs that rely on spurious associations. The survey explicitly mentions node-permutation tests (Eulig et al., 2023) as a tool to help refute learned structures.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>General observational or interventional datasets</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Applies generically to datasets where a learned graph implies testable distributional constraints; not tied to a single virtual lab but can be used in simulated or real settings for post-hoc verification/refutation.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Statistical falsification via permutation testing to reveal edges or graphs that depend on spurious signals.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Spurious edges arising from finite-sample artifacts, model misspecification, or unmodeled confounding that render graph implications inconsistent with data.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Node-permutation based hypothesis test: permute nodes/labels to build a null distribution for the graph-implied statistic and compute p-values to reject inconsistent graphs.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Rejects candidate graphs (or specific edges) when permutation-based test statistics indicate the model-implied constraints are incompatible with the observed data.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Survey highlights permutation-based tests as concrete tools to 'falsify' learned causal graphs and thus to detect/refute relationships that stem from spurious signals rather than true causal mechanisms.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Landscape of Causal Discovery Data: Grounding Causal Discovery in Real-World Applications', 'publication_date_yy_mm': '2024-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e764.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e764.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SID</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Structural Interventional Distance</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An evaluation metric that counts how many interventional distributions would be incorrectly computed using the parents from the learned structure as adjustment sets, thereby quantifying how a learned graph would fail in predicting intervention effects.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Structural intervention distance for evaluating causal graphs</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Structural Interventional Distance (SID)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>A structural evaluation metric that, instead of only comparing graph edges, measures how many interventions would produce incorrect interventional predictions if one used the learned graph's parent sets for adjustment; intended to better capture practical utility in the presence of interventions.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>General (applies when interventional data/targets are available)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>An evaluator used on datasets that include interventions or where intervention effects are of interest; not an interactive environment itself but evaluates how models perform under hypothetical or real interventions.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Used as a diagnostic to reveal when learned graphs would produce incorrect intervention effect estimates (thus indirectly identifying models affected by spurious edges).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Survey emphasizes SID as an interventional metric that is more aligned with practitioners' goals than pure structural metrics like SHD; SID can detect when structural correctness does not imply correct intervention predictions, which helps reveal spurious learned relations.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Landscape of Causal Discovery Data: Grounding Causal Discovery in Real-World Applications', 'publication_date_yy_mm': '2024-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e764.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e764.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>I-NLL (interventional NLL)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Interventional Negative Log-Likelihood (I-NLL)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An interventional evaluation metric that measures how well a learned model predicts held-out interventional distributions, typically via negative log-likelihood or other distributional distances.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Evaluating causal models by comparing interventional distributions</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Interventional negative log-likelihood (I-NLL)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Compute the negative log-likelihood (or other distance such as MAE, TV, KL) of held-out interventional data under the learned model's predictive distribution; average over multiple interventions to assess predictive quality under unseen interventions.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>General interventional datasets (e.g., biological perturbation datasets)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Applicable to datasets that include interventional measurements; evaluates models on real or simulated interventional test sets rather than on purely observational held-out data.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>By directly evaluating predictive accuracy on interventions, I-NLL exposes models that rely on spurious correlations that fail to predict interventional distributions.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Poor interventional predictive performance can be used to refute learned causal claims that appear plausible observationally but fail under interventions.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Survey recommends interventional metrics such as I-NLL to assess the real causal utility of learned models, as these metrics can reveal reliance on spurious correlations that structural metrics miss.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Landscape of Causal Discovery Data: Grounding Causal Discovery in Real-World Applications', 'publication_date_yy_mm': '2024-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e764.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e764.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Causally (generator)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Causally (synthetic data generator enabling controlled assumption violations)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A synthetic data generator (referred to as 'Causally' by Montagna et al.) that natively allows explicit control over modeling assumptions (latent confounders, unfaithful paths, etc.) so that causal discovery methods can be stress-tested against realistic assumption violations and spurious artifacts.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Causally (synthetic data generator)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>A simulator that can generate synthetic datasets while explicitly controlling for common assumption violations (presence/absence of latent confounders, unfaithful paths, selection bias, measurement error), enabling more realistic benchmarks and revealing spurious cues exploited by methods trained only on idealized synthetic data.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Synthetic/pseudo-real simulation environment</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Not an interactive environment per se, but a synthetic data generator used to create datasets that mimic real-world violations of causal discovery assumptions for benchmarking; supports generating both i.i.d. and interventional data with controllable nuisances.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Unfaithful paths, latent confounders, measurement noise, model-matched artifacts used by algorithms</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>By creating datasets that include controlled nuisances and artifacts, the generator makes it possible to detect when a method relies on spurious dataset artifacts (e.g., variance sorting) rather than genuine causal signals.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Enables stress tests and comparative evaluations that can refute methods that exploit synthetic artifacts by showing performance degradation under controlled violations.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Survey recommends using generators like 'Causally' to craft benchmarks where common assumptions are violated so that methods that exploit spurious cues are revealed; the paper cites Montagna et al. as an example of improved synthetic benchmarking.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Landscape of Causal Discovery Data: Grounding Causal Discovery in Real-World Applications', 'publication_date_yy_mm': '2024-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e764.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e764.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Variance-sorting artifact / scale-invariant sorting</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Variance-based artifact in synthetic benchmarks; scale-invariant sorting criterion to recover causal order</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Work demonstrating that some synthetic causal benchmarks admit trivial solutions (e.g., sorting variables by variance) that let algorithms recover causal order via spurious statistics, and proposing scale-invariant fixes (sorting criteria) to avoid such artifacts.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Beware of the simulated dag! causal discovery benchmarks may be easy to game.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Variance-sorting detection and scale-invariant sorting correction</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Reisach et al. showed that certain synthetic data generators leak spurious information (e.g., variance differences) that can be used to recover causal order without true causal learning; subsequent work proposed scale-invariant sorting criteria and generator adjustments to remove such trivial cues and produce more realistic benchmarks.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Synthetic benchmark datasets (standard DAG generators)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Applies to commonly used synthetic generators (ErdsRnyi, scale-free, linear-Gaussian mechanisms) where inadvertent artifacts can be introduced; these insights are relevant to anyone using virtual labs or simulators for causal-discovery evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Identification of spurious statistical cues (e.g., variance) and correction via scale-invariant generation or sorting criteria to prevent trivial exploitation.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Artifacts in synthetic generators (variance differences, distributional cues) that act as spurious signals enabling trivial recovery of causal order.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Empirical analysis showing recovery by naive statistics (sorting by variance) and proposing diagnostic checks; propose scale-invariant measures to remove cue.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Demonstrate that algorithms succeed only because of artifact; corrected generators/refined sorting refute conclusions drawn from flawed benchmarks.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Survey cites Reisach et al. to show that naive synthetic datasets can introduce spurious signals which inflate method performance; recommends improved generators or evaluation strategies (scale-invariant criteria) to avoid these artifacts.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Landscape of Causal Discovery Data: Grounding Causal Discovery in Real-World Applications', 'publication_date_yy_mm': '2024-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e764.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e764.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Bacadi</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Bacadi: Bayesian causal discovery with unknown interventions</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A Bayesian causal discovery approach that infers causal structure when interventions are present but their targets are unknown or uncertain, thereby addressing a form of spurious signal introduced by mis-specified intervention targets.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Bacadi: Bayesian causal discovery with unknown interventions</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Bacadi (Bayesian discovery with unknown interventions)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>A probabilistic/Bayesian framework that jointly infers intervention targets (or models uncertainty over targets) and the causal graph, permitting robust structure learning when interventions are imperfectly labeled or their effects are ambiguous; the survey references Hgele et al. (2023) in this context.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Interventional datasets with uncertain / unknown targets (e.g., biological perturbation data)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Applies to datasets where interventions have been performed but the actual targets or exact nature of the intervention are uncertain (common in CRISPR / biological experiments); helps make inference robust to mislabeled or unknown interventions.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Probabilistic modeling of intervention target uncertainty and Bayesian integration over possible intervention-target assignments.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Unknown/uncertain interventions that produce spurious associations if treated as perfectly-targeted; mislabeled or ineffective perturbations.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Survey mentions Bacadi as an example of work that explicitly handles unknown interventions, an important source of spurious signals in real-world interventional datasets, but provides no experimental details in the review.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Landscape of Causal Discovery Data: Grounding Causal Discovery in Real-World Applications', 'publication_date_yy_mm': '2024-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Causal discovery under off-target interventions <em>(Rating: 2)</em></li>
                <li>Toward falsifying causal graphs using a permutation-based test <em>(Rating: 2)</em></li>
                <li>Beware of the simulated dag! causal discovery benchmarks may be easy to game. <em>(Rating: 2)</em></li>
                <li>Bacadi: Bayesian causal discovery with unknown interventions <em>(Rating: 2)</em></li>
                <li>Causalworld: A robotic manipulation benchmark for causal structure and transfer learning. <em>(Rating: 2)</em></li>
                <li>Causal chambers as a real-world physical testbed for ai methodology. <em>(Rating: 2)</em></li>
                <li>Structural intervention distance for evaluating causal graphs <em>(Rating: 2)</em></li>
                <li>Evaluating causal models by comparing interventional distributions <em>(Rating: 2)</em></li>
                <li>A scale-invariant sorting criterion to find a causal order in additive noise models <em>(Rating: 1)</em></li>
                <li>Causally <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-764",
    "paper_id": "paper-274446165",
    "extraction_schema_id": "extraction-schema-20",
    "extracted_data": [
        {
            "name_short": "CausalWorld",
            "name_full": "CausalWorld: A robotic manipulation benchmark for causal structure and transfer learning",
            "brief_description": "An interactive robotic-manipulation benchmark / virtual lab designed to study causal structure learning and transfer in manipulation tasks; provides simulated robotic environments where interventions (actions) and counterfactuals can be explored.",
            "citation_title": "Causalworld: A robotic manipulation benchmark for causal structure and transfer learning.",
            "mention_or_use": "mention",
            "method_name": "CausalWorld (benchmark/environment)",
            "method_description": "A simulated, interactive robotic-manipulation benchmark intended to evaluate causal structure learning and transfer learning in a virtual lab; offers environments where actions produce interventional data and where agents can perform experiments by applying different controls. The survey only lists it as an example environment for interactive/reinforcement settings and does not evaluate a specific algorithm within it.",
            "environment_name": "CausalWorld",
            "environment_description": "A virtual, interactive robotics environment (robotic manipulation tasks) that supports active interventions and transfer experiments; designed as a benchmark rather than a causal-discovery algorithm; the survey mentions it in the context of causal reinforcement learning and interactive datasets.",
            "handles_distractors": null,
            "distractor_handling_technique": null,
            "spurious_signal_types": null,
            "detection_method": null,
            "downweighting_method": null,
            "refutation_method": null,
            "uses_active_learning": null,
            "inquiry_strategy": null,
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "Mentioned as an example of an interactive environment suitable for causal/transfer learning; the reviewed paper does not report experiments or analyses using CausalWorld and provides no data about distractor handling or spurious-signal mitigation in that environment.",
            "uuid": "e764.0",
            "source_info": {
                "paper_title": "The Landscape of Causal Discovery Data: Grounding Causal Discovery in Real-World Applications",
                "publication_date_yy_mm": "2024-12"
            }
        },
        {
            "name_short": "Causal Chambers",
            "name_full": "Causal Chambers as a real-world physical testbed for AI methodology",
            "brief_description": "A pair of computer-controlled physical simulators that generate observational and interventional data with experimentally verified ground-truth causal graphs, intended as a real-world testbed for causal methods.",
            "citation_title": "Causal chambers as a real-world physical testbed for ai methodology.",
            "mention_or_use": "mention",
            "method_name": "Causal Chambers (physical testbed)",
            "method_description": "Physically instantiated, computer-controlled simulators that produce both observational and interventional datasets and for which the ground-truth causal graph has been experimentally verified; presented in the survey as a recently proposed dataset/resource for causal discovery evaluation. The survey notes that, because of its recency, few or no causal discovery methods have yet been evaluated on it.",
            "environment_name": "Causal Chambers",
            "environment_description": "A physical, interactive experimental platform (real-world, not purely simulated) that allows controlled interventions and yields experimentally validated ground-truth graphs; suitable for testing whether methods are robust to real-world nuisances and spurious correlations.",
            "handles_distractors": null,
            "distractor_handling_technique": null,
            "spurious_signal_types": null,
            "detection_method": null,
            "downweighting_method": null,
            "refutation_method": null,
            "uses_active_learning": null,
            "inquiry_strategy": null,
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": false,
            "number_of_distractors": null,
            "key_findings": "Survey highlights Causal Chambers as a promising real-world interactive testbed for causal discovery with verified ground-truth graphs, but reports that as of writing no causal-discovery method evaluations on this testbed had been reported.",
            "uuid": "e764.1",
            "source_info": {
                "paper_title": "The Landscape of Causal Discovery Data: Grounding Causal Discovery in Real-World Applications",
                "publication_date_yy_mm": "2024-12"
            }
        },
        {
            "name_short": "Off-target / fat-hand interventions",
            "name_full": "Causal discovery under off-target interventions",
            "brief_description": "A class of methods and analyses that explicitly model and/or correct for interventions that unintentionally affect multiple variables (off-target or 'fat-hand' effects), which produce spurious signals if treated as single-target perfect interventions.",
            "citation_title": "Causal discovery under off-target interventions",
            "mention_or_use": "mention",
            "method_name": "Off-target (fat-hand) intervention methods",
            "method_description": "Approaches that account for imperfect or multi-target interventions by modeling interventions as possibly affecting multiple variables (unknown/partial target sets) rather than as perfect single-target interventions; survey cites Choo et al. (2024) and Eaton & Murphy (2007) as examples of work addressing this challenge but does not provide algorithmic details in the review.",
            "environment_name": "Biological perturbation datasets / general interventional settings",
            "environment_description": "Typically applied in biological contexts (e.g., CRISPR knockouts with off-target effects) or any interventional datasets where interventions may be imperfect or affect multiple variables; these settings are interactive in that interventions are performed but the targets are uncertain.",
            "handles_distractors": true,
            "distractor_handling_technique": "Explicit modeling of interventions as affecting multiple targets / probabilistic modeling of unknown intervention targets (fat-hand intervention models).",
            "spurious_signal_types": "Off-target intervention effects (intervention spillover), imperfect interventions causing spurious dependencies.",
            "detection_method": null,
            "downweighting_method": null,
            "refutation_method": null,
            "uses_active_learning": null,
            "inquiry_strategy": null,
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "Survey flags off-target (fat-hand) interventions as a real-world challenge (notably in biology) and references work (Choo et al., Eaton & Murphy) that explicitly address causal discovery under such imperfect interventions; the review does not report empirical performance numbers.",
            "uuid": "e764.2",
            "source_info": {
                "paper_title": "The Landscape of Causal Discovery Data: Grounding Causal Discovery in Real-World Applications",
                "publication_date_yy_mm": "2024-12"
            }
        },
        {
            "name_short": "Permutation-based falsification",
            "name_full": "Toward falsifying causal graphs using a permutation-based test",
            "brief_description": "A permutation (node-permutation) based statistical testing procedure designed to falsify candidate causal graphs by testing model-implied conditional independencies or predictions against permuted-data baselines.",
            "citation_title": "Toward falsifying causal graphs using a permutation-based test",
            "mention_or_use": "mention",
            "method_name": "Permutation-based falsification test (node-permutation)",
            "method_description": "A statistical test that permutes node labels or data to assess whether the conditional independence and/or predictive implications of a learned causal graph are supported by the data; used to reject (falsify) learned graphs that rely on spurious associations. The survey explicitly mentions node-permutation tests (Eulig et al., 2023) as a tool to help refute learned structures.",
            "environment_name": "General observational or interventional datasets",
            "environment_description": "Applies generically to datasets where a learned graph implies testable distributional constraints; not tied to a single virtual lab but can be used in simulated or real settings for post-hoc verification/refutation.",
            "handles_distractors": true,
            "distractor_handling_technique": "Statistical falsification via permutation testing to reveal edges or graphs that depend on spurious signals.",
            "spurious_signal_types": "Spurious edges arising from finite-sample artifacts, model misspecification, or unmodeled confounding that render graph implications inconsistent with data.",
            "detection_method": "Node-permutation based hypothesis test: permute nodes/labels to build a null distribution for the graph-implied statistic and compute p-values to reject inconsistent graphs.",
            "downweighting_method": null,
            "refutation_method": "Rejects candidate graphs (or specific edges) when permutation-based test statistics indicate the model-implied constraints are incompatible with the observed data.",
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "Survey highlights permutation-based tests as concrete tools to 'falsify' learned causal graphs and thus to detect/refute relationships that stem from spurious signals rather than true causal mechanisms.",
            "uuid": "e764.3",
            "source_info": {
                "paper_title": "The Landscape of Causal Discovery Data: Grounding Causal Discovery in Real-World Applications",
                "publication_date_yy_mm": "2024-12"
            }
        },
        {
            "name_short": "SID",
            "name_full": "Structural Interventional Distance",
            "brief_description": "An evaluation metric that counts how many interventional distributions would be incorrectly computed using the parents from the learned structure as adjustment sets, thereby quantifying how a learned graph would fail in predicting intervention effects.",
            "citation_title": "Structural intervention distance for evaluating causal graphs",
            "mention_or_use": "mention",
            "method_name": "Structural Interventional Distance (SID)",
            "method_description": "A structural evaluation metric that, instead of only comparing graph edges, measures how many interventions would produce incorrect interventional predictions if one used the learned graph's parent sets for adjustment; intended to better capture practical utility in the presence of interventions.",
            "environment_name": "General (applies when interventional data/targets are available)",
            "environment_description": "An evaluator used on datasets that include interventions or where intervention effects are of interest; not an interactive environment itself but evaluates how models perform under hypothetical or real interventions.",
            "handles_distractors": false,
            "distractor_handling_technique": null,
            "spurious_signal_types": null,
            "detection_method": null,
            "downweighting_method": null,
            "refutation_method": "Used as a diagnostic to reveal when learned graphs would produce incorrect intervention effect estimates (thus indirectly identifying models affected by spurious edges).",
            "uses_active_learning": null,
            "inquiry_strategy": null,
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "Survey emphasizes SID as an interventional metric that is more aligned with practitioners' goals than pure structural metrics like SHD; SID can detect when structural correctness does not imply correct intervention predictions, which helps reveal spurious learned relations.",
            "uuid": "e764.4",
            "source_info": {
                "paper_title": "The Landscape of Causal Discovery Data: Grounding Causal Discovery in Real-World Applications",
                "publication_date_yy_mm": "2024-12"
            }
        },
        {
            "name_short": "I-NLL (interventional NLL)",
            "name_full": "Interventional Negative Log-Likelihood (I-NLL)",
            "brief_description": "An interventional evaluation metric that measures how well a learned model predicts held-out interventional distributions, typically via negative log-likelihood or other distributional distances.",
            "citation_title": "Evaluating causal models by comparing interventional distributions",
            "mention_or_use": "mention",
            "method_name": "Interventional negative log-likelihood (I-NLL)",
            "method_description": "Compute the negative log-likelihood (or other distance such as MAE, TV, KL) of held-out interventional data under the learned model's predictive distribution; average over multiple interventions to assess predictive quality under unseen interventions.",
            "environment_name": "General interventional datasets (e.g., biological perturbation datasets)",
            "environment_description": "Applicable to datasets that include interventional measurements; evaluates models on real or simulated interventional test sets rather than on purely observational held-out data.",
            "handles_distractors": false,
            "distractor_handling_technique": null,
            "spurious_signal_types": null,
            "detection_method": "By directly evaluating predictive accuracy on interventions, I-NLL exposes models that rely on spurious correlations that fail to predict interventional distributions.",
            "downweighting_method": null,
            "refutation_method": "Poor interventional predictive performance can be used to refute learned causal claims that appear plausible observationally but fail under interventions.",
            "uses_active_learning": null,
            "inquiry_strategy": null,
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "Survey recommends interventional metrics such as I-NLL to assess the real causal utility of learned models, as these metrics can reveal reliance on spurious correlations that structural metrics miss.",
            "uuid": "e764.5",
            "source_info": {
                "paper_title": "The Landscape of Causal Discovery Data: Grounding Causal Discovery in Real-World Applications",
                "publication_date_yy_mm": "2024-12"
            }
        },
        {
            "name_short": "Causally (generator)",
            "name_full": "Causally (synthetic data generator enabling controlled assumption violations)",
            "brief_description": "A synthetic data generator (referred to as 'Causally' by Montagna et al.) that natively allows explicit control over modeling assumptions (latent confounders, unfaithful paths, etc.) so that causal discovery methods can be stress-tested against realistic assumption violations and spurious artifacts.",
            "citation_title": "",
            "mention_or_use": "mention",
            "method_name": "Causally (synthetic data generator)",
            "method_description": "A simulator that can generate synthetic datasets while explicitly controlling for common assumption violations (presence/absence of latent confounders, unfaithful paths, selection bias, measurement error), enabling more realistic benchmarks and revealing spurious cues exploited by methods trained only on idealized synthetic data.",
            "environment_name": "Synthetic/pseudo-real simulation environment",
            "environment_description": "Not an interactive environment per se, but a synthetic data generator used to create datasets that mimic real-world violations of causal discovery assumptions for benchmarking; supports generating both i.i.d. and interventional data with controllable nuisances.",
            "handles_distractors": null,
            "distractor_handling_technique": null,
            "spurious_signal_types": "Unfaithful paths, latent confounders, measurement noise, model-matched artifacts used by algorithms",
            "detection_method": "By creating datasets that include controlled nuisances and artifacts, the generator makes it possible to detect when a method relies on spurious dataset artifacts (e.g., variance sorting) rather than genuine causal signals.",
            "downweighting_method": null,
            "refutation_method": "Enables stress tests and comparative evaluations that can refute methods that exploit synthetic artifacts by showing performance degradation under controlled violations.",
            "uses_active_learning": null,
            "inquiry_strategy": null,
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "Survey recommends using generators like 'Causally' to craft benchmarks where common assumptions are violated so that methods that exploit spurious cues are revealed; the paper cites Montagna et al. as an example of improved synthetic benchmarking.",
            "uuid": "e764.6",
            "source_info": {
                "paper_title": "The Landscape of Causal Discovery Data: Grounding Causal Discovery in Real-World Applications",
                "publication_date_yy_mm": "2024-12"
            }
        },
        {
            "name_short": "Variance-sorting artifact / scale-invariant sorting",
            "name_full": "Variance-based artifact in synthetic benchmarks; scale-invariant sorting criterion to recover causal order",
            "brief_description": "Work demonstrating that some synthetic causal benchmarks admit trivial solutions (e.g., sorting variables by variance) that let algorithms recover causal order via spurious statistics, and proposing scale-invariant fixes (sorting criteria) to avoid such artifacts.",
            "citation_title": "Beware of the simulated dag! causal discovery benchmarks may be easy to game.",
            "mention_or_use": "mention",
            "method_name": "Variance-sorting detection and scale-invariant sorting correction",
            "method_description": "Reisach et al. showed that certain synthetic data generators leak spurious information (e.g., variance differences) that can be used to recover causal order without true causal learning; subsequent work proposed scale-invariant sorting criteria and generator adjustments to remove such trivial cues and produce more realistic benchmarks.",
            "environment_name": "Synthetic benchmark datasets (standard DAG generators)",
            "environment_description": "Applies to commonly used synthetic generators (ErdsRnyi, scale-free, linear-Gaussian mechanisms) where inadvertent artifacts can be introduced; these insights are relevant to anyone using virtual labs or simulators for causal-discovery evaluation.",
            "handles_distractors": null,
            "distractor_handling_technique": "Identification of spurious statistical cues (e.g., variance) and correction via scale-invariant generation or sorting criteria to prevent trivial exploitation.",
            "spurious_signal_types": "Artifacts in synthetic generators (variance differences, distributional cues) that act as spurious signals enabling trivial recovery of causal order.",
            "detection_method": "Empirical analysis showing recovery by naive statistics (sorting by variance) and proposing diagnostic checks; propose scale-invariant measures to remove cue.",
            "downweighting_method": null,
            "refutation_method": "Demonstrate that algorithms succeed only because of artifact; corrected generators/refined sorting refute conclusions drawn from flawed benchmarks.",
            "uses_active_learning": null,
            "inquiry_strategy": null,
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "Survey cites Reisach et al. to show that naive synthetic datasets can introduce spurious signals which inflate method performance; recommends improved generators or evaluation strategies (scale-invariant criteria) to avoid these artifacts.",
            "uuid": "e764.7",
            "source_info": {
                "paper_title": "The Landscape of Causal Discovery Data: Grounding Causal Discovery in Real-World Applications",
                "publication_date_yy_mm": "2024-12"
            }
        },
        {
            "name_short": "Bacadi",
            "name_full": "Bacadi: Bayesian causal discovery with unknown interventions",
            "brief_description": "A Bayesian causal discovery approach that infers causal structure when interventions are present but their targets are unknown or uncertain, thereby addressing a form of spurious signal introduced by mis-specified intervention targets.",
            "citation_title": "Bacadi: Bayesian causal discovery with unknown interventions",
            "mention_or_use": "mention",
            "method_name": "Bacadi (Bayesian discovery with unknown interventions)",
            "method_description": "A probabilistic/Bayesian framework that jointly infers intervention targets (or models uncertainty over targets) and the causal graph, permitting robust structure learning when interventions are imperfectly labeled or their effects are ambiguous; the survey references Hgele et al. (2023) in this context.",
            "environment_name": "Interventional datasets with uncertain / unknown targets (e.g., biological perturbation data)",
            "environment_description": "Applies to datasets where interventions have been performed but the actual targets or exact nature of the intervention are uncertain (common in CRISPR / biological experiments); helps make inference robust to mislabeled or unknown interventions.",
            "handles_distractors": true,
            "distractor_handling_technique": "Probabilistic modeling of intervention target uncertainty and Bayesian integration over possible intervention-target assignments.",
            "spurious_signal_types": "Unknown/uncertain interventions that produce spurious associations if treated as perfectly-targeted; mislabeled or ineffective perturbations.",
            "detection_method": null,
            "downweighting_method": null,
            "refutation_method": null,
            "uses_active_learning": null,
            "inquiry_strategy": null,
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "Survey mentions Bacadi as an example of work that explicitly handles unknown interventions, an important source of spurious signals in real-world interventional datasets, but provides no experimental details in the review.",
            "uuid": "e764.8",
            "source_info": {
                "paper_title": "The Landscape of Causal Discovery Data: Grounding Causal Discovery in Real-World Applications",
                "publication_date_yy_mm": "2024-12"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Causal discovery under off-target interventions",
            "rating": 2,
            "sanitized_title": "causal_discovery_under_offtarget_interventions"
        },
        {
            "paper_title": "Toward falsifying causal graphs using a permutation-based test",
            "rating": 2,
            "sanitized_title": "toward_falsifying_causal_graphs_using_a_permutationbased_test"
        },
        {
            "paper_title": "Beware of the simulated dag! causal discovery benchmarks may be easy to game.",
            "rating": 2,
            "sanitized_title": "beware_of_the_simulated_dag_causal_discovery_benchmarks_may_be_easy_to_game"
        },
        {
            "paper_title": "Bacadi: Bayesian causal discovery with unknown interventions",
            "rating": 2,
            "sanitized_title": "bacadi_bayesian_causal_discovery_with_unknown_interventions"
        },
        {
            "paper_title": "Causalworld: A robotic manipulation benchmark for causal structure and transfer learning.",
            "rating": 2,
            "sanitized_title": "causalworld_a_robotic_manipulation_benchmark_for_causal_structure_and_transfer_learning"
        },
        {
            "paper_title": "Causal chambers as a real-world physical testbed for ai methodology.",
            "rating": 2,
            "sanitized_title": "causal_chambers_as_a_realworld_physical_testbed_for_ai_methodology"
        },
        {
            "paper_title": "Structural intervention distance for evaluating causal graphs",
            "rating": 2,
            "sanitized_title": "structural_intervention_distance_for_evaluating_causal_graphs"
        },
        {
            "paper_title": "Evaluating causal models by comparing interventional distributions",
            "rating": 2,
            "sanitized_title": "evaluating_causal_models_by_comparing_interventional_distributions"
        },
        {
            "paper_title": "A scale-invariant sorting criterion to find a causal order in additive noise models",
            "rating": 1,
            "sanitized_title": "a_scaleinvariant_sorting_criterion_to_find_a_causal_order_in_additive_noise_models"
        },
        {
            "paper_title": "Causally",
            "rating": 1
        }
    ],
    "cost": 0.025793,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>The Landscape of Causal Discovery Data: Grounding Causal Discovery in Real-World Applications
13 Jun 2025</p>
<p>Philippe Brouillard philippebrouillard@gmail.com 
Chandler Squires csquires@andrew.cmu.edu 
Jonas Wahl jonas.wahl@dfki.de 
Konrad P Krding kording@upenn.edu 
Karen Sachs 
Alexandre Drouin alexandre.drouin@servicenow.com 
Dhanya Sridhar dhanya.sridhar@mila.quebec 
Biwei Huang 
Mathias Drton 
K P Wahl 
A Sachs 
Drouin </p>
<p>Mila-Qubec
Universit de Montral</p>
<p>Carnegie Mellon University</p>
<p>University of Pennsylvania</p>
<p>ServiceNow Research
Mila-Qubec
Universit Laval</p>
<p>Mila-Qubec
Universit de Montral</p>
<p>The Landscape of Causal Discovery Data: Grounding Causal Discovery in Real-World Applications
13 Jun 20252CA1FA916120DE2E489064B0EE5005F8arXiv:2412.01953v2[cs.LG]Causal discoveryevaluation metricsreal-world applications
Causal discovery aims to automatically uncover causal relationships from data, a capability with significant potential across many scientific disciplines.However, its real-world applications remain limited.Current methods often rely on unrealistic assumptions and are evaluated only on simple synthetic toy datasets, often with inadequate evaluation metrics.In this paper, we substantiate these claims by performing a systematic review of the recent causal discovery literature.We present applications in biology, neuroscience, and Earth sciences-fields where causal discovery holds promise for addressing key challenges.We highlight available simulated and real-world datasets from these domains and discuss common assumption violations that have spurred the development of new methods.Our goal is to encourage the community to adopt better evaluation practices by utilizing realistic datasets and more adequate metrics.</p>
<p>Introduction</p>
<p>In many scientific endeavors, researchers are not merely interested in identifying statistical patterns, but in understanding the underlying causal relationships that govern complex systems.They want to answer causal questions such as "What would be the impact of changing a specific variable on this system?".This kind of question cannot be answered by purely statistical models.For instance, in healthcare, understanding causal relationships is essential to determine the efficacy of treatments leading to better patient outcomes and more efficient resource allocation.If a purely statistical model is used instead, the model might rely on spurious correlations, leading to erroneous conclusions.Causal discovery aims at recovering causal relations directly from data, allowing us to answer causal queries.While causal inference is challenging, most scientific fields could benefit from that capability.</p>
<p>That being said, the field of causal discovery is predominantly method-driven rather than applicationdriven (Rolnick et al., 2024): the community produces new methods and algorithms at high speed but still relies on toy datasets and simple metrics for their evaluation (Gentzel et al., 2019), impeding its development and applicability to real-world problems.Recently, a plethora of surveys of causal discovery have covered existing causal discovery methods (Wang et al., 2024;Hasan et al., 2023;Zanga et al., 2022;Assaad et al., 2022;Vowels et al., 2022;Zhou and Chen, 2022;Nogueira et al., 2021;Guo et al., 2020;Glymour and Zhang, 2019;Malinsky and Danks, 2018;Singh et al., 2017), but none focused on the datasets and real-world applications to which these methods were applied.However, using good datasets and benchmarks is just as crucial as having good algorithms.For example, this has been pivotal in the recent deep learning boom with datasets such as ImageNet (Deng et al., 2009) and its associated challenge (Russakovsky et al., 2015).Beyond the choice of datasets, there is also a need for deeper consideration of the types of problems to which causal discovery can and should be applied.Over-reliance on simple settings makes the field disconnected from real-world challenges, and without practical applications, causal discovery risks becoming merely theoretical storytelling.</p>
<p>The goal of this review is to incite the community to be more application-driven: we do that by surveying the recent literature and highlighting key methodological shortcomings to be improved, as well as identifying fields that seem ripe to benefit the application of causal discovery.First, by performing a systematic review, we show in Section 4 that the field of causal discovery still relies on synthetic datasets and a low diversity of real-world datasets.Also, in most studies, inadequate metrics are used for evaluation.Second, in Section 5, we show that many alternatives exist to simple synthetic datasets, both pseudo-real and real-world datasets, and we provide a list of some common datasets that are used to assess new causal discovery methods (see our github repo).Finally, we highlight a few key scientific fields -biology, neuroscience, and Earth sciences -where a significant amount of real-world data is generated and causal discovery should be a short-term target.Overall, the resulting overview reveals that real-world applications frequently challenge established causal discovery assumptions and may serve as catalysts for innovation, underscoring the importance of grounding research in practical scenarios and utilizing real-world datasets over purely synthetic ones.</p>
<p>Background</p>
<p>Causal models make formal predictions about the effects of intervention, i.e., external manipulations that set a variable to some specific value or distribution.While many approaches exist to this end, this section briefly presents one specific class of causal models that is popular in the field.We detail the entailed assumptions and introduce causal discovery (for details, see Peters et al. (2017); Pearl (2009)).</p>
<p>Causal Bayesian Network.A Causal Bayesian Network (CBN) consists of a directed acyclic graph (DAG) G = (V,E) with |V | = d and a random vector X = (X 1 ,...,X d )  P X whose entries correspond to the nodes of G.The distribution P X is connected to the graph G by the Markov property which asserts that P X factorizes as
P X = d i=1 P (0) (X i | pa G i ),(1)
where pa G i are the parents of X i in the graph G. Up to this point, this model is a standard Bayesian network.The causal semantics stem from the interventional interpretation of the edge directions and the fact that interventions on variables can also be considered.Let (I 1 ,...,I k ) be a collection of interventional targets.Each interventional target I j  [d] represents a set of variables that have been intervened upon during intervention j.The distribution induced by the j-th intervention is given by P (j)
X = i / I j P (0) (X i | pa G i ) iI j P (j) (X i | pa G i ),(2)
where P (0) are the observational conditionals that stay invariants (i.e., same as in Eq 1) and P (j) are conditionals intervened upon which are specific to the interventional distribution j.This is a general formulation, with perfect interventions being a notable specific case that corresponds to a setting where the conditional P (j) (X i ) does not depend on its parents pa G i .Causal discovery.The task of recovering the graph G from a dataset D (possibly containing interventional data) is called causal discovery.Constraint-based methods such as the PC algorithm (Spirtes et al., 2001) perform conditional independence tests to recover G, while score-based methods achieve this by finding the graph that maximizes a score, such as the Bayesian Information Criterion (BIC) (Chickering, 2002).Some hybrid methods combine aspects of both approaches.Other methods make parametric assumptions on the functional form of the causal mechanisms or the variable distributions and orient edges based on detected asymmetries.For a more complete presentation, see for example Glymour and Zhang (2019).All of these methods are only guaranteed to recover the correct "groundtruth" graph in the infinite sample limit if the data-generating mechanism satisfies specific assumptions.</p>
<p>Common assumptions.Causal discovery relies on many assumptions, some directly induced by the CBN approach: 1) acyclicity of the graph over variables, 2) causal sufficiency which refers to the fact that there are no unobserved confounders, i.e., variables that are parents to more than one X i , 3) the faithfulness assumption that stipulates that conditional independencies in the distribution P X implies the corresponding d-separation in the graph G, and 4) the random variables provide an appropriate representation to reason about the problem of interest (Spirtes, 2009;Eberhardt, 2016).As already mentioned above, many methods also assume a particular functional form of the causal mechanisms (e.g., linearity).In practice, as we will explain in more detail in Section 5.4, most of these assumptions are violated in real-world problems.</p>
<p>Even when all these assumptions are satisfied, causal discovery is a hard task, both combinatorically and statistically.The space of DAGs scales super-exponentially with respect to the number of variables, and the assumptions above only guarantee correctness in the infinite sample limit, while in practice, one also has to deal with finite sample errors.Moreover, when the data is purely observational, without further assumptions one can at best identify an equivalence class of graphs, called the Markov Equivalence Class.Utilizing interventions represents the optimal strategy for overcoming obstacles in causal identifiability since it can greatly shrink the size of the equivalence class.If single-target interventions are performed on every node except one, the ground-truth graph is identifiable and, in general, fewer interventions are required (Eberhardt et al., 2005).</p>
<p>Evaluation.To evaluate the performance of causal discovery algorithms, there are, broadly speaking, four classes of metrics: structural, qualitative, observational, and interventional.Structural metrics consist of comparing the learned graph to the ground-truth graph using distances, such as the structural Hamming distance (SHD) which counts the total number of edges that are missing, superfluous, and reversed.Qualitative assessments consist of experts in the field who will discuss, based on their domain knowledge, the plausibility of some causal relations.This is similar to structural measure, but it is used when the ground-truth graph is not known.Observational and interventional metrics correspond to evaluating how well the learned model predicts held-out observational data and data from an unseen intervention, respectively.The latter is arguably closest to what most practitioners care about: the ability to predict the effect of unseen interventions.Appendix D provides further details on these metrics.</p>
<p>From Purely Synthetic Datasets to Real-World Datasets</p>
<p>We first describe different families of datasets that are available for evaluating causal discovery methods before analyzing their use in recent papers.</p>
<p>Synthetic Datasets</p>
<p>We need to address the elephant in the room: many causal discovery methods are evaluated only on simple synthetic datasets that do not reflect any real-world phenomenon (Gentzel et al., 2019) (a claim that we will also demonstrate in Section 4).Moreover, many of these synthetic datasets even use exactly the same generator as the model fitted.Still, synthetic datasets are used since they offer many advantages: the ground-truth causal graph is known, a large sample size can be used and different properties of the causal model can be precisely controlled (e.g.density of the graph, number of vertices, functional form, etc) to assess a method.By design, the generated data will perfectly respect many stringent assumptions such as causal sufficiency, faithfulness, a particular functional form, etc.Moreover, a motivation for using synthetic datasets might come from the misconception that real-world datasets are scarce or impossible to evaluate quantitatively, a notion we aim to refute.</p>
<p>Synthetic datasets are usually generated by following these steps: first, the causal graph is sampled, then the causal mechanisms parameters, and finally, the data is sampled using ancestral sampling (i.e., by sampling the variables following their topological ordering).Common approaches to sample a DAG include the Erds-Rnyi scheme, which samples directed edges with a fixed probability, and scale-free networks (Barabsi and Albert, 1999), which samples edges following a preferential attachment process (Barabsi, 2009).The causal mechanisms parameters often follow a particular functional form assumed by the causal discovery method.For instance, one of the most common causal mechanisms is linear relations with Gaussian noise.Alternatives include nonlinear (Peters et al., 2014) and post-nonlinear additive noise models (Zhang and Hyvarinen, 2012) which are often used since they lead to identifiability results.However, as highlighted in Reisach et al. (2021) and Reisach et al. (2024), the way these datasets are generated can sometimes be problematic as it introduces artifacts that some causal discovery methods may exploit.Namely, Reisach et al. (2021) showed that one can recover the causal ordering of some synthetic datasets simply by sorting the variables according to their variances.Even when these pitfalls are avoided by changing the data generating process (Andrews and Kummerfeld, 2024;Ormaniec et al., 2024), synthetic datasets are much simpler than their real-world counterpart and thus, the performance of proposed causal discovery methods is overestimated (Eigenmann et al., 2020).As we will elaborate in Section 5.4, real-world problems rarely conform to many of the assumptions built into synthetic datasets.We finish by noting that synthetic datasets can still be used for more realistic evaluation by benchmarking causal discovery methods in scenarios where these stringent assumptions are violated, as in Montagna et al. (2024).</p>
<p>Purely Synthetic</p>
<p>Real-World Pseudo-real</p>
<p>Figure 1: The realism of datasets spans a spectrum, from purely synthetic to real-world datasets.</p>
<p>Real-World Datasets</p>
<p>In the end, what we really care about is the application of causal discovery to real-world problems.Real-world datasets are particularly interesting since they often break common assumptions and inform the causal discovery community of what are remaining and interesting challenges to overcome.The primary limitation of real-world datasets, compared to synthetic and pseudo-real datasets, is the difficulty in evaluating the quality of discovered structures due to the absence of a known ground truth, making most assessments qualitative.However, when interventional data are available, we stress the fact that quantitative evaluation is possible via interventional metrics.</p>
<p>Pseudo-Real Datasets</p>
<p>Pseudo-real datasets are designed to be similar to real-world data while retaining the benefits of synthetic datasets: a known ground-truth graph, adherence to common assumptions, and control over generation parameters.As a result, some strongly advocate to use this type of data (Glymour et al., 2019).</p>
<p>Many pseudo-real datasets rely on a data generation process inspired by mathematical models, such as ordinary or stochastic differential equations, used in their respective fields.In biology, many simulators that generate synthetic gene expression data have been proposed: SynTReN (Van den Bulcke et al., 2006), GeneNetWeaver (Schaffter et al., 2011), BEELINE (Pratapa et al., 2020), SERGIO (Dibaeinia and Sinha, 2020).Similarly, in neuroscience, various simulators have been proposed such as simulated spiking interactions between neurons from hippocampus (Bezaire, 2015), simulated network dynamics between network areas approximated by mean-field dynamics along with fMRI signal generation and calibrated against some brain data (Smith et al., 2011).Additionally, several datasets derive from variants of the virtual brain project (Sanz Leon et al., 2013).In Earth sciences, Ebert-Uphoff and Deng (2017) simulate data that reflects typical advection and diffusion processes in the planet's atmosphere to investigate unexplained connections found by causal discovery algorithms on real-world data.</p>
<p>Alternatively, some pseudo-real datasets are generated by directly learning a model from real-world datasets.Once fitted, the model can produce examples similar to the original data under different conditions, with the model's graph serving as the ground truth.This often leads to datasets that, by design, respect most common causal discovery assumptions.The most popular resource of that type is the bnlearn repository (Scutari, 2009;Friedman et al., 1997) that contains several datasets from a wide range of fields.More recently, in the medical setting, Tu et al. (2019) created a simulator for neuropathic pain diagnosis.In the field of manufacturing (Vukovi and Thalmann, 2022), Gbler et al. (2023) proposed a Benchmark called Causalassembly where a model has been fitted to real production line data.Runge et al. (2019) propose the platform CauseMe that contains several time-series datasets, some pseudo-real and some real with a consensus graph.Finally, Lawrence et al. ( 2021); Cheng et al. (2024) propose more general frameworks where several datasets from different fields can be combined for generating realistic time-series data.Simply put, their methods can be applied to any real-world dataset and yield a new simulator.</p>
<p>The realism of datasets can be viewed as a spectrum, with purely synthetic datasets at one end and real-world datasets at the other (see Fig. 1).Pseudo-real datasets fall in between and they can greatly vary in their realism: on one end, they can resemble purely synthetic datasets by respecting all common assumptions and integrating little information from real-world data (e.g., only the graph), at the other end, they can represent a significant improvement over synthetic datasets as they resemble real-world problems and can violate common causal assumptions.As an example of the latter, the simulator of Smith et al. (2011) generates cycles and the simulator of Tu et al. (2019) can generate data with unknown confounders, selection bias, and missing data.In short, a good simulator should faithfully replicate realworld datasets in all their complexity and, hopefully, causal discovery methods that perform well on the simulator should also transfer to real-world datasets.To do so, considering real-world problems and datasets is essential when designing pseudo-real datasets to ensure their realism and practical relevance.</p>
<p>Systematic Review of the Causal Discovery Literature</p>
<p>To better understand the trends in the causal discovery community regarding dataset use and evaluation metrics, we conducted a systematic literature review similar to the one of Gentzel et al. (2019).Using the Semantic Scholar API (Kinney et al., 2023), we collected scientific articles on causal discovery published between 2019 and 2024 at major machine learning conferences (NeurIPS, ICLR, ICML, AISTATS, UAI, AAAI, and CLeaR).We collected a total of 221 papers and, after manually filtering them, we retained 167 papers.A detailed presentation of our methodology, along with some additional results, can be found in Appendix A. The list of selected papers and the analysis code are available at our github repo.</p>
<p>Fig 2 shows the distribution of dataset types used in the selected studies.We observe that 20% of these only make use of purely synthetic datasets, while 62% rely on real-world datasets.Most real-world datasets are small, with 80% containing 20 or fewer variables.Fig 3 shows the field of provenance of pseudo-real and real-world datasets.Biology is by far the most prevalent field.This is partly explained by the ubiquitous use of the flow cytometry dataset, often simply named Sachs (Sachs et al., 2005).It is the only real-world dataset considered for 35% of all the papers relying on real-world datasets (we redo our analysis excluding it in Appendix A.4).For the pseudo-real datasets, the most commonly used datasets come from the bnlearn repository (Scutari, 2009;Friedman et al., 1997).</p>
<p>These two widely used datasets have some notable limitations.For the Sachs datasets, the consensus network used is not fully consistent with the one given in Sachs et al. (2005), in particular, the cycles are often omitted; the ground truth provided is not definitive (see Ramsey and Andrews (2018); Mooij et al. ( 2020)), and varies between studies.Unfortunately, the existence of a ground truth network leads to an over-reliance on structural metrics (less than 5% of studies use interventional metrics) -even though the dataset includes several interventions.Also, some studies rely on a pseudo-real version of the dataset generated by fitting a model to a consensus network (without cycles) (Scutari, 2009).Finally, the dataset is often not discriminatory for causal discovery methods: the reported performance has peaked at an SHD of around 12. For the pseudo-real datasets from bnlearn, most studies rely only on structural metrics and we note that the way the datasets are generated, all common assumptions are respected.</p>
<p>Table 1 summarizes the types of metrics used to evaluate performance on simulated (synthetic and pseudo-real) versus real-world datasets.Structural metrics dominate for simulated datasets, where the ground-truth graph is known (100% of studies use them).In contrast, evaluations on real-world datasets depend more heavily on qualitative assessments (36% vs. 3%).Structural metrics are also widely used for real-world datasets (67%) which can be explained by the overreliance on real-world datasets that contain a ground-truth graph.Both observational and interventional metrics are rare across dataset types, used in fewer than 10% of studies.Overall, most studies rely solely on structural metrics: 86% for the simulated data and 54% for the real-world data.We also note that for real-world datasets that do contain interventions, interventional metrics were not used 89% of the time.In summary, we observed that 1) the choice of datasets could be improved to be closer to realistic settings and 2) most studies rely only on structural or qualitative evaluations.We want to emphasize that the community can readily improve its approach.First, by incorporating a broader range of real-world tasks such as some suggested in the following section.Second, by using interventional metrics as they assess the outcomes we truly care about -namely, the effects of unseen interventions.</p>
<p>Real-World Datasets: Examples and Unique Challenges</p>
<p>This section highlights three scientific fields-biology, neuroscience, and Earth sciences-that offer numerous real-world datasets for the causal discovery community.We outline key datasets where new methods have been applied and suggest others as promising candidates (see Appendix C for lists and links to datasets).For each field, we explain the nature of the datasets, their challenges, and some potential opportunities.Finally, we also present some works that expand causal discovery methods by tackling unique challenges of real-world datasets where most common assumptions do not hold.</p>
<p>Biology: Biomolecular Networks</p>
<p>The field of cellular biology stands out as a key area for applying causal discovery (Lagani et al., 2016;Uhler, 2024): first since biologists already analyze cellular processes like metabolism and DNA repair through the lens of networks and pathways (Pavlopoulos et al., 2011;Alberts et al., 2022), but also because it is driven by recent advances in technology that have enabled the creation of large-scale datasets, often including samples generated under interventional conditions.An enhanced understanding of these networks can shed light on development, disease, and other biological processes (Emmert-Streib et al., 2014).Many technologies now exist for inferring cellular activity, with some focusing on messenger RNA (mRNA) levels, others on protein levels, and some targeting entire cell populations (bulk methods), while newer methods allow observation of individual cells.One prevalent approach is single-cell RNA sequencing (scRNA-seq).Gene-editing techniques like CRISPR (Qi et al., 2013) are also of great interest, as they can naturally be framed as interventions.Technologies such as Perturb-seq (Dixit et al., 2016) combine gene perturbations with single-cell RNA-sequencing, making them ideal for generating datasets well-suited to causal discovery.We discuss in more depth the field-specific characteristics of such data in Appendix B. Biomolecular datasets.In Table 2, we summarize several biological datasets that have been studied in causal discovery, with an emphasis on gene expression datasets.Prior to the development of scRNAseq, the gene expression microarray dataset of Wille et al. (2004) was a common testbed for causal discovery and other graphical structure learning algorithms (Drton and Perlman, 2007;Bhlmann et al., 2014).Following the development of Perturb-seq, several papers have applied causal discovery to such perturbational gene expression datasets.Often, the datasets have to be preprocessed and only a small subset of the genes are used to perform causal discovery.For instance, the complete dataset of bone marrow-derived dendritic cells (BMDCs) from Dixit et al. (2016) contains over 30,000 measurements of 32,777 genes under CRISPR/Cas9 gene deletion perturbations.Following the authors' practice, researchers in causal discovery focus on 24 genes that code for highly influential transcription factors and use a shortened version of the datasets that passed a quality control (Wang et al., 2017;Yang et al., 2018;Varici et al., 2021).</p>
<p>More recently, Replogle et al. ( 2022) introduced three much more comprehensive Perturb-seq datasets, including a dataset of 2.5 million K562 cells under thousands of interventions, and two smaller datasets focused on more putatively important genes.These datasets have primarily been used for directly predicting the effects of genetic perturbations (Lopez et al., 2023;Roohani et al., 2024), but have also been considered in causal discovery (Xue et al., 2023;Lagemann et al., 2023).Indeed, Chevalley et al. (2022) use these two datasets as the basis of CausalBench, a benchmarking suite for causal discovery.Lastly, the Perturb-CITE-seq datasets from Frangieh et al. (2021) have been widely used in causal discovery (Lopez et al., 2022;Sethuraman et al., 2023;Rohbeck et al., 2024); these datasets also include protein expression data, which is typically ignored.</p>
<p>As mentioned in Section 4, the Sachs dataset (Sachs et al., 2005) is by far one of the most commonly used real-world datasets in the causal discovery community.Sachs et al. (2005) pioneered the use of individual cells as the smallest observational unit of intact biological systems, catapulting the available dataset size from dozens or hundreds (of mice, patients, etc) to thousands of cells.This is a flow cytometry dataset that includes abundance measurements for 11 proteins and phospholipids over 7466 CD4+ T cells exposed to nine perturbation conditions.Causal discovery algorithms are often applied to a limited version of the dataset that includes only the 5846 measurements from these seven conditions, see e.g., Wang et al. (2017), Yang et al. (2018), andSquires et al. (2020).The popularity of this dataset is partially accounted for by the fact that, in contrast with the papers above, Sachs et al. (2005) introduced a consensus network based on existing biological literature.In the absence of such a network, one often resorts to comparing against partial ground truth, e.g., as done by Frot et al. (2019), who compare against the reference database TRRUST (Han et al., 2015).</p>
<p>Caveats, challenges, and opportunities.We note that while graphs are prevalent in biology, the "textbook" examples are significantly different from the kinds of networks learned through causal discovery (Tejada-Lapuerta et al., 2023).In a way, causal sufficiency never holds since biologists typically conceive of networks that involve several different types of molecules, such as membrane channel proteins, enzymes, various other kinds of proteins, and RNA.Meanwhile, causal discovery methods are typically applied to datasets that contain measurements of only a single type of molecule, e.g.gene expression datasets.Thus, the networks returned by typical causal discovery algorithms only explicitly involve genes, though some recent methods are also designed to include other latent factors (Squires et al., 2022;Lopez et al., 2023).There is also an opportunity to use datasets involving more direct quantification than latent correlates such as mRNA (see Fig 6).Technologies such as CRISPR are amazing as they yield many interventional data.We note however that these interventions are often imperfect; in particular, a knocked-out gene may persist in the system, even when it was theoretically completely removed.It is not common practice in the literature to check the perturbations for efficacy, leading to potential issues with both training and validation.</p>
<p>Neuroscience</p>
<p>Neuroscience is often concerned with understanding mechanisms, which ultimately is about causality (Ross and Bassett, 2024).It distinguishes the connectome, which describes the wires -the observable physical connections between neurons or brain areas -from the effectome, which describes the causal influences between brain regions (Pospisil et al., 2024).And when it comes to causality, there is a wide spectrum of approaches, including those that assume that correlation is causation and those that ask for perturbations (Siddiqi et al., 2022).There has been growing interest in how we can uncover genuine causal relationships from neuronal recordings, establishing causal inference as a central paradigm in neuroscience research (Reid et al., 2019).</p>
<p>Observational data.Most causal discovery studies in neuroscience are almost entirely focused on observational data where there is no known ground truth.Most branches of neuroscience produce datasets that are used to obtain insights into causal relations.This includes spiking data (Stevenson et al., 2008), signals typically recorded at milliseconds resolution of which we currently record about 3000 simultaneously from many brain regions and that is high signal to noise (Stevenson and Krding, 2011).This includes fMRI datasets that are typically recording either about 10 4 voxels or roughly 10 2 brain areas at roughly 1Hz resolution (Smith et al., 2011).There are many other modalities including Ca2+ imaging, EEG, MEG, and fNIRS.The key is that there are plenty of datasets available and they are generally either purely observational (and without ground truth causal labels) or come from simulations.We give a list of some frequently used datasets in the field of causal discovery in Appendix C.1.We note that while there are no ground-truth graphs for most datasets, for some, we can rely on the known anatomical connectivity.For example, if there are no anatomical connections, there can not be a direct causal connection (Monti et al., 2020;Bird and Burgess, 2008).</p>
<p>Challenges and opportunities.There are major problems for causal inference from brain data.To start with, none of the recording methods obtains data from more than a vanishing subset of underlying variables (e.g., thousands out of many billions of neurons).As such, all observational datasets have dramatically more confounders than observed variables (Mehler and Krding, 2018).Many causal inference techniques popular in neuroscience also assume an absence of cycles (Friston et al., 2011;Zeki and Shipp, 1988) however, the existence of feedback loops is arguably a key principle of brain connectivity (Braitenberg, 1985).For a more complete list of challenges, see Ramsey et al. (2010); Mehler and Krding (2018); Stevenson and Krding (2010);Ocker et al. (2017); Das and Fiete (2020), who list specific problems of applying causal discovery to brain signals.</p>
<p>Recent advancements are also paving the way for performing targeted interventions.Recently, concurrent electrical stimulation with fMRI (es-fMRI) has been proposed (Oya et al., 2017) and causal discovery, namely fGES, has been applied on such dataset (Dubois et al., 2020).Combining large-scale perturbations with transcranial magnetic stimulation (TMS) with brain imaging is an interesting avenue to acquire interventional data (Oathes et al., 2021).Electrical and optogenetic stimulation, which uses light to stimulate genetically modified neurons, is also a promising way to obtain interventional data on animal models (Stroh and Diester, 2012;Lepperd et al., 2023;Lu et al., 2024).All these studies produce interventional data allowing for a more reliable evaluation of causal discovery methods by verifying if they correctly predict the effects of perturbations.</p>
<p>Earth sciences</p>
<p>In the Earth sciences, a field in which controlled experimentation is virtually impossible, researchers rely on a mixture of observational data and physics-based simulations of varying degrees of complexity.Most data is time series or spatio-temporal data and as a consequence, time series causal discovery methods dominate the field, see Runge et al. (2019Runge et al. ( , 2023)).</p>
<p>Reanalysis and observational data.Due to the intricacies of measuring atmospheric and surface variables across large spatial and temporal scales (e.g., irregular measurement locations or measurement times, meteorological conditions affecting remote sensing capabilities), most studies involving causal discovery in the Earth sciences do not use purely observational data.Instead, the most commonly used type of data, in particular for atmospheric variables, is reanalysis data.Reanalysis data is imputed by fitting observations to numerical meteorological prediction models and is thus pseudo-real in the sense of Section 3.3.There are several large reanalysis projects led by national research institutes that make reanalysis data available to the public, including the NCEP/NCAR 40-year reanalysis project and the ERA reanalysis project (Hersbach et al., 2020).These databases contain a wide range of atmospheric parameters such as temperature, humidity, pressure, and wind speed direction (Kalnay et al., 2018).Runge et al. (2019) discuss some of the general challenges of these datasets: strong autocorrelation, time delays, time aggregation, unobserved variables, and more.Examples of causal discovery applications on reanalysis data include Kretschmer et al. (2017); Saranya Ganesh et al. (2023); Iglesias-Suarez et al. (2024) in which causal discovery is used as a feature selection pre-processing step for downstream prediction tasks and neural network parameter selection.Kretschmer et al. (2018) investigate interactions between global modes of climate variability in the Earth system, so-called teleconnections, using ERA reanalysis data.Di Capua et al. (2020b) combine reanalysis data with climate indices available in the KNMI Climate Explorer to investigate teleconnections in boreal summer; see also Saggioro et al. (2020) for another causal discovery application to teleconnections using climate indices.Di Capua et al. (2019, 2020a) use causal discovery on observational data from the Climate Prediction Center (CPC) global rainfall dataset as well as ERA reanalysis surface temperature data to examine causal drivers of Indian summer monsoon rainfall.Engelke and Hitz (2020); Amndola et al. (2021);Tran et al. (2024) apply causal discovery methods targeting extreme events to a river flow network dataset.</p>
<p>In Environmental Science, causal discovery has been applied in Krich et al. (2021Krich et al. ( , 2022) ) to atmospheric flux data from the FLUXNET dataset (Pastorello et al., 2020).FLUXNET contains measurements of carbon, water vapor and energy exchange in different regions of the planet.Guo et al. (2024) investigate the influence of ozone levels on influenza with three causal discovery approaches, using data from the Tropospheric Ozone Assessment Report (TOAR) database and the CDC Influenza report.</p>
<p>Physics-based model data.In addition to direct observations and reanalysis data, climate scientists employ large-scale global or regional climate models to simulate interventions, most notably to investigate global warming under different carbon emission scenarios.Global climate models are coordinated within the Climate Model Intercomparison Project (CMIP), currently in its 6th phase (Eyring et al., 2016).However, these simulators are so computationally demanding that it can take months to run a single simulation (Balaji et al., 2017), making it hard to simulate an abundance of interventional data.Additionally, while there is a huge amount of data that has been produced by climate model runs, different datasets are often inconsistent (e.g., due to a different space or time resolution) and may be hard to retrieve.Recently, an effort has been made to make curated versions of these datasets available (Watson-Parris et al., 2022;Kaltenborn et al., 2024).Applications of causal discovery to CMIP data include Karmouche et al. (2024) who compare the output of the causal discovery method PCMCI+ across different climate models and Nowack et al. (2020) who investigate whether CMIP6 models whose causal discovery output graphs are similar to the graph found on reanalysis data exhibit better performance on a downstream prediction task.Simpler data simulators for climate-specific causal discovery that are faster to run but far less detailed have been developed in Ebert-Uphoff and Deng (2017) and Tibau et al. (2022).</p>
<p>Evaluation of causal discovery output graphs.Due to the unfeasibility of interventions, it is usually impossible to directly validate the output of a causal discovery method.In addition, as in almost all real-world applications causal discovery assumptions are almost certainly violated, and the degree of violation is often difficult to estimate.Therefore, Earth scientists resort to softer plausibility criteria, for instance by asking whether the returned network is consistent with physical laws.Sometimes more than one causal discovery algorithm is applied to verify whether conclusions are consistent across methods, e.g. in Guo et al. (2024).As Earth scientists are well aware that such validations need to be handled with care due to the danger of confirmation bias, causal discovery is predominantly used for feature selection (Kretschmer et al., 2017;Saranya Ganesh et al., 2023;Iglesias-Suarez et al., 2024) or model comparison (Nowack et al., 2020;Karmouche et al., 2024).</p>
<p>Challenges of Real-World Datasets</p>
<p>In this section, we highlight several causal discovery works that have been designed specifically to answer challenges arising in the field of biology and neuroscience.By exploring these works, we aim to illustrate how the violation of standard assumptions can drive innovation, offering insights that purely synthetic or pseudo-real datasets alone might not provide.</p>
<p>High-dimensionality. Real-world datasets often present a high number of features.For instance, brain imaging datasets can contain tens of thousands of features corresponding to individual voxels.Ramsey et al. (2017) proposed fGES, a modification of the popular score-based method GES that assumes linearity, that can scale to a million variables.Gene regulatory network (GRN) datasets, which frequently encompass the entire human genome with around 20,000 features, pose a similar computational challenge, especially for nonlinear causal discovery methods.This is why most applications usually focus on a much smaller subset of genes (often less than a hundred).Recently, a few works have focused on adapting existing nonlinear methods to scale to a much higher number of features (of the order of thousands) (Lee et al., 2019;Lopez et al., 2022).One specificity of the data that can be leveraged is its modularity.Gene regulatory networks form modules or programs of genes that act together.Segal et al. (2005); Lopez et al. (2022) have used this prior to learning more efficiently causal structures.</p>
<p>Heterogeneity.The heterogeneity of biological data often necessitates the integration of multiple datasets to achieve a comprehensive understanding of the underlying biological processes.To address this, Triantafillou and Tsamardinos (2015) and Huang et al. (2020) introduced methods for combining datasets that share a subset of variables, allowing for the leveraging of complementary information across datasets.The heterogeneity can also arise from datasets generated under different populations, such as cell types or disease states.Recognizing this, researchers have proposed methods to model biological data as a mixture of DAGs, each representing a distinct causal structure corresponding to a specific population (Saeed et al., 2020b).Finally, brain imaging datasets are often collected from a cohort of subjects.Although there are strong shared connectivities across the subjects (Damoiseaux et al., 2006), each subject also exhibits unique brain connectivity patterns.Exploring methods to conduct multisubject analyses presents a compelling research challenge that has been explored in Oates et al. (2014Oates et al. ( , 2016)), Monti and Hyvrinen (2018), and Huang et al. (2019).</p>
<p>Cyclic models.While GRNs and brain connectivity networks contain undoubtedly feedback loops (Ferrell Jr, 2013), most causal discovery methods assume acyclicity.Recent works motivated by GRNs (Rohbeck et al., 2024;Sethuraman et al., 2023;Sethuraman and Fekri, 2024) and by the brain examples (Sanchez-Romero et al., 2019) have continued the exploration of cyclic causal models.</p>
<p>Off-target interventions.While a gene knockout is usually considered as an intervention targeting a specific gene, in reality, gene knockouts exhibit off-target effects (Fu et al., 2013).In causality terms, this phenomenon is called fat-hand interventions and has been investigated in different biological contexts (Eaton and Murphy, 2007;Choo et al., 2024).</p>
<p>Measurement error.Technologies such as scRNA-seq can fail to detect some RNA at low levels and will report mistakenly many expression levels at zeros (a phenomenon called dropout) (Hicks et al., 2018).Saeed et al. (2020a); Ke et al. ( 2023); Dai et al. (2024) have proposed causal discovery methods that take into account this type of measurement error.</p>
<p>Conclusion</p>
<p>We systematically surveyed recent work in causal discovery research, focusing on datasets and evaluations used in these studies.Our findings reveal that not much has changed since the study of Gentzel et al. (2019), indicating that the time is well overdue for a critical change in the field.Most studies still only use structural metrics instead of interventional ones.Several studies only include synthetic datasets and while several do include real-world datasets, they often rely on the same ones which have some major limitations.Furthermore, most causal discovery methods rely on strong assumptions that real-world datasets rarely satisfy.Overall, causal discovery still has considerable progress to make before it can be directly applied; practitioners tend to be aware of its limitations and they employ it pragmatically, for instance as an exploratory tool, rather than as a means to derive an irrevocable causal truth.Finally, although we focused on causal discovery, in Appendix E we discuss how similar problems are also present in the emerging field of causal representation learning where simple toy datasets are mostly used and where the common assumptions of the field probably don't hold in real-world settings.We offer recommendations and urge researchers in this field to also use more realistic datasets.</p>
<p>We also explored in more detail the real-world datasets used in causal discovery.A key observation from our exploration is the increased availability of these kinds of datasets, alongside a trend towards larger and more detailed real-world datasets in recent years.In the field of biology, biomolecular network datasets contain even more interventions than before thanks to new technological advances.These datasets present an invaluable opportunity for the advancement of causal discovery and could also be used in tandem with optimal experimental design as explored in Cho et al. (2016);Ness et al. (2017); Agrawal et al. (2019); Tigas et al. (2022); Zhang et al. (2023).Additionally, we showed that real-world domains provide a fertile ground for pushing the boundaries of causal discovery methods since they challenge existing assumptions.</p>
<p>Our conclusion in recommending the use of empirical datasets echoes the one from Gentzel et al. (2019).To be clear, synthetic datasets are useful, but they should be complemented by more realistic evaluations on pseudo-real and real-world datasets.When interventional data are present, good quantitative evaluation on real-world datasets exists.However, in many fields besides biology, interventional data are hard to come by and thus pseudo-real datasets might be more adequate.They conserve most of the synthetic datasets' advantages while being more realistic.Still, the creation of pseudo-real datasets should always remain grounded by considering real-world datasets and the assumptions they violate.Through this review, which compiles an extensive list of both simulators and empirical datasets, we aim to motivate researchers to diversify their dataset usage, moving beyond the confines of synthetic data to embrace the complexity and richness of the real world in their causal discovery endeavors.We hope this effort will also foster the collaboration between causal discovery researchers and practitioners, leading to even more relevant real-world datasets and better integration of domain knowledge.</p>
<p>A.3. Scope and limits of the systematic review</p>
<p>We limited our review to papers published at major machine-learning conferences.Of course, this is not necessarily representative of what practitioners do in their respective fields.The bulk method of Semantic Scholar seems adequate for our use as it leads to only a few false positives, but, on the other hand, we might have missed some relevant articles.The choice of categories for the type of datasets was subjectively created on the prevalence of some datasets.Finally, the review was performed by two different reviewers.To alleviate possible bias, the reviewers reviewed a similar subsample to make sure their judgment were similar.</p>
<p>A.4. Additional results</p>
<p>Excluding papers with only Sachs.We perform the same analysis as in the main text but we exclude the papers containing only Sachs as their real-world datasets (a total of 37 papers).Overall, the results are similar, but we can notice a few interesting differences.The proportion of papers using only synthetic datasets is higher at 26% (see Fig. 4).The field of biology is still the most popular, but it is now more closely followed by the field of neuroscience (see Fig. 5).Finally, for the real-world evaluations, the use of structural metrics is lower leading to an almost equal use of qualitative and structural metrics (see Table 3).This can be explained by the frequent use of Sachs where the structural metrics are used based on the consensus network.Most popular datasets.In this section, we briefly discuss the most used datasets for real-world and pseudo-real datasets.For the real-world datasets, besides Sachs, the Tbingen pairs (Mooij et al., 2016) is the most frequent real-world datasets.We describe in more detail this dataset in Appendix C.2.This contains only pairs of variables and the ground truth is assumed to be known, driving up the number of the use structural metrics for real-world datasets.The third most used dataset is the resting state fMRI data from Poldrack et al. (2015).The recording comes from a single subject over 84 successive days.This is a small graph (6 nodes) representing regions of the hippocampus.We note that in some studies, the different days are considered as different experimental conditions.The ground-truth graph is unknown and qualitative metrics are mostly used.Finally, in fourth position is the perturb-CITE-seq data from Frangieh et al. (2021) coming from three different cell populations, which contains approximatively 20000 genes (for all studies, only a subset is used 1000), and interventions under the form of gene knockdowns.The most common metric used is the interventional one.</p>
<p>For the pseudo-real datasets, the bnlearn repository (Scutari, 2009) is followed by the simulated fMRI data from Smith et al. (2011), the DREAM datasets (Marbach et al., 2010;Greenfield et al., 2010), and SERGIO that generates single-cell expression data of gene regulatory networks from Dibaeinia and Sinha (2020).For all of them, since they are simulated, the ground-truth graph is known and structural metrics are mostly used.Note that the simulated fMRI data violates the acyclicity assumption by relying on differential equations model.Although a single organism is composed of vastly different types of cells (e.g., skin cells, neurons, immune cells), all of these cells have the same genetic code (DNA).Within an organism, variation in cell state is not driven by variation in genetic profiles.Rather, such variation depends heavily upon the process of transcription, in which (protein-coding) genes from the DNA are transcribed into messenger RNA (mRNA) molecules, which are then used as a template to synthesize the cell's proteins.One of the most important determining factors of a cell's state is its transcriptome (also called its gene expression profile), i.e., the total number of mRNA molecules transcribed from each gene.Thus, the field of transcriptomics is a key part of understanding questions about development, disease, and other processes (Emmert-Streib et al., 2014).</p>
<p>In causal discovery, one might say, as a shortcut, that Gene A regulates Gene B if changing the expression of Gene A results in a change in the expression of Gene B. Physically speaking, this relationship is mediated by other, unmeasured molecules, e.g.Gene A might code for a transcription factor (i.e., a protein) which in turn binds to a promoter region for Gene B, increasing the expression of Gene B. Thus, in causal discovery, an edge Gene A Gene B represents the existence of such a mediated causal relationship.</p>
<p>Transcriptomic technologies exist both for measuring and for experimentally manipulating gene expression.Two common approaches to measuring gene expression are microarrays, which measure a fixed panel of genes, and the much more comprehensive RNA sequencing (RNA-seq), which sequences all mRNA transcripts in an untargeted manner.Molecular measurements are either done in bulk, wherein a population of cells are lysed and an average is measured, or can be performed in single cells.Single-cell RNA sequencing (scRNA-seq) has obvious advantages with respect to the number of observational units; however, it should be noted that the data can be extremely sparse.Low abundance genes -including crucial regulators like transcription factors -may fall below the level of detection in individual cells, but are readily detectable in bulk.Single-cell experiments are also far more expensive.</p>
<p>B.2. Beyond transcriptomics.</p>
<p>As aforementioned, mRNA readout of gene expression is highly informative of cell state.However, one has to keep in mind that the relation between genes is always mediated: genes themselves do not execute functions in the cells, but rather the proteins which are created based on the information encoded in the genes.Roughly speaking, mRNA (from Gene X) translates into protein (to Protein X).However, factors such as RNA stability and degradation strongly affect this relationship.Hence, the Gene Regulatory Networks (GRN) being modeled via transcriptomics are actually carried out not by the quantified gene mRNAs, but by latent variables: the gene-encoded proteins.One way to model biomolecular networks more directly is via proteomic datasets, especially ones in which the abundance of the activated proteins is quantified (Sheng Wu and Radvanyi, 2010;Sachs et al., 2005;Brandi et al., 2022), though these tend to be more challenging experimentally.TableShift.Recently Gardner et al. (2024) proposed TableShift: a benchmark comprising many tabular datasets chosen to assess the robustness of machine learning methods to distribution shift.Although not originally intended for causal discovery, it has been explored in Nastl and Hardt (2024), where causal discovery methods are used with the aim of finding causal parents of variables of interest.causal feature learning (Chalupka et al., 2014(Chalupka et al., , 2017)), causal grouping (Parviainen and Kaski, 2017;Anand et al., 2023;Wahl et al., 2023Wahl et al., , 2024)), and causal representation learning (Schlkopf et al., 2021).In this section, we will briefly present causal representation learning where the main task is identifying latent causal variables usually from an unstructured input.This recent development opens the doors to many new practical applications where datasets are unstructured.So far, the field has focused on proving identifiability results, showing that it is possible to recover the right representation (up to some minor transformations) under some assumptions.</p>
<p>Formally, we have the observed variable X = (X 1 ,...,X n ) that are generated by applying a function g to the latent variable Z = (Z 1 ,...,Z d ) that is Markov to a graph G.The data-generating process is as follows:
X = g(Z), P Z = d i=1 P i (Z i | pa G i ),(4)
where g : R d  R n is an injective function called decoder or mixing function.The goal is to find from X a representation of Z that is causally disentangled.Disentangled representations allow interpretability and can also be useful for many downstream tasks.However, without assumptions, it is impossible to learn such a representation (Hyvrinen and Pajunen, 1999;Locatello et al., 2019).Thus, data-generating processes considered follow additional assumptions: assumptions are made on the distribution of the latent variable Z and its support, additional assumptions, such as sparsity, are made about g (Moran et al., 2021;Rhodes and Lee, 2021;Zheng et al., 2022;Brouillard et al., 2024) or the latent graph (Lachapelle et al., 2022) and often the presence of auxiliary information is assumed (e.  2023)).Given these assumptions, many identification results have been discovered showing that the disentangled representation is unique up to some minor transformation (such as affine transformations).However, so far, the field has compared new methods almost exclusively on simple synthetic datasets.We present in Table 9 a list of commonly used datasets in causal representation learning and show visual examples in Figure 7.These synthetic datasets are, in many respects, really not representative of real-world tasks: they focus only on problems where images are the observable input, the latent variables are always simple properties of objects (e.g., position, color, etc), and the latent variables are only a few (i.e., less than 10).Liu et al. (2023) also highlight that images coming from synthetic datasets are too simple: most have plain textures, contain only a small number of objects, and do not contain object occlusion (see Figure 7, except the image to the right).As for the evaluation metrics, the situation is similar to causal discovery.Most rely on the Mean Correlation Coefficient (MCC) that finds the best permutation to evaluate how well the learned latent variables correlate with the ground-truth latent variables.However, the MCC is, at least in some instances, not directly related to the models' performance on downstream tasks.As for the causal discovery evaluation, we recommend evaluating models on downstream tasks such as predicting the effect of interventions.</p>
<p>A few recent works have used real-world datasets, such as Lopez et al. (2023); Zhang et al. (2024) for gene regulatory networks, Yao et al. (2024); Brouillard et al. (2024) in the Earth science domain, and Cadei et al. (2025) in ecology.However, no realistic simulators like the one proposed for causal discovery exist.We also observe that many real-world datasets reported in Table 5, 6 and 7 are good candidates for causal representation learning methods since they are high-dimensional unstructured data before their preprocessing.These datasets offer a more diversified and challenging repertoire than what is presently used in the field.Furthermore, the common practice in causal discovery applied  to unstructured problems is to use dimensionality reduction methods or to drop features with less variation.This constitutes an opportunity for causal representation learning since these common practices probably lead to an incorrect choice of variables.</p>
<p>We conclude by stating that we only focused on causal representation learning, but the realm of domains where causal methods are applied has grown abundantly yielding many other possible applications.While deviating from classical causal discovery, they often use more realistic datasets.Some new methods relying on LLM can directly rely on text metadata to learn relevant causal variables (Liu et al., 2024).Causally-inspired algorithms have also been proposed to tackle the problem of multidomain data (e.g., Arjovsky et al. (2019)), where different domains are interpreted as different interventional environments (for examples of datasets, see Gulrajani and Lopez-Paz (2021)).Finally, we could also mention the active field of causal reinforcement learning (e.g., Ahmed et al. (2021);Ke et al. (2021)).</p>
<p>Figure 6 :
6
Figure 6: Details of biomolecular datasets.A. Central Dogma of biology.The unique code for each organism is encoded in the genome, consisting of a sequence of genes encoded in DNA.The uniqueness is due to variations in genes.Genes are codes or "recipes" for proteins.This code is copied into gene-specific mRNA molecules, via a process called transcription.The information from mRNA molecules is used to create unique proteins via a process called translation.Proteins that comprise the nodes of biomolecular regulatory networks must be activated via processes catalyzed by other (upstream) proteins, in a process called post-translational modification.Processes are shown in blue, measurement technologies are shown in green.Antibody-based modalities include flow cytometry and microscopy-based technologies.B. Depiction of lysate-based (bulk) measurements vs. single cell.Bulk technologies are easier and cheaper, but yield just one vector per sample; single-cell data is sparse in the context of transcriptomics, or of limited dimensionality in proteomics.C. Activity perturbations such as small molecule inhibitors (drugs), and abundance perturbations, typically carried out by genetic means such as CRISPR or ASOs.Activity perturbations leave the protein intact, but block its activity, while abundance perturbations, typically remove the protein by removing the gene from the DNA (genome), or by removing the gene's transcript.</p>
<p>g., Locatello et al. (2020); Von Kugelgen et al. (2021); Brehmer et al. (2022); Ahuja et al. (2022); Lachapelle et al. (</p>
<p>Figure 7 :
7
Figure 7: From left to right: Causal3DIdent, CausalCircuit, Causal Pinball, Interventional Pong, Causal triplet (see Table9for the references).</p>
<p>Table 9 :
9
List of the most common CRL datasets.d z is the dimensionality of the latent variables.Dataset Description d z Von Kgelgen et al. (2021) Causal3DIdent: a 3D object under various conditions 7 Brehmer et al. (2022) CausalCircuit: A robot arm can interact with lights 4 Lippe et al. (2022a) Causal Pinball 5 Lippe et al. (2022b) Interventional Pong 6 Liu et al. (2023) Causal triplet -</p>
<p>Table 1 :
1
Percentage of studies using evaluation metrics.
Synthetic20%Pseudo-realBiology (56%)Real-47% 2% Real-world 13%13%2%Neurosciences (16%) Earth Sciences (6%) Social Sciences (6%) Economy (5%)Structural Qualitative Observational InterventionalSimulated 100.0% 3.0% 5.5% 9.1%world 67.3% 36.4% 5.6% 7.5%Figure 2: Distribution of papersFigure 3: Common fields of thebased on used dataset types.pseudo-real and real-world datasets.</p>
<p>Table 2 :
2
Commonly used biomolecular network datasets.Int, n, and d represent respectively the number of interventions, data points, and features commonly used in causal discovery papers.
Dataset DescriptionInt.ndWille et al. (2004) Gene expression microarray (A. thaliana)-11839Dixit et al. (2016) Perturb-seq (bone marrow-derived dendritic cells) 814427 24Replogle et al. (2022) Perturb-seq (cell line K562)1158 310385 8552Replogle et al. (2022) Perturb-seq (cell line RPE1)651 247914 8833Frangieh et al. (2021) Perturb-CITE-seq (melanoma cells)249 218331 1000Sachs et al. (2005) Flow cytometry (CD4+ T cells)6584611</p>
<p>Table 3 :
3
Percentage of studies using evaluation metrics.</p>
<p>AcknowledgmentsPB acknowledges the support of the Natural Sciences and Engineering Research Council of Canada (NSERC) and acknowledges Assya Trofimov for helpful discussions.JW received funding from the European Research Council (ERC) Starting Grant CausalEarth (Grant Agreement No. 948112) and from the German Federal Ministry of Education and Research (BMBF) as part of the project MAC-MERLin (Grant Agreement No. 01IW24007).CS received funding from Valence Labs and acknowledges Jason Hartford for helpful discussions.AD acknowledges Sara Magliacane for helpful discussions.KS was funded in part by NIMH grant 1R44MH135465.DS acknowledges support from NSERC Discovery Grant RGPIN-2023-04869, and a Canada-CIFAR AI Chair.AppendixAppendix A. Systematic ReviewA.1. MethodologyAs explained in the main text we used the Semantic Scholar API to collect papers(Kinney et al., 2023).Specifically, we used the bulk method to find scientific articles containing the keywords "Causal discovery", "Causal structure learning", "DAG learning", and "DAG structure learning" in their title or abstract.The list of papers was retrieved on September 19, 2024.We did not include articles from workshops at the selected conferences.We manually verified the relevance of each of the 221 papers.We removed articles that were not doing causal discovery or that did not contain any experiments.After this filtering, we kept 167 papers.The whole list of articles and their properties are accessible at our github repo as a CSV file (curated_papers.csv).A.2. Description of each fieldIn this section, we describe briefly each field of the CSV file curated_papers.csv.The title, year, and conf represent the title of the article, the year it was made accessible (note that this is not necessarily the date of publication if, for example, it was put on an open-access repository such as arXiv), and the name of the conference where the article was published.For the field column, we report the field of the provenance of the pseudo-real and real-world datasets.We used the following fields: biology (bio), neuroscience (neuro), Earth Sciences (earth), economy (econ), computational systems (comp), social sciences (socio), health sciences (health), and others.For some common datasets, we noted their use in the pseudo_datasets and real_datasets columns, respectively for pseudo-real and real-world datasets.We noted in time_series and interv_setting if the proposed causal discovery method operated respectively in a time series and/or interventional setting.In synthetic, pseudo_real, and real, we noted if any experiments were performed on these types of datasets.In interventions, we report if the real-world datasets used contained interventional data.In the columns small, medium, and big, we reported the biggest real-world datasets used in each study.Small means 20 variables or less, medium is between 20 and 100 variables, and big is more than 100 variables.The columns synth_structural, synth_observational, synth_interventional, and synth_qualitative correspond to the type of evaluation that was used on synthetic and pseudo-real datasets.By structural, we refer to measures comparing the learned graph to the ground-truth graph such as SHD, SID, AUROC, F1-score, etc.By qualitative, we refer to any qualitative judgment that was done to assess the performance of the algorithm.Most of the time, it was about some edges of the learning graph based on some domain knowledge.By observational and interventional, we refer to metrics such as the negative log-likelihood that evaluate the learned model respectively on held-out data in the observational setting and data in an unseen interventional setting.We give more details of our classification of metrics in Appendix D. The four following columns (real_structural, real_observational, real_ interventional, and real_qualitative) are similar, but refer to the evaluation on real-world datasets.Finally, included denotes whether the article was included or not in our analysis.(Cheng et al., 2024)CausalTime link to dataset(Gbler et al., 2023)CausalAssembly link to dataset(Lawrence et al., 2021)link to dataset(Pratapa et al., 2020)BEELINE link to dataset(Dibaeinia and Sinha, 2020)SERGIO link to dataset(Runge et al., 2019)CauseMe link to dataset(Sanchez-Romero et al., 2019)link to dataset(Tu et al., 2019)Neuropathic Pain Diagnosis Simulator link to dataset(Schaffter et al., 2011)GeneNetWeaver link to dataset(Smith et al., 2011)Netsim link to dataset(Marbach et al., 2010)DREAM4 link to dataset (Van denBulcke et al., 2006)SynTReN link to datasetLysed vs. single cells.Starting with cells in a dish or test tube, cells are either lysed and measured in bulk, or measured as individual cells.In transcriptomics, single-cell data may be very sparse, as genes may not need to be expressed all the time (if the coded proteins are stable), or may fall below the limit of detection.Bulk data is also far cheaper.In proteomics, mass spectrometry-based modalities measure the entire proteome, but are still in the very early days of single-cell capabilities, and are expensive even in bulk measurements.Most such datasets focus on proteome abundance, some also include post-translational modification (PTM).Antibody or label-based modalities for single-cell proteomics such as flow cytometry have been around the longest (&gt;50 years) and are neither sparse nor prohibitively expensive, and readily report an abundance of PTM proteins.However, they must focus on far more limited sets of proteins, in the tens rather than thousands.Activity vs. abundance perturbations.It is useful to distinguish between activity perturbations such as small molecule inhibitors (drugs), and abundance perturbations, typically carried out by genetic means such as CRISPR or ASOs.Activity perturbations leave the protein intact, but block its activity, such that it cannot activate further proteins in the signaling cascade or biomolecular network, while abundance perturbations typically remove the protein by removing the gene from the DNA (genome), or by removing the gene's transcript.Details of data modalities and intervention technologies are summarized in Fig.6.Appendix C. Datasets C.1. Links to datasetsIn the following tables, we provide links to the different datasets we discussed in the main text.In Table4, 5, 6 and 7 we report the links for pseudo-real, biology, neuroscience and Earth science datasets.We also keep an updated version of these lists of datasets at our github repo.The lists contain mainly datasets that have been used in causal discovery studies.Several are particularly interesting since they contain interventional data and can violate some common assumptions.Still, we advise thoughtful use in line with our recommendations, rather than applying them blindly.Also, the lists are by no means exhaustive and we do encourage researchers to explore new applications that are not listed here.While this section provides links to pseudo-real and real-world datasets, we would also like to share the synthetic generator Causally(Montagna et al., 2024)where it is natively possible to control the modelling assumptions (e.g., presence of latent confounders, unfaithful path, etc).Perturb-seq (cell line RPE1) link to dataset(Frangieh et al., 2021)Perturb-CITE-seq data from melanoma cells link to dataset(Frot et al., 2019)RNA-seq of ovarian cancer link to dataset(Dixit et al., 2016)Perturb-Seq of bone marrow-derived dendritic cells link to dataset(Singer et al., 2016)Naive and activated T cells (Drop-seq) link to dataset(Sachs et al., 2005)Flow cytometry dataset of immune cells link to dataset(Wille et al., 2004)Microarray of A. thaliana gene expression link to datasetet al., 2020)es-fMRI data (intracranial electrodes) raw dataset same link(Shah et al., 2018)rs-fMRI data from the medial temporal lobe raw dataset -(Poldrack et al., 2015)Hippocampal rs-fMRI (MyConnectome project) raw dataset -(Di Martino et al., 2014)rs-fMRI (ABIDE Consortium) raw dataset link to dataset(Van Essen et al., 2013)rs-fMRI (Human Connectome Project) raw dataset -(Ramsey et al., 2010)Task fMRI (Rhyme judgment) raw dataset link to dataset(Wang et al., 2003)Task fMRI (star/plus experiment) --We provide the links pointing to the original datasets.However, several of these datasets require some data preprocessing.In this paragraph, we elaborate on some datasets giving references to preprocessed versions that have been in causal discovery settings.The two datasets from Replogle et al. (2022) have been processed and curated byChevalley et al. (2022), and made accessible on CausalBench.The dataset fromFrangieh et al. (2021)has been preprocessed byLopez et al. (2022).The code is available online.For the simulator SERGIO(Dibaeinia and Sinha, 2020), a modified version has been proposed byHgele et al. (2023), making it possible to use custom graphs and generate (perfect) interventional data.C.2. Miscellaneous DatasetsIn this section, we elaborate on a few other source of datasets that are particularly interesting.Computational systems.Datasets generated by existing computational systems have been recently proposed and used to evaluate causal discovery methods.They are of considerable interest since they are deterministic yet complex systems composed of many components.Also, compared to pseudo-real datasets, they are generated from real-world environments.For example, the C++ simulator of the MOS 6502 microprocessor(Jonas and Krding, 2017;Wang and Krding, 2022) is composed of 3510 transistors and 1904 connection elements where the variables of interest are the voltage of the different transistors.While the physical connections are known, it is not sufficient to know the causal graph, instead, it was determined from the perturbation of single transistors.Similarly,Gamella et al., 2025)Causal Chambers link to simulator(Wang and Krding, 2022)MOS 6502 microprocessor link to dataset(Gentzel et al., 2019)Software Systems (PostgreSQL, JDK, Networking) link to datasets(Huang et al., 2018)Archaeology data set -(Mooij et al., 2016)Cause-effect pairs (Tbingen pairs) link to dataset(Byrne, 2013)Teacher's burnout study link to dataset(Shimizu et al., 2011)General Social Survey link to dataset data from the analysis of microservice-based applications(Ikram et al., 2022)(from a sock-shop demo and a production-based microservice system hosted on AWS cloud-native system) has been used to evaluate root-cause analysis methods.The data can be different metrics such as CPU and memory utilization, while the interventions can be failures such as CPU hog and memory leak.Gentzel et al. (2019)also proposed several datasets from such systems: Java Development Kit, PostgreSQL, and a web server infrastructure.Recently, datasets generated by the activation of neural networks have also been used in order to interpret their learned representations(Geiger et al., 2021(Geiger et al., , 2022)).The Causal Chambers.Recently, Gamella et al. (2025) have proposed an interesting new type of dataset where the data is generated from real-world experiments but the ground-truth graph is known.Gamella et al. (2025) designed two computer-controlled physical simulators, that can generate observational and interventional data (i.i.d. as well as time series) with experimentally verified groundtruth graphs.Due to the recency of its development, as far as we know, no causal discovery method has been evaluated on Causal Chamber data yet (seeLohse and Wahl (2024)for an investigation on var-/R 2 -sortability of Causal Chambers time series data).Tbingen pairs.The Tbingen pairs (or CauseEffectPairs benchmark)(Mooij et al., 2016)is a repository regrouping 108 datasets composed of pairs of cause and effect coming from many different domains.The range of domains is vast: climate data, biology (e.g., growth of abalone), healthcare (e.g., arrhythmia and diabetes), economy (e.g., census income), stock market, etc.Note that many of these pairs are adapted from the UCI Machine Learning Repository(Bach and Lichman)where the complete datasets are available.While being real-world data, the ground-truth causal direction is given by the authors since in many cases, it is obvious from common sense (e.g., the altitude causes the temperature).Appendix D. Metrics to evaluate causal models Structural metrics.The most commonly used structural metric is clearly the structural Hamming distance (SHD)(Acid and de Campos, 2003;Tsamardinos et al., 2006).The distance SHD( ,G) is defined as the number of edges that should be added, removed or reversed in order to modify an estimated graph  to a target graph G.Besides SHD, other similar metrics are also often reported: precision-recall, false discovery rate, F 1 score, AUROC, etc.They can be more useful since the SHD alone can be misleading (e.g., for a really sparse graph, an empty graph can be better in terms of SHD than denser graphs that contain many ground-truth edges).A major limitation of these metrics is that they are purely based on the graph without any notion of causality.Other structural metrics assess the distance in terms of topological ordering (e.g., Rolland et al. (2022)) conditional independencies(Textor et al., 2016), d-separation statements(Wahl and Runge, 2025), node-permutation tests(Eulig et al., 2023), etc.More focused on the effect of interventions,Peters and Bhlmann (2015)proposed the Structural Interventional Distance (SID) which counts the number of interventional distributions that would be wrongly computed using the parents from the learned structure as its adjustment sets.While considering interventions, this measure is still about the graph and correlates strongly with SHD(Gentzel et al., 2019).A generalization of this measure that considers other adjustment sets has also been proposed byHenckel et al. (2024).It also has the advantage of being directly applicable to CPDAGs as it returns a scalar instead of bounds and is computationally less demanding.Interventional metrics.As previously mentioned, interventional metrics do not necessitate a known ground-truth graph as it evaluates directly how well a causal model can predict data coming from an unseen interventional distribution(Garant and Jensen, 2016).A common interventional metric is the interventional negative log-likelihood (I-NLL)(Lopez et al., 2022):where data from P (j) were not part of the training set and P (j) is the learned model.Usually, the average is taken over multiple interventional distributions.We also note that this metric does not even require the learned model P  to use a graph and can thus be used with a more general class of methods.While it often takes the form of a likelihood, it can also be any distance between the learned distribution and the ground-truth one: some have used the mean absolute error(Lopez et al., 2022), total variation distance(Garant and Jensen, 2016), the KL divergence, etc.It can also take the form of the strength of a causal relation or the average/conditional treatment effect.Appendix E. Causal Representation LearningIn this review, we focused on causal discovery where it is assumed that we have access to structured data.However, many datasets generated by real-world phenomena are unstructured data(e.g., images, videos, texts, etc).The question of how to deal with such datasets has been central in causal abstraction(Rubenstein et al., 2017;Beckers and Halpern, 2019;Beckers et al., 2020;Massidda et al., 2023),
Searching for bayesian network structures in the space of restricted acyclic partially directed graphs. Silvia Acid, Luis M De Campos, Journal of artificial intelligence research. 182003</p>
<p>Abcd-strategy: Budgeted experimental design for targeted causal structure discovery. Raj Agrawal, Chandler Squires, Karren Yang, Karthikeyan Shanmugam, Caroline Uhler, The 22nd International Conference on Artificial Intelligence and Statistics. PMLR2019</p>
<p>Causalworld: A robotic manipulation benchmark for causal structure and transfer learning. Ossama Ahmed, Frederik Truble, Anirudh Goyal, Alexander Neitz, Manuel Wuthrich, Yoshua Bengio, Bernhard Schlkopf, Stefan Bauer, International Conference on Learning Representations. 2021</p>
<p>Weakly supervised representation learning with sparse perturbations. Kartik Ahuja, Jason Hartford, Yoshua Bengio, Advances in Neural Information Processing Systems. 2022</p>
<p>. B Alberts, R Heald, A Johnson, D Morgan, M Raff, K Roberts, P Walter, Molecular Biology of the Cell. W. W. NortonSeventh Edition. Incorporated, 2022. ISBN 9780393884647</p>
<p>Markov equivalence of max-linear Bayesian networks. Carlos Amndola, Benjamin Hollering, Seth Sullivant, Ngoc Tran, Proceedings of the Thirty-Seventh Conference on Uncertainty in Artificial Intelligence. Cassio De Campos, Marloes H Maathuis, the Thirty-Seventh Conference on Uncertainty in Artificial IntelligencePMLRJul 2021161of Proceedings of Machine Learning Research</p>
<p>Causal effect identification in cluster dags. Adele H Tara V Anand, Jin Ribeiro, Elias Tian, Bareinboim, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202337</p>
<p>Better simulations for validating causal discovery with the dag-adaptation of the onion method. Bryan Andrews, Erich Kummerfeld, arXiv:2405.131002024arXiv preprint</p>
<p>Martin Arjovsky, Lon Bottou, Ishaan Gulrajani, David Lopez-Paz, arXiv:1907.02893Invariant risk minimization. 2019arXiv preprint</p>
<p>Survey and evaluation of causal discovery methods for time series. Emilie Charles K Assaad, Eric Devijver, Gaussier, Journal of Artificial Intelligence Research. 732022</p>
<p>Uci machine learning repository (2013) university of california. K Bach, M Lichman, School of Information and Computer Science</p>
<p>Cpmip: measurements of real computational performance of earth system models in cmip6. Venkatramani Balaji, Eric Maisonnave, Niki Zadeh, Bryan N Lawrence, Joachim Biercamp, Uwe Fladrich, Giovanni Aloisio, Rusty Benson, Arnaud Caubel, Jeffrey Durachta, Geoscientific Model Development. 201710</p>
<p>Albert-Lszl Barabsi and Rka Albert. Emergence of scaling in random networks. Albert-Lszl Barabsi, Scale-free networks: a decade and beyond. 2009. 1999325science</p>
<p>Abstracting causal models. Sander Beckers, Joseph Y Halpern, Proceedings of the aaai conference on artificial intelligence. the aaai conference on artificial intelligence201933</p>
<p>Approximate causal abstractions. Sander Beckers, Frederick Eberhardt, Joseph Y Halpern, Uncertainty in artificial intelligence. PMLR2020</p>
<p>Modeling physiological oscillations in a biologically constrained CA1 network from two perspectives: full-scale parallel network and rationally reduced Network Clamp. Marianne Bezaire, 2015University of California, Irvine</p>
<p>The hippocampus and memory: insights from spatial processing. M Chris, Neil Bird, Burgess, Nature reviews neuroscience. 932008</p>
<p>Charting the visual cortex. Valentino Braitenberg, Cerebral Cortex 3: Visual Cortex. Plenum Press1985</p>
<p>Advances in enrichment methods for mass spectrometry-based proteomics analysis of post-translational modifications. Jessica Brandi, Roberta Noberini, Tiziana Bonaldi, Daniela Cecconi, Journal of Chromatography A. 0021-967316784633522022</p>
<p>Weakly supervised causal representation learning. Johann Brehmer, Pim De Haan, Phillip Lippe, Taco S Cohen, Advances in Neural Information Processing Systems. 202235</p>
<p>Causal representation learning in temporal data via single-parent decoding. Philippe Brouillard, Sbastien Lachapelle, Julia Kaltenborn, Yaniv Gurwicz, Dhanya Sridhar, Alexandre Drouin, Peer Nowack, Jakob Runge, David Rolnick, arXiv:2410.070132024arXiv preprint</p>
<p>Cam: Causal additive models, high-dimensional order search and penalized regression. Peter Bhlmann, Jonas Peters, Jan Ernest, The Annals of Statistics. 4262014</p>
<p>Structural equation modeling with Mplus: Basic concepts, applications, and programming. routledge. Barbara M Byrne, 2013</p>
<p>Smoke and mirrors in causal downstream tasks. Riccardo Cadei, Lukas Lindorfer, Sylvia Cremer, Cordelia Schmid, Francesco Locatello, Advances in Neural Information Processing Systems. 202537</p>
<p>Krzysztof Chalupka, Pietro Perona, Frederick Eberhardt, arXiv:1412.2309Visual causal feature learning. 2014arXiv preprint</p>
<p>Causal feature learning: an overview. Krzysztof Chalupka, Frederick Eberhardt, Pietro Perona, Behaviormetrika. 442017</p>
<p>Causaltime: Realistically generated time-series for benchmarking of causal discovery. Yuxiao Cheng, Ziqian Wang, Tingxiong Xiao, Qin Zhong, Jinli Suo, Kunlun He, The Twelfth International Conference on Learning Representations. 2024</p>
<p>Causalbench: A large-scale benchmark for network inference from single-cell perturbation data. Mathieu Chevalley, Yusuf Roohani, Arash Mehrjou, Jure Leskovec, Patrick Schwab, arXiv:2210.172832022arXiv preprint</p>
<p>Optimal structure identification with greedy search. David Maxwell, Chickering , Journal of machine learning research. 3Nov. 2002</p>
<p>Reconstructing causal biological networks through active learning. Hyunghoon Cho, Bonnie Berger, Jian Peng, PloS one. 113e01506112016</p>
<p>Causal discovery under off-target interventions. Davin Choo, Kirankumar Shiragur, Caroline Uhler, Proceedings of The 27th International Conference on Artificial Intelligence and Statistics. Sanjoy Dasgupta, Stephan Mandt, Yingzhen Li, The 27th International Conference on Artificial Intelligence and StatisticsPMLRMay 2024238of Proceedings of Machine Learning Research</p>
<p>Gene regulatory network inference in the presence of dropouts: a causal view. Haoyue Dai, Ignavier Ng, Gongxu Luo, Peter Spirtes, Petar Stojanov, Kun Zhang, The Twelfth International Conference on Learning Representations. 2024</p>
<p>Consistent resting-state networks across healthy subjects. Jessica S Damoiseaux, Serge Arb Rombouts, Frederik Barkhof, Philip Scheltens, J Cornelis, Stephen M Stam, Christian F Smith, Beckmann, 2006Proceedings of the national academy of sciences103</p>
<p>Systematic errors in connectivity inferred from activity in strongly recurrent networks. Abhranil Das, Ila R Fiete, Nature Neuroscience. 23102020</p>
<p>Rainbench: Towards data-driven global precipitation forecasting from satellite imagery. Christian Schroeder De Witt, Catherine Tong, Valentina Zantedeschi, Daniele De Martini, Alfredo Kalaitzis, Matthew Chantry, Duncan Watson-Parris, Piotr Bilinski, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202135</p>
<p>Imagenet: A large-scale hierarchical image database. Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, Li Fei-Fei, 2009 IEEE conference on computer vision and pattern recognition. Ieee2009</p>
<p>Long-lead statistical forecasts of the indian summer monsoon rainfall based on causal precursors. M Di Capua, Kretschmer, Runge, Alessandri, B Donner, Van Den, Hurk, Vellore, Krishnan, Coumou, 2019Weather and Forecasting341377</p>
<p>Tropical and mid-latitude teleconnections interacting with the indian summer monsoon rainfall: a theory-guided causal effect network approach. G Di Capua, M Kretschmer, R V Donner, B Van Den Hurk, R Vellore, R Krishnan, D Coumou, 10.5194/esd-11-17-2020Earth System Dynamics. 1112020a</p>
<p>Dominant patterns of interaction between the tropics and mid-latitudes in boreal summer: Causal relationships and the role of time-scales. Weather and Climate Dynamics Discussions. Giorgia Di Capua, Jakob Runge, V Reik, Bart Donner, Van Den, Andrew G Hurk, Ramesh Turner, Raghavan Vellore, Dim Krishnan, Coumou, 2020b2020</p>
<p>The autism brain imaging data exchange: towards a large-scale evaluation of the intrinsic brain architecture in autism. Adriana Di, Martino , Chao-Gan Yan, Qingyang Li, Erin Denio, Kaat Francisco X Castellanos, Alaerts, Michal Jeffrey S Anderson, Susan Y Assaf, Mirella Bookheimer, Dapretto, Molecular psychiatry. 1962014</p>
<p>Sergio: a single-cell expression simulator guided by gene regulatory networks. Payam Dibaeinia, Saurabh Sinha, Cell systems. 1132020</p>
<p>Perturb-seq: dissecting molecular circuits with scalable single-cell rna profiling of pooled genetic screens. Atray Dixit, Oren Parnas, Biyu Li, Jenny Chen, Charles P Fulco, Livnat Jerby-Arnon, Nemanja D Marjanovic, Danielle Dionne, Tyler Burks, Raktima Raychowdhury, cell. 16772016</p>
<p>Flywire: online community for whole-brain connectomics. Sven Dorkenwald, Claire E Mckellar, Thomas Macrina, Nico Kemnitz, Kisuk Lee, Ran Lu, Jingpeng Wu, Sergiy Popovych, Eric Mitchell, Barak Nehoran, Nature methods. 1912022</p>
<p>Multiple testing and error control in gaussian graphical model selection. Mathias Drton, Michael D Perlman, Statistical Science. 2232007</p>
<p>Causal mapping of emotion networks in the human brain: Framework and initial findings. Julien Dubois, Hiroyuki Oya, Matthew Michael Tyszka, Iii Howard, Frederick Eberhardt, Ralph Adolphs, Neuropsychologia. 1451065712020</p>
<p>Exact bayesian structure learning from uncertain interventions. Daniel Eaton, Kevin Murphy, Artificial intelligence and statistics. PMLR2007</p>
<p>On the number of experiments sufficient and in the worst case necessary to identify all causal relations among n variables. Frederick Eberhardt, Proceedings of the Twenty-First Conference on Uncertainty in Artificial Intelligence, UAI'05. Frederick Eberhardt, Clark Glymour, Richard Scheines, the Twenty-First Conference on Uncertainty in Artificial Intelligence, UAI'05AUAI Press2016. 2005193Synthese</p>
<p>Causal discovery in the geosciences-using synthetic data to learn how to interpret results. Imme Ebert, -Uphoff , Yi Deng, Computers &amp; geosciences. 992017</p>
<p>Evaluation of causal structure learning algorithms via risk estimation. Marco Eigenmann, Sach Mukherjee, Marloes Maathuis, Conference on Uncertainty in Artificial Intelligence. PMLR2020</p>
<p>Gene regulatory networks and their applications: understanding biological and medical problems in terms of networks. Frank Emmert-Streib, Matthias Dehmer, Benjamin Haibe-Kains, Frontiers in cell and developmental biology. 2382014</p>
<p>Graphical models for extremes. Sebastian Engelke, Adrien S Hitz, 10.1111/rssb.12355Journal of the Royal Statistical Society: Series B (Statistical Methodology). 8242020</p>
<p>Toward falsifying causal graphs using a permutation-based test. Elias Eulig, A Atalanti, Patrick Mastakouri, Michaela Blbaum, Dominik Hardt, Janzing, arXiv:2305.095652023arXiv preprint</p>
<p>Overview of the coupled model intercomparison project phase 6 (cmip6) experimental design and organization. Veronika Eyring, Sandrine Bony, Gerald A Meehl, Catherine A Senior, Bjorn Stevens, Ronald J Stouffer, Karl E Taylor, Geoscientific Model Development. 20169</p>
<p>Feedback loops and reciprocal regulation: recurring motifs in the systems biology of the cell cycle. E James, FerrellJr, Current opinion in cell biology. 2562013</p>
<p>Multimodal pooled perturb-cite-seq screens in patient models define mechanisms of cancer immune evasion. Chris J Frangieh, Johannes C Melms, Kathryn R Pratiksha I Thakore, Patricia Geiger-Schuller, Adrienne M Ho, Brian Luoma, Livnat Cleary, Shruti Jerby-Arnon, Malu, Michael S Cuoco, Nature genetics. 5332021</p>
<p>Where is the impact of bayesian networks in learning. Nir Friedman, Moises Goldszmidt, David Heckerman, Stuart Russell, International Joint Conference on Artificial Intelligence. Citeseer1997</p>
<p>Network discovery with dcm. Baojuan Karl J Friston, Jean Li, Klaas E Daunizeau, Stephan, Neuroimage. 5632011</p>
<p>Robust causal structure learning with some hidden variables. Benjamin Frot, Preetam Nandy, Marloes H Maathuis, Journal of the Royal Statistical Society Series B: Statistical Methodology. 8132019</p>
<p>High-frequency off-target mutagenesis induced by crispr-cas nucleases in human cells. Yanfang Fu, Jennifer A Foden, Cyd Khayter, Morgan L Maeder, Deepak Reyon, Keith Joung, Jeffry D Sander, Nature biotechnology. 3192013</p>
<p>Causal chambers as a real-world physical testbed for ai methodology. Jonas Juan L Gamella, Peter Peters, Bhlmann, Nature Machine Intelligence. 72025</p>
<p>Evaluating causal models by comparing interventional distributions. Dan Garant, David Jensen, arXiv:1608.046982016arXiv preprint</p>
<p>Benchmarking distribution shift in tabular data with tableshift. Josh Gardner, Zoran Popovic, Ludwig Schmidt, Advances in Neural Information Processing Systems. 202436</p>
<p>Causal abstractions of neural networks. Atticus Geiger, Hanson Lu, Thomas Icard, Christopher Potts, Advances in Neural Information Processing Systems. 202134</p>
<p>Inducing causal structure for interpretable neural networks. Atticus Geiger, Zhengxuan Wu, Hanson Lu, Josh Rozner, Elisa Kreiss, Thomas Icard, Noah Goodman, Christopher Potts, International Conference on Machine Learning. PMLR2022</p>
<p>The case for evaluating causal models using interventional measures and empirical data. Amanda Gentzel, Dan Garant, David Jensen, Advances in Neural Information Processing Systems. 322019</p>
<p>Review of causal discovery methods based on graphical models. Clark Glymour, Kun Zhang, Frontiers in genetics. 104184072019</p>
<p>The evaluation of discovery: Models, simulation and search through "big data. Clark Glymour, Joseph D Ramsey, Kun Zhang, Open Philosophy. 212019</p>
<p>causalassembly: Generating realistic production data for benchmarking causal discovery. Konstantin Gbler, Tobias Windisch, Tim Pychynski, Steffen Sonntag, Martin Roth, Mathias Drton, 2023CoRR</p>
<p>Dream4: Combining genetic and dynamic information to identify biological networks and dynamical models. Alex Greenfield, Aviv Madar, Harry Ostrer, Richard Bonneau, PloS one. 510e133972010</p>
<p>In search of lost domain generalization. Ishaan Gulrajani, David Lopez-Paz, International Conference on Learning Representations. 2021</p>
<p>Ozone as an environmental driver of influenza. Fang Guo, Pei Zhang, Vivian Do, Jakob Runge, Kun Zhang, Zheshen Han, Shenxi Deng, Hongli Lin, Taslim Sheikh, Ruchong Ali, Chen, Nature Communications. 15137632024</p>
<p>A survey of learning causality with data: Problems and methods. Ruocheng Guo, Lu Cheng, Jundong Li, Richard Hahn, Huan Liu, ACM Computing Surveys (CSUR). 5342020</p>
<p>Bacadi: Bayesian causal discovery with unknown interventions. Alexander Hgele, Jonas Rothfuss, Lars Lorch, Ram Vignesh, Bernhard Somnath, Andreas Schlkopf, Krause, International Conference on Artificial Intelligence and Statistics. PMLR2023</p>
<p>Trrust: a reference database of human transcriptional regulatory interactions. Heonjong Han, Hongseok Shim, Donghyun Shin, Jung Eun Shim, Yunhee Ko, Junha Shin, Hanhae Kim, Ara Cho, Eiru Kim, Tak Lee, Scientific reports. 51114322015</p>
<p>A survey on causal discovery methods for iid and time series data. Uzma Hasan, Emam Hossain, Md Osman, Gani , Transactions on Machine Learning Research. 2023</p>
<p>Adjustment identification distance: A gadjid for causal structure learning. Leonard Henckel, Theo Wrtzen, Sebastian Weichwald, Proceedings of the Fortieth Conference on Uncertainty in Artificial Intelligence. Negar Kiyavash, Joris M Mooij, the Fortieth Conference on Uncertainty in Artificial IntelligencePMLRJul 2024244of Proceedings of Machine Learning Research</p>
<p>The era5 global reanalysis. Hans Hersbach, Bill Bell, Paul Berrisford, Shoji Hirahara, Andrs Hornyi, Joaqun Muoz-Sabater, Julien Nicolas, Carole Peubey, Raluca Radu, Dinand Schepers, Quarterly Journal of the Royal Meteorological Society. 1467302020</p>
<p>Missing data and technical variability in single-cell rna-sequencing experiments. Stephanie C Hicks, William Townes, Mingxiang Teng, Rafael A Irizarry, Biostatistics. 1942018</p>
<p>Generalized score functions for causal discovery. Biwei Huang, Kun Zhang, Yizhu Lin, Bernhard Schlkopf, Clark Glymour, Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery &amp; data mining. the 24th ACM SIGKDD international conference on knowledge discovery &amp; data mining2018</p>
<p>Specific and shared causal relation modeling and mechanism-based clustering. Biwei Huang, Kun Zhang, Pengtao Xie, Mingming Gong, Eric P Xing, Clark Glymour, Advances in Neural Information Processing Systems. 201932</p>
<p>Causal discovery from heterogeneous/nonstationary data. Biwei Huang, Kun Zhang, Jiji Zhang, Joseph Ramsey, Ruben Sanchez-Romero, Clark Glymour, Bernhard Schlkopf, Journal of Machine Learning Research. 21892020</p>
<p>Nonlinear independent component analysis: Existence and uniqueness results. Aapo Hyvrinen, Petteri Pajunen, Neural networks. 1231999</p>
<p>Causally-informed deep learning to improve climate models and projections. Fernando Iglesias-Suarez, Pierre Gentine, Breixo Solino-Fernandez, Tom Beucler, Michael Pritchard, Jakob Runge, Veronika Eyring, Journal of Geophysical Research: Atmospheres. 12942024</p>
<p>Root cause analysis of failures in microservices through causal discovery. Azam Ikram, Sarthak Chakraborty, Subrata Mitra, Shiv Saini, Saurabh Bagchi, Murat Kocaoglu, Advances in Neural Information Processing Systems. 202235</p>
<p>. Eric Jonas, Konrad Paul, Krding , PLoS computational biology. 131e10052682017</p>
<p>The ncep/ncar 40-year reanalysis project. Eugenia Kalnay, Masao Kanamitsu, Robert Kistler, William Collins, Dennis Deaven, Lev Gandin, Mark Iredell, Suranjana Saha, Glenn White, John Woollen, Renewable energy. Routledge2018</p>
<p>Climateset: A large-scale climate model dataset for machine learning. Julia Kaltenborn, Charlotte Lange, Venkatesh Ramesh, Philippe Brouillard, Yaniv Gurwicz, Chandni Nagda, Jakob Runge, Peer Nowack, David Rolnick, Advances in Neural Information Processing Systems. 362024</p>
<p>Changing effects of external forcing on atlantic-pacific interactions. S Karmouche, E Galytska, G A Meehl, J Runge, K Weigel, V Eyring, 10.5194/esd-15-689-2024Earth System Dynamics. 1532024</p>
<p>Systematic evaluation of causal discovery in visual model based reinforcement learning. Nan Rosemary Ke, Aniket Rajiv Didolkar, Sarthak Mittal, Anirudh Goyal, Guillaume Lajoie, Stefan Bauer, Danilo Jimenez Rezende, Yoshua Bengio, Christopher Pal, Michael Curtis Mozer, Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track. 2021</p>
<p>Nan Rosemary Ke, Sara-Jane Dunn, Jorg Bornschein, Silvia Chiappa, Melanie Rey, Jean-Baptiste Lespiau, Albin Cassirer, Jane Wang, Theophane Weber, David Barrett, arXiv:2304.05823Learning to discover gene regulatory networks. 2023arXiv preprint</p>
<p>The semantic scholar open data platform. R Kinney, C Anastasiades, R Authur, I Beltagy, J Bragg, A Buraczynski, I Cachola, S Candra, Y Chandrasekhar, A Cohan, M Crawford, 2023</p>
<p>Early prediction of extreme stratospheric polar vortex states based on causal precursors. Marlene Kretschmer, Jakob Runge, Dim Coumou, Geophysical research letters. 44162017</p>
<p>The different stratospheric influence on cold-extremes in eurasia and north america. npj Climate and Atmospheric Science. Marlene Kretschmer, Judah Cohen, Vivien Matthias, Jakob Runge, Dim Coumou, 2018144</p>
<p>Functional convergence of biosphere-atmosphere interactions in response to meteorological conditions. Christopher Krich, Mirco Migliavacca, Diego G Miralles, Guido Kraemer, S Tarek, Markus El-Madany, Jakob Reichstein, Miguel D Runge, Mahecha, Biogeosciences. 1872021</p>
<p>Decoupling between ecosystem photosynthesis and transpiration: a last resort against overheating. Christopher Krich, Miguel D Mahecha, Mirco Migliavacca, Martin G De Kauwe, Anne Griebel, Jakob Runge, Diego G Miralles, Environmental Research Letters. 174440132022</p>
<p>Disentanglement via mechanism sparsity regularization: A new principle for nonlinear ica. Sbastien Lachapelle, Pau Rodriguez, Yash Sharma, Katie E Everett, Rmi Le Priol, Alexandre Lacoste, Simon Lacoste-Julien, First Conference on Causal Learning and Reasoning. 2022</p>
<p>Synergies between disentanglement and sparsity: Generalization and identifiability in multi-task learning. Sbastien Lachapelle, Tristan Deleu, Divyat Mahajan, Ioannis Mitliagkas, Yoshua Bengio, Simon Lacoste-Julien, Quentin Bertrand, International Conference on Machine Learning. 2023</p>
<p>Probabilistic computational causal discovery for systems biology. Vincenzo Lagani, Sofia Triantafillou, Gordon Ball, Jesper Tegnr, Ioannis Tsamardinos, Uncertainty in biology: a computational modeling approach. 2016</p>
<p>Deep learning of causal structures in high dimensions under data limitations. Kai Lagemann, Christian Lagemann, Bernd Taschler, Sach Mukherjee, Nature Machine Intelligence. 5112023</p>
<p>Data generating process to evaluate causal discovery techniques for time series data. Marcus Andrew R Lawrence, Rui Kaiser, Maksim Sampaio, Sipos, arXiv:2104.080432021arXiv preprint</p>
<p>Scaling structural learning with no-bears to infer causal transcriptome networks. Hao-Chih Lee, Matteo Danieletto, Riccardo Miotto, Sarah T Cherng, Joel T Dudley, Pacific Symposium on Biocomputing 2020. World Scientific2019</p>
<p>Inferring causal connectivity from pairwise recordings and optogenetics. Elle Mikkel, Tristan Lepperd, Torkel Stber, Marianne Hafting, Konrad Paul Fyhn, Krding, PLoS Computational Biology. 1911e10115742023</p>
<p>Causal representation learning for instantaneous and temporal effects in interactive systems. Phillip Lippe, Sara Magliacane, Sindy Lwe, Yuki M Asano, Taco Cohen, Efstratios Gavves, The Eleventh International Conference on Learning Representations. 2022a</p>
<p>Citris: Causal identifiability from temporal intervened sequences. Phillip Lippe, Sara Magliacane, Sindy Lwe, Yuki M Asano, Taco Cohen, Stratis Gavves, International Conference on Machine Learning. PMLR2022b</p>
<p>Chenxi Liu, Yongqiang Chen, Tongliang Liu, Mingming Gong, James Cheng, Bo Han, Kun Zhang, arXiv:2402.03941Discovery of the hidden world with large language models. 2024arXiv preprint</p>
<p>Causal triplet: An open challenge for intervention-centric causal representation learning. Yuejiang Liu, Alexandre Alahi, Chris Russell, Max Horn, Dominik Zietlow, Bernhard Schlkopf, Francesco Locatello, arXiv:2301.051692023arXiv preprint</p>
<p>Challenging common assumptions in the unsupervised learning of disentangled representations. Francesco Locatello, Stefan Bauer, Mario Lucic, Gunnar Raetsch, Sylvain Gelly, Bernhard Schlkopf, Olivier Bachem, international conference on machine learning. PMLR2019</p>
<p>Weakly-supervised disentanglement without compromises. Francesco Locatello, Ben Poole, Gunnar Rtsch, Bernhard Schlkopf, Olivier Bachem, Michael Tschannen, International Conference on Machine Learning. 2020</p>
<p>Christopher Lohse, Jonas Wahl, arXiv:2407.13313Sortability of time series data. 2024arXiv preprint</p>
<p>Large-scale differentiable causal discovery of factor graphs. Romain Lopez, Jan-Christian Htter, Jonathan Pritchard, Aviv Regev, Advances in Neural Information Processing Systems. 202235</p>
<p>Learning causal representations of single cells via sparse mechanism shift modeling. Romain Lopez, Natasa Tagasovska, Stephen Ra, Kyunghyun Cho, Jonathan Pritchard, Aviv Regev, Conference on Causal Learning and Reasoning. PMLR2023</p>
<p>Causal cortical and thalamic connections in the human brain. Dian Lu, James Stieger, Zoe Lusk, Vivek Buch, Josef Parvizi, bioRxiv. 2024</p>
<p>Causal discovery algorithms: A practical guide. Daniel Malinsky, David Danks, Philosophy Compass. 131e124702018</p>
<p>Revealing strengths and weaknesses of methods for gene network inference. Daniel Marbach, Robert J Prill, Thomas Schaffter, Claudio Mattiussi, Dario Floreano, Gustavo Stolovitzky, Proceedings of the national academy of sciences. the national academy of sciences2010107</p>
<p>Causal abstraction with soft interventions. Riccardo Massidda, Atticus Geiger, Thomas Icard, Davide Bacciu, Conference on Causal Learning and Reasoning. PMLR2023</p>
<p>David Marc, Anton Mehler, Konrad Paul, Krding , arXiv:1812.03363The lure of misleading causal statements in functional connectivity research. 2018arXiv preprint</p>
<p>Assumption violations in causal discovery and the robustness of score matching. Francesco Montagna, Atalanti Mastakouri, Elias Eulig, Nicoletta Noceti, Lorenzo Rosasco, Dominik Janzing, Bryon Aragam, Francesco Locatello, Advances in Neural Information Processing Systems. 202436</p>
<p>A unified probabilistic model for learning latent factors and their connectivities from high-dimensional data. Ricardo Pio, Monti , Aapo Hyvrinen, arXiv:1805.095672018arXiv preprint</p>
<p>Causal discovery with general non-linear relationships using non-linear ica. Ricardo Pio Monti, Kun Zhang, Aapo Hyvrinen, Uncertainty in artificial intelligence. PMLR2020</p>
<p>Distinguishing cause from effect using observational data: methods and benchmarks. Jonas Joris M Mooij, Dominik Peters, Jakob Janzing, Bernhard Zscheischler, Schlkopf, Journal of Machine Learning Research. 17322016</p>
<p>Joint causal inference from multiple contexts. Sara Joris M Mooij, Tom Magliacane, Claassen, Journal of Machine Learning Research. 21992020</p>
<p>Identifiable deep generative models via sparse decoding. Gemma E Moran, Dhanya Sridhar, Yixin Wang, David M Blei, arXiv:2110.108042021arXiv preprint</p>
<p>Do causal predictors generalize better to new domains?. Yvonne Vivian, Moritz Nastl, Hardt, The Thirty-eighth Annual Conference on Neural Information Processing Systems. 2024</p>
<p>A bayesian active learning experimental design for inferring signaling networks. Robert Osazuwa Ness, Karen Sachs, Parag Mallick, Olga Vitek, Research in Computational Molecular Biology: 21st Annual International Conference. Hong Kong, ChinaSpringer2017. May 3-7, 2017. 201721</p>
<p>Climatelearn: Benchmarking machine learning for weather and climate modeling. Tung Nguyen, Jason Jewik, Hritik Bansal, Prakhar Sharma, Aditya Grover, Advances in Neural Information Processing Systems. 362024</p>
<p>Causal discovery in machine learning: Theories and applications. Ana Rita Nogueira, Joo Gama, Carlos Abreu Ferreira, Journal of Dynamics &amp; Games. 832021</p>
<p>Causal networks for climate model evaluation and constrained projections. Peer Nowack, Jakob Runge, Veronika Eyring, Joanna D Haigh, Nature communications. 11114152020</p>
<p>Toward a multisubject analysis of neural connectivity. Chris J Oates, L Costa, Tom E Nichols, Neural Computation. 2712014</p>
<p>Exact estimation of multiple directed acyclic graphs. Chris J Oates, Jim Q Smith, Sach Mukherjee, James Cussens, Statistics and Computing. 262016</p>
<p>Combining transcranial magnetic stimulation with functional magnetic resonance imaging for probing and modulating neural circuits relevant to affective disorders. Desmond J Oathes, Konrad P Nicholas L Balderston, Joseph A Krding, Gianna M Deluisi, John D Perez, Yong Medaglia, Romain J Fan, Theodore D Duprat, Yvette I Satterthwaite, Sheline, Wiley Interdisciplinary Reviews: Cognitive Science. 124e15532021</p>
<p>From the statistics of connectivity to the statistics of spike times in neuronal networks. Gabriel Koch Ocker, Yu Hu, Michael A Buice, Brent Doiron, Kreimir Josi, Robert Rosenbaum, Eric Shea-Brown, Current opinion in neurobiology. 462017</p>
<p>Weronika Ormaniec, Scott Sussex, Lars Lorch, Bernhard Schlkopf, Andreas Krause, arXiv:2406.11601Standardizing structural causal models. 2024arXiv preprint</p>
<p>Mapping effective connectivity in the human brain with concurrent intracranial electrical stimulation and bold-fmri. Hiroyuki Oya, Matthew A Howard, Vincent A Magnotta, Anton Kruger, Timothy D Griffiths, Louis Lemieux, David W Carmichael, Christopher I Petkov, Hiroto Kawasaki, Christopher K Kovach, Journal of neuroscience methods. 2772017</p>
<p>Learning structures of bayesian networks for variable groups. Pekka Parviainen, Samuel Kaski, International Journal of Approximate Reasoning. 882017</p>
<p>The fluxnet2015 dataset and the oneflux processing pipeline for eddy covariance data. Gilberto Pastorello, Carlo Trotta, Eleonora Canfora, Housen Chu, Danielle Christianson, You-Wei Cheah, Cristina Poindexter, Jiquan Chen, Abdelrahman Elbashandy, Marty Humphrey, Scientific data. 20207225</p>
<p>Using graph theory to analyze biological networks. Maria Georgios A Pavlopoulos, Charalampos N Secrier, Theodoros G Moschopoulos, Sophia Soldatos, Jan Kossida, Reinhard Aerts, Pantelis G Schneider, Bagos, BioData mining. 42011</p>
<p>Structural intervention distance for evaluating causal graphs. Jonas Peters, Peter Bhlmann, Neural computation. 2732015</p>
<p>Causal discovery with continuous additive noise models. Jonas Peters, M Joris, Dominik Mooij, Bernhard Janzing, Schlkopf, Journal of Machine Learning Research. 15582014</p>
<p>Elements of causal inference: foundations and learning algorithms. Jonas Peters, Dominik Janzing, Bernhard Schlkopf, 2017The MIT Press</p>
<p>Long-term neural and physiological phenotyping of a single human. Timothy O Russell A Poldrack, Oluwasanmi Laumann, Brenda Koyejo, Ashleigh Gregory, Mei-Yen Hover, Krzysztof J Chen, Jeffrey Gorgolewski, Sung Jun Luci, Ryan L Joo, Boyd, Nature communications. 6188852015</p>
<p>The fly connectome reveals a path to the effectome. Max J Dean A Pospisil, Sven Aragon, Arie Dorkenwald, Amy R Matsliah, Philipp Sterling, Szi-Chieh Schlegel, Claire E Yu, Marta Mckellar, Katharina Costa, Eichler, Nature. 63480322024</p>
<p>Benchmarking algorithms for gene regulatory network inference from single-cell transcriptomic data. Aditya Pratapa, P Amogh, Jeffrey N Jalihal, Aditya Law, Bharadwaj, Murali, Nature methods. 1722020</p>
<p>Repurposing crispr as an rna-guided platform for sequence-specific control of gene expression. Matthew H Lei S Qi, Luke A Larson, Jennifer A Gilbert, Jonathan S Doudna, Adam P Weissman, Wendell A Arkin, Lim, Cell. 15252013</p>
<p>Joseph Ramsey, Bryan Andrews, arXiv:1805.03108Fask with interventional knowledge recovers edges from the sachs model. 2018arXiv preprint</p>
<p>A million variables and more: the fast greedy equivalence search algorithm for learning high-dimensional graphical causal models, with an application to functional magnetic resonance images. Joseph Ramsey, Madelyn Glymour, Ruben Sanchez-Romero, Clark Glymour, International journal of data science and analytics. 32017</p>
<p>Six problems for causal inference from fmri. Stephen Joseph D Ramsey, Catherine Jos Hanson, Yaroslav O Hanson, Russell A Halchenko, Clark Poldrack, Glymour, neuroimage. 4922010</p>
<p>Neural signal propagation atlas of caenorhabditis elegans. Francesco Randi, K Anuj, Sophie Sharma, Andrew M Dvali, Leifer, Nature. 62379862023</p>
<p>Weatherbench: a benchmark data set for data-driven weather forecasting. Stephan Rasp, Sebastian Peter D Dueben, Jonathan A Scher, Soukayna Weyn, Nils Mouatadid, Thuerey, Journal of Advances in Modeling Earth Systems. 12112020</p>
<p>Advancing functional connectivity research from association to causation. Drew B Andrew T Reid, Ravi D Headley, Ruben Mill, Lucina Q Sanchez-Romero, Daniele Uddin, Marinazzo, Pedro A Daniel J Lurie, Stephen Jos Valds-Sosa, Bharat B Hanson, Biswal, Nature neuroscience. 22112019</p>
<p>Beware of the simulated dag! causal discovery benchmarks may be easy to game. Alexander Reisach, Christof Seiler, Sebastian Weichwald, Advances in Neural Information Processing Systems. 342021</p>
<p>A scale-invariant sorting criterion to find a causal order in additive noise models. Alexander Reisach, Myriam Tami, Christof Seiler, Antoine Chambaz, Sebastian Weichwald, Advances in Neural Information Processing Systems. 202436</p>
<p>Mapping information-rich genotype-phenotype landscapes with genome-scale perturb-seq. Reuben A Joseph M Replogle, Angela N Saunders, Jeffrey A Pogson, Alexander Hussmann, Alina Lenail, Lauren Guna, Eric J Mascibroda, Karen Wagner, Gila Adelman, Lithwick-Yanai, Cell. 185142022</p>
<p>Local disentanglement in variational auto-encoders using jacobian l_1 regularization. Travers Rhodes, Daniel Lee, Advances in Neural Information Processing Systems. 202134</p>
<p>Bicycle: Intervention-based causal discovery with cycles. Martin Rohbeck, Brian Clarke, Katharina Mikulik, Alexandra Pettet, Oliver Stegle, Kai Ueltzhffer, Causal Learning and Reasoning. PMLR2024</p>
<p>Score matching enables causal discovery of nonlinear additive noise models. Paul Rolland, Volkan Cevher, Matthus Kleindessner, Chris Russell, Dominik Janzing, Bernhard Schlkopf, Francesco Locatello, International Conference on Machine Learning. PMLR2022</p>
<p>Application-driven innovation in machine learning. David Rolnick, Alan Aspuru-Guzik, Sara Beery, Bistra Dilkina, L Priya, Marzyeh Donti, Hannah Ghassemi, Claire Kerner, Esther Monteleoni, Milind Rolf, Tambe, arXiv:2403.173812024arXiv preprint</p>
<p>Predicting transcriptional outcomes of novel multigene perturbations with gears. Yusuf Roohani, Kexin Huang, Jure Leskovec, Nature Biotechnology. 4262024</p>
<p>Causation in neuroscience: Keeping mechanism meaningful. Lauren N Ross, Dani S Bassett, Nature Reviews Neuroscience. 2522024</p>
<p>Sebastian Paul K Rubenstein, Stephan Weichwald, Joris M Bongers, Dominik Mooij, Moritz Janzing, Bernhard Grosse-Wentrup, Schlkopf, arXiv:1707.00819Causal consistency of structural equation models. 2017arXiv preprint</p>
<p>Inferring causation from time series in earth system sciences. Jakob Runge, Sebastian Bathiany, Erik Bollt, Gustau Camps-Valls, Dim Coumou, Ethan Deyle, Clark Glymour, Marlene Kretschmer, Miguel D Mahecha, Jordi Muoz-Mar, Nature communications. 10125532019</p>
<p>Gherardo Varando, Veronika Eyring, and Gustau Camps-Valls. Causal inference for time series. Jakob Runge, Andreas Gerhardus, Nature Reviews Earth &amp; Environment. 472023</p>
<p>Imagenet large scale visual recognition challenge. Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, International journal of computer vision. 1152015</p>
<p>Causal protein-signaling networks derived from multiparameter single-cell data. Karen Sachs, Omar Perez, Dana Pe'er, Douglas A Lauffenburger, Garry P Nolan, Science. 30857212005</p>
<p>Anchored causal inference in the presence of measurement error. Basil Saeed, Anastasiya Belyaeva, Yuhao Wang, Caroline Uhler, Conference on uncertainty in artificial intelligence. PMLR2020a</p>
<p>Causal structure discovery from distributions arising from mixtures of dags. Basil Saeed, Snigdha Panigrahi, Caroline Uhler, International Conference on Machine Learning. PMLR2020b</p>
<p>Reconstructing regimedependent causal relationships from observational time series. Elena Saggioro, Jana De Wiljes, Marlene Kretschmer, Jakob Runge, Chaos: An Interdisciplinary Journal of Nonlinear Science. 30112020</p>
<p>Estimating feedforward and feedback effective connections from fmri time series: Assessments of statistical methods. Ruben Sanchez-Romero, Joseph D Ramsey, Kun Zhang, Madelyn Rk Glymour, Biwei Huang, Clark Glymour, Network Neuroscience. 322019</p>
<p>The virtual brain: a simulator of primate brain network dynamics. Paula Sanz, Leon , Stuart A Knock, Marmaduke Woodman, Lia Domide, Jochen Mersmann, Anthony R Mcintosh, Viktor Jirsa, Frontiers in neuroinformatics. 7102013</p>
<p>Selecting robust features for machine-learning applications using multidata causal discovery. S Saranya Ganesh, Tom Beucler, Frederick Iat-Hin, Milton S Tam, Jakob Gomez, Andreas Runge, Gerhardus, 10.1017/eds.2023.21Environmental Data Science. 22023</p>
<p>Genenetweaver: in silico benchmark generation and performance profiling of network inference methods. Thomas Schaffter, Daniel Marbach, Dario Floreano, Bioinformatics. 27162011</p>
<p>Toward causal representation learning. Bernhard Schlkopf, Francesco Locatello, Stefan Bauer, Nan Rosemary Ke, Nal Kalchbrenner, Anirudh Goyal, Yoshua Bengio, Proceedings of the IEEE. the IEEE2021109</p>
<p>Marco Scutari, arXiv:0908.3817Learning bayesian networks with the bnlearn r package. 2009arXiv preprint</p>
<p>Learning module networks. Eran Segal, Dana Pe'er, Aviv Regev, Daphne Koller, Nir Friedman, Tommi Jaakkola, Journal of Machine Learning Research. 642005</p>
<p>Learning cyclic causal models from incomplete data. G Muralikrishnna, Faramarz Sethuraman, Fekri, arXiv:2402.156252024arXiv preprint</p>
<p>Nodags-flow: Nonlinear cyclic causal structure learning. Romain Muralikrishnna G Sethuraman, Rahul Lopez, Faramarz Mohan, Tommaso Fekri, Jan-Christian Biancalani, Htter, International Conference on Artificial Intelligence and Statistics. PMLR2023</p>
<p>Mapping the structural and functional network architecture of the medial temporal lobe using 7t mri. Preya Shah, Danielle S Bassett, Laura Em Wisse, John A Detre, Joel M Stein, Paul A Yushkevich, Russell T Shinohara, John B Pluta, Elijah Valenciano, Molly Daffner, Human Brain Mapping. 3922018</p>
<p>Development and application of 'phosphoflow' as a tool for immunomonitoring. Luis Vence, Sheng Wu, Lei Jin, G Laszlo, Radvanyi, Expert Review of Vaccines. 962010</p>
<p>Directlingam: A direct method for learning a linear non-gaussian structural equation model. Shohei Shimizu, Takanori Inazumi, Yasuhiro Sogawa, Aapo Hyvarinen, Yoshinobu Kawahara, Takashi Washio, Patrik O Hoyer, Kenneth Bollen, Patrik Hoyer, Journal of Machine Learning Research-JMLR. 12Apr. 2011</p>
<p>Causal mapping of human brain function. Konrad P Shan H Siddiqi, Josef Krding, Michael D Parvizi, Fox, Nature reviews neuroscience. 2362022</p>
<p>A distinct gene module for dysfunction uncoupled from activation in tumor-infiltrating t cells. Meromit Singer, Chao Wang, Le Cong, Monika S Nemanja D Marjanovic, Huiyuan Kowalczyk, Jackson Zhang, Kaori Nyman, Sema Sakuishi, David Kurtulus, Gennert, Cell. 16662016</p>
<p>Karamjit Singh, Garima Gupta, Vartika Tewari, Gautam Shroff, arXiv:1708.06246Comparative benchmarking of causal discovery techniques. 2017arXiv preprint</p>
<p>Network modelling methods for fmri. Karla L Stephen M Smith, Gholamreza Miller, Matthew Salimi-Khorshidi, Christian F Webster, Thomas E Beckmann, Joseph D Nichols, Mark W Ramsey, Woolrich, Neuroimage. 5422011</p>
<p>Variable definition and causal inference. Peter Spirtes, 2009</p>
<p>Permutation-based causal structure learning with unknown intervention targets. Peter Spirtes, Clark Glymour, Richard Scheines, Conference on Uncertainty in Artificial Intelligence. Chandler Squires, Yuhao Wang, and Caroline UhlerPMLR2001. 2020Causation, prediction, and search</p>
<p>Causal structure discovery between clusters of nodes induced by latent factors. Chandler Squires, Annie Yun, Eshaan Nichani, Raj Agrawal, Caroline Uhler, Conference on Causal Learning and Reasoning. PMLR2022</p>
<p>On the similarity of functional connectivity between neurons estimated across timescales. H Ian, Konrad P Stevenson, Krding, PloS one. 52e92062010</p>
<p>How advances in neural recording affect data analysis. H Ian, Konrad P Stevenson, Krding, Nature neuroscience. 1422011</p>
<p>Inferring functional connections between neurons. Ian H Stevenson, James M Rebesco, Lee E Miller, Konrad P Krding, Current opinion in neurobiology. 1862008</p>
<p>Optogenetics: a new method for the causal analysis of neuronal networks in vivo. Albrecht Stroh, Ilka Diester, Neuroforum. 342012</p>
<p>Climsim-online: A large multi-scale dataset and framework for hybrid ml-physics climate emulation. Akshay Subramaniam, Sungduk Yu, Zeyuan Hu, Walter M Hannah, Liran Peng, Jerry Lin, Mohamed Aziz Bhouri, Ritwik Gupta, Bjrn Ltjens, Justus Will, 202424</p>
<p>Crcns. org: a repository of high-quality data sets and tools for computational neuroscience. L Jeff, Friedrich T Teeters, Sommer, BMC Neuroscience. 101S62009Suppl</p>
<p>Causal machine learning for single-cell genomics. Alejandro Tejada-Lapuerta, Paul Bertin, Stefan Bauer, Hananeh Aliee, Yoshua Bengio, Fabian J Theis, arXiv:2310.149352023arXiv preprint</p>
<p>Robust causal inference using directed acyclic graphs: the r package 'dagitty. Johannes Textor, Benito Van Der, Mark S Zander, Maciej Gilthorpe, George Th Likiewicz, Ellison, International journal of epidemiology. 4562016</p>
<p>A data resource from concurrent intracranial stimulation and functional mri of the human brain. Wh Thompson, H Nair, Oya, Esteban, Shine, Petkov, Poldrack, R Howard, Scientific data. 20207258</p>
<p>A spatiotemporal stochastic climate model for benchmarking causal discovery methods for teleconnections. Xavier-Andoni Tibau, Christian Reimers, Andreas Gerhardus, Joachim Denzler, Veronika Eyring, Jakob Runge, Environmental Data Science. 1e122022</p>
<p>Interventions, where and how? experimental design for causal models at scale. Advances in neural information processing systems. Panagiotis Tigas, Yashas Annadani, Andrew Jesson, Bernhard Schlkopf, Yarin Gal, Stefan Bauer, 202235</p>
<p>Estimating a directed tree for extremes. Ngoc Mai Tran, Johannes Buck, Claudia Klppelberg, Journal of the Royal Statistical Society Series B: Statistical Methodology. 1652024</p>
<p>Constraint-based causal discovery from multiple interventions over overlapping variable sets. Sofia Triantafillou, Ioannis Tsamardinos, The Journal of Machine Learning Research. 1612015</p>
<p>The max-min hill-climbing bayesian network structure learning algorithm. Ioannis Tsamardinos, Laura E Brown, Constantin F Aliferis, Machine learning. 652006</p>
<p>Neuropathic pain diagnosis simulator for causal discovery algorithm evaluation. Ruibo Tu, Kun Zhang, Bo Bertilson, Hedvig Kjellstrom, Cheng Zhang, Advances in Neural Information Processing Systems. 201932</p>
<p>Building a two-way street between cell biology and machine learning. Caroline Uhler, Nature Cell Biology. 2612024</p>
<p>Syntren: a generator of synthetic gene expression data for design and analysis of structure learning algorithms. Tim Van Den Bulcke, Koenraad Van Leemput, Bart Naudts, Piet Van Remortel, Hongwu Ma, Alain Verschoren, Bart De Moor, Kathleen Marchal, BMC bioinformatics. 72006</p>
<p>The wu-minn human connectome project: an overview. Stephen M David C Van Essen, Deanna M Smith, Timothy Ej Barch, Essa Behrens, Kamil Yacoub, Ugurbil, Wu-Minn Hcp Consortium, Neuroimage. 802013</p>
<p>Scalable intervention target estimation in linear models. Burak Varici, Karthikeyan Shanmugam, Prasanna Sattigeri, Ali Tajer, Advances in Neural Information Processing Systems. 202134</p>
<p>Self-supervised learning with data augmentations provably isolates content from style. Y Von Kugelgen, L Sharma, W Gresele, B Brendel, M Scholkopf, F Besserve, Locatello, Advances in Neural Information Processing Systems. 2021</p>
<p>Self-supervised learning with data augmentations provably isolates content from style. Julius Von Kgelgen, Yash Sharma, Luigi Gresele, Wieland Brendel, Bernhard Schlkopf, Michel Besserve, Francesco Locatello, Advances in neural information processing systems. 202134</p>
<p>D'ya like dags? a survey on structure learning and causal discovery. J Matthew, Necati Vowels, Richard Cihan Camgoz, Bowden, ACM Computing Surveys. 5542022</p>
<p>Causal discovery in manufacturing: A structured literature review. Matej Vukovi, Stefan Thalmann, Journal of Manufacturing and Materials Processing. 61102022</p>
<p>Separation-based distance measures for causal graphs. Jonas Wahl, Jakob Runge, The 28th International Conference on Artificial Intelligence and Statistics. 2025</p>
<p>Vector causal inference between two groups of variables. Jonas Wahl, Urmi Ninad, Jakob Runge, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202337</p>
<p>Foundations of causal discovery on groups of variables. Jonas Wahl, Urmi Ninad, Jakob Runge, Journal of Causal Inference. 121202300412024</p>
<p>A survey of causal discovery based on functional causal model. Lei Wang, Shanshan Huang, Shu Wang, Jun Liao, Tingpeng Li, Li Liu, Engineering Applications of Artificial Intelligence. 1331082582024</p>
<p>Learning domain-specific causal discovery from time series. Xinyue Wang, Konrad Paul, Krding , arXiv:2209.055982022arXiv preprint</p>
<p>Training fmri classifiers to detect cognitive states across multiple human subjects. Xuerui Wang, Rebecca Hutchinson, Tom M Mitchell, Advances in neural information processing systems. 200316</p>
<p>Permutation-based causal inference algorithms with interventions. Yuhao Wang, Liam Solus, Karren Yang, Caroline Uhler, Advances in Neural Information Processing Systems. 201730</p>
<p>Climatebench v1. 0: A benchmark for data-driven climate projections. Duncan Watson-Parris, Yuhan Rao, Dirk Olivi, yvind Seland, Peer Nowack, Gustau Camps-Valls, Philip Stier, Shahine Bouabid, Maura Dewey, Emilie Fons, Journal of Advances in Modeling Earth Systems. 14102022</p>
<p>Sparse graphical gaussian modeling of the isoprenoid gene network in arabidopsis thaliana. Anja Wille, Philip Zimmermann, Eva Vranov, Andreas Frholz, Oliver Laule, Stefan Bleuler, Lars Hennig, Amela Preli, Lothar Peter Von Rohr, Thiele, Genome biology. 52004</p>
<p>Albert Xue, Jingyou Rao, Sriram Sankararaman, Harold Pimentel, arXiv:2305.19215dotears: Scalable, consistent dag estimation using observational and interventional data. 2023arXiv preprint</p>
<p>Characterizing and learning equivalence classes of causal dags under interventions. Karren Yang, Abigail Katcoff, Caroline Uhler, International Conference on Machine Learning. PMLR2018</p>
<p>Marrying causal representation learning with dynamical systems for science. Dingling Yao, Caroline Muller, Francesco Locatello, arXiv:2405.138882024arXiv preprint</p>
<p>A survey on causal discovery: theory and practice. Alessio Zanga, Elif Ozkirimli, Fabio Stella, International Journal of Approximate Reasoning. 1512022</p>
<p>The functional logic of cortical connections. Semir Zeki, Stewart Shipp, Nature. 33561881988</p>
<p>Active learning for optimal intervention design in causal models. Jiaqi Zhang, Louis Cammarata, Chandler Squires, Themistoklis P Sapsis, Caroline Uhler, Nature Machine Intelligence. 5102023</p>
<p>Identifiability guarantees for causal disentanglement from soft interventions. Jiaqi Zhang, Kristjan Greenewald, Chandler Squires, Akash Srivastava, Karthikeyan Shanmugam, Caroline Uhler, Advances in Neural Information Processing Systems. 202436</p>
<p>Kun Zhang, Aapo Hyvarinen, arXiv:1205.2599On the identifiability of the post-nonlinear causal model. 2012arXiv preprint</p>
<p>On the identifiability of nonlinear ICA sparsity and beyond. Y Zheng, I Ng, K Zhang, Advances in Neural Information Processing Systems. 2022</p>
<p>A survey on causal discovery. Wenxiu Zhou, Qingcai Chen, China Conference on Knowledge Graph and Semantic Computing. Springer2022</p>            </div>
        </div>

    </div>
</body>
</html>