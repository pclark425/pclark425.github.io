<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-8177 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-8177</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-8177</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-150.html">extraction-schema-150</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the memory mechanism, tasks, comparative results, ablations, and key findings.</div>
                <p><strong>Paper ID:</strong> paper-280011015</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2506.21605v1.pdf" target="_blank">MemBench: Towards More Comprehensive Evaluation on the Memory of LLM-based Agents</a></p>
                <p><strong>Paper Abstract:</strong> Recent works have highlighted the significance of memory mechanisms in LLM-based agents, which enable them to store observed information and adapt to dynamic environments. However, evaluating their memory capabilities still remains challenges. Previous evaluations are commonly limited by the diversity of memory levels and interactive scenarios. They also lack comprehensive metrics to reflect the memory capabilities from multiple aspects. To address these problems, in this paper, we construct a more comprehensive dataset and benchmark to evaluate the memory capability of LLM-based agents. Our dataset incorporates factual memory and reflective memory as different levels, and proposes participation and observation as various interactive scenarios. Based on our dataset, we present a benchmark, named MemBench, to evaluate the memory capability of LLM-based agents from multiple aspects, including their effectiveness, efficiency, and capacity. To benefit the research community, we release our dataset and project at https://github.com/import-myself/Membench.</p>
                <p><strong>Cost:</strong> 0.017</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e8177.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e8177.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the memory mechanism, tasks, comparative results, ablations, and key findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>FullMemory</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Full Memory (full-context buffer)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A memory mechanism that keeps the full conversation/history in the agent's accessible context (effectively concatenating all past messages) to answer memory queries; evaluated as a baseline in this paper's MemBench benchmark.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>FullMemory</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Agent variant that uses the entire past trajectory (no explicit compression or retrieval) as its memory input when answering; implemented as one of seven memory mechanisms in MemBench.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Qwen2.5-7B-Instruct (primary; also evaluated with GPT-4o-mini, Meta-Llama-3.1-8B-Instruct, glm-4-9b-chat)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Qwen2.5-7B-Instruct used as default base model for agents; other LLMs tested to measure model choice effects (GPT-4o-mini, Meta-Llama-3.1-8B-Instruct, glm-4-9b-chat).</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>MemBench factual & reflective memory evaluation (participation & observation scenarios)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Agents must store and recall factual attributes (single-hop, multi-hop, temporal, knowledge-update) and reflective memory (high-level preferences, emotions) from time-aware multi-session dialogues and message streams; tests include varying noise level and dataset scale (10k vs 100k token trajectories).</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>time-aware memory evaluation; question answering / summarization</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>working/full-context buffer</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism</strong></td>
                            <td>Concatenate/keep full past messages in the prompt (no specialized retrieval or summarization); answers generated using full context.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_representation</strong></td>
                            <td>Raw past messages and agent responses (full dialogue history).</td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_method</strong></td>
                            <td>Prompt concatenation (entire buffer is presented to model).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>Factual participation accuracy: 10k=0.647, 100k=0.489; Factual observation accuracy: 1k=0.786, 100k=0.631. Reflective participation accuracy: 10k=0.733, 100k=0.533; Reflective observation accuracy: 1k=0.883, 100k=0.333 (see Tables 3 & 4).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_with_without_memory</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_comparison</strong></td>
                            <td>Compared to retrieval and recency methods, FullMemory performs well at moderate scale (10k) but degrades at large scale (100k) due to context window limits and inefficiency; read/write times negligible for small context but full-context scalability limited.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>FullMemory is strong on short-to-moderate trajectories but suffers performance declines when target evidence falls outside the model context window; it is efficient for small contexts but not scalable to very long histories.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Context-window limitations lead to loss of earlier evidence in long interactions; storing full history incurs practical scaling issues and does not handle noisy long trajectories well.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'MemBench: Towards More Comprehensive Evaluation on the Memory of LLM-based Agents', 'publication_date_yy_mm': '2025-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8177.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e8177.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the memory mechanism, tasks, comparative results, ablations, and key findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RetrievalMemory</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Retrieval-based Memory</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A retrieval-augmented memory mechanism that stores memory items externally and retrieves relevant evidence via vector search (multilingual-e5-small embeddings) to augment the model prompt at query time.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>RetrievalMemory</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Agent variant that writes memory items to an external store and retrieves the most relevant items using semantic embeddings (multilingual-e5-small) and semantic search; implemented and benchmarked in MemBench.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Qwen2.5-7B-Instruct (primary; also evaluated with GPT-4o-mini, Meta-Llama-3.1-8B-Instruct, glm-4-9b-chat)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Same as above; retrieval operations used multilingual-e5-small embeddings for vector search.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>MemBench factual & reflective memory evaluation (participation & observation scenarios)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>As above: time-aware QA tests over factual and reflective content across participation and observation scenarios with noise and two dataset scales.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>retrieval-augmented question answering / memory retrieval</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>external retrieval-augmented memory (episodic store + vector DB)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism</strong></td>
                            <td>Write memory items to an external vector store and at query time perform semantic search (multilingual-e5-small) to retrieve top evidence items, then provide retrieved items to the LM.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_representation</strong></td>
                            <td>Key evidence dialogues/messages and indexed memory items (text chunks, evidence dialogues, summaries).</td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_method</strong></td>
                            <td>Semantic search (embedding-based retrieval using multilingual-e5-small).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>Factual participation accuracy: 10k=0.692, 100k=0.833; Factual observation accuracy: 1k=0.883, 100k=0.933. Reflective participation accuracy: 10k=0.692, 100k=0.833; Reflective observation accuracy: 1k=0.883, 100k=0.933. Participation/observation recall@10: 10k P=0.776 O=0.847; 100k P=0.749 O=0.769 (see Tables 3,4).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_with_without_memory</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_comparison</strong></td>
                            <td>RetrievalMemory is the most robust method at large scale (100k): it maintains high accuracy where FullMemory and RecentMemory decline; retrieval-based approach outperforms generative/summarization-based memories on long trajectories in MemBench.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Retrieval-augmented memory is more robust to long histories and noisy contexts, preserving factual and reflective performance at scale; it also achieves strong recall@10 indicating effective retrieval of evidence.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Requires an external index and retrieval pipeline; retrieval quality depends on embedding quality and indexing; retrieval introduces read/write latency (measured RT ~0.024-0.041s in experiments).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'MemBench: Towards More Comprehensive Evaluation on the Memory of LLM-based Agents', 'publication_date_yy_mm': '2025-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8177.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e8177.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the memory mechanism, tasks, comparative results, ablations, and key findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RecentMemory</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Recent Memory (recency window)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A simple memory mechanism that only keeps a fixed recent window of past interactions (recency-based buffer) so the agent relies on the most recent messages.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>RecentMemory</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Agent variant that stores only a short sliding window of the most recent conversation turns (smaller context window) to answer memory queries; implemented in MemBench as a baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Qwen2.5-7B-Instruct (primary; also evaluated with GPT-4o-mini, Meta-Llama-3.1-8B-Instruct, glm-4-9b-chat)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>See above.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>MemBench factual & reflective memory evaluation (participation & observation scenarios)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>As above.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>recency-based memory question answering</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>working short-term/recency buffer</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism</strong></td>
                            <td>Keep only the most recent N turns/messages (fixed-time or fixed-turn sliding window); older content is not stored or retrievable.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_representation</strong></td>
                            <td>Recent messages (sliding window of last turns).</td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_method</strong></td>
                            <td>Recency-based (simply present recent window to model).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>Factual participation accuracy: 10k=0.639, 100k=0.422; Factual observation accuracy: 1k=0.800, 100k=0.512. Reflective participation accuracy: 10k=0.700, 100k=0.333; Reflective observation accuracy: 1k=0.867, 100k=0.400 (Tables 3 & 4).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_with_without_memory</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_comparison</strong></td>
                            <td>RecentMemory performs well when target evidence is recent (good observation accuracy at small scale), but performance degrades substantially on large-scale/long-range tasks where evidence falls outside the recency window; decline is more pronounced than FullMemory because of smaller window size.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Recency buffers are simple and effective for short-lived information, but insufficient for long-term memories or cross-session reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Inability to recall older evidence; choice of window size trades off recency vs. long-term retention; not robust to long histories.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'MemBench: Towards More Comprehensive Evaluation on the Memory of LLM-based Agents', 'publication_date_yy_mm': '2025-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8177.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e8177.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the memory mechanism, tasks, comparative results, ablations, and key findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GenerativeAgent</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GenerativeAgent (simulated agent memory via generative summaries)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An agent approach that uses LLM generative capabilities to synthesize/summarize human-like memory traces (generative agent paradigm) and uses those generated artifacts as memory to drive behavior and answer queries.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Generative agents: Interactive simulacra of human behavior</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>GenerativeAgent</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Implements the Generative Agents paradigm (Park et al., 2023): the agent generates higher-level summaries/behaviors from observed messages (reflective memory) and uses those to reason and respond.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Qwen2.5-7B-Instruct (primary; also evaluated with GPT-4o-mini, Meta-Llama-3.1-8B-Instruct, glm-4-9b-chat)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>See above.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>MemBench reflective & factual memory evaluation (participation & observation scenarios)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>As above; emphasis on capturing reflective memory (preferences/emotions) via generative summarization and using summaries to answer reflective queries.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>generative memory summarization & QA</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>generative summarization / synthesized episodic memory</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism</strong></td>
                            <td>Use the LLM to produce summaries or simulated memory objects (high-level reflective memory) from multiple low-level factual mentions; store these summaries and use them to answer queries.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_representation</strong></td>
                            <td>Generated summaries / high-level reflective memory artifacts, plus some factual evidence excerpts.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_method</strong></td>
                            <td>Prompting with generated summaries and relevant excerpts (combination of semantic retrieval of generated artifacts and prompt concatenation).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>Reflective participation accuracy: 10k=0.742, 100k=0.333; Reflective observation accuracy: 1k=0.883, 100k=0.200. Factual participation accuracy: 10k=0.478, 100k=0.455; Factual observation accuracy: 1k=0.779, 100k=0.476 (Tables 3 & 4).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_with_without_memory</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_comparison</strong></td>
                            <td>GenerativeAgent variants capture reflective memory well at smaller scale (10k), outperforming some baselines on reflective tasks, but performance drops at 100k likely due to limited context, forgetting, or compressed summaries losing traceability to original evidence.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Generative summarization is effective for extracting reflective memory in moderate-length dialogues, but struggles to maintain accuracy over very long interaction histories; time/compute cost higher than simple retrieval for some base models.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Performance collapses on very long trajectories (100k) suggesting generated summaries may forget or overwrite earlier evidence; can be computationally expensive (noted high RT/WT for some LLM choices).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'MemBench: Towards More Comprehensive Evaluation on the Memory of LLM-based Agents', 'publication_date_yy_mm': '2025-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8177.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e8177.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the memory mechanism, tasks, comparative results, ablations, and key findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MemoryBank</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>MemoryBank</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A long-term memory system that maintains a memory bank (external store) with mechanisms for storing and retrieving memory items; evaluated as an agent memory mechanism in MemBench.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Memorybank: Enhancing large language models with long-term memory</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>MemoryBank</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Implements a memory bank approach (Zhong et al., 2024) that writes structured memory items to an external storage and retrieves them; in MemBench it showed good reflective-memory performance at small scale but high write-time cost.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Qwen2.5-7B-Instruct (primary; also tested with other LLMs)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>See above.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>MemBench reflective & factual memory evaluation (participation & observation scenarios)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>As above.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>external long-term memory retrieval & QA</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>external long-term memory bank</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism</strong></td>
                            <td>Write structured entries (memory items) to a memory bank; retrieve via index/search and feed retrieved items to model; includes explicit write operations.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_representation</strong></td>
                            <td>Structured memory items and summaries derived from dialogues.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_method</strong></td>
                            <td>Indexed retrieval/search (implementation-specific; evaluated using multilingual-e5-small for retrieval-type operations in experiments).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>Reflective participation accuracy: 10k=0.692, 100k=0.400; Reflective observation accuracy: 1k=0.900, 100k=0.333. Factual participation accuracy: 10k=0.442, 100k=0.456; Factual observation accuracy: 1k=0.721, 100k=0.488 (Tables 3 & 4).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_with_without_memory</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_comparison</strong></td>
                            <td>MemoryBank performed well on reflective tasks at 10k but degraded at 100k; notable for high write time (WT ~18.243s on some factual settings) making it expensive to maintain at scale compared to retrieval buffers.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>MemoryBank can capture reflective memory when resources permit, but its write-time cost limits practical scalability; may be effective when application tolerates slower writes.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>High write-time overhead; capacity and long-term retention degrade at very large scales in the evaluated setup.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'MemBench: Towards More Comprehensive Evaluation on the Memory of LLM-based Agents', 'publication_date_yy_mm': '2025-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8177.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e8177.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the memory mechanism, tasks, comparative results, ablations, and key findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MemGPT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>MemGPT</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A memory method that leverages an LLM-centric approach (treating the LLM as an OS-like memory manager) for reading and organizing memory; evaluated in MemBench and noted for slow read time.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Memgpt: Towards llms as operating systems</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>MemGPT</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Implements the MemGPT approach (Packer et al., 2023): uses the LLM itself heavily to read/process memory and produce memory artifacts; in MemBench it showed good reflective results at small scale but large read-time and steep performance decline at scale.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Qwen2.5-7B-Instruct (primary; also tested other LLMs)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>See above.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>MemBench factual & reflective memory evaluation (participation & observation scenarios)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>As above.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>LLM-driven memory management / retrieval & generation</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>LLM-mediated memory management (model-centric memory operations)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism</strong></td>
                            <td>Use the LLM to read large amounts of history and generate summaries/artifacts or select evidence; relies on the model to perform memory indexing/selection (heavy read operations).</td>
                        </tr>
                        <tr>
                            <td><strong>memory_representation</strong></td>
                            <td>Generated summaries, extracted evidence, LLM-produced memory artifacts.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_method</strong></td>
                            <td>LLM-based reading and synthesis (model performs selection and summarization rather than pure vector retrieval).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>Factual participation accuracy: 10k=0.455, 100k=0.411; Factual observation accuracy: 1k=0.789, 100k=0.488. Reflective participation accuracy: 10k=0.733, 100k=0.367; Reflective observation accuracy: 1k=0.883, 100k=0.200 (Tables 3 & 4). Capacity tests (Figure 5) show MemGPT accuracy sharply declines as memory tokens increase.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_with_without_memory</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_comparison</strong></td>
                            <td>MemGPT achieves good reflective performance at small scale but shows a sharp decline with increasing memory tokens and exhibits very large read-time cost (RT ~1.541s to 4.549s depending on setting), making it slow compared to retrieval-based systems.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>LLM-centric memory approaches can capture reflective memory for short histories, but they are computationally expensive and fragile at scale; capacity limits of the base model manifest as steep accuracy drops for long token histories.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>High read-time latency and limited capacity retention as token count increases; not scalable for very long trajectories in the evaluated setup.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'MemBench: Towards More Comprehensive Evaluation on the Memory of LLM-based Agents', 'publication_date_yy_mm': '2025-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8177.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e8177.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the memory mechanism, tasks, comparative results, ablations, and key findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SCMemory</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Self-Controlled Memory (SCMemory)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A memory framework where the agent controls what to store and forget (a self-controlled forgetting/selection mechanism); evaluated in MemBench and shown to have limitations on capacity and reflective tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Enhancing large language model with self-controlled memory framework</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>SCMemory</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Implements Self-Controlled Memory (Wang et al., 2023): the agent selectively stores and prunes memory guided by policies; included in MemBench to evaluate trade-offs between compactness and retention.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Qwen2.5-7B-Instruct (primary; also evaluated with other LLMs)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>See above.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>MemBench factual & reflective memory evaluation (participation & observation scenarios)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>As above.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>selective memory storage & forgetting</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>controlled/managed memory with forgetting policy</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism</strong></td>
                            <td>Selective storage and forgetting of memory items according to internal heuristics/policies (self-controlled); reduces stored memory footprint but may remove useful items.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_representation</strong></td>
                            <td>Selected memory items and pruned memory store; sometimes summarized representations.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_method</strong></td>
                            <td>Depending on retained items: either semantic retrieval on remaining store or recency prompt; combination varies with implementation.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>Factual participation accuracy: 10k=0.355, 100k=0.444; Factual observation accuracy: 1k=0.529, 100k=0.429. Reflective participation accuracy: 10k=0.542, 100k=0.267; Reflective observation accuracy: 1k=0.783, 100k=0.333 (Tables 3 & 4). Capacity tests (Figure 5) show SCMemory accuracy also exhibits sharp decline as tokens increase.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_with_without_memory</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_comparison</strong></td>
                            <td>SCMemory maintains compactness but underperforms many other mechanisms on factual and reflective tasks at scale; shows sharp accuracy declines with growing token histories similar to MemGPT.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Selective forgetting can reduce memory size but may remove evidence needed for long-term queries; achieving the right retention policy is challenging and current SCMemory implementation underperforms retrieval-based methods on the long-range MemBench tests.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Designing effective forgetting policies is hard; observed capacity limitations and accuracy degradation as dataset size grows; trade-off between compactness and retention reduces accuracy on multi-session queries.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'MemBench: Towards More Comprehensive Evaluation on the Memory of LLM-based Agents', 'publication_date_yy_mm': '2025-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Generative agents: Interactive simulacra of human behavior <em>(Rating: 2)</em></li>
                <li>Memgpt: Towards llms as operating systems <em>(Rating: 2)</em></li>
                <li>Memorybank: Enhancing large language models with long-term memory <em>(Rating: 2)</em></li>
                <li>Enhancing large language model with self-controlled memory framework <em>(Rating: 2)</em></li>
                <li>Memsim: A bayesian simulator for evaluating memory of llm-based personal assistants <em>(Rating: 2)</em></li>
                <li>MemEngine: A unified and modular library for developing advanced memory of LLM-based agents <em>(Rating: 2)</em></li>
                <li>LongMemEval: Benchmarking chat assistants on long-term interactive memory <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-8177",
    "paper_id": "paper-280011015",
    "extraction_schema_id": "extraction-schema-150",
    "extracted_data": [
        {
            "name_short": "FullMemory",
            "name_full": "Full Memory (full-context buffer)",
            "brief_description": "A memory mechanism that keeps the full conversation/history in the agent's accessible context (effectively concatenating all past messages) to answer memory queries; evaluated as a baseline in this paper's MemBench benchmark.",
            "citation_title": "",
            "mention_or_use": "use",
            "agent_name": "FullMemory",
            "agent_description": "Agent variant that uses the entire past trajectory (no explicit compression or retrieval) as its memory input when answering; implemented as one of seven memory mechanisms in MemBench.",
            "model_name": "Qwen2.5-7B-Instruct (primary; also evaluated with GPT-4o-mini, Meta-Llama-3.1-8B-Instruct, glm-4-9b-chat)",
            "model_description": "Qwen2.5-7B-Instruct used as default base model for agents; other LLMs tested to measure model choice effects (GPT-4o-mini, Meta-Llama-3.1-8B-Instruct, glm-4-9b-chat).",
            "task_name": "MemBench factual & reflective memory evaluation (participation & observation scenarios)",
            "task_description": "Agents must store and recall factual attributes (single-hop, multi-hop, temporal, knowledge-update) and reflective memory (high-level preferences, emotions) from time-aware multi-session dialogues and message streams; tests include varying noise level and dataset scale (10k vs 100k token trajectories).",
            "task_type": "time-aware memory evaluation; question answering / summarization",
            "memory_used": true,
            "memory_type": "working/full-context buffer",
            "memory_mechanism": "Concatenate/keep full past messages in the prompt (no specialized retrieval or summarization); answers generated using full context.",
            "memory_representation": "Raw past messages and agent responses (full dialogue history).",
            "memory_retrieval_method": "Prompt concatenation (entire buffer is presented to model).",
            "performance_with_memory": "Factual participation accuracy: 10k=0.647, 100k=0.489; Factual observation accuracy: 1k=0.786, 100k=0.631. Reflective participation accuracy: 10k=0.733, 100k=0.533; Reflective observation accuracy: 1k=0.883, 100k=0.333 (see Tables 3 & 4).",
            "performance_without_memory": null,
            "has_performance_with_without_memory": false,
            "ablation_or_comparison": "Compared to retrieval and recency methods, FullMemory performs well at moderate scale (10k) but degrades at large scale (100k) due to context window limits and inefficiency; read/write times negligible for small context but full-context scalability limited.",
            "key_findings": "FullMemory is strong on short-to-moderate trajectories but suffers performance declines when target evidence falls outside the model context window; it is efficient for small contexts but not scalable to very long histories.",
            "limitations_or_challenges": "Context-window limitations lead to loss of earlier evidence in long interactions; storing full history incurs practical scaling issues and does not handle noisy long trajectories well.",
            "uuid": "e8177.0",
            "source_info": {
                "paper_title": "MemBench: Towards More Comprehensive Evaluation on the Memory of LLM-based Agents",
                "publication_date_yy_mm": "2025-06"
            }
        },
        {
            "name_short": "RetrievalMemory",
            "name_full": "Retrieval-based Memory",
            "brief_description": "A retrieval-augmented memory mechanism that stores memory items externally and retrieves relevant evidence via vector search (multilingual-e5-small embeddings) to augment the model prompt at query time.",
            "citation_title": "",
            "mention_or_use": "use",
            "agent_name": "RetrievalMemory",
            "agent_description": "Agent variant that writes memory items to an external store and retrieves the most relevant items using semantic embeddings (multilingual-e5-small) and semantic search; implemented and benchmarked in MemBench.",
            "model_name": "Qwen2.5-7B-Instruct (primary; also evaluated with GPT-4o-mini, Meta-Llama-3.1-8B-Instruct, glm-4-9b-chat)",
            "model_description": "Same as above; retrieval operations used multilingual-e5-small embeddings for vector search.",
            "task_name": "MemBench factual & reflective memory evaluation (participation & observation scenarios)",
            "task_description": "As above: time-aware QA tests over factual and reflective content across participation and observation scenarios with noise and two dataset scales.",
            "task_type": "retrieval-augmented question answering / memory retrieval",
            "memory_used": true,
            "memory_type": "external retrieval-augmented memory (episodic store + vector DB)",
            "memory_mechanism": "Write memory items to an external vector store and at query time perform semantic search (multilingual-e5-small) to retrieve top evidence items, then provide retrieved items to the LM.",
            "memory_representation": "Key evidence dialogues/messages and indexed memory items (text chunks, evidence dialogues, summaries).",
            "memory_retrieval_method": "Semantic search (embedding-based retrieval using multilingual-e5-small).",
            "performance_with_memory": "Factual participation accuracy: 10k=0.692, 100k=0.833; Factual observation accuracy: 1k=0.883, 100k=0.933. Reflective participation accuracy: 10k=0.692, 100k=0.833; Reflective observation accuracy: 1k=0.883, 100k=0.933. Participation/observation recall@10: 10k P=0.776 O=0.847; 100k P=0.749 O=0.769 (see Tables 3,4).",
            "performance_without_memory": null,
            "has_performance_with_without_memory": false,
            "ablation_or_comparison": "RetrievalMemory is the most robust method at large scale (100k): it maintains high accuracy where FullMemory and RecentMemory decline; retrieval-based approach outperforms generative/summarization-based memories on long trajectories in MemBench.",
            "key_findings": "Retrieval-augmented memory is more robust to long histories and noisy contexts, preserving factual and reflective performance at scale; it also achieves strong recall@10 indicating effective retrieval of evidence.",
            "limitations_or_challenges": "Requires an external index and retrieval pipeline; retrieval quality depends on embedding quality and indexing; retrieval introduces read/write latency (measured RT ~0.024-0.041s in experiments).",
            "uuid": "e8177.1",
            "source_info": {
                "paper_title": "MemBench: Towards More Comprehensive Evaluation on the Memory of LLM-based Agents",
                "publication_date_yy_mm": "2025-06"
            }
        },
        {
            "name_short": "RecentMemory",
            "name_full": "Recent Memory (recency window)",
            "brief_description": "A simple memory mechanism that only keeps a fixed recent window of past interactions (recency-based buffer) so the agent relies on the most recent messages.",
            "citation_title": "",
            "mention_or_use": "use",
            "agent_name": "RecentMemory",
            "agent_description": "Agent variant that stores only a short sliding window of the most recent conversation turns (smaller context window) to answer memory queries; implemented in MemBench as a baseline.",
            "model_name": "Qwen2.5-7B-Instruct (primary; also evaluated with GPT-4o-mini, Meta-Llama-3.1-8B-Instruct, glm-4-9b-chat)",
            "model_description": "See above.",
            "task_name": "MemBench factual & reflective memory evaluation (participation & observation scenarios)",
            "task_description": "As above.",
            "task_type": "recency-based memory question answering",
            "memory_used": true,
            "memory_type": "working short-term/recency buffer",
            "memory_mechanism": "Keep only the most recent N turns/messages (fixed-time or fixed-turn sliding window); older content is not stored or retrievable.",
            "memory_representation": "Recent messages (sliding window of last turns).",
            "memory_retrieval_method": "Recency-based (simply present recent window to model).",
            "performance_with_memory": "Factual participation accuracy: 10k=0.639, 100k=0.422; Factual observation accuracy: 1k=0.800, 100k=0.512. Reflective participation accuracy: 10k=0.700, 100k=0.333; Reflective observation accuracy: 1k=0.867, 100k=0.400 (Tables 3 & 4).",
            "performance_without_memory": null,
            "has_performance_with_without_memory": false,
            "ablation_or_comparison": "RecentMemory performs well when target evidence is recent (good observation accuracy at small scale), but performance degrades substantially on large-scale/long-range tasks where evidence falls outside the recency window; decline is more pronounced than FullMemory because of smaller window size.",
            "key_findings": "Recency buffers are simple and effective for short-lived information, but insufficient for long-term memories or cross-session reasoning.",
            "limitations_or_challenges": "Inability to recall older evidence; choice of window size trades off recency vs. long-term retention; not robust to long histories.",
            "uuid": "e8177.2",
            "source_info": {
                "paper_title": "MemBench: Towards More Comprehensive Evaluation on the Memory of LLM-based Agents",
                "publication_date_yy_mm": "2025-06"
            }
        },
        {
            "name_short": "GenerativeAgent",
            "name_full": "GenerativeAgent (simulated agent memory via generative summaries)",
            "brief_description": "An agent approach that uses LLM generative capabilities to synthesize/summarize human-like memory traces (generative agent paradigm) and uses those generated artifacts as memory to drive behavior and answer queries.",
            "citation_title": "Generative agents: Interactive simulacra of human behavior",
            "mention_or_use": "use",
            "agent_name": "GenerativeAgent",
            "agent_description": "Implements the Generative Agents paradigm (Park et al., 2023): the agent generates higher-level summaries/behaviors from observed messages (reflective memory) and uses those to reason and respond.",
            "model_name": "Qwen2.5-7B-Instruct (primary; also evaluated with GPT-4o-mini, Meta-Llama-3.1-8B-Instruct, glm-4-9b-chat)",
            "model_description": "See above.",
            "task_name": "MemBench reflective & factual memory evaluation (participation & observation scenarios)",
            "task_description": "As above; emphasis on capturing reflective memory (preferences/emotions) via generative summarization and using summaries to answer reflective queries.",
            "task_type": "generative memory summarization & QA",
            "memory_used": true,
            "memory_type": "generative summarization / synthesized episodic memory",
            "memory_mechanism": "Use the LLM to produce summaries or simulated memory objects (high-level reflective memory) from multiple low-level factual mentions; store these summaries and use them to answer queries.",
            "memory_representation": "Generated summaries / high-level reflective memory artifacts, plus some factual evidence excerpts.",
            "memory_retrieval_method": "Prompting with generated summaries and relevant excerpts (combination of semantic retrieval of generated artifacts and prompt concatenation).",
            "performance_with_memory": "Reflective participation accuracy: 10k=0.742, 100k=0.333; Reflective observation accuracy: 1k=0.883, 100k=0.200. Factual participation accuracy: 10k=0.478, 100k=0.455; Factual observation accuracy: 1k=0.779, 100k=0.476 (Tables 3 & 4).",
            "performance_without_memory": null,
            "has_performance_with_without_memory": false,
            "ablation_or_comparison": "GenerativeAgent variants capture reflective memory well at smaller scale (10k), outperforming some baselines on reflective tasks, but performance drops at 100k likely due to limited context, forgetting, or compressed summaries losing traceability to original evidence.",
            "key_findings": "Generative summarization is effective for extracting reflective memory in moderate-length dialogues, but struggles to maintain accuracy over very long interaction histories; time/compute cost higher than simple retrieval for some base models.",
            "limitations_or_challenges": "Performance collapses on very long trajectories (100k) suggesting generated summaries may forget or overwrite earlier evidence; can be computationally expensive (noted high RT/WT for some LLM choices).",
            "uuid": "e8177.3",
            "source_info": {
                "paper_title": "MemBench: Towards More Comprehensive Evaluation on the Memory of LLM-based Agents",
                "publication_date_yy_mm": "2025-06"
            }
        },
        {
            "name_short": "MemoryBank",
            "name_full": "MemoryBank",
            "brief_description": "A long-term memory system that maintains a memory bank (external store) with mechanisms for storing and retrieving memory items; evaluated as an agent memory mechanism in MemBench.",
            "citation_title": "Memorybank: Enhancing large language models with long-term memory",
            "mention_or_use": "use",
            "agent_name": "MemoryBank",
            "agent_description": "Implements a memory bank approach (Zhong et al., 2024) that writes structured memory items to an external storage and retrieves them; in MemBench it showed good reflective-memory performance at small scale but high write-time cost.",
            "model_name": "Qwen2.5-7B-Instruct (primary; also tested with other LLMs)",
            "model_description": "See above.",
            "task_name": "MemBench reflective & factual memory evaluation (participation & observation scenarios)",
            "task_description": "As above.",
            "task_type": "external long-term memory retrieval & QA",
            "memory_used": true,
            "memory_type": "external long-term memory bank",
            "memory_mechanism": "Write structured entries (memory items) to a memory bank; retrieve via index/search and feed retrieved items to model; includes explicit write operations.",
            "memory_representation": "Structured memory items and summaries derived from dialogues.",
            "memory_retrieval_method": "Indexed retrieval/search (implementation-specific; evaluated using multilingual-e5-small for retrieval-type operations in experiments).",
            "performance_with_memory": "Reflective participation accuracy: 10k=0.692, 100k=0.400; Reflective observation accuracy: 1k=0.900, 100k=0.333. Factual participation accuracy: 10k=0.442, 100k=0.456; Factual observation accuracy: 1k=0.721, 100k=0.488 (Tables 3 & 4).",
            "performance_without_memory": null,
            "has_performance_with_without_memory": false,
            "ablation_or_comparison": "MemoryBank performed well on reflective tasks at 10k but degraded at 100k; notable for high write time (WT ~18.243s on some factual settings) making it expensive to maintain at scale compared to retrieval buffers.",
            "key_findings": "MemoryBank can capture reflective memory when resources permit, but its write-time cost limits practical scalability; may be effective when application tolerates slower writes.",
            "limitations_or_challenges": "High write-time overhead; capacity and long-term retention degrade at very large scales in the evaluated setup.",
            "uuid": "e8177.4",
            "source_info": {
                "paper_title": "MemBench: Towards More Comprehensive Evaluation on the Memory of LLM-based Agents",
                "publication_date_yy_mm": "2025-06"
            }
        },
        {
            "name_short": "MemGPT",
            "name_full": "MemGPT",
            "brief_description": "A memory method that leverages an LLM-centric approach (treating the LLM as an OS-like memory manager) for reading and organizing memory; evaluated in MemBench and noted for slow read time.",
            "citation_title": "Memgpt: Towards llms as operating systems",
            "mention_or_use": "use",
            "agent_name": "MemGPT",
            "agent_description": "Implements the MemGPT approach (Packer et al., 2023): uses the LLM itself heavily to read/process memory and produce memory artifacts; in MemBench it showed good reflective results at small scale but large read-time and steep performance decline at scale.",
            "model_name": "Qwen2.5-7B-Instruct (primary; also tested other LLMs)",
            "model_description": "See above.",
            "task_name": "MemBench factual & reflective memory evaluation (participation & observation scenarios)",
            "task_description": "As above.",
            "task_type": "LLM-driven memory management / retrieval & generation",
            "memory_used": true,
            "memory_type": "LLM-mediated memory management (model-centric memory operations)",
            "memory_mechanism": "Use the LLM to read large amounts of history and generate summaries/artifacts or select evidence; relies on the model to perform memory indexing/selection (heavy read operations).",
            "memory_representation": "Generated summaries, extracted evidence, LLM-produced memory artifacts.",
            "memory_retrieval_method": "LLM-based reading and synthesis (model performs selection and summarization rather than pure vector retrieval).",
            "performance_with_memory": "Factual participation accuracy: 10k=0.455, 100k=0.411; Factual observation accuracy: 1k=0.789, 100k=0.488. Reflective participation accuracy: 10k=0.733, 100k=0.367; Reflective observation accuracy: 1k=0.883, 100k=0.200 (Tables 3 & 4). Capacity tests (Figure 5) show MemGPT accuracy sharply declines as memory tokens increase.",
            "performance_without_memory": null,
            "has_performance_with_without_memory": false,
            "ablation_or_comparison": "MemGPT achieves good reflective performance at small scale but shows a sharp decline with increasing memory tokens and exhibits very large read-time cost (RT ~1.541s to 4.549s depending on setting), making it slow compared to retrieval-based systems.",
            "key_findings": "LLM-centric memory approaches can capture reflective memory for short histories, but they are computationally expensive and fragile at scale; capacity limits of the base model manifest as steep accuracy drops for long token histories.",
            "limitations_or_challenges": "High read-time latency and limited capacity retention as token count increases; not scalable for very long trajectories in the evaluated setup.",
            "uuid": "e8177.5",
            "source_info": {
                "paper_title": "MemBench: Towards More Comprehensive Evaluation on the Memory of LLM-based Agents",
                "publication_date_yy_mm": "2025-06"
            }
        },
        {
            "name_short": "SCMemory",
            "name_full": "Self-Controlled Memory (SCMemory)",
            "brief_description": "A memory framework where the agent controls what to store and forget (a self-controlled forgetting/selection mechanism); evaluated in MemBench and shown to have limitations on capacity and reflective tasks.",
            "citation_title": "Enhancing large language model with self-controlled memory framework",
            "mention_or_use": "use",
            "agent_name": "SCMemory",
            "agent_description": "Implements Self-Controlled Memory (Wang et al., 2023): the agent selectively stores and prunes memory guided by policies; included in MemBench to evaluate trade-offs between compactness and retention.",
            "model_name": "Qwen2.5-7B-Instruct (primary; also evaluated with other LLMs)",
            "model_description": "See above.",
            "task_name": "MemBench factual & reflective memory evaluation (participation & observation scenarios)",
            "task_description": "As above.",
            "task_type": "selective memory storage & forgetting",
            "memory_used": true,
            "memory_type": "controlled/managed memory with forgetting policy",
            "memory_mechanism": "Selective storage and forgetting of memory items according to internal heuristics/policies (self-controlled); reduces stored memory footprint but may remove useful items.",
            "memory_representation": "Selected memory items and pruned memory store; sometimes summarized representations.",
            "memory_retrieval_method": "Depending on retained items: either semantic retrieval on remaining store or recency prompt; combination varies with implementation.",
            "performance_with_memory": "Factual participation accuracy: 10k=0.355, 100k=0.444; Factual observation accuracy: 1k=0.529, 100k=0.429. Reflective participation accuracy: 10k=0.542, 100k=0.267; Reflective observation accuracy: 1k=0.783, 100k=0.333 (Tables 3 & 4). Capacity tests (Figure 5) show SCMemory accuracy also exhibits sharp decline as tokens increase.",
            "performance_without_memory": null,
            "has_performance_with_without_memory": false,
            "ablation_or_comparison": "SCMemory maintains compactness but underperforms many other mechanisms on factual and reflective tasks at scale; shows sharp accuracy declines with growing token histories similar to MemGPT.",
            "key_findings": "Selective forgetting can reduce memory size but may remove evidence needed for long-term queries; achieving the right retention policy is challenging and current SCMemory implementation underperforms retrieval-based methods on the long-range MemBench tests.",
            "limitations_or_challenges": "Designing effective forgetting policies is hard; observed capacity limitations and accuracy degradation as dataset size grows; trade-off between compactness and retention reduces accuracy on multi-session queries.",
            "uuid": "e8177.6",
            "source_info": {
                "paper_title": "MemBench: Towards More Comprehensive Evaluation on the Memory of LLM-based Agents",
                "publication_date_yy_mm": "2025-06"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Generative agents: Interactive simulacra of human behavior",
            "rating": 2,
            "sanitized_title": "generative_agents_interactive_simulacra_of_human_behavior"
        },
        {
            "paper_title": "Memgpt: Towards llms as operating systems",
            "rating": 2,
            "sanitized_title": "memgpt_towards_llms_as_operating_systems"
        },
        {
            "paper_title": "Memorybank: Enhancing large language models with long-term memory",
            "rating": 2,
            "sanitized_title": "memorybank_enhancing_large_language_models_with_longterm_memory"
        },
        {
            "paper_title": "Enhancing large language model with self-controlled memory framework",
            "rating": 2,
            "sanitized_title": "enhancing_large_language_model_with_selfcontrolled_memory_framework"
        },
        {
            "paper_title": "Memsim: A bayesian simulator for evaluating memory of llm-based personal assistants",
            "rating": 2,
            "sanitized_title": "memsim_a_bayesian_simulator_for_evaluating_memory_of_llmbased_personal_assistants"
        },
        {
            "paper_title": "MemEngine: A unified and modular library for developing advanced memory of LLM-based agents",
            "rating": 2,
            "sanitized_title": "memengine_a_unified_and_modular_library_for_developing_advanced_memory_of_llmbased_agents"
        },
        {
            "paper_title": "LongMemEval: Benchmarking chat assistants on long-term interactive memory",
            "rating": 1,
            "sanitized_title": "longmemeval_benchmarking_chat_assistants_on_longterm_interactive_memory"
        }
    ],
    "cost": 0.0168905,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>MemBench: Towards More Comprehensive Evaluation on the Memory of LLM-based Agents
20 Jun 2025</p>
<p>Haoran Tan tanhaoran1321@ruc.edu.cn 
Gaoling School of Artificial
Renmin University of China
BeijingChina</p>
<p>MOE * https://github.com/import-myself/Membench
Beijing Key Laboratory of Research on Large Models and Intelligent Governance  Engineering Research Center of Next-Generation Intelli-gent Search and Recommendation</p>
<p>Zeyu Zhang zeyuzhang@ruc.edu.cn 
Gaoling School of Artificial
Renmin University of China
BeijingChina</p>
<p>MOE * https://github.com/import-myself/Membench
Beijing Key Laboratory of Research on Large Models and Intelligent Governance  Engineering Research Center of Next-Generation Intelli-gent Search and Recommendation</p>
<p>Chen Ma 
Gaoling School of Artificial
Renmin University of China
BeijingChina</p>
<p>MOE * https://github.com/import-myself/Membench
Beijing Key Laboratory of Research on Large Models and Intelligent Governance  Engineering Research Center of Next-Generation Intelli-gent Search and Recommendation</p>
<p>Xu Chen xu.chen@ruc.edu.cn 
Gaoling School of Artificial
Renmin University of China
BeijingChina</p>
<p>Quanyu Dai daiquanyu@huawei.com 
Huawei Noah's Ark Lab</p>
<p>MOE * https://github.com/import-myself/Membench
Beijing Key Laboratory of Research on Large Models and Intelligent Governance  Engineering Research Center of Next-Generation Intelli-gent Search and Recommendation</p>
<p>Zhenhua Dong 
Huawei Noah's Ark Lab</p>
<p>MemBench: Towards More Comprehensive Evaluation on the Memory of LLM-based Agents
20 Jun 20258B889177265CE41F57D8A4D2EEB7227EarXiv:2506.21605v1[cs.CL]
Recent works have highlighted the significance of memory mechanisms in LLM-based agents, which enable them to store observed information and adapt to dynamic environments.However, evaluating their memory capabilities still remains challenges.Previous evaluations are commonly limited by the diversity of memory levels and interactive scenarios.They also lack comprehensive metrics to reflect the memory capabilities from multiple aspects.To address these problems, in this paper, we construct a more comprehensive dataset and benchmark to evaluate the memory capability of LLMbased agents.Our dataset incorporates factual memory and reflective memory as different levels, and proposes participation and observation as various interactive scenarios.Based on our dataset, we present a benchmark, named MemBench, to evaluate the memory capability of LLM-based agents from multiple aspects, including their effectiveness, efficiency, and capacity.To benefit the research community, we release our dataset and project at https: //github.com/import-myself/Membench.</p>
<p>Introduction</p>
<p>In recent years, large language models (LLMs) have demonstrated remarkable capabilities in processing natural languages and performing complex tasks across various domains (Zhao et al., 2023;Wu et al., 2024b).However, vanilla LLMs typically operate in static scenarios, without interacting with external environments, thereby limiting their potential advancement toward artificial general intelligence (AGI).To address this limitation, many recent works propose LLM-based agents with extra modules besides the foundation models, enabling them to interact with environments with autonomous learning and dynamic adaptation (Wang et al., 2024a;Xi et al., 2025).Among them, the memory module serves as an essential foundation for saving critical information and accumulating experiences.It empowers LLM-based agents to better meet the demands of dynamic tasks, as well as evolve within their environments continuously (Zhang et al., 2024a).</p>
<p>Some previous studies evaluate the memory capability of LLM-based agents in a subjective way, which adopts human evaluators or LLMs to score the memory process (Zhong et al., 2024).Other studies focus on the evaluation in an indirect way (Packer et al., 2023).They measure the task performances of agents conditional on different memory mechanisms, where a better memory mechanism generally leads to better performances.Recently, some studies introduce longterm dialogue datasets, which can be used to evaluate the long-term memory capabilities of LLMbased agents objectively (Wu et al., 2024a).</p>
<p>However, previous works have some limitations on evaluating the memory capability of LLM-based agents.First of all, most of them provide insufficient evaluation of the different levels of memory capabilities, which primarily focus on factual memory while neglecting reflective memory.Here, we define the factual memory as a low-level type of memory that involves information that is explicitly provided.In contrast, the reflective memory stands a higher level, which is not explicitly stated but can be implicitly reflected.For example, a user's taste preferences represent reflective memory, while their preference for specific dishes is factual memory.Second, most of them are limited to participation scenarios, where the agent interacts with the user from a first-person perspective.However, in the agent's daily usage, there are also observation scenarios, where the agent observes and records the user's messages from a third-person perspective.Moreover, most of them are just focusing on the effectiveness of memory mechanisms without considering their efficiency and capacity, which is also significant in real-world applications.</p>
<p>To address these limitations, we propose a more comprehensive dataset and benchmark to evaluate the memory capability of LLM-based agents.The major features of our dataset and benchmark are presented as follows:</p>
<p>Multi-scenario Dataset.To evaluate the agent's memory capabilities across different scenarios, our dataset includes data from two common usage scenarios.The first is the participation scenario, where the agent interacts with the user.The second is the observation scenario, where the agent is assumed as the role of an observer and required to record the information provided by the user.</p>
<p>Multi-level Memory Content.Our dataset focuses on both factual memory and reflective memory, enabling a comprehensive evaluation of the memory capability of LLM-based agents.It allows for the evaluation of memory capabilities in tasks including information extraction, cross-session reasoning, knowledge updating, temporal reasoning, as well as reflective summarization.</p>
<p>Multi-metric Evaluation.Based on our dataset, we introduce a multi-metric benchmark to evaluate the memory capabilities of LLM-based agents.To provide a comprehensive and obvious assessment of the various aspects of the agent's memory performance, we offer four evaluation metrics, including accuracy, recall, capacity, and temporal efficiency.</p>
<p>In summary, we introduce a dataset featuring multi-scenario and multi-level content, which is distinctively different from previous datasets.Additionally, we introduce a more comprehensive benchmark with mutli-metric evaluations.To benefit the research community, we have released our dataset and project at Github repository * .In the following parts, we provide the related works in Section 2. We illustrate the process of data construction in Section 3, and present the benchmark with analyses in Section 4. Finally, we draw conclusions of our paper in Section 5.</p>
<p>Related Works</p>
<p>In recent years, LLM-based agents have been widely applied in many fields, such as recommendation (Wu et al., 2024b), finance (Ding et al., 2024)  and personal assistants (Li et al., 2024), because of their great capabilities in solving complex tasks and interactive scenarios (Wang et al., 2024a).Among the various abilities of agents to solve problems, memory is one of the most important, which is responsible to store observed information and recall relevant experiences, in order to support LLM inference (Zhang et al., 2024a).The evaluation on the memory capability of LLM-based agents is a critical problem for developing advanced memory.Previous datasets used for memory evaluation mainly come from dialogue datasets designed to evaluate chat assistants, focusing on assessing the factual memory capabilities of the assistant.Lo-CoMo (Maharana et al., 2024) constructs longterm conversations with LLM-expanded personalized descriptions and temporal event graphs, creating conversations for multiple evaluation tasks.LongMemEval (Wu et al., 2024a) builds a userassistant interaction dataset with attribute ontology and timestamped history.Xu et al. (2022) adapts PersonaChat (Zhang et al., 2019) through translation and role-playing, with annotated personalization usage and partial information visibility.Bai et al. (2023) propose a bilingual benchmark in English and Chinese, covering comprehensive tasks like Q&amp;A, summarization, and code completion.An et al. (2023) provide a dataset designed to evaluate long-context language models across diverse domains and input lengths.PerLTQA (Du et al., 2024) generates character profiles and events with ChatGPT and Wikipedia, creating profiles, events, and QA pairs after manual validation.</p>
<p>As we have shown in Table 1, most of these datasets lack diverse scenarios, focusing only on participation scenarios (PS) and overlooking the agent's observation scenarios (OS).Additionally, they only focus on factual memory (FM), neglecting reflective memory (RM).Some works do not include the profiles of users.Previous studies typically use these datasets in long-context evaluation methods that do not align with the agent's mem-ory process.Moreover, the evaluation metrics used with these datasets are not comprehensive.</p>
<p>Compared with previous works, our work is the first study that emphasizes reflective memory, puts forward observation scenarios, adopts evaluation methods that are better suited to the agent's memory process, with more comprehensive metrics.</p>
<p>Dataset Construction</p>
<p>Pipeline of Data Generation</p>
<p>Inspired by MemSim (Zhang et al., 2024b), we expand the dataset for memory evaluation based on this framework.Building upon the question types of factual memory included in Memsim, we extend the evaluation of the ability for memory knowledge updating and extracting information from the assistant's response in single or multi-session.In addition, we incorporate reflective memory generation methods and extend observation scenario to participation scenario.The dataset creation process is as follows and as shown in Figure 1.</p>
<p>User's Relation Graph Sampling.Following the approach of Memsim, we create a relation graph composed of user profiles and their related entities including individuals, events, places, and items.Based on Memsim's method for sampling attributes related to factual memory, we propose a method for sampling of high-level attributes related to reflective memory.To better fit the distribution of high-level attributes in the real world, we leverage user-item relationship pairs and relevant ratings from three recommendation datasets, including MovieLens (Harper and Konstan, 2015), Food (Majumder et al., 2019), and Goodreads (Wan and McAuley, 2018;Wan et al., 2019).We extract each user's high-level preferences in each recommendation dataset by identifying the most frequent category of items with which he or she likes or rates positively.If there is no category information, we utilize LLMs(GPT-4o-mini) to summarize the highlevel preferences corresponding to these positive relation items.We assign high-level preference attributes using either random matching or matching based on identical attributes, and then we obtain the user's relation graph shown in Figure 2. At the same time, we construct three one-to-many mappings between high-level preferences and low-level factual attributes with LLMs or the item-category relationships from the recommendation datasets.</p>
<p>Memory Dataset Construction.Memsim provides a data creation process for the observation scenario.We expand it to the participation scenario using the self-dialogue method.When selecting high-level preference attributes, we should choose multiple low-level preference attributes from the mapping dictionary and use these low-level preference attributes to generate the corresponding evidence dialogues.For example, a user might say, "I like the movie Star Wars".To ensure fluency of the conversation, the specific discussions about the low-level preferences, such as the discussion about content of the movie, are inserted between the key dialogues to form a complete conversation.Finally, the remaining relevant attributes are used to generate multi-turn dialogues.The evidence dialogues will be inserted into them to form a complete session.We introduce a time-based session division approach, where the timestamp within a session is assigned continuously to each turn dialogue, typically with short intervals, such as one minute.The timestamp across different sessions maintains a sequential order, but the time gap between two adjacent sessions is typically longer, such as one day.</p>
<p>Multi-scenario Memory</p>
<p>The interactive scenarios of the agent can be categorized into two types, including the participation scenario and the observation scenario.In the participation scenario, the agent interacts with the user, while in the observation scenario, the agent serves only as an observer, recording user-inputted messages.In the participation scenario, other modules of the agent, such as the reasoning module, will affect the memory module.However, in the observation scenario, the agent does not perform actions and thus does not influence memory.These two scenarios cannot be considered the same.Therefore, we provide the following two types of datasets:</p>
<p>Participation Memory Scenario.The participation memory scenario is represented by the dialogue between the user and the agent, which is the agent's typical usage scenario.To eliminate the influence of other modules of the agent, we predefine the agent's responses to the user's expressions.In the user-agent dialogue interaction, the agent's memory not only needs to remember the message expressed by the user but also needs to store the message of the agent's responses, such as the agent's reply when the user requests a recommendation.In our dataset, the data for participation scenario dataset consists of sessions composed of many turns in dialogues.</p>
<p>Observation Memory Scenario.The observa-    tion memory scenario is represented by the flow of message input from the user to the agent.In this process, the agent passively receives the user's message flow over time and does not interact with the user.This scenario focuses on the agent's role as an observer, where the agent only needs to remember the message expressed by the user without taking any action.In our dataset, the data for observation scenario dataset consists of message lists composed of many messages.</p>
<p>Multi-level Memory</p>
<p>In the daily usage of LLM-based agents, we expect it to have factual memory capabilities, while also hoping that its memory mechanism can summarize and reason at higher levels to generate reflective memory.Reflective memory enables the agent to gain a more comprehensive understanding of the user, thereby improving the satisfaction of subsequent interactions.From this perspective, we divide the types of memory data and questions in our dataset into two categories:</p>
<p>Factual Memory.It refers to the specific factual attributes of the users or the entities associated with them, such as their relative's age or occupation, the time details of events and so on.This information will be expressed in daily dialogues between users and agents.Asking questions about these attributes can test various memory abilities of the agent.For example, in dialogues, the user may not directly express the time of an event but might use indirect references, such as "next Monday", we can evaluate the agent's ability to extract information and instantly convert time-related information by asking it the exact time of the day of the month of the event.In addition, we can also evaluate its ability to update knowledge based on different expressions of the same attribute over time.Furthermore, by designing questions that require the integration of multiple entities' attributes for answers, we evaluate the agent's memory capability in terms of its memory reasoning abilities in both single-session and multi-session contexts.These question examples are shown in Figure 3.   to the extraction and summarization of high-level preferences based on the user's expression of lowlevel preferences, including some factual attributes in the dialogue.For example, the user's taste preferences are inferred from his expressions of liking for different dishes.To enhance the credibility of the answers, our memory content is reinforced through multiple expressions of different factual preferences or attributes to strengthen the understanding of the agent.We can evaluate the agent's memory mechanism's ability to extract and summarize preferences at different levels.</p>
<p>Reflective Memory. Reflective memory refers</p>
<p>Multi-metric Evaluation</p>
<p>In order to more comprehensively assess the memory mechanism of the agent, we employ a total of four evaluation metrics as follows.</p>
<p>Memory Accuracy.To avoid misjudgments caused by the agent's flexible expression of answers, in our evaluation dataset, all questions are set as multiple-choice questions.After the agent completes the memory process, both the questions and options will be submitted to the agent.The accuracy score of the memory is calculated by comparing the agent's choice with the true choice.</p>
<p>Memory Recall.For retrieval-based memory mechanisms, the accuracy of retrieval is also an important metric that needs to be measured.It not only reflects the agent's ability to effectively store and organize memory content, but also indicates the agent's efficient use of memory when answering questions.In the process of creating dialogues, we first generate key evidence dialogues for answering questions, which enables the measurement of retrieval accuracy.</p>
<p>Memory Capacity.We consider that the agent's memory mechanism might have a capacity limit, which is reflected in a sharp decline in accuracy when the amount of memory content reaches a certain point.This critical threshold represents the capacity of the memory.This phenomenon might not exist, because, for example, when evaluating the retrieval-based memory mechanisms, their accuracy depends on the effectiveness of retrieval.Memory Efficiency.Regarding the design of the agent's memory mechanism, we need to focus not only on the accuracy and completeness of the memory but also on efficiency.Some memory mechanisms may result in excessively high processing time costs for the agent, which could be unacceptable in practical applications.</p>
<p>Dataset Statistics</p>
<p>The dataset consists of two parts: (1) 500 graphs composed of user profiles and profiles of entities associated with users, and (2) multiple dialogues between users and assistants, multiple users' messages, and corresponding questions.The quantity is shown in Table 2.In order to better simulate the distribution of the location of answer in real-world conversation, the key evidence rounds in a session are almost evenly distributed in each round in a session.As shown in Figure 4, we can see the quantity distribution of different categories and the quantity distribution of key evidence rounds in the session.</p>
<p>Benchmark</p>
<p>In this section, we create a benchmark based on our dataset to evaluate the memory capabilities of LLMbased personal agents.To better evaluate the upper bounds of the agent's memory mechanism capabilities, we also utilize the News dataset (DataGuy and Amoako, 2022) to generate a large amount of dialogues and messages serving as noise memory content that is irrelevant to the questions.We ensures that the content of noise data does not contain factual conflicts with memory messages, or dialogues in our evaluation dataset.It also allows us to control the difficulty of the evaluation by adjusting the proportion of noise data.</p>
<p>Experimental Settings</p>
<p>To better align with the memory process of agents in real-world scenarios, particularly the flow of time, we simulate the interaction process between the user and the agent to input the content that needs to be remembered.At time t, we input the user's statement from the t-th round, while content from the previous t  1 round and earlier can only be recalled through memory.In the participation memory scenario, at the t-th round, the agent not only needs to remember the user's messages but also needs to remember the response it has generated, which is predefined by us.Meanwhile, in the observation scenario, the agent only needs to remember the user's messages.</p>
<p>To set different levels of difficulty, we utilize the noise dataset to randomly insert some noise sessions into the adjacent sessions.By controlling the proportion, we create a dataset with an average length of over 100k tokens for each individual test.Due to the large number of datasets we have created and the complexity of the agent's memory mechanism design, we perform uniform sampling on each subset of the two different sized datasets as the final tests in this paper.In the dataset of ordinary size, we extract 120 reflective memory and 360 factual memory data in participation test data (each session has about 10K tokens), as well as 60 reflective memory data and 280 factual memory data in observation test data (each message list has about 1K tokens), formulating as Sub-dataset 1.For the 100k dataset, we extract 30 reflective memory data and 90 factual memory data in participation test data (each session has about 100K tokens), as well as 15 reflective and 84 factual memory data in observation test data (each message list has about 10K tokens), denoted as Sub-dataset 2.</p>
<p>To eliminate the influence of other memory mechanism designs on the agent in the evaluation results, we make no modifications to the agent's action modules or other components.Based on MemEngine (Zhang et al., 2025), we implement seven memory mechanisms, using Qwen2.5-7Bas the base model for the agent applications on our benchmark, including FullMemory, RetrievalMemory, RecentMemory, Genera-tiveAgent (Park et al., 2023), MemoryBank (Zhong et al., 2024), MemGPT (Packer et al., 2023), and Self-Controlled Memory (SCMemory) (Wang et al., 2023).In our experiments, all methods that involve retrieval use the multilingual-e5- small (Wang et al., 2024b) for retrieval.</p>
<p>Evaluations on Factual Memory</p>
<p>The test results for factual memory are shown in Table 3. FullMemory, RetrievalMemory, and Recent-Memory perform better than other memory mechanisms on Sub-dataset 1.However, on Sub-dataset 2, FullMemory and RecentMemory exhibit a certain degree of decline, as the target message may fall outside the memory window.Due to the smaller window size of RecentMemory, the decline is more obvious.Other designed memory mechanisms did not show significantly superior performance in our evaluation, which might be due to flaws in these memory mechanisms.Additionally, it is important to note the time consumed by these memory mechanisms when reading and writing each round of message, especially MemGPT, which takes a longer time to read information, and MemoryBank, which takes longer to write information.</p>
<p>The previous evaluation works are not focusing on the design of agent memory mechanisms and solely provided factual memory datasets, so it could not adequately discuss the agent's ability to summarize reflective memory.In the following part, we evaluate on the reflective memory.</p>
<p>Evaluations on Reflective Memory</p>
<p>The test results for reflective memory are shown in Table 4.It can be observed that GenerativeAgent, MemGPT, and MemoryBank performed very well on Sub-dataset 1, but their performance significantly declines on Sub-dataset 2. Only the retrievalbased RetrievalMemory achieved the remaining good results.It is likely due to the limited con- text window of the models or the incorporation of forgetting mechanisms in these memory systems, which leads to the loss of important memories.However, these findings still suggest that well-designed memory mechanisms are capable of effectively capturing reflective memory.How to maintain this ability after prolonged interactions may pose a challenging research problem.</p>
<p>Evaluations on Memory Capacity</p>
<p>To explore the capacity of the agent's memory mechanism, we test the answering accuracy of each round after the key evidence turns on the observation scenario in Sub-dataset 2(100k).In order to observe the changes in the accuracy of MemGPT and Self-Controlled Memory with the number tokens increases, we drew Figure 5. From the results, we can observe that both memory mechanisms exhibit a sharp decline, which may be due to the upper limit of memory performance retention capacity for these memory mechanisms in Qwen2.5-7B-Instruct(Yang et al., 2024;Team, 2024).</p>
<p>Comparison of Different Inference Models</p>
<p>In practical applications of agents, different models may be selected for different memory mechanisms.</p>
<p>Therefore, we evaluate the performance of several common models across various memory mechanisms.Specifically, we selected Qwen2.5-7B-Instruct,gpt-4o-mini, Meta-Llama-3.1-8B-Instructand glm-4b-chat (GLM et al., 2024) for evaluation.The results are shown in Table 5.Under the same context window length, the choice of base model significantly affects the agents' performence.</p>
<p>In most cases, GPT-4o-mini performs as the best model compared to others.Although the factual memory capability of Meta-Llama-3.1-8B-Instruct is notably inferior to that of other models, its reflective memory ability is still relatively good.Interestingly, for GenerativeAgent, choosing GPT-4o-mini as the base model results in a significantly higher time consumption compared to other models in our experiments.However, in most cases, the time consumption differences between the three models are not substantial.</p>
<p>Conclusion</p>
<p>This paper provides a more comprehensive and scalable dataset for evaluating LLM-based agent's memory mechanisms.It includes a dataset with multi-scenarios (both participation and observation), and multi-level memory content include re-flective memory and factual memory.Based on this dataset, we constructed a time-aware evaluation framework that simulates the daily interactions between users and agents with multi-metric include accuracy, recall, capacity and temporal efficiency.We evaluate the performance of seven common memory mechanisms in agents on our benchmark.</p>
<p>Limitations</p>
<p>The dataset proposed in this paper consists of a graph formed by the profiles of users and relevant entities, enabling further exploration of the agent's memory mechanism.Our evaluation method is limited by an assessment of memory for structured data.However, by comparing the construction of relevant entity profiles or the capture of specific attribute information in the agent's memory during user-agent interactions, we can investigate the agent's ability to structure memory.In addition, there are still many areas to explore in reflective memory, such as users' emotional memory.</p>
<p>Ethics Statement</p>
<p>The data used in this article to construct the dataset includes data from publicly available, authorized datasets.All publicly available data are used in accordance with their respective licenses for research purposes.The LLM-generated content may pose risks, including the potential for unintended biases or harmful output.Although we have taken steps to minimize these risks, we encourage users to apply the dataset responsibly to avoid ethical risks.</p>
<p>RestEventProfile."event type": "Community Fair", "main content": "Join us at the Community Fair for climbing challenges, equipment demos, and safety workshops!Engage with fellow enthusiasts, explore local climbing spots, and enjoy inspiring talks from seasoned climbers.Perfect for all skill levels and climbing enthusiasts!","location": "Miami, FL", "time": "2024-10-12 19:00", "event name": "Climb Fest", "scale": "nine hundred people", duration": "three day" ItemProfile: "relationship": "Own", "item type": "Laundry Detergent", "item name": "Arm &amp; Hammer Liquid Detergent", "item review": "As a police officer, I'm always on the go, and I need products that can keep up with my busy lifestyle.I've been using Arm &amp; Hammer Liquid Detergent for a while now, and I have to say, it's been a game changer for me.Not only does it tackle tough stains from my uniforms and gear with ease, but it also leaves my clothes smelling fresh and clean.The added baking soda really helps to neutralize odors, which is a must when you're working in various environments.Plus, I appreciate that it's available in eco-friendly options, making it easier to care for the planet while looking after my laundry.Definitely a solid choice for anyone looking for effective and reliable detergent!"PlaceProfile.Place example: "relationship": "Visited","place type": "Mall", "place name": "The Grove", "place review": "I recently visited The Grove and I have to say, it was a really refreshing experience.The vibe there is incredibly friendly and welcoming, just like the community I strive to serve as a police officer.The shops and restaurants offer a great variety, and I especially enjoyed grabbing a bite at one of the local eateries.The layout is easy to navigate, making it a perfect spot to relax and enjoy some fresh air.As someone who loves climbing, I appreciated the green spaces where you can unwind and enjoy nature.It's a fantastic place to spend time with family or friends.The only downside I found was that it got a bit crowded during peak hours, but that's to be expected in such a popular location.Overall, I'd highly recommend The Grove to anyone looking for a fun and friendly outing!"User: I'm looking for a delicious dish to try, aside from the ones mentioned earlier.</p>
<p>Assistant: I'm a big fan of Apple Pie; it's such a delightful treat that everyone should definitely give it a try! User: I'm looking for a good book to read, excluding the ones mentioned earlier.</p>
<p>Assistant: I really think Naked is a fantastic read; it's definitely worth checking out!User: I'm looking for a good book to read, aside from the ones mentioned earlier.</p>
<p>Assistant: I really think everyone should check out Politically Correct Bedtime Stories: Modern Tales for Our Life and Times; it offers a hilarious twist on classic tales that resonate with today's issues.</p>
<p>Question: What movies, books and dishes have you recommended to me?</p>
<p>Answer:</p>
<p>["Alien (1979)","Fugitive, The (1993)","Apple Pie","Naked","Politically Correct Bedtime Stories: Modern Tales for Our Life and Times"]</p>
<p>Multi session highlevel preference User: I'm a big fan of prosciutto and melon; there's just something about that sweet and savory combination that I can't resist!Assistant:... User: I'm a fan of Prosciutto and Melon, but I also really enjoy Salted Maple Ice Cream; it's a unique treat that hits the spot!Assistant: ... User: I really love Salted Maple Ice Cream, and Pecan Praline is another favorite of mine!Assistant: ... User: I really enjoy Pecan Praline, but I also have a soft spot for Salted Butter Toffee; there's something so satisfying about that perfect blend of sweet and salty.</p>
<p>Assistant: ... User: I really love Salted Peanut Butter Cookies, just like I enjoy Salted Butter Toffee.</p>
<p>Assistant:... Question: According to the dishes I mentioned, Which flavor I might prefer?</p>
<p>Answer: Sweet and Salty</p>
<p>A.5 Observation Example</p>
<p>The only difference between the data for participation and the data here is the absence of responses from "assistant," so specific examples are not provided here.["Sweet", "Sour", "Spicy", "Salty", "Umami", "Bitter", "Sweet and Salty", "Sweet and Sour", "Salty and Umami", "Sour and Spicy", "Sweet, Salty, and Spicy", "Sour and Salty", "Sour, Sweet, and Salty", "Salty, Umami, and Spicy", "Numbing and Spicy", "Creamy and Sweet", "Umami and Sweet", "Bitter and Sweet", "Astringent", "Numbing", "Rich and Fatty", "Cool", "Warm and Spicy"] example output:{{'taste': 'sweet'}} C.2 Self-dialogue Prompt Role Dialogue Generation Prompt.Please generate a {round_length}-round interactive conversion between the user and assistant, with a total of {sen-tence_length} sentences.The dialogue's main content should based on the given information about the user's {entity}.Ensure that no information beyond what is provided is introduced in the dialogue.<strong>Note that the user cannot ask the assistant for information because the assistant does not know the information.</strong>Note that the assistant is the user's personal assistant, so it should only respond passively to the user's dialogue, but it can reply with varied content.Please return the conversation in a JSON list format as shown in the example, ensuring that the result can be directly parsed json.loads.<strong>Every json must includes both user and assistant with their words!Every json's format is {{"user": user's words, "assistant": assistant's words}}</strong> #[Information]: {information} #example: [{{"user": "I wanted to talk to you about my cousin, Ethan Parker.He's 39 years old.","assistant": "Certainly!Ethan is 39.Is there something specific you'd like to discuss about him?"}}, {{"user": "Well, he's actually pretty short for a guy, only 162 cm.He always jokes about it, though.","assistant": "It sounds like Ethan has a good sense of humor about his height.That's always a great quality!"}}, {{"user": "Yes, he really does.It's one of the things that makes him so fun to be around.","assistant": "I can imagine!Having a cousin with a lighthearted attitude must make family gatherings enjoyable."}},{{"user": "Definitely.And since we're so close in age, it feels like he's more of a friend than just family.","assistant": "That sounds wonderful.It must be special to have that kind of bond with your cousin."}}{{"user": "It really is.We've shared a lot of memories growing up together.","assistant": "Those shared memories must make your relationship even stronger.It sounds like Ethan has been a big part of your life."}}]</p>
<p>Event Dialogue Generation Prompt.Please generate a {round_length}-round interactive conversion between the user and assistant, with a total of {sentence_length} sentences.The dialogue's main content should based on the given information about the {event_name}.Ensure that no information beyond what is provided is introduced in the dialogue.Note that the assistant is the user's personal assistant, so it should only respond passively to the user's dialogue, but it can reply with varied content.Note that the user cannot ask the assistant for information because the assistant does not know the information.You can start with user saying I'm going to attend {event_name} Please return the conversation in a JSON list format as shown in the example, ensuring that the result can be directly parsed by json.loads.#[Information]: {information} #example: [{{"user": "I wanted to talk to you about my cousin, Ethan Parker.He's 39 years old.","assistant": "Certainly!Ethan is 39.Is there something specific you'd like to discuss about him?"}}, {{"user": "Well, he's actually pretty short for a guy, only 162 cm.He always jokes about it, though.","assistant": "It sounds like Ethan has a good sense of humor about his height.That's always a great quality!"}}, {{"user": "Yes, he really does.It's one of the things that makes him so fun to be around.","assistant": "I can imagine!Having a cousin with a lighthearted attitude must make family gatherings enjoyable."}},{{"user": "Definitely.And since we're so close in age, it feels like he's more of a friend than just family.","assistant": "That sounds wonderful.It must be special to have that kind of bond with your cousin."}}{{"user": "It really is.We've shared a lot of memories growing up together.","assistant": "Those shared memories must make your relationship even stronger.It sounds like Ethan has been a big part of your life."}}]</p>
<p>C.3 Observation Prompt</p>
<p>Role Message Prompt.[User Message]: {mes-sage} Please rewrite the above user message into a colloquial declarative sentence.Ensure it is smooth and free of grammatical errors, without changing the original information.Only output the rewritten user message, without including the original message.Do not output any other description.Output example: Lucas Grant, who is my boss, has a Master's degree.""" Event Message Prompt.[User Message]: {mes-sage} Please rewrite the above user message into a colloquial declarative sentence.Ensure it is smooth and free of grammatical errors, without changing the original information, and avoid using 'you'.Don't forget use I , me or my Only output the rewritten user message, without including the original message.Do not output any other description.Output example: Climb Fest draws a crowd of around nine hundred people.</p>
<p>D Result Details D.1 Reflective Result</p>
<p>In Tab 10, we show the detailed results of our 10k-Reflective memory dataset.</p>
<p>D.2 Facutal Result</p>
<p>In Tab 11, we show the detailed results of our 10k-Factual-Partipation memory dataset.In Tab 12, we show the detailed results of our 10k-Factual-Observation memory dataset.</p>
<p>Figure 1 :
1
Figure 1: An example of generating dialogue data.First, the event "Build Start 2024" is extracted with the time "next week Mon 7:00 PM," which is then used to generate evidence dialogues and questions.It's merged with dialogues generated from other attributes to form a complete dialogue, and an answer is generated based on the provided time label "2024-10-07 Monday 19:00".</p>
<p>Figure 2 :
2
Figure 2: A user relation graph is composed of a user's profile and his or her associated entities including individuals, events, items and places.</p>
<p>The distribution of the number of different round locations of key evidence dialogue turn within a session.</p>
<p>Figure 4 :
4
Figure 4: The details of the category distribution and answer distribution in the dataset.</p>
<p>Figure 5 :
5
Figure 5: The accuracy of SCMemory(top-left), MemGPT(top-right), GenerativeAgent(bottom-left) and RecentMemory(bottom-right) as the memory token increases.</p>
<p>Table 1 :
1
The comparision among different datasets.PS indicates Participation Scenario.OS indicates Observation Scenario.FM indicates Factual Memory.RM indicates Reflective Memory.
DatasetsProfilesScenariosLevelsPerLTQAPSFMLoCoMoPSFMLongMemEvalPSFMMemBenchPS &amp; OSFM &amp; RM</p>
<p>OR time: next week Mon 7:00 PM event_name: Build Start 2024 scale: seven hun  relation_profiles:  Places:  work_events: event_type: Project Kickoff Meeting location: Portland, OR event_name: Build Start 2024 time: next week Mon 7:00 PM scale: seven hundred people duration: nine day items:  name: Emily Johnson age: 36 years old height: 170 cm birthday: 10/22 hometown: Jacksonville, FL colleague_profiles:  Question:
Notework_events: event_type: Project Kickoff Meeting location: Portland, What time is Build Start 2024 scheduled to begin? SamplingI'm going to attendBuild Start 2024.That sounds exciting!Build Start 2024 is agreat opportunity.</p>
<p>Note Single Hop Single Session. Multi Session. Comparative Multi Hop Knowledge Update Single session assistant
charm. standout with her creativity and and she's always been a real My sister's name is Amelia Brooks, My niece runs a company called TechInnovate Systems LLC. Question: What is the name of my niece's company? Answer: Question: of someone named What is the birthday LLC TechInnovate Systemsold. My Uncle Landon Pierce is 27 years My niece, Clara Jennings, is 28 years old. Clara Jennings Answer: Pierce? or Landon Question: Who is older, Clara JenningsPlease recommend a delicious dish to try, aside from the ones mentioned. Apple Pie is a great treat everyone should try!User Agent Session gapMy sister's birthday is coming up onAmelia Brooks?December 11th.Answer: 12/11Question:The Policing Forum lasts for four days, and I can't wait to see what they have in store during that time.Question: How long does the Policing Forum last?How many people live in Philadelphia, PA?I just realized I need to correct myself-Policing Forum lasts forAnswer: one dayAnswer: 2 peopleone day. My subordinate's email address is  hobby of collecting antiques. My subordinate has this coolQuestion: What are the main of the individual with the email aw.gov? maya.carter@bostonl interests and hobbiesSophie Turner, my aunt, hails from Chicago, IL. might prefer? Which flavor I mentioned, the dishes I According to Question:watch. Recommend a great movie to maya.carter@bostonlaw.gov. Answer: Gather historical their value items and appreciateRecommend a great movie.to me? recommended dishes have you Question: What movies, books, andAnswer: Sweet and SaltyQuestion: What movies have you recommended?Answer: [Alien (1979), The FugitiveSuggest another fantastic movie. Jurassic Park (1993) is incredible with groundbreaking effects!Answer: <a href="1993">Return of the Jedi (1983), Jurassic Park (1993)</a>, Apple Pie, Naked, Politically Correct Bedtime Stories]
 My brother Ethan is from Boston, MA   My uncle, Pierce, is from Philadelphia, PA   A series of other Other Sessions My boss, Nolan Hayes, is from Philadelphia, PA.Try Alien (1979); it's a great sci-fi horror!Please suggest another movie, aside from the ones I mentioned.How about The Fugitive (1993)?It's thrilling!Recommend a new book to read.Naked is excellent, worth checking out!Suggest another book, please.Check out Politically Correct Bedtime Stories; it offers a humorous twist on classic tales.Multi session highlevel preference I'm a big fan of prosciutto and melon; there's just something about that sweet and savory combination that I can't resist!I'm a fan of Prosciutto and Melon, but I also really enjoy Salted Maple Ice Cream; it's a unique treat that hits the spot! I really love Salted Maple Ice Cream, and Pecan Praline is another favorite of mine!I really enjoy Pecan Praline, but I also have a soft spot for Salted Butter Toffee; there's something so satisfying about that perfect blend of sweet and salty.  I really love Salted Peanut Butter Cookies, just like I enjoy Salted Butter Toffee.   Return of the Jedi (1983) is iconic with thrilling space battles! Post</p>
<p>Processing Aggregative Multi session assistant
My coworker, Maxwell, is fromIndianapolis, IN.9.1% 9.1% 9.1% 13.6% 9.1% 9.1% 13.6% 9.1% 13.6% 4.5%SingleHop MultiHop Comparative Aggregative PostProcessing KnowledgeUpdate SingleAssistant MultiHighlevel SingleHighlevel MultiAssistant20.8%20.8% 12.5%8.3%12.5% 12.5% 12.5%SingleHop MultiHop Comparative Aggregative PostProcessing KnowledgeUpdate SingleHighlevel(a) The distribution of different types of(b) The distribution of different types ofquestions in the participation dataset.questions in the participation dataset.
  Figure 3: An overview of part categories of data used to test different abilities.</p>
<p>Table 2 :
2
The statistics of our dataset.TPT indicates the average number of tokens per trajectory.PS indicates Participation Scenario.OS indicates Observation Scenario.RM indicates Reflective Memory.FM indicates Factual Memory
Data Type # Session # Question # TrajectoryTPTPS-RM3.5k3.5k3.5k2,195PS-FM51k39k8k10,285OS-RM2k2k2k745OS-FM8.5k8.5k8.5k617</p>
<p>Table 3 :
3
The results of different memory mechanisms on factual memory dataset.The read time (RT) and write time (WT) are presented in seconds per operation.
Participation-Accuracy Paticipation-Efficiency Observation-Accuracy Observation-EfficiencyMethod10k100kRTWT1k100kRTWTFullMemory0.6470.4890.001&lt;0.0010.7860.631&lt;0.001&lt;0.001RecentMemory0.6390.4220.001&lt;0.0010.80.512&lt;0.001&lt;0.001RetrievalMemmory 0.6920.8330.0410.0580.8830.9330.0240.026GenerativeAgent0.4780.4550.0456.1160.7790.4760.0316.239MemoryBank0.4420.4560.0358.0470.7210.4880.03718.243MemGPT0.4550.4114.5490.1060.7890.4881.5412.480SCMemory0.3550.4441.5312.2760.5290.4290.0850.535Participation-Recall@10Observation-Recall@10Method10k100k10k100kRetrievalMemmory0.7760.7490.8470.769</p>
<p>Table 4 :
4
The results of different mechanisms on reflective memory dataset.The read time (RT) and write time (WT) are presented in seconds per operation.
Participation-Accuracy Paticipation-Efficiency Observation-Accuracy Observation-EfficiencyMethod10k100kRTWT1k100kRTWTFullMemory0.7330.533&lt;0.001&lt;0.0010.8830.333&lt;0.001&lt;0.001RecentMemory0.7000.333&lt;0.001&lt;0.0010.8670.400&lt;0.001&lt;0.001RetrievalMemmory 0.6920.8330.0360.0570.8830.9330.0260.028GenerativeAgent0.7420.3330.0286.0640.8830.2000.0306.019MemoryBank0.6920.4000.03315.7050.9000.3330.03212.827MemGPT0.7330.3671.042&lt;0.0010.8830.2000.921&lt;0.001SCMemory0.5420.2670.0360.0570.7830.3330.0250.028</p>
<p>Table 5 :
5
The results of memory mechanisms with different LLMs on our sub-dataset 1.The read time (RT) and write time (WT) are presented in seconds per operation.For the reflective memory, P-Accuracy means the accuracy under the participant scenario, and O-Accuracy refers to the accuracy under the observation scenario.
Factual-ParticipationFactual-ObservationReflective MemoryMethodAccuracyRTWTAccuracyRTWTP-AccuracyO-AccuracyQwen2.5-7B-InstructFullMemory0.6470.001 &lt;0.0010.786&lt;0.001 &lt;0.0010.7330.883RecentMemory0.6390.001 &lt;0.0010.800&lt;0.001 &lt;0.0010.7000.867RetrievalMemmory0.6920.041 0.0580.8830.0240.0260.6920.883GenerativeAgent0.4780.045 6.1160.7790.0316.2390.7420.883GPT-4o-miniFullMemory0.7360.001 &lt;0.0010.864&lt;0.001 &lt;0.0010.7830.883RecentMemory0.6970.001 &lt;0.0010.864&lt;0.001 &lt;0.0010.7580.900RetrievalMemmory0.6330.003 0.0310.8570.0230.0230.7670.900GenerativeAgent0.5920.107 0.9700.8460.0300.9980.7580.900Meta-Llama-3.1-8B-InstructFullMemory0.5190.001 &lt;0.0010.779&lt;0.001 &lt;0.0010.7080.817RecentMemory0.4610.001 &lt;0.0010.779&lt;0.001 &lt;0.0010.6830.850RetrievalMemmory0.5000.050 0.0620.7000.0440.0490.7330.833GenerativeAgent0.4300.036 6.5510.7250.065 12.3220.7250.850glm-4-9b-chatFullMemory0.4750.001 &lt;0.0010.775&lt;0.001 &lt;0.0010.6580.850RecentMemory0.5390.001 &lt;0.0010.746&lt;0.001 &lt;0.0010.7080.850RetrievalMemmory0.4830.032 0.0370.7390.0250.0250.7420.800GenerativeAgent0.4390.050 0.1650.7180.0300.1110.6750.900</p>
<p>Table 8 :
8
The detail statistics of our Participation dataset.RM indicates Reflective Memory.FM indicates Factual Memory.The types we have include ssh(sigle-hop), mh(multi-hop), comp(comparative), agg(aggregative), pp(post-processing), ku(knowledge-update), ssa(signlesession-assistant), msa(multi-session-assistant).
Data Type # Session # Question # TrajectoryRM-Pr3.0k3.0k3.0kRM-Em0.5k0.5k0.5kFM-sh8k8k1kFM-mh8k8k1kFM-comp8k4k1kFM-agg8k1k1kFM-ku8k8k1kFM-pp8k8k1kFM-ssa1.5k1.5k1.5kFM-msa1.5k0.5k0.5k</p>
<p>Table 9 :
9
The detail statistics of our Participation dataset.RM indicates Reflective Memory.FM indicates Factual Memory.The types we have include sh(sigle-hop), mh(multi-hop), comp(comparative), agg(aggregative), pp(post-processing), ku(knowledge-update).
Data Type # Session # Question # TrajectoryRM-Pr1.5k1.5k1.5kRM-Em0.5k0.5k0.5kFM-sh1.5k1.5k1.5kFM-mh1.5k1.5k1.5kFM-comp1.5k1.5k1.5kFM-agg1.5k1.5k1.5kFM-pp1.5k1.5k1.5kFM-ku1k1k1kB Detail Data StaticsIn Tab 8, we provide the detail statistics of Par-ticipation dataset. In Tab 9, we provide the detailstatistics of Observation dataset.C Data Creation PromptC.1 Profile PromptFlavour Reflective Memory Attribute Pleasechoose user's taste from [Tastes] according to thedishes he likes below. [Dishes]:{Dishes} [Tastes]:</p>
<p>Table 10 :
10
The results of different mechanisms on different types of our 10k-Reflective memory dataset.
Participation-Accuracy Observation-AccuracyMethodpreference emotion preference emotionFullMemory0.7330.5930.8830.630RecentMemory0.7000.4810.8670.556RetrievalMemmory0.6920.5560.8830.593GenerativeAgent0.7420.4120.8830.676MemoryBank0.6920.2960.9000.481MemGPT0.7330.4710.8830.556SCMemory0.5420.2940.7830.333</p>
<p>Table 11 :
11
The results of different mechanisms on different types of our 10k-Factual-Participation dataset.Including sh(sigle-hop), mh(multi-hop), comp(comparative), agg(aggregative), pp(post-processing), ku(knowledge-update), ssa(signle-session-assistant), msa(multi-session-assistant).
MethodParticipation-AccuracyshmhcompaggppkussamsaFullMemory0.8250.80.55 0.275 0.625 0.750.70.55RecentMemory0.850.75 0.425 0.450.65 0.725 0.717 0.5RetrievalMemmory 0.875 0.775 0.55 0.275 0.475 0.6750.40.3GenerativeAgent0.75 0.6750.30.35 0.525 0.525 0.267 0.55MemoryBank0.5750.70.250.25 0.475 0.55 0.417 0.4MemGPT0.625 0.625 0.275 0.225 0.45 0.625 0.367 0.45SCMemory0.575 0.475 0.05 0.275 0.525 0.475 0.217 0.1</p>
<p>Table 12 :
12
The results of different mechanisms on different types of our 10k-Factual-Observation memory dataset.Including sh(sigle-hop), mh(multi-hop), comp(comparative), agg(aggregative), pp(post-processing), ku(knowledgeupdate).
MethodObservation-Accuracyshmh compaggppkuFullMemory0.92 0.92 0.667 0.233 0.820.6RecentMemory0.92 0.92 0.667 0.367 0.820.65RetrievalMemmory 0.92 0.92 0.633 0.367 0.780.45GenerativeAgent0.88 0.940.70.30.820.4MemoryBank0.8 0.78 0.633 0.233 0.8000.6MemGPT0.94 0.92 0.667 0.233 0.82 0.600SCMemory0.46 0.68 0.133 0.133 0.780.65
 https://www.mindspore.cn
AcknowledgmentsThis work is supported in part by National Natural Science Foundation of China (No. 62422215 and No. 62472427), Major Innovation &amp; Planning Interdisciplinary Platform for the "Double-First Class" Initiative, Renmin University of China, Public Computing Cloud, Renmin University of China, fund for building world-class universities (disciplines) of Renmin University of China.This work is also sponsored by Huawei Innovation Research Programs.We gratefully acknowledge the support from Mindspore  , CANN(Compute Architecture for Neural Networks) and Ascend AI Processor used for this research.Types Descriptions Single-hopRely on one message to answer the question directly.Multi-hopRequire multiple messages to answer the question jointly.ComparativeCompare two entities on a shared attribute with multiple messages.AggregativeAggregate messages about more than two entities on a common attribute.Post-processingInvolve extra reasoning steps to answer with multiple messages.Knoewledge-updating The basis for answering questions will be updated over time with different messages.Single-session-assistant Rely on a single message from the assistant to directly answer the question.Multi-session-assistant Require Multiple messages from the assistant to collectively answer the question.TypesDescriptions Preference Rely on multiple messages to actively express the user's lower-level preferences.EmotionRely on multiple consecutive messages within a specific time to express the user's emotional state.A.2 FM-RM Directionary ExampleWhen creating the correspondence between factual memory attribute and reflective memory attribute, we simultaneously created a dictionary mapping the two.Below, we provide examples from each category of reflective memory.Movie."Action":["Star Wars (1977)","Godfather, The (1972)","Raiders of the Lost Ark (1981)","Titanic (1997)","Empire Strikes Back, The (1980)","Boot, Das (1981)","Godfather: Part II, The (1974)","African Queen, The (1951)","Princess Bride, The (1987)","Braveheart (1995)", "Glory (1989)", "Fugitive, The (1993)","Alien (1979)","Return of the Jedi (1983)","Terminator 2: Judgment Day (1991)", "Butch Cassidy and the Sundance Kid (1969)","Aliens (1986)","Magnificent Seven, The (1954)","Terminator, The (1984)","Apollo 13 (1995)","Indiana Jones and the Last Crusade (1989)","Die Hard (1988)","Hunt for Red October, The (1990)","Good, The Bad and The Ugly, The (1966)","Blues Brothers, The (1980)","Ben-Hur (1959)", "Cyrano de Bergerac (1990)", "Star Trek: The Wrath of Khan (1982)","In the Line of Fire (1993)", "Adventures of Robin Hood, The (1938)","Jaws (1975)","Face/Off (1997)","Men in Black (1997)","Diva (1981)","Jurassic Park (1993)","Rock, The (1996)","Full Metal Jacket (1987)", "Perfect World, A (1993)","Star Trek: First Contact (1996)","Speed (1994)","Air Force One (1997)", "Crying Game, The (1992)", "True Romance (1993)","Abyss, The (1989)","Clear and Present Danger (1994)","Heat (1995)","True Lies (1994)","Get Shorty (1995)","Last of the Mohicans, The (1992)","Supercop (1992)"] Food."Sweet": ["Candy", "Honey", "Fruit", "Maple Syrup Pancakes", "Baklava", "Chocolate Cake", "Custard", "Jelly", "Pecan Pie", "Apple Pie", "Brownies", "Banana Bread", "Donuts", "Rice Krispies"] Book."Health &amp; Fitness": ["What to Expect When You're Expecting (Revised Edition)", "Make the Connection: Ten Steps to a Better Body and a Better Life", "The South Beach Diet: The Delicious, Doctor-Designed, Foolproof Plan for Fast and Healthy Weight Loss", "Dr.Atkins' New Diet Revolution", "Dr.Atkins' New Diet Revolution", "Prescription for Nutritional Healing: A Practical A-Z Reference to Drug-Free Remedies Using Vitamins, Minerals, Herbs &amp; Food Supplements", "8 Weeks to Optimum Health", "Body for Life: 12 Weeks to Mental and Physical Strength", "Your Pregnancy: Week by Week (Your Pregnancy Series)", "Fat Land: How Americans Became the Fattest People in the World"]A.3 Question DescriptionIn Tab 6, we provide an explanation for each type of Factual Memory questions.In Tab 7, we provide an explanation for each type of Reflective Memory questions.A.4 Participation ExampleIn this section, we provide more detailed examples from the participation scenarios in our dataset.To make the presentation clearer, we have only listed the key evidence dialogue rounds necessary for answering the questions and omitted any unnecessary information.The Assistant:... User: My subordinate's email address is maya.carter@bostonlaw.gov.Assistant:... Question: What are the main interests and hobbies of the individual with the email address maya.carter@bostonlaw.gov?Answer: Gather historical items and appreciate their valueSingle session assistant user: I'm looking for a great movie to watch, aside from the ones I've mentioned earlier.assistant: I'm all about Return of the Jedi; it's such an iconic film with those thrilling space battles and unforgettable characters that make it a mustsee!user: I'm looking for a fantastic movie to watch, aside from the ones I've mentioned earlier.assistant: I recommend the Jurassic Park from 1993; it's such an incredible film with its groundbreaking special effects and thrilling adventure that really grabs my attention!Answer: 2 people Multi session assistant User: I'm looking for a great movie to watch, excluding the ones mentioned earlier.Assistant: I definitely think Alien (1979) is a must-see; it's an intense blend of science fiction and horror that really keeps you on the edge of your seat!User: I'm looking for a great movie to watch, aside from the ones I mentioned earlier.Assistant: "I'm all about The Fugitive from 1993; it's a thrilling ride that really keeps you on the edge of your seat!
Chenxin An, Shansan Gong, Ming Zhong, Mukai Li, Jun Zhang, arXiv:2307.11088Lingpeng Kong, and Xipeng Qiu. 2023. L-eval: Instituting standardized evaluation for long context language models. arXiv preprint</p>
<p>Longbench: A bilingual, multitask benchmark for long context understanding. Yushi Bai, Xin Lv, Jiajie Zhang, Hongchang Lyu, Jiankai Tang, Zhidian Huang, Zhengxiao Du, Xiao Liu, Aohan Zeng, Lei Hou, 10.34740/KAGGLE/DSV/4086173arXiv:2308.145082023arXiv preprintDataGuy and Gordon Amoako. 2022. twitter-news</p>
<p>Large language model agent in financial trading: A survey. Han Ding, Yinheng Li, Junhao Wang, Hang Chen, arXiv:2408.063612024arXiv preprint</p>
<p>Perltqa: A personal long-term memory dataset for memory classification, retrieval, and synthesis in question answering. Yiming Du, Hongru Wang, Zhengyi Zhao, Bin Liang, Baojun Wang, Wanjun Zhong, Zezhong Wang, Kam-Fai Wong, arXiv:2402.162882024arXiv preprint</p>
<p>Glm Team, Aohan Zeng, Bin Xu, Bowen Wang, Chenhui Zhang, Da Yin, Diego Rojas, Guanyu Feng, Hanlin Zhao, Hanyu Lai, Hao Yu, Hongning Wang, Jiadai Sun, Jiajie Zhang, Jiale Cheng, Jiayi Gui, Jie Tang, Jing Zhang, Juanzi Li, Lei Zhao, Lindong Wu, Lucen Zhong, Mingdao Liu, Minlie Huang, Peng Zhang, Qinkai Zheng, Rui Lu, Shuaiqi Duan, Shudan Zhang, Shulin Cao, Shuxun Yang, Weng Lam Tam, Wenyi Zhao, Xiao Liu, Xiao Xia, Xiaohan Zhang, Xiaotao Gu, Xin Lv, Xinghan Liu, Xinyi Liu, Xinyue Yang, Xixuan Song, Xunkai Zhang, Yifan An, Yifan Xu, Yilin Niu, Yuantao Yang, Yueyan Li, Yushi Bai, Yuxiao Dong, Zehan Qi, Zhaoyu Wang, Zhen Yang, Zhengxiao Du, Zhenyu Hou, Zihan Wang, arXiv:2406.12793Chatglm: A family of large language models from glm-130b to glm-4 all tools. 2024Preprint</p>
<p>Maxwell Harper, Joseph A Konstan, The movielens datasets: History and context. Acm transactions on interactive intelligent systems (tiis). 20155</p>
<p>Yuanchun Li, Hao Wen, Weijun Wang, Xiangyu Li, Yizhen Yuan, Guohong Liu, Jiacheng Liu, Wenxing Xu, Xiang Wang, Yi Sun, arXiv:2401.05459Personal llm agents: Insights and survey about the capability, efficiency and security. 2024arXiv preprint</p>
<p>Adyasha Maharana, Dong-Ho Lee, Sergey Tulyakov, Mohit Bansal, Francesco Barbieri, Yuwei Fang, arXiv:2402.17753Evaluating very long-term conversational memory of llm agents. 2024arXiv preprint</p>
<p>Prasad Bodhisattwa, Shuyang Majumder, Jianmo Li, Julian Ni, Mcauley, arXiv:1909.00105Generating personalized recipes from historical user preferences. 2019arXiv preprint</p>
<p>Charles Packer, Sarah Wooders, Kevin Lin, Vivian Fang, G Shishir, Ion Patil, Joseph E Stoica, Gonzalez, arXiv:2310.08560Memgpt: Towards llms as operating systems. 2023arXiv preprint</p>
<p>Generative agents: Interactive simulacra of human behavior. Sung Joon, Park, O' Joseph, Carrie Jun Brien, Meredith Ringel Cai, Percy Morris, Michael S Liang, Bernstein, Proceedings of the 36th annual acm symposium on user interface software and technology. the 36th annual acm symposium on user interface software and technology2023</p>
<p>Qwen Team. 2024. Qwen2.5: A party of foundation models. </p>
<p>Item recommendation on monotonic behavior chains. Mengting Wan, Julian J Mcauley, 10.1145/3240323.3240369Proceedings of the 12th ACM Conference on Recommender Systems. the 12th ACM Conference on Recommender SystemsVancouver, BC, CanadaACM2018. 2018. October 2-7, 2018</p>
<p>Fine-grained spoiler detection from large-scale review corpora. Mengting Wan, Rishabh Misra, Ndapa Nakashole, Julian J Mcauley, 10.18653/V1/P19-1248Proceedings of the 57th Conference of the Association for Computational Linguistics, ACL 2019. Long Papers. the 57th Conference of the Association for Computational Linguistics, ACL 2019Florence, Italy2019. July 28-August 2, 20191Association for Computational Linguistics</p>
<p>Enhancing large language model with self-controlled memory framework. Bing Wang, Xinnian Liang, Jian Yang, Hui Huang, Shuangzhi Wu, Peihao Wu, Lu Lu, Zejun Ma, Zhoujun Li, arXiv:2304.133432023arXiv preprint</p>
<p>A survey on large language model based autonomous agents. Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang, Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, Frontiers of Computer Science. 1861863452024a</p>
<p>Liang Wang, Nan Yang, Xiaolong Huang, Linjun Yang, Rangan Majumder, Furu Wei, arXiv:2402.05672Multilingual e5 text embeddings: A technical report. 2024barXiv preprint</p>
<p>Di Wu, Hongwei Wang, Wenhao Yu, Yuwei Zhang, Kai-Wei Chang, Dong Yu, arXiv:2410.10813Longmemeval: Benchmarking chat assistants on long-term interactive memory. 2024aarXiv preprint</p>
<p>A survey on large language models for recommendation. Likang Wu, Zhi Zheng, Zhaopeng Qiu, Hao Wang, Hongchao Gu, Tingjia Shen, Chuan Qin, Chen Zhu, Hengshu Zhu, Qi Liu, 2024b2760World Wide Web</p>
<p>The rise and potential of large language model based agents: A survey. Zhiheng Xi, Wenxiang Chen, Xin Guo, Wei He, Yiwen Ding, Boyang Hong, Ming Zhang, Junzhe Wang, Senjie Jin, Enyu Zhou, arXiv:2203.05797Long time no see! open-domain conversation with long-term persona memory. Zhibin Xu, Wenquan Gou, Zheng-Yu Wu, Hua Niu, Haifeng Wu, Shihang Wang, Wang, 2025. 202268arXiv preprint</p>
<p>. An Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Zhou, Chengpeng Li, Chengyuan Li, Dayiheng Liu, Fei Huang, Guanting Dong, Haoran Wei, Huan Lin, Jialong Tang, Jialin Wang, Jian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Ma, Jin Xu, Jingren Zhou, Jinze Bai, Jinzheng He, Junyang Lin, Kai Dang, Keming Lu, Keqin Chen, Kexin Yang, Mei Li, Mingfeng Xue, Na Ni, Pei Zhang, Peng Wang, Ru Peng, Rui Men, Ruize Gao, Runji Lin, Shijie Wang, Shuai Bai, Sinan Tan, Tianhang Zhu, Tianhao Li, Tianyu Liu, Wenbin Ge, Xiaodong Deng, Xiaohuan Zhou, Xingzhang Ren, Xinyu Zhang, Xipin Wei, arXiv:2407.10671Xuancheng Ren, Yang Fan, Yang Yao, Yichang Zhang, Yu Wan, Yunfei ChuarXiv preprintYuqiong Liu, Zeyu Cui, Zhenru Zhang, and Zhihao Fan. 2024. Qwen2 technical report</p>
<p>Neural personalized response generation as domain adaptation. Wei-Nan Zhang, Qingfu Zhu, Yifa Wang, Yanyan Zhao, Ting Liu, 201922World Wide Web</p>
<p>Zeyu Zhang, Xiaohe Bo, Chen Ma, Rui Li, Xu Chen, Quanyu Dai, Jieming Zhu, Zhenhua Dong, Ji-Rong Wen, arXiv:2404.13501A survey on the memory mechanism of large language model based agents. 2024aarXiv preprint</p>
<p>Zeyu Zhang, Quanyu Dai, Luyu Chen, Zeren Jiang, Rui Li, Jieming Zhu, Xu Chen, Yi Xie, Zhenhua Dong, Ji-Rong Wen, arXiv:2409.20163Memsim: A bayesian simulator for evaluating memory of llm-based personal assistants. 2024barXiv preprint</p>
<p>Memengine: A unified and modular library for developing advanced memory of llm-based agents. Zeyu Zhang, Quanyu Dai, Xu Chen, Rui Li, Zhongyang Li, Zhenhua Dong, Companion Proceedings of the ACM on Web Conference 2025. 2025</p>
<p>Kun Wayne Xin Zhao, Junyi Zhou, Tianyi Li, Xiaolei Tang, Yupeng Wang, Yingqian Hou, Beichen Min, Junjie Zhang, Zican Zhang, Dong, arXiv:2303.18223A survey of large language models. 2023arXiv preprint</p>
<p>Memorybank: Enhancing large language models with long-term memory. Wanjun Zhong, Lianghong Guo, Qiqi Gao, He Ye, Yanlin Wang, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202438</p>
<p>A Case Studies A.1 User Relation Graph Example In this section, we present examples of the components of our dataset, including the user graph and test cases. San Francisco, CAFor the user graph, we show profile examples of the user itself. related individuals, events, items, and places. UserProfile: "gender": "Male", "relationship": "self", "name": "James Smith", "age": "30 years old", "height": "164 cm", "birthday": "08.13", "hometown. work location": "Boston, MA", "education": "Associate Degree", "occupation": "Police Officer", "position": "Community Policing Officer", "company name": "Boston Law Enforcement Agency", "hobby": "Climbing", "character": "Friendly", "contact number": "4150430511", "email address": "james.smith@bostonlawenforcement.gov", "ssn": "914610199408130162", "passport number": "PUP4822676", "bank account": "6222022865544246", "driver license": "914EAPRDV5F", "highlevel preference": ["movie genre preference": ("Comedy", "Romance", "Action", "Drama", "Thriller"), "taste preference": "Umami and Sweet", "book preference": "Humor"</p>
<p>Relativeroleprofile, Community engagement workshop for team bonding. Company Team Building. location": "Los Angeles, CA", "time": "the week after next Sat 9:00 AM", "event name": "Team Connect", "scale": "one hundred people", "duration": "eight day</p>            </div>
        </div>

    </div>
</body>
</html>