<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2622 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2622</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2622</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-67.html">extraction-schema-67</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <p><strong>Paper ID:</strong> paper-c4b57fe0d8aa8fd976be9e3fb0d17a202c8a21aa</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/c4b57fe0d8aa8fd976be9e3fb0d17a202c8a21aa" target="_blank">Batch Bayesian Optimization via Local Penalization</a></p>
                <p><strong>Paper Venue:</strong> International Conference on Artificial Intelligence and Statistics</p>
                <p><strong>Paper TL;DR:</strong> A simple heuristic based on an estimate of the Lipschitz constant is investigated that captures the most important aspect of this interaction at negligible computational overhead and compares well, in running time, with much more elaborate alternatives.</p>
                <p><strong>Paper Abstract:</strong> The popularity of Bayesian optimization methods for efficient exploration of parameter spaces has lead to a series of papers applying Gaussian processes as surrogates in the optimization of functions. However, most proposed approaches only allow the exploration of the parameter space to occur sequentially. Often, it is desirable to simultaneously propose batches of parameter values to explore. This is particularly the case when large parallel processing facilities are available. These facilities could be computational or physical facets of the process being optimized. E.g. in biological experiments many experimental set ups allow several samples to be simultaneously processed. Batch methods, however, require modeling of the interaction between the evaluations in the batch, which can be expensive in complex scenarios. We investigate a simple heuristic based on an estimate of the Lipschitz constant that captures the most important aspect of this interaction (i.e. local repulsion) at negligible computational overhead. The resulting algorithm compares well, in running time, with much more elaborate alternatives. The approach assumes that the function of interest, $f$, is a Lipschitz continuous function. A wrap-loop around the acquisition function is used to collect batches of points of certain size minimizing the non-parallelizable computational effort. The speed-up of our method with respect to previous approaches is significant in a set of computationally expensive experiments.</p>
                <p><strong>Cost:</strong> 0.023</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2622.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2622.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BBO-LP</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Batch Bayesian Optimization via Local Penalization</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A heuristic batch Bayesian optimization algorithm that builds batches by iteratively maximizing an acquisition function and applying Lipschitz-based local penalizers (exclusion zones) around previously chosen batch points to mimic sequential behavior without repeated GP updates.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Batch Bayesian Optimization with Local Penalization (BBO-LP)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>BBO-LP constructs batches of evaluation points by (1) fitting a Gaussian process surrogate, (2) building a base acquisition function (e.g. EI or UCB), (3) transforming it to be positive if needed, and (4) selecting batch members by repeated maximization of the acquisition multiplied by local penalizer functions centered at the previously selected batch points. The local penalizers are probability-based exclusion functions derived from a Lipschitz bound on the objective (or an estimated Lipschitz constant) that smoothly reduce acquisition values in neighbourhoods where the global maximizer is unlikely to lie, thereby inducing repulsion between batch points. This avoids re-fitting the GP between batch picks, reducing non-parallelizable overhead.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>General black-box optimization and experimental design (examples in paper: algorithm configuration, wet-lab gene design, synthetic functions); applicable to automated experimental design and active learning scenarios where function evaluations can be parallelized.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Allocate evaluation budget in parallel batches by selecting points that maximize a penalized acquisition: x_k = argmax_x { g(alpha(x)) * prod_j phi(x; x_{t,j}) }, where phi are Lipschitz-based local penalizers centered at previously chosen batch points and g is a positive transformation of the acquisition. The strategy approximates the sequential optimal policy by creating exclusion zones around chosen points (so later points in the same batch explore different modes/regions) while avoiding the computational cost of sequential GP updates.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Wall-clock time and GP update complexity (GP refits scale as O(n^3)); the paper reports wall-clock seconds and number of iterations/batches completed within fixed time budgets and emphasizes 'information gained per second'.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Uses standard BO acquisition functions (Expected Improvement (EI) and Upper Confidence Bound (UCB)) as the surrogate for expected utility/information; also reports 'gained information per second' as an empirical efficiency metric.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Balances exploration and exploitation via the chosen acquisition function (EI trades off improvement vs uncertainty; UCB mixes mean and variance). The local penalizers reinforce exploration diversity in a batch by suppressing acquisition near already-selected batch points, simulating the reduction in acquisition that would occur after observing those points under a sequential policy.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Explicit local penalizers (phi) derived from Lipschitz bounds create probabilistic exclusion zones around selected points; these zones reduce acquisition in nearby regions and thus force later batch members to be spatially diverse. The method also suggests Latin-square style initial designs when no data exist.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Fixed number of evaluations per batch and overall iteration budget; also explicit wall-clock time budgets used in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Optimizes batch composition to minimize non-parallelizable computation (avoiding GP re-fitting between points) so that parallel evaluations use wall-clock time efficiently; uses fixed batch sizes and repeated penalized maximization until batch full, then parallel evaluation of the batch.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>No bespoke 'breakthrough' score; high-impact discoveries are measured by best objective value found (optimization progress) and information-per-second gains (efficiency); the algorithm aims to quickly find high-value optima.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Reported metrics include best objective value found (mean ± std) across replicates and 'gained information per second' empirically. Examples from experiments: on the gSobol benchmark (d=2, n_b=5) LP-EI achieved 0.35 ± 0.11 and LP-UCB 0.31 ± 0.06 (best among batch methods); LP-UCB was best in 5 of 9 gSobol cases. Empirical wall-clock comparisons show LP methods complete more effective iterations per time budget and higher information-per-second on Cosines, wet-lab (71-d) and SVR tuning experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared against sequential EI and UCB, random batch (Rand), exploratory batch designs (B, PE), predictive/fake-observation methods (Pred), simulating-and-matching (SM), and multi-point Expected Improvement (qEI).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>BBO-LP (LP-EI/LP-UCB) matched or outperformed other batch methods in convergence to the maximum while being more efficient in runtime. Specifics: LP-UCB produced best results in 5/9 gSobol settings; LP methods had smaller standard deviations and improved results as batch size increased; in costly-evaluation tasks (wet-lab, SVR) LP methods yielded superior wall-clock efficiency compared to sequential methods and competing batch algorithms.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Qualitative and empirical efficiency gains: higher 'information gained per second' vs alternatives; fewer non-parallelizable operations (no GP re-fit per batch element), leading to faster batch construction. The paper reports that LP methods are overall the most efficient in experiments; exact percent/time gains depend on task and are reported per-experiment (e.g. able to complete more effective iterations within fixed wall-clock budgets).</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>The paper analyzes the tradeoff between computational overhead (GP refitting cost ~O(n^3)) and information quality of batch selection: exact joint optimization (e.g. qEI) gives theoretically better batches but is computationally costly; BBO-LP approximates the sequential policy with Lipschitz-based exclusion to gain most of the practical benefit while dramatically reducing overhead. It also discusses the choice of Lipschitz constant L: smaller feasible L increases exclusion (more exploration) but must be valid; GP-LCA is proposed to estimate L. Parallelization is most beneficial when evaluation cost dominates design cost.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Key findings: (1) Approximating the sequential policy via local penalization yields high-quality batches with much lower computational cost than joint multi-point optimization; (2) estimating a small but valid Lipschitz constant helps produce larger exclusion zones and more efficient search; (3) when function evaluations are expensive and parallelizable, well-designed batches (LP) outperform sequential acquisition in wall-clock time; (4) avoid re-fitting the GP between batch members to reduce non-parallelizable overhead.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Batch Bayesian Optimization via Local Penalization', 'publication_date_yy_mm': '2015-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2622.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2622.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GP-LCA</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Gaussian Process Lipschitz Constant Approximation (GP-LCA)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A probabilistic method to approximate a valid Lipschitz constant for the unknown objective by taking the maximum norm of the GP posterior mean gradient over the domain: L_hat = max_x || mu_grad(x) ||.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Gaussian Process Lipschitz Constant Approximation (GP-LCA)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>GP-LCA computes an approximation to the objective's Lipschitz constant by using a fitted GP: the posterior mean of the gradient mu_grad(x) is computed analytically from kernel derivatives, and the estimated Lipschitz constant is taken as the maximum of the gradient norm over the domain. This estimate is plugged into the local penalizers to determine exclusion-zone radii used in batch construction.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Used within batch Bayesian optimization for experimental design and black-box optimization tasks in the paper (same domains as BBO-LP).</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>GP-LCA influences allocation indirectly by setting the size of exclusion zones: a smaller estimated L produces wider exclusion zones and therefore more spatial diversity in batch selections (favoring exploration); a larger L reduces penalization (favoring local exploitation).</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Cost arises from evaluating mu_grad(x) and maximizing its norm over the domain; reported as part of GP-based computations (gradient computations and domain maximization), typically negligible compared to expensive objective evaluations; overall GP update cost still dominated by O(n^3) when refits are performed.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>None intrinsic — GP-LCA is used to parameterize penalizers that act on acquisition functions (which represent expected improvement or UCB utility).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>By controlling exclusion zone size (via L), GP-LCA biases batch composition towards exploration (small L -> big exclusion -> explore) or exploitation (large L -> small exclusion -> focus locally).</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Indirect: L_hat sets radii r_j = (M - mu(x_j)) / L_hat used in probabilistic exclusion phi(x; x_j), thereby enforcing spatial diversity in batch points.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Same as BBO-LP: fixed batch sizes and iteration budgets; used to tune penalization under these constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>GP-LCA provides an automatic, data-driven method to choose L for local penalizers to improve batch efficiency under time/evaluation budgets by shaping how aggressively the algorithm spreads batch points.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>None specific; it is a parameter-estimation component intended to improve search efficiency (measured via downstream optimization performance and information-per-second).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Empirical validation: GP-LCA converged toward the true gradient-norm Lipschitz constant on the Cosines function as sample size increased (plot shown); experiments using GP-LCA within BBO-LP produced the LP methods' reported performance (see BBO-LP entry).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared implicitly to heuristic or hand-tuned L choices (e.g., L = max_x ||mu_grad(x)|| was suggested; alternative local L_j = ||mu_grad(x_j)|| also discussed).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Paper reports that GP-LCA yields good practical L estimates (converging in experiments) and enables effective penalization for batch design, contributing to the BBO-LP performance advantages. No explicit percentage gains reported solely for GP-LCA.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Enables larger, valid exclusion zones without manual tuning, which contributes to faster exploration and improved batch efficiency in BBO-LP.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Paper notes tradeoff in L choice: smaller feasible L increases exploration but must remain valid; GP-LCA ignores posterior gradient variance (uses mean only), which can be extended to actively refine L estimates if desired.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Recommendation: use GP-LCA (maximizing posterior mean gradient norm) as a practical and effective estimate of the Lipschitz constant to parameterize batch penalizers; consider local L_j for heteroscedastic cases.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Batch Bayesian Optimization via Local Penalization', 'publication_date_yy_mm': '2015-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2622.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2622.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>qEI</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Multi-point Expected Improvement (q-EI)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An acquisition criterion that generalizes Expected Improvement to propose a batch of points by optimizing the joint expected improvement over multiple locations simultaneously.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Fast computation of the multi-points expected improvement with applications in batch selection.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Multi-point Expected Improvement (qEI)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>qEI defines the expected improvement of the best outcome obtained from a batch of proposed points and selects batches by maximizing this joint expected utility. This requires evaluating integrals over the multivariate GP predictive distribution and typically joint optimization in the high-dimensional batch-input space.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Batch Bayesian optimization for expensive black-box functions; experimental design and active learning when batch proposals are required.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Allocates resources by directly maximizing joint expected improvement across a candidate batch, implicitly trading off exploration and exploitation within the batch via the EI utility aggregated over joint outcomes.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>High computational cost due to joint GP predictive computations and optimization in batch-dimensional space; often scales poorly with input dimension and batch size; practical implementations may time out for large d or large batches (paper reports qEI failing to complete within time budget in some experiments).</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Expected Improvement aggregated over the joint predictive distribution (i.e., expected utility of the batch).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Intrinsic to EI: quantifies potential improvement vs uncertainty for the batch; joint optimization tends to pick a diverse set if that maximizes joint improvement, but computational constraints may limit applicability.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Implicit via joint optimization of the batch's expected improvement (points that collectively maximize improvement will often be diverse), but no explicit penalizer for diversity beyond the joint EI formulation.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Computational (time) and batch size limits; often constrained by time budgets for joint optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Exact joint qEI optimization can be computationally expensive; implementations may approximate or fail to complete under strict time budgets; paper includes qEI in comparisons but notes its computational burden.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Maximization of EI (improvement over current best) — high-impact discoveries measured as large improvements in objective.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Included in benchmark tables when runnable; in some higher-dimensional / large-batch cases qEI could not complete within the time budget, denoted '-' in tables.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared against BBO-LP, predictive methods, simulating-and-matching, random batches, sequential EI/UCB.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>qEI is theoretically well-founded and can produce high-quality batches but tends to be computationally prohibitive in higher dimensions and large batch sizes; in this paper LP methods often matched or outperformed alternatives in wall-clock-limited experiments because qEI could not complete.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Noted to be poor in many practical settings due to computational overhead; no consistent efficiency gain reported relative to BBO-LP in wall-clock constrained experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>qEI exemplifies the tradeoff: joint-optimization yields potentially higher-quality batches (better information per batch) but incurs computational cost that can negate net gains under wall-clock/time budgets.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>When computational cost is negligible, joint qEI is theoretically attractive; in realistic wall-clock constrained settings, cheaper heuristics like local penalization can produce better end-to-end efficiency.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Batch Bayesian Optimization via Local Penalization', 'publication_date_yy_mm': '2015-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2622.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2622.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Predictive (fake obs.)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Predictive (fake-observation) Batch BO (Azimi et al. style)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A set of batch BO strategies that sequentially simulate the outcomes at selected batch points (using predictive GP draws or means) to 'hallucinate' observations, allowing selection of the next batch elements without marginalizing over actual unknown outcomes.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Hybrid batch Bayesian optimization</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Predictive/fake-observation Batch Bayesian Optimization</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>These methods select batch elements by generating synthetic ('fake') observations from the GP predictive distribution at previously chosen batch points (e.g., sampling or setting to predictive mean), updating the surrogate with those faked observations, and selecting the next point conditioned on them. This avoids full marginalization over future outcomes but still uses the predictive GP to model interaction between batch members.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Batch black-box optimization and experimental design where parallel evaluations are desired and simulating outcomes can speed batch construction.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Allocates resources by simulating likely outcomes at batch points (using the GP predictive distributions) and greedily maximizing the acquisition function conditioned on these simulated outcomes, effectively approximating the sequential policy.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Requires GP updates (with simulated data) for each simulated choice in the batch; cost measured in GP refit computations and wall-clock time; these methods reduce marginalization complexity but still incur significant computational workload compared to purely heuristic approaches.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Driven by the underlying acquisition (EI, UCB) computed on GPs augmented with simulated observations — uses expected improvement or UCB computed after hallucinated data.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Exploration-exploitation is governed by the base acquisition function; the fake-observation updates attempt to emulate the sequential reduction in acquisition around sampled points, encouraging diversity/exploration as a byproduct of simulated posterior changes.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Diversity arises indirectly from simulated updates that reduce acquisition near simulated locations; no explicit Lipschitz-based penalizer unless combined with other heuristics.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Computational/time budgets (recomputing GP per simulated point) and batch size constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Reduces exact marginalization by simulating outcomes but still requires multiple GP updates; tradeoff between fidelity of simulation and computational cost.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Same as the acquisition used (e.g., improvement over best observed).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Included in experiments as 'Pred-EI' and 'Pred-UCB'; numerical performance varies by task and dimension. Predictive methods were competitive in some low-dimensional settings but often outperformed by LP methods in wall-clock-limited experiments due to higher computation per batch.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared against LP, SM, qEI, random batches, sequential EI/UCB.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Predictive approaches can approximate sequential batching better than naive heuristics but are computationally costlier; in many experiments BBO-LP delivered equal or better optimization per unit time.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Reduces marginalization complexity relative to full joint marginalization but at higher cost than BBO-LP; net efficiency depends on problem dimensionality and evaluation cost.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Paper highlights the computational tradeoff: modeling batch interactions via predictive updates captures dependencies more accurately but increases non-parallelizable computation, which can negate benefits under wall-clock constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Use predictive (fake) observations to model batch interactions when computational budget allows; for heavy time constraints or large problems, cheaper heuristics like local penalization may be preferable.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Batch Bayesian Optimization via Local Penalization', 'publication_date_yy_mm': '2015-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2622.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2622.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Simulating-and-Matching Batch BO (Azimi et al. 2010)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A method that simulates sequential policy behavior to produce batches by matching the distribution of points chosen by a sequential policy, effectively approximating multi-step selection without full marginalization.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Batch Bayesian optimization via simulation matching</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Simulating-and-Matching (SM) Batch Bayesian Optimization</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>SM simulates the sequential acquisition process (either by sampling or matching) to generate candidate batch points whose distribution matches that of the sequential policy. It attempts to mimic the decisions of a sequential policy when many evaluations can be performed in parallel.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Batch Bayesian optimization; used in hyperparameter tuning and other black-box optimization tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Allocates batch points by simulation of sequential selection paths and selecting a set of points that match the simulated distribution, approximating the marginalization over unknown outcomes.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Simulation cost plus GP updates; computational cost can be significant especially for larger problems; in the paper SM is implemented with UCB only and included in runtime comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Implicit via the underlying acquisition used to simulate sequential decisions (e.g., UCB).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Uses the acquisition policy being simulated (e.g., UCB) to produce diverse batch members reflecting the sequential explore/exploit tradeoff.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Diversity can result from the simulated sequential policy distribution; not via explicit Lipschitz penalizers.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Computational/time budgets and batch size limits.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Simulation-based approximation to avoid explicit marginalization, but still incurs non-trivial computational cost.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Objective improvement as per acquisition criterion (e.g., best value found).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Included in experimental comparisons (SM-UCB); showed mixed results—SM can be competitive in some settings but may be outperformed by LP methods in wall-clock-limited tests.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared to LP, predictive methods, qEI, random batches, sequential methods.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>SM sometimes performed well but in many experiments LP methods provided superior wall-clock efficiency.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Simulation avoids full marginalization but at computational expense; overall efficiency depends on problem size.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>SM embodies the tradeoff between a more faithful approximation to the sequential policy and the extra computation required to simulate many possible sequential paths.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Use SM when a closer approximation to a sequential policy is worth the computational overhead; otherwise lightweight heuristics (LP) can be preferable.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Batch Bayesian Optimization via Local Penalization', 'publication_date_yy_mm': '2015-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2622.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e2622.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Entropy search / PES</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Entropy Search and Predictive Entropy Search</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Information-theoretic BO methods that choose evaluation points to maximally reduce uncertainty about the location of the global optimizer (entropy reduction or mutual information).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Entropy search for information-efficient global optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Entropy Search (Hennig & Schuler) and Predictive Entropy Search (Hernández-Lobato et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Entropy Search (ES) and Predictive Entropy Search (PES) select queries to maximize expected reduction in entropy over the location of the optimizer, directly optimizing an information-gain objective (mutual information between query outcomes and optimizer location). These are non-local and often computationally expensive acquisition rules that prioritize the most informative experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Information-efficient global optimization; experimental design where learning about global optimizer location is primary.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Allocates experiments by maximizing expected information gain (entropy reduction) about the global optimum, potentially sacrificing immediate improvement for long-term information.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>High computational cost due to need to approximate entropies and integrate over GP posterior; often more expensive than EI/UCB-based methods.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Expected entropy reduction / mutual information about the optimizer location.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Pure information-driven: exploration is driven by expected information gain; exploitation occurs only insofar as it reduces uncertainty about the optimizer.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Implicit: information-driven queries tend to be diverse because they target regions that most reduce global uncertainty.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Computational/time budget; these methods are often unsuitable for large-scale/high-dimension due to computational cost.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Approximation techniques exist but computational burden remains high; paper mentions these as non-local entropy-based alternatives.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Reduction in uncertainty about optimizer location; improvement in best-found objective can be a secondary metric.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Mentioned as related work; not empirically compared in this paper's experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared conceptually to EI/UCB and the proposed heuristic as more principled but often more costly.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Not evaluated in this paper; generally known to be information-efficient but computationally intensive.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Potentially high information efficiency per evaluation but large computational overhead can reduce wall-clock efficiency in practice.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Represents the tradeoff of maximizing information gain at the expense of high computational cost; motivates simpler heuristics like BBO-LP when wall-clock efficiency is critical.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>If computational cost is tolerable and information about the optimizer is the primary objective, entropy-based acquisition is appropriate; otherwise approximate, cheaper heuristics may outperform in wall-clock-limited settings.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Batch Bayesian Optimization via Local Penalization', 'publication_date_yy_mm': '2015-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2622.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e2622.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Parallel GP-UCB (Desautels)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Parallelizing exploration-exploitation tradeoffs with Gaussian process bandit optimization</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A framework for parallelizing GP bandit algorithms (UCB style) that analyzes exploration-exploitation tradeoffs and provides algorithms and bounds for batch selection.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Parallelizing exploration-exploitation tradeoffs with Gaussian process bandit optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Parallel GP-UCB / Batch GP-UCB</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Approaches that extend GP-UCB style bandit algorithms to batch settings, providing theory and practical batch selection rules (often via heuristics) to preserve exploration-exploitation guarantees while allowing parallel evaluations.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Bandit-style black-box optimization where multiple queries can be issued in parallel.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Batch selection rules that aim to preserve UCB-style optimism while allocating multiple queries; sometimes use pure-exploration subroutines or penalization to spread queries.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Wall-clock time and number of parallel workers; complexity per selection depends on GP computations.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>UCB surrogate (mean + kappa * std) rather than direct information-theoretic measures; theoretical regret bounds used for analysis.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>UCB's optimism parameter (kappa) controls exploration vs exploitation; parallel extensions aim to pick diverse points that maintain regret guarantees.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Batch algorithms often include diversity-inducing rules (e.g., penalization or exploration subroutines) to avoid redundant queries in a batch.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Fixed number of parallel workers / batch size and time budgets.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Designs batch selection to respect parallel worker limits while trying to maintain theoretical performance guarantees (regret bounds).</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Regret reduction; optimization progress measured via cumulative or simple regret.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Discussed in related work; referenced as theoretical and algorithmic precedent for batch BO approaches.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Sequential GP-UCB and other batch heuristics (e.g., LP, Pred, SM).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Paper is cited as related theoretical work; not directly benchmarked in experiments here.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Enables parallelism with bounds on regret; practical efficiency depends on implementation and problem specifics.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Analyzes tradeoffs in batched GP-UCB between parallelism and regret; motivates heuristics that approximate sequential decisions while enabling parallel evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Batch UCB-style methods can preserve exploration-exploitation performance while enabling parallelism, but efficient practical implementations require approximations to reduce computational cost.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Batch Bayesian Optimization via Local Penalization', 'publication_date_yy_mm': '2015-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2622.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e2622.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Lipschitz BO (Jalali)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>A Lipschitz exploration-exploitation scheme for Bayesian optimization</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A batch BO approach that leverages Lipschitz continuity assumptions to guide exploration-exploitation tradeoffs, using Lipschitz bounds to construct exclusion zones or selection rules.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>A lipschitz exploration-exploitation scheme for Bayesian optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Lipschitz-based Exploration-Exploitation BO</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Methods that explicitly exploit Lipschitz continuity of the objective to bound possible function values away from evaluated points, thereby guiding where to explore (regions not excluded by Lipschitz bounds) and where to exploit.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Global optimization and experimental design where Lipschitz continuity is a reasonable prior.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Use Lipschitz-derived exclusion regions (or scoring) to allocate queries away from regions that cannot contain a better optimum given current observations, effectively prioritizing resource allocation to plausible improvement regions.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Depends on the method; typically lower than full joint marginalization since Lipschitz bounds can be evaluated cheaply; wall-clock time used in comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Indirect: selection guided by bounding potential improvement rather than explicit mutual information.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Tight Lipschitz bounds reduce search space (favor exploitation near promising points) but also create exclusion zones to force exploration elsewhere; parameter L choice controls this balance.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Exclusion zones encourage spatial diversity in selected points.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Fixed evaluation budgets and computational limitations.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Leveraging Lipschitz bounds to cheaply discard regions reduces wasted evaluations and computational effort.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Bounds-based potential improvement; practical metric is best objective found.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Cited as related theoretical work; not directly benchmarked in this paper beyond conceptual connection.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Linked conceptually and compared to the paper's GP-LCA/Lipschitz penalization approach.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Paper positions Lipschitz schemes as conceptually similar; BBO-LP differentiates by estimating L from GP and using probabilistic penalizers.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Lipschitz schemes can dramatically prune search space where assumptions hold, improving allocation efficiency.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Choice of L is critical: too small invalidates bounds; too large reduces exclusion and search efficiency. Paper argues GP-based estimation of L is practical.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Use Lipschitz information to shape exploration/exclusion; practical implementation benefits from data-driven L estimates (as in GP-LCA).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Batch Bayesian Optimization via Local Penalization', 'publication_date_yy_mm': '2015-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Batch Bayesian optimization via simulation matching <em>(Rating: 2)</em></li>
                <li>Hybrid batch Bayesian optimization <em>(Rating: 2)</em></li>
                <li>Parallelizing exploration-exploitation tradeoffs with Gaussian process bandit optimization <em>(Rating: 2)</em></li>
                <li>Entropy search for information-efficient global optimization <em>(Rating: 2)</em></li>
                <li>Predictive entropy search for efficient global optimization of black-box functions <em>(Rating: 2)</em></li>
                <li>Fast computation of the multi-points expected improvement with applications in batch selection. <em>(Rating: 2)</em></li>
                <li>A lipschitz exploration-exploitation scheme for Bayesian optimization <em>(Rating: 2)</em></li>
                <li>Dynamic batch Bayesian optimization <em>(Rating: 1)</em></li>
                <li>Parallel Gaussian process optimization with upper confidence bound and pure exploration <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2622",
    "paper_id": "paper-c4b57fe0d8aa8fd976be9e3fb0d17a202c8a21aa",
    "extraction_schema_id": "extraction-schema-67",
    "extracted_data": [
        {
            "name_short": "BBO-LP",
            "name_full": "Batch Bayesian Optimization via Local Penalization",
            "brief_description": "A heuristic batch Bayesian optimization algorithm that builds batches by iteratively maximizing an acquisition function and applying Lipschitz-based local penalizers (exclusion zones) around previously chosen batch points to mimic sequential behavior without repeated GP updates.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Batch Bayesian Optimization with Local Penalization (BBO-LP)",
            "system_description": "BBO-LP constructs batches of evaluation points by (1) fitting a Gaussian process surrogate, (2) building a base acquisition function (e.g. EI or UCB), (3) transforming it to be positive if needed, and (4) selecting batch members by repeated maximization of the acquisition multiplied by local penalizer functions centered at the previously selected batch points. The local penalizers are probability-based exclusion functions derived from a Lipschitz bound on the objective (or an estimated Lipschitz constant) that smoothly reduce acquisition values in neighbourhoods where the global maximizer is unlikely to lie, thereby inducing repulsion between batch points. This avoids re-fitting the GP between batch picks, reducing non-parallelizable overhead.",
            "application_domain": "General black-box optimization and experimental design (examples in paper: algorithm configuration, wet-lab gene design, synthetic functions); applicable to automated experimental design and active learning scenarios where function evaluations can be parallelized.",
            "resource_allocation_strategy": "Allocate evaluation budget in parallel batches by selecting points that maximize a penalized acquisition: x_k = argmax_x { g(alpha(x)) * prod_j phi(x; x_{t,j}) }, where phi are Lipschitz-based local penalizers centered at previously chosen batch points and g is a positive transformation of the acquisition. The strategy approximates the sequential optimal policy by creating exclusion zones around chosen points (so later points in the same batch explore different modes/regions) while avoiding the computational cost of sequential GP updates.",
            "computational_cost_metric": "Wall-clock time and GP update complexity (GP refits scale as O(n^3)); the paper reports wall-clock seconds and number of iterations/batches completed within fixed time budgets and emphasizes 'information gained per second'.",
            "information_gain_metric": "Uses standard BO acquisition functions (Expected Improvement (EI) and Upper Confidence Bound (UCB)) as the surrogate for expected utility/information; also reports 'gained information per second' as an empirical efficiency metric.",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "Balances exploration and exploitation via the chosen acquisition function (EI trades off improvement vs uncertainty; UCB mixes mean and variance). The local penalizers reinforce exploration diversity in a batch by suppressing acquisition near already-selected batch points, simulating the reduction in acquisition that would occur after observing those points under a sequential policy.",
            "diversity_mechanism": "Explicit local penalizers (phi) derived from Lipschitz bounds create probabilistic exclusion zones around selected points; these zones reduce acquisition in nearby regions and thus force later batch members to be spatially diverse. The method also suggests Latin-square style initial designs when no data exist.",
            "uses_diversity_promotion": true,
            "budget_constraint_type": "Fixed number of evaluations per batch and overall iteration budget; also explicit wall-clock time budgets used in experiments.",
            "budget_constraint_handling": "Optimizes batch composition to minimize non-parallelizable computation (avoiding GP re-fitting between points) so that parallel evaluations use wall-clock time efficiently; uses fixed batch sizes and repeated penalized maximization until batch full, then parallel evaluation of the batch.",
            "breakthrough_discovery_metric": "No bespoke 'breakthrough' score; high-impact discoveries are measured by best objective value found (optimization progress) and information-per-second gains (efficiency); the algorithm aims to quickly find high-value optima.",
            "performance_metrics": "Reported metrics include best objective value found (mean ± std) across replicates and 'gained information per second' empirically. Examples from experiments: on the gSobol benchmark (d=2, n_b=5) LP-EI achieved 0.35 ± 0.11 and LP-UCB 0.31 ± 0.06 (best among batch methods); LP-UCB was best in 5 of 9 gSobol cases. Empirical wall-clock comparisons show LP methods complete more effective iterations per time budget and higher information-per-second on Cosines, wet-lab (71-d) and SVR tuning experiments.",
            "comparison_baseline": "Compared against sequential EI and UCB, random batch (Rand), exploratory batch designs (B, PE), predictive/fake-observation methods (Pred), simulating-and-matching (SM), and multi-point Expected Improvement (qEI).",
            "performance_vs_baseline": "BBO-LP (LP-EI/LP-UCB) matched or outperformed other batch methods in convergence to the maximum while being more efficient in runtime. Specifics: LP-UCB produced best results in 5/9 gSobol settings; LP methods had smaller standard deviations and improved results as batch size increased; in costly-evaluation tasks (wet-lab, SVR) LP methods yielded superior wall-clock efficiency compared to sequential methods and competing batch algorithms.",
            "efficiency_gain": "Qualitative and empirical efficiency gains: higher 'information gained per second' vs alternatives; fewer non-parallelizable operations (no GP re-fit per batch element), leading to faster batch construction. The paper reports that LP methods are overall the most efficient in experiments; exact percent/time gains depend on task and are reported per-experiment (e.g. able to complete more effective iterations within fixed wall-clock budgets).",
            "tradeoff_analysis": "The paper analyzes the tradeoff between computational overhead (GP refitting cost ~O(n^3)) and information quality of batch selection: exact joint optimization (e.g. qEI) gives theoretically better batches but is computationally costly; BBO-LP approximates the sequential policy with Lipschitz-based exclusion to gain most of the practical benefit while dramatically reducing overhead. It also discusses the choice of Lipschitz constant L: smaller feasible L increases exclusion (more exploration) but must be valid; GP-LCA is proposed to estimate L. Parallelization is most beneficial when evaluation cost dominates design cost.",
            "optimal_allocation_findings": "Key findings: (1) Approximating the sequential policy via local penalization yields high-quality batches with much lower computational cost than joint multi-point optimization; (2) estimating a small but valid Lipschitz constant helps produce larger exclusion zones and more efficient search; (3) when function evaluations are expensive and parallelizable, well-designed batches (LP) outperform sequential acquisition in wall-clock time; (4) avoid re-fitting the GP between batch members to reduce non-parallelizable overhead.",
            "uuid": "e2622.0",
            "source_info": {
                "paper_title": "Batch Bayesian Optimization via Local Penalization",
                "publication_date_yy_mm": "2015-05"
            }
        },
        {
            "name_short": "GP-LCA",
            "name_full": "Gaussian Process Lipschitz Constant Approximation (GP-LCA)",
            "brief_description": "A probabilistic method to approximate a valid Lipschitz constant for the unknown objective by taking the maximum norm of the GP posterior mean gradient over the domain: L_hat = max_x || mu_grad(x) ||.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Gaussian Process Lipschitz Constant Approximation (GP-LCA)",
            "system_description": "GP-LCA computes an approximation to the objective's Lipschitz constant by using a fitted GP: the posterior mean of the gradient mu_grad(x) is computed analytically from kernel derivatives, and the estimated Lipschitz constant is taken as the maximum of the gradient norm over the domain. This estimate is plugged into the local penalizers to determine exclusion-zone radii used in batch construction.",
            "application_domain": "Used within batch Bayesian optimization for experimental design and black-box optimization tasks in the paper (same domains as BBO-LP).",
            "resource_allocation_strategy": "GP-LCA influences allocation indirectly by setting the size of exclusion zones: a smaller estimated L produces wider exclusion zones and therefore more spatial diversity in batch selections (favoring exploration); a larger L reduces penalization (favoring local exploitation).",
            "computational_cost_metric": "Cost arises from evaluating mu_grad(x) and maximizing its norm over the domain; reported as part of GP-based computations (gradient computations and domain maximization), typically negligible compared to expensive objective evaluations; overall GP update cost still dominated by O(n^3) when refits are performed.",
            "information_gain_metric": "None intrinsic — GP-LCA is used to parameterize penalizers that act on acquisition functions (which represent expected improvement or UCB utility).",
            "uses_information_gain": false,
            "exploration_exploitation_mechanism": "By controlling exclusion zone size (via L), GP-LCA biases batch composition towards exploration (small L -&gt; big exclusion -&gt; explore) or exploitation (large L -&gt; small exclusion -&gt; focus locally).",
            "diversity_mechanism": "Indirect: L_hat sets radii r_j = (M - mu(x_j)) / L_hat used in probabilistic exclusion phi(x; x_j), thereby enforcing spatial diversity in batch points.",
            "uses_diversity_promotion": true,
            "budget_constraint_type": "Same as BBO-LP: fixed batch sizes and iteration budgets; used to tune penalization under these constraints.",
            "budget_constraint_handling": "GP-LCA provides an automatic, data-driven method to choose L for local penalizers to improve batch efficiency under time/evaluation budgets by shaping how aggressively the algorithm spreads batch points.",
            "breakthrough_discovery_metric": "None specific; it is a parameter-estimation component intended to improve search efficiency (measured via downstream optimization performance and information-per-second).",
            "performance_metrics": "Empirical validation: GP-LCA converged toward the true gradient-norm Lipschitz constant on the Cosines function as sample size increased (plot shown); experiments using GP-LCA within BBO-LP produced the LP methods' reported performance (see BBO-LP entry).",
            "comparison_baseline": "Compared implicitly to heuristic or hand-tuned L choices (e.g., L = max_x ||mu_grad(x)|| was suggested; alternative local L_j = ||mu_grad(x_j)|| also discussed).",
            "performance_vs_baseline": "Paper reports that GP-LCA yields good practical L estimates (converging in experiments) and enables effective penalization for batch design, contributing to the BBO-LP performance advantages. No explicit percentage gains reported solely for GP-LCA.",
            "efficiency_gain": "Enables larger, valid exclusion zones without manual tuning, which contributes to faster exploration and improved batch efficiency in BBO-LP.",
            "tradeoff_analysis": "Paper notes tradeoff in L choice: smaller feasible L increases exploration but must remain valid; GP-LCA ignores posterior gradient variance (uses mean only), which can be extended to actively refine L estimates if desired.",
            "optimal_allocation_findings": "Recommendation: use GP-LCA (maximizing posterior mean gradient norm) as a practical and effective estimate of the Lipschitz constant to parameterize batch penalizers; consider local L_j for heteroscedastic cases.",
            "uuid": "e2622.1",
            "source_info": {
                "paper_title": "Batch Bayesian Optimization via Local Penalization",
                "publication_date_yy_mm": "2015-05"
            }
        },
        {
            "name_short": "qEI",
            "name_full": "Multi-point Expected Improvement (q-EI)",
            "brief_description": "An acquisition criterion that generalizes Expected Improvement to propose a batch of points by optimizing the joint expected improvement over multiple locations simultaneously.",
            "citation_title": "Fast computation of the multi-points expected improvement with applications in batch selection.",
            "mention_or_use": "use",
            "system_name": "Multi-point Expected Improvement (qEI)",
            "system_description": "qEI defines the expected improvement of the best outcome obtained from a batch of proposed points and selects batches by maximizing this joint expected utility. This requires evaluating integrals over the multivariate GP predictive distribution and typically joint optimization in the high-dimensional batch-input space.",
            "application_domain": "Batch Bayesian optimization for expensive black-box functions; experimental design and active learning when batch proposals are required.",
            "resource_allocation_strategy": "Allocates resources by directly maximizing joint expected improvement across a candidate batch, implicitly trading off exploration and exploitation within the batch via the EI utility aggregated over joint outcomes.",
            "computational_cost_metric": "High computational cost due to joint GP predictive computations and optimization in batch-dimensional space; often scales poorly with input dimension and batch size; practical implementations may time out for large d or large batches (paper reports qEI failing to complete within time budget in some experiments).",
            "information_gain_metric": "Expected Improvement aggregated over the joint predictive distribution (i.e., expected utility of the batch).",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "Intrinsic to EI: quantifies potential improvement vs uncertainty for the batch; joint optimization tends to pick a diverse set if that maximizes joint improvement, but computational constraints may limit applicability.",
            "diversity_mechanism": "Implicit via joint optimization of the batch's expected improvement (points that collectively maximize improvement will often be diverse), but no explicit penalizer for diversity beyond the joint EI formulation.",
            "uses_diversity_promotion": true,
            "budget_constraint_type": "Computational (time) and batch size limits; often constrained by time budgets for joint optimization.",
            "budget_constraint_handling": "Exact joint qEI optimization can be computationally expensive; implementations may approximate or fail to complete under strict time budgets; paper includes qEI in comparisons but notes its computational burden.",
            "breakthrough_discovery_metric": "Maximization of EI (improvement over current best) — high-impact discoveries measured as large improvements in objective.",
            "performance_metrics": "Included in benchmark tables when runnable; in some higher-dimensional / large-batch cases qEI could not complete within the time budget, denoted '-' in tables.",
            "comparison_baseline": "Compared against BBO-LP, predictive methods, simulating-and-matching, random batches, sequential EI/UCB.",
            "performance_vs_baseline": "qEI is theoretically well-founded and can produce high-quality batches but tends to be computationally prohibitive in higher dimensions and large batch sizes; in this paper LP methods often matched or outperformed alternatives in wall-clock-limited experiments because qEI could not complete.",
            "efficiency_gain": "Noted to be poor in many practical settings due to computational overhead; no consistent efficiency gain reported relative to BBO-LP in wall-clock constrained experiments.",
            "tradeoff_analysis": "qEI exemplifies the tradeoff: joint-optimization yields potentially higher-quality batches (better information per batch) but incurs computational cost that can negate net gains under wall-clock/time budgets.",
            "optimal_allocation_findings": "When computational cost is negligible, joint qEI is theoretically attractive; in realistic wall-clock constrained settings, cheaper heuristics like local penalization can produce better end-to-end efficiency.",
            "uuid": "e2622.2",
            "source_info": {
                "paper_title": "Batch Bayesian Optimization via Local Penalization",
                "publication_date_yy_mm": "2015-05"
            }
        },
        {
            "name_short": "Predictive (fake obs.)",
            "name_full": "Predictive (fake-observation) Batch BO (Azimi et al. style)",
            "brief_description": "A set of batch BO strategies that sequentially simulate the outcomes at selected batch points (using predictive GP draws or means) to 'hallucinate' observations, allowing selection of the next batch elements without marginalizing over actual unknown outcomes.",
            "citation_title": "Hybrid batch Bayesian optimization",
            "mention_or_use": "use",
            "system_name": "Predictive/fake-observation Batch Bayesian Optimization",
            "system_description": "These methods select batch elements by generating synthetic ('fake') observations from the GP predictive distribution at previously chosen batch points (e.g., sampling or setting to predictive mean), updating the surrogate with those faked observations, and selecting the next point conditioned on them. This avoids full marginalization over future outcomes but still uses the predictive GP to model interaction between batch members.",
            "application_domain": "Batch black-box optimization and experimental design where parallel evaluations are desired and simulating outcomes can speed batch construction.",
            "resource_allocation_strategy": "Allocates resources by simulating likely outcomes at batch points (using the GP predictive distributions) and greedily maximizing the acquisition function conditioned on these simulated outcomes, effectively approximating the sequential policy.",
            "computational_cost_metric": "Requires GP updates (with simulated data) for each simulated choice in the batch; cost measured in GP refit computations and wall-clock time; these methods reduce marginalization complexity but still incur significant computational workload compared to purely heuristic approaches.",
            "information_gain_metric": "Driven by the underlying acquisition (EI, UCB) computed on GPs augmented with simulated observations — uses expected improvement or UCB computed after hallucinated data.",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "Exploration-exploitation is governed by the base acquisition function; the fake-observation updates attempt to emulate the sequential reduction in acquisition around sampled points, encouraging diversity/exploration as a byproduct of simulated posterior changes.",
            "diversity_mechanism": "Diversity arises indirectly from simulated updates that reduce acquisition near simulated locations; no explicit Lipschitz-based penalizer unless combined with other heuristics.",
            "uses_diversity_promotion": true,
            "budget_constraint_type": "Computational/time budgets (recomputing GP per simulated point) and batch size constraints.",
            "budget_constraint_handling": "Reduces exact marginalization by simulating outcomes but still requires multiple GP updates; tradeoff between fidelity of simulation and computational cost.",
            "breakthrough_discovery_metric": "Same as the acquisition used (e.g., improvement over best observed).",
            "performance_metrics": "Included in experiments as 'Pred-EI' and 'Pred-UCB'; numerical performance varies by task and dimension. Predictive methods were competitive in some low-dimensional settings but often outperformed by LP methods in wall-clock-limited experiments due to higher computation per batch.",
            "comparison_baseline": "Compared against LP, SM, qEI, random batches, sequential EI/UCB.",
            "performance_vs_baseline": "Predictive approaches can approximate sequential batching better than naive heuristics but are computationally costlier; in many experiments BBO-LP delivered equal or better optimization per unit time.",
            "efficiency_gain": "Reduces marginalization complexity relative to full joint marginalization but at higher cost than BBO-LP; net efficiency depends on problem dimensionality and evaluation cost.",
            "tradeoff_analysis": "Paper highlights the computational tradeoff: modeling batch interactions via predictive updates captures dependencies more accurately but increases non-parallelizable computation, which can negate benefits under wall-clock constraints.",
            "optimal_allocation_findings": "Use predictive (fake) observations to model batch interactions when computational budget allows; for heavy time constraints or large problems, cheaper heuristics like local penalization may be preferable.",
            "uuid": "e2622.3",
            "source_info": {
                "paper_title": "Batch Bayesian Optimization via Local Penalization",
                "publication_date_yy_mm": "2015-05"
            }
        },
        {
            "name_short": "SM",
            "name_full": "Simulating-and-Matching Batch BO (Azimi et al. 2010)",
            "brief_description": "A method that simulates sequential policy behavior to produce batches by matching the distribution of points chosen by a sequential policy, effectively approximating multi-step selection without full marginalization.",
            "citation_title": "Batch Bayesian optimization via simulation matching",
            "mention_or_use": "use",
            "system_name": "Simulating-and-Matching (SM) Batch Bayesian Optimization",
            "system_description": "SM simulates the sequential acquisition process (either by sampling or matching) to generate candidate batch points whose distribution matches that of the sequential policy. It attempts to mimic the decisions of a sequential policy when many evaluations can be performed in parallel.",
            "application_domain": "Batch Bayesian optimization; used in hyperparameter tuning and other black-box optimization tasks.",
            "resource_allocation_strategy": "Allocates batch points by simulation of sequential selection paths and selecting a set of points that match the simulated distribution, approximating the marginalization over unknown outcomes.",
            "computational_cost_metric": "Simulation cost plus GP updates; computational cost can be significant especially for larger problems; in the paper SM is implemented with UCB only and included in runtime comparisons.",
            "information_gain_metric": "Implicit via the underlying acquisition used to simulate sequential decisions (e.g., UCB).",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "Uses the acquisition policy being simulated (e.g., UCB) to produce diverse batch members reflecting the sequential explore/exploit tradeoff.",
            "diversity_mechanism": "Diversity can result from the simulated sequential policy distribution; not via explicit Lipschitz penalizers.",
            "uses_diversity_promotion": true,
            "budget_constraint_type": "Computational/time budgets and batch size limits.",
            "budget_constraint_handling": "Simulation-based approximation to avoid explicit marginalization, but still incurs non-trivial computational cost.",
            "breakthrough_discovery_metric": "Objective improvement as per acquisition criterion (e.g., best value found).",
            "performance_metrics": "Included in experimental comparisons (SM-UCB); showed mixed results—SM can be competitive in some settings but may be outperformed by LP methods in wall-clock-limited tests.",
            "comparison_baseline": "Compared to LP, predictive methods, qEI, random batches, sequential methods.",
            "performance_vs_baseline": "SM sometimes performed well but in many experiments LP methods provided superior wall-clock efficiency.",
            "efficiency_gain": "Simulation avoids full marginalization but at computational expense; overall efficiency depends on problem size.",
            "tradeoff_analysis": "SM embodies the tradeoff between a more faithful approximation to the sequential policy and the extra computation required to simulate many possible sequential paths.",
            "optimal_allocation_findings": "Use SM when a closer approximation to a sequential policy is worth the computational overhead; otherwise lightweight heuristics (LP) can be preferable.",
            "uuid": "e2622.4",
            "source_info": {
                "paper_title": "Batch Bayesian Optimization via Local Penalization",
                "publication_date_yy_mm": "2015-05"
            }
        },
        {
            "name_short": "Entropy search / PES",
            "name_full": "Entropy Search and Predictive Entropy Search",
            "brief_description": "Information-theoretic BO methods that choose evaluation points to maximally reduce uncertainty about the location of the global optimizer (entropy reduction or mutual information).",
            "citation_title": "Entropy search for information-efficient global optimization.",
            "mention_or_use": "mention",
            "system_name": "Entropy Search (Hennig & Schuler) and Predictive Entropy Search (Hernández-Lobato et al.)",
            "system_description": "Entropy Search (ES) and Predictive Entropy Search (PES) select queries to maximize expected reduction in entropy over the location of the optimizer, directly optimizing an information-gain objective (mutual information between query outcomes and optimizer location). These are non-local and often computationally expensive acquisition rules that prioritize the most informative experiments.",
            "application_domain": "Information-efficient global optimization; experimental design where learning about global optimizer location is primary.",
            "resource_allocation_strategy": "Allocates experiments by maximizing expected information gain (entropy reduction) about the global optimum, potentially sacrificing immediate improvement for long-term information.",
            "computational_cost_metric": "High computational cost due to need to approximate entropies and integrate over GP posterior; often more expensive than EI/UCB-based methods.",
            "information_gain_metric": "Expected entropy reduction / mutual information about the optimizer location.",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "Pure information-driven: exploration is driven by expected information gain; exploitation occurs only insofar as it reduces uncertainty about the optimizer.",
            "diversity_mechanism": "Implicit: information-driven queries tend to be diverse because they target regions that most reduce global uncertainty.",
            "uses_diversity_promotion": true,
            "budget_constraint_type": "Computational/time budget; these methods are often unsuitable for large-scale/high-dimension due to computational cost.",
            "budget_constraint_handling": "Approximation techniques exist but computational burden remains high; paper mentions these as non-local entropy-based alternatives.",
            "breakthrough_discovery_metric": "Reduction in uncertainty about optimizer location; improvement in best-found objective can be a secondary metric.",
            "performance_metrics": "Mentioned as related work; not empirically compared in this paper's experiments.",
            "comparison_baseline": "Compared conceptually to EI/UCB and the proposed heuristic as more principled but often more costly.",
            "performance_vs_baseline": "Not evaluated in this paper; generally known to be information-efficient but computationally intensive.",
            "efficiency_gain": "Potentially high information efficiency per evaluation but large computational overhead can reduce wall-clock efficiency in practice.",
            "tradeoff_analysis": "Represents the tradeoff of maximizing information gain at the expense of high computational cost; motivates simpler heuristics like BBO-LP when wall-clock efficiency is critical.",
            "optimal_allocation_findings": "If computational cost is tolerable and information about the optimizer is the primary objective, entropy-based acquisition is appropriate; otherwise approximate, cheaper heuristics may outperform in wall-clock-limited settings.",
            "uuid": "e2622.5",
            "source_info": {
                "paper_title": "Batch Bayesian Optimization via Local Penalization",
                "publication_date_yy_mm": "2015-05"
            }
        },
        {
            "name_short": "Parallel GP-UCB (Desautels)",
            "name_full": "Parallelizing exploration-exploitation tradeoffs with Gaussian process bandit optimization",
            "brief_description": "A framework for parallelizing GP bandit algorithms (UCB style) that analyzes exploration-exploitation tradeoffs and provides algorithms and bounds for batch selection.",
            "citation_title": "Parallelizing exploration-exploitation tradeoffs with Gaussian process bandit optimization.",
            "mention_or_use": "mention",
            "system_name": "Parallel GP-UCB / Batch GP-UCB",
            "system_description": "Approaches that extend GP-UCB style bandit algorithms to batch settings, providing theory and practical batch selection rules (often via heuristics) to preserve exploration-exploitation guarantees while allowing parallel evaluations.",
            "application_domain": "Bandit-style black-box optimization where multiple queries can be issued in parallel.",
            "resource_allocation_strategy": "Batch selection rules that aim to preserve UCB-style optimism while allocating multiple queries; sometimes use pure-exploration subroutines or penalization to spread queries.",
            "computational_cost_metric": "Wall-clock time and number of parallel workers; complexity per selection depends on GP computations.",
            "information_gain_metric": "UCB surrogate (mean + kappa * std) rather than direct information-theoretic measures; theoretical regret bounds used for analysis.",
            "uses_information_gain": false,
            "exploration_exploitation_mechanism": "UCB's optimism parameter (kappa) controls exploration vs exploitation; parallel extensions aim to pick diverse points that maintain regret guarantees.",
            "diversity_mechanism": "Batch algorithms often include diversity-inducing rules (e.g., penalization or exploration subroutines) to avoid redundant queries in a batch.",
            "uses_diversity_promotion": true,
            "budget_constraint_type": "Fixed number of parallel workers / batch size and time budgets.",
            "budget_constraint_handling": "Designs batch selection to respect parallel worker limits while trying to maintain theoretical performance guarantees (regret bounds).",
            "breakthrough_discovery_metric": "Regret reduction; optimization progress measured via cumulative or simple regret.",
            "performance_metrics": "Discussed in related work; referenced as theoretical and algorithmic precedent for batch BO approaches.",
            "comparison_baseline": "Sequential GP-UCB and other batch heuristics (e.g., LP, Pred, SM).",
            "performance_vs_baseline": "Paper is cited as related theoretical work; not directly benchmarked in experiments here.",
            "efficiency_gain": "Enables parallelism with bounds on regret; practical efficiency depends on implementation and problem specifics.",
            "tradeoff_analysis": "Analyzes tradeoffs in batched GP-UCB between parallelism and regret; motivates heuristics that approximate sequential decisions while enabling parallel evaluation.",
            "optimal_allocation_findings": "Batch UCB-style methods can preserve exploration-exploitation performance while enabling parallelism, but efficient practical implementations require approximations to reduce computational cost.",
            "uuid": "e2622.6",
            "source_info": {
                "paper_title": "Batch Bayesian Optimization via Local Penalization",
                "publication_date_yy_mm": "2015-05"
            }
        },
        {
            "name_short": "Lipschitz BO (Jalali)",
            "name_full": "A Lipschitz exploration-exploitation scheme for Bayesian optimization",
            "brief_description": "A batch BO approach that leverages Lipschitz continuity assumptions to guide exploration-exploitation tradeoffs, using Lipschitz bounds to construct exclusion zones or selection rules.",
            "citation_title": "A lipschitz exploration-exploitation scheme for Bayesian optimization.",
            "mention_or_use": "mention",
            "system_name": "Lipschitz-based Exploration-Exploitation BO",
            "system_description": "Methods that explicitly exploit Lipschitz continuity of the objective to bound possible function values away from evaluated points, thereby guiding where to explore (regions not excluded by Lipschitz bounds) and where to exploit.",
            "application_domain": "Global optimization and experimental design where Lipschitz continuity is a reasonable prior.",
            "resource_allocation_strategy": "Use Lipschitz-derived exclusion regions (or scoring) to allocate queries away from regions that cannot contain a better optimum given current observations, effectively prioritizing resource allocation to plausible improvement regions.",
            "computational_cost_metric": "Depends on the method; typically lower than full joint marginalization since Lipschitz bounds can be evaluated cheaply; wall-clock time used in comparisons.",
            "information_gain_metric": "Indirect: selection guided by bounding potential improvement rather than explicit mutual information.",
            "uses_information_gain": false,
            "exploration_exploitation_mechanism": "Tight Lipschitz bounds reduce search space (favor exploitation near promising points) but also create exclusion zones to force exploration elsewhere; parameter L choice controls this balance.",
            "diversity_mechanism": "Exclusion zones encourage spatial diversity in selected points.",
            "uses_diversity_promotion": true,
            "budget_constraint_type": "Fixed evaluation budgets and computational limitations.",
            "budget_constraint_handling": "Leveraging Lipschitz bounds to cheaply discard regions reduces wasted evaluations and computational effort.",
            "breakthrough_discovery_metric": "Bounds-based potential improvement; practical metric is best objective found.",
            "performance_metrics": "Cited as related theoretical work; not directly benchmarked in this paper beyond conceptual connection.",
            "comparison_baseline": "Linked conceptually and compared to the paper's GP-LCA/Lipschitz penalization approach.",
            "performance_vs_baseline": "Paper positions Lipschitz schemes as conceptually similar; BBO-LP differentiates by estimating L from GP and using probabilistic penalizers.",
            "efficiency_gain": "Lipschitz schemes can dramatically prune search space where assumptions hold, improving allocation efficiency.",
            "tradeoff_analysis": "Choice of L is critical: too small invalidates bounds; too large reduces exclusion and search efficiency. Paper argues GP-based estimation of L is practical.",
            "optimal_allocation_findings": "Use Lipschitz information to shape exploration/exclusion; practical implementation benefits from data-driven L estimates (as in GP-LCA).",
            "uuid": "e2622.7",
            "source_info": {
                "paper_title": "Batch Bayesian Optimization via Local Penalization",
                "publication_date_yy_mm": "2015-05"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Batch Bayesian optimization via simulation matching",
            "rating": 2
        },
        {
            "paper_title": "Hybrid batch Bayesian optimization",
            "rating": 2
        },
        {
            "paper_title": "Parallelizing exploration-exploitation tradeoffs with Gaussian process bandit optimization",
            "rating": 2
        },
        {
            "paper_title": "Entropy search for information-efficient global optimization",
            "rating": 2
        },
        {
            "paper_title": "Predictive entropy search for efficient global optimization of black-box functions",
            "rating": 2
        },
        {
            "paper_title": "Fast computation of the multi-points expected improvement with applications in batch selection.",
            "rating": 2
        },
        {
            "paper_title": "A lipschitz exploration-exploitation scheme for Bayesian optimization",
            "rating": 2
        },
        {
            "paper_title": "Dynamic batch Bayesian optimization",
            "rating": 1
        },
        {
            "paper_title": "Parallel Gaussian process optimization with upper confidence bound and pure exploration",
            "rating": 1
        }
    ],
    "cost": 0.0234985,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Batch Bayesian Optimization via Local Penalization</h1>
<p>Javier González<br>University of Sheffield</p>
<p>Zhenwen Dai<br>University of Sheffield</p>
<p>Philipp Hennig<br>Max Planck Institute for Intelligent Systems</p>
<p>Neil Lawrence<br>University of Sheffield</p>
<h2>Abstract</h2>
<p>The popularity of Bayesian optimization methods for efficient exploration of parameter spaces has lead to a series of papers applying Gaussian processes as surrogates in the optimization of functions. However, most proposed approaches only allow the exploration of the parameter space to occur sequentially. Often, it is desirable to simultaneously propose batches of parameter values to explore. This is particularly the case when large parallel processing facilities are available. These could either be computational or physical facets of the process being optimized. Batch methods, however, require the modeling of the interaction between the different evaluations in the batch, which can be expensive in complex scenarios. We investigate this issue and propose a highly effective heuristic based on an estimate of the function's Lipschitz constant that captures the most important aspect of this interactionlocal repulsion-at negligible computational overhead. A penalized acquisition function is used to collect batches of points minimizing the non-parallelizable computational effort. The resulting algorithm compares very well, in run-time, with much more elaborate alternatives.</p>
<h2>1 Introduction</h2>
<p>Many problems, such as the configuration of machine learning algorithms [Snoek et al., 2012] or the experimental design of biological experiments [González et al., 2014] require the optimization of an unknown,</p>
<h2>1 Introduction</h2>
<p>Many problems, such as the configuration of machine learning algorithms [Snoek et al., 2012] or the experimental design of biological experiments [González et al., 2014] require the optimization of an unknown,</p>
<h2>2. A. Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear</h2>
<p>now available, ranging from fast heuristics [Osborne, 2010, Jones et al., 1998] to non-local entropy-based approaches [Hennig and Schuler, 2012, HernándezLobato et al., 2014].</p>
<p>While the goal of Bayesian optimization is to keep the number of evaluations of $f$ as low as possible, in highdimensional and or otherwise complex problems, the number of required evaluations can still be considerable. Parallel approaches arise as the natural solution to circumvent the computational bottleneck around these evaluations of $f$. We focus on cases in which the cost of evaluating $f$ in a batch of points of size $n_{b}$ is the same as evaluating $f$ in a single point. Such scenarios appear, for instance, in the optimization of computer models where several cores are available to run in parallel, or in wet-lab experiments when the cost of testing one experimental design is the same as testing a batch of them. In these settings, the set of available pairs $\left{\left(\mathbf{x}<em i="i">{i}, y</em>\right)\right}<em t="t">{i=1}^{n}$ can be augmented with the evaluations of $f$ on batches of data points $\mathcal{B}</em>}^{n_{b}}=\left{\mathbf{x<em b="b" n="n" t_="t,">{t, 1}, \ldots, \mathbf{x}</em>}\right}$, for $t=1, \ldots, m$, rather than on single observations. Our goal here is to define a design rule for such batches $\mathcal{B<em b="b">{1}^{n</em>}}, \ldots, \mathcal{B<em b="b">{m}^{n</em>$. The batch selection problem can be generalized further, e.g. by adapting the batch size [Azimi et al., 2012] or by collecting batches asynchronously [Ginsbourger et al., 2011, Janusevskis et al., 2012, Snoek et al., 2012]. For simplicity of exposition these ideas will not feature further here.}</p>
<h3>1.1 Optimal batch design and previous work</h3>
<p>The goal of any batch criterion is to mimic the decisions that would be made under the equivalent (optimal) sequential policy: Consider the choice of selecting $\mathbf{x}<em k="k" t_="t,">{t, k}$, the $k$-th element of the $t$-th batch. Under a sequential policy, in which the evaluations of $f$ at all locations prior to $\mathbf{x}</em>}$ are available, the decision is to take $\mathbf{x<em k-1="k-1" t_="t,">{t, k}$ as the maximizer of $\alpha\left(\mathbf{x} ; \mathcal{I}</em>}\right)$. In the batch case, the decision about where to collect $\mathbf{x<em 1="1" t_="t,">{t, k}$ has to incorporate the uncertainty about the locations $\mathbf{x}</em>$, and the outcomes of the evaluation of $f$ there. Iteratively marginalizing these sources of uncertainty gives}, \ldots, \mathbf{x}_{t, k-1</p>
<p>$$
\begin{aligned}
\mathbf{x}<em _mathbf_x="\mathbf{x">{t, k}= &amp; \arg \max </em>} \in \mathcal{X}} \int \alpha\left(\mathbf{x} ; \mathcal{I<em j="1">{t, k-1}\right) \
&amp; \prod</em>}^{k-1} p\left(y_{t, j} \mid \mathbf{x<em j-1="j-1" t_="t,">{t, j}, \mathcal{I}</em>}\right) p\left(\mathbf{x<em j-1="j-1" t_="t,">{t, j} \mid \mathcal{I}</em>}\right) \mathrm{d} \mathbf{x<em j="j" t_="t,">{t, j} \mathrm{~d} y</em>
\end{aligned}
$$</p>
<p>where</p>
<p>$$
p\left(y_{t, j} \mid \mathbf{x}<em j-1="j-1" t_="t,">{t, j}, \mathcal{I}</em>}\right)=\mathcal{N}\left(y_{t, j} ; \mu_{n}\left(\mathbf{x<em n="n">{t, j}\right), \sigma</em>\right)\right)
$$}^{2}\left(\mathbf{x}_{t, j</p>
<p>is the predictive distribution of the GP at $\mathbf{x}_{t, j}$ when a total of $n$ points are available and</p>
<p>$$
p\left(\mathbf{x}<em j-1="j-1" t_="t,">{t, j} \mid \mathcal{I}</em>}\right)=\delta\left(\mathbf{x<em _mathbf_x="\mathbf{x">{t, j}-\arg \max </em>\right)\right)
$$} \in \mathcal{X}} \alpha\left(\mathbf{x} ; \mathcal{I}_{t, j-1</p>
<p>reflects the optimization step required to obtain $\mathbf{x}_{t, j}$ after the evaluations of $f$ at previous batch-elements have been marginalized.</p>
<p>The optimization in Eq. (2) is intractable even for small batch-sizes, due to the optimizationmarginalization loop required to obtain $\mathbf{x}<em j="j" t_="t,">{t, k}$. The literature in batch BO has tried to avoid this computational burden by means of different strategies, most of which involve the explicit use of the predictive distributions $p\left(y</em>} \mid \mathbf{x<em j-1="j-1" t_="t,">{t, j}, \mathcal{I}</em>}\right)$, for $j=1, \ldots, n_{b}$. Exploratory approaches [Schonlau et al., 1998, Contal et al., 2013] search for a reduction in system uncertainty. This is using the property that the variance of $p\left(y_{t, j} \mid \mathbf{x<em j-1="j-1" t_="t,">{t, j}, \mathcal{I}</em>}\right)$ does not depend on the value of the objective there. Other methods use $p\left(y_{t, j} \mid \mathbf{x<em j-1="j-1" t_="t,">{t, j}, \mathcal{I}</em>$ to simultaneously optimize elements on the batch [Azimi et al., 2010]. These nongreedy strategies are very well founded from a theoretical perspective in practice but tend to scale poorly with the dimension of the problem and the sizes of the batches. Other theoretical properties of batch BO have been studied in the context of Bayesian networks [Oenek and Schwarz, 2000], multi-armed bandits [Desautels et al., 2012], and the optimal balance between exploration and exploitation in batch designs [Jalali et al., 2013].}\right)$ to generate 'fake' observations of the model [Azimi et al., 2012, 2011, Bergstra et al., 2011] and avoid the marginalization step. In statistics, the suitability of the expected improvement utility has been studied for the design of batches [Chevalier and Ginsbourger, 2013, Frazier, 2012]. In contrast to the previous mentioned works, these methods use the joint distribution of $y_{t_{1}}, \ldots y_{t, n b</p>
<h3>1.2 Goal and Contributions of this work</h3>
<p>Using $p\left(y_{t, j} \mid \mathbf{x}<em j-1="j-1" t_="t,">{t, j}, \mathcal{I}</em>\right)$, since the GP needs to be updated after each batch location is selected to jointly optimize all the elements in the batch. The motivation of this work is to develop a heuristic approximation of Eq. (2) at lower computational cost, while incorporating information about global properties of $f$ from the GP model into the batch design.}\right)$ to model the interaction between batch elements has a computational overhead of $\mathcal{O}\left(n^{3</p>
<p>Our approach rests on the hypothesis that $f$ is a Lipschitz continuous function, which is a common assumption in global optimization [Floudas and Pardalos, 2009]. For easy reference: a real-valued function $f: \mathcal{X} \rightarrow \mathbb{R}$ on a compact subset $\mathcal{X} \subseteq \mathbb{R}^{d}$ of the $d$ dimensional real vector space is said to be $L$-Lipschitz if it satisfies</p>
<p>$$
\left|f\left(\mathbf{x}<em 2="2">{1}\right)-f\left(\mathbf{x}</em>}\right)\right| \leq L\left|\mathbf{x<em 2="2">{1}-\mathbf{x}</em>}\right|, \quad \forall \mathbf{x<em 2="2">{1}, \mathbf{x}</em>
$$} \in \mathcal{X</p>
<p>where $L$ is a global positive constant, and $|\cdot|$ is the</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: Forrester function $f(x)=(6 x-2)^{2} \sin (12 x-$ 4) in the interval $[0.3,01,4]$. We take 6 evaluations $\mathbf{x}<em 6="6">{1}, \ldots, \mathbf{x}</em>$ of the function, $M=\max <em i="i">{i} f\left(\mathbf{x}</em>\right)$ are shown.
$\ell^{2}$-norm on $\mathbb{R}^{d}$, a property that has been previously exploited in global optimization [Horst and Pardalos, 1995, Strongin and Sergeyev, 2000].}\right)$ and $L=$ 400. The exclusion zones for the maximum of $f$ determined by the balls $B_{r}\left(\mathbf{x}_{i</p>
<p>In the context of parallelizing Bayesian optimization, a beneficial aspect of the Lipschitzian assumption is that it naturally allows us to place bounds on how far the optimum of $f$ is from a certain location. See Figure 1 for details. As explained below, this information can be used to define policies to collect a batch of points multiple steps ahead without evaluating $f$, by mimicking the hypothesized behavior of a sequential policy. The main challenge is that, in practice, the constant $L$ is unknown. In the literature, this problem has been addressed from different angles [Floudas and Pardalos, 2009]. We explore a new alternative: inferring the Lipschitz constant directly from the Gaussian process model for $f$.</p>
<p>Our contributions are: (i) A new batch BO heuristic, BBO-LP, that selects batches of points by an iterative maximization-penalization loop around the the acquisition function. This leads to efficient parallelization of BO and can be used with any acquisition function. (ii) A probabilistic framework to approximately infer the Lipschitz constant of $f$, termed GP-LCA, that uses the properties of the gradients of the GP. The inferred value of $L$ is used to improve batch selection. (iii) A python implementation of several batch BO methods is published in conjunction with this work. ${ }^{1}$ (iv) Confirmation of the effectiveness of the approach is demonstrated through several simulated experiments, an algorithm configuration problem, and a real wet-lab experimental design. In particular, the local penalization approach performs equal or better than current</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup>batch BO methods in terms of the convergence to the maximum, but shows better performance in terms of gained information per second.</p>
<h2>2 Maximization-Penalization Strategy for Batch Design</h2>
<p>The intuition behind our approach is that for most GP priors in practical use for BO, the dominant effect of a function evaluation on the acquisition function is a local exclusion around the new evaluation. This shape of the acquisition function will be modeled through the Lipschitz properties of $f$, to distribute the elements in each batch. This should be understood as a heuristic to the shape of $\alpha\left(\mathbf{x} ; \mathcal{I}_{t, k-1}\right)$ if all previous observations were available, mimicking the effect a sequential policy. This is especially useful in cases in which the acquisition function shows multi-modal shape, a common situation in the first iterations of BO algorithms. The following definition is helpful for the formalization of the algorithm:</p>
<p>Definition 1 A function $\varphi\left(\mathbf{x} ; \mathbf{x}<em j="j">{j}\right), \mathbf{x} \in \mathcal{X}$, is a local penalizer of a generic acquisition function $\alpha(\mathbf{x})$ at $\mathbf{x}</em>}$ if $\varphi\left(\mathbf{x} ; \mathbf{x<em j="j">{j}\right)$ is differentiable, $0 \leq \varphi\left(\mathbf{x} ; \mathbf{x}</em>}\right) \leq 1$ and $\varphi\left(\mathbf{x} ; \mathbf{x<em j="j">{j}\right)$ is an non-decreasing function in $\left|\mathbf{x}-\mathbf{x}</em>\right|$.</p>
<p>We propose to replace the maximizationmarginalization loop in Eq. 2 by a maximizationpenalization strategy: while the optimization is carried out in a similar fashion, the marginalization step is replaced by the direct penalization of $\alpha\left(\mathbf{x} ; \mathcal{I}<em k="k" t_="t,">{t, k-1}\right)$ around its most recent maximum, i.e, the previous batch element. Figure 2 gives a graphical illustration. The maximization-penalization strategy selects $\mathbf{x}</em>$ as</p>
<p>$$
\mathbf{x}<em _in="\in" _mathcal_X="\mathcal{X" x="x">{t, k}=\arg \max </em>}}\left{g\left(\alpha\left(\mathbf{x} ; \mathcal{I<em j="1">{t, 0}\right)\right) \prod</em>\right)\right}
$$}^{k-1} \varphi\left(\mathbf{x} ; \mathbf{x}_{t, j</p>
<p>where $\varphi\left(\mathbf{x} ; \mathbf{x}<em j="j" t_="t,">{t, j}\right)$ are local local penalizers centered at $\mathbf{x}</em>\right)$ elsewhere. This does not require re-estimation of the GP model after each location is selected, just a new optimization of the penalized utility.}$ and $g: \mathbb{R} \rightarrow \mathbb{R}^{+}$is a differentiable transformation of $\alpha(\mathbf{x})$ that keeps it strictly positive without changing the location of its extrema. We will use $g(z)=z$ if $\alpha(\mathbf{x})$ is already positive and the soft-plus transformation $g(z)=\ln \left(1+e^{z</p>
<p>The effect of a local penalizer is to smoothly reduce the value of the acquisition function in a neighborhood of $\mathbf{x}<em j="j">{j}$. A 'good' local penalizer centered at $\mathbf{x}</em>}$ should reflect the belief about the distance from $\mathbf{x<em M="M">{j}$ to $\mathbf{x}</em>}$ : If we suspect that $\mathbf{x<em j="j">{M}$ is far from $\mathbf{x}</em>$ in which we don't}$, a broad $\varphi\left(\mathbf{x} ; \mathbf{x}_{j}\right)$ will discard a large portion of $\mathcal{X</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: Illustration of three iterations of the maximization-penalization loop. The main task of good batch design is to explore the modes of the acquisition function, achieved by iterative maximization (black stars) and penalization (using $\varphi_{1}(\mathbf{x}), \varphi_{2}(\mathbf{x})$ ) of the acquisition function $\alpha(\mathbf{x})$.
need to collect any sample. On the other hand, if we believe that $\mathbf{x}<em j="j">{M}$ and $\mathbf{x}</em>\right)$ are surrogates for this neighborhood.}$ are close, ideally we want to minimize the penalization of $\alpha(\mathbf{x})$ and keep collecting samples is a close neighborhood. This local penalization mimics the acquisition function's dynamics under a sequential policy in the following sense: the modes of the acquisition functions correspond to regions in which either $\mu_{n}(\mathbf{x})$ or $\sigma_{n}^{2}(\mathbf{x})$ (or both) are large. Evaluating, for instance, where $\sigma_{n}(\mathbf{x})$ is large will reduce uncertainty in that region, decreasing $\alpha(\mathbf{x})$ in a neighborhood. The functions $\varphi\left(\mathbf{x} ; \mathbf{x}_{j</p>
<h3>2.1 Choosing Local Penalizers $\varphi\left(\mathbf{x} ; \mathbf{x}_{j}\right)$</h3>
<p>We now construct penalizing functions $\varphi\left(\mathbf{x} ; \mathbf{x}<em M="M">{j}\right)$ that incorporate into $\alpha(\mathbf{x})$ the current belief about the distance from the batch locations to $\mathbf{x}</em>)$, and a valid Lipschitz constant $L$. Consider the ball}$. Take $M=$ $\max _{\mathbf{x} \in \mathcal{X}} f(\mathbf{x</p>
<p>$$
B_{r_{j}}\left(\mathbf{x}<em j="j">{j}\right)=\left{\mathbf{x} \in \mathcal{X}:\left|\mathbf{x}</em>\right}
$$}-\mathbf{x}\right| \leq r_{j</p>
<p>where</p>
<p>$$
r_{j}=\frac{M-f\left(\mathbf{x}_{j}\right)}{L}
$$</p>
<p>To simplify the notation we write $r_{j}=r\left(\mathbf{x}<em j="j">{j}\right)$ for the radius of the ball around $\mathbf{x}</em>}$. If $f$ in (5) is the true optimization objective, then $\mathbf{x<em r__j="r_{j">{M} \notin B</em>}}(\mathbf{x})$-otherwise the Lipschitz condition would be violated. The size of $B_{r_{j}}\left(\mathbf{x<em j="j">{j}\right)$ depends on $L, M$ and the value of $f$ at $\mathbf{x}</em>}$. Both large variability in $f$ (large $L$ ) and proximity of $f\left(\mathbf{x<em r__j="r_{j">{j}\right)$ to the optimum $M$ shrink $B</em>}}\left(\mathbf{x<em j="j">{j}\right)$.
In the BO context, under the assumption $f(\mathbf{x}) \sim$ $\mathcal{G P}\left(\mu(\mathbf{x}), k\left(\mathbf{x}, \mathbf{x}^{\prime}\right)\right)$, we choose $\varphi\left(\mathbf{x} ; \mathbf{x}</em>$ that is a potential candidate
to be a maximum, does not belong to $B_{r_{j}}\left(\mathbf{x}_{j}\right)$ :}\right)$ as the probability that $\mathbf{x}$, any point in $\mathcal{X</p>
<p>$$
\varphi\left(\mathbf{x} ; \mathbf{x}<em r__j="r_{j">{j}\right)=1-p\left(\mathbf{x} \in B</em>\right)\right)
$$}}\left(\mathbf{x}_{j</p>
<p>The following proposition (proof in Supp. Materials A) shows that this local penalizer can be computed in closed form.</p>
<p>Proposition 1 Let $f(\mathbf{x})$ be a $\mathcal{G} \mathcal{P}$ with posterior mean $\mu_{n}(\mathbf{x})$ and posterior variance $\sigma_{n}^{2}(\mathbf{x})$. The function $\varphi\left(\mathbf{x} ; \mathbf{x}<em j="j">{j}\right)$ in Eq. (6) is a valid local penalizer of $\alpha(\mathbf{x})$ at $\mathbf{x}</em>$ such that:</p>
<p>$$
\varphi\left(\mathbf{x} ; \mathbf{x}_{j}\right)=\frac{1}{2} \operatorname{erfc}(-z)
$$</p>
<p>where $z=\frac{1}{\sqrt{2 \sigma_{n}^{2}\left(\mathbf{x}<em j="j">{j}\right)}}\left(L\left|\mathbf{x}</em>}-\mathbf{x}\right|-M+\mu_{n}\left(\mathbf{x<em _mathbf_x="\mathbf{x">{j}\right)\right)$, for erfc the complementary error function, $M=$ $\max </em>)$ and $L$ a valid Lipschitz constant.} \in \mathcal{X}} f(\mathbf{x</p>
<p>The functions $\varphi\left(\mathbf{x} ; \mathbf{x}<em n="n">{j}\right)$ thus create exclusion zones whose size is governed by $L$. If $\mu</em>}\left(\mathbf{x<em j="j">{j}\right)$ is close to $M$, then $\varphi\left(\mathbf{x} ; \mathbf{x}</em>}\right)$ will have a smaller and more localized effect on $\alpha(\mathbf{x})$ (a smaller exclusion area). On the other hand, if $\mu_{n}\left(\mathbf{x<em j="j">{j}\right)$ is far from $M, \varphi\left(\mathbf{x} ; \mathbf{x}</em>)$, decreasing it as $L$ increases.}\right)$ will produce a wider yet less intense correction on $\alpha(\mathbf{x})$. The value of $L$ also affects the size of the effect of $\varphi\left(\mathbf{x} ; \mathbf{x}_{j}\right)$ on $\alpha(\mathbf{x</p>
<h3>2.2 Selecting the parameters $L$ and $M$</h3>
<p>The values of $M$ and $L$ are unknown in general. To approximate $M$, one can take $\hat{M}=\max <em n="n">{\mathcal{X}} \mu</em>=\max }(\mathbf{x})$ or, to avoid solving this maximization problem, use the even rougher approximation $\hat{M<em i="i">{i}\left{y</em>\right}$.
Regarding the parameter $L$ note that the definition of Lipschitz continuity in Eq. (3) does not uniquely</p>
<p>Algorithm 1 Batch Bayesian Optimization with Local Penalization (BBO-LP).</p>
<p>Input: dataset $\mathcal{D}<em i="i">{1}=\left{\mathbf{x}</em>\right}}, y_{i<em b="b">{i=1}^{n}$, batch size $n</em>$, iteration budget $m$, acquisition transformation $g$.
for $t=1$ to $m$ do
Fit a GP to $\mathcal{D}<em 0="0" t_="t,">{t}$.
Build the acquisition function $\alpha\left(\mathbf{x}, \mathcal{I}</em>\right)$ using the current GP.
$\tilde{\alpha}<em 0="0" t_="t,">{t, 0}(\mathbf{x}) \leftarrow g\left(\alpha\left(\mathbf{x}, \mathcal{I}</em>\right)\right)$.
$\hat{L} \leftarrow \max <em _nabla="\nabla">{\mathcal{X}}\left|\mu</em>)\right|$.
for $j=1$ to $n_{b}$ do}(\mathbf{x</p>
<ol>
<li>M-step: $\mathbf{x}<em _in="\in" _mathcal_X="\mathcal{X" x="x">{t, j} \leftarrow \arg \max </em>)\right}$.}}\left{\tilde{\alpha}_{t, j-1}(\mathbf{x</li>
<li>P-step: $\tilde{\alpha}<em 0="0" t_="t,">{t, j}(\mathbf{x}) \leftarrow \tilde{\alpha}</em>}(\mathbf{x}) \prod_{j=1}^{k} \varphi\left(\mathbf{x} ; \mathbf{x<em t="t">{t, j}, \hat{L}\right)$.
end for
$\mathcal{B}</em>}^{n_{b}} \leftarrow\left{\mathbf{x<em n__b="n_{b" t_="t,">{t, 1}, \ldots, \mathbf{x}</em>\right}$
$y_{t, 1}, \ldots, y_{t, n_{b}} \leftarrow$ Parallel evaluations of $f$ at $\mathcal{B}}<em b="b">{t}^{n</em>$.
$\mathcal{D}}<em t="t">{t+1} \leftarrow \mathcal{D}</em>} \cup\left{\left(\mathbf{x<em j="j" t_="t,">{t, j}, y</em>\right)\right}<em b="b">{j=1}^{n</em>$.
end for
Fit GP to $\mathcal{D}}<em M="M">{n}$.
Returns: $\hat{\mathbf{x}}</em>=\arg \max <em _nabla="\nabla">{x \in \mathcal{X}}{\mu(\mathbf{x})}$.
identify $L$. In the BO penalization context, small but feasible values of $L$ are preferred, because they produce large exclusion zones and thus more efficient search. Given access to the true objective $f$, one can show that $L</em>=\max <em _nabla="\nabla">{\mathbf{x} \in \mathcal{X}}|\nabla f(\mathbf{x})|$ is a valid Lipschitz constant (see Supp. Material C for further details). Note that $L</em>}$ is the smallest value of $L$ that satisfies the Lipschitz condition Eq. 3 in the limit $\mathbf{x<em 2="2">{1} \rightarrow \mathbf{x}</em>$ in (3).</li>
</ol>
<p>We now construct an approximation for $L_{\nabla}$. Assuming that $f$ is a draw from a GP with a (at least) twice differentiable kernel $k$, the gradient of $f$ at $\mathbf{x}^{<em>}$ is distributed as a multivariate Gaussian $\nabla f\left(\mathbf{x}^{</em>}\right) \mid \mathbf{X}, \mathbf{y}, \mathbf{x}^{<em>} \sim$ $\mathcal{N}\left(\mu_{\nabla}\left(\mathbf{x}^{</em>}\right), \Sigma_{\nabla}^{2}\left(\mathbf{x}^{*}\right)\right)$ with mean vector</p>
<p>$$
\mu_{\nabla}\left(\mathbf{x}^{<em>}\right)=\partial \mathbf{K}_{n, </em>}\left(\mathbf{x}^{*}\right) \hat{\mathbf{K}}_{n}^{-1} \mathbf{y}
$$</p>
<p>and covariance matrix</p>
<p>$$
\Sigma_{\nabla}^{2}\left(\mathbf{x}^{<em>}\right)=\partial^{2} \mathbf{K}_{</em>, <em>}-\partial \mathbf{K}_{n, </em>}\left(\mathbf{x}^{<em>}\right) \hat{\mathbf{K}}<em>{n}^{-1} \partial \mathbf{K}</em>{n, </em>}\left(\mathbf{x}^{*}\right)^{\top}
$$</p>
<p>for $\hat{\mathbf{K}}<em n="n">{n}=\mathbf{K}</em>$ and where, for $i, j=1, \ldots, d$ and $l=1, \ldots, n$,}+\sigma^{2} \mathbf{I</p>
<p>$$
\left(\partial \mathbf{K}<em>{n, <em>}\right)<em N="N">{i, l}=\frac{\partial \mathbf{k}</em>^{}\left(\mathbf{x</em>}\right)}{\partial x^{(i)}}, \quad\left(\partial^{2} \mathbf{K}</em>{<em>, </em>}\right)_{i j}=\frac{\partial^{2} k\left(\mathbf{x}^{<em>}, \mathbf{x}^{</em>}\right)}{\partial x^{(i)} \partial x^{(j)}}
$$</p>
<p>We choose</p>
<p>$$
\hat{L}<em _mathcal_X="\mathcal{X">{G P-L C A}=\max </em>\right)\right|
$$}}\left|\mu_{\nabla}\left(\mathbf{x}^{*</p>
<p>and call this the Gaussian Process Lipschitz Constant Approximation criterion (GP-LCA). Note that this definition of $\hat{L}<em _nabla="\nabla">{G P-L C A}$ ignores the variance of the gradient, which could be used to identify candidate points
to improve the approximation of $L</em>$ in a Bayesian optimization fashion. The supplement contains further experiments supporting the quality of this approximation. See Algorithm 1 for a description of all the steps described in this section.</p>
<h3>2.3 Heteroscedastic scenarios</h3>
<p>The use of an unique value of $L$ assumes that the function to optimize is Lipschitz homocedastic. Although this is a typical hypothesis for most BO methods, recent works have pointed out that some real problems do not satisfy this condition [Assael et al., 2014]. It is not the goal of this work to analyze this case further but, interestingly, the method proposed here can be extended to non-Lipschitz cases by replacing $L$ in the penalizers $\varphi\left(\mathbf{x} ; \mathbf{x}<em j="j">{j}, \hat{L}\right)$ by a local values of $L$. For instance, a possible approach would be to replace the local penalizers by $\varphi\left(\mathbf{x} ; \mathbf{x}</em>}, \hat{L<em j="j">{j}\right)$ where $\hat{L}</em>\right)\right|$.}=\left|\mu_{\nabla}\left(\mathbf{x}_{j</p>
<h3>2.4 Optimizing the penalized acquisition function</h3>
<p>The optimization of (4) can be performed most easily by any gradient-based method in the log space because there, the gradients have an additive form. More formally, when the transformation used to make the acquisition positive is the soft-plus function, $g(z)=$ $\ln \left(1+e^{z}\right)$, the gradient of $\log \tilde{\alpha}<em 0="0" t_="t,">{t, k}\left(\mathbf{x} ; \mathcal{I}</em>}\right)$, being $\tilde{\alpha<em 0="0" t_="t,">{t, k}\left(\mathbf{x} ; \mathcal{I}</em>\right)$ the penalized acquisition in Eq. (4), is:</p>
<p>$$
\begin{aligned}
\nabla \ln \tilde{\alpha}<em 0="0" t_="t,">{t, k}\left(\mathbf{x}, \mathcal{I}</em>}\right)= &amp; \frac{1}{\ln \left(1+e^{\alpha\left(\mathbf{X} ; \mathcal{I<em 0="0" t_="t,">{t, 0}\right)}\right)} \frac{e^{\alpha\left(\mathbf{X} ; \mathcal{I}</em>}\right)}}{1+e^{\alpha\left(\mathbf{X} ; \mathcal{I<em 0="0" t_="t,">{t, 0}\right)}} \
&amp; \nabla \alpha\left(\mathbf{x} ; \mathcal{I}</em>}\right)+\sum_{j=1}^{k-1} \varphi\left(\mathbf{x} ; \mathbf{x<em j="j" t_="t,">{t, j}\right)^{-1} \
&amp; \nabla \varphi\left(\mathbf{x} ; \mathbf{x}</em>\right)
\end{aligned}
$$</p>
<p>where $\nabla \alpha\left(\mathbf{x} ; \mathcal{I}<em j="j" t_="t,">{t, 0}\right)$ is the (assumed known) gradient of the original acquisition function and $\nabla \varphi\left(\mathbf{x} ; \mathbf{x}</em>\right)$ are the gradients of the local penalizers</p>
<p>$$
\nabla \varphi\left(\mathbf{x} ; \mathbf{x}<em n="n">{t, j}\right)=\frac{e^{-z^{2}}}{\sqrt{2 \pi \sigma</em>}^{2}\left(\mathbf{x<em j="j">{j}\right)}} \frac{2 L}{\left|\mathbf{x}</em>\right)
$$}-\mathbf{x}\right|}\left(\mathbf{x}_{j}-\mathbf{x</p>
<p>See Supp. Materials B for details.</p>
<h2>3 Experimental Section</h2>
<p>This section compares the performance of Algorithm 1 with the state-of-the-art methods for batch BO. We label the different methods by means of the batch design type followed by the acquisition used: Rand is used when the first element in the batch is collected maximizing the acquisition and the remaining ones randomly, B and PE denote the exploratory approaches in</p>
<table>
<thead>
<tr>
<th style="text-align: center;">d</th>
<th style="text-align: center;">$n_{b}$</th>
<th style="text-align: center;">EI</th>
<th style="text-align: center;">UCB</th>
<th style="text-align: center;">Rand-EI</th>
<th style="text-align: center;">Rand-UCB</th>
<th style="text-align: center;">SM-UCB</th>
<th style="text-align: center;">B-UCB</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">2</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">$0.31 \pm 0.03$</td>
<td style="text-align: center;">$0.32 \pm 0.06$</td>
<td style="text-align: center;">$0.32 \pm 0.05$</td>
<td style="text-align: center;">$0.31 \pm 0.05$</td>
<td style="text-align: center;">$1.86 \pm 1.06$</td>
<td style="text-align: center;">$0.56 \pm 0.03$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">10</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">$0.65 \pm 0.32$</td>
<td style="text-align: center;">$0.79 \pm 0.42$</td>
<td style="text-align: center;">$4.40 \pm 2.97$</td>
<td style="text-align: center;">$0.59 \pm 0.00$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">20</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">$0.67 \pm 0.31$</td>
<td style="text-align: center;">$0.75 \pm 0.32$</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">$0.57 \pm 0.01$</td>
</tr>
<tr>
<td style="text-align: center;">5</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">$8.84 \pm 3.69$</td>
<td style="text-align: center;">$11.89 \pm 9.44$</td>
<td style="text-align: center;">$9.19 \pm 5.32$</td>
<td style="text-align: center;">$10.59 \pm 5.04$</td>
<td style="text-align: center;">$137.2 \pm 113.0$</td>
<td style="text-align: center;">$6.01 \pm 0.00$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">10</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">$1.74 \pm 1.47$</td>
<td style="text-align: center;">$2.20 \pm 1.85$</td>
<td style="text-align: center;">$108.7 \pm 74.38$</td>
<td style="text-align: center;">$3.77 \pm 0.00$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">20</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">$2.18 \pm 2.30$</td>
<td style="text-align: center;">$2.76 \pm 3.06$</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">$2.53 \pm 0.00$</td>
</tr>
<tr>
<td style="text-align: center;">10</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">$559.1 \pm 1014$</td>
<td style="text-align: center;">$1463 \pm 1803$</td>
<td style="text-align: center;">$690.5 \pm 947.5$</td>
<td style="text-align: center;">$1825 \pm 2149$</td>
<td style="text-align: center;">$9 \mathrm{e}+04 \pm 7 \mathrm{e}+04$</td>
<td style="text-align: center;">$2098 \pm 0.00$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">10</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">$200.9 \pm 455.9$</td>
<td style="text-align: center;">$1149 \pm 1830$</td>
<td style="text-align: center;">$9 \mathrm{e}+04 \pm 1 \mathrm{e}+05$</td>
<td style="text-align: center;">$857.8 \pm 0.00$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">20</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">$639.4 \pm 1204$</td>
<td style="text-align: center;">$385.9 \pm 642.9$</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">$1656 \pm 0.00$</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align: center;">d</th>
<th style="text-align: center;">$n_{b}$</th>
<th style="text-align: center;">PE-UCB</th>
<th style="text-align: center;">Pred-EI</th>
<th style="text-align: center;">Pred-UCB</th>
<th style="text-align: center;">qEI</th>
<th style="text-align: center;">LP-EI</th>
<th style="text-align: center;">LP-UCB</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">2</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">$0.99 \pm 0.74$</td>
<td style="text-align: center;">$0.41 \pm 0.15$</td>
<td style="text-align: center;">$0.45 \pm 0.16$</td>
<td style="text-align: center;">$1.53 \pm 0.86$</td>
<td style="text-align: center;">$0.35 \pm 0.11$</td>
<td style="text-align: center;">$0.31 \pm 0.06$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">$0.66 \pm 0.29$</td>
<td style="text-align: center;">$1.16 \pm 0.70$</td>
<td style="text-align: center;">$1.26 \pm 0.81$</td>
<td style="text-align: center;">$3.82 \pm 2.09$</td>
<td style="text-align: center;">$0.66 \pm 0.48$</td>
<td style="text-align: center;">$0.69 \pm 0.51$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">20</td>
<td style="text-align: center;">$0.75 \pm 0.44$</td>
<td style="text-align: center;">$1.28 \pm 0.93$</td>
<td style="text-align: center;">$1.34 \pm 0.77$</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">$\mathbf{0 . 5 0} \pm \mathbf{0 . 2 1}$</td>
<td style="text-align: center;">$0.58 \pm 0.21$</td>
</tr>
<tr>
<td style="text-align: center;">5</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">$123.5 \pm 81.43$</td>
<td style="text-align: center;">$10.43 \pm 4.88$</td>
<td style="text-align: center;">$11.77 \pm 9.44$</td>
<td style="text-align: center;">$15.70 \pm 8.90$</td>
<td style="text-align: center;">$11.85 \pm 5.68$</td>
<td style="text-align: center;">$10.85 \pm 8.08$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">$120.8 \pm 78.56$</td>
<td style="text-align: center;">$9.58 \pm 7.85$</td>
<td style="text-align: center;">$11.66 \pm 11.48$</td>
<td style="text-align: center;">$17.69 \pm 9.04$</td>
<td style="text-align: center;">$3.88 \pm 4.15$</td>
<td style="text-align: center;">$\mathbf{1 . 8 8} \pm \mathbf{2 . 4 6}$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">20</td>
<td style="text-align: center;">$98.60 \pm 82.60$</td>
<td style="text-align: center;">$8.58 \pm 8.13$</td>
<td style="text-align: center;">$10.86 \pm 10.89$</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">$6.53 \pm 4.12$</td>
<td style="text-align: center;">$\mathbf{1 . 4 4} \pm \mathbf{1 . 9 3}$</td>
</tr>
<tr>
<td style="text-align: center;">10</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">$2 \mathrm{e}+05 \pm 2 \mathrm{e}+05$</td>
<td style="text-align: center;">$793.0 \pm 1226$</td>
<td style="text-align: center;">$1412 \pm 3032$</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">$1881 \pm 1176$</td>
<td style="text-align: center;">$1194 \pm 1428$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">$6 \mathrm{e}+04 \pm 8 \mathrm{e}+04$</td>
<td style="text-align: center;">$442.6 \pm 717.9$</td>
<td style="text-align: center;">$1725 \pm 3205$</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">$1042 \pm 1562$</td>
<td style="text-align: center;">$\mathbf{1 0 0 . 4} \pm \mathbf{3 3 8 . 7}$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">20</td>
<td style="text-align: center;">$5 \mathrm{e}+04 \pm 4 \mathrm{e}+04$</td>
<td style="text-align: center;">$1091 \pm 1724$</td>
<td style="text-align: center;">$2231 \pm 3110$</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">$1249 \pm 1570$</td>
<td style="text-align: center;">$\mathbf{2 0 . 7 5} \pm \mathbf{5 0 . 1 2}$</td>
</tr>
</tbody>
</table>
<p>Table 1: Results for the gSobol function across different dimensions, batch sizes and methods. For each algorithm, the mean and standard deviation are shown. Best results among the batch methods are highlighted in bold. '-' represents that the method could not complete the first iteration within the time budget. The value of $f$ at the minimum is always zero. EI and UCB represent the Expected improvement and the upper confidence bound acquisitions. Rand stands for the random batch collection. SM is the simulating and matching approach. Pred is the predictive approach and LP the local penalization method presented in this work. qEI is the multi-point expected improvement.
[Schonlau et al., 1998] and [Contal et al., 2013], Pred is used in cases when the model is used to generate 'fake' batch observations as in [Azimi et al., 2012], SM identifies the simulating and matching method [Azimi et al., 2010] and LP stands for our local penalization method. The multi-point expected improvement [Chevalier and Ginsbourger, 2013] is denoted by qEI. Two acquisition functions are used: the expected improvement (EI) defined as $\alpha_{E I}\left(\mathbf{x} ; \mathcal{I}<em n="n">{n}\right)=(u \Phi(u)+\phi(u)) \sigma</em>}(\mathbf{x})$, where $u=\left(\mu_{n}(\mathbf{x})-y_{\min }\right) / \sigma_{n}(\mathbf{x})$ and $\Phi(\cdot), \phi(\cdot)$ are the standard Gaussian distribution and density functions respectively and $y_{\min }$ is the best current location and the Upper Confidence Bound (UCB) defined as $\alpha_{U C B}\left(\mathbf{x} ; \mathcal{I<em n="n">{n}\right)=\mu</em>$ The implementation of}(\mathbf{x})+\kappa \sigma_{n}(\mathbf{x})$, with $\kappa \geq 0$. The batch methods that can be used with an arbitrary acquisition function are tested using both, with the exception of the SM whose implementation is only available with the UCB. When used in a sequential setting (for baseline reference) the EI and UCB are referred by their acronyms. In total, we use 2 sequential and 10 batch methods. To run the B, PE, SM, methods, we use the available Matlab code. ${ }^{2</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup>these methods optimize $f$ by searching its optimum in a fine grid, which is an advantage computationally but a drawback in terms of precision. The qEI was taken from the R-package DiceOptim. ${ }^{3}$ Unless specified otherwise, the default implemented settings of all the previous methods are used.</p>
<p>We perform: (i) a simulation in which the performance of the algorithms is compared for a fixed time budget across different problem dimensions, batch sizes and acquisition functions and (ii) a comparison of the gained information per second rate in three objective functions with different evaluation costs. We always minimize the objective, minimizing $-f$ in examples in which the goal is to find maximum of $f$. In all the experiments the exponentiated quadratic (EQ) covariance $k\left(\mathbf{x}, \mathbf{x}^{\prime}\right)=\theta \exp \left(-\gamma\left|\mathbf{x}-\mathbf{x}^{\prime}\right|^{2}\right), \theta, \gamma&gt;0$ is used in the GP, whose parameters are optimized by maximizing the marginal likelihood from the best of 10 random initializations. The results are taken over 20 replicates with different initial values. All the simulations were code is available at http://www.its.caltech.edu/ tadesaut/GPBUCBCode/ but we used the former one for consistency in the comparisons.
${ }^{3} \mathrm{http}: / /$ cran.r-project.org/web/packages/DiceOptim</p>
<p>done on Amazon EC2 servers with Intel Xeon E5-2666 processors and 2 virtual CPUs except the SVR tuning with 16 virtual CPUs.</p>
<h3>3.1 Comparisons in terms of the dimension, batch size and acquisition function</h3>
<p>We consider the gSobol function (see Supp. Materials D) to compare the above mentioned methods across dimensions $d=2,5,10$ and batch sizes, $n_{b}=5,10,20$. For methods using the UCB, $\kappa$ was fixed to 2 , which allows us to compare the different batch designs using the same acquisition function. For dimension 2, 5 and 10 , we use a time budget of 1,5 and 10 mins. respectively. Table 3 shows the averaged best value found by each algorithm for all the iterations completed within the time limit. In general, the batch methods using the UCB show a better performance that methods using the EI, especially in dimensions 5 and 10. The overall best technique is the LP-UCB, that achieves the best results in 5 of the 9 cases. It is also notable that it exhibits fairly small standard deviations compared with the rest of the methods and it is coherent accumulating information about the optimum of $f$ in terms of the batch size: as $n_{b}$ increases the results are consistently better. In dimension 2 and batch size 5, the LP-EI is the best method. There are three cases in which the LP batch designs are not the most competitive (although still providing good results). Exploratory approaches works well in low dimensional cases, being the B-UCB the best method in two scenarios.</p>
<h3>3.2 Comparisons in terms of the cost to evaluate the objective</h3>
<p>We choose three scenarios to compare the algorithms in terms of the running time. The examples correspond to three functions that are cheap, moderate and expensive to evaluate. More specifically, the first experiment uses a function (Cosines) that is inexpensive to evaluate but quite multi-modal. The second experiment is motivated by a wet-lab experimental design. We work with a surface that emulates the performance of mammalian cells in protein production given different gene designs. The function has dimension 71 and is is moderately expensive to evaluate since it corresponds to the predictive mean of a GP trained over 1,500 data instances. The qEI was not used in this experiment due to the huge computational effort required to jointly optimize the batches in dimension 71. The third experiment involves the tuning of the three parameters of a support vector regression (SVR) [Drucker et al., 1997] in a example with 45730 instances and 9 continuous attributes [Bache and Lichman, 2013]. The objective function is the cross-validation error of the model, which is expen-
sive to evaluate due to the amount of data used. See Supp. Materials D for further details. We take a batch size of $n_{b}=5$ for the Cosines function and $n_{b}=10$ for the wet-lab and SVR experiments. We compare the averaged best found results in terms of the number of collected batches and the wall-clock time. In the last experiment we use the SVR implementation available in scikit-learn ${ }^{4}$ and only the methods implemented in python are used (EI, UCB, Rand-EI, RandUCB, Pred-EI, Pred-UCB, LP-EI and LP-UCB).
In the Cosines experiment both the sequential EI and UCB policies achieve the best results during the first 10 iterations of the algorithms ( 2 full batches). As the algorithms progress, however, a significant improvement is observed by the LP-EI and LP-UCB methods in terms of the number iterations and in terms of the wall-clock-time. When many points are collected, the update of the GP is more expensive and a good batch design is able to explore regions that the sequential method cannot. The rest of the batch methods, however, are not able to do this exploration efficiently, which leads to poorer results. Similar results are obtained for the wet-lab experiment. The LP-EI and LP-UCB are again the most competitive techniques improving the rest of the batch methods and the sequential policies. The differences are even more significant in this scenario. Since $f$ is now more expensive to evaluate, the parallelization of the evaluations makes the search much more efficient, specially for the LP-UCB method. Regarding the last experiment, the cost of evaluating the function dominates the cost of designing the batch. In this case the performance of the different batch methods is comparable but significantly better than the sequential policies due to the parallel evaluations of $f$. The results for the three functions are coherent with those observed in Section 3.1 showing that the BBP-LP methods is overall the most efficient method for batches collection in BO.</p>
<h2>4 Discussion</h2>
<p>We have investigated a new heuristic for batch BO, BBO-LP, that significantly reduces the computational burden of non-parallelizable tasks. The resulting method can be used with any acquisition function and it is able to make fast and appropriate decisions about the locations where $f$ should be evaluated. When the batch evaluations of $f$ are parallelizable this is an important advantage, meaning that they don't lead to considerable additional computational overhead. We have found other interesting results. In simple scenarios, batch policies based on random exploration work reasonably well in terms of the information gained</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3: Results for the three test functions described in Section 3.2. Geometric figures on top of the lines represent the moments in which the batches are evaluated. See caption of Table 3 for details on the acronyms.</p>
<p>per second. When the complexity of the problem increases, however, methods that make use of some information about $f$ improve the random policy. In particular, the approach here proposed makes use of the Lipschitz continuity of $f$ to model the interaction between the elements in the batch. In spirit, this is similar to use the GP to predict the evaluations of $f$ but, in practice, is much more efficient because it avoids the re-computation of the GP after every point is selected. The limitations of this approach are, however, determined by the ability to learn correctly a small enough, and valid, Lipschitz constant for $f$.</p>
<p>One could also wonder whether it is necessary to require that sample paths from the GP measure on $f$ should be Lipschitz-continuous themselves. This would severely restrict the applicability of this notion, because the relationship between regularity of the kernel and the sample paths is complicated. Even if the kernel is Lipschitz-continuous, sample paths may not be Lipschitz [Adler, 1981]. However, our approach only tries to model the effect of evaluations on the BO objective, not the GP probability measure itself. Many BO objectives, in particular the EI and UCB, are smooth functions of only the sufficient statistics (mean and covariance function) of the GP posterior. Both the posterior mean and covariance function are members of the Reproducing kernel Hilbert space induced by the kernel (i.e. they are weighted sums of kernel functions). Thus, if the kernel is Lipschitz, so is the acquisition function, even if the GP measure itself has non-Lipschitz sample paths. Finally, note that our local repulsion criterion naturally suggests a Latin square design for the case when no functional values have been been acquired. The latin square design is widely suggested for this domain [Jones et al., 1998].</p>
<h2>References</h2>
<p>Robert J. Adler. The geometry of random fields. Wiley, 1981.</p>
<p>John-Alexander M. Assael, Ziyu Wang, and Nando de Freitas. Heteroscedastic treed bayesian optimisation. CoRR, abs/1410.7172, 2014.
Javad Azimi, Alan Fern, and Xiaoli Fern. Batch Bayesian optimization via simulation matching. In Advances in Neural Information Processing Systems, pages 109-117, 2010.
Javad Azimi, Ali Jalali, and Xiaoli Fern. Dynamic batch Bayesian optimization. CoRR, abs/1110.3347, 2011.</p>
<p>Javad Azimi, Ali Jalali, and Xiaoli Zhang Fern. Hybrid batch Bayesian optimization. In Proceedings of the 29th International Conference on Machine Learning, 2012.
Kevin Bache and Moshe Lichman. UCI machine learning repository, 2013.
James Bergstra, Rémy Bardenet, Yoshua Bengio, and Balázs Kégl. Algorithms for hyper-parameter optimization. In NIPS'2011, 2011.
Clment Chevalier and David Ginsbourger. Fast computation of the multi-points expected improvement with applications in batch selection. In Giuseppe Nicosia and Panos M. Pardalos, editors, LION, volume 7997 of LNCS, pages 59-69. Springer, 2013. ISBN 978-3-642-44972-7.
Emile Contal, David Buffoni, Alexandre Robicquet, and Nicolas Vayatis. Parallel Gaussian process optimization with upper confidence bound and pure exploration. CoRR, abs/1304.5350, 2013.
Thomas Desautels, Andreas Krause, and Joel W. Burdick. Parallelizing exploration-exploitation tradeoffs with Gaussian process bandit optimization. In Proceedings of the 29th International Conference on Machine Learning, 2012.
Harris Drucker, Chris, Burges L. Kaufman, Alex Smola, and Vladimir Vapnik. Support vector regression machines. In Advances in Neural Information Processing Systems 9, pages 155-161, 1997.
Christodoulos A. Floudas and Panos M. Pardalos, editors. Encyclopedia of Optimization, Second Edition. Springer, 2009.
P. I. Frazier. Parallel global optimization using an improved multi-points expected improvement criterion. In INFORMS Optimization Society Conference, Miami FL, 2012.
David Ginsbourger, Janis Janusevskis, and Rodolphe Le Riche. Dealing with asynchronicity in parallel</p>
<p>Gaussian Process based global optimization. Technical report, 2011.
Javier González, Joseph Longworth, David James, and Neil Lawrence. Bayesian optimisation for synthetic gene design. NIPS Workshop on Bayesian Optimization in Academia and Industry, 2014.
Philipp Hennig and Christian J. Schuler. Entropy search for information-efficient global optimization. Journal of Machine Learning Research, 13, 2012.
José M. Hernández-Lobato, Matthew W. Hoffman, and Zoubin Ghahramani. Predictive entropy search for efficient global optimization of black-box functions. In Advances in Neural Information Processing Systems 27, pages 918-926. Curran Associates, Inc., 2014.
Reiner Horst and Panos M. Pardalos, editors. Handbook of global optimization. Nonconvex optimization and its applications. Kluwer Academic Publishers, Dordrecht, Boston, 1995.
Ali Jalali, Javad Azimi, Xiaoli Fern, and Ruofei Zhang. A lipschitz exploration-exploitation scheme for Bayesian optimization. In Machine Learning and Knowledge Discovery in Databases, pages 210-224, 2013.</p>
<p>Janis Janusevskis, Rodolphe Le Riche, David Ginsbourger, and Ramunas Girdziusas. Expected improvements for the asynchronous parallel global optimization of expensive functions: Potentials and challenges. In Y. Hamadi and M. Schoenauer, editors, LION, volume 7219 of LNCS, pages 413-418. Springer, 2012.
Donald R. Jones, Matthias Schonlau, and William J. Welch. Efficient global optimization of expensive black-box functions. Journal of Global Optimization, 13(4):455-492, 1998.
Michael Osborne. Bayesian Gaussian Processes for Sequential Prediction, Optimisation and Quadrature. PhD thesis, PhD thesis, University of Oxford, 2010.
Ji Oenek and Josef Schwarz. The parallel Bayesian optimization algorithm. In Peter Sink, Jn Vak, Vladimir Kvasnika, and Radko Mesiar, editors, The State of the Art in Computational Intelligence, volume 5 of Advances in Soft Computing, pages 61-67. Physica-Verlag HD, 2000.
Carl Edward Rasmussen and Christopher K. I. Williams. Gaussian Processes for Machine Learning (Adaptive Computation and Machine Learning). The MIT Press, 2005.
Matthias Schonlau, William J. Welch, and Donald R. Jones. Global versus local search in constrained optimization of computer models, volume Volume 34 of</p>
<p>Lecture Notes-Monograph Series, pages 11-25. Institute of Mathematical Statistics, Hayward, CA, 1998.</p>
<p>Jasper Snoek, Hugo Larochelle, and Ryan P. Adams. Practical Bayesian optimization of machine learning algorithms. In Advances in Neural Information Processing Systems 25, pages 2960-2968, 2012.
Roman G. Strongin and Yaroslav D. Sergeyev. Global optimization with non-convex constraints : sequential and parallel algorithms. Nonconvex Optimization and Its Applications. Kluwer academic publishers, Dordrecht, Boston, Londres, 2000.</p>
<h2>A Proof of Proposition 1</h2>
<p>We compute the explicit form of the penalization functions $\varphi\left(\mathbf{x} ; \mathbf{x}<em j="j">{j}\right)$. The distribution of $r</em>}$ is Gaussian with mean $\left(M-\mu_{n}\left(\mathbf{x<em n="n">{j}\right)\right) / L$ and variance $\sigma</em>}^{2}\left(\mathbf{x<em j="j">{j}\right) / L^{2}$ by the properties of $f\left(\mathbf{x}</em>\right)$. Then we obtain that</p>
<p>$$
\begin{aligned}
\varphi\left(\mathbf{x} ; \mathbf{x}<em r__j="r_{j">{j}\right) &amp; =1-p\left(\mathbf{x} \in B</em>}}\left(\mathbf{x<em j="j">{j}\right)\right) \
&amp; =1-p\left(r</em>} \geq\left|\mathbf{x<em p="p">{j}-\mathbf{x}\right|</em>\right) \
&amp; =p\left(r_{j} \leq\left|\mathbf{x}<em p="p">{j}-\mathbf{x}\right|</em>\right) \
&amp; =p\left(\mathcal{N}(0,1) \leq \frac{L\left|\mathbf{x}<em p="p">{j}-\mathbf{x}\right|</em>}-M+\mu_{n}\left(\mathbf{x<em n="n">{j}\right)}{\sigma</em>}\left(\mathbf{x<em j="j">{j}\right)}\right) \
&amp; =\Phi\left(\frac{L\left|\mathbf{x}</em>\right|}-\mathbf{x<em n="n">{p}-M+\mu</em>}\left(\mathbf{x<em n="n">{j}\right)}{\sigma</em>\right) \
&amp; =\frac{1}{2} \operatorname{erfc}(-z)
\end{aligned}
$$}\left(\mathbf{x}_{j}\right)</p>
<p>for</p>
<p>$$
z=\frac{1}{\sqrt{2 \sigma_{n}^{2}\left(\mathbf{x}<em j="j">{j}\right)}}\left(L\left|\mathbf{x}</em>\right)\right)
$$}-\mathbf{x}\right|-M+\mu_{n}\left(\mathbf{x}_{j</p>
<h2>B Optimization of the penalized acquisition function</h2>
<p>Under the proposed local penalization method, to select the $k$-th element of the $t$-th batch requires the optimization of the function</p>
<p>$$
\tilde{\alpha}<em 0="0" t_="t,">{t, k}\left(\mathbf{x} ; \mathcal{I}</em>}\right)=g\left(\alpha\left(\mathbf{x} ; \mathcal{I<em j="1">{t, 0}\right)\right) \prod</em>\right)
$$}^{k-1} \varphi\left(\mathbf{x} ; \mathbf{x}_{t, j</p>
<p>which can be done by any gradient descend method as follows. We fist map the problem into the natural log space by observing that</p>
<p>$$
\arg \max <em k="k" t_="t,">{x \in \mathcal{X}}\left{\tilde{\alpha}</em>}\left(\mathbf{x}, \mathcal{I<em _in="\in" _mathcal_X="\mathcal{X" x="x">{t, 0}\right)\right}=\arg \max </em>}}\left{\ln \tilde{\alpha<em 0="0" t_="t,">{t, k}\left(\mathbf{x}, \mathcal{I}</em>\right)\right}
$$</p>
<p>Applying the properties of the logarithms we transform the problem into the maximization of</p>
<p>$$
\ln \tilde{\alpha}<em 0="0" t_="t,">{t, k}\left(\mathbf{x}, \mathcal{I}</em>}\right)=\ln \left[g\left(\alpha\left(\mathbf{x} ; \mathcal{I<em j="1">{t, 0}\right)\right)\right]+\sum</em>\right)\right]
$$}^{k-1} \ln \left[\varphi\left(\mathbf{x} ; \mathbf{x}_{t, j</p>
<p>The gradient with respect to $\mathbf{x}$ is now easy to calculate since the problem is in additive form. First, note that the gradients of the local penalizers $\nabla \varphi\left(\mathbf{x} ; \mathbf{x}_{t, j}\right)$ are</p>
<p>$$
\nabla \varphi\left(\mathbf{x} ; \mathbf{x}<em n="n">{t, j}\right)=\frac{e^{-z^{2}}}{\sqrt{2 \pi \sigma</em>}^{2}\left(\mathbf{x<em j="j">{j}\right)}} \frac{2 L}{\left|\mathbf{x}</em>\right)
$$}-\mathbf{x}\right|}\left(\mathbf{x}_{j}-\mathbf{x</p>
<p>with</p>
<p>$$
z=\frac{1}{\sqrt{2 \sigma_{n}^{2}\left(\mathbf{x}<em j="j">{j}\right)}}\left(L\left|\mathbf{x}</em>\right)\right)
$$}-\mathbf{x}\right|-M+\mu_{n}\left(\mathbf{x}_{j</p>
<p>Then, it holds that</p>
<p>$$
\begin{aligned}
\nabla \ln \tilde{\alpha}<em 0="0" t_="t,">{t, k}\left(\mathbf{x}, \mathcal{I}</em>}\right)= &amp; {\left[g\left(\alpha\left(\mathbf{x} ; \mathcal{I<em 0="0" t_="t,">{t, 0}\right)\right)^{-1}\right.} \
&amp; \left.\frac{d}{d \alpha\left(\mathbf{x} ; \mathcal{I}</em>}\right)} g\left(\alpha\left(\mathbf{x} ; \mathcal{I<em 0="0" t_="t,">{t, 0}\right)\right)\right] \nabla \alpha\left(\mathbf{x} ; \mathcal{I}</em>\right) \
+ &amp; \sum_{j=1}^{k-1} \varphi\left(\mathbf{x} ; \mathbf{x}<em j="j" t_="t,">{t, j}\right)^{-1} \nabla \varphi\left(\mathbf{x} ; \mathbf{x}</em>\right)
\end{aligned}
$$</p>
<p>where $\nabla \alpha\left(\mathbf{x} ; \mathcal{I}<em k="k" t_="t,">{t, 0}\right)$ is the (assumed known) gradient of the original acquisition function. In cases in which the acquisition is already positive it is natural to choose $g(z)=z$ and the gradient of $\ln \tilde{\alpha}</em>\right)$ reduces to}\left(\mathbf{x}, \mathcal{I}_{t, 0</p>
<p>$$
\begin{aligned}
\nabla \ln \tilde{\alpha}<em 0="0" t_="t,">{t, k}\left(\mathbf{x}, \mathcal{I}</em>}\right) &amp; =\alpha\left(\mathbf{x} ; \mathcal{I<em 0="0" t_="t,">{t, 0}\right)^{-1} \nabla \alpha\left(\mathbf{x} ; \mathcal{I}</em>\right)+ \
&amp; =\sum_{j=1}^{k-1} \varphi\left(\mathbf{x} ; \mathbf{x}<em j="j" t_="t,">{t, j}\right)^{-1} \nabla \varphi\left(\mathbf{x} ; \mathbf{x}</em>\right)
\end{aligned}
$$</p>
<p>When $\alpha\left(\mathbf{x} ; \mathcal{I}_{t, 0}\right)$ is not necessarily positive one can take $g(z)=\exp (z)$ and the gradient simplifies to</p>
<p>$$
\nabla \ln \tilde{\alpha}<em 0="0" t_="t,">{t, k}\left(\mathbf{x}, \mathcal{I}</em>}\right)=\nabla \alpha\left(\mathbf{x} ; \mathcal{I<em j="1">{t, 0}\right)+\sum</em>}^{k-1} \varphi\left(\mathbf{x} ; \mathbf{x<em j="j" t_="t,">{t, j}\right)^{-1} \nabla \varphi\left(\mathbf{x} ; \mathbf{x}</em>\right)
$$</p>
<p>When $g(z)=\ln \left(1+e^{z}\right)$ the gradient is</p>
<p>$$
\begin{aligned}
\nabla \ln \tilde{\alpha}<em 0="0" t_="t,">{t, k}\left(\mathbf{x}, \mathcal{I}</em>}\right)= &amp; \frac{1}{\ln \left(1+e^{\alpha\left(\mathbf{X} ; \mathcal{I<em 0="0" t_="t,">{t, 0}\right)}\right)} \frac{e^{\alpha\left(\mathbf{X} ; \mathcal{I}</em>}\right)}}{1+e^{\alpha\left(\mathbf{X} ; \mathcal{I<em 0="0" t_="t,">{t, 0}\right)}} \
&amp; \nabla \alpha\left(\mathbf{x} ; \mathcal{I}</em>}\right)+\sum_{j=1}^{k-1} \varphi\left(\mathbf{x} ; \mathbf{x<em j="j" t_="t,">{t, j}\right)^{-1} \
&amp; \nabla \varphi\left(\mathbf{x} ; \mathbf{x}</em>\right)
\end{aligned}
$$</p>
<h2>C Lipschitz constant approximation</h2>
<p>In this section we elaborate in the approximation of the Lipschitz constant. First, we include the following proposition that allows to uniquely identify a valid value of $L$.</p>
<p>Proposition 2 Let $f: \mathcal{X} \rightarrow \mathbb{R}$ be a L-Lipschitz continuous function defined on a compact subset $\mathcal{X} \subseteq \mathbb{R}^{d}$. Take</p>
<p>$$
L_{p}=\max <em p="p">{\boldsymbol{x} \in \mathcal{X}}|\nabla f(\boldsymbol{x})|</em>
$$</p>
<p>where $\nabla f(\boldsymbol{x})=\left(\frac{\partial f}{\partial \boldsymbol{x}<em p="p">{1}}, \cdots, \frac{\partial f}{\partial \boldsymbol{x}</em>$ is a valid Lipschitz constant such that the Lipschitz condition}}\right)^{\top}$. Then, $L_{p</p>
<p>$$
\left|f\left(\boldsymbol{x}<em 2="2">{1}\right)-f\left(\boldsymbol{x}</em>}\right)\right| \leq L_{p}\left|\boldsymbol{x<em 2="2">{1}-\boldsymbol{x}</em>
$$}\right|_{q</p>
<p>where $\frac{1}{s}+\frac{1}{t}=1$, holds.
Proof 1 Using the mean value theorem for every $\boldsymbol{x}<em 2="2">{1}, \boldsymbol{x}</em>} \in \mathcal{X}$ there exist a $\boldsymbol{w}=\boldsymbol{x<em 2="2">{1}+\beta \boldsymbol{x}</em>$, with $\beta \in(0,1)$ such that,</p>
<p>$$
\left|f\left(\boldsymbol{x}<em 2="2">{1}\right)-f\left(\boldsymbol{x}</em>}\right)\right|=\left|\nabla f(\boldsymbol{w})\left(\boldsymbol{x<em 2="2">{1}-\boldsymbol{x}</em>\right)\right|
$$</p>
<p>By the Holder's inequality we have that</p>
<p>$$
\left|f\left(\boldsymbol{x}<em 2="2">{1}\right)-f\left(\boldsymbol{x}</em>)|}\right)\right| \leq|\nabla f(\boldsymbol{w<em 1="1">{p}\left|\boldsymbol{x}</em>}-\boldsymbol{x<em q="q">{2}\right|</em>
$$</p>
<p>Since $\boldsymbol{w} \in \mathcal{X}$ by definition, we have that</p>
<p>$$
\left|f\left(\boldsymbol{x}<em 2="2">{1}\right)-f\left(\boldsymbol{x}</em>}\right)\right| \leq L_{p}\left|\boldsymbol{x<em 2="2">{1}-\boldsymbol{x}</em>
$$}\right|_{q</p>
<p>for $L_{p}=\max <em p="p">{\boldsymbol{x} \in \mathcal{X}}|\nabla f(\boldsymbol{x})|</em>$.
In order to test the empirical approximation of the Lipschitz constant detailed in Section 2.2 we use the Cosines function described in the experimental section of this work. The true $L_{\nabla}$ for this function is 8.808636 , that was calculated by maximizing the norm of gradient of $f$ in a very fine grid. We check the quality of our approximation to $L_{\nabla}$ for increasing sample size up to 50 observations, where the locations of the points are randomly selected along the domain of $f$ using a bivariate uniform distribution. The evaluations of $f$ at the selected locations were perturbed with Gaussian noise with standard deviations $\sigma=0,0.1,0.25$. In Figure 4 we show the results for 30 replicates of the experiment. The average approximation of L converges to the true $L_{\nabla}$, being this convergence slower when the evaluation errors increase.
<img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 4: Approximation of the Lipschitz constant in the cosines function using the GP-LCA method. We compare the convergence in the approximation for different noise levels and increasing sample size. For each sample size show we show the average of 30 replications. Vertical bars represent the $95 \%$ confidence interval for the average estimate.</p>
<h2>D Detailed description of the experiments</h2>
<h2>D. 1 Synthetic functions</h2>
<p>Table 2 contains the the details of the functions used in the experiments of this work.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Name</th>
<th style="text-align: center;">Function</th>
<th style="text-align: center;">$\mathcal{X}$</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">gSobol</td>
<td style="text-align: center;">$f(\mathbf{x})=\prod_{i=1}^{d} \frac{\left</td>
<td style="text-align: center;">4 x_{i}-2\right</td>
</tr>
<tr>
<td style="text-align: center;">Cosines</td>
<td style="text-align: center;">$f(\mathbf{x})=1-\sum_{i=1}^{2}\left(g\left(x_{i}\right)-r\left(x_{i}\right)\right)$ <br> with $g\left(x_{i}\right)=\left(1.6 x_{i}-0.5\right)^{2}$, <br> $r\left(x_{i}\right)=0.3 \cos \left(3 \pi\left(1.6 x_{i}-0.5\right)\right)$.</td>
<td style="text-align: center;">$[0,5]^{2}$</td>
</tr>
</tbody>
</table>
<p>Table 2: Functions used in the experimental section. All the parameters $a_{i}$ of the gSobol function are set to $a_{i}=1$ in the experiments.</p>
<h2>D. 2 Gene design experiment</h2>
<p>There is an increasing interest in the pharmacological industry in the the design of synthetic genes capable of transforming cells into 'factories' able to produce drugs of interest. In this experiment we emulate a gene design process.</p>
<p>The function to maximize is the production of cell proteins, that it is known depends on certain features of the gene sequences. We built a GP to link gene features and protein production efficiency based the model described in González et al. [2014]. A total of 71 gene features are considered, which correspond to the dimension of the final design space. We validated the model with the remaining 2908 genes of the dataset and we used its posterior mean as the function to optimize. We can understand this model as a mathematical surrogate of the cell behavior in which the mean evaluations play the role of physical wet-lab gene design tests, many of which can be run in parallel for the same price of one.</p>
<h2>D. 3 SVR parameter tuning experiment</h2>
<p>Support Vector Machines (SVR) for regression Drucker et al. [1997] with an EQ kernel, depend on three parameters: the kernel lengthscale $(\gamma)$, the soft margin parameter $(C)$ and the band size $(\epsilon)$. A proper choice of the parameters is crucial to guarantee a good performance of the SVR, which is typically done by minimizing the mean square error (RMSE) in a test dataset. This task can be expensive, specially for large datasets. We use BO to optimize the parameters of the SVR using the 'Physiochemical' properties of protein tertiary structure' dataset available in the UCI Machine Learning repository Bache and Lichman [2013]. This dataset has 45,730 instances and 9 continuous attributes that are used to predict the coordinate root mean square distance (RMSD), a measure that describes the distance per residue between to optimally aligned protein sequences. We trained the SVR using a randomly selected subset of 22,000 proteins and we tested the results of using the rest. Every iteration takes around 300 seconds.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{4}$ http://scikit-learn.org/stable/index.html.&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>