<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2326 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2326</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2326</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-63.html">extraction-schema-63</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <p><strong>Paper ID:</strong> paper-164916889</p>
                <p><strong>Paper Title:</strong> A survey on evolutionary machine learning</p>
                <p><strong>Paper Abstract:</strong> ABSTRACT Artificial intelligence (AI) emphasises the creation of intelligent machines/systems that function like humans. AI has been applied to many real-world applications. Machine learning is a branch of AI based on the idea that systems can learn from data, identify hidden patterns, and make decisions with little/minimal human intervention. Evolutionary computation is an umbrella of population-based intelligent/learning algorithms inspired by nature, where New Zealand has a good international reputation. This paper provides a review on evolutionary machine learning, i.e. evolutionary computation techniques for major machine learning tasks such as classification, regression and clustering, and emerging topics including combinatorial optimisation, computer vision, deep learning, transfer learning, and ensemble learning. The paper also provides a brief review of evolutionary learning applications, such as supply chain and manufacturing for milk/dairy, wine and seafood industries, which are important to New Zealand. Finally, the paper presents current issues with future perspectives in evolutionary machine learning.</p>
                <p><strong>Cost:</strong> 0.026</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2326.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2326.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>EC-agriculture</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Evolutionary computation for agricultural decision making (land use, crop and fish farming)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Use of evolutionary computation (GAs, PSO and related EC methods) to support land-use planning, crop-farming decisions and fish-farming operational decisions by searching large combinatorial policy/parameter spaces and optimising multi-objective trade-offs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>A survey on evolutionary machine learning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Agriculture (land-use planning, crop farming, fish farming)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Optimise resource allocation and operational decisions in agriculture and aquaculture (e.g., land use allocation, crop planning, fish-farm management) under multiple objectives and uncertain/dynamic constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>null</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>null</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>High — multi-objective combinatorial decision spaces, domain constraints, and dynamic/uncertain environments; potentially large-scale search spaces.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Moderately mature — established decision-analytic and optimisation practice exists, but specific applications vary and need domain expertise; EC provides automated search where manual design is costly.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Medium — interpretable policies are useful for adoption by domain experts, but good-performing heuristics/solutions are also acceptable.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Evolutionary computation (genetic algorithms, particle swarm optimisation, memetic algorithms)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Population-based global search techniques encode candidate policies/allocations as individuals (e.g., bitstrings or real vectors) and evolve them using crossover/mutation or swarm updates; multi-objective variants return Pareto fronts to reveal trade-offs between objectives such as cost, yield and risk.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Multi-objective evolutionary optimisation / heuristic search</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Applicable — EC methods are appropriate given large, constrained, multi-objective search spaces and the need for automated heuristic generation; survey notes successful applications in land use and farm decision problems.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Reported as effective and promising in many domain studies; EC methods can reduce human effort in heuristic design and find trade-offs between conflicting objectives.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>High potential to reduce planning cost/time and produce practical heuristics for operational decision support; can scale to different farm types and support scenario analysis.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>null</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Population-based global search that handles multiple objectives and constraints; ability to return diverse Pareto-optimal solutions; reduces need for domain-expert handcrafted heuristics.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>EC is well suited for agricultural decision problems with large combinatorial and multi-objective search spaces where automated heuristic generation and Pareto trade-offs are valuable.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2326.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2326.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>EC-manufacturing</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Evolutionary computation in manufacturing and supply-chain optimisation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Application of EC (GAs, DE, PSO and hybrids) to production scheduling, resource allocation and transportation routing problems in manufacturing and supply chains (including dairy, wine, wood, mineral processing, seafood).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>A survey on evolutionary machine learning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Manufacturing and supply chain optimisation (dairy, wine, wood, minerals, seafood transport)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Solve scheduling, resource allocation and routing to minimise time/cost and meet operational constraints in dynamic and large-scale manufacturing/supply chain systems.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>null</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>null</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>High — combinatorial optimisation with many constraints, dynamic arrivals, multi-objective trade-offs, and large instance sizes (many items/customers/jobs).</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Mature in operational research terms, but specific problems often complex and domain-specific requiring heuristic approaches; EC offers automated hyper-heuristic solutions.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Low-to-medium — practical heuristics that perform well are often acceptable, but interpretability of rules can aid deployment in operations.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Evolutionary hyper-heuristics (genetic programming Hyper-Heuristics, GPHH), genetic algorithms, differential evolution</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>EC methods represent heuristics/dispatching rules as individuals (e.g., GP trees or parameter vectors) and evolve them by evaluating performance across training instances; hyper-heuristics produce generalisable rules for dynamic scheduling/routing/bin-packing.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Reinforcement-like / hyper-heuristic (automated heuristic design)</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Applicable — well matched to dynamic, real-time scheduling where traditional optimisation is too slow and hand-crafted heuristics are costly to produce.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Reported successes in evolving dispatching rules and packing heuristics; shown to produce reusable heuristics for dynamic variants of classical problems.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Substantial — can automate design of online heuristics, reducing human engineering time and enabling real-time decision making in manufacturing and logistics.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Survey notes GPHHs outperform or match traditional heuristics in many studies; hybrid approaches (e.g., GA + k-means for clustering components of problems) are used to balance global/local search.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Encoding heuristics directly (GP) for dynamic invocation, multi-instance training evaluation for robustness, and multi-objective evaluation for trade-offs.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Evolving heuristics via EC is especially effective for dynamic, real-time scheduling and routing problems where traditional static optimisation and manual heuristics fail to adapt quickly.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2326.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2326.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>EC-energy</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Evolutionary computation in energy systems (load forecasting and wind farm design)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Use of EC methods (GA, PSO) for forecasting electricity load and optimising wind turbine placement/design to improve energy capture and system planning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>A survey on evolutionary machine learning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Energy systems (short-term load forecasting, wind farm design)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Predict electrical load time series for operational planning and design wind farm layouts to maximise energy capture while respecting constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>null</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Time series for load forecasting; spatial/geometric data for wind farm layout.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Medium-to-high — temporal dependencies for forecasting; spatially coupled, non-convex placement/design optimisation for wind farm layout.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Established domain with mature modelling and forecasting methods; EC provides flexible alternatives for hard nonconvex layout/design problems.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Low-to-medium — forecasting often accepts black-box models if accurate; design optimisation benefits from interpretable constraints but not necessarily mechanistic models.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Particle swarm optimisation, genetic algorithms, hybrid fuzzy/EC models</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>EC techniques used to tune or discover models (e.g., fuzzy neural networks with GA/PSO) for forecasting and to search nonconvex design spaces (e.g., turbine placement) using population-based optimisers.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Supervised learning (forecasting) and black-box optimisation</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Applicable — EC handles non-convexity and multimodality in design and can optimise hybrid forecasting models.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Reported as effective in cited studies, providing promising results for wind turbine placement and load forecasting when combined with appropriate model structures.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Moderate to high — improvements in forecasting accuracy and layout optimisation can yield operational cost savings and increased energy yield.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>null</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Ability to search global, multimodal landscapes and tune hybrid models; use of domain-specific fitness evaluations (e.g., energy yield metrics).</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>EC methods are suitable where models are non-differentiable or design spaces are highly nonconvex, while forecasting benefits from EC when integrating model selection/tuning with optimization.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2326.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2326.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>EC-finance</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Evolutionary computation for financial time-series analysis and risk modelling</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Application of EC (GP, GA, PSO) to model, forecast and extract trading/credit/bankruptcy signals from temporal financial data.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>A survey on evolutionary machine learning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Finance (time series forecasting, market price prediction, bankruptcy ratio analysis, credit risk)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Model temporal financial series for forecasting and classification tasks (price prediction, risk assessment) under noisy, nonstationary conditions.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>null</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Time series; tabular financial ratios; high-frequency or low-frequency depending on task.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>High — temporal non-stationarity, noise, potential nonlinearity, and high-dimensional feature sets in some tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Mature with extensive econometric methods; EC offers flexible nonlinear modelling and feature construction to capture complex patterns.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Low-to-medium — predictive performance is primary in many applications, though interpretability is important in risk/regulatory contexts.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Genetic programming, genetic algorithms, particle swarm optimisation, ANFIS with PSO</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>EC used to evolve predictive models (GP trees) or tune hybrid models (e.g., ANFIS with PSO); temporal models evolved or parameters optimised by population-based search.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Supervised learning (time-series regression/classification), symbolic regression</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Applicable — EC can model nonlinear relationships and perform feature/structure search where domain equations are unknown.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Cited studies show EC methods are widely employed and effective for complex temporal financial modelling, though forecasting in dynamic environments remains challenging.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Significant for prediction and risk management, but adoption depends on generalisability and interpretability in regulatory contexts.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>null</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Flexible model representation (GP), capacity to perform feature construction/selection, and ability to handle nonlinearity and noise.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>EC provides flexible nonlinear modelling and automated structure search valuable for noisy, nonstationary financial time series, but success hinges on generalisability and overfitting control.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2326.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2326.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>EC-bio</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Evolutionary computation in bioinformatics and biomedical applications (gene analysis, biomarker ID, protein structure, drug discovery, materials design)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Use of EC (GP, GAs, memetic algorithms, AIS) for gene sequence analysis, biomarker selection, 3D protein structure prediction, and exploration tasks in drug discovery and materials design where search spaces can be extremely large.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>A survey on evolutionary machine learning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Biomedical and materials science (genomics, proteomics, biomarker identification, drug discovery, materials design)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Discover predictive models and functional relationships from high-dimensional biological data (gene expression, PPI), predict 3D protein structures, and search chemical/material spaces for candidate molecules/materials.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Varies — gene expression and PPI datasets can be high-dimensional but moderately sized; drug/materials search spaces are effectively infinite (large/virtual libraries); labelled outcomes available for some supervised tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>High-dimensional tabular data (gene expression), graph/network data (protein interactions), 3D structural data (proteins), combinatorial chemical/material descriptors.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Very high — extremely large search spaces (symbolic regression over combinatorial chemistry), nonlinearity, complex interactions, multi-scale structure (molecular geometry), and computationally expensive evaluations (e.g., structure prediction, simulation).</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Mixed — genomics and protein structure fields are mature with established experimental methods, but computational discovery (drug/material design) remains exploratory and open-ended.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>High — interpretability and mechanistic insight are often required to validate biological findings and guide experimental follow-up.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Genetic programming, genetic algorithms, memetic algorithms, artificial immune systems, differential evolution, evolutionary symbolic regression</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>EC used to evolve interpretable symbolic models (GP/symbolic regression) and feature constructions for biomarker discovery; memetic and hybrid EC methods applied to 3D protein structure prediction; EC applied to search chemical/material spaces for candidate compounds using fitness functions derived from predicted properties.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Supervised learning (classification/regression), symbolic regression, black-box optimisation</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Highly applicable — EC's global search and flexible representations suit problems with huge or poorly-understood search spaces and where interpretability is valuable.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Reported as promising across several tasks (biomarker identification, protein structure prediction, drug/material discovery), with GP symbolic models noted for interpretability and ability to distill novel knowledge.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>High — can accelerate candidate discovery, provide interpretable models for scientific insight, and enable exploration of vast chemical/material spaces previously infeasible by exhaustive search.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Survey references works (e.g., Schmidt & Lipson) where symbolic regression distilled natural laws from data; GP favored for interpretability over black-box DL in some scientific discovery contexts.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Interpretable symbolic representation (GP), parsimony/regularisation to control complexity, multi-objective approaches to balance error and model complexity, and hybridisation with local search or domain-specific evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>EC—especially GP—excels in biomedical and materials discovery when interpretability and global search over enormous, poorly characterized spaces are required, but managing complexity and validation are critical.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2326.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e2326.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>EC-earthquake</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Evolutionary machine learning for earthquake prediction</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Application of EC (GP, ensembles) to seismic indicator analysis and earthquake prediction tasks, often combined with boosting/ensemble classifiers.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>A survey on evolutionary machine learning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Seismology / earthquake prediction</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Predict earthquake occurrence using seismic indicators and sensor data, a noisy and sparsely labeled problem with rare events.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Limited with respect to event rarity — seismic records are abundant but labelled positive events (large quakes) are comparatively scarce; data quality and station coverage vary.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Time series and sensor-derived features; potentially spatial-temporal data.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Very high — rare-event prediction, high noise-to-signal ratio, complex geophysical processes, and uncertain causal mechanisms.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Scientific domain mature, but reliable predictive models for earthquakes remain elusive; computational methods are exploratory.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>High — domain experts require mechanistic plausibility; black-box predictions are insufficient without geophysical justification.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Genetic programming combined with boosting (e.g., AdaBoost)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>GP used to evolve predictive classifiers or feature transformations from seismic indicators, sometimes combined with ensemble boosting methods to improve detection of rare events.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Supervised learning (classification) / ensemble methods</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Applicable as an exploratory tool to find patterns and construct features, but domain validation is necessary due to high stakes and rarity of events.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Described as showing promising results in cited work, but earthquake prediction remains a challenging and uncertain application area.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Potentially large if reliable models could be found, but practical impact currently limited by fundamental limits in predictability and data scarcity.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>null</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Feature construction and ensemble techniques to handle noisy, imbalanced data; GP's flexibility to explore nonlinear indicator combinations.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>EC can aid exploratory modelling in seismology, but the rarity and complexity of earthquakes require cautious interpretation and strong mechanistic validation.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2326.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e2326.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>EC-CV</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Evolutionary computation for computer vision (image segmentation, feature extraction, object detection, classification)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Use of GP, PSO, ACO and related EC methods to automatically design image preprocessing, feature extraction/descriptors, segmentation, edge detection and classification pipelines for vision tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>A survey on evolutionary machine learning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Computer vision (medical imaging, object detection, texture classification, salient object detection)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Automate and optimise tasks such as segmentation, edge detection, feature construction/extraction and image classification, often to reduce human-designed heuristics and improve robustness.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Often abundant (images), but domain-dependent — medical imaging datasets may be smaller and require labels; some tasks (texture descriptors) can use moderate datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Unstructured image data (pixels), possibly high-dimensional; sometimes multi-modal (biomedical + engineered features).</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>High — large feature dimensionality, spatial structure, invariances (rotation/scale), noise and occlusion issues.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Mature field with many expert-designed descriptors and deep learning methods; EC serves to automate and improve descriptors and preprocessing where domain heuristics exist.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Medium — interpretable descriptors and rule-based detectors are valuable, especially in medical contexts where explainability is important.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Genetic programming, particle swarm optimisation, ant colony optimisation, artificial immune systems</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>GP evolves tree-based operators or descriptors (e.g., image filters, LBP-like descriptors) to detect keypoints or construct features; PSO optimises feature weights and thresholds; ACO used for edge detection and template matching.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Supervised learning (classification), unsupervised preprocessing (segmentation), feature construction</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Applicable — EC is effective in automated feature/operator discovery and in domains with limited labeled data where engineered descriptors help, and where interpretability of features matters.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Cited studies report promising and sometimes outperforming results compared to hand-crafted descriptors (e.g., GP-evolved descriptors vs LBP) and standard methods in certain tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Moderate to high — can reduce human effort in feature engineering, yield more robust or invariant descriptors, and improve performance in domain-specific vision tasks (e.g., medical screening).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>GP-based descriptors were compared with manual descriptors (LBP) and reported to design keypoints/features automatically, sometimes achieving better adaptability; PSO and ACO reported improvements for specific tasks like segmentation and edge detection.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Flexible representations (GP trees) to combine operators, capability to evolve invariant features, use of task-specific fitness measures, and combination with local search or GPU acceleration.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>EC is valuable in computer vision for automated feature/operator design and preprocessing, especially where invariances or domain-specific descriptors matter and deep learning is impractical or less interpretable.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2326.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e2326.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>EC-clustering</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Evolutionary computation for clustering and unsupervised learning (fixed and automatic clustering, feature reduction)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Application of GAs, PSO, GP and EMO for both fixed-K clustering and automatic discovery of the number of clusters, often coupled with feature selection/weighting for high-dimensional data.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>A survey on evolutionary machine learning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Unsupervised learning / clustering across domains (text mining, bioinformatics, image partitioning)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Partition unlabeled datasets into meaningful clusters, determine the number of clusters automatically, and select/weight features to improve clustering in high-dimensional settings.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Varies by domain — many datasets available but unlabeled; high-dimensional datasets (e.g., gene expression) common.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Structured/tabular feature vectors, high-dimensional, sometimes spatial/image pixel data.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>High — unknown K in many problems, high dimensionality, feature irrelevance and redundancy, and potential for complex cluster shapes.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Mature field with established methods (k-means, hierarchical), but automatic clustering and feature-aware clustering are active research areas needing robust solutions.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Low-to-medium — interpretability of clusters is useful but not always required; feature selection increases interpretability.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Genetic algorithms, particle swarm optimisation, genetic programming, evolutionary multi-objective optimisation</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>EC encodings represent centroids, labels, or graph structures and evolve partitions; multi-objective formulations balance compactness and separation; feature weighting/selection integrated into the evolutionary process for high-dimensional data.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Unsupervised learning / evolutionary multi-objective optimisation</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Applicable — EC is effective where K is unknown, cluster shapes are irregular, and feature relevance varies across clusters.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Survey reports EC approaches can find good partitions and discover K automatically; joint clustering + feature selection improves performance in high-dimensions.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Moderate — improves clustering quality on complex/high-dimensional datasets and reduces reliance on manual feature selection.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Hybrid GA + k-means approaches balance global and local search and have been shown to outperform naive single-method approaches in cited work.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Flexible encodings (centroid, label, graph), multi-objective fitness to balance competing clustering criteria, and integrating feature selection/weighting.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>EC methods are particularly useful for clustering when the number of clusters is unknown, cluster shapes are complex, or feature relevance varies—feature-aware EC clustering improves results in high-dimensional data.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2326.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e2326.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>EDL</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Evolutionary deep learning (neural-network-based and GP-based approaches)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Use of EC to design neural network architectures, optimize weights, and create GP-based deep representations (deep GP) that can learn layer-wise feature transformations without conventional neural networks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>A survey on evolutionary machine learning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Deep learning model design for image classification and representation learning</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Automatically design or optimise deep network architectures and weights to achieve high performance while controlling resource use and model complexity.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Often large datasets required for supervised DL; unsupervised EUDNN approaches exist for representation learning with varying data requirements.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Images and other high-dimensional feature-rich data suitable for deep architectures.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Very high — extremely large parameter spaces, non-convex optimisation, and computationally expensive evaluations.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Highly mature field (deep learning) with rapidly advancing architecture search; evolutionary approaches are a growing subfield.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Low-to-medium — for many DL applications black-box performance is acceptable, but resource-constrained or safety-critical contexts require interpretability or compact models.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Neural-network based evolutionary architecture search (NN-EDL), genetic programming for deep representations (GP-EDL)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>NN-EDL: EC evolves network architectures (supervised and unsupervised), and may directly or indirectly encode weights; multi-objective approaches optimise accuracy vs computational cost. GP-EDL: GP learns layered representations or forests (autoencoder-like) using tree-based operators to construct hierarchical features.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Neural architecture search / representation learning / supervised/unsupervised learning</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Applicable but computationally expensive — EC can discover novel architectures and compact representations, particularly when combined with resource-aware multi-objective criteria.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Cited works show promising performance (e.g., large-scale evolution of image classifiers) but note computational cost; GP-EDL can achieve deep-like representation learning without NNs in some tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>High for automated architecture search, model compression, and domain-adapted network design; resource-aware EDL can broaden DL usability on constrained devices.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>References to large-scale evolution and other NAS approaches; trade-offs between direct weight encoding and indirect search are discussed.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Multi-objective optimisation for accuracy vs resource use, GPU/TPU acceleration, indirect encoding to reduce search burden, and use of domain-specific operators in GP-EDL.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Evolutionary methods can automate deep model design and balance accuracy-resource trade-offs, but computational cost and scalability remain the main challenges.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2326.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e2326.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>E-transfer</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Evolutionary transfer learning</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Use of EC techniques to transfer learned components (e.g., GP subtrees, parameter distributions) from source problems to improve optimisation or learning on related target tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>A survey on evolutionary machine learning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Transfer learning across optimisation and learning tasks (general ML)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Improve learning/optimisation on a target domain by reusing knowledge (substructures, distributions, parameters) acquired on related source domains to reduce computation and improve performance.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>null</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>null</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Varies — depends on source/target similarity and complexity of transferred structures; dynamic multi-objective problems mentioned.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Emerging within EC — transfer learning is a growing area and EC-specific transfer methods are being explored.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Medium — understanding when/how to transfer is critical to avoid negative transfer.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Transfer of GP subtrees, transfer of parameter/distribution information in DE and other EC methods</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Methods include reusing evolved GP subtrees across domains, transferring probability distributions of solutions to seed population generation, and transferring tuned algorithm parameters to new problems.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Transfer learning / meta-learning within evolutionary computation</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Applicable — particularly effective when source and target are related and when computational cost is high; needs careful selection to avoid negative transfer.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Cited examples report performance improvements and reduced computation when useful knowledge is transferred; research ongoing.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Moderate to high — can substantially reduce computation and improve convergence on related tasks if transfer is well-managed.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>null</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Similarity between source and target, choice of transferable elements (subtrees vs parameters), and mechanisms to prevent negative transfer.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>EC benefits from transfer learning when reusable building blocks or parameter distributions exist across related problems, offering computational savings and faster convergence.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2326.10">
                <h3 class="extraction-instance">Extracted Data Instance 10 (e2326.10)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AutoML-EC</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Automated machine learning using evolutionary computation (e.g., TPOT, Autostacker)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Application of GP and EC to automatically compose ML pipelines (preprocessing, feature engineering, model selection and hyperparameter tuning) to make ML accessible to non-experts.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>A survey on evolutionary machine learning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Automated machine learning (AutoML) across general ML tasks</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Automatically search for and optimise ML pipelines to maximise predictive performance while reducing manual design effort.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>null</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Varies with task — tabular, image, text depending on target pipeline libraries.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>High — combinatorial search over pipeline components and hyperparameters with expensive evaluations (cross-validation).</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Rapidly maturing — tools like Auto-WEKA, Auto-Sklearn and TPOT are established; EC-based AutoML (TPOT) is an active approach.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Low-to-medium — end-users often prioritise performance and ease-of-use; interpretability of pipelines can be beneficial.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Genetic programming pipeline optimisation (TPOT), evolutionary pipeline/hyperparameter search (Autostacker)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>GP evolves program-like pipelines that chain data transformations and estimators; fitness is typically cross-validated predictive performance, optionally multi-objective to include complexity.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>AutoML / supervised learning pipeline optimisation</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Highly applicable — especially useful when users lack ML expertise and when search spaces are complex; computationally intensive due to evaluations.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>TPOT and similar EC AutoML systems have been successful at automating pipeline design and achieving competitive performance with manual tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>High — democratizes ML, reduces need for expert tuning, and can accelerate applied research across scientific domains.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>TPOT (GP-based) is compared conceptually to Auto-WEKA and Auto-Sklearn (non-EC AutoML frameworks); EC offers flexible pipeline structure search.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Flexible tree-based pipeline representation, fitness evaluation using cross-validation, and potential for multi-objective optimisation to control complexity.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>GP-based AutoML is effective at automating complex pipeline search, making ML more accessible, though evaluation cost is the limiting factor.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2326.11">
                <h3 class="extraction-instance">Extracted Data Instance 11 (e2326.11)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>EC-feature</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Evolutionary computation for feature selection and construction</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Use of GAs, PSO and GP for removing irrelevant features, constructing higher-level features, and selecting subsets to improve supervised learning performance on high-dimensional data.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>A survey on evolutionary machine learning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Feature engineering across domains (classification, regression, clustering)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Identify informative features or construct new features to reduce dimensionality and improve model generalisation and runtime.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>High-dimensional datasets common; labelled data for supervised tasks available in many studies but varies by domain.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>High-dimensional tabular data, image features (for construction), gene expression data in bioinformatics.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Very high — exponential number of feature subsets (2^N), interactions between features, and large N in domains like genomics and imaging.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Mature research area with many EC-based methods; ongoing work to scale to very high dimensions.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Medium — interpretability of selected/constructed features is valuable for scientific insight.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Genetic algorithms, particle swarm optimisation (binary/continuous variants), genetic programming for feature construction</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>GAs/PSO represent subsets as binary/continuous encodings and evaluate via wrapper/filter criteria; GP constructs features via tree-structured combinations of original features and operators, with evaluation via filter or wrapper strategies.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Feature engineering (supervised/unsupervised), optimisation</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Highly applicable — EC handles large, multimodal search spaces and feature interactions better than greedy methods.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>EC-based FS/FC frequently improves learning performance and reduces runtime by reducing dimensionality; GP-based feature construction can produce compact, informative features.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>High for improving model generalisation and interpretability in high-dimensional scientific datasets (e.g., genomics, imaging).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>EC methods outperform greedy/heuristic FS in presence of interactions and high dimensionality; continuous PSO shown sometimes superior to binary PSO.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Global search avoiding local optima, implicit handling of feature interactions, hybridisation with local search and filter/wrapper evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Population-based EC methods are effective for feature selection/construction in high-dimensional problems where feature interactions make greedy methods fail.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2326.12">
                <h3 class="extraction-instance">Extracted Data Instance 12 (e2326.12)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>EC-symbolic</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Genetic programming for symbolic regression and interpretable scientific model discovery</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>GP-based symbolic regression evolves interpretable mathematical expressions that explain relationships in data, used for scientific discovery and modelling where interpretability and mechanistic insight matter.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>A survey on evolutionary machine learning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Scientific model discovery and regression across disciplines (physics, biology, chemistry)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Discover closed-form analytical expressions or simple symbolic models that explain observed relationships and can provide scientific insight.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Varies — often requires moderate quantities of high-quality labelled data; some studies derive laws from experimental data.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Tabular/structured datasets of input-output measurements; possibly time series.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>High — search over expression trees of variable structure and size; risk of overfitting; trade-off between fit and complexity.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Emerging but impactful; symbolic regression has demonstrated ability to distil physical laws (e.g., Schmidt & Lipson).</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>High — interpretability is a key objective; parsimonious symbolic forms preferred for scientific utility.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Genetic programming (symbolic regression), geometric semantic GP, parsimony pressure, Tikhonov/VC-based regularisation</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>GP evolves expression trees combining mathematical operators and features; improvements include semantic operators, explicit parsimony pressure and regularisation methods to control complexity and improve generalisation.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Supervised learning / symbolic regression / interpretable ML</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Very applicable for scientific discovery tasks where interpretable functional forms are desired; less suited where only predictive performance is required and data are huge.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>GP has distinct strengths in interpretability and has produced novel insights; controlling complexity and overfitting are ongoing concerns addressed by regularisation and multi-objective approaches.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>High for hypothesis generation and providing mechanistic formulas that can be experimentally tested.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Symbolic GP provides interpretability advantages over black-box DL; regularisation and semantic operators improve generalisation compared to naïve GP.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Parsimony pressure, semantic-aware operators, explicit complexity control (e.g., VC dimension), and validation mechanisms to improve generalisation.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>GP-based symbolic regression uniquely balances interpretability and data-driven discovery, making it powerful for deriving mechanistic hypotheses when controlled for complexity and overfitting.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Discovery and optimization of materials using evolutionary approaches <em>(Rating: 2)</em></li>
                <li>A bright future for evolutionary methods in drug design <em>(Rating: 2)</em></li>
                <li>Evolutionary computation in bioinformatics: A review <em>(Rating: 2)</em></li>
                <li>Large-scale evolution of image classifiers <em>(Rating: 2)</em></li>
                <li>Tpot: a tree-based pipeline optimization tool for automating machine learning <em>(Rating: 2)</em></li>
                <li>Distilling free-form natural laws from experimental data <em>(Rating: 2)</em></li>
                <li>Evolutionary multiobjective algorithms: a survey of the state of the art <em>(Rating: 1)</em></li>
                <li>An evolutionary approach to multiobjective clustering <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2326",
    "paper_id": "paper-164916889",
    "extraction_schema_id": "extraction-schema-63",
    "extracted_data": [
        {
            "name_short": "EC-agriculture",
            "name_full": "Evolutionary computation for agricultural decision making (land use, crop and fish farming)",
            "brief_description": "Use of evolutionary computation (GAs, PSO and related EC methods) to support land-use planning, crop-farming decisions and fish-farming operational decisions by searching large combinatorial policy/parameter spaces and optimising multi-objective trade-offs.",
            "citation_title": "A survey on evolutionary machine learning",
            "mention_or_use": "mention",
            "scientific_problem_domain": "Agriculture (land-use planning, crop farming, fish farming)",
            "problem_description": "Optimise resource allocation and operational decisions in agriculture and aquaculture (e.g., land use allocation, crop planning, fish-farm management) under multiple objectives and uncertain/dynamic constraints.",
            "data_availability": "null",
            "data_structure": "null",
            "problem_complexity": "High — multi-objective combinatorial decision spaces, domain constraints, and dynamic/uncertain environments; potentially large-scale search spaces.",
            "domain_maturity": "Moderately mature — established decision-analytic and optimisation practice exists, but specific applications vary and need domain expertise; EC provides automated search where manual design is costly.",
            "mechanistic_understanding_requirements": "Medium — interpretable policies are useful for adoption by domain experts, but good-performing heuristics/solutions are also acceptable.",
            "ai_methodology_name": "Evolutionary computation (genetic algorithms, particle swarm optimisation, memetic algorithms)",
            "ai_methodology_description": "Population-based global search techniques encode candidate policies/allocations as individuals (e.g., bitstrings or real vectors) and evolve them using crossover/mutation or swarm updates; multi-objective variants return Pareto fronts to reveal trade-offs between objectives such as cost, yield and risk.",
            "ai_methodology_category": "Multi-objective evolutionary optimisation / heuristic search",
            "applicability": "Applicable — EC methods are appropriate given large, constrained, multi-objective search spaces and the need for automated heuristic generation; survey notes successful applications in land use and farm decision problems.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "Reported as effective and promising in many domain studies; EC methods can reduce human effort in heuristic design and find trade-offs between conflicting objectives.",
            "impact_potential": "High potential to reduce planning cost/time and produce practical heuristics for operational decision support; can scale to different farm types and support scenario analysis.",
            "comparison_to_alternatives": "null",
            "success_factors": "Population-based global search that handles multiple objectives and constraints; ability to return diverse Pareto-optimal solutions; reduces need for domain-expert handcrafted heuristics.",
            "key_insight": "EC is well suited for agricultural decision problems with large combinatorial and multi-objective search spaces where automated heuristic generation and Pareto trade-offs are valuable.",
            "uuid": "e2326.0"
        },
        {
            "name_short": "EC-manufacturing",
            "name_full": "Evolutionary computation in manufacturing and supply-chain optimisation",
            "brief_description": "Application of EC (GAs, DE, PSO and hybrids) to production scheduling, resource allocation and transportation routing problems in manufacturing and supply chains (including dairy, wine, wood, mineral processing, seafood).",
            "citation_title": "A survey on evolutionary machine learning",
            "mention_or_use": "mention",
            "scientific_problem_domain": "Manufacturing and supply chain optimisation (dairy, wine, wood, minerals, seafood transport)",
            "problem_description": "Solve scheduling, resource allocation and routing to minimise time/cost and meet operational constraints in dynamic and large-scale manufacturing/supply chain systems.",
            "data_availability": "null",
            "data_structure": "null",
            "problem_complexity": "High — combinatorial optimisation with many constraints, dynamic arrivals, multi-objective trade-offs, and large instance sizes (many items/customers/jobs).",
            "domain_maturity": "Mature in operational research terms, but specific problems often complex and domain-specific requiring heuristic approaches; EC offers automated hyper-heuristic solutions.",
            "mechanistic_understanding_requirements": "Low-to-medium — practical heuristics that perform well are often acceptable, but interpretability of rules can aid deployment in operations.",
            "ai_methodology_name": "Evolutionary hyper-heuristics (genetic programming Hyper-Heuristics, GPHH), genetic algorithms, differential evolution",
            "ai_methodology_description": "EC methods represent heuristics/dispatching rules as individuals (e.g., GP trees or parameter vectors) and evolve them by evaluating performance across training instances; hyper-heuristics produce generalisable rules for dynamic scheduling/routing/bin-packing.",
            "ai_methodology_category": "Reinforcement-like / hyper-heuristic (automated heuristic design)",
            "applicability": "Applicable — well matched to dynamic, real-time scheduling where traditional optimisation is too slow and hand-crafted heuristics are costly to produce.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "Reported successes in evolving dispatching rules and packing heuristics; shown to produce reusable heuristics for dynamic variants of classical problems.",
            "impact_potential": "Substantial — can automate design of online heuristics, reducing human engineering time and enabling real-time decision making in manufacturing and logistics.",
            "comparison_to_alternatives": "Survey notes GPHHs outperform or match traditional heuristics in many studies; hybrid approaches (e.g., GA + k-means for clustering components of problems) are used to balance global/local search.",
            "success_factors": "Encoding heuristics directly (GP) for dynamic invocation, multi-instance training evaluation for robustness, and multi-objective evaluation for trade-offs.",
            "key_insight": "Evolving heuristics via EC is especially effective for dynamic, real-time scheduling and routing problems where traditional static optimisation and manual heuristics fail to adapt quickly.",
            "uuid": "e2326.1"
        },
        {
            "name_short": "EC-energy",
            "name_full": "Evolutionary computation in energy systems (load forecasting and wind farm design)",
            "brief_description": "Use of EC methods (GA, PSO) for forecasting electricity load and optimising wind turbine placement/design to improve energy capture and system planning.",
            "citation_title": "A survey on evolutionary machine learning",
            "mention_or_use": "mention",
            "scientific_problem_domain": "Energy systems (short-term load forecasting, wind farm design)",
            "problem_description": "Predict electrical load time series for operational planning and design wind farm layouts to maximise energy capture while respecting constraints.",
            "data_availability": "null",
            "data_structure": "Time series for load forecasting; spatial/geometric data for wind farm layout.",
            "problem_complexity": "Medium-to-high — temporal dependencies for forecasting; spatially coupled, non-convex placement/design optimisation for wind farm layout.",
            "domain_maturity": "Established domain with mature modelling and forecasting methods; EC provides flexible alternatives for hard nonconvex layout/design problems.",
            "mechanistic_understanding_requirements": "Low-to-medium — forecasting often accepts black-box models if accurate; design optimisation benefits from interpretable constraints but not necessarily mechanistic models.",
            "ai_methodology_name": "Particle swarm optimisation, genetic algorithms, hybrid fuzzy/EC models",
            "ai_methodology_description": "EC techniques used to tune or discover models (e.g., fuzzy neural networks with GA/PSO) for forecasting and to search nonconvex design spaces (e.g., turbine placement) using population-based optimisers.",
            "ai_methodology_category": "Supervised learning (forecasting) and black-box optimisation",
            "applicability": "Applicable — EC handles non-convexity and multimodality in design and can optimise hybrid forecasting models.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "Reported as effective in cited studies, providing promising results for wind turbine placement and load forecasting when combined with appropriate model structures.",
            "impact_potential": "Moderate to high — improvements in forecasting accuracy and layout optimisation can yield operational cost savings and increased energy yield.",
            "comparison_to_alternatives": "null",
            "success_factors": "Ability to search global, multimodal landscapes and tune hybrid models; use of domain-specific fitness evaluations (e.g., energy yield metrics).",
            "key_insight": "EC methods are suitable where models are non-differentiable or design spaces are highly nonconvex, while forecasting benefits from EC when integrating model selection/tuning with optimization.",
            "uuid": "e2326.2"
        },
        {
            "name_short": "EC-finance",
            "name_full": "Evolutionary computation for financial time-series analysis and risk modelling",
            "brief_description": "Application of EC (GP, GA, PSO) to model, forecast and extract trading/credit/bankruptcy signals from temporal financial data.",
            "citation_title": "A survey on evolutionary machine learning",
            "mention_or_use": "mention",
            "scientific_problem_domain": "Finance (time series forecasting, market price prediction, bankruptcy ratio analysis, credit risk)",
            "problem_description": "Model temporal financial series for forecasting and classification tasks (price prediction, risk assessment) under noisy, nonstationary conditions.",
            "data_availability": "null",
            "data_structure": "Time series; tabular financial ratios; high-frequency or low-frequency depending on task.",
            "problem_complexity": "High — temporal non-stationarity, noise, potential nonlinearity, and high-dimensional feature sets in some tasks.",
            "domain_maturity": "Mature with extensive econometric methods; EC offers flexible nonlinear modelling and feature construction to capture complex patterns.",
            "mechanistic_understanding_requirements": "Low-to-medium — predictive performance is primary in many applications, though interpretability is important in risk/regulatory contexts.",
            "ai_methodology_name": "Genetic programming, genetic algorithms, particle swarm optimisation, ANFIS with PSO",
            "ai_methodology_description": "EC used to evolve predictive models (GP trees) or tune hybrid models (e.g., ANFIS with PSO); temporal models evolved or parameters optimised by population-based search.",
            "ai_methodology_category": "Supervised learning (time-series regression/classification), symbolic regression",
            "applicability": "Applicable — EC can model nonlinear relationships and perform feature/structure search where domain equations are unknown.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "Cited studies show EC methods are widely employed and effective for complex temporal financial modelling, though forecasting in dynamic environments remains challenging.",
            "impact_potential": "Significant for prediction and risk management, but adoption depends on generalisability and interpretability in regulatory contexts.",
            "comparison_to_alternatives": "null",
            "success_factors": "Flexible model representation (GP), capacity to perform feature construction/selection, and ability to handle nonlinearity and noise.",
            "key_insight": "EC provides flexible nonlinear modelling and automated structure search valuable for noisy, nonstationary financial time series, but success hinges on generalisability and overfitting control.",
            "uuid": "e2326.3"
        },
        {
            "name_short": "EC-bio",
            "name_full": "Evolutionary computation in bioinformatics and biomedical applications (gene analysis, biomarker ID, protein structure, drug discovery, materials design)",
            "brief_description": "Use of EC (GP, GAs, memetic algorithms, AIS) for gene sequence analysis, biomarker selection, 3D protein structure prediction, and exploration tasks in drug discovery and materials design where search spaces can be extremely large.",
            "citation_title": "A survey on evolutionary machine learning",
            "mention_or_use": "mention",
            "scientific_problem_domain": "Biomedical and materials science (genomics, proteomics, biomarker identification, drug discovery, materials design)",
            "problem_description": "Discover predictive models and functional relationships from high-dimensional biological data (gene expression, PPI), predict 3D protein structures, and search chemical/material spaces for candidate molecules/materials.",
            "data_availability": "Varies — gene expression and PPI datasets can be high-dimensional but moderately sized; drug/materials search spaces are effectively infinite (large/virtual libraries); labelled outcomes available for some supervised tasks.",
            "data_structure": "High-dimensional tabular data (gene expression), graph/network data (protein interactions), 3D structural data (proteins), combinatorial chemical/material descriptors.",
            "problem_complexity": "Very high — extremely large search spaces (symbolic regression over combinatorial chemistry), nonlinearity, complex interactions, multi-scale structure (molecular geometry), and computationally expensive evaluations (e.g., structure prediction, simulation).",
            "domain_maturity": "Mixed — genomics and protein structure fields are mature with established experimental methods, but computational discovery (drug/material design) remains exploratory and open-ended.",
            "mechanistic_understanding_requirements": "High — interpretability and mechanistic insight are often required to validate biological findings and guide experimental follow-up.",
            "ai_methodology_name": "Genetic programming, genetic algorithms, memetic algorithms, artificial immune systems, differential evolution, evolutionary symbolic regression",
            "ai_methodology_description": "EC used to evolve interpretable symbolic models (GP/symbolic regression) and feature constructions for biomarker discovery; memetic and hybrid EC methods applied to 3D protein structure prediction; EC applied to search chemical/material spaces for candidate compounds using fitness functions derived from predicted properties.",
            "ai_methodology_category": "Supervised learning (classification/regression), symbolic regression, black-box optimisation",
            "applicability": "Highly applicable — EC's global search and flexible representations suit problems with huge or poorly-understood search spaces and where interpretability is valuable.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "Reported as promising across several tasks (biomarker identification, protein structure prediction, drug/material discovery), with GP symbolic models noted for interpretability and ability to distill novel knowledge.",
            "impact_potential": "High — can accelerate candidate discovery, provide interpretable models for scientific insight, and enable exploration of vast chemical/material spaces previously infeasible by exhaustive search.",
            "comparison_to_alternatives": "Survey references works (e.g., Schmidt & Lipson) where symbolic regression distilled natural laws from data; GP favored for interpretability over black-box DL in some scientific discovery contexts.",
            "success_factors": "Interpretable symbolic representation (GP), parsimony/regularisation to control complexity, multi-objective approaches to balance error and model complexity, and hybridisation with local search or domain-specific evaluation.",
            "key_insight": "EC—especially GP—excels in biomedical and materials discovery when interpretability and global search over enormous, poorly characterized spaces are required, but managing complexity and validation are critical.",
            "uuid": "e2326.4"
        },
        {
            "name_short": "EC-earthquake",
            "name_full": "Evolutionary machine learning for earthquake prediction",
            "brief_description": "Application of EC (GP, ensembles) to seismic indicator analysis and earthquake prediction tasks, often combined with boosting/ensemble classifiers.",
            "citation_title": "A survey on evolutionary machine learning",
            "mention_or_use": "mention",
            "scientific_problem_domain": "Seismology / earthquake prediction",
            "problem_description": "Predict earthquake occurrence using seismic indicators and sensor data, a noisy and sparsely labeled problem with rare events.",
            "data_availability": "Limited with respect to event rarity — seismic records are abundant but labelled positive events (large quakes) are comparatively scarce; data quality and station coverage vary.",
            "data_structure": "Time series and sensor-derived features; potentially spatial-temporal data.",
            "problem_complexity": "Very high — rare-event prediction, high noise-to-signal ratio, complex geophysical processes, and uncertain causal mechanisms.",
            "domain_maturity": "Scientific domain mature, but reliable predictive models for earthquakes remain elusive; computational methods are exploratory.",
            "mechanistic_understanding_requirements": "High — domain experts require mechanistic plausibility; black-box predictions are insufficient without geophysical justification.",
            "ai_methodology_name": "Genetic programming combined with boosting (e.g., AdaBoost)",
            "ai_methodology_description": "GP used to evolve predictive classifiers or feature transformations from seismic indicators, sometimes combined with ensemble boosting methods to improve detection of rare events.",
            "ai_methodology_category": "Supervised learning (classification) / ensemble methods",
            "applicability": "Applicable as an exploratory tool to find patterns and construct features, but domain validation is necessary due to high stakes and rarity of events.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "Described as showing promising results in cited work, but earthquake prediction remains a challenging and uncertain application area.",
            "impact_potential": "Potentially large if reliable models could be found, but practical impact currently limited by fundamental limits in predictability and data scarcity.",
            "comparison_to_alternatives": "null",
            "success_factors": "Feature construction and ensemble techniques to handle noisy, imbalanced data; GP's flexibility to explore nonlinear indicator combinations.",
            "key_insight": "EC can aid exploratory modelling in seismology, but the rarity and complexity of earthquakes require cautious interpretation and strong mechanistic validation.",
            "uuid": "e2326.5"
        },
        {
            "name_short": "EC-CV",
            "name_full": "Evolutionary computation for computer vision (image segmentation, feature extraction, object detection, classification)",
            "brief_description": "Use of GP, PSO, ACO and related EC methods to automatically design image preprocessing, feature extraction/descriptors, segmentation, edge detection and classification pipelines for vision tasks.",
            "citation_title": "A survey on evolutionary machine learning",
            "mention_or_use": "mention",
            "scientific_problem_domain": "Computer vision (medical imaging, object detection, texture classification, salient object detection)",
            "problem_description": "Automate and optimise tasks such as segmentation, edge detection, feature construction/extraction and image classification, often to reduce human-designed heuristics and improve robustness.",
            "data_availability": "Often abundant (images), but domain-dependent — medical imaging datasets may be smaller and require labels; some tasks (texture descriptors) can use moderate datasets.",
            "data_structure": "Unstructured image data (pixels), possibly high-dimensional; sometimes multi-modal (biomedical + engineered features).",
            "problem_complexity": "High — large feature dimensionality, spatial structure, invariances (rotation/scale), noise and occlusion issues.",
            "domain_maturity": "Mature field with many expert-designed descriptors and deep learning methods; EC serves to automate and improve descriptors and preprocessing where domain heuristics exist.",
            "mechanistic_understanding_requirements": "Medium — interpretable descriptors and rule-based detectors are valuable, especially in medical contexts where explainability is important.",
            "ai_methodology_name": "Genetic programming, particle swarm optimisation, ant colony optimisation, artificial immune systems",
            "ai_methodology_description": "GP evolves tree-based operators or descriptors (e.g., image filters, LBP-like descriptors) to detect keypoints or construct features; PSO optimises feature weights and thresholds; ACO used for edge detection and template matching.",
            "ai_methodology_category": "Supervised learning (classification), unsupervised preprocessing (segmentation), feature construction",
            "applicability": "Applicable — EC is effective in automated feature/operator discovery and in domains with limited labeled data where engineered descriptors help, and where interpretability of features matters.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "Cited studies report promising and sometimes outperforming results compared to hand-crafted descriptors (e.g., GP-evolved descriptors vs LBP) and standard methods in certain tasks.",
            "impact_potential": "Moderate to high — can reduce human effort in feature engineering, yield more robust or invariant descriptors, and improve performance in domain-specific vision tasks (e.g., medical screening).",
            "comparison_to_alternatives": "GP-based descriptors were compared with manual descriptors (LBP) and reported to design keypoints/features automatically, sometimes achieving better adaptability; PSO and ACO reported improvements for specific tasks like segmentation and edge detection.",
            "success_factors": "Flexible representations (GP trees) to combine operators, capability to evolve invariant features, use of task-specific fitness measures, and combination with local search or GPU acceleration.",
            "key_insight": "EC is valuable in computer vision for automated feature/operator design and preprocessing, especially where invariances or domain-specific descriptors matter and deep learning is impractical or less interpretable.",
            "uuid": "e2326.6"
        },
        {
            "name_short": "EC-clustering",
            "name_full": "Evolutionary computation for clustering and unsupervised learning (fixed and automatic clustering, feature reduction)",
            "brief_description": "Application of GAs, PSO, GP and EMO for both fixed-K clustering and automatic discovery of the number of clusters, often coupled with feature selection/weighting for high-dimensional data.",
            "citation_title": "A survey on evolutionary machine learning",
            "mention_or_use": "mention",
            "scientific_problem_domain": "Unsupervised learning / clustering across domains (text mining, bioinformatics, image partitioning)",
            "problem_description": "Partition unlabeled datasets into meaningful clusters, determine the number of clusters automatically, and select/weight features to improve clustering in high-dimensional settings.",
            "data_availability": "Varies by domain — many datasets available but unlabeled; high-dimensional datasets (e.g., gene expression) common.",
            "data_structure": "Structured/tabular feature vectors, high-dimensional, sometimes spatial/image pixel data.",
            "problem_complexity": "High — unknown K in many problems, high dimensionality, feature irrelevance and redundancy, and potential for complex cluster shapes.",
            "domain_maturity": "Mature field with established methods (k-means, hierarchical), but automatic clustering and feature-aware clustering are active research areas needing robust solutions.",
            "mechanistic_understanding_requirements": "Low-to-medium — interpretability of clusters is useful but not always required; feature selection increases interpretability.",
            "ai_methodology_name": "Genetic algorithms, particle swarm optimisation, genetic programming, evolutionary multi-objective optimisation",
            "ai_methodology_description": "EC encodings represent centroids, labels, or graph structures and evolve partitions; multi-objective formulations balance compactness and separation; feature weighting/selection integrated into the evolutionary process for high-dimensional data.",
            "ai_methodology_category": "Unsupervised learning / evolutionary multi-objective optimisation",
            "applicability": "Applicable — EC is effective where K is unknown, cluster shapes are irregular, and feature relevance varies across clusters.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "Survey reports EC approaches can find good partitions and discover K automatically; joint clustering + feature selection improves performance in high-dimensions.",
            "impact_potential": "Moderate — improves clustering quality on complex/high-dimensional datasets and reduces reliance on manual feature selection.",
            "comparison_to_alternatives": "Hybrid GA + k-means approaches balance global and local search and have been shown to outperform naive single-method approaches in cited work.",
            "success_factors": "Flexible encodings (centroid, label, graph), multi-objective fitness to balance competing clustering criteria, and integrating feature selection/weighting.",
            "key_insight": "EC methods are particularly useful for clustering when the number of clusters is unknown, cluster shapes are complex, or feature relevance varies—feature-aware EC clustering improves results in high-dimensional data.",
            "uuid": "e2326.7"
        },
        {
            "name_short": "EDL",
            "name_full": "Evolutionary deep learning (neural-network-based and GP-based approaches)",
            "brief_description": "Use of EC to design neural network architectures, optimize weights, and create GP-based deep representations (deep GP) that can learn layer-wise feature transformations without conventional neural networks.",
            "citation_title": "A survey on evolutionary machine learning",
            "mention_or_use": "mention",
            "scientific_problem_domain": "Deep learning model design for image classification and representation learning",
            "problem_description": "Automatically design or optimise deep network architectures and weights to achieve high performance while controlling resource use and model complexity.",
            "data_availability": "Often large datasets required for supervised DL; unsupervised EUDNN approaches exist for representation learning with varying data requirements.",
            "data_structure": "Images and other high-dimensional feature-rich data suitable for deep architectures.",
            "problem_complexity": "Very high — extremely large parameter spaces, non-convex optimisation, and computationally expensive evaluations.",
            "domain_maturity": "Highly mature field (deep learning) with rapidly advancing architecture search; evolutionary approaches are a growing subfield.",
            "mechanistic_understanding_requirements": "Low-to-medium — for many DL applications black-box performance is acceptable, but resource-constrained or safety-critical contexts require interpretability or compact models.",
            "ai_methodology_name": "Neural-network based evolutionary architecture search (NN-EDL), genetic programming for deep representations (GP-EDL)",
            "ai_methodology_description": "NN-EDL: EC evolves network architectures (supervised and unsupervised), and may directly or indirectly encode weights; multi-objective approaches optimise accuracy vs computational cost. GP-EDL: GP learns layered representations or forests (autoencoder-like) using tree-based operators to construct hierarchical features.",
            "ai_methodology_category": "Neural architecture search / representation learning / supervised/unsupervised learning",
            "applicability": "Applicable but computationally expensive — EC can discover novel architectures and compact representations, particularly when combined with resource-aware multi-objective criteria.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "Cited works show promising performance (e.g., large-scale evolution of image classifiers) but note computational cost; GP-EDL can achieve deep-like representation learning without NNs in some tasks.",
            "impact_potential": "High for automated architecture search, model compression, and domain-adapted network design; resource-aware EDL can broaden DL usability on constrained devices.",
            "comparison_to_alternatives": "References to large-scale evolution and other NAS approaches; trade-offs between direct weight encoding and indirect search are discussed.",
            "success_factors": "Multi-objective optimisation for accuracy vs resource use, GPU/TPU acceleration, indirect encoding to reduce search burden, and use of domain-specific operators in GP-EDL.",
            "key_insight": "Evolutionary methods can automate deep model design and balance accuracy-resource trade-offs, but computational cost and scalability remain the main challenges.",
            "uuid": "e2326.8"
        },
        {
            "name_short": "E-transfer",
            "name_full": "Evolutionary transfer learning",
            "brief_description": "Use of EC techniques to transfer learned components (e.g., GP subtrees, parameter distributions) from source problems to improve optimisation or learning on related target tasks.",
            "citation_title": "A survey on evolutionary machine learning",
            "mention_or_use": "mention",
            "scientific_problem_domain": "Transfer learning across optimisation and learning tasks (general ML)",
            "problem_description": "Improve learning/optimisation on a target domain by reusing knowledge (substructures, distributions, parameters) acquired on related source domains to reduce computation and improve performance.",
            "data_availability": "null",
            "data_structure": "null",
            "problem_complexity": "Varies — depends on source/target similarity and complexity of transferred structures; dynamic multi-objective problems mentioned.",
            "domain_maturity": "Emerging within EC — transfer learning is a growing area and EC-specific transfer methods are being explored.",
            "mechanistic_understanding_requirements": "Medium — understanding when/how to transfer is critical to avoid negative transfer.",
            "ai_methodology_name": "Transfer of GP subtrees, transfer of parameter/distribution information in DE and other EC methods",
            "ai_methodology_description": "Methods include reusing evolved GP subtrees across domains, transferring probability distributions of solutions to seed population generation, and transferring tuned algorithm parameters to new problems.",
            "ai_methodology_category": "Transfer learning / meta-learning within evolutionary computation",
            "applicability": "Applicable — particularly effective when source and target are related and when computational cost is high; needs careful selection to avoid negative transfer.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "Cited examples report performance improvements and reduced computation when useful knowledge is transferred; research ongoing.",
            "impact_potential": "Moderate to high — can substantially reduce computation and improve convergence on related tasks if transfer is well-managed.",
            "comparison_to_alternatives": "null",
            "success_factors": "Similarity between source and target, choice of transferable elements (subtrees vs parameters), and mechanisms to prevent negative transfer.",
            "key_insight": "EC benefits from transfer learning when reusable building blocks or parameter distributions exist across related problems, offering computational savings and faster convergence.",
            "uuid": "e2326.9"
        },
        {
            "name_short": "AutoML-EC",
            "name_full": "Automated machine learning using evolutionary computation (e.g., TPOT, Autostacker)",
            "brief_description": "Application of GP and EC to automatically compose ML pipelines (preprocessing, feature engineering, model selection and hyperparameter tuning) to make ML accessible to non-experts.",
            "citation_title": "A survey on evolutionary machine learning",
            "mention_or_use": "mention",
            "scientific_problem_domain": "Automated machine learning (AutoML) across general ML tasks",
            "problem_description": "Automatically search for and optimise ML pipelines to maximise predictive performance while reducing manual design effort.",
            "data_availability": "null",
            "data_structure": "Varies with task — tabular, image, text depending on target pipeline libraries.",
            "problem_complexity": "High — combinatorial search over pipeline components and hyperparameters with expensive evaluations (cross-validation).",
            "domain_maturity": "Rapidly maturing — tools like Auto-WEKA, Auto-Sklearn and TPOT are established; EC-based AutoML (TPOT) is an active approach.",
            "mechanistic_understanding_requirements": "Low-to-medium — end-users often prioritise performance and ease-of-use; interpretability of pipelines can be beneficial.",
            "ai_methodology_name": "Genetic programming pipeline optimisation (TPOT), evolutionary pipeline/hyperparameter search (Autostacker)",
            "ai_methodology_description": "GP evolves program-like pipelines that chain data transformations and estimators; fitness is typically cross-validated predictive performance, optionally multi-objective to include complexity.",
            "ai_methodology_category": "AutoML / supervised learning pipeline optimisation",
            "applicability": "Highly applicable — especially useful when users lack ML expertise and when search spaces are complex; computationally intensive due to evaluations.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "TPOT and similar EC AutoML systems have been successful at automating pipeline design and achieving competitive performance with manual tuning.",
            "impact_potential": "High — democratizes ML, reduces need for expert tuning, and can accelerate applied research across scientific domains.",
            "comparison_to_alternatives": "TPOT (GP-based) is compared conceptually to Auto-WEKA and Auto-Sklearn (non-EC AutoML frameworks); EC offers flexible pipeline structure search.",
            "success_factors": "Flexible tree-based pipeline representation, fitness evaluation using cross-validation, and potential for multi-objective optimisation to control complexity.",
            "key_insight": "GP-based AutoML is effective at automating complex pipeline search, making ML more accessible, though evaluation cost is the limiting factor.",
            "uuid": "e2326.10"
        },
        {
            "name_short": "EC-feature",
            "name_full": "Evolutionary computation for feature selection and construction",
            "brief_description": "Use of GAs, PSO and GP for removing irrelevant features, constructing higher-level features, and selecting subsets to improve supervised learning performance on high-dimensional data.",
            "citation_title": "A survey on evolutionary machine learning",
            "mention_or_use": "mention",
            "scientific_problem_domain": "Feature engineering across domains (classification, regression, clustering)",
            "problem_description": "Identify informative features or construct new features to reduce dimensionality and improve model generalisation and runtime.",
            "data_availability": "High-dimensional datasets common; labelled data for supervised tasks available in many studies but varies by domain.",
            "data_structure": "High-dimensional tabular data, image features (for construction), gene expression data in bioinformatics.",
            "problem_complexity": "Very high — exponential number of feature subsets (2^N), interactions between features, and large N in domains like genomics and imaging.",
            "domain_maturity": "Mature research area with many EC-based methods; ongoing work to scale to very high dimensions.",
            "mechanistic_understanding_requirements": "Medium — interpretability of selected/constructed features is valuable for scientific insight.",
            "ai_methodology_name": "Genetic algorithms, particle swarm optimisation (binary/continuous variants), genetic programming for feature construction",
            "ai_methodology_description": "GAs/PSO represent subsets as binary/continuous encodings and evaluate via wrapper/filter criteria; GP constructs features via tree-structured combinations of original features and operators, with evaluation via filter or wrapper strategies.",
            "ai_methodology_category": "Feature engineering (supervised/unsupervised), optimisation",
            "applicability": "Highly applicable — EC handles large, multimodal search spaces and feature interactions better than greedy methods.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "EC-based FS/FC frequently improves learning performance and reduces runtime by reducing dimensionality; GP-based feature construction can produce compact, informative features.",
            "impact_potential": "High for improving model generalisation and interpretability in high-dimensional scientific datasets (e.g., genomics, imaging).",
            "comparison_to_alternatives": "EC methods outperform greedy/heuristic FS in presence of interactions and high dimensionality; continuous PSO shown sometimes superior to binary PSO.",
            "success_factors": "Global search avoiding local optima, implicit handling of feature interactions, hybridisation with local search and filter/wrapper evaluation.",
            "key_insight": "Population-based EC methods are effective for feature selection/construction in high-dimensional problems where feature interactions make greedy methods fail.",
            "uuid": "e2326.11"
        },
        {
            "name_short": "EC-symbolic",
            "name_full": "Genetic programming for symbolic regression and interpretable scientific model discovery",
            "brief_description": "GP-based symbolic regression evolves interpretable mathematical expressions that explain relationships in data, used for scientific discovery and modelling where interpretability and mechanistic insight matter.",
            "citation_title": "A survey on evolutionary machine learning",
            "mention_or_use": "mention",
            "scientific_problem_domain": "Scientific model discovery and regression across disciplines (physics, biology, chemistry)",
            "problem_description": "Discover closed-form analytical expressions or simple symbolic models that explain observed relationships and can provide scientific insight.",
            "data_availability": "Varies — often requires moderate quantities of high-quality labelled data; some studies derive laws from experimental data.",
            "data_structure": "Tabular/structured datasets of input-output measurements; possibly time series.",
            "problem_complexity": "High — search over expression trees of variable structure and size; risk of overfitting; trade-off between fit and complexity.",
            "domain_maturity": "Emerging but impactful; symbolic regression has demonstrated ability to distil physical laws (e.g., Schmidt & Lipson).",
            "mechanistic_understanding_requirements": "High — interpretability is a key objective; parsimonious symbolic forms preferred for scientific utility.",
            "ai_methodology_name": "Genetic programming (symbolic regression), geometric semantic GP, parsimony pressure, Tikhonov/VC-based regularisation",
            "ai_methodology_description": "GP evolves expression trees combining mathematical operators and features; improvements include semantic operators, explicit parsimony pressure and regularisation methods to control complexity and improve generalisation.",
            "ai_methodology_category": "Supervised learning / symbolic regression / interpretable ML",
            "applicability": "Very applicable for scientific discovery tasks where interpretable functional forms are desired; less suited where only predictive performance is required and data are huge.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "GP has distinct strengths in interpretability and has produced novel insights; controlling complexity and overfitting are ongoing concerns addressed by regularisation and multi-objective approaches.",
            "impact_potential": "High for hypothesis generation and providing mechanistic formulas that can be experimentally tested.",
            "comparison_to_alternatives": "Symbolic GP provides interpretability advantages over black-box DL; regularisation and semantic operators improve generalisation compared to naïve GP.",
            "success_factors": "Parsimony pressure, semantic-aware operators, explicit complexity control (e.g., VC dimension), and validation mechanisms to improve generalisation.",
            "key_insight": "GP-based symbolic regression uniquely balances interpretability and data-driven discovery, making it powerful for deriving mechanistic hypotheses when controlled for complexity and overfitting.",
            "uuid": "e2326.12"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Discovery and optimization of materials using evolutionary approaches",
            "rating": 2,
            "sanitized_title": "discovery_and_optimization_of_materials_using_evolutionary_approaches"
        },
        {
            "paper_title": "A bright future for evolutionary methods in drug design",
            "rating": 2,
            "sanitized_title": "a_bright_future_for_evolutionary_methods_in_drug_design"
        },
        {
            "paper_title": "Evolutionary computation in bioinformatics: A review",
            "rating": 2,
            "sanitized_title": "evolutionary_computation_in_bioinformatics_a_review"
        },
        {
            "paper_title": "Large-scale evolution of image classifiers",
            "rating": 2,
            "sanitized_title": "largescale_evolution_of_image_classifiers"
        },
        {
            "paper_title": "Tpot: a tree-based pipeline optimization tool for automating machine learning",
            "rating": 2,
            "sanitized_title": "tpot_a_treebased_pipeline_optimization_tool_for_automating_machine_learning"
        },
        {
            "paper_title": "Distilling free-form natural laws from experimental data",
            "rating": 2,
            "sanitized_title": "distilling_freeform_natural_laws_from_experimental_data"
        },
        {
            "paper_title": "Evolutionary multiobjective algorithms: a survey of the state of the art",
            "rating": 1,
            "sanitized_title": "evolutionary_multiobjective_algorithms_a_survey_of_the_state_of_the_art"
        },
        {
            "paper_title": "An evolutionary approach to multiobjective clustering",
            "rating": 1,
            "sanitized_title": "an_evolutionary_approach_to_multiobjective_clustering"
        }
    ],
    "cost": 0.025845,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>A survey on evolutionary machine learning</p>
<p>Harith Al-Sahaf 
School of Engineering and Computer Science
Victoria University of Wellington
WellingtonNew Zealand</p>
<p>Ying Bi 
School of Engineering and Computer Science
Victoria University of Wellington
WellingtonNew Zealand</p>
<p>Qi Chen 
School of Engineering and Computer Science
Victoria University of Wellington
WellingtonNew Zealand</p>
<p>Andrew Lensen 
School of Engineering and Computer Science
Victoria University of Wellington
WellingtonNew Zealand</p>
<p>Yi Mei 
School of Engineering and Computer Science
Victoria University of Wellington
WellingtonNew Zealand</p>
<p>Yanan Sun 
School of Engineering and Computer Science
Victoria University of Wellington
WellingtonNew Zealand</p>
<p>Binh Tran 
School of Engineering and Computer Science
Victoria University of Wellington
WellingtonNew Zealand</p>
<p>Bing Xue 
School of Engineering and Computer Science
Victoria University of Wellington
WellingtonNew Zealand</p>
<p>Mengjie Zhang 
School of Engineering and Computer Science
Victoria University of Wellington
WellingtonNew Zealand</p>
<p>A survey on evolutionary machine learning
10.1080/03036758.2019.1609052Received 30 September 2018 Accepted 15 April 2019REVIEW ARTICLEArtificial intelligencemachine learningevolutionary computationclassificationregressionclusteringcombinatorial optimisationdeep learningtransfer learningensemble learning
Artificial intelligence (AI) emphasises the creation of intelligent machines/systems that function like humans. AI has been applied to many real-world applications. Machine learning is a branch of AI based on the idea that systems can learn from data, identify hidden patterns, and make decisions with little/minimal human intervention. Evolutionary computation is an umbrella of population-based intelligent/learning algorithms inspired by nature, where New Zealand has a good international reputation. This paper provides a review on evolutionary machine learning, i.e. evolutionary computation techniques for major machine learning tasks such as classification, regression and clustering, and emerging topics including combinatorial optimisation, computer vision, deep learning, transfer learning, and ensemble learning. The paper also provides a brief review of evolutionary learning applications, such as supply chain and manufacturing for milk/ dairy, wine and seafood industries, which are important to New Zealand. Finally, the paper presents current issues with future perspectives in evolutionary machine learning.ARTICLE HISTORY</p>
<p>Introduction</p>
<p>Artificial intelligence (AI) is a broad umbrella covering a wide range of techniques for building systems that can simulate human intelligence including thinking, behaviours, perception in computers. Although AI was first coined in the 1950s, its applications have flourished in just the last several decades within its core sub-area of machine learning (ML), where computers exhibit the ability to automatically learn and improve without being explicitly programmed.</p>
<p>ML has been applied to many applications in different domains, such as in manufacturing industry, finance, and biomedical problems. Its main tasks include classification, regression, and clustering. The first two tasks are supervised learning in which a model is learnt from a set of labelled data, while the last is unsupervised learning that does not have labelled data. Classification is a task where each example/instance is classified into one of the predefined categories, whereas regression predict numeric outputs for instances. However, both aim to build a model that can correctly predict the output of an unseen instance by observing a set of labelled instances. On the other hand, clustering algorithms aim to learn a model that can group instances into separate clusters based on the intrinsic characteristics of the unlabelled data. Solving scheduling and combinatorial optimisation problems such as determining product delivery routes and flight scheduling, as well as analysing patterns and recognising objects in computer vision are also important research areas in ML.</p>
<p>Although these ML tasks have been studied for decades, challenges still arise when massive datasets are collected due to advanced technologies and a rapidly growing user market. Firstly, the number of features has increased over time in different domains such as images, gene expression, text, and web mining . The search space of recent ML tasks continues to rise. This space may be 'infinite' in some domains such as materials design and drug discovery (Le and Winkler 2016). Secondly, more and more complex applications need to be solved without domain expertise. Therefore, more powerful search techniques are needed to find better solutions. Evolutionary computation (EC) is a sub-field of AI that contains a family of nature-inspired algorithms. These are population-based algorithms, which maintain a population of candidate solutions (individuals) and evolve towards good/optimal solutions. By evolving multiple solutions simultaneously, EC techniques are well known for their good global search ability.</p>
<p>EC techniques can be broadly divided into two main categories: evolutionary algorithms and swarm intelligence (Bäck et al. 1997). Evolutionary algorithms apply Darwinian natural selection principles to search for optimal solutions. Genetic algorithms (GAs) and genetic programming (GP) are widely-used algorithms in this category. Both methods use genetic operators such as crossover and mutation to evolve new individuals. While GAs use a fixed-length bit string representation, GP can work with more flexible structures such as trees and graphs with variable sizes. In contrast, swarm intelligence techniques are inspired by the social behaviours of animals. Typical techniques of this branch are particle swarm optimisation (PSO) and ant colony optimisation (ACO), which mimic birds and ants, respectively. While PSO uses information about the best-found solutions shared among particles to guide the search towards more fruitful areas, ACO works by simulating a communication system based on pheromones between ants about favourable paths to food. There are also other popular EC algorithms such as differential evolution (DE), learning classifier systems (LCS), artificial immune systems (AIS), and artificial bee colony (ABC) algorithms (Bäck et al. 1997).</p>
<p>With the ability to evolve multiple solutions simultaneously, EC techniques have shown significant promise in solving multi-objective problems where optimal solutions need to be considered in the presence of two or more conflicting objectives, e.g. minimising both cost and travel time in flight bookings. Because it is unlikely to have an optimal solution that satisfies both conflicting objectives, a multi-objective method returns a set of nondominated (Pareto optimal) solutions that cannot be improved in one objective without another objective suffering (Zhou et al. 2011). Evolutionary multi-objective optimisation (EMO) is one of the most-studied EC topics recently, with a dramatic increase in publications over the last ten years.</p>
<p>Although a number of surveys exist on the use of EC for machine learning tasks (EML), they focus on a particular task/aspect such as feature selection , classification using GP (Espejo et al. 2010), a particular EC technique (Neri and Tirronen 2010), technical orientation such as EC and ML ), or EMO (Zhou et al. 2011. There is no survey that covers EML techniques for different tasks with a non-technical presentation for a broader range of readers. Given the rapid development and growth of this field and its role in facilitating more ML applications, this paper aims to provide a comprehensive survey on using EC techniques for major ML tasks. The remainder of this section briefly summarises the current EML applications in different domains.</p>
<p>Current evolutionary machine learning applications</p>
<p>EML methods have been widely applied to real-world problems in various fields, including agriculture, manufacturing, power and energy, internet/wifi/networking, finance, and healthcare.</p>
<p>In agriculture, EML techniques are used to plan land use (Kaim et al. 2018). The decision making in crop farming ) and fishing (Cobo et al. 2018) have also been addressed by EML.</p>
<p>EML techniques have been widely applied to manufacturing in different industries such as dairy production (Notte et al. 2016), wine production (Mohais et al. 2012), wood production (Zhao et al. 2017), mineral processing (Yu et al. 2011), and transportation scheduling for seafood and milk products (Sethanan and Pitakaso 2016). EML methods can find solutions that help to reduce time and cost for both production and transportation. Supply chain optimisation has been performed using EML methods to reduce held inventory and cost in supply chains of different industries such as food (Cheraghalipour et al. 2018) and fisheries (Tabrizi et al. 2018).</p>
<p>EML techniques have been applied to the energy industry, including load forecasting in power systems (Liao and Tsao 2006) and wind farm design (Hou et al. 2015).</p>
<p>Finance is another important application area of EML. Financial data are often time series data, which are difficult to analyse due to their temporal nature. EML methods have been widely employed for financial data analysis (Wagner et al. 2007), market price prediction (Bagheri et al. 2014), bankrupt ratio analysis (Lakshmi et al. 2016), and credit risk management (Srinivasan and Kamalakannan 2018).</p>
<p>In healthcare and biomedical applications, EML techniques are used for gene sequence analysis, gene mapping, structure prediction and analysis of DNA (Pal et al. 2006), and biomarker identification (Ahmed et al. 2014). Computation of 3D protein structure has been addressed by many EML methods (Correa et al. 2018). EML also shows promising results in important applications such as drug discovery (Le and Winkler 2015) and materials design (Le and Winkler 2016), where the search space is effectively infinite.</p>
<p>In addition, EML techniques have been applied to earthquake prediction (Asim et al. 2018), web service composition (da Silva et al. 2016), cloud computing (Guzek et al. 2015), cyber security (Buczak and Guven 2016), and video games (Yannakakis and Togelius 2018). Readers are referred to (Chiong et al. 2012) for more EML real-world applications.</p>
<p>Organisation</p>
<p>This survey is presented mainly in a task-based manner. The first three sections present EML algorithms for classification, regression, and clustering tasks. Sections 5 and 6 discuss two large EML application areas: computer vision, and scheduling and computational optimisation, respectively. Section 7 is dedicated to evolutionary deep learning, a hot topic in ML. Emerging topics and current issues/challenges are described in Section 8. Section 9 concludes this paper. Due to the page limit, we cite only representative works. Figure 1 shows the taxonomy and structure of the paper.</p>
<p>Evolutionary computation for classification</p>
<p>EML techniques have been widely used for classification. The aim of classification algorithms is to learn a model/classifier that can correctly classify unseen instances (test data) by observing a set of given instances (training data). Each instance is represented by a set of attributes/ variables/features, and a label. The quantity, quality, and representation of the data are important factors influencing the performance of the learned classifiers (Tran et al. 2016b).</p>
<p>Although classifier construction is the main task in classification, some other tasks related to data preprocessing are also crucial. The existence of irrelevant and redundant features negatively affects the performance of learning algorithms. Therefore, feature selection/dimensionality reduction is widely used to remove irrelevant and redundant features, which effectively reduces the search space of a problem and hence improves the learning ability and running time. Feature construction is typically used to create high-level features that can better represent the problem.</p>
<p>The following subsections discuss the main EML techniques that have been proposed for these tasks and related tasks such as unbalanced or missing data.</p>
<p>EC for classifier construction</p>
<p>Many EML techniques are used for classification such as GAs, GP, and PSO. GAs were the earliest EC technique used to evolve classification rules. Many methods have been proposed for general classification problems (Vivekanandan et al. 2013) as well as for specific domains such as text classification (Khaleel et al. 2016) and medical diagnosis (Fidelis et al. 2000). Chernbumroong et al. (2015) proposed a GA-based method for activity classification using data from multiple sensors to recognise a person's activity. Using a similar vector representation to GAs, PSO has also been proposed for rule induction (Zheng et al. 2014). PSO has been shown to be more flexible than GAs and other classification algorithms.</p>
<p>Unlike PSO and GAs where individuals are represented using vectors, GP has more flexible representations. Discriminant functions are a form of mathematical expression that classify an instance into a class based on different thresholds (Espejo et al. 2010). With a tree-based representation, GP is well suited to developing discriminant functions (Nag and Pal 2016). GP also has a long history in evolving decision trees (Zhao 2007) which are more effective than traditional approaches. GP is also used in inducing classification rules (Luna et al. 2014) which are more representative and use fewer conditions. Rivero et al. (2010) developed a GP-based method to automatically evolve artificial neural networks. LCS are also strong at evolving rules, having been applied in boolean function/classifier learning for multiplexer and even-parity problems (Iqbal et al. 2014).</p>
<p>In addition to evolving classifiers, GP can also deal with common problems in classification. Bhowan et al. (2014) proposed a GP-based classification method that can effectively cope with unbalanced data: a common problem where the number of instances in one class is much smaller than in other class(es), e.g. malignant traffic is infrequent compared to normal traffic in network intrusion detection. Missing data is another common problem in real-world applications, which negatively affects the learning performance or makes some classification algorithms unusable. Tran et al. (2018b) developed a GP-based imputation method that can effectively impute/predict missing values based on the other features.</p>
<p>Instance selection is used to reduce learning time by selecting a good subset of instances that give maximum classification performance. EC techniques have been used for this task (Derrac et al. 2010).</p>
<p>By using a population-based search, EML techniques can evolve better classifiers than using greedy search methods, which use a heuristic for making locally optimal choices in classifier construction. Readers are referred to (Espejo et al. 2010) for further information.</p>
<p>EC for feature selection</p>
<p>Feature selection (FS) is a complex problem. With N original features, there are 2 N different feature subsets, which is impractical for exhaustive search on high-dimensional datasets (with thousands or more features). FS is challenging due to the large search space and possible interactions between features, which makes traditional greedy search prone to local optima. Many non-EC FS methods have been proposed, however, these tend to be limited by these issues. EC techniques are effective at FS as they search globally and can evaluate the whole feature subset while considering possible interactions between features.</p>
<p>GAs were the first EC technique widely applied to FS. GAs use an N-dimension binary vector to represent a feature subset where '1' means the corresponding feature is selected and '0' means it is not (Zhu et al. 2010). Many strategies have been proposed to improve GAs' performance such as improving the crossover and mutation operators (Jeong et al. 2015), enhancing the initial population (Oreski and Oreski 2014) and using different feature subset evaluation methods (Xue et al. 2012) to better guide the search during the evolutionary process.</p>
<p>Although PSO was proposed much later than GAs, a larger number of PSO-based FS methods have been developed during the last decade ). To represent a feature subset, PSO can use bit-strings (binary PSO) as GAs or continuous vectors (continuous PSO) where a threshold is used to determine if the corresponding feature is selected. Although binary PSO naturally suits FS, Engelbrecht (2007) observed limitations leading to inferior performance compared to continuous PSO. Researchers continue to improve PSO's performance for FS in a number of ways including initialisation strategies , representation (Tran et al. 2018a), updating mechanisms (Gu et al. 2018), integrating local search (Tran et al. 2016a), and evaluating features based on their intrinsic characteristics (aka filter approach)  or performance of learning algorithms (aka wrapper approach) .</p>
<p>Thanks to the implicit FS process in building GP trees, GP has been proposed for FS implicitly or explicitly. Implicit FS happens in all GP-based classification algorithms (Nag and Pal 2016). Explicit FS methods using GP have also been proposed for feature subset selection (Sandin et al. 2012), feature subset ranking (Neshatian and Zhang 2009a), and feature space exploration (Neshatian and Zhang 2009b). More information about FS using EC can be found in .</p>
<p>EC for feature construction</p>
<p>Feature construction (FC) is another technique used to enhance the representation of the feature space. FC combines the original features to construct new high-level features with better discriminating ability. The created features are used to augment the original ones (Muharram and Smith 2005) or replace them as a dimensionality reduction solution .</p>
<p>Compared with FS, FC is more challenging due to a larger search space as it must choose not only a good subset of features but also an appropriate set of operators to combine them. The optimal model to combine the original features is unknown in practice. With a flexible representation, GP can automatically evolve models without assuming any model structure. Constructed features can be represented with tree-based GP, where leaf nodes are features/constants and internal nodes are operators.</p>
<p>Many GP-based FC methods have been proposed using single-tree  or multiple-tree representations (Tran et al. 2017). GP is used to construct features that are generally good for all classes (class-independent) (Krawiec 2002) or for a specific class (class-dependent) . Different approaches are also used to evaluate the constructed features during the evolutionary process such as filter (Tran et al. 2017), wrapper (Smith and Bull 2005), or a combination (Tran et al. 2016b).</p>
<p>In addition to GP, GAs (Alfred 2008) and PSO (Dai et al. 2014) have also been proposed and shown promise for FC.</p>
<p>Evolutionary computation for regression</p>
<p>Regression is a major ML task that attempts to identify and express the underlying relationship between input features/variables and the target variable(s). Regression analysis is utilised for forecasting in widespread areas, such as finance, traffic, medicine, and biology (Glaeser and Nathanson 2017). To build a regression model, two main tasks need to be solved: model identification and parameter estimation. Many EC techniques have been proposed for these two tasks.</p>
<p>EC for regression tasks</p>
<p>Model identification</p>
<p>Paterlini and Minerva (2010) developed a new GA method which not only selects the input features but also determines the most appropriate mathematical transformations on these features. A multi-objective GA method (Sinha et al. 2015) was proposed to identify regression models with a good balance between empirical error and model complexity. An evolutionary algorithm was proposed for fuzzy regression by choosing the best fuzzy function within a predefined library (Buckley and Feuring 2000). PSO was used to generate the structures of fuzzy models in a nonlinear polynomial form (Chan et al. 2011).</p>
<p>Parameter estimation A large number of EC methods have been proposed for parameter estimation for complicated or non-differentiable regression models. A GA method (Zhou and Wang 2005) was used for least-squares estimation of parameters in linear regression models. A GA with seven different crossover operators for parameter estimation has been proposed (Kapanoglu et al. 2007). The convergence of the GA method was explored by analysing the convergence of parameters in regression models with different levels of difficulty. Chen et al. (2010) employed PSO to optimise the parameters for orthogonal forward regression.</p>
<p>EC for symbolic regression</p>
<p>Some EC techniques for regression are able to learn directly from the data and evolve both the structure and parameters of the regression models simultaneously. This task is known as symbolic regression. The distinguishing characteristic of symbolic regression is its interpretability, which can provide domain experts with meaningful insight into the underlying data generating process and highlight the most relevant features.</p>
<p>The symbolic nature of GP solutions and its flexible representation make GP a very suitable approach for symbolic regression (Vyas et al. 2018).</p>
<p>Interpretability is a distinct property of symbolic models, with which the models are able to distil novel knowledge (Schmidt and Lipson 2009). Many studies have improved the interpretability of models evolved by GP. A typical approach is introducing parsimony pressure into GP, which considers the size of the solutions in their fitness evaluation. Parsimony pressure was added to the fitness function as an adaptive penalty based on growth metrics in individuals and the population (Poli and McPhee 2008). A new FS method based on a permutating test was developed, producing GP regression models with good interpretability .</p>
<p>Prediction/generalisation ability is another important metric for regression techniques. The validation set, which is the most widespread mechanism for improving generalisability in ML, is also used for symbolic regression (Schmidt and Lipson 2009). Geometric semantic GP, which drives the search in GP using the semantic information, has been shown to have good prediction performance (Chen et al. 2018b).</p>
<p>Controlling the functional complexity of models is an effective way to improve prediction performance. Tikhonov regularisation was introduced into GP to control model complexity (Ni and Rockett 2015). Vladislavleva et al. (2009) used the order of nonlinearity (based on the minimum degree of Chebyshev polynomials) to approximate the complexity of GP models. Chen et al. (2018) introduced the Vapnik-Chervonenkis dimension to directly measure and control the complexity of GP solutions.</p>
<p>Some other EC techniques are also used for symbolic regression. However, most of them are in their infancy. LCS was recently used for symbolic regression for the first time (Naqvi and Browne 2016). AIS (Johnson 2003) was applied to solve symbolic regression tasks. Grammatical evolution (O'Neill and Ryan 2001), which evolves binary strings to select production rules in a grammar definition to generate any kind of programmes, can also be used for symbolic regression.</p>
<p>Evolutionary computation for clustering</p>
<p>Often, data may have no labels and so the previously discussed supervised ML methods cannot be used. ML algorithms developed for this scenario are called unsupervised learning algorithms, which discover underlying patterns within the data (Nanda and Panda 2014). There are several approaches to this problem, but the most studied is clustering. Clustering algorithms split a dataset into a set of clusters, so that data within a cluster are similar, while data in distinct clusters are different. A good clustering result (partition) gives insight into a dataset by splitting it into 'natural' groups. Clustering is widely used in real-world tasks such as text mining, bioinformatics, and image categorisation (Nanda and Panda 2014).</p>
<p>EML has been widely applied to clustering problems (Hruschka et al. 2009) due to its ability to find good partitions in reasonable computational time on 'big data' or when the number of clusters (K) is not known in advance (Garcı´a and Gómez-Flores 2016). The field of evolutionary clustering algorithms can be split into two categories: fixed algorithms that require that K is known, and automatic algorithms which discover K themselves. Fixed clustering algorithms are prevalent historically, whereas most recent work tackles the more difficult automatic clustering problem. The third category of algorithms which has emerged recently uses feature reduction to improve clustering performance. Traditional clustering approaches assume all features of a dataset to be equally useful. This is often untrue: for example, clustering weather records by 'day of the week' is clearly less useful than by 'daily rainfall'. This becomes even more problematic in high-dimensional datasets. EC has also recently been used to reduce the dimensionality of data in clustering (Alelyani et al. 2013).</p>
<p>Evolutionary fixed clustering</p>
<p>The first EC methods used for clustering were GAs, and this continues to be the most popular approach. Initial work (Krovi 1992) used primitive encodings (representations) on small datasets, with two or three clusters and at most 150 instances. Since then, substantial progress has been made on extending GAs to much more difficult problems, with over 40 clusters, and thousands of instances. Several new encoding schemes have been proposed that are suited to different clustering problems (Hruschka et al. 2009).</p>
<p>The label-based encoding scheme represents a partition as a vector of length N for N instances, where each instance has a label of the cluster it is in. This encoding was first proposed in the binary form (K = 2) (Krovi 1992), but more general forms have been explored since, such as bioinformatics with 16 clusters (Lu et al. 2004). In recent years, as clustering has been applied to larger datasets, this encoding is seldom used due to its inefficient representation.</p>
<p>The centroid-based encoding scheme is the most popular in recent EC clustering work, with an encoding length of K × D for D dimensions in the data. This encoding represents each cluster by a set of D features which form the cluster centre (centroid). Each instance is assigned to the cluster whose centroid is closest by distance. One of the pioneering works in this field proposed a hybrid approach of a GA and k-means clustering to balance global and local search (Bandyopadhyay and Maulik 2002). PSO is also often used with this encoding as it can efficiently optimise real-valued problems. The first approach was proposed for image clustering (Omran et al. 2005), with good results compared to GA and traditional methods. Other swarm intelligence methods such as ACO have also seen some use (Handl and Meyer 2007).</p>
<p>GP has also been briefly investigated for fixed clustering. Multi-tree GP was proposed for clustering, where each tree represents a cluster, and an instance is assigned to the tree producing the maximum output (Boric and Estévez 2007). GP is also used to build ensembles of clustering algorithms to produce more robust and accurate partitions (Coelho et al. 2011).</p>
<p>Evolutionary automatic clustering</p>
<p>One of the seminal works in evolutionary automatic clustering is MOCK (Handl and Knowles 2007). MOCK uses a graph-inspired label (locus) GA representation, where each instance's label indicates an instance it has an edge to. The set of graphs in this encoding represents the set of clusters. This encoding is shape-invariant, i.e. clusters are not assumed to be a certain shape (e.g. hyper-spherical) as in many clustering methods. The use of a multi-objective fitness function was also very novel. Recently, many EMO clustering methods have been proposed (Garcı´a and Gómez-Flores 2016), including a number of extensions to MOCK (Garza-Fabre et al. 2018). Other graph-inspired techniques have been proposed, including GPGC, which uses GP to evolve tailored similarity measures for clustering problems (Lensen et al. 2017a).</p>
<p>A flexible-length centroid encoding (Sheng et al. 2016) and a medoid-based encoding have also been used for automatic clustering, primarily with GAs or PSO. A medoid-based encoding is a binary encoding of length N, where an instance is coded as a '1' if it is a medoid and '0' if it is not. A medoid indicates that an instance is the centre of a cluster. This has the advantages of a fixed-length encoding, while also allowing K to be discovered automatically (Lensen et al. 2016).</p>
<p>Many other EC algorithms such as DE, ABC, and GP have also seen some use for automatic clustering (Garcı´a and Gómez-Flores 2016).</p>
<p>Evolutionary clustering with feature reduction NMA_CFS (Sheng et al. 2008) was a pioneering GA method that simultaneously performs feature selection and clustering, selecting features tailored to the clusters found. Recently, PSO-based approaches have been investigated using sophisticated initialisation and local search methods (Lensen et al. 2017c). Feature weighting for clustering has also been proposed (O'Neill et al. 2018).</p>
<p>FC methods are very effective at improving performance in classification tasks (Espejo et al. 2010) but have seen little use in clustering. An initial wrapper approach was proposed using GP for FC to improve k-means clustering (Lensen et al. 2017b), and embedded approaches have also been proposed (Nanda and Panda 2014). Given the upsurge of high-dimensional data, it is expected that future work will focus on new ways of incorporating feature manipulation techniques into clustering.</p>
<p>Evolutionary computer vision</p>
<p>Utilising EML to tackle a variety of problems in different computer vision tasks such as image classification, image segmentation, object detection, feature extraction, image compression, image registration, image restoration, and image enhancement has received significant attention over the last few decades. Generally, EML for computer vision problems and applications can be categorised based on the application domain (e.g. medical, military, and environment), task (e.g. classification, segmentation, and feature manipulation), and the solution representation (e.g. tree structure, and chromosomes or strings of bits). A brief review of EML methods in computer vision is provided in the following subsections, and interested readers can check (Olague 2016).</p>
<p>EC techniques for image preprocessing</p>
<p>Designing a method to handle tasks such as noise cancellation, image segmentation and image enhancement often requires human intervention and sufficient domain knowledge. EC techniques have been successfully utilised to automatically handle such tasks and such methods do not only remove/reduce the human intervention requirement but also evolve potentially better models compared to the domain-expert designed ones.</p>
<p>Image segmentation aims divides an image into different regions based on some criteria such as the connectivity of the pixels. GP has been applied to image segmentation by automatically evolving a similarity measure (Vojodi et al. 2013) or using object segmentation (Liang et al. 2015). PSO was utilised for road sign segmentation (Mussi et al. 2010), and region identification (Dhanalakshmi et al. 2016). Defining the threshold values for image segmentation is a challenging task that has been tackled using AIS (Cuevas et al. 2012).</p>
<p>Other EC techniques such as DE (Maulik and Saha 2009) and ACO (Tao et al. 2007) show significant promise in improving fuzzy clustering for image segmentation by grouping pixels into different clusters.</p>
<p>Edge detection is a very important task that finds the edges between different regions in an image, which helps in finding the boundaries of an object of interest. Lu and Chen (2008) utilised ACO to improve the performance of edge detection; GP has been used to automatically evolve an edge detector in (Fu et al. 2015).</p>
<p>Salient object detection (SOD) identifies the most attention-grabbing regions in an image, as a form of preprocessing that focuses the search into a specific part of the image. Finding an optimal set of weights for different features to improve SOD has been achieved using PSO (Afzali et al. 2017).</p>
<p>EC techniques for image feature manipulation</p>
<p>Traditionally, building or training an image classifier requires a set of features, as operating directly on the raw pixel values is very challenging due to the large search space. Feature manipulation, including feature extraction, feature construction and feature selection, is very important in computer vision and pattern recognition.</p>
<p>GP has been utilised for automatically evolving models that improve existing image descriptors such as speeded-up robust features (Perez and Olague 2013); EMO has been adopted for extracting image features (Albukhanajer et al. 2015).</p>
<p>Image descriptors are used to identify different image keypoints, e.g. lines, corners and spots, in an image and generating the corresponding feature vector. In , GP was utilised to automatically evolve image descriptors that automatically detect keypoints for multi-class texture image classification. This method mimics the well-known and largely utilised local binary pattern (LBP) image descriptor. While both methods operate in a similar fashion, i.e. using a sliding window, they differ in being manually designed by domain-experts (LBP) or automatically designed by the evolutionary process. Furthermore, LBP is designed to detect a specific set of keypoints whereas GP-based descriptors automatically design the keypoints to be detected.</p>
<p>PSO has also been used in conjunction with SIFT for face recognition (Lanzarini et al. 2010). Furthermore, selecting optimal image features by utilising accelerated binary PSO is investigated in (Aneesh et al. 2011). In (Valarmathy and Vanitha 2017), AIS was used for image feature selection in MRI images.</p>
<p>EC techniques for object detection and image classification</p>
<p>Object detection aims to localise the different objects in an image. Bhanu and Lin (2004) used GP for object detection, with promising results. Image classification is the task of categorising images into different groups (classes) based on their visual content. In order to detect breast cancer in images, GP has been used to classify different cut-outs of medical images into malignant and benign classes (Ryan et al. 2015), whereas Ain et al. (2017) tackled the problem of skin cancer classification in images by utilising GP with a mix of biomedical and LBP features. A GPbased classification method for identifying active tuberculosis in X-ray images was proposed by Burks and Punch (2018). Motivated by the promising results achieved in (Li and Ciesielski 2004), Abdulhamid et al. (2011) further investigated the potential of utilising loops with GP for binary image classification, revealing a number of interesting observations. Feature extraction is a crucial task that identifies/generates informative features to discriminate the different classes/objects. GP has been shown to perform very well in this regard (Al-Sahaf et al. 2012), even with the presence of noise (Albukhanajer et al. 2015). Perez et al. (2010) utilised PSO to extract features for face and iris localisation. PSO has been used for object (Perlin et al. 2008) and face recognition (Ramadan and Abdel-Kader 2009).</p>
<p>Template matching is a well-known approach for object detection and recognition. An ACO-based method for fingerprint matching was proposed in (Cao et al. 2012), and the results were shown to outperform the state-of-art methods.</p>
<p>Other EC techniques such as LCSs (Kukenys et al. 2011), and AISs (Wang et al. 2008) have been proposed for image classification, and an AIS based identity recognition system was proposed by Silva et al. (2015).</p>
<p>Evolutionary computation for scheduling and combinatorial optimisation</p>
<p>Scheduling and combinatorial optimisation is an important research area with many realworld applications such as manufacturing and cloud computing. These areas have been studied extensively as pure optimisation problems. Recently, more research regards them as machine learning tasks due to the following two main motivations.</p>
<p>First, the environment is often dynamic in reality. For example, in manufacturing, job orders arrive in real time and need to be scheduled immediately. Traditional optimisation approaches such as mathematical programming are not fast enough to respond, and it is necessary to find a heuristic/rule that can generate/adjust the solution in real time effectively.</p>
<p>Second, manually designing an effective optimisation algorithm for a complex problem requires substantial domain expertise and time. Using ML techniques to automatically design algorithms/heuristics saves significant human effort.</p>
<p>ML approaches that search for promising heuristics are called hyper-heuristics (Burke et al. 2013). EC methods have been successfully applied as hyper-heuristics by modelling each individual as a heuristic. In contrast to conventional optimisation, the fitness evaluation is key when EC methods are used as hyper-heuristics. A heuristic is evaluated by applying it to a set of training instances, generating solutions. The fitness of a heuristic is set as the average quality of the solutions it generates.</p>
<p>In the rest of this section, we will provide a brief review on evolutionary hyper-heuristics for classic problems including scheduling, routing and bin packing.</p>
<p>Evolutionary hyper-heuristics for scheduling</p>
<p>Scheduling aims to design a schedule to process a set of jobs by a set of machines at minimal cost and time. Dispatching rules are commonly used to generate schedules in an online fashion. GP-based Hyper-Heuristics (GPHHs) have achieved great success in automatically designing dispatching rules.</p>
<p>In a standard job shop scheduling problem, a dispatching rule is invoked whenever a machine becomes idle. It uses a priority function to prioritise the jobs in the machine's queue and decides the job to be processed next. There have been a number of studies on developing GPHHs to evolve such priority functions for the standard job shop scheduling problem. Branke et al. (2016) and Nguyen et al. (2017) give comprehensive surveys of this area.</p>
<p>In addition to the standard job shop scheduling problem, people have also applied GPHHs for solving other problem variants, such as multi-objective job shop scheduling (Nguyen et al. 2014) and flexible job shop scheduling (Yska et al. 2018).</p>
<p>Evolutionary hyper-heuristics for routing</p>
<p>A routing problem seeks optimal routes subject to some constraints, e.g. delivering to all customers, or visiting all the attractions on a trip. Oltean and Dumitrescu (2004) employed GPHHs to evolve heuristics which decide the next node to add into the current partial tour in the travelling salesman problem. Weise et al. (2012) developed a GPHH algorithm to evolve heuristics for the arc routing problem, which uses a vehicle to serve the streets on a road network, where each street has an uncertain request. Whenever the vehicle becomes idle, it calculates the priority of the remaining streets to decide the street to be served next. Here, GPHH evolves the priority function. Liu et al. (2017) considered a more realistic problem model and improved the performance of GPHH by designing more features. Jacobsen-Grocott et al. (2017) developed a GPHH approach to the vehicle routing problem with time windows, which serves the nodes rather than edges.</p>
<p>Evolutionary hyper-heuristics for bin packing</p>
<p>Bin packing aims to minimise the number of bins needed to store a set of items. A typical heuristic for bin packing starts with empty bins. Then, for each item, the heuristic calculates a priority value for each bin based on the current situation and places the item into the bin with the best priority. GPHHs have been used to evolve the priority function. Burke et al. (2006) developed a GPHH for one-dimensional bin packing. Burke et al. (2010) and Allen et al. (2009) extended the problem to two-dimensional and 3-dimensional packing, respectively.</p>
<p>Evolutionary deep learning</p>
<p>Deep learning (DL) is a class of ML algorithms that use multiple layers of nonlinear processing units to solve a problem (LeCun et al. 2015). DL has achieved remarkable performance in addressing increasingly complex data with large feature sizes from different domains such as images, gene expression, text, and web mining ), due to it automatic feature generation and selection capabilities (Bengio 2009). Evolutionary DL (EDL) aims at using EC approaches to improve the usability or improve the performance of DL algorithms. Existing EDL algorithms are mainly composed of neural network-based (NN-EDL) and GP-based (GP-EDL) algorithms.</p>
<p>Neural network-based evolutionary deep learning NN-EDL algorithms mainly focus on designing network architectures, optimising the weights, and solving multi-objective optimisation problems.</p>
<p>Existing approaches for designing architectures can be divided into two different categories: supervised NN-EDL and unsupervised NN-EDL. One typical work on NN-EDL for unsupervised deep learning is the EUDNN method . Existing supervised NN-EDL algorithms includes Large-scale Evolution (Real et al. 2017), EvoCNN (Sun et al. 2017), and so on.</p>
<p>There are two main different weight optimisation strategies. The first directly encodes the weights (Lehman et al. 2018), whereas the second searches for the best weights indirectly ).</p>
<p>An NN-based deep learning algorithm with promising performance usually has a large number of parameters, necessitating a large amount of computational resources. However, computational resources are often limited, such as on mobile devices. Thus, maximising performance and minimising computational resources are two conflicting objectives, i.e. a multi-objective (MO) optimisation problem. NN-EDL for MO was highlighted by Sun et al. (2017) and specifically investigated by Dong et al. (2018).</p>
<p>Because NN-based DL often has a large number of parameters, high-performance hardware is used to accelerate their performance, such as the graphics processing unit (GPU), field-programmable gate array and tensor processing unit.</p>
<p>GP-based evolutionary deep learning</p>
<p>GP has been used to achieve DL without NNs. The flexible structure of GP allows it to learn abstract and compact representations with suitable model complexity in a layerby-layer feature transformation manner, which meet the key characteristics of DL.</p>
<p>GP-EDL has been used to integrate multiple steps to learn a single high-level feature for image classification in a single GP tree. The first method was a multi-tier GP using image filtering, aggregation, and classification tiers to perform region detection, feature extraction, feature construction, and image classification simultaneously (Atkins et al. 2011). Bi et al. (2018) proposed a multi-layer GP method with utilisation of image-related operators to learn high-level features for image classification.</p>
<p>GP-EDL has also been proposed to learn multiple features. Shao et al. (2014) proposed a multi-objective GP with a multi-layer structure to learn features for difficult image classification tasks. Rodriguez-Coayahuitl et al. (2018) defined a structured layered GP for representation learning and introduced deep GP. A GP autoencoder was designed with an encoding forest and a decoding forest to transform an original representation into a new representation of fewer features using arithmetic operators.</p>
<p>Emerging topics and current issues</p>
<p>This section provides a number of emerging topics and summarises the major issues/challenges in EML while providing future perspective.</p>
<p>Emerging topics</p>
<p>Evolutionary transfer learning Transfer learning has become increasingly popular in ML in recent years. It aims to improve the performance of learning algorithms in a target task/domain by using useful knowledge extracted from a source task/domain (Pan and Yang 2010). In transfer learning, it is important to address three questions: what to transfer, when to transfer, and how to transfer (Pan and Yang 2010).</p>
<p>Recently, EC methods have been used with transfer learning. Iqbal et al. (2017) transferred subtrees learnt by GP on the source domain to improve the performance of GP on related target tasks. Jiang et al. (2018) transferred the probability distributions of solutions to population generation in a dynamic MO algorithm to reduce the computation cost. The parameters of DE learnt from the source problems were transferred to the target problems by Gong et al. (2015).</p>
<p>More approaches can be investigated in EC using instances transfer, feature representation transfer, parameter transfer, and rational-knowledge transfer (Pan and Yang 2010).</p>
<p>Evolutionary ensemble learning</p>
<p>Ensemble learning algorithms learn multiple learners/models from the training data. An ensemble consists of multiple base learners, which are learnt using traditional learning algorithms. Commonly used ensemble methods include bagging, boosting and stacking (Zhou 2012). Generally, to construct a strong ensemble, the base learner needs to be accurate and diverse (Zhou 2012).</p>
<p>EC methods are also beneficial in ensemble learning in different ways. EC has been combined with learning algorithms to obtain strong SVM ensembles (de Araújo Padilha et al. 2016) and NN ensembles (Pulido et al. 2014). EC has also been used to evolve ensembles using bagging and boosting (Folino et al. 2006). Finally, EMO has been used to improve the diversity of ensembles for difficult problems (Bhowan et al. 2013). Further development of EC in ensemble learning is expected to address the diversity of base learners and the interpretability of ensembles.</p>
<p>Automated machine learning (AutoML) AutoML aims to automate ML techniques, allowing people without ML domain knowledge to use them for problem-solving. An AutoML method optimises the integration of different methods and their hyper-parameters for data preprocessing, feature engineering, and learning. Well-known AutoML methods include Auto-WEKA, Auto-Sklearn and Auto-Keras, which are based on existing ML libraries.</p>
<p>EC methods have also been used for AutoML. The well-known tree-based pipeline optimisation tool (TPOT) uses GP to evolve a set of data transformations and ML models (Olson and Moore 2016). Chen et al. (2018a) developed an Autostacker method, using an EC algorithm to find the optimal hyper-parameters for ML pipelines. There are still many unexplored opportunities in this topic, such as EMO for AutoML, which need to be investigated in the future.</p>
<p>Current issues</p>
<p>Despite its successes, EML remains an active research area with challenges and opportunities. This section discusses some of its major issues: its theoretical foundation, computational cost, scalability, generalisability, and interpretability.</p>
<p>There has been some theoretical analysis of EML methods on running time, convergence guarantee, and parameter settings (Auger and Doerr 2011). However, current EML methods still lack mathematical foundation, which may prevent scientists and practitioners from using EML methods.</p>
<p>Computational cost is another major issue in existing EML methods. EML methods evaluate a population of individuals at each generation, which often makes them more expensive than many traditional ML methods.</p>
<p>Scalability is a common problem in EML where learning methods do not scale well when datasets increase in size. An increase in the number of features and the number of instances often requires larger memory and longer computation time. This may limit the viability of EML methods in large-scale problems.</p>
<p>Like most ML techniques, EML methods also face the challenge of poor generalisability, due to insufficient data, overfitting, and poor feature choice. For EML methods, poor generalisability is often due to overfitting, where the learnt model perfectly fits the training data, but works poorly on unseen data. The issue of overfitting in EML warrants further investigation in the future.</p>
<p>Interpretability is another important issue in EML and ML. Good interpretability of a learnt model not only provides insights into why it obtains a result but also encourages experts to accept and reuse the model. The use of arcane features and complex models can often lead to poor interpretability. Among EML methods, several methods such as tree-based GP have good interpretability of solutions, which can be further investigated in the future.</p>
<p>Conclusions</p>
<p>This paper provided a comprehensive review of major EC techniques for ML tasks, covering both supervised and unsupervised tasks, and applications. A number of emergent techniques such as evolutionary deep learning and transfer learning were studied. This paper also discussed major current issues and challenges in this area, including scalability, generalisability, and interpretability/comprehensibility of evolved models.</p>
<p>The fast development of hardware such as GPU devices and cloud computing facilities has allowed previously impossible EML tasks to become reality. Involvement and investment from large corporations such as Google, Microsoft, Uber, Huawei, and IBM have made EML methods more practically useful. It is anticipated that EML methods will play a significant role in AI and ML in the next ten years. EML is expected to be applied to most real-world data mining and big data tasks and applications in our daily life. In the future, the AI and EC/ ML group at Victoria University of Wellington will seek research collaborations with colleagues who are interested in using AI in science, engineering, commerce/business, humanities and social sciences, education, law, and in the primary industries of New Zealand.</p>
<p>Disclosure statement</p>
<p>No potential conflict of interest was reported by the authors.</p>
<p>Funding</p>
<p>This work was supported in part by the Marsden Fund of the New Zealand Government under Contract VUW1509, VUW1614, VUW1615 through the Royal Society of New Zealand, in part by the Novel Transfer Learning Techniques in Genetic Programming for Big Data Mining under Grant 216378/3764 through the Victoria University of Wellington, and Industry Grant E2880/ 3663 Huawei Technologies.</p>
<p>Figure 1 .
1Taxonomy and structure of the paper.</p>
<p>Image recognition using genetic programming with loop structures. F Abdulhamid, K Neshatian, M Zhang, Proceedings of the 26th International Conference on Image and Vision Computing. the 26th International Conference on Image and Vision ComputingNew Zealand29Abdulhamid F, Neshatian K, Zhang M. 2011. Image recognition using genetic programming with loop structures. In: Proceedings of the 26th International Conference on Image and Vision Computing New Zealand; vol. 29. p. 553-558.</p>
<p>A supervised feature weighting method for salient object detection using PSO. S Afzali, B Xue, H Al-Sahaf, M Zhang, Proceedings of the 2017 IEEE Symposium Series on Computational Intelligence. IEEE. the 2017 IEEE Symposium Series on Computational Intelligence. IEEEAfzali S, Xue B, Al-Sahaf H, Zhang M. 2017. A supervised feature weighting method for salient object detection using PSO. In: Proceedings of the 2017 IEEE Symposium Series on Computational Intelligence. IEEE. p. 1-8.</p>
<p>Multiple feature construction for effective biomarker identification and classification using genetic programming. S Ahmed, M Zhang, L Peng, B Xue, Proceedings of the 2014 Annual Conference on Genetic and Evolutionary Computation. the 2014 Annual Conference on Genetic and Evolutionary ComputationACMAhmed S, Zhang M, Peng L, Xue B. 2014. Multiple feature construction for effective biomarker identification and classification using genetic programming. In: Proceedings of the 2014 Annual Conference on Genetic and Evolutionary Computation. ACM. p. 249-256.</p>
<p>Genetic programming for skin cancer detection in dermoscopic images. Q U Ain, B Xue, H Al-Sahaf, M Zhang, Proceedings of the IEEE Congress on Evolutionary Computation. IEEE. the IEEE Congress on Evolutionary Computation. IEEEAin QU, Xue B, Al-Sahaf H, Zhang M. 2017. Genetic programming for skin cancer detection in dermoscopic images. In: Proceedings of the IEEE Congress on Evolutionary Computation. IEEE. p. 2420-2427.</p>
<p>Automatically evolving rotationinvariant texture image descriptors by genetic programming. H Al-Sahaf, Al - Sahaf, A Xue, B Johnston, M Zhang, M , IEEE Transactions on Evolutionary Computation. 211Al-Sahaf H, Al-Sahaf A, Xue B, Johnston M, Zhang M. 2017. Automatically evolving rotationinvar- iant texture image descriptors by genetic programming. IEEE Transactions on Evolutionary Computation. 21(1):83-101.</p>
<p>Extracting image features for classification by two-tier genetic programming. H Al-Sahaf, A Song, K Neshatian, M Zhang, Proceedings of the IEEE Congress on Evolutionary Computation. the IEEE Congress on Evolutionary ComputationIEEEAl-Sahaf H, Song A, Neshatian K, Zhang M. 2012. Extracting image features for classification by two-tier genetic programming. In: Proceedings of the IEEE Congress on Evolutionary Computation. IEEE.</p>
<p>Evolutionary multiobjective image feature extraction in the presence of noise. W Albukhanajer, J Briffa, Y Jin, IEEE Transactions on Cybernetics. 459Albukhanajer W, Briffa J, Jin Y. 2015. Evolutionary multiobjective image feature extraction in the presence of noise. IEEE Transactions on Cybernetics. 45(9):1757-1768.</p>
<p>Feature selection for clustering: a review. S Alelyani, J Tang, H Liu, Data clustering: algorithms and applications. Milton ParkCRC PressAlelyani S, Tang J, Liu H. 2013. Feature selection for clustering: a review. In: Data clustering: algor- ithms and applications. Milton Park: CRC Press; p. 29-60.</p>
<p>A genetic-based feature construction method for data summarisation. R Alfred, SpringerBerlin, HeidelbergAlfred R. 2008. A genetic-based feature construction method for data summarisation. Berlin, Heidelberg: Springer. p. 39-50.</p>
<p>Evolving reusable 3D packing heuristics with genetic programming. S Allen, E K Burke, M Hyde, G Kendall, Proceedings of Genetic and Evolutionary Computation Conference. Genetic and Evolutionary Computation ConferenceACMAllen S, Burke EK, Hyde M, Kendall G. 2009. Evolving reusable 3D packing heuristics with genetic programming. In: Proceedings of Genetic and Evolutionary Computation Conference. ACM. p. 931-938.</p>
<p>Optimal feature selection based on image preprocessing using accelerated binary particle swarm optimization for enhanced face recognition. M Aneesh, A A Masand, K Manikantan, Proceedings of the 2011 International Conference on Communication Technology and System Design. the 2011 International Conference on Communication Technology and System DesignElsevierAneesh M, Masand AA, Manikantan K. 2011. Optimal feature selection based on image preproces- sing using accelerated binary particle swarm optimization for enhanced face recognition. In: Proceedings of the 2011 International Conference on Communication Technology and System Design. Elsevier. p. 750-758.</p>
<p>Seismic indicators based earthquake predictor system using genetic programming and adaboost classification. K M Asim, A Idris, T Iqbal, F Martı´nez-Álvarez, Soil Dynamics and Earthquake Engineering. 111Asim KM, Idris A, Iqbal T, Martı´nez-Álvarez F. 2018. Seismic indicators based earthquake predic- tor system using genetic programming and adaboost classification. Soil Dynamics and Earthquake Engineering. 111:1-7.</p>
<p>A domain independent genetic programming approach to automatic feature extraction for image classification. D L Atkins, K Neshatian, M Zhang, Proceedings of the IEEE Congress on Evolutionary Computation. IEEE. the IEEE Congress on Evolutionary Computation. IEEEAtkins DL, Neshatian K, Zhang M. 2011. A domain independent genetic programming approach to automatic feature extraction for image classification. In: Proceedings of the IEEE Congress on Evolutionary Computation. IEEE. p. 238-245.</p>
<p>Theory of randomized search heuristics: foundations and recent developments. A Auger, B Doerr, World Scientific1SingaporeAuger A, Doerr B. 2011. Theory of randomized search heuristics: foundations and recent develop- ments. vol. 1. Singapore: World Scientific.</p>
<p>Handbook of evolutionary computation. T Bäck, D B Fogel, Z Michalewicz, CRC PressOxfordBäck T, Fogel DB, Michalewicz Z. 1997. Handbook of evolutionary computation. Oxford: CRC Press.</p>
<p>Financial forecasting using anfis networks with quantumbehaved particle swarm optimization. A Bagheri, H M Peyhani, M Akbari, Expert Systems with Applications. 4114Bagheri A, Peyhani HM, Akbari M. 2014. Financial forecasting using anfis networks with quantum- behaved particle swarm optimization. Expert Systems with Applications. 41(14):6235-6250.</p>
<p>An evolutionary technique based on k-means algorithm for optimal clustering in R N. S Bandyopadhyay, U Maulik, Information Science. 1461-4Bandyopadhyay S, Maulik U. 2002. An evolutionary technique based on k-means algorithm for optimal clustering in R N . Information Science. 146(1-4):221-237.</p>
<p>Learning deep architectures for AI. Foundations and Trends in Machine Learning. Y Bengio, 2Bengio Y. 2009. Learning deep architectures for AI. Foundations and Trends in Machine Learning. 2(1):1-127.</p>
<p>Object detection in multi-modal images using genetic programming. B Bhanu, Y Lin, Applied Soft Computing. 42Bhanu B, Lin Y. 2004. Object detection in multi-modal images using genetic programming. Applied Soft Computing. 4(2):175-201.</p>
<p>Evolving diverse ensembles using genetic programming for classification with unbalanced data. U Bhowan, M Johnston, M Zhang, X Yao, IEEE Transactions on Evolutionary Computation. 173Bhowan U, Johnston M, Zhang M, Yao X. 2013. Evolving diverse ensembles using genetic program- ming for classification with unbalanced data. IEEE Transactions on Evolutionary Computation. 17(3):368-386.</p>
<p>Reusing genetic programming for ensemble selection in classification of unbalanced data. U Bhowan, M Johnston, M Zhang, X Yao, IEEE Transactions on Evolutionary Computation. 186Bhowan U, Johnston M, Zhang M, Yao X. 2014. Reusing genetic programming for ensemble selec- tion in classification of unbalanced data. IEEE Transactions on Evolutionary Computation. 18 (6):893-908.</p>
<p>An automatic feature extraction approach to image classification using genetic programming. Y Bi, B Xue, M Zhang, Proceedings of the International Conference on the Applications of Evolutionary Computation. the International Conference on the Applications of Evolutionary ComputationSpringerBi Y, Xue B, Zhang M. 2018. An automatic feature extraction approach to image classification using genetic programming. In: Proceedings of the International Conference on the Applications of Evolutionary Computation. Springer. p. 421-438.</p>
<p>Genetic programming-based clustering using an information theoretic fitness measure. N Boric, P A Estévez, Proceedings of the IEEE Congress on Evolutionary Computation. the IEEE Congress on Evolutionary ComputationBoric N, Estévez PA. 2007. Genetic programming-based clustering using an information theoretic fitness measure. In: Proceedings of the IEEE Congress on Evolutionary Computation. p. 31-38.</p>
<p>Automated design of production scheduling heuristics: A review. J Branke, S Nguyen, C W Pickardt, M Zhang, IEEE Transactions on Evolutionary Computation. 201Branke J, Nguyen S, Pickardt CW, Zhang M. 2016. Automated design of production scheduling heuristics: A review. IEEE Transactions on Evolutionary Computation. 20(1):110-124.</p>
<p>Linear and non-linear fuzzy regression: evolutionary algorithm solutions. Fuzzy Sets and Systems. J J Buckley, T Feuring, 112Buckley JJ, Feuring T. 2000. Linear and non-linear fuzzy regression: evolutionary algorithm sol- utions. Fuzzy Sets and Systems. 112(3):381-394.</p>
<p>A survey of data mining and machine learning methods for cybersecurity intrusion detection. A L Buczak, E Guven, IEEE Communications Surveys &amp; Tutorials. 182Buczak AL, Guven E. 2016. A survey of data mining and machine learning methods for cybersecur- ity intrusion detection. IEEE Communications Surveys &amp; Tutorials. 18(2):1153-1176.</p>
<p>Hyper-heuristics: a survey of the state of the art. E K Burke, M Gendreau, M Hyde, G Kendall, G Ochoa, E Özcan, R Qu, Journal of the Operational Research Society. 6412Burke EK, Gendreau M, Hyde M, Kendall G, Ochoa G, Özcan E, Qu R. 2013. Hyper-heuristics: a survey of the state of the art. Journal of the Operational Research Society. 64(12):1695-1724.</p>
<p>A genetic programming hyper-heuristic approach for evolving 2-D strip packing heuristics. E K Burke, M Hyde, G Kendall, J Woodward, IEEE Transactions on Evolutionary Computation. 146Burke EK, Hyde M, Kendall G, Woodward J. 2010. A genetic programming hyper-heuristic approach for evolving 2-D strip packing heuristics. IEEE Transactions on Evolutionary Computation. 14(6):942-958.</p>
<p>Evolving bin packing heuristics with genetic programming. In: Parallel problem solving from nature. E K Burke, M R Hyde, G Kendall, SpringerBerlinBurke EK, Hyde MR, Kendall G. 2006. Evolving bin packing heuristics with genetic programming. In: Parallel problem solving from nature. Berlin: Springer; p. 860-869.</p>
<p>Genetic programming for tuberculosis screening from raw X-ray images. A R Burks, W F Punch, Proceedings of the 2018 Genetic and Evolutionary Computation Conference. the 2018 Genetic and Evolutionary Computation ConferenceACMBurks AR, Punch WF. 2018. Genetic programming for tuberculosis screening from raw X-ray images. In: Proceedings of the 2018 Genetic and Evolutionary Computation Conference. ACM. p. 1214-1221.</p>
<p>A novel ant colony optimization algorithm for large-distorted fingerprint matching. K Cao, X Yang, X Chen, Y Zang, J Liang, J Tian, Pattern Recognition. 451Cao K, Yang X, Chen X, Zang Y, Liang J, Tian J. 2012. A novel ant colony optimization algorithm for large-distorted fingerprint matching. Pattern Recognition. 45(1):151-161.</p>
<p>Modeling of a liquid epoxy molding process using aparticle swarm optimization-based fuzzy regression approach. K Y Chan, T S Dillon, C K Kwong, IEEE Transactions on Industrial Informatics. 71Chan KY, Dillon TS, Kwong CK. 2011. Modeling of a liquid epoxy molding process using aparticle swarm optimization-based fuzzy regression approach. IEEE Transactions on Industrial Informatics. 7(1):148-158.</p>
<p>Autostacker: a compositional evolutionary learning system. B Chen, H Wu, W Mo, I Chattopadhyay, H Lipson, arXiv:180300684arXiv preprintChen B, Wu H, Mo W, Chattopadhyay I, Lipson H. 2018a. Autostacker: a compositional evolution- ary learning system. arXiv preprint arXiv:180300684.</p>
<p>Improving generalisation of genetic programming for symbolic regression with angle-driven geometric semantic operators. Q Chen, B Xue, M Zhang, 10.1109/TEVC.2018.2869621IEEE Transactions on Evolutionary Computation. Chen Q, Xue B, Zhang M. 2018b. Improving generalisation of genetic programming for symbolic regression with angle-driven geometric semantic operators. IEEE Transactions on Evolutionary Computation. doi:10.1109/TEVC.2018.2869621.</p>
<p>Feature selection to improve generalization of genetic programming for high-dimensional symbolic regression. Q Chen, M Zhang, B Xue, IEEE Transactions on Evolutionary Computation. 215Chen Q, Zhang M, Xue B. 2017. Feature selection to improve generalization of genetic program- ming for high-dimensional symbolic regression. IEEE Transactions on Evolutionary Computation. 21(5):792-806.</p>
<p>Structural risk minimisation-driven genetic programming for enhancing generalisation in symbolic regression. Q Chen, M Zhang, B Xue, 10.1109/TEVC.2018.2881392IEEE Transactions on Evolutionary Computation. Chen Q, Zhang M, Xue B. 2018. Structural risk minimisation-driven genetic programming for enhancing generalisation in symbolic regression. IEEE Transactions on Evolutionary Computation. doi:10.1109/TEVC.2018.2881392.</p>
<p>Particle swarm optimization aided orthogonal forward regression for unified data modeling. S Chen, X Hong, C J Harris, IEEE Transactions on Evolutionary Computation. 144Chen S, Hong X, Harris CJ. 2010. Particle swarm optimization aided orthogonal forward regression for unified data modeling. IEEE Transactions on Evolutionary Computation. 14(4):477-499.</p>
<p>A bi-objective optimization for citrus closed-loop supply chain using Pareto-based algorithms. A Cheraghalipour, M M Paydar, M Hajiaghaei-Keshteli, Applied Soft Computing. 69Cheraghalipour A, Paydar MM, Hajiaghaei-Keshteli M. 2018. A bi-objective optimization for citrus closed-loop supply chain using Pareto-based algorithms. Applied Soft Computing. 69:33-59.</p>
<p>Genetic algorithm-based classifiers fusion for multisensor activity recognition of elderly people. S Chernbumroong, S Cang, H Yu, IEEE Journal of Biomedical and Health Informatics. 191Chernbumroong S, Cang S, Yu H. 2015. Genetic algorithm-based classifiers fusion for multisensor activity recognition of elderly people. IEEE Journal of Biomedical and Health Informatics. 19 (1):282-289.</p>
<p>Variants of evolutionary algorithms for real-world applications. R Chiong, T Weise, Z Michalewicz, SpringerBerlinChiong R, Weise T, Michalewicz Z. 2012. Variants of evolutionary algorithms for real-world appli- cations. Berlin: Springer.</p>
<p>A decision support system for fish farming using particle swarm optimization. Computers and Electronics in Agriculture. Á Cobo, I Llorente, L Luna, M Luna, 10.1016/j.compag.2018.03.036Cobo Á, Llorente I, Luna L, Luna M. 2018. A decision support system for fish farming using particle swarm optimization. Computers and Electronics in Agriculture. doi:10.1016/j.compag.2018.03.036</p>
<p>Multi-objective design of hierarchical consensus functions for clustering ensembles via genetic programming. Alv Coelho, E Fernandes, K Faceli, Decision Support Systems. 514Coelho ALV, Fernandes E, Faceli K. 2011. Multi-objective design of hierarchical consensus func- tions for clustering ensembles via genetic programming. Decision Support Systems. 51 (4):794-809.</p>
<p>A memetic algorithm for 3D protein structure prediction problem. L Correa, B Borguesan, C Farfan, M Inostroza-Ponta, M Dorn, IEEE/ACM Transactions on Computational Biology and Bioinformatics. 153Correa L, Borguesan B, Farfan C, Inostroza-Ponta M, Dorn M. 2018. A memetic algorithm for 3D protein structure prediction problem. IEEE/ACM Transactions on Computational Biology and Bioinformatics. 15(3):690-704.</p>
<p>Multithreshold segmentation based on artificial immune systems. E Cuevas, V Osuna-Enciso, D Zaldivar, M Pérez-Cisneros, H Sossa, Mathematical Problems in Engineering. 2012Cuevas E, Osuna-Enciso V, Zaldivar D, Pérez-Cisneros M, Sossa H. 2012. Multithreshold segmen- tation based on artificial immune systems. Mathematical Problems in Engineering. 2012 (2012):1-20.</p>
<p>New Representations in PSO for Feature Construction in Classification. Y Dai, B Xue, M Zhang, Proceedings of the applications of evolutionary computation. the applications of evolutionary computationSpringerDai Y, Xue B, Zhang M. 2014. New Representations in PSO for Feature Construction in Classification. In: Proceedings of the applications of evolutionary computation. Springer;</p>
<p>Genetic programming for QoS-aware web service composition and selection. A S Da Silva, H Ma, M Zhang, Soft Computing. 2010da Silva AS, Ma H, Zhang M. 2016. Genetic programming for QoS-aware web service composition and selection. Soft Computing. 20(10):3851-3867.</p>
<p>A multi-level approach using genetic algorithms in an ensemble of least squares support vector machines. Knowledge-Based Systems. C A De Araújo Padilha, Dac Barone, Add Neto, 106de Araújo Padilha CA, Barone DAC, Neto ADD. 2016. A multi-level approach using genetic algor- ithms in an ensemble of least squares support vector machines. Knowledge-Based Systems. 106:85-95.</p>
<p>A survey on evolutionary instance selection and generation. J Derrac, S Garcı´a, F Herrera, International Journal of Applied Metaheuristic Computing. 11Derrac J, Garcı´a S, Herrera F. 2010. A survey on evolutionary instance selection and generation. International Journal of Applied Metaheuristic Computing. 1(1):60-92.</p>
<p>A novel method for image processing using particle swarm optimization technique. L Dhanalakshmi, S Ranjitha, H N Suresh, Proceedings of 2016 International Conference on Electrical, Electronics, and Optimization Techniques. 2016 International Conference on Electrical, Electronics, and Optimization TechniquesDhanalakshmi L, Ranjitha S, Suresh HN. 2016. A novel method for image processing using particle swarm optimization technique. In: Proceedings of 2016 International Conference on Electrical, Electronics, and Optimization Techniques. IEEE. p. 3357-3363.</p>
<p>J D Dong, A C Cheng, D C Juan, W Wei, M Sun, arXiv:180608198Dpp-net: device-aware progressive search for pareto-optimal neural architectures. arXiv preprintDong JD, Cheng AC, Juan DC, Wei W, Sun M. 2018. Dpp-net: device-aware progressive search for pareto-optimal neural architectures. arXiv preprint arXiv:180608198.</p>
<p>Computational intelligence: An introduction. A P Engelbrecht, WileyHoboken (NJ2nd ed.Engelbrecht AP. 2007. Computational intelligence: An introduction, 2nd ed. Hoboken (NJ): Wiley.</p>
<p>A survey on the application of genetic programming to classification. P Espejo, S Ventura, F Herrera, IEEE Transactions on systems, Man, and Cybernetics. Part C: Applications and Reviews. 402Espejo P, Ventura S, Herrera F. 2010. A survey on the application of genetic programming to classification. IEEE Transactions on systems, Man, and Cybernetics. Part C: Applications and Reviews. 40(2):121-144.</p>
<p>Discovering comprehensible classification rules with a genetic algorithm. M V Fidelis, H S Lopes, A A Freitas, Proceedings of the IEEE Congress on Evolutionary Computation. the IEEE Congress on Evolutionary ComputationFidelis MV, Lopes HS, Freitas AA. 2000. Discovering comprehensible classification rules with a genetic algorithm. In: Proceedings of the IEEE Congress on Evolutionary Computation; vol. 1;</p>
<p>. July, July. p. 805-810.</p>
<p>GP ensembles for large-scale data classification. G Folino, C Pizzuti, G Spezzano, IEEE Transactions on Evolutionary Computation. 105Folino G, Pizzuti C, Spezzano G. 2006. GP ensembles for large-scale data classification. IEEE Transactions on Evolutionary Computation. 10(5):604-616.</p>
<p>Distribution-based invariant feature construction using genetic programming for edge detection. W Fu, M Johnston, M Zhang, Soft Computing. 198Fu W, Johnston M, Zhang M. 2015. Distribution-based invariant feature construction using genetic programming for edge detection. Soft Computing. 19(8):2371-2389.</p>
<p>Automatic clustering using nature-inspired metaheuristics: a survey. A J Garcı´a, W Gómez-Flores, Applied Soft Computing. 41Garcı´a AJ, Gómez-Flores W. 2016. Automatic clustering using nature-inspired metaheuristics: a survey. Applied Soft Computing. 41:192-213.</p>
<p>An improved and more scalable evolutionary approach to multiobjective clustering. M Garza-Fabre, J Handl, J D Knowles, IEEE Transactions on Evolutionary Computation. 224Garza-Fabre M, Handl J, Knowles JD. 2018. An improved and more scalable evolutionary approach to multiobjective clustering. IEEE Transactions on Evolutionary Computation. 22(4):515-535.</p>
<p>An extrapolative model of house price dynamics. E L Glaeser, C G Nathanson, Journal of Financial Economics. 1261Glaeser EL, Nathanson CG. 2017. An extrapolative model of house price dynamics. Journal of Financial Economics. 126(1):147-170.</p>
<p>Parameter extraction of different fuel cell models with transferred adaptive differential evolution. W Gong, X Yan, X Liu, Z Cai, Energy. 86Gong W, Yan X, Liu X, Cai Z. 2015. Parameter extraction of different fuel cell models with trans- ferred adaptive differential evolution. Energy. 86:139-151.</p>
<p>Feature selection for high-dimensional classification using a competitive swarm optimizer. S Gu, R Cheng, Y Jin, Soft Computing. 223Gu S, Cheng R, Jin Y. 2018. Feature selection for high-dimensional classification using a competi- tive swarm optimizer. Soft Computing. 22(3):811-822.</p>
<p>A survey of evolutionary computation for resource management of processing in cloud computing. M Guzek, P Bouvry, E G Talbi, IEEE Computational Intelligence Magazine. 102Guzek M, Bouvry P, Talbi EG. 2015. A survey of evolutionary computation for resource management of processing in cloud computing. IEEE Computational Intelligence Magazine. 10(2):53-67.</p>
<p>An evolutionary approach to multiobjective clustering. J Handl, J D Knowles, IEEE Transactions on Evolutionary Computation. 111Handl J, Knowles JD. 2007. An evolutionary approach to multiobjective clustering. IEEE Transactions on Evolutionary Computation. 11(1):56-76.</p>
<p>Ant-based and swarm-based clustering. J Handl, B Meyer, Swarm Intelligence. 12Handl J, Meyer B. 2007. Ant-based and swarm-based clustering. Swarm Intelligence. 1(2):95-113.</p>
<p>Optimized placement of wind turbines in large-scale offshore wind farm using particle swarm optimization algorithm. P Hou, W Hu, M Soltani, Chen Z , IEEE Transactions on Sustainable Energy. 64Hou P, Hu W, Soltani M, Chen Z. 2015. Optimized placement of wind turbines in large-scale offshore wind farm using particle swarm optimization algorithm. IEEE Transactions on Sustainable Energy. 6(4):1272-1282.</p>
<p>A survey of evolutionary algorithms for clustering. E R Hruschka, Rjgb Campello, A A Freitas, Acplf De Carvalho, IEEE Transactions on Systems, Man, and Cybernetics, Part C. 392Hruschka ER, Campello RJGB, Freitas AA, de Carvalho ACPLF. 2009. A survey of evolutionary algorithms for clustering. IEEE Transactions on Systems, Man, and Cybernetics, Part C. 39 (2):133-155.</p>
<p>Reusing building blocks of extracted knowledge to solve complex, large-scale boolean problems. M Iqbal, W N Browne, M Zhang, IEEE Transactions on Evolutionary Computation. 184Iqbal M, Browne WN, Zhang M. 2014. Reusing building blocks of extracted knowledge to solve complex, large-scale boolean problems. IEEE Transactions on Evolutionary Computation. 18 (4):465-480.</p>
<p>Cross-domain reuse of extracted knowledge in genetic programming for image classification. M Iqbal, B Xue, H Al-Sahaf, M Zhang, IEEE Transactions on Evolutionary Computation. 214Iqbal M, Xue B, Al-Sahaf H, Zhang M. 2017. Cross-domain reuse of extracted knowledge in genetic programming for image classification. IEEE Transactions on Evolutionary Computation. 21 (4):569-587.</p>
<p>Evolving heuristics for dynamic vehicle routing with time windows using genetic programming. J Jacobsen-Grocott, Y Mei, G Chen, M Zhang, Proceedings of the IEEE Congress on Evolutionary Computation. IEEE. the IEEE Congress on Evolutionary Computation. IEEEJacobsen-Grocott J, Mei Y, Chen G, Zhang M. 2017. Evolving heuristics for dynamic vehicle routing with time windows using genetic programming. In: Proceedings of the IEEE Congress on Evolutionary Computation. IEEE. p. 1948-1955.</p>
<p>An evolutionary algorithm with the partial sequential forward floating search mutation for large-scale feature selection problems. Y S Jeong, K S Shin, M K Jeong, Journal of the Operational Research Society. 664Jeong YS, Shin KS, Jeong MK. 2015. An evolutionary algorithm with the partial sequential forward floating search mutation for large-scale feature selection problems. Journal of the Operational Research Society. 66(4):529-538.</p>
<p>Transfer learning-based dynamic multiobjective optimization algorithms. M Jiang, Z Huang, L Qiu, W Huang, G G Yen, IEEE Transactions on Evolutionary Computation. 224Jiang M, Huang Z, Qiu L, Huang W, Yen GG. 2018. Transfer learning-based dynamic multiobjec- tive optimization algorithms. IEEE Transactions on Evolutionary Computation. 22(4):501-514.</p>
<p>Artificial immune system programming for symbolic regression. C G Johnson, Proceedings of the European Conference on Genetic Programming. the European Conference on Genetic ProgrammingSpringerJohnson CG. 2003. Artificial immune system programming for symbolic regression. In: Proceedings of the European Conference on Genetic Programming. Springer. p. 345-353.</p>
<p>A review of multi-criteria optimization techniques for agricultural land use allocation. A Kaim, A F Cord, M Volk, Environmental Modelling &amp; Software. 105Kaim A, Cord AF, Volk M. 2018. A review of multi-criteria optimization techniques for agricultural land use allocation. Environmental Modelling &amp; Software. 105:79-93.</p>
<p>Genetic algorithms in parameter estimation for nonlinear regression models: an experimental approach. M Kapanoglu, Ozan Koc, I Erdogmus, S , Journal of Statistical Computation and Simulation. 7710Kapanoglu M, Ozan Koc I, Erdogmus S. 2007. Genetic algorithms in parameter estimation for non- linear regression models: an experimental approach. Journal of Statistical Computation and Simulation. 77(10):851-867.</p>
<p>An automatic text classification system based on genetic algorithm. M I Khaleel, I I Hmeidi, H M Najadat, Proceedings of the 3rd Multidisciplinary International Social Networks Conference on Social Informatics. the 3rd Multidisciplinary International Social Networks Conference on Social Informatics31Khaleel MI, Hmeidi II, Najadat HM. 2016. An automatic text classification system based on genetic algorithm. In: Proceedings of the 3rd Multidisciplinary International Social Networks Conference on Social Informatics. ACM. p. 31:1-31:7.</p>
<p>Genetic programming-based construction of features for machine learning and knowledge discovery tasks. Genetic Programming and Evolvable Machines. K Krawiec, 3Krawiec K. 2002. Genetic programming-based construction of features for machine learning and knowledge discovery tasks. Genetic Programming and Evolvable Machines. 3:329-343.</p>
<p>Genetic algorithms for clustering: a preliminary investigation. R Krovi, Proceedings of the 25th Hawaii International Conference on System Sciences. the 25th Hawaii International Conference on System SciencesIEEE4Krovi R. 1992. Genetic algorithms for clustering: a preliminary investigation. In: Proceedings of the 25th Hawaii International Conference on System Sciences; vol. 4. IEEE. p. 540-544.</p>
<p>Transparent, online image pattern classification using a learning classifier system. I Kukenys, W N Browne, M Zhang, Proceedings of the 2011 European Conference on the Applications of Evolutionary Computation. the 2011 European Conference on the Applications of Evolutionary ComputationSpringerKukenys I, Browne WN, Zhang M. 2011. Transparent, online image pattern classification using a learning classifier system. In: Proceedings of the 2011 European Conference on the Applications of Evolutionary Computation. Springer. p. 183-193.</p>
<p>A genetic bankrupt ratio analysis tool using a genetic algorithm to identify influencing financial ratios. T M Lakshmi, A Martin, V P Venkatesan, IEEE Transactions on Evolutionary Computation. 201Lakshmi TM, Martin A, Venkatesan VP. 2016. A genetic bankrupt ratio analysis tool using a genetic algorithm to identify influencing financial ratios. IEEE Transactions on Evolutionary Computation. 20(1):38-51.</p>
<p>Face recognition using SIFT and binary PSO descriptors. L Lanzarini, J L Battaglia, J Maulini, W Hasperué, Proceedings of the 32nd International Conference on Information Technology Interfaces. IEEE. the 32nd International Conference on Information Technology Interfaces. IEEELanzarini L, Battaglia JL, Maulini J, Hasperué W. 2010. Face recognition using SIFT and binary PSO descriptors. In: Proceedings of the 32nd International Conference on Information Technology Interfaces. IEEE. p. 557-562.</p>
<p>A bright future for evolutionary methods in drug design. T C Le, D A Winkler, ChemMedChem. 108Le TC, Winkler DA. 2015. A bright future for evolutionary methods in drug design. ChemMedChem. 10(8):1296-1300.</p>
<p>Discovery and optimization of materials using evolutionary approaches. T C Le, D A Winkler, Chemical Reviews. 11610Le TC, Winkler DA. 2016. Discovery and optimization of materials using evolutionary approaches. Chemical Reviews. 116(10):6107-6132.</p>
<p>Deep learning. Y Lecun, Y Bengio, G Hinton, Nature. 5217553LeCun Y, Bengio Y, Hinton G. 2015. Deep learning. Nature. 521(7553):436-444.</p>
<p>ES is more than just a traditional finitedifference approximator. J Lehman, J Chen, J Clune, K O Stanley, Proceedings of the Genetic and Evolutionary Computation Conference. the Genetic and Evolutionary Computation ConferenceACMLehman J, Chen J, Clune J, Stanley KO. 2018. ES is more than just a traditional finitedifference approximator. In: Proceedings of the Genetic and Evolutionary Computation Conference. ACM. p. 450-457.</p>
<p>Particle swarm optimisation representations for simultaneous clustering and feature selection. A Lensen, B Xue, M Zhang, Proceedings of the Symposium Series on Computational Intelligence. IEEE. the Symposium Series on Computational Intelligence. IEEELensen A, Xue B, Zhang M. 2016. Particle swarm optimisation representations for simultaneous clustering and feature selection. In: Proceedings of the Symposium Series on Computational Intelligence. IEEE. p. 1-8.</p>
<p>GPGC: genetic programming for automatic clustering using a flexible non-hyper-spherical graph-based approach. A Lensen, B Xue, M Zhang, Proceedings of the Genetic and Evolutionary Computation Conference. the Genetic and Evolutionary Computation ConferenceACMLensen A, Xue B, Zhang M. 2017a. GPGC: genetic programming for automatic clustering using a flexible non-hyper-spherical graph-based approach. In: Proceedings of the Genetic and Evolutionary Computation Conference. ACM. p. 449-456.</p>
<p>New representations in genetic programming for feature construction in k-means clustering. A Lensen, B Xue, M Zhang, Simulated Evolution and Learning. SpringerLensen A, Xue B, Zhang M. 2017b. New representations in genetic programming for feature con- struction in k-means clustering. In: Simulated Evolution and Learning. Springer. p. 543-555.</p>
<p>Using particle swarm optimisation and the silhouette metric to estimate the number of clusters, select features, and perform clustering. A Lensen, B Xue, M Zhang, Proceedings of the Applications of Evolutionary Computation. the Applications of Evolutionary ComputationSpringerLensen A, Xue B, Zhang M. 2017c. Using particle swarm optimisation and the silhouette metric to estimate the number of clusters, select features, and perform clustering. In: Proceedings of the Applications of Evolutionary Computation. Springer. p. 538-554.</p>
<p>Using loops in genetic programming for a two class binary image classification problem. X Li, V Ciesielski, Proceedings of the 17th Australian Joint Conference on Artificial Intelligence. the 17th Australian Joint Conference on Artificial IntelligenceSpringer3339Li X, Ciesielski V. 2004. Using loops in genetic programming for a two class binary image classifi- cation problem. In: Proceedings of the 17th Australian Joint Conference on Artificial Intelligence; vol. 3339. Springer. p. 898-909.</p>
<p>A supervised figure-ground segmentation method using genetic programming. Y Liang, M Zhang, W Browne, Proceedings of the 18th European Conference on the Applications of Evolutionary Computation. the 18th European Conference on the Applications of Evolutionary ComputationSpringer9028Liang Y, Zhang M, Browne W. 2015. A supervised figure-ground segmentation method using genetic programming. In: Proceedings of the 18th European Conference on the Applications of Evolutionary Computation; vol. 9028. Springer. p. 491-503.</p>
<p>Application of a fuzzy neural network combined with a chaos genetic algorithm and simulated annealing to short-term load forecasting. G C Liao, T P Tsao, IEEE Transactions on Evolutionary Computation. 103Liao GC, Tsao TP. 2006. Application of a fuzzy neural network combined with a chaos genetic algorithm and simulated annealing to short-term load forecasting. IEEE Transactions on Evolutionary Computation. 10(3):330-340.</p>
<p>Automated heuristic design using genetic programming hyper-heuristic for uncertain capacitated arc routing problem. Y Liu, Y Mei, M Zhang, Z Zhang, Proceedings of Genetic and Evolutionary Computation Conference. Genetic and Evolutionary Computation ConferenceACMLiu Y, Mei Y, Zhang M, Zhang Z. 2017. Automated heuristic design using genetic programming hyper-heuristic for uncertain capacitated arc routing problem. In: Proceedings of Genetic and Evolutionary Computation Conference. ACM. p. 290-297.</p>
<p>Edge detection improvement by ant colony optimization. D S Lu, C C Chen, Pattern Recognition Letters. 294Lu DS, Chen CC. 2008. Edge detection improvement by ant colony optimization. Pattern Recognition Letters. 29(4):416-425.</p>
<p>Incremental genetic k-means algorithm and its application in gene expression data analysis. Y Lu, S Lu, F Fotouhi, Y Deng, S J Brown, BMC Bioinformatics. 5Lu Y, Lu S, Fotouhi F, Deng Y, Brown SJ. 2004. Incremental genetic k-means algorithm and its application in gene expression data analysis. BMC Bioinformatics. 5:172-181.</p>
<p>On the use of genetic programming for mining comprehensible rules in subgroup discovery. J M Luna, J R Romero, C Romero, S Ventura, IEEE Transactions on Cybernetics. 4412Luna JM, Romero JR, Romero C, Ventura S. 2014. On the use of genetic programming for mining comprehensible rules in subgroup discovery. IEEE Transactions on Cybernetics. 44(12):2329-2341.</p>
<p>Modified differential evolution based fuzzy clustering for pixel classification in remote sensing imagery. U Maulik, I Saha, Pattern Recognition. 429Maulik U, Saha I. 2009. Modified differential evolution based fuzzy clustering for pixel classification in remote sensing imagery. Pattern Recognition. 42(9):2135-2149.</p>
<p>An evolutionary approach to practical constraints in scheduling: a case-study of the wine bottling problem. A Mohais, S Schellenberg, M Ibrahimov, N Wagner, Z Michalewicz, SpringerBerlin, HeidelbergMohais A, Schellenberg S, Ibrahimov M, Wagner N, Michalewicz Z. 2012. An evolutionary approach to practical constraints in scheduling: a case-study of the wine bottling problem. Berlin, Heidelberg: Springer. p. 31-58.</p>
<p>Evolutionary constructive induction. M Muharram, G Smith, IEEE Transactions on Knowledge and Data Engineering. 17Muharram M, Smith G. 2005. Evolutionary constructive induction. IEEE Transactions on Knowledge and Data Engineering. 17:1518-1528.</p>
<p>GPU implementation of a road sign detector based on particle swarm optimization. L Mussi, S Cagnoni, E Cardarelli, F Daolio, P Medici, P P Porta, Evolutionary Intelligence. 33Mussi L, Cagnoni S, Cardarelli E, Daolio F, Medici P, Porta PP. 2010. GPU implementation of a road sign detector based on particle swarm optimization. Evolutionary Intelligence. 3(3):155-169.</p>
<p>A multiobjective genetic programming-based ensemble for simultaneous feature selection and classification. K Nag, N Pal, IEEE Transactions on Cybernetics. 462Nag K, Pal N. 2016. A multiobjective genetic programming-based ensemble for simultaneous feature selection and classification. IEEE Transactions on Cybernetics. 46(2):499-510.</p>
<p>A survey on nature inspired metaheuristic algorithms for partitional clustering. Swarm and Evolutionary Computation. S J Nanda, G Panda, 16Nanda SJ, Panda G. 2014. A survey on nature inspired metaheuristic algorithms for partitional clus- tering. Swarm and Evolutionary Computation. 16:1-18.</p>
<p>Adapting learning classifier systems to symbolic regression. S S Naqvi, W N Browne, Proceedings of the IEEE Congress on Evolutionary Computation (CEC). the IEEE Congress on Evolutionary Computation (CEC)Naqvi SS, Browne WN. 2016. Adapting learning classifier systems to symbolic regression. In: Proceedings of the IEEE Congress on Evolutionary Computation (CEC). p. 2209-2216.</p>
<p>Recent advances in differential evolution: a survey and experimental analysis. F Neri, V Tirronen, Artificial Intelligence Review. 331-2Neri F, Tirronen V. 2010. Recent advances in differential evolution: a survey and experimental analysis. Artificial Intelligence Review. 33(1-2):61-106.</p>
<p>Genetic programming for feature subset ranking in binary classification problems. K Neshatian, M Zhang, Vanneschi L, Gustafson S, Moraglio A, De Falco I, Ebner MSpringer Genetic ProgrammingBerlin, HeidelbergNeshatian K, Zhang M. 2009a. Genetic programming for feature subset ranking in binary classifi- cation problems. In: Vanneschi L, Gustafson S, Moraglio A, De Falco I, Ebner M, editor. Berlin, Heidelberg: Springer Genetic Programming; p. 121-132.</p>
<p>Pareto front feature selection: using genetic programming to explore feature space. K Neshatian, M Zhang, Proceedings of the Conference on Genetic and Evolutionary Computation. the Conference on Genetic and Evolutionary ComputationNeshatian K, Zhang M. 2009b. Pareto front feature selection: using genetic programming to explore feature space. In: Proceedings of the Conference on Genetic and Evolutionary Computation. p. 1027-1034.</p>
<p>A filter approach to multiple feature construction for symbolic learning classifiers using genetic programming. K Neshatian, M Zhang, P Andreae, IEEE Transactions on Evolutionary Computation. 165Neshatian K, Zhang M, Andreae P. 2012. A filter approach to multiple feature construction for sym- bolic learning classifiers using genetic programming. IEEE Transactions on Evolutionary Computation. 16(5):645-661.</p>
<p>Mutual information for feature selection: estimation or counting?. B H Nguyen, B Xue, P Andreae, Evolutionary Intelligence. 93Nguyen BH, Xue B, Andreae P. 2016. Mutual information for feature selection: estimation or count- ing? Evolutionary Intelligence. 9(3):95-110.</p>
<p>Genetic programming for production scheduling: a survey with a unified framework. S Nguyen, Y Mei, M Zhang, Complex &amp; Intelligent Systems. 31Nguyen S, Mei Y, Zhang M. 2017. Genetic programming for production scheduling: a survey with a unified framework. Complex &amp; Intelligent Systems. 3(1):41-66.</p>
<p>Automatic design of scheduling policies for dynamic multi-objective job shop scheduling via cooperative coevolution genetic programming. S Nguyen, M Zhang, M Johnston, K C Tan, IEEE Transactions on Evolutionary Computation. 182Nguyen S, Zhang M, Johnston M, Tan KC. 2014. Automatic design of scheduling policies for dynamic multi-objective job shop scheduling via cooperative coevolution genetic programming. IEEE Transactions on Evolutionary Computation. 18(2):193-208.</p>
<p>Tikhonov regularization as a complexity measure in multiobjective genetic programming. J Ni, P Rockett, IEEE Transactions on Evolutionary Computation. 192Ni J, Rockett P. 2015. Tikhonov regularization as a complexity measure in multiobjective genetic programming. IEEE Transactions on Evolutionary Computation. 19(2):157-166.</p>
<p>Resource allocation in pastoral dairy production systems: evaluating exact and genetic algorithms approaches. G Notte, M Pedemonte, H Cancela, P Chilibroste, Agricultural Systems. 148Notte G, Pedemonte M, Cancela H, Chilibroste P. 2016. Resource allocation in pastoral dairy pro- duction systems: evaluating exact and genetic algorithms approaches. Agricultural Systems. 148:114-123.</p>
<p>Evolutionary computer vision: the first footprints. G Olague, SpringerBerlinOlague G. 2016. Evolutionary computer vision: the first footprints. Berlin: Springer.</p>
<p>Tpot: a tree-based pipeline optimization tool for automating machine learning. R S Olson, J H Moore, Proceedings of the Workshop on Automatic Machine Learning. the Workshop on Automatic Machine LearningOlson RS, Moore JH. 2016. Tpot: a tree-based pipeline optimization tool for automating machine learning. In: Proceedings of the Workshop on Automatic Machine Learning. p. 66-74.</p>
<p>Evolving TSP heuristics using multi expression programming. M Oltean, D Dumitrescu, Proceedings of the International Conference on Computational Science. the International Conference on Computational ScienceSpringerOltean M, Dumitrescu D. 2004. Evolving TSP heuristics using multi expression programming. In: Proceedings of the International Conference on Computational Science. Springer. p. 670-673.</p>
<p>Particle swarm optimization method for image clustering. Mgh Omran, A P Engelbrecht, A A Salman, International Journal of Pattern Recognition and Artificial Intelligence. 193Omran MGH, Engelbrecht AP, Salman AA. 2005. Particle swarm optimization method for image clustering. International Journal of Pattern Recognition and Artificial Intelligence. 19(3):297-321.</p>
<p>Particle swarm optimisation for feature selection and weighting in high-dimensional clustering. D O&apos;neill, A Lensen, B Xue, M Zhang, Proceedings of the IEEE Congress on Evolutionary Computation. IEEE. the IEEE Congress on Evolutionary Computation. IEEEO'Neill D, Lensen A, Xue B, Zhang M. 2018. Particle swarm optimisation for feature selection and weighting in high-dimensional clustering. In: Proceedings of the IEEE Congress on Evolutionary Computation. IEEE. p. 1-8.</p>
<p>Grammatical evolution. M O&apos;neill, C Ryan, IEEE Transactions on Evolutionary Computation. 54O'Neill M, Ryan C. 2001. Grammatical evolution. IEEE Transactions on Evolutionary Computation. 5(4):349-358.</p>
<p>Genetic algorithm-based heuristic for feature selection in credit risk assessment. S Oreski, G Oreski, Expert Systems with Applications. 414Oreski S, Oreski G. 2014. Genetic algorithm-based heuristic for feature selection in credit risk assessment. Expert Systems with Applications. 41(4):2052-2064.</p>
<p>A genetic algorithm to goal programming model for crop production with interval data uncertainty. B B Pal, S Roy, M Kumar, Handbook of research on natural computing for optimization problems. IGI GlobalPal BB, Roy S, Kumar M. 2016. A genetic algorithm to goal programming model for crop pro- duction with interval data uncertainty. In: Handbook of research on natural computing for optimization problems. IGI Global; p. 30-65.</p>
<p>Evolutionary computation in bioinformatics: A review. S K Pal, S Bandyopadhyay, S S Ray, IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews). 365Pal SK, Bandyopadhyay S, Ray SS. 2006. Evolutionary computation in bioinformatics: A review. IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews). 36 (5):601-615.</p>
<p>A survey on transfer learning. S J Pan, Yang Q , IEEE Transactions on Knowledge and Data Engineering. 2210Pan SJ, Yang Q. 2010. A survey on transfer learning. IEEE Transactions on Knowledge and Data Engineering. 22(10):1345-1359.</p>
<p>Regression model selection using genetic algorithms. S Paterlini, Minerva T , Proceedings of the 11th WSEAS international conference on evolutionary computing. the 11th WSEAS international conference on evolutionary computingPaterlini S, Minerva T. 2010. Regression model selection using genetic algorithms. In: Proceedings of the 11th WSEAS international conference on evolutionary computing. p. 19-27.</p>
<p>Face and iris localization using templates designed by particle swarm optimization. C A Perez, C M Aravena, J I Vallejos, P A Estevez, C M Held, Pattern Recognit Lett. 319Perez CA, Aravena CM, Vallejos JI, Estevez PA, Held CM. 2010. Face and iris localization using templates designed by particle swarm optimization. Pattern Recognit Lett. 31(9):857-868.</p>
<p>Genetic programming as strategy for learning image descriptor operators. C B Perez, G Olague, Intelligent Data Analysis. 174Perez CB, Olague G. 2013. Genetic programming as strategy for learning image descriptor oper- ators. Intelligent Data Analysis. 17(4):561-583.</p>
<p>Particle swarm optimization for object recognition in computer vision. H A Perlin, H S Lopes, T M Centeno, Proceedings of the International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems. the International Conference on Industrial, Engineering and Other Applications of Applied Intelligent SystemsSpringerPerlin HA, Lopes HS, Centeno TM. 2008. Particle swarm optimization for object recognition in computer vision. In: Proceedings of the International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems. Springer. p. 11-21.</p>
<p>Parsimony pressure made easy. R Poli, N F Mcphee, Proceedings of the Genetic and Evolutionary Computation Conference. the Genetic and Evolutionary Computation ConferenceACMPoli R, McPhee NF. 2008. Parsimony pressure made easy. In: Proceedings of the Genetic and Evolutionary Computation Conference. ACM. p. 1267-1274.</p>
<p>Particle swarm optimization of ensemble neural networks with fuzzy aggregation for time series prediction of the Mexican stock exchange. M Pulido, P Melin, O Castillo, Information Sciences. 280Pulido M, Melin P, Castillo O. 2014. Particle swarm optimization of ensemble neural networks with fuzzy aggregation for time series prediction of the Mexican stock exchange. Information Sciences. 280:188-204.</p>
<p>Particle swarm optimization for human face recognition. R M Ramadan, Abdel-Kader Rf, Proceedings of the 2009 IEEE International Symposium on Signal Processing and Information Technology. the 2009 IEEE International Symposium on Signal Processing and Information TechnologyIEEERamadan RM, Abdel-Kader RF. 2009. Particle swarm optimization for human face recognition. In: Proceedings of the 2009 IEEE International Symposium on Signal Processing and Information Technology. IEEE. p. 579-584.</p>
<p>Large-scale evolution of image classifiers. E Real, S Moore, A Selle, S Saxena, Y L Suematsu, J Tan, Q Le, A Kurakin, Proceedings of Machine Learning Research. Machine Learning ResearchReal E, Moore S, Selle A, Saxena S, Suematsu YL, Tan J, Le Q, Kurakin A. 2017. Large-scale evol- ution of image classifiers. In: Proceedings of Machine Learning Research. p. 2902-2911.</p>
<p>Generation and simplification of artificial neural networks by means of genetic programming. D Rivero, J Dorado, J Rabunal, A Pazos, Neurocomputing. 7316Rivero D, Dorado J, Rabunal J, Pazos A. 2010. Generation and simplification of artificial neural net- works by means of genetic programming. Neurocomputing. 73(16):3200-3223.</p>
<p>Structurally layered representation learning: Towards deep learning through genetic programming. L Rodriguez-Coayahuitl, A Morales-Reyes, H J Escalante, Proceedings of the European Conference on Genetic Programming. the European Conference on Genetic ProgrammingSpringerRodriguez-Coayahuitl L, Morales-Reyes A, Escalante HJ. 2018. Structurally layered representation learning: Towards deep learning through genetic programming. In: Proceedings of the European Conference on Genetic Programming. Springer. p. 271-288.</p>
<p>Image classification with genetic programming: building a stage 1 computer aided detector for breast cancer. In: Handbook of Genetic Programming Applications. C Ryan, J Fitzgerald, K Krawiec, D Medernach, SpringerRyan C, Fitzgerald J, Krawiec K, Medernach D. 2015. Image classification with genetic program- ming: building a stage 1 computer aided detector for breast cancer. In: Handbook of Genetic Programming Applications. Springer. p. 245-287.</p>
<p>Aggressive and effective feature selection using genetic programming. I Sandin, G Andrade, F Viegas, D Madeira, L Rocha, T Salles, M Gonçalves, Proceedings of the IEEE Congress on Evolutionary Computation. IEEE. the IEEE Congress on Evolutionary Computation. IEEESandin I, Andrade G, Viegas F, Madeira D, Rocha L, Salles T, Gonçalves M. 2012. Aggressive and effective feature selection using genetic programming. In: Proceedings of the IEEE Congress on Evolutionary Computation. IEEE. p. 1-8.</p>
<p>Distilling free-form natural laws from experimental data. M Schmidt, H Lipson, science. 3245923Schmidt M, Lipson H. 2009. Distilling free-form natural laws from experimental data. science. 324 (5923):81-85.</p>
<p>Differential evolution algorithms for scheduling raw milk transportation. Computers and Electronics in Agriculture. K Sethanan, R Pitakaso, 121Sethanan K, Pitakaso R. 2016. Differential evolution algorithms for scheduling raw milk transpor- tation. Computers and Electronics in Agriculture. 121:245-259.</p>
<p>Feature learning for image classification via multiobjective genetic programming. L Shao, L Liu, X Li, IEEE Transactions on Neural Networks and Learning Systems. 257Shao L, Liu L, Li X. 2014. Feature learning for image classification via multiobjective genetic pro- gramming. IEEE Transactions on Neural Networks and Learning Systems. 25(7):1359-1371.</p>
<p>Adaptive multisubpopulation competition and multiniche crowding-based memetic algorithm for automatic data clustering. W Sheng, S Chen, M Sheng, Xiao G Mao, J Zheng, Y , IEEE Trans Evolutionary Computation. 206Sheng W, Chen S, Sheng M, Xiao G, Mao J, Zheng Y. 2016. Adaptive multisubpopulation compe- tition and multiniche crowding-based memetic algorithm for automatic data clustering. IEEE Trans Evolutionary Computation. 20(6):838-858.</p>
<p>A niching memetic algorithm for simultaneous clustering and feature selection. W Sheng, X Liu, M C Fairhurst, IEEE Transactions on Knowledge Data Engineering. 207Sheng W, Liu X, Fairhurst MC. 2008. A niching memetic algorithm for simultaneous clustering and feature selection. IEEE Transactions on Knowledge Data Engineering. 20(7):868-879.</p>
<p>Identity recognition using an artificial intelligence based on artificial immune system. Jcd Silva, Fpda Lima, Adp Lotufo, Jmmdcp Batista, Proceedings of the 2015 Asia-Pacific Conference on Computer Aided System Engineering. the 2015 Asia-Pacific Conference on Computer Aided System EngineeringIEEESilva JCD, Lima FPDA, Lotufo ADP, Batista JMMDCP. 2015. Identity recognition using an artificial intelligence based on artificial immune system. In: Proceedings of the 2015 Asia-Pacific Conference on Computer Aided System Engineering. IEEE. p. 158-162.</p>
<p>A multiobjective exploratory procedure for regression model selection. A Sinha, P Malo, T Kuosmanen, Journal of Computational and Graphical Statistics. 241Sinha A, Malo P, Kuosmanen T. 2015. A multiobjective exploratory procedure for regression model selection. Journal of Computational and Graphical Statistics. 24(1):154-182.</p>
<p>Genetic programming with a genetic algorithm for feature construction and selection. Genetic Programming and Evolvable Machines. M Smith, L Bull, 6Smith M, Bull L. 2005. Genetic programming with a genetic algorithm for feature construction and selection. Genetic Programming and Evolvable Machines. 6:265-281.</p>
<p>Multi criteria decision making in financial risk management with a multi-objective genetic algorithm. S Srinivasan, T Kamalakannan, Computational Economics. 522Srinivasan S, Kamalakannan T. 2018. Multi criteria decision making in financial risk management with a multi-objective genetic algorithm. Computational Economics. 52(2):443-457.</p>
<p>Y Sun, B Xue, M Zhang, arXiv:171010741Evolving deep convolutional neural networks for image classification. arXiv preprintSun Y, Xue B, Zhang M. 2017. Evolving deep convolutional neural networks for image classifi- cation. arXiv preprint arXiv:171010741.</p>
<p>Evolving unsupervised deep neural networks for learning meaningful representations. Y Sun, G G Yen, Z Yi, 10.1109/TEVC.2018.2808689IEEE Transactions on Evolutionary Computation. Sun Y, Yen GG, Yi Z. 2018. Evolving unsupervised deep neural networks for learning meaningful rep- resentations. IEEE Transactions on Evolutionary Computation. doi:10.1109/TEVC.2018.2808689.</p>
<p>Modelling three-echelon warm-water fish supply chain: a bi-level optimization approach under nash-cournot equilibrium. S Tabrizi, S H Ghodsypour, A Ahmadi, Applied Soft Computing. 71Tabrizi S, Ghodsypour SH, Ahmadi A. 2018. Modelling three-echelon warm-water fish supply chain: a bi-level optimization approach under nash-cournot equilibrium. Applied Soft Computing. 71:1035-1053.</p>
<p>Object segmentation using ant colony optimization algorithm and fuzzy entropy. W Tao, H Jin, L Liu, Pattern Recognition Letters. 287Tao W, Jin H, Liu L. 2007. Object segmentation using ant colony optimization algorithm and fuzzy entropy. Pattern Recognition Letters. 28(7):788-796.</p>
<p>Class dependent multiple feature construction using genetic programming for high-dimensional data. B Tran, B Xue, M Zhang, Proceedings of the Australasian Joint Conference on Artificial Intelligence. the Australasian Joint Conference on Artificial IntelligenceSpringer International Publishing10400Tran B, Xue B, Zhang M. 2017. Class dependent multiple feature construction using genetic pro- gramming for high-dimensional data. In: Proceedings of the Australasian Joint Conference on Artificial Intelligence; vol. 10400. Springer International Publishing. p. 182-194.</p>
<p>Variable-length particle swarm optimisation for feature selection on high-dimensional classification. B Tran, B Xue, M Zhang, 10.1109/TEVC.2018.2869405doi:10. 1109/TEVC.2018.2869405IEEE Transactions on Evolutionary Computation. Tran B, Xue B, Zhang M. 2018a. Variable-length particle swarm optimisation for feature selection on high-dimensional classification. IEEE Transactions on Evolutionary Computation. doi:10. 1109/TEVC.2018.2869405.</p>
<p>Investigation on particle swarm optimisation for feature selection on high-dimensional data: local search and selection bias. B Tran, B Xue, M Zhang, S Nguyen, Connection Science. 283Tran B, Xue B, Zhang M, Nguyen S. 2016a. Investigation on particle swarm optimisation for feature selection on high-dimensional data: local search and selection bias. Connection Science. 28 (3):270-294.</p>
<p>Multiple feature construction in classification on high-dimensional data using GP. B Tran, M Zhang, B Xue, 10.1109/SSCI.2016.7850130Proceedings of the IEEE Symposium Series on Computational Intelligence. the IEEE Symposium Series on Computational IntelligenceTran B, Zhang M, Xue B. 2016b. Multiple feature construction in classification on high-dimensional data using GP. In: Proceedings of the IEEE Symposium Series on Computational Intelligence. doi:10.1109/SSCI.2016.7850130.</p>
<p>An effective and efficient approach to classification with incomplete data. Knowledge-Based Systems. C T Tran, M Zhang, P Andreae, B Xue, L T Bui, 154Tran CT, Zhang M, Andreae P, Xue B, Bui LT. 2018b. An effective and efficient approach to classifi- cation with incomplete data. Knowledge-Based Systems. 154:1-16.</p>
<p>Feature selection optimization using artificial immune system algorithm for identifying dementia in MRI images. S Valarmathy, N S Vanitha, Journal of Medical Imaging and Health Informatics. 71Valarmathy S, Vanitha NS. 2017. Feature selection optimization using artificial immune system algorithm for identifying dementia in MRI images. Journal of Medical Imaging and Health Informatics. 7(1):73-78.</p>
<p>An intelligent genetic algorithm for mining classification rules in large datasets. P Vivekanandan, M Rajalakshmi, R Nedunchezhian, Computing &amp; Informatics. 321Vivekanandan P, Rajalakshmi M, Nedunchezhian R. 2013. An intelligent genetic algorithm for mining classification rules in large datasets. Computing &amp; Informatics. 32(1):1-22.</p>
<p>Order of nonlinearity as a complexity measure for models generated by symbolic regression via Pareto genetic programming. E J Vladislavleva, G F Smits, Den Hertog, D , IEEE Transactions on Evolutionary Computation. 132Vladislavleva EJ, Smits GF, Den Hertog D. 2009. Order of nonlinearity as a complexity measure for models generated by symbolic regression via Pareto genetic programming. IEEE Transactions on Evolutionary Computation. 13(2):333-349.</p>
<p>A new evaluation measure for color image segmentation based on genetic programming approach. H Vojodi, A Fakhari, Ame Moghadam, Image and Vision Computing. 3111Vojodi H, Fakhari A, Moghadam AME. 2013. A new evaluation measure for color image segmen- tation based on genetic programming approach. Image and Vision Computing. 31(11):877-886.</p>
<p>Application of genetic programming GP Formalism for building Disease Predictive models from protein-protein interactions PPI data. R Vyas, S Bapat, P Goel, M Karthikeyan, S S Tambe, B D Kulkarni, IEEE/ACM Transactions on Computational Biology and Bioinformatics. 151Vyas R, Bapat S, Goel P, Karthikeyan M, Tambe SS, Kulkarni BD. 2018. Application of genetic pro- gramming GP Formalism for building Disease Predictive models from protein-protein inter- actions PPI data. IEEE/ACM Transactions on Computational Biology and Bioinformatics. 15 (1):27-37.</p>
<p>Time series forecasting for dynamic environments: The dyfor genetic program model. N Wagner, Z Michalewicz, M Khouja, R R Mcgregor, IEEE Transactions on Evolutionary Computation. 114Wagner N, Michalewicz Z, Khouja M, McGregor RR. 2007. Time series forecasting for dynamic environments: The dyfor genetic program model. IEEE Transactions on Evolutionary Computation. 11(4):433-452.</p>
<p>Artificial immune system based image pattern recognition in energy efficient wireless multimedia sensor networks. H Wang, D Peng, W Wang, H Sharif, J Wegiel, D Nguyen, R Bowne, C Backhaus, 10.1109/MILCOM.2008.4753651doi:10.1109/ MILCOM.2008.4753651Proceedings of the IEEE Military Communications Conference. IEEE. the IEEE Military Communications Conference. IEEEWang H, Peng D, Wang W, Sharif H, Wegiel J, Nguyen D, Bowne R, Backhaus C. 2008. Artificial immune system based image pattern recognition in energy efficient wireless multimedia sensor networks. In: Proceedings of the IEEE Military Communications Conference. IEEE. doi:10.1109/ MILCOM.2008.4753651.</p>
<p>A developmental solution to (dynamic) capacitated arc routing problems using genetic programming. T Weise, A Devert, K Tang, Proceedings of Genetic and Evolutionary Computation Conference. Genetic and Evolutionary Computation ConferenceACMWeise T, Devert A, Tang K. 2012. A developmental solution to (dynamic) capacitated arc routing problems using genetic programming. In: Proceedings of Genetic and Evolutionary Computation Conference. ACM. p. 831-838.</p>
<p>A multi-objective particle swarm optimisation for filter-based feature selection in classification problems. B Xue, L Cervante, L Shang, W N Browne, M Zhang, Connection Science. 242-3Xue B, Cervante L, Shang L, Browne WN, Zhang M. 2012. A multi-objective particle swarm optim- isation for filter-based feature selection in classification problems. Connection Science. 24(2- 3):91-116.</p>
<p>Particle swarm optimisation for feature selection in classification: novel initialisation and updating mechanisms. B Xue, M Zhang, W N Browne, Applied Soft Computing. 18Xue B, Zhang M, Browne WN. 2014. Particle swarm optimisation for feature selection in classifi- cation: novel initialisation and updating mechanisms. Applied Soft Computing. 18:261-276.</p>
<p>A survey on evolutionary computation approaches to feature selection. B Xue, M Zhang, W N Browne, X Yao, IEEE Transactions on Evolutionary Computation. 204Xue B, Zhang M, Browne WN, Yao X. 2016. A survey on evolutionary computation approaches to feature selection. IEEE Transactions on Evolutionary Computation. 20(4):606-626.</p>
<p>. G N Yannakakis, J Togelius, Artificial intelligence and games. 2SpringerYannakakis GN, Togelius J. 2018. Artificial intelligence and games. Vol. 2. New York: Springer.</p>
<p>Genetic programming hyper-heuristic with cooperative coevolution for dynamic flexible job shop scheduling. D Yska, Y Mei, M Zhang, Proceedings of the European Conference on Genetic Programming. the European Conference on Genetic ProgrammingSpringerYska D, Mei Y, Zhang M. 2018. Genetic programming hyper-heuristic with cooperative coevolution for dynamic flexible job shop scheduling. In: Proceedings of the European Conference on Genetic Programming. Springer. p. 306-321.</p>
<p>Multiobjective production planning optimization using hybrid evolutionary algorithms for mineral processing. G Yu, T Chai, X Luo, IEEE Transactions on Evolutionary Computation. 154Yu G, Chai T, Luo X. 2011. Multiobjective production planning optimization using hybrid evol- utionary algorithms for mineral processing. IEEE Transactions on Evolutionary Computation. 15(4):487-514.</p>
<p>Multiple Bayesian discriminant functions for highdimensional massive data classification. J Zhang, S Wang, L Chen, P Gallinari, Data Mining and Knowledge Discovery. 6Zhang J, Wang S, Chen L, Gallinari P. 2016. Multiple Bayesian discriminant functions for high- dimensional massive data classification. Data Mining and Knowledge Discovery. 6:1-37.</p>
<p>Evolutionary computation meets machine learning: a survey. J Zhang, Z Zhan, Y Lin, N Chen, Y Gong, J Zhong, H S Chung, Y Li, Y Shi, IEEE Computational Intelligence Magazine. 64Zhang J, Zhan Z, Lin Y, Chen N, Gong Y, Zhong J, Chung HS, Li Y, Shi Y. 2011. Evolutionary computation meets machine learning: a survey. IEEE Computational Intelligence Magazine. 6(4):68-75.</p>
<p>A multi-objective genetic programming approach to developing pareto optimal decision trees. H Zhao, Decision Support Systems. 433Zhao H. 2007. A multi-objective genetic programming approach to developing pareto optimal decision trees. Decision Support Systems. 43(3):809-826.</p>
<p>The study on reconfigurable algorithm of the wood flexible manufacturing system based on ootcpn-gasa. Y Zhao, X Feng, L Shi, J Zhang, L Wang, Y Xu, Proceedings of the 2nd International Conference on Control and Robotics Engineering. the 2nd International Conference on Control and Robotics EngineeringZhao Y, Feng X, Shi L, Zhang J, Wang L, Xu Y. 2017. The study on reconfigurable algorithm of the wood flexible manufacturing system based on ootcpn-gasa. In: Proceedings of the 2nd International Conference on Control and Robotics Engineering. IEEE. p. 68-72.</p>
<p>Population classification in fire evacuation: a multiobjective particle swarm optimization approach. Y J Zheng, H F Ling, J Y Xue, Chen Sy, IEEE Transactions on Evolutionary Computation. 181Zheng YJ, Ling HF, Xue JY, Chen SY. 2014. Population classification in fire evacuation: a multiob- jective particle swarm optimization approach. IEEE Transactions on Evolutionary Computation. 18(1):70-81.</p>
<p>Multiobjective evolutionary algorithms: a survey of the state of the art. A Zhou, B Y Qu, H Li, S Z Zhao, P N Suganthan, Q Zhang, Swarm and Evolutionary Computation. 11Zhou A, Qu BY, Li H, Zhao SZ, Suganthan PN, Zhang Q. 2011. Multiobjective evolutionary algor- ithms: a survey of the state of the art. Swarm and Evolutionary Computation. 1(1):32-49.</p>
<p>A genetic method of LAD estimation for models with censored data. X Zhou, J Wang, Computational statistics &amp; Data Analysis. 483Zhou X, Wang J. 2005. A genetic method of LAD estimation for models with censored data. Computational statistics &amp; Data Analysis. 48(3):451-466.</p>
<p>Ensemble methods: foundations and algorithms. Z H Zhou, Chapman and Hall/ CRCLondonZhou ZH. 2012. Ensemble methods: foundations and algorithms. London: Chapman and Hall/ CRC.</p>
<p>Identification of full and partial class relevant genes. Z Zhu, Y S Ong, J M Zurada, IEEE/ACM Transactions on Computational Biology and Bioinformatics. 72Zhu Z, Ong YS, Zurada JM. 2010. Identification of full and partial class relevant genes. IEEE/ACM Transactions on Computational Biology and Bioinformatics. 7(2):263-277.</p>            </div>
        </div>

    </div>
</body>
</html>