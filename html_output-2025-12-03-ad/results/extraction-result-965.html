<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-965 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-965</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-965</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-23.html">extraction-schema-23</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that use probabilistic symbolic world models (such as PPDDL, PDDL, or belief states) for planning in text-based environments, especially those that integrate uncertainty from large language models.</div>
                <p><strong>Paper ID:</strong> paper-b8f57509a228f1c84bf67094ec1fa8a99407368b</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/b8f57509a228f1c84bf67094ec1fa8a99407368b" target="_blank">Church: a language for generative models</a></p>
                <p><strong>Paper Venue:</strong> Conference on Uncertainty in Artificial Intelligence</p>
                <p><strong>Paper TL;DR:</strong> This work introduces Church, a universal language for describing stochastic generative processes, based on the Lisp model of lambda calculus, containing a pure Lisp as its deterministic subset.</p>
                <p><strong>Paper Abstract:</strong> Formal languages for probabilistic modeling enable re-use, modularity, and descriptive clarity, and can foster generic inference techniques. We introduce Church, a universal language for describing stochastic generative processes. Church is based on the Lisp model of lambda calculus, containing a pure Lisp as its deterministic subset. The semantics of Church is defined in terms of evaluation histories and conditional distributions on such histories. Church also includes a novel language construct, the stochastic memoizer, which enables simple description of many complex non-parametric models. We illustrate language features through several examples, including: a generalized Bayes net in which parameters cluster over trials, infinite PCFGs, planning by inference, and various non-parametric clustering models. Finally, we show how to implement query on any Church program, exactly and approximately, using Monte Carlo techniques.</p>
                <p><strong>Cost:</strong> 0.012</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e965.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e965.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that use probabilistic symbolic world models (such as PPDDL, PDDL, or belief states) for planning in text-based environments, especially those that integrate uncertainty from large language models.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Church</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Church (stochastic programming language)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A Lisp-based universal probabilistic programming language that represents generative processes as evaluable expressions, provides query/eval primitives for conditional sampling, and supports memoization (including nonparametric memoizers) to represent persistent latent structure.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Church</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Church is a dynamically-typed, Scheme-derived probabilistic programming language in which expressions denote stochastic generative processes. Key components include eval (sampling from the generative model), query (conditional sampling / inference), lex-query for shared random-world programming, mem (memoization) and DPmem (Dirichlet-process-based stochastic memoizer) for persistent latent objects, and a Monte Carlo inference suite (collapsed rejection sampler and a Metropolis-Hastings MCMC over computation traces). Church represents states, actions and transitions as arbitrary Church expressions and procedures (first-class values) and composes them to form probabilistic symbolic world models. The implementation uses evaluation histories / computation traces as the latent structure for MCMC proposals and supports metacircular nesting of queries.</td>
                        </tr>
                        <tr>
                            <td><strong>world_model_type</strong></td>
                            <td>probabilistic program (stochastic functional / symbolic world model)</td>
                        </tr>
                        <tr>
                            <td><strong>world_model_description</strong></td>
                            <td>World models are represented as Church expressions/procedures: states and actions are arbitrary symbols or compound values, transitions are stochastic procedures (elementary random procedures like flip, beta, normal, or composed procedures), and persistent state or object identity is expressed via mem/DPmem creating shared random-world bindings. The representation is explicitly probabilistic: evaluation histories define probability measures over executions, transitions are stochastic and can be marginalised; DPmem and other primitives permit nonparametric, discrete latent structure.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_llm</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>llm_role</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_modeling</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_type</strong></td>
                            <td>state uncertainty, action outcome uncertainty, model (parameter) uncertainty, and uncertainty over latent structure (nonparametric / DP prior)</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_method</strong></td>
                            <td>explicit probability distributions in the program (flip, beta, normal, multinomial, DPmem), marginalization via Monte Carlo sampling (rejection sampling, collapsed rejection) and MCMC over computation traces; stochastic memoization to represent uncertainty over persistent assignments (exchangeable random-world semantics).</td>
                        </tr>
                        <tr>
                            <td><strong>planning_algorithm</strong></td>
                            <td>planning-as-inference (reward-to-probability transformation) implemented via conditional sampling / query; approximate inference via rejection sampling and Metropolis-Hastings MCMC over evaluation histories</td>
                        </tr>
                        <tr>
                            <td><strong>planning_integrates_uncertainty</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>text_environment_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>text_environment_description</strong></td>
                            <td>The paper does not evaluate on interactive text-based environments (TextWorld/Jericho/ALFWorld). It demonstrates language and model examples including PCFGs, infinite PCFG/HMM, and a toy planning 'red-light' game represented as stochastic transition models.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>demonstrative metrics: posterior samples, plotted probability estimates (e.g., 'probability of cheating' vs position) and MCMC convergence diagnostics</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>none reported (examples are illustrative; no benchmark comparisons against external baselines)</td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_uncertainty</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_results</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Church provides a flexible formalism for building probabilistic symbolic world models where states, actions and transitions are expressed as executable stochastic programs. Planning is expressed as inference (translating rewards into conditioning) and performed by sampling (exact collapsed rejection where possible, otherwise MCMC over computation traces). Persistent latent structure and uncertainty about object identities or parameters are modeled via mem/DPmem (including Dirichlet-process nonparametrics). The system explicitly represents and reasons about uncertainty, but the paper does not integrate or evaluate large language models or benchmark on text-based interactive environments.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Church: a language for generative models', 'publication_date_yy_mm': '2008-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e965.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e965.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that use probabilistic symbolic world models (such as PPDDL, PDDL, or belief states) for planning in text-based environments, especially those that integrate uncertainty from large language models.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DPmem / stochastic memoizer</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>DPmem (Dirichlet-process-based stochastic memoizer)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A Church-level construct implementing stochastic memoization by sampling a discrete random measure (stick-breaking DP) to cache generative history, enabling exchangeable persistent assignments and nonparametric clustering within generative programs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>DPmem (stochastic memoizer)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>DPmem is a higher-order Church procedure that wraps an admissible generative procedure and returns a memoized stochastic function whose return distribution for repeated arguments is drawn from a sample of a Dirichlet process with base measure given by the underlying procedure. It generalizes deterministic memoization (mem) by allowing repeated calls to share values according to a DP prior, enabling an unbounded number of persistent latent categories or reused substructures within a probabilistic symbolic world model.</td>
                        </tr>
                        <tr>
                            <td><strong>world_model_type</strong></td>
                            <td>nonparametric probabilistic memoization / discrete latent structure via Dirichlet process</td>
                        </tr>
                        <tr>
                            <td><strong>world_model_description</strong></td>
                            <td>Represents persistent assignments by binding per-argument return values to atoms sampled from a DP; supports clustering of objects/arguments into shared latent categories. Transitions remain probabilistic as they are defined by the underlying generative procedure; DPmem governs reuse/identity across repeated evaluations (i.e., models identity uncertainty and latent class structure).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_llm</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>llm_role</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_modeling</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_type</strong></td>
                            <td>uncertainty over persistent assignments / latent clustering (nonparametric discrete uncertainty), model structure uncertainty</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_method</strong></td>
                            <td>Dirichlet process prior (stick-breaking construction implemented in Church), implemented via DPmem and optionally collapsed representations (Chinese restaurant process) for inference; integrated in Monte Carlo inference.</td>
                        </tr>
                        <tr>
                            <td><strong>planning_algorithm</strong></td>
                            <td>When used in planning models, DPmem supplies prior over latent objects/types that planning-as-inference conditions on; planning itself still performed by query/rejection or MCMC</td>
                        </tr>
                        <tr>
                            <td><strong>planning_integrates_uncertainty</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>text_environment_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>text_environment_description</strong></td>
                            <td>Not applied to interactive text environments in this paper; DPmem examples demonstrate persistent latent structure in mixture models and grammar/HMM settings relevant to language modeling but not interactive text games.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>illustrative posterior samples and visualizations for mixture/grammar examples</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>none</td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_uncertainty</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_results</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>DPmem provides a simple, composable way to incorporate nonparametric uncertainty about persistent entities into symbolic generative programs; it supports exchangeable semantics and can be used to model unknown numbers of objects or reused substructures (e.g., latent classes in mixtures, adapted grammars). It is a mechanism for representing uncertainty in symbolic world models, but the paper does not connect this to LLM output uncertainty or text-game planning.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Church: a language for generative models', 'publication_date_yy_mm': '2008-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e965.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e965.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that use probabilistic symbolic world models (such as PPDDL, PDDL, or belief states) for planning in text-based environments, especially those that integrate uncertainty from large language models.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Planning-as-inference (Toussaint et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Planning by probabilistic inference (planning-as-inference) as used in Church</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A method that casts planning / decision-making as probabilistic inference by transforming rewards into a conditioning predicate (an 'ultimate reward') so that posterior sampling yields action distributions that softmax-maximize expected reward.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Probabilistic inference for solving (PO)MDPs</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>planning-as-inference (reward-to-probability transformation)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>The approach maps the planning / control problem to inference by creating a generative model over action sequences and trajectories and defining a predicate whose truth is proportional to reward; conditional sampling (query) from this model yields a posterior over actions that preferentially selects high-reward behavior. In Church, this skeleton is implemented via unfold/transition models, a stochastic terminal? predicate that yields an implicit discount factor, construction of reward-list from final states, and conditioning via reward-pred inside lex-query/query.</td>
                        </tr>
                        <tr>
                            <td><strong>world_model_type</strong></td>
                            <td>probabilistic generative transition model (planning represented as stochastic symbolic program)</td>
                        </tr>
                        <tr>
                            <td><strong>world_model_description</strong></td>
                            <td>States and actions are represented as Church values and procedures; transitions are stochastic Church procedures (forward-model/state-action), terminal conditions are stochastic (to model discounting), and rewards are computed from sampled trajectories; the representation is explicitly probabilistic and planning arises by conditioning on high-reward outcomes.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_llm</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>llm_role</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_modeling</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_type</strong></td>
                            <td>trajectory/state/outcome uncertainty and parameter uncertainty (as expressed in the generative model)</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_method</strong></td>
                            <td>probabilistic program semantics (eval/query), sampling-based inference (rejection sampling, collapsed rejection, MCMC over traces) to integrate over uncertainty when choosing actions</td>
                        </tr>
                        <tr>
                            <td><strong>planning_algorithm</strong></td>
                            <td>inference-based planning via conditional sampling; approximate inference via collapsed rejection sampling and Metropolis-Hastings MCMC over computation traces</td>
                        </tr>
                        <tr>
                            <td><strong>planning_integrates_uncertainty</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>text_environment_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>text_environment_description</strong></td>
                            <td>The paper demonstrates the method on a toy 'red-light' planning game (symbolic state: light color and position) but does not apply it to text-based interactive environments.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>illustrative behavior curves (e.g., probability of 'cheating' vs position) and qualitative analysis of policy stochasticity</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>none (no benchmarks against standard planning algorithms reported)</td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_uncertainty</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_results</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Casting planning as probabilistic inference within Church allows explicit integration of model and outcome uncertainty via the program's probabilistic semantics; conditional sampling yields a softmax-like policy over actions. The paper implements this idea and demonstrates behavior on a toy stochastic domain, but does not evaluate on textual interactive environments nor couple this method with LLM-provided uncertainty.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Church: a language for generative models', 'publication_date_yy_mm': '2008-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e965.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e965.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that use probabilistic symbolic world models (such as PPDDL, PDDL, or belief states) for planning in text-based environments, especially those that integrate uncertainty from large language models.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MCMC over computation traces</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Metropolis-Hastings MCMC on evaluation histories / computation traces</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An MCMC algorithm that proposes local changes to elementary random procedure return values inside a computation trace (equivalence class of evaluation histories), maintaining trace consistency and marginalizing predicate randomness, to approximate query (conditional sampling) in Church.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>MCMC over computation traces (Church inference)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>The paper describes an MCMC algorithm that represents a program execution as a computation trace (graph encoding evaluation calls and environment extensions). Proposals modify return values of elementary random procedures using local proposal kernels K_p; consistency of the trace is restored by recursively re-evaluating dependent nodes and updating proposal probabilities. The MH acceptance uses likelihoods of equivalence classes of histories. This enables approximate conditional sampling (query) when rejection sampling is infeasible.</td>
                        </tr>
                        <tr>
                            <td><strong>world_model_type</strong></td>
                            <td>inference algorithm for probabilistic program world models (trace-augmented MCMC)</td>
                        </tr>
                        <tr>
                            <td><strong>world_model_description</strong></td>
                            <td>Not a world model per se but an inference mechanism operating on symbolic probabilistic world models represented as Church programs; it reasons over evaluation histories (explicit latent choices underlying states and transitions) and thus captures uncertainty about states, parameters, and identity bindings.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_llm</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>llm_role</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_modeling</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_type</strong></td>
                            <td>captures posterior uncertainty over evaluation histories, latent choices, and resulting state trajectories</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_method</strong></td>
                            <td>Metropolis-Hastings MCMC over traces, proposals for elementary random procedures, collapsing predicate randomness when possible, and bookkeeping of proposal probabilities to preserve detailed balance</td>
                        </tr>
                        <tr>
                            <td><strong>planning_algorithm</strong></td>
                            <td>used as the inference backend for planning-as-inference queries; planning decisions are sampled from the posterior produced by this MCMC</td>
                        </tr>
                        <tr>
                            <td><strong>planning_integrates_uncertainty</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>text_environment_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>text_environment_description</strong></td>
                            <td>Algorithm demonstrated on toy models (sprinkler, red-light, infinite mixture examples) but not applied to text-based interactive environments in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>convergence diagnostics (plots shown), posterior estimate trajectories (e.g., probability of rain; expected value plots)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>none</td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_uncertainty</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_results</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Trace-based MCMC provides a general and principled way to perform approximate conditional sampling in expressive probabilistic programs where many latent random choices determine outcomes. The method explicitly accounts for uncertainty over latent choices and supports planning-as-inference by returning posterior distributions over actions/trajectories; however, no integration with LLMs or explicit evaluation on text-based interactive benchmarks is provided.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Church: a language for generative models', 'publication_date_yy_mm': '2008-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Probabilistic inference for solving (PO)MDPs <em>(Rating: 2)</em></li>
                <li>Adaptor grammars: A framework for specifying compositional nonparametric Bayesian models <em>(Rating: 2)</em></li>
                <li>The Infinite PCFG using Hierarchical Dirichlet Processes <em>(Rating: 2)</em></li>
                <li>The infinite hidden Markov model <em>(Rating: 2)</em></li>
                <li>BLOG: Probabilistic models with unknown objects <em>(Rating: 2)</em></li>
                <li>IBAL: A probabilistic rational programming language <em>(Rating: 1)</em></li>
                <li>Markov logic networks <em>(Rating: 1)</em></li>
                <li>PRISM: A symbolic-statistical modeling language <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-965",
    "paper_id": "paper-b8f57509a228f1c84bf67094ec1fa8a99407368b",
    "extraction_schema_id": "extraction-schema-23",
    "extracted_data": [
        {
            "name_short": "Church",
            "name_full": "Church (stochastic programming language)",
            "brief_description": "A Lisp-based universal probabilistic programming language that represents generative processes as evaluable expressions, provides query/eval primitives for conditional sampling, and supports memoization (including nonparametric memoizers) to represent persistent latent structure.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Church",
            "system_description": "Church is a dynamically-typed, Scheme-derived probabilistic programming language in which expressions denote stochastic generative processes. Key components include eval (sampling from the generative model), query (conditional sampling / inference), lex-query for shared random-world programming, mem (memoization) and DPmem (Dirichlet-process-based stochastic memoizer) for persistent latent objects, and a Monte Carlo inference suite (collapsed rejection sampler and a Metropolis-Hastings MCMC over computation traces). Church represents states, actions and transitions as arbitrary Church expressions and procedures (first-class values) and composes them to form probabilistic symbolic world models. The implementation uses evaluation histories / computation traces as the latent structure for MCMC proposals and supports metacircular nesting of queries.",
            "world_model_type": "probabilistic program (stochastic functional / symbolic world model)",
            "world_model_description": "World models are represented as Church expressions/procedures: states and actions are arbitrary symbols or compound values, transitions are stochastic procedures (elementary random procedures like flip, beta, normal, or composed procedures), and persistent state or object identity is expressed via mem/DPmem creating shared random-world bindings. The representation is explicitly probabilistic: evaluation histories define probability measures over executions, transitions are stochastic and can be marginalised; DPmem and other primitives permit nonparametric, discrete latent structure.",
            "uses_llm": false,
            "llm_role": null,
            "llm_model_name": null,
            "uncertainty_modeling": true,
            "uncertainty_type": "state uncertainty, action outcome uncertainty, model (parameter) uncertainty, and uncertainty over latent structure (nonparametric / DP prior)",
            "uncertainty_method": "explicit probability distributions in the program (flip, beta, normal, multinomial, DPmem), marginalization via Monte Carlo sampling (rejection sampling, collapsed rejection) and MCMC over computation traces; stochastic memoization to represent uncertainty over persistent assignments (exchangeable random-world semantics).",
            "planning_algorithm": "planning-as-inference (reward-to-probability transformation) implemented via conditional sampling / query; approximate inference via rejection sampling and Metropolis-Hastings MCMC over evaluation histories",
            "planning_integrates_uncertainty": true,
            "text_environment_name": null,
            "text_environment_description": "The paper does not evaluate on interactive text-based environments (TextWorld/Jericho/ALFWorld). It demonstrates language and model examples including PCFGs, infinite PCFG/HMM, and a toy planning 'red-light' game represented as stochastic transition models.",
            "performance_metric": "demonstrative metrics: posterior samples, plotted probability estimates (e.g., 'probability of cheating' vs position) and MCMC convergence diagnostics",
            "performance_value": null,
            "baseline_comparison": "none reported (examples are illustrative; no benchmark comparisons against external baselines)",
            "has_ablation_uncertainty": false,
            "ablation_results": "",
            "key_findings": "Church provides a flexible formalism for building probabilistic symbolic world models where states, actions and transitions are expressed as executable stochastic programs. Planning is expressed as inference (translating rewards into conditioning) and performed by sampling (exact collapsed rejection where possible, otherwise MCMC over computation traces). Persistent latent structure and uncertainty about object identities or parameters are modeled via mem/DPmem (including Dirichlet-process nonparametrics). The system explicitly represents and reasons about uncertainty, but the paper does not integrate or evaluate large language models or benchmark on text-based interactive environments.",
            "uuid": "e965.0",
            "source_info": {
                "paper_title": "Church: a language for generative models",
                "publication_date_yy_mm": "2008-07"
            }
        },
        {
            "name_short": "DPmem / stochastic memoizer",
            "name_full": "DPmem (Dirichlet-process-based stochastic memoizer)",
            "brief_description": "A Church-level construct implementing stochastic memoization by sampling a discrete random measure (stick-breaking DP) to cache generative history, enabling exchangeable persistent assignments and nonparametric clustering within generative programs.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "DPmem (stochastic memoizer)",
            "system_description": "DPmem is a higher-order Church procedure that wraps an admissible generative procedure and returns a memoized stochastic function whose return distribution for repeated arguments is drawn from a sample of a Dirichlet process with base measure given by the underlying procedure. It generalizes deterministic memoization (mem) by allowing repeated calls to share values according to a DP prior, enabling an unbounded number of persistent latent categories or reused substructures within a probabilistic symbolic world model.",
            "world_model_type": "nonparametric probabilistic memoization / discrete latent structure via Dirichlet process",
            "world_model_description": "Represents persistent assignments by binding per-argument return values to atoms sampled from a DP; supports clustering of objects/arguments into shared latent categories. Transitions remain probabilistic as they are defined by the underlying generative procedure; DPmem governs reuse/identity across repeated evaluations (i.e., models identity uncertainty and latent class structure).",
            "uses_llm": false,
            "llm_role": null,
            "llm_model_name": null,
            "uncertainty_modeling": true,
            "uncertainty_type": "uncertainty over persistent assignments / latent clustering (nonparametric discrete uncertainty), model structure uncertainty",
            "uncertainty_method": "Dirichlet process prior (stick-breaking construction implemented in Church), implemented via DPmem and optionally collapsed representations (Chinese restaurant process) for inference; integrated in Monte Carlo inference.",
            "planning_algorithm": "When used in planning models, DPmem supplies prior over latent objects/types that planning-as-inference conditions on; planning itself still performed by query/rejection or MCMC",
            "planning_integrates_uncertainty": true,
            "text_environment_name": null,
            "text_environment_description": "Not applied to interactive text environments in this paper; DPmem examples demonstrate persistent latent structure in mixture models and grammar/HMM settings relevant to language modeling but not interactive text games.",
            "performance_metric": "illustrative posterior samples and visualizations for mixture/grammar examples",
            "performance_value": null,
            "baseline_comparison": "none",
            "has_ablation_uncertainty": false,
            "ablation_results": "",
            "key_findings": "DPmem provides a simple, composable way to incorporate nonparametric uncertainty about persistent entities into symbolic generative programs; it supports exchangeable semantics and can be used to model unknown numbers of objects or reused substructures (e.g., latent classes in mixtures, adapted grammars). It is a mechanism for representing uncertainty in symbolic world models, but the paper does not connect this to LLM output uncertainty or text-game planning.",
            "uuid": "e965.1",
            "source_info": {
                "paper_title": "Church: a language for generative models",
                "publication_date_yy_mm": "2008-07"
            }
        },
        {
            "name_short": "Planning-as-inference (Toussaint et al.)",
            "name_full": "Planning by probabilistic inference (planning-as-inference) as used in Church",
            "brief_description": "A method that casts planning / decision-making as probabilistic inference by transforming rewards into a conditioning predicate (an 'ultimate reward') so that posterior sampling yields action distributions that softmax-maximize expected reward.",
            "citation_title": "Probabilistic inference for solving (PO)MDPs",
            "mention_or_use": "use",
            "system_name": "planning-as-inference (reward-to-probability transformation)",
            "system_description": "The approach maps the planning / control problem to inference by creating a generative model over action sequences and trajectories and defining a predicate whose truth is proportional to reward; conditional sampling (query) from this model yields a posterior over actions that preferentially selects high-reward behavior. In Church, this skeleton is implemented via unfold/transition models, a stochastic terminal? predicate that yields an implicit discount factor, construction of reward-list from final states, and conditioning via reward-pred inside lex-query/query.",
            "world_model_type": "probabilistic generative transition model (planning represented as stochastic symbolic program)",
            "world_model_description": "States and actions are represented as Church values and procedures; transitions are stochastic Church procedures (forward-model/state-action), terminal conditions are stochastic (to model discounting), and rewards are computed from sampled trajectories; the representation is explicitly probabilistic and planning arises by conditioning on high-reward outcomes.",
            "uses_llm": false,
            "llm_role": null,
            "llm_model_name": null,
            "uncertainty_modeling": true,
            "uncertainty_type": "trajectory/state/outcome uncertainty and parameter uncertainty (as expressed in the generative model)",
            "uncertainty_method": "probabilistic program semantics (eval/query), sampling-based inference (rejection sampling, collapsed rejection, MCMC over traces) to integrate over uncertainty when choosing actions",
            "planning_algorithm": "inference-based planning via conditional sampling; approximate inference via collapsed rejection sampling and Metropolis-Hastings MCMC over computation traces",
            "planning_integrates_uncertainty": true,
            "text_environment_name": null,
            "text_environment_description": "The paper demonstrates the method on a toy 'red-light' planning game (symbolic state: light color and position) but does not apply it to text-based interactive environments.",
            "performance_metric": "illustrative behavior curves (e.g., probability of 'cheating' vs position) and qualitative analysis of policy stochasticity",
            "performance_value": null,
            "baseline_comparison": "none (no benchmarks against standard planning algorithms reported)",
            "has_ablation_uncertainty": false,
            "ablation_results": "",
            "key_findings": "Casting planning as probabilistic inference within Church allows explicit integration of model and outcome uncertainty via the program's probabilistic semantics; conditional sampling yields a softmax-like policy over actions. The paper implements this idea and demonstrates behavior on a toy stochastic domain, but does not evaluate on textual interactive environments nor couple this method with LLM-provided uncertainty.",
            "uuid": "e965.2",
            "source_info": {
                "paper_title": "Church: a language for generative models",
                "publication_date_yy_mm": "2008-07"
            }
        },
        {
            "name_short": "MCMC over computation traces",
            "name_full": "Metropolis-Hastings MCMC on evaluation histories / computation traces",
            "brief_description": "An MCMC algorithm that proposes local changes to elementary random procedure return values inside a computation trace (equivalence class of evaluation histories), maintaining trace consistency and marginalizing predicate randomness, to approximate query (conditional sampling) in Church.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "MCMC over computation traces (Church inference)",
            "system_description": "The paper describes an MCMC algorithm that represents a program execution as a computation trace (graph encoding evaluation calls and environment extensions). Proposals modify return values of elementary random procedures using local proposal kernels K_p; consistency of the trace is restored by recursively re-evaluating dependent nodes and updating proposal probabilities. The MH acceptance uses likelihoods of equivalence classes of histories. This enables approximate conditional sampling (query) when rejection sampling is infeasible.",
            "world_model_type": "inference algorithm for probabilistic program world models (trace-augmented MCMC)",
            "world_model_description": "Not a world model per se but an inference mechanism operating on symbolic probabilistic world models represented as Church programs; it reasons over evaluation histories (explicit latent choices underlying states and transitions) and thus captures uncertainty about states, parameters, and identity bindings.",
            "uses_llm": false,
            "llm_role": null,
            "llm_model_name": null,
            "uncertainty_modeling": true,
            "uncertainty_type": "captures posterior uncertainty over evaluation histories, latent choices, and resulting state trajectories",
            "uncertainty_method": "Metropolis-Hastings MCMC over traces, proposals for elementary random procedures, collapsing predicate randomness when possible, and bookkeeping of proposal probabilities to preserve detailed balance",
            "planning_algorithm": "used as the inference backend for planning-as-inference queries; planning decisions are sampled from the posterior produced by this MCMC",
            "planning_integrates_uncertainty": true,
            "text_environment_name": null,
            "text_environment_description": "Algorithm demonstrated on toy models (sprinkler, red-light, infinite mixture examples) but not applied to text-based interactive environments in this paper.",
            "performance_metric": "convergence diagnostics (plots shown), posterior estimate trajectories (e.g., probability of rain; expected value plots)",
            "performance_value": null,
            "baseline_comparison": "none",
            "has_ablation_uncertainty": false,
            "ablation_results": "",
            "key_findings": "Trace-based MCMC provides a general and principled way to perform approximate conditional sampling in expressive probabilistic programs where many latent random choices determine outcomes. The method explicitly accounts for uncertainty over latent choices and supports planning-as-inference by returning posterior distributions over actions/trajectories; however, no integration with LLMs or explicit evaluation on text-based interactive benchmarks is provided.",
            "uuid": "e965.3",
            "source_info": {
                "paper_title": "Church: a language for generative models",
                "publication_date_yy_mm": "2008-07"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Probabilistic inference for solving (PO)MDPs",
            "rating": 2
        },
        {
            "paper_title": "Adaptor grammars: A framework for specifying compositional nonparametric Bayesian models",
            "rating": 2
        },
        {
            "paper_title": "The Infinite PCFG using Hierarchical Dirichlet Processes",
            "rating": 2
        },
        {
            "paper_title": "The infinite hidden Markov model",
            "rating": 2
        },
        {
            "paper_title": "BLOG: Probabilistic models with unknown objects",
            "rating": 2
        },
        {
            "paper_title": "IBAL: A probabilistic rational programming language",
            "rating": 1
        },
        {
            "paper_title": "Markov logic networks",
            "rating": 1
        },
        {
            "paper_title": "PRISM: A symbolic-statistical modeling language",
            "rating": 1
        }
    ],
    "cost": 0.0122505,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Church: a language for generative models</h1>
<p>Noah D. Goodman, Vikash K. Mansinghka,<br>Daniel Roy, Keith Bonawitz \&amp; Joshua B. Tenenbaum<br>MIT BCS/CSAIL<br>Cambridge, MA 02139</p>
<h4>Abstract</h4>
<p>Formal languages for probabilistic modeling enable re-use, modularity, and descriptive clarity, and can foster generic inference techniques. We introduce Church, a universal language for describing stochastic generative processes. Church is based on the Lisp model of lambda calculus, containing a pure Lisp as its deterministic subset. The semantics of Church is defined in terms of evaluation histories and conditional distributions on such histories. Church also includes a novel language construct, the stochastic memoizer, which enables simple description of many complex non-parametric models. We illustrate language features through several examples, including: a generalized Bayes net in which parameters cluster over trials, infinite PCFGs, planning by inference, and various non-parametric clustering models. Finally, we show how to implement query on any Church program, exactly and approximately, using Monte Carlo techniques.</p>
<h2>1 INTRODUCTION</h2>
<p>Probabilistic models have proven to be an enormously useful tool in artificial intelligence, machine learning, and cognitive science. Most often these models are specified in a combination of natural and mathematical language, and inference for each new model is implemented by hand. Stochastic programming languages [e.g. 12, 14, 10] aim to tame the model-building process by giving a formal language which provides simple, uniform, and re-usable descriptions of a wide class of models, and supports generic inference techniques. In this paper we present the Church stochastic</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup>programming language (named for computation pioneer Alonzo Church), a universal language for describing generative processes and conditional queries over them. Because this language is based on Church's lambda calculus, expressions, which represent generative models, may be arbitrarily composed and abstracted. The distinctive features of Church, and the main contributions of this paper, are: 1) a Lisp-like language specification in which we view evaluation as sampling and query as conditional sampling, 2) a stochastic memoizer, which allows separate evaluations to share generative history and enables easy description of non-parametric probabilistic models, and, 3) generic schemes for exact and approximate inference, which implement the query primitive, so that any Church program may be run without writing specialpurpose inference code.</p>
<h2>2 THE CHURCH LANGUAGE</h2>
<p>The Church language is based upon a pure subset of the functional language Scheme [6], a Lisp dialect. Church is a dynamically-typed, applicative-order language, in which procedures are first-class and expressions are values. Church expressions describe generative processes: the meaning of an expression is specified through a primitive procedure eval, which samples from the process, and a primitive procedure query, which generalizes eval to sample conditionally. In true Lisp spirit, eval and query are ordinary procedures that may be nested within a Church program. Randomness is introduced through stochastic primitive functions; memoization allows random computations to be reused.</p>
<p>Church expressions have the form:</p>
<p>$$
\begin{aligned}
&amp; \text { expression }::=c|x|\left(e_{1} e_{2} \ldots\right) \mid(\text { lambda }(x \ldots) e) \mid \
&amp; \left(\text { if } e_{1} e_{2} e_{3}\right) \mid(\text { define } x e) \mid(\text { quote } e)
\end{aligned}
$$</p>
<p>Here $x$ stands for a variable (from a countable set of</p>
<p>variable symbols), $e_{i}$ for expressions, and $c$ for a (primitive) constant. (We often write ' $e$ as shorthand for (quote e).)</p>
<p>The constants include primitive data types (nil, Boolean, char, integer, fixed-precision real, etc.), and standard functions to build data structures (notably pair, first, and rest for lists) and manipulate basic types (e.g. and, not) ${ }^{1}$. As in most programming languages, all primitive types are countable; real numbers are approximated by either fixed- or floating-precision arithmetic. A number of standard (deterministic) functions, such as the higher-order function map, are provided as a standard library, automatically defined in the global environment. Other standard Scheme constructs are provided-such as (let ((a a-def) (b b-def) ...) body), which introduces names that can be used in body, and is sugar for nested lambdas.</p>
<p>Church values include Church expressions, and procedures; if $v_{1} \ldots v_{n}$ are Church values the list $\left(v_{1} \ldots v_{n}\right)$ is a Church value. A Church environment is a list of pairs consisting of a variable symbol and a value (the variable is bound to the value); note that an environment is a Church value. Procedures come in two types: Ordinary procedures are triples, (body, args, env), of a Church expression (the body), a list of variable symbols (the formal parameters, or arguments), and an environment. Elementary random procedures are ordinary procedures that also have a distribution func-tion-a probability function that reports the probability $P($ value $\mid$ env, args) of a return value from evaluating the body (via the eval procedure described below) given env and values of the formal parameters ${ }^{2}$.</p>
<p>To provide an initial set of elementary random procedures we allow stochastic primitive functions, in addition to the usual constants, that randomly sample a return value depending only on the current environment. Unlike other constants, these random functions are available only wrapped into elementary random procedures: (fun, args, env, dist), where dist $=P($ value $\mid$ env, args) is the probability function for fun. We include several elementary random procedures, such as flip which flips a fair coin (or flips a weighted coin when called with a weight argument).</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup>A Church expression defines a generative process via the recursive evaluation procedure, eval. This primitive procedure takes an expression and an environment and returns a value-it is an environment model, shared with Scheme, of Church's lambda calculus [4, 6]. The evaluation rules are given in Fig. 1. An evaluation history for an expression $e$ is the sequence of recursive calls to eval, and their return values, made by (eval 'e env). The probability of a finite evaluation history is the product of the probabilities for each elementary random procedure evaluation in this history ${ }^{3}$. The weight of an expression in a particular environment is the sum of the probabilities of all of its finite evaluation histories. An expression is admissible in an environment if it has weight one, and a procedure is admissible if its body is admissible in its environment for all values of its arguments. An admissible expression defines a distribution on evaluation histories (we make this claim precise in section 2.2). Note that an admissible expression can have infinite histories, but the set of infinite histories must have probability zero. Thus admissibility can be thought of as the requirement that evaluation of an expression halts with probability one. Marginalizing this distribution over histories results in a distribution on values, which we write $\mu(\mathrm{e}$, env). Thus, (eval ' $e$ env), for admissible $e$, returns a sample from $\mu(\mathrm{e}$, env).</p>
<p>The procedure eval allows us to interpret Church as a language for generative processes, but for useful probabilistic inference we must be able to sample from a distribution conditioned on some assertions (for instance the posterior probability of a hypothesis conditioned on observed data). The procedure (query ' $e p$ env) is defined to be a procedure which samples a value from $\mu(\mathrm{e}$, env) conditioned on the predicate procedure $p$ returning True when applied to the value of (eval ' $e$ env). The environment argument env is optional, defaulting to the current environment. (Note that the special case of query when the predicate $p$ is the constant procedure (lambda (x) True) defines the same distribution on values as eval.) For example, one might write (query '(pair (flip) (flip)) (lambda (v) (+ (first v) (last v)))) to describe the conditional distribution of two flips given that at least one flip landed heads. If $e$ or $p$ are not admissible in env the query result is undefined. We describe this conditional distribution, and conditions for its welldefinedness, more formally in Theorem 2.3. In Section 4 we consider Monte Carlo techniques for implementing query.</p>
<p><sup id="fnref:1"><a class="footnote-ref" href="#fn:1">2</a></sup></p>
<ul>
<li>(eval ' $c$ env): For constant $c$, return $c$ (env).</li>
<li>(eval ' $x$ env): Look-up symbol $x$ in env, return the value it is bound to.</li>
<li>(eval ' $\left(e_{1} e_{2} \ldots\right)$ env): Evaluate each (eval ' $e_{i}$ env). The value of (eval ' $e_{1}$ env) should be a procedure (body, $x_{2} \ldots$, env2). Make env3 by extending env2, binding $x_{2} \ldots$ to the return values of $e_{2} \ldots$ Return the value of (eval body env3).</li>
<li>(eval '(lambda $\left.(x \ldots\right)$ e) env): Return the procedure $(e, x \ldots$, env $)$.</li>
<li>(eval '(if $e_{1} e_{2} e_{3}$ ) env): If (eval $e_{1}$ env) returns True return the return value of (eval $e_{2}$ env), otherwise of (eval $e_{3}$ env).</li>
<li>(eval '(quote e) env): Return the expression $e$ (as a value).</li>
<li>(eval '(define $x$ e) env): Extend env by binding the value of (eval ' $e$ env) to $x$; return the extended environment.</li>
</ul>
<p>Figure 1: An informal definition of the eval procedure. If preconditions of these descriptions fail the constant value error is returned. Note that constants represent (possibly stochastic) functions from environments to values-truly "constant" constants return themselves.</p>
<p>It can be awkward in practice to write programs using query, because many random values must be explicitly passed from the query expression to the predicate through the return value. An alternative is to provide a means to name random values which are shared by all evaluations, building up a "random world" within the query. To enable a this style of programming, we provide the procedure lex-query (for "lexicalizing query") which has the form:</p>
<div class="codehilite"><pre><span></span><code>(lex-query
    &#39;( (A A-definition)
        (B B-definition)
        ...)
    &#39;e &#39;p)
</code></pre></div>

<p>where the first argument binds a lexicon of symbols to definitions, which are available in the environment in which the remaining (query and predicate) expressions are evaluated. In this form the predicate is an expression, and the final environment argument is omittedthe current environment is used.</p>
<p>A program in Church consists of a sequence of Church expressions-this sequence is called the top level. Any definitions at the top level are treated as extending the global (i.e. initial) environment, which then is used to evaluate the remaining top-level expressions. For instance:
(define A $e_{1}$ ) $e_{2}$
is treated as:
(eval ' $e_{2}$ (eval '(define A $e_{1}$ ) global-env)).</p>
<h3>2.1 Stochastic Memoization</h3>
<p>In deterministic computation, memoization is a technique for efficient implementation that does not affect the language semantics: the first time a (purely functional) procedure is evaluated with given arguments its return value is recorded; thereafter evaluations of that procedure with those arguments directly return this value, without re-evaluating the procedure body. Memoization of a stochastic program can radically change the semantics: if flip is an ordinary random procedure (= (flip) (flip)) is True with probability 0.5 , but if flip is memoized this expression is True with probability one. More generally, a collection of memoized functions has a random-world semantics as discussed in [10]. In Section 3 we use memoization together with lex-query to describe generative processes involving an unknown number of objects with persistent features, similar to the BLOG language [12].
To formally define memoization in Church, we imagine extending the notion of environment to allow countably many variables to be bound in an environment. The higher-order procedure mem takes an admissibleprocedure and returns another procedure: if (eval $e$ env) returns the admissible procedure (body, args, env2), then (eval '(mem e) env) returns the memoized procedure (mfun ${ }_{e}$, args, env+), where:</p>
<ul>
<li>env+ is env2 (notionally) extended with a symbol $\mathrm{V}_{\text {val }}$, for each value val, bound to a value drawn from the distribution $\mu((e v a l)$, env).</li>
<li>mfun $<em e="e">{e}$ is a new constant function such that mfun ${ }</em>$.}$ applied to the environment env+ extended with args bound to val returns the value bound to $\mathrm{V}_{\text {val }</li>
</ul>
<p>This definition implies that infinitely many random choices may be made when a memoized random procedure is created-the notion of admissibility must be extended to expressions which involve mem. In the next section we describe an appropriate extension of admissibility, such that admissible expressions still define a marginal distribution on values, and the conditional distributions defining query are well-formed.</p>
<p>Ordinary memoization becomes a semantically meaningful construct within stochastic languages. This suggests that there may be useful generalizations of mem, which are not apparent in non-stochastic computation. Indeed, instead of always returning the initial value or always re-evaluating, one could stochastically decide on each evaluation whether to use a previously computed value or evaluate anew. We define such a stochastic memoizer DPmem by using the Dirichlet process (DP) [20]-a distribution on discrete distributions</p>
<div class="codehilite"><pre><span></span><code><span class="ss">(</span><span class="nv">define</span><span class="w"> </span><span class="ss">(</span><span class="nv">DP</span><span class="w"> </span><span class="nv">alpha</span><span class="w"> </span><span class="nv">proc</span><span class="ss">)</span>
<span class="w">    </span><span class="ss">(</span><span class="nv">let</span><span class="w"> </span><span class="ss">((</span><span class="nv">sticks</span><span class="w"> </span><span class="ss">(</span><span class="nv">mem</span><span class="w"> </span><span class="ss">(</span><span class="nv">lambda</span><span class="w"> </span><span class="nv">x</span><span class="w"> </span><span class="ss">(</span><span class="nv">beta</span><span class="w"> </span><span class="mi">1</span>.<span class="mi">0</span><span class="w"> </span><span class="nv">alpha</span><span class="ss">))))</span>
<span class="w">        </span><span class="ss">(</span><span class="nv">atoms</span><span class="w"> </span><span class="ss">(</span><span class="nv">mem</span><span class="w"> </span><span class="ss">(</span><span class="nv">lambda</span><span class="w"> </span><span class="nv">x</span><span class="w"> </span><span class="ss">(</span><span class="nv">proc</span><span class="ss">)))))</span>
<span class="w">    </span><span class="ss">(</span><span class="nv">lambda</span><span class="w"> </span><span class="ss">()</span><span class="w"> </span><span class="ss">(</span><span class="nv">atoms</span><span class="w"> </span><span class="ss">(</span><span class="nv">pick</span><span class="o">-</span><span class="nv">a</span><span class="o">-</span><span class="nv">stick</span><span class="w"> </span><span class="nv">sticks</span><span class="w"> </span><span class="mi">1</span><span class="ss">)))))</span>
<span class="ss">(</span><span class="nv">define</span><span class="w"> </span><span class="ss">(</span><span class="nv">pick</span><span class="o">-</span><span class="nv">a</span><span class="o">-</span><span class="nv">stick</span><span class="w"> </span><span class="nv">sticks</span><span class="w"> </span><span class="nv">J</span><span class="ss">)</span>
<span class="w">    </span><span class="ss">(</span><span class="k">if</span><span class="w"> </span><span class="ss">(</span><span class="o">&lt;</span><span class="w"> </span><span class="ss">(</span><span class="k">random</span><span class="ss">)</span><span class="w"> </span><span class="ss">(</span><span class="nv">sticks</span><span class="w"> </span><span class="nv">J</span><span class="ss">))</span>
<span class="w">        </span><span class="nv">J</span>
<span class="w">        </span><span class="ss">(</span><span class="nv">pick</span><span class="o">-</span><span class="nv">a</span><span class="o">-</span><span class="nv">stick</span><span class="w"> </span><span class="nv">sticks</span><span class="w"> </span><span class="ss">(</span><span class="o">+</span><span class="w"> </span><span class="nv">J</span><span class="w"> </span><span class="mi">1</span><span class="ss">))))</span>
<span class="ss">(</span><span class="nv">define</span><span class="w"> </span><span class="ss">(</span><span class="nv">DPmem</span><span class="w"> </span><span class="nv">alpha</span><span class="w"> </span><span class="nv">proc</span><span class="ss">)</span>
<span class="w">    </span><span class="ss">(</span><span class="nv">let</span><span class="w"> </span><span class="ss">((</span><span class="nv">dps</span><span class="w"> </span><span class="ss">(</span><span class="nv">mem</span><span class="w"> </span><span class="ss">(</span><span class="nv">lambda</span><span class="w"> </span><span class="nv">args</span>
<span class="w">                                    </span><span class="ss">(</span><span class="nv">DP</span><span class="w"> </span><span class="nv">alpha</span>
<span class="w">                                    </span><span class="ss">(</span><span class="nv">lambda</span><span class="w"> </span><span class="ss">()</span><span class="w"> </span><span class="ss">(</span><span class="nv">apply</span><span class="w"> </span><span class="nv">proc</span><span class="w"> </span><span class="nv">args</span><span class="ss">))</span>
<span class="w">            </span><span class="ss">)))))</span>
<span class="w">    </span><span class="ss">(</span><span class="nv">lambda</span><span class="w"> </span><span class="nv">argsin</span><span class="w"> </span><span class="ss">((</span><span class="nv">apply</span><span class="w"> </span><span class="nv">dps</span><span class="w"> </span><span class="nv">argsin</span><span class="ss">)))</span><span class="w"> </span><span class="ss">))</span>
</code></pre></div>

<p>Figure 2: Church implementation of the Dirichlet Process, via stick breaking, and DPmem. (Evaluating (apply proc args) in env for $\operatorname{args}=\left(\mathrm{a}<em 1="1">{1} \ldots\right)$ is equivalent to (eval '(proc $\mathrm{a}</em> \ldots$ ) env).)
built from an underlying base measure. For an admissible procedure e, the expression (DPmem $a e$ ) evaluates in env to a procedure which samples from a (fixed) sample from the DP with base measure $\mu(e$, env) and concentration parameter $a$. (When $a=0$, DPmem reduces to mem, when $a=\infty$, it reduces to the identity.) The notion of using the Dirichlet process to cache generative histories was first suggested in Johnson et al. [5], in the context of grammar learning. In Fig. 2 we write the Dirichlet Process and DPmem directly in Church, via a stick-breaking representation. This gives a definition of these objects, proves that they are semantically well-formed (provided the rest of the language is), and gives one possible implementation.</p>
<p>We pause here to explain choices made in the language definition. Programs written with pure functions, those that always return the same value when applied to the same arguments, have a number of advantages. It is clear that a random function cannot be pure, yet there should be an appropriate generalization of purity which maintains some locality of information. We believe the right notion of purity in a stochastic language is exchangeability: if an expression is evaluated several times in the same environment, the distribution on return values is invariant to the order of evaluations. This exchangeability is exploited by the Metropolis-Hastings algorithm for approximating query given in Section 4.</p>
<p>Mutable state (or an unpleasant, whole-program transformation into continuation passing style) is necessary to implement Church, both to model randomness and to implement mem using finite computation. However, this statefulness preserves exchangeability. Understanding the ways in which other stateful language constructs - in particular, primitives for
the construction and modification of mutable statemight aid in the description of stochastic processes remains an important area for future work.</p>
<h3>2.2 Semantic Correctness</h3>
<p>In this section we give formal statements of the claims above, needed to specify the semantics of Church, and sketch their proofs. Let Church ${ }^{-}$denote the set of Church expressions that do not include mem.
Lemma 2.1. If $e \in$ Church $^{-}$then the weight of e in a given environment is well-defined and $\leq 1$.</p>
<p>Proof sketch. Arrange the recursive calls to eval into a tree with an evaluation at each node and edges connecting successive applications of eval-if a node indicates the evaluation of an elementary random procedure there will be several edges descending from this node (one for each possible return value), and these edges are labeled with their probability. A history is a path from root to leaf in this tree and its probability is the product of the labels along the path. Let $W_{n}$ indicate the sum of probabilities of paths of length $n$ or less. The claim is now that $\lim <em n="n">{n \rightarrow \infty} W</em>$ converges and is bounded above by 1 . The bound follows because the sum of labels below any random node is 1 ; convergence then follows from the monotone convergence theorem because the labels are non-negative.</p>
<p>We next extend the notion of admissibility to arbitrary Church expressions involving mem. To compute the probability of an evaluation history we must include the probability of calls to mem - that is, the probability of drawing each return value $\mathrm{V}<em _text="\text" _val="{val">{\text {val }}$. Because there are infinitely many $\mathrm{V}</em>$-in particular they must evaluate all memoized procedures on the same arguments with the same return values. The probability of an equivalence class of histories is the marginal probability over all unused arguments and return values, and this is non-zero. The weight of an expression can now be defined as the sum over equivalence classes of finite histories.
Lemma 2.2. The admissibility of a Church expression in a given environment is well defined, and any expression e admissible in environment env defines a distribution $\mu\left(\mathrm{e}\right.$, env) on return values of (eval ' $e$ env).}}$, the probability of many histories will then be zero, therefore we pass to equivalence classes of histories. Two histories are equivalent if they are the same up to the values bound to $\mathrm{V}_{\text {val }</p>
<p>Proof sketch: The proof is by induction on the number of times mem is used. Take as base case expressions without mem; by Lemma 2.1 the weight is well defined, so the set of admissible expressions is also well defined.</p>
<p>This function provides persistent class assignments to objects, where classes are symbols drawn from a pool with DP prior:
(define drawclass (DPmem 1.0 gensym))
(define class (mem (lambda (obj) (drawclass))))
For the beta-binomial model there's a coin weight for each feature/class pair, and each object has features that depend only on it's type:</p>
<div class="codehilite"><pre><span></span><code>(define coin-weight
    (mem (lambda (feat obj-class) (beta 1 1))) )
(define value
    (mem (lambda (obj feat)
        (flip (coin-weight feat (class obj))) )))
</code></pre></div>

<p>For a gaussian-mixture on continuous data (with known variance), we just change the code for generating values:</p>
<div class="codehilite"><pre><span></span><code>(define mean
    (mem (lambda (obj-class) (normal 0.0 10.0))) )
(define cont-value
    (mem (lambda (obj)
        (normal (mean (class obj)) 1.0) )))
</code></pre></div>

<p>The infinite relational model [7] with continuous data is similar, but means depend on classes of two objects:</p>
<div class="codehilite"><pre><span></span><code>(define irm-mean
    (mem (lambda (obj-class1 obj-class2)
        (normal 0.0 10.0) )))
(define irm-value
    (mem (lambda (obj1 obj2)
        (normal (irm-mean (class obj1) (class obj2))
            1.0 ))))
</code></pre></div>

<p>Figure 3: Church expressions for infinite mixture type models, showing use of the random-world programming style in which objects have persistent properties. Functions beta and normal generate samples from these standard distributions.</p>
<p>Now, assume $p=$ (body, args, env) is an admissible procedure with well defined distribution on return values. The return from (mem p) is well defined, because the underlying measure $\mu(\mathrm{p}$, env) is well defined. It is then straightforward to show that any expression involving (mem p), but no other new memoized procedures, has a well defined weight. The induction step follows.</p>
<p>A subtlety in this argument comes if one wishes to express recursive memoized functions such as:
(define F (mem (lambda (x) (.. F ...)) )).
Prima facie this recursion seems to eliminate the memoization-free base case. However, any recursive definition (or set of definitions) may be re-written without recursion in terms of a fixed-point combinator: (define F (fix ...)). With this replacement made we are reduced to the expected situation-application of fix may fail to halt, in which case F will be inadmissible, but the weight is well defined.</p>
<p>Lemma 2.2 only applies to expressions involving mem
for admissible procedures - a relaxation is possible for partially admissible procedures in some situations. From Lemma 2.2 it is straightforward to prove:
Theorem 2.3. Assume expression e and procedure $p$ are admissible in env, and let $V$ be a random value distributed according to $\mu(\mathrm{e}, \mathrm{env})$. If there exists a value $v$ in the support of $\mu(\mathrm{e}, \mathrm{env})$ and True has non-zero probability under $\mu((p v)$, env), then the conditional probability</p>
<p>$$
P(V=\text { val } \mid(\text { eval } \prime(p V) \text { env })=\text { True })
$$</p>
<p>is well defined.
Theorem 2.3 shows that query is a well-posed procedure; in Section 4 we turn to the technical challenge of actually implementing query.</p>
<h2>3 EXAMPLE PROGRAMS</h2>
<p>In this section we describe a number of example programs, stressing the ability of Church to express a range of standard generative models. As our first example, we describe diagnostic causal reasoning in a simple scenario: given that the grass is wet on a given day, did it rain (or did the sprinkler come on)? In outline of this might take the form of the query:</p>
<div class="codehilite"><pre><span></span><code>(lex-query
    &#39;((grass-is-wet ...)
        (rain ...)
        (sprinkler ...)
    &#39;(rain &#39;day2)
    &#39;(grass-is-wet &#39;day2) )
</code></pre></div>

<p>where we define a causal model by defining functions that describe whether it rained, whether the sprinkler was on, and whether the grass is wet. The function grass-is-wet will depend on both rain and sprinkler-first we define a noisy-or function:</p>
<div class="codehilite"><pre><span></span><code>(define (noisy-or a astrength b bstrength baserate)
    (or (and (flip astrength) a)
        (and (flip bstrength) b)
        (flip baserate)))
</code></pre></div>

<p>Using this noisy-or function, and a look-up table for various weights, we can fill in the causal model:</p>
<div class="codehilite"><pre><span></span><code>(lex-query
    &#39;((weight (lambda (ofwhat)
        (case ofwhat
            ((&#39;rain-str) 0.9)
            ((&#39;rain-prior) 0.3)
            ..etc..)))
    (grass-is-wet (mem (lambda (day)
        (noisy-or
            (rain day) (weight &#39;rain-str)
            (sprinkler day) (weight &#39;sprinkler-str)
            (weight &#39;grass-baserate)))))
</code></pre></div>

<p>This deterministic higher-order function defines the basic structure of stochastic transition models:</p>
<div class="codehilite"><pre><span></span><code><span class="ss">(</span><span class="nv">define</span><span class="w"> </span><span class="ss">(</span><span class="nv">unfold</span><span class="w"> </span><span class="nv">expander</span><span class="w"> </span><span class="nv">symbol</span><span class="ss">)</span>
<span class="w">    </span><span class="ss">(</span><span class="k">if</span><span class="w"> </span><span class="ss">(</span><span class="nv">terminal</span>?<span class="w"> </span><span class="nv">symbol</span><span class="ss">)</span>
<span class="w">        </span><span class="nv">symbol</span>
<span class="w">            </span><span class="ss">(</span><span class="nv">map</span><span class="w"> </span><span class="ss">(</span><span class="nv">lambda</span><span class="w"> </span><span class="ss">(</span><span class="nv">x</span><span class="ss">)</span><span class="w"> </span><span class="ss">(</span><span class="nv">unfold</span><span class="w"> </span><span class="nv">expander</span><span class="w"> </span><span class="nv">x</span><span class="ss">))</span>
<span class="w">                </span><span class="ss">(</span><span class="nv">expander</span><span class="w"> </span><span class="nv">symbol</span><span class="ss">)</span><span class="w"> </span><span class="ss">)))</span>
</code></pre></div>

<p>A Church model for a PCFG transitions via a fixed multinomial over expansions for each symbol:</p>
<div class="codehilite"><pre><span></span><code>(define (PCFG-productions symbol)
    (cond ((eq? symbol &#39;S)
        (multinomial &#39;((S a) (T a)) &#39;(0.2 0.8)) )
        ((eq? symbol &#39;T)
            (multinomial &#39;((T b) (a b)) &#39;(0.3 0.7)) ))
</code></pre></div>

<p>(define (sample-pcfg) (unfold PCFG-productions 'S))</p>
<p>The HDP-HMM [2] uses memoized symbols for states and memoizes transitions:</p>
<div class="codehilite"><pre><span></span><code><span class="ss">(</span><span class="nv">define</span><span class="w"> </span><span class="nv">get</span><span class="o">-</span><span class="nv">symbol</span><span class="w"> </span><span class="ss">(</span><span class="nv">DPmem</span><span class="w"> </span><span class="mi">1</span>.<span class="mi">0</span><span class="w"> </span><span class="nv">gensym</span><span class="ss">))</span>
<span class="ss">(</span><span class="nv">define</span><span class="w"> </span><span class="nv">get</span><span class="o">-</span><span class="nv">observation</span><span class="o">-</span><span class="nv">model</span>
<span class="w">    </span><span class="ss">(</span><span class="nv">mem</span><span class="w"> </span><span class="ss">(</span><span class="nv">lambda</span><span class="w"> </span><span class="ss">(</span><span class="nv">symbol</span><span class="ss">)</span><span class="w"> </span><span class="ss">(</span><span class="nv">make</span><span class="o">-</span><span class="mi">100</span><span class="o">-</span><span class="nv">sided</span><span class="o">-</span><span class="nv">die</span><span class="ss">))))</span>
<span class="ss">(</span><span class="nv">define</span><span class="w"> </span><span class="nv">ihmm</span><span class="o">-</span><span class="nv">transition</span>
<span class="w">    </span><span class="ss">(</span><span class="nv">DPmem</span><span class="w"> </span><span class="mi">1</span>.<span class="mi">0</span><span class="w"> </span><span class="ss">(</span><span class="nv">lambda</span><span class="w"> </span><span class="ss">(</span><span class="nv">state</span><span class="ss">)</span>
<span class="w">        </span><span class="ss">(</span><span class="k">if</span><span class="w"> </span><span class="ss">(</span><span class="nv">flip</span><span class="ss">)</span><span class="w"> </span><span class="err">&#39;stop (get-symbol))</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code>(define (ihmm-expander symbol)
    (list ((get-observation-model symbol))
        (ihmm-transition symbol) ))
(define (sample-ihmm) (unfold ihmm-expander &#39;S))
</code></pre></div>

<p>The HDP-PCFG [8] is also straightforward:</p>
<div class="codehilite"><pre><span></span><code><span class="p">(</span><span class="nx">define</span><span class="w"> </span><span class="nx">terms</span><span class="w"> </span><span class="err">&#39;</span><span class="p">(</span><span class="w"> </span><span class="nx">a</span><span class="w"> </span><span class="nx">b</span><span class="w"> </span><span class="nx">c</span><span class="w"> </span><span class="nx">d</span><span class="p">))</span>
<span class="p">(</span><span class="nx">define</span><span class="w"> </span><span class="nx">term</span><span class="o">-</span><span class="nx">probs</span><span class="w"> </span><span class="err">&#39;</span><span class="p">(</span><span class="m m-Double">.1</span><span class="w"> </span><span class="m m-Double">.2</span><span class="w"> </span><span class="m m-Double">.2</span><span class="w"> </span><span class="m m-Double">.5</span><span class="p">))</span>
<span class="p">(</span><span class="nx">define</span><span class="w"> </span><span class="nx">rule</span><span class="o">-</span><span class="k">type</span>
<span class="w">    </span><span class="p">(</span><span class="nx">mem</span><span class="w"> </span><span class="p">(</span><span class="nx">lambda</span><span class="w"> </span><span class="nx">symbol</span><span class="p">)</span>
<span class="w">                            </span><span class="p">(</span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="nx">flip</span><span class="p">)</span><span class="w"> </span><span class="err">&#39;</span><span class="nx">terminal</span><span class="w"> </span><span class="err">&#39;</span><span class="nx">binary</span><span class="o">-</span><span class="nx">production</span><span class="p">))</span>
<span class="p">(</span><span class="nx">define</span><span class="w"> </span><span class="nx">ipcfg</span><span class="o">-</span><span class="nx">expander</span>
<span class="w">    </span><span class="p">(</span><span class="nx">DPmem</span><span class="w"> </span><span class="m m-Double">1.0</span>
<span class="w">                            </span><span class="p">(</span><span class="nx">lambda</span><span class="w"> </span><span class="p">(</span><span class="nx">symbol</span><span class="p">)</span>
<span class="w">                            </span><span class="p">(</span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="nx">eq</span><span class="p">?</span><span class="w"> </span><span class="p">(</span><span class="nx">rule</span><span class="o">-</span><span class="k">type</span><span class="w"> </span><span class="nx">symbol</span><span class="p">)</span><span class="w"> </span><span class="err">&#39;</span><span class="nx">terminal</span><span class="p">)</span>
<span class="w">                            </span><span class="p">(</span><span class="nx">multinomial</span><span class="w"> </span><span class="nx">terms</span><span class="w"> </span><span class="nx">term</span><span class="o">-</span><span class="nx">probs</span><span class="p">)</span>
<span class="w">                            </span><span class="p">(</span><span class="nx">list</span><span class="w"> </span><span class="p">(</span><span class="nx">get</span><span class="o">-</span><span class="nx">symbol</span><span class="p">)</span><span class="w"> </span><span class="p">(</span><span class="nx">get</span><span class="o">-</span><span class="nx">symbol</span><span class="p">))))</span>
<span class="p">(</span><span class="nx">define</span><span class="w"> </span><span class="p">(</span><span class="nx">sample</span><span class="o">-</span><span class="nx">ipcfg</span><span class="p">)</span><span class="w"> </span><span class="p">(</span><span class="nx">unfold</span><span class="w"> </span><span class="nx">ipcfg</span><span class="o">-</span><span class="nx">expander</span><span class="w"> </span><span class="err">&#39;</span><span class="nx">S</span><span class="p">))</span>
</code></pre></div>

<p>Making adapted versions of any of these models [5] only requires stochastically memoizing unfold:</p>
<div class="codehilite"><pre><span></span><code><span class="ss">(</span><span class="nv">define</span><span class="w"> </span><span class="nv">adapted</span><span class="o">-</span><span class="nv">unfold</span>
<span class="w">    </span><span class="ss">(</span><span class="nv">DPmem</span><span class="w"> </span><span class="mi">1</span>.<span class="mi">0</span>
<span class="w">                            </span><span class="ss">(</span><span class="nv">lambda</span><span class="w"> </span><span class="ss">(</span><span class="nv">expander</span><span class="w"> </span><span class="nv">symbol</span><span class="ss">)</span>
<span class="w">                            </span><span class="ss">(</span><span class="k">if</span><span class="w"> </span><span class="ss">(</span><span class="nv">terminal</span>?<span class="w"> </span><span class="nv">symbol</span><span class="ss">)</span>
<span class="w">                            </span><span class="nv">symbol</span>
<span class="w">                            </span><span class="ss">(</span><span class="nv">map</span><span class="w"> </span><span class="ss">(</span><span class="nv">lambda</span><span class="w"> </span><span class="ss">(</span><span class="nv">x</span><span class="ss">)</span>
<span class="w">                                </span><span class="ss">(</span><span class="nv">adapted</span><span class="o">-</span><span class="nv">unfold</span><span class="w"> </span><span class="nv">expander</span><span class="w"> </span><span class="nv">x</span><span class="ss">))</span>
<span class="w">                                </span><span class="ss">(</span><span class="nv">expander</span><span class="w"> </span><span class="nv">symbol</span><span class="ss">)</span><span class="w"> </span><span class="ss">)))))</span>
</code></pre></div>

<p>Figure 4: Some examples of "stochastic transition models".</p>
<div class="codehilite"><pre><span></span><code>(rain (mem (lambda (day)
    (flip (weight &#39;rain-prior)))))
(sprinkler (mem (lambda (day)
    (flip (weight &#39;sprinkler-prior))))))
&#39;(rain &#39;day2)
&#39;(grass-is-wet &#39;day2) )
</code></pre></div>

<p>Note that we have used mem to make the grass-is-wet, rain, and sprinkler functions persistent. For example, (= (rain 'day2) (rain 'day2)) is always True (it either rained on day two or not), this is necessary since both the query and predicate expressions will evaluate (rain 'day2).</p>
<p>A Bayes net representation of this example would have clearly exposed the dependencies involved (though it would need to be supplemented with descriptions of the form of these dependencies). The Church representation, while more complex, lends itself to intuitive extensions that would be quite difficult in a Bayes net formulation. For instance, what if we don't know the Bernoulli weights, but we do have observations of other days? We can capture this by drawing the weights from a hyper-prior, redefining the weight function to:</p>
<div class="codehilite"><pre><span></span><code>...(weight (mem (lambda (ofwhat) (beta 1 1))))...
</code></pre></div>

<p>If we now query conditioned on observations from other days, we implicitly learn the weight parameters of the model:</p>
<div class="codehilite"><pre><span></span><code>(lex-query
    &#39;...model definitions...
    &#39;(rain &#39;day2)
    &#39;(and
        (grass-is-wet &#39;day1)
        (rain &#39;day1)
        (not (sprinkler &#39;day1))
        (grass-is-wet &#39;day2)) )
</code></pre></div>

<p>Going further, perhaps the probability of rain depends on (unknown) types of days (e.g. those with cumulus clouds, cirrus clouds, etc.), and perhaps the probability of the sprinkler activating depends on orthogonal types of days (e.g. Mondays and Fridays versus other days). We can model this scenario by drawing the prior probabilities from two stochastically memoized beta distributions:</p>
<div class="codehilite"><pre><span></span><code>(lex-query
    &#39;((new-rain-prob
        (DPmem 1.0 (lambda () (beta 1 1))))
    (new-sprinkler-prob
        (DPmem 1.0 (lambda () (beta 1 1))))
    (rain (mem (lambda (day)
        (flip (new-rain-prob)))))
    (sprinkler (mem (lambda (day)
        (flip (new-sprinkler-prob))))))
    ...)
</code></pre></div>

<p>With this simple change we have extended the original causal model into an infinite mixture of such models,</p>
<p>in which days are co-clustered into two sets of types, based on their relationship to the wetness of the grass.</p>
<p>In the previous example we left the types of days implicit in the memoizer, using only the probability of rain or sprinkler. In Fig. 3 we have given Church implementations for several infinite mixture models [see 7] using a different idiom - making the types into persistent properties of objects, drawn from an underlying memoized gensym (recall that gensym is simply a procedure which returns a unique value on each evaluation). Once we have defined the basic structure, class to draw latent classes for objects, it is straightforward to define the latent information for each class (e.g. coin-weight), and the observation model (e.g. value). This basic structure may be used to easily describe more complicated mixture models, such as the continuous-data infinite relational model (IRM) from [7]. Fig. 3 describes forward sampling for these models; to describe a conditional model, these definitions must be made within the scope of a query. For instance, if we wished to query whether two objects have the same class, conditioned on observed features:</p>
<div class="codehilite"><pre><span></span><code>(lex-query
    &#39;((drawclass (mem 1.0 gensym))
        (class ...)
        (coin-weight ...)
        (value ...))
&#39;(= (class &#39;alice) (class &#39;bob))
&#39;(and
        (= (value &#39;alice &#39;blond) 1)
        (= (value &#39;bob &#39;blond) 1)
        (= (value &#39;jim &#39;blond) 0)))
</code></pre></div>

<p>Another idiom (Fig. 4) allows us to write the common class of "stochastic transition" models, which includes probabilistic context free grammars (PCFGs), hidden Markov models (HMMs), and their "infinite" analogs. Writing the HDP-PCFG [8] and HDP-HMM [2] in Church provides a compact and clear specification to these complicated non-parametric models. If we memoize unfold and use this adapted-unfold on PCFG transitions we recover the Adaptor Grammar model of [5]; if we similarly "adapt" the HDP-PCFG or HDP-HMM we get interesting new models that have not been considered in the literature.</p>
<p>Fig. 5(top) gives an outline for using Church to represent planning problems. This is based on the translation of planning into inference, given in Toussaint et al. [21], in which rewards are transformed into the probability of getting a single "ultimate reward". Inference on this representation results in decisions which softmaximizes the expected reward. Fig. 5(bottom) fills in this framework for a simple "red-light" game: the state is a light color (red/green) and an integer position, a "go" action advances one position forward</p>
<div class="codehilite"><pre><span></span><code>(define (transition state-action)
    (pair
        (forward-model state-action)
        (action-prior) ))
(define (terminal? symbol) (flip gamma))
(define (reward-pred rewards)
    (flip ((/ (sum rewards) (length rewards)))))
(lex-query
    &#39;((first-action (action-prior))
        (final-state
            (first (unfold transition
                (pair start-state first-action) )))
            (reward-list
            (list (sp1 final-state)
                (sp2 final-state)
                    . .etc.. ))
    &#39;first-action
    &#39;(reward-pred reward-list))
</code></pre></div>

<p>(define (forward-model s-a)
(pair
(if (flip 0.5) 'red-light 'green-light)
(let ((light (first (first s-a)))
(position (last (first s-a)))
(action (last s-a)))
(if (eq? action 'go)
(if (and (eq? light 'red-light)
(flip cheat-det))
0
(* position 1))
position))))
(define (action-prior) (if (flip 0.5) 'go 'stop))
(define (sp1 state) (if (&gt; (last state) 5) 1 0))
Figure 5: Top: The skeleton of planning-as-inference in Church (inspired by [21]). For simplicity, we assume an equal reward amount for each boolean "state property" that is true. Reward is given only when the state reaches a "terminal state", however the stochastic termination decision given by terminal? results in an infinite horizon with discount factor gamma. Bottom: A specific planning problem for the "red-light" game.
except that going on a red light results in being sent back to position 0 with probability cheat-det. The goal is to be past position 5 when the game ends; other rewards (e.g. for a staged game) could be added by adding sp2, sp3, and so on.</p>
<h2>4 CHURCH IMPLEMENTATION</h2>
<p>Implementing Church involves two complications beyond the implementation of eval as shown in Fig. 1 (which is essentially the same as any lexically scoped, applicative order, pure Lisp [6]). First, we must find a way to implement mem without requiring infinite structures (such as the $\mathrm{V}_{\text {val }}$ ). Second, we must implement query by devising a means to sample from the appropriate conditional distribution.</p>
<p>To implement mem we first note that the countably many $\mathrm{V}_{\text {val }}$ are not all needed at once: they can be</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 6: Posterior samples from the infinite gaussianmixture (with unknown variance) of Section 3, using the collapsed rejection algorithm for query. Two datasets are shown (as dots) with mixture components and posterior predictive distribution.
created as needed, extending the environment env+ when they are created. (Note that this implementation choices is stateful, but may be implemented easily in full Scheme: the argument/return value pairs can be stored in an association list which grows as need. $)^{4}$</p>
<p>We now turn to query. The sampling-based semantics of Church allows us to define a simple rejection sampler from the conditional distribution defining query; we may describe this as a Church expression:</p>
<div class="codehilite"><pre><span></span><code><span class="ss">(</span><span class="nv">define</span><span class="w"> </span><span class="ss">(</span><span class="nv">query</span><span class="w"> </span><span class="nv">exp</span><span class="w"> </span><span class="nv">pred</span><span class="w"> </span><span class="nv">env</span><span class="ss">)</span>
<span class="w">    </span><span class="ss">(</span><span class="nv">let</span><span class="w"> </span><span class="ss">((</span><span class="nv">val</span><span class="w"> </span><span class="ss">(</span><span class="nv">eval</span><span class="w"> </span><span class="nv">exp</span><span class="w"> </span><span class="nv">env</span><span class="ss">))</span>
<span class="w">        </span><span class="ss">(</span><span class="k">if</span><span class="w"> </span><span class="ss">(</span><span class="nv">pred</span><span class="w"> </span><span class="nv">val</span><span class="ss">)</span>
<span class="w">            </span><span class="nv">val</span>
<span class="w">            </span><span class="ss">(</span><span class="nv">query</span><span class="w"> </span><span class="nv">exp</span><span class="w"> </span><span class="nv">pred</span><span class="w"> </span><span class="nv">env</span><span class="ss">)))))</span>
</code></pre></div>

<p>The ability to write query as a Church programa metacircular [1] implementation-provides a compelling argument for Church's modeling power. However, exact sampling using this algorithm will often be intractable. It is straightforward to implement a collapsed rejection sampler that integrates out randomness in the predicate procedure (accepting or rejecting a val with probability equal to the marginal probability that (p val) is true). We show results in Fig. 6 of this exact sampler used to query the infinite gaussianmixture model from Section 3.</p>
<p>In Fig. 7 we show the result of running the collapsed rejection query for planning in the "red-light" game, as shown in Fig. 5 (here gamma=0.2, cheat-det=0.7). The result is intuitive: when position is near 0 there is little to lose by "cheating", as position nears 5 (the goal line) there is more to loose, hence the probability of cheating decreases; once past the goal line there is nothing to be gained by going, so the probability of cheating drops sharply. Note that the "soft-max" formulation of planning used here results in fairly random behavior even in extreme positions.</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 7: Results from planning in the "redlight" game (Fig. 5), showing the probability of "cheating" (going when the light is red) versus position. The goal is to end the game past position 5.</p>
<h3>4.1 A Metropolis-Hastings Algorithm</h3>
<p>We now present a Markov chain Monte Carlo algorithm for approximately implementing query, as we expect (even collapsed) rejection sampling to be intractable in general. Our algorithm executes stochastic local search over evaluation histories, making small changes by proposing changes to the return values of elementary random procedures. These changes are constrained to produce the conditioned result, collapsing out the predicate expression via its marginal probability ${ }^{5}$. The use of evaluation histories, rather than values alone, can be viewed as an extreme form of data-augmentation: all random choices that lead to a value are made explicit in its history.</p>
<p>The key abstraction we use for MCMC is the computation trace. A computation trace is a directed, acyclic graph composed of two connected trees. The first is a tree of evaluations, where an evaluation node points to evaluation nodes for its recursive calls to eval. The second is a tree of environment extensions, where the node for an extended environment points to the node of the environment it extends. The evaluation node for each (eval ' $c$ env) points to the environment node for env, and evaluation nodes producing values to be bound are pointed to by the environment extension of the binding. Traces are in one-to-one correspondence with equivalence classes of evaluation histories, described earlier ${ }^{6}$. Fig. 8 shows the fragment of a computation trace for evaluation of the expression ((lambda $(\mathrm{x})(+\mathrm{x} 3))$ (flip)).</p>
<p>For each elementary random procedure p we need a Markov chain transition kernel $K_{\mathrm{p}}$ that proposes a new return value for that procedure given its current arguments. A generic such kernel comes from re-</p>
<p><sup id="fnref2:1"><a class="footnote-ref" href="#fn:1">2</a></sup></p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 8: A schematic computation trace.
evaluating (eval '( $p$ args) env); however, a proper Church standard library could frequently supply more efficient proposal kernels for particular procedures (for instance a drift kernel for normal). Our requirement is that we are able to sample a proposal from $K_{\mathrm{p}}$ as well as evaluate its transition probability $q_{\mathrm{p}}(\cdot \mid \cdot)$.
If we simply apply $K_{\mathrm{p}}$ to a trace, the trace can become "inconsistent"-no longer representing a valid evaluation history from eval. To construct a complete Metropolis-Hastings proposal from $K_{\mathrm{p}}$, we must keep the computation trace consistent, and modify the proposal probabilities accordingly, by recursing along the trace updating values and potentially triggering new evaluations. For example, if we change the value of flip in (if (flip) $e_{1} e_{2}$ ) from False to True we must: absorb the probability of (eval $e_{2}$ env) in the reverse proposal probability, evaluate $e_{1}$ and attach it to the trace, and include the probability of the resulting sub-trace in the forward proposal probability. (For a particular trace, the probability of the sub-trace for expression $e$ is the probability of the equivalence class of evaluation histories corresponding to this subtrace.) The recursions for trace consistency and proposal computation are delicate but straightforward, and we omit the details due to space constraints ${ }^{7}$. Each step of our MCMC algorithm ${ }^{8}$ consists of applying a kernel $K_{\mathrm{p}}$ to the evaluations of a randomly chosen elementary random primitive in the trace, updating the trace to maintain consistency (collecting appropriate corrections to the proposal probability), and applying the Metropolis-Hastings criterion to accept or reject this proposal. (This algorithm ignores some details needed for queries containing nested queries, though we believe these to be straightforward.)</p>
<p>We have implemented and verified this algorithm on several examples that exercise all of the recursion and update logic of the system. In Fig. 9 we have shown convergence results for this algorithm running on the simple "sprinkler" example of Section 3.</p>
<p><sup id="fnref4:0"><a class="footnote-ref" href="#fn:0">1</a></sup><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 9: Convergence of one run of the MCMC algorithm on the "sprinkler" example. (Each sample from query uses 30 MCMC steps.) Top: The probability of rain. Bottom: The expected value of (+ (rain) (sprinkler)), showing explaining away. The sum is slightly above 1.0 because one cause is usually present, but both rarely are.</p>
<h2>5 DISCUSSION</h2>
<p>While Church builds on many other attempts to marry probability theory with computation, it is distinct in several important ways. First, Church is founded on the lambda calculus, allowing it to represent higherorder logic and separating it from many related languages. For example, unlike several widely used languages grounded in propositional logic (e.g. BUGS [9]) and first-order logic (e.g. the logic programming approaches of $[13,19]$, BLOG [12], and Markov logic [18]), generative processes in Church are first-class objects that can be arbitrarily composed and abstracted. The example programs in Section 3 illustrate the representational flexibility of Church; while some of these programs may be naturally represented in one or another existing language, we believe that no other language can easily represent all of these examples.</p>
<p>The stochastic functional language IBAL [14], based on the functional language ML, is quite similar to Church, but the two languages emphasize different aspects of functional programming. Other related work includes non-determistic [11] and weighted nondeterministic [16] extensions to Lisp. Unlike these approaches, the semantics of Church is fundamentally sampling-based: the denotation of admissible expressions as distributions follows from the semantics of evaluation rather than defining it. This semantics, combined with dynamic typing (cf. static typing of ML), permits the definition and exact implementation of query as an ordinary Church procedure, rather than a special transformation applied to the distribution denoted by a program. Because query is defined via sampling, describing approximate inference is particularly natural within Church.</p>
<p>A number of the more unusual features of Church as a stochastic programming language derive from its ba-</p>
<p>sis in Lisp. Since query and eval are the basic constructs defining the meaning of Church expressions, we have a metacircular [17] description of Church within Church. This provides clarity in reasoning about the language, and allows self-reflection within programs: queries may be nested within queries, and programs may reason about programs. Church expressions can serve both as a declarative notation for uncertain beliefs (via the distributions they represent) and as a procedural notation for stochastic and deterministic processes (via evaluation). Because expressions are themselves values, this generalizes the Lisp unification of programs and data to a unification of stochastic processes, Church expressions, and uncertain beliefs. These observations suggest exciting new modeling paradigms. For instance, eval nested within query may be used to learn programs, where the prior on programs is represented by another Church program. Issues of programming style then become issues of description length and inductive bias. As another example, query nested within query may be used to represent an agent reasoning about another agent.</p>
<p>Of course, Church's representational flexibility comes at the cost of substantially increased inference complexity. Providing efficient implementations of query is a critical challenge as our current implementation is not yet efficient enough for typical machine learning applications; this may be greatly aided by building on techniques used for inference in other probabilistic languages [e.g. 10, 14, 12]. For example, in Church, exact inference by enumeration could be seen as a program analysis that transforms expressions involving query into expressions involving only eval; identifying and exploiting opportunities for such transformations seems appealing.</p>
<p>Probabilistic models and stochastic algorithms are finding increasingly widespread use throughout artificial intelligence and cognitive science, central to areas as diverse as vision, planning, and natural language understanding. As their usage grows and becomes more intricate, so does the need for formal languages supporting model exchange, reuse, and machine execution. We hope Church represents a significant step toward this goal.</p>
<h2>Acknowledgements</h2>
<p>The authors would like to thank Gerry Sussman, Hal Abelson, Tom Knight, Brian Milch, David McAllester and Alexey Radul for helpful discussions. This work was funded in part by a grant from NTT Communication Sciences Laboratory.</p>
<h2>References</h2>
<p>[1] H. Abelson and G. Sussman. Structure and Interpretation of Computer Programs. MIT Press, 1996.
[2] M.J. Beal, Z. Ghahramani, and C.E. Rasmussen. The infinite hidden Markov model. NIPS 14, 2002.
[3] K. A. Bonawitz. Composable Probabilistic Inference with BlaiSE. PhD thesis, MIT, 2008.
[4] A. Church. A Set of Postulates for the Foundation of Logic. The Annals of Mathematics, 33(2):346-366, 1932.
[5] M. Johnson, T. Griffiths, and S. Goldwater. Adaptor grammars: A framework for specifying compositional nonparametric Bayesian models. NIPS 19, 2007.
[6] R. Kelsey, W. Clinger, and J. Rees (eds.). Revised ${ }^{5}$ Report on the Algorithmic Language Scheme. HigherOrder and Symbolic Computation, 11(1):7-105, 1998.
[7] C. Kemp, J.B. Tenenbaum, T.L. Griffiths, T. Yamada, and N. Ueda. Learning systems of concepts with an infinite relational model. Proc. 21st Natl Conf. Artif. Intell., AAAI Press, 2006.
[8] P. Liang, S. Petrov, M.I. Jordan, and D. Klein. The Infinite PCFG using Hierarchical Dirichlet Processes. Proc. EMNLP-CoNLL, 2007.
[9] D.J. Lunn, A. Thomas, N. Best, and D. Spiegelhalter. WinBUGS-A Bayesian modelling framework: Concepts, structure, and extensibility. Statistics and Computing, 10(4):325-337, 2000.
[10] D. McAllester, B. Milch, and N. D. Goodman. Random-world semantics and syntactic independence for expressive languages. Technical Report MIT-CSAIL-TR-2008-025, Massachusetts Institute of Technology, 2008.
[11] J. McCarthy. A Basis for a Mathematical Theory of Computation. In Computer Programming and Formal Systems, pages 33-70, 1963.
[12] B. Milch, B. Marthi, S. Russell, D. Sontag, D.L. Ong, and A. Kolobov. BLOG: Probabilistic models with unknown objects. Proc. IJCAI, 2005.
[13] S. Muggleton. Stochastic logic programs. In L. de Raedt, editor, Advances in Inductive Logic Programming, pages 254-264. IOS Press, 1996.
[14] A. Pfeffer. IBAL: A probabilistic rational programming language. Proc. IJCAI, 2001.
[15] J. Pitman. Combinatorial stochastic processes, 2002. Notes for Saint Flour Summer School.
[16] A. Radul. Report on the probabilistic language scheme. Technical Report MIT-CSAIL-TR-2007-059, Massachusetts Institute of Technology, 2007.
[17] J.C. Reynolds. Definitional interpreters for higherorder programming. ACM Annual Conference, pages $717-740,1972$.
[18] M. Richardson and P. Domingos. Markov logic networks. Machine Learning, 62(1):107-136, 2006.
[19] T. Sato and Y. Kameya. PRISM: A symbolicstatistical modeling language. In International Joint Conference on Artificial Intelligence, 1997.
[20] J. Sethuraman. A Constructive definition of Dirichlet priors. Statistica Sinica, 4, 1994.
[21] M. Toussaint, S. Harmeling, and A. Storkey. Probabilistic inference for solving (PO)MDPs. Technical Report EDI-INF-RR-0934, University of Edinburgh, 2006.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{7}$ We implemented our MCMC algorithm atop the Blaise system [3], which simplifies these recursively triggered kernel compositions.
${ }^{8}$ At the time of writing we have not implemented this algorithm for programs that use mem, though we believe the necessary additions to be straightforward.&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref4:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
<li id="fn:1">
<p>${ }^{5}$ Handling the rejection problem on chain initialization (and queries across deterministic programs, more generally) is a challenge. Replacing all language primitives (including if) with noisy alternatives and using tempering techniques provides one general solution, to be explored in future work.
${ }^{6}$ Also note that the acyclicity of traces is a direct result of the purity of the Church language: if a symbol's value were mutated, its environment would point to the evaluation node that determined its new value, but that node would have been evaluated in the same environment.&#160;<a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 2 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:1" title="Jump back to footnote 2 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>