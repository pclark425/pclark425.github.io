<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-7395 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-7395</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-7395</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-139.html">extraction-schema-139</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <p><strong>Paper ID:</strong> paper-276770303</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2503.02800v2.pdf" target="_blank">RAAD-LLM: Adaptive Anomaly Detection Using LLMs and RAG Integration</a></p>
                <p><strong>Paper Abstract:</strong> Anomaly detection in complex industrial environments poses unique challenges, particularly in contexts characterized by data sparsity and evolving operational conditions. Predictive maintenance (PdM) in such settings demands methodologies that are adaptive, transferable, and capable of integrating domain-specific knowledge. In this paper, we present RAAD-LLM, a novel framework for adaptive anomaly detection, leveraging large language models (LLMs) integrated with Retrieval-Augmented Generation (RAG). This approach addresses the aforementioned PdM challenges. By effectively utilizing domain-specific knowledge, RAAD-LLM enhances the detection of anomalies in time series data without requiring fine-tuning on specific datasets. The framework's adaptability mechanism enables it to adjust its understanding of normal operating conditions dynamically, thus increasing detection accuracy. We validate this methodology through a real-world application for a plastics manufacturing plant and the Skoltech Anomaly Benchmark (SKAB). Results show significant improvements over our previous model with an accuracy increase from 70.7% to 88.6% on the real-world dataset. By allowing for the enriching of input series data with semantics, RAAD-LLM incorporates multimodal capabilities that facilitate more collaborative decision-making between the model and plant operators. Overall, our findings support RAAD-LLM's ability to revolutionize anomaly detection methodologies in PdM, potentially leading to a paradigm shift in how anomaly detection is implemented across various industries.</p>
                <p><strong>Cost:</strong> 0.017</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e7395.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e7395.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RAAD-LLM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>RAAD-LLM: Adaptive Anomaly Detection Using LLMs and RAG Integration</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An expert-system style pipeline that repurposes a frozen pretrained LLM (hosted via Ollama) augmented by a Retrieval‑Augmented Generation (RAG) component, domain context, SPC filtering, windowing and DFT-based signal summarization to perform zero‑shot anomaly detection on multivariate industrial time‑series.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Llama 3.1 (hosted via Ollama)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Frozen pretrained Llama 3.1 model used as the backbone LLM (served by an Ollama LLM server); LLM is not fine‑tuned — used for instruction‑style zero‑shot inference with RAG‑augmented prompts.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>8b</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_approach</strong></td>
                            <td>Zero‑shot prompting of a frozen LLM augmented with RAG retrieval and domain‑context templates; preprocessing pipeline includes SPC (MAMR) outlier filtering, non‑overlapping windowing, discrete Fourier transform (DFT) to extract the dominant sinusoidal component, injection of selected summary statistics into text templates, LLM reasoning, and a domain‑knowledge binarization rule mapping textual outputs to {0,1}.</td>
                        </tr>
                        <tr>
                            <td><strong>prompt_template</strong></td>
                            <td>Instruction + domain context + injected statistics templates. Example template shown in paper: an instruction block ('You are a helpful assistant...'), CONTEXT: <cached info>, DATA: 'Melt Pressure 1 has a z-score of <val>. Melt Pressure Differential has a z-score of <val>.' RAG: z-score comparison lines ('The z-score for Melt Pressure 1 is <greater than/less than/equal to> acceptable...'). LLM returns itemized text like 'High deviation is present for Melt Pressure 1.'; textual outputs are then binarized according to domain correlation rules.</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Multivariate time‑series sensor data (tabular time‑series from manufacturing sensors)</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>Plastics manufacturing use‑case (screen‑pack failure dataset — 65 hours run‑to‑failure sensor readings for two downtime events) and SKAB (Skoltech Anomaly Benchmark)</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Accuracy, Precision, Recall, F1‑score; SKAB comparisons reported with F1, FAR (False Alarm Rate), MAR (Missed Alarm Rate)</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Use‑case (plastics plant): accuracy 88.6 ± 2.1%; precision 92.6 ± 0.1%; recall 91.1 ± 3.3%; F1 91.9 ± 1.7%. SKAB: accuracy reported 71.6 ± 0.4%; F1 reported ≈ 0.744 (74.4%) with FAR and MAR reported in Table II (paper reports FAR ≈ 42.1% and MAR ≈ 11.4% in the SKAB results table as presented).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared to prior AAD‑LLM (prior work) which had ~70.7% accuracy on the real‑world use case; on SKAB RAAD‑LLM ranked 1st by F1 among listed methods. Table III lists competing models and F1s (examples: LSTMCaps ~0.742, MSET ~0.732, MSCRED ~0.701, vanilla LSTM/AE variants lower).</td>
                        </tr>
                        <tr>
                            <td><strong>zero_shot_or_few_shot</strong></td>
                            <td>Zero‑shot (no training or fine‑tuning on target datasets)</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Requires manual domain‑context restructuring for the best performance (paper notes manual reformatting was necessary); relatively high false alarm rate (FAR) on SKAB compared to some methods (RAAD‑LLM and RAAD‑LLMv2 rank last in FAR in Table III); performance degrades on the public SKAB benchmark vs the controlled manufacturing use case; the paper notes RAAD‑LLMv2's automated retrieval reduced performance (trade‑off between automation and accuracy).</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'RAAD-LLM: Adaptive Anomaly Detection Using LLMs and RAG Integration', 'publication_date_yy_mm': '2025-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7395.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e7395.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RAAD-LLMv2</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>RAAD-LLMv2 (RAAD‑LLM with LlamaIndex integration)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A variant of RAAD‑LLM that replaces manual context injection with an automated RAG retrieval powered by LlamaIndex (embeddings stored in a vector DB) so only retrieved content is added to prompts, aiming for scalable domain context retrieval at inference time.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Llama 3.1 (used both as the LLM and to generate embeddings via Ollama)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Same frozen Llama 3.1 8b backbone; embedding generation and retrieval managed by LlamaIndex and a vector store; retrieved context is concatenated to prompts prior to LLM inference.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>8b</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_approach</strong></td>
                            <td>Zero‑shot LLM prompting with automated retrieval of domain context via LlamaIndex (RAG); pipeline retains SPC, windowing, DFT summarization and template injection but uses vector retrieval instead of adding full raw context to every prompt.</td>
                        </tr>
                        <tr>
                            <td><strong>prompt_template</strong></td>
                            <td>Similar templates to RAAD‑LLM but instead of adding all domain context manually, the system issues retrieval for relevant context snippets from a vector store (LlamaIndex) and appends only those retrieved snippets to the prompt before LLM inference.</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Multivariate time‑series sensor data (tabular time‑series)</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>Plastics manufacturing use‑case (screen‑pack failures) and SKAB (Skoltech Anomaly Benchmark)</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>F1, FAR, MAR (same metrics as RAAD‑LLM and presented in Table II/III comparisons); accuracy/precision/recall reported for use case comparisons qualitatively (RAAD‑LLMv2 reported lower than RAAD‑LLM).</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Reported to perform worse than RAAD‑LLM on both datasets. On SKAB RAAD‑LLMv2 averaged F1 ≈ 0.704 (70.4%) in Table II and ranked 4th by F1 in Table III; RAAD‑LLMv2 had higher MAR (e.g., Table II shows MAR ~18.67% for RAAD‑LLMv2) and overall lower scores than RAAD‑LLM. Exact use‑case numeric metrics for RAAD‑LLMv2 are not enumerated in the main text beyond stating it is lower than RAAD‑LLM.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared against RAAD‑LLM (higher), prior AAD‑LLM (lower), and multiple NN/ML baselines in Table III (e.g., LSTMCaps, MSET, MSCRED, LSTM/AE variants). RAAD‑LLMv2 ranked 4th by F1 on SKAB in the paper's comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>zero_shot_or_few_shot</strong></td>
                            <td>Zero‑shot (no fine‑tuning on target datasets)</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Automated retrieval via LlamaIndex introduced a performance trade‑off: RAAD‑LLMv2 is more scalable but showed lower detection metrics than the manually‑restructured RAAD‑LLM; performance sensitive to LlamaIndex/embedding configurations; still exhibits high FAR relative to some baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'RAAD-LLM: Adaptive Anomaly Detection Using LLMs and RAG Integration', 'publication_date_yy_mm': '2025-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7395.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e7395.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AAD-LLM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>AAD-LLM: Adaptive Anomaly Detection Using Large Language Models</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The authors' prior architecture that repurposed pretrained LLMs for adaptive anomaly detection by enriching time‑series with semantics and applying a frozen LLM for zero‑shot detection (no fine‑tuning); RAAD‑LLM extends this work by adding RAG and other pipeline improvements.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>AAD-LLM: Adaptive Anomaly Detection Using Large Language Models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Unspecified pretrained LLM (prior work)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Frozen pretrained LLM repurposed for time‑series anomaly detection via textualization/semantic enrichment and prompting; no fine‑tuning reported in original AAD‑LLM.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_approach</strong></td>
                            <td>Zero‑shot prompting of a frozen LLM with semantic enrichment and an adaptability mechanism; used windowing and SPC methods to define normal baselines prior to prompting.</td>
                        </tr>
                        <tr>
                            <td><strong>prompt_template</strong></td>
                            <td>Templates that inject statistical summaries of time‑series segments and domain semantics into prompts for the LLM (similar style to RAAD‑LLM but without RAG); exact templates described in prior work (referenced).</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Multivariate time‑series sensor data</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>Applied to the same plastics manufacturing use‑case (real‑world) and evaluated on SKAB as a comparison baseline</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Accuracy, F1‑score reported in comparisons</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Reported prior accuracy on the real‑world plastics use‑case ≈ 70.7% (paper cites improvement from 70.7% to 88.6% when moving to RAAD‑LLM). On SKAB AAD‑LLM reported an F1 ≈ 0.564 in the comparison table.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Served as the predecessor baseline for RAAD‑LLM; compared against classical NN/ML baselines in Table III where AAD‑LLM performed worse than RAAD‑LLM but was notable for requiring no fine‑tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>zero_shot_or_few_shot</strong></td>
                            <td>Zero‑shot (no fine‑tuning reported)</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Paper stated AAD‑LLM had inconsistent comparative evaluations between historical normal and observed statistics and required a more robust computational mechanism (motivating RAG integration); performance lower than RAAD‑LLM.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'RAAD-LLM: Adaptive Anomaly Detection Using LLMs and RAG Integration', 'publication_date_yy_mm': '2025-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>AAD-LLM: Adaptive Anomaly Detection Using Large Language Models <em>(Rating: 2)</em></li>
                <li>Skoltech anomaly benchmark (skab) <em>(Rating: 2)</em></li>
                <li>Extended context for instructgpt with llamaindex <em>(Rating: 2)</em></li>
                <li>Retrieval-augmented generation for large language models: A survey <em>(Rating: 1)</em></li>
                <li>Time-llm: Time series forecasting by reprogramming large language models <em>(Rating: 1)</em></li>
                <li>One fits all: Power general time series analysis by pretrained lm <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-7395",
    "paper_id": "paper-276770303",
    "extraction_schema_id": "extraction-schema-139",
    "extracted_data": [
        {
            "name_short": "RAAD-LLM",
            "name_full": "RAAD-LLM: Adaptive Anomaly Detection Using LLMs and RAG Integration",
            "brief_description": "An expert-system style pipeline that repurposes a frozen pretrained LLM (hosted via Ollama) augmented by a Retrieval‑Augmented Generation (RAG) component, domain context, SPC filtering, windowing and DFT-based signal summarization to perform zero‑shot anomaly detection on multivariate industrial time‑series.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Llama 3.1 (hosted via Ollama)",
            "model_description": "Frozen pretrained Llama 3.1 model used as the backbone LLM (served by an Ollama LLM server); LLM is not fine‑tuned — used for instruction‑style zero‑shot inference with RAG‑augmented prompts.",
            "model_size": "8b",
            "anomaly_detection_approach": "Zero‑shot prompting of a frozen LLM augmented with RAG retrieval and domain‑context templates; preprocessing pipeline includes SPC (MAMR) outlier filtering, non‑overlapping windowing, discrete Fourier transform (DFT) to extract the dominant sinusoidal component, injection of selected summary statistics into text templates, LLM reasoning, and a domain‑knowledge binarization rule mapping textual outputs to {0,1}.",
            "prompt_template": "Instruction + domain context + injected statistics templates. Example template shown in paper: an instruction block ('You are a helpful assistant...'), CONTEXT: &lt;cached info&gt;, DATA: 'Melt Pressure 1 has a z-score of &lt;val&gt;. Melt Pressure Differential has a z-score of &lt;val&gt;.' RAG: z-score comparison lines ('The z-score for Melt Pressure 1 is &lt;greater than/less than/equal to&gt; acceptable...'). LLM returns itemized text like 'High deviation is present for Melt Pressure 1.'; textual outputs are then binarized according to domain correlation rules.",
            "training_data": null,
            "data_type": "Multivariate time‑series sensor data (tabular time‑series from manufacturing sensors)",
            "dataset_name": "Plastics manufacturing use‑case (screen‑pack failure dataset — 65 hours run‑to‑failure sensor readings for two downtime events) and SKAB (Skoltech Anomaly Benchmark)",
            "evaluation_metric": "Accuracy, Precision, Recall, F1‑score; SKAB comparisons reported with F1, FAR (False Alarm Rate), MAR (Missed Alarm Rate)",
            "performance": "Use‑case (plastics plant): accuracy 88.6 ± 2.1%; precision 92.6 ± 0.1%; recall 91.1 ± 3.3%; F1 91.9 ± 1.7%. SKAB: accuracy reported 71.6 ± 0.4%; F1 reported ≈ 0.744 (74.4%) with FAR and MAR reported in Table II (paper reports FAR ≈ 42.1% and MAR ≈ 11.4% in the SKAB results table as presented).",
            "baseline_comparison": "Compared to prior AAD‑LLM (prior work) which had ~70.7% accuracy on the real‑world use case; on SKAB RAAD‑LLM ranked 1st by F1 among listed methods. Table III lists competing models and F1s (examples: LSTMCaps ~0.742, MSET ~0.732, MSCRED ~0.701, vanilla LSTM/AE variants lower).",
            "zero_shot_or_few_shot": "Zero‑shot (no training or fine‑tuning on target datasets)",
            "limitations_or_failure_cases": "Requires manual domain‑context restructuring for the best performance (paper notes manual reformatting was necessary); relatively high false alarm rate (FAR) on SKAB compared to some methods (RAAD‑LLM and RAAD‑LLMv2 rank last in FAR in Table III); performance degrades on the public SKAB benchmark vs the controlled manufacturing use case; the paper notes RAAD‑LLMv2's automated retrieval reduced performance (trade‑off between automation and accuracy).",
            "computational_cost": null,
            "uuid": "e7395.0",
            "source_info": {
                "paper_title": "RAAD-LLM: Adaptive Anomaly Detection Using LLMs and RAG Integration",
                "publication_date_yy_mm": "2025-03"
            }
        },
        {
            "name_short": "RAAD-LLMv2",
            "name_full": "RAAD-LLMv2 (RAAD‑LLM with LlamaIndex integration)",
            "brief_description": "A variant of RAAD‑LLM that replaces manual context injection with an automated RAG retrieval powered by LlamaIndex (embeddings stored in a vector DB) so only retrieved content is added to prompts, aiming for scalable domain context retrieval at inference time.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Llama 3.1 (used both as the LLM and to generate embeddings via Ollama)",
            "model_description": "Same frozen Llama 3.1 8b backbone; embedding generation and retrieval managed by LlamaIndex and a vector store; retrieved context is concatenated to prompts prior to LLM inference.",
            "model_size": "8b",
            "anomaly_detection_approach": "Zero‑shot LLM prompting with automated retrieval of domain context via LlamaIndex (RAG); pipeline retains SPC, windowing, DFT summarization and template injection but uses vector retrieval instead of adding full raw context to every prompt.",
            "prompt_template": "Similar templates to RAAD‑LLM but instead of adding all domain context manually, the system issues retrieval for relevant context snippets from a vector store (LlamaIndex) and appends only those retrieved snippets to the prompt before LLM inference.",
            "training_data": null,
            "data_type": "Multivariate time‑series sensor data (tabular time‑series)",
            "dataset_name": "Plastics manufacturing use‑case (screen‑pack failures) and SKAB (Skoltech Anomaly Benchmark)",
            "evaluation_metric": "F1, FAR, MAR (same metrics as RAAD‑LLM and presented in Table II/III comparisons); accuracy/precision/recall reported for use case comparisons qualitatively (RAAD‑LLMv2 reported lower than RAAD‑LLM).",
            "performance": "Reported to perform worse than RAAD‑LLM on both datasets. On SKAB RAAD‑LLMv2 averaged F1 ≈ 0.704 (70.4%) in Table II and ranked 4th by F1 in Table III; RAAD‑LLMv2 had higher MAR (e.g., Table II shows MAR ~18.67% for RAAD‑LLMv2) and overall lower scores than RAAD‑LLM. Exact use‑case numeric metrics for RAAD‑LLMv2 are not enumerated in the main text beyond stating it is lower than RAAD‑LLM.",
            "baseline_comparison": "Compared against RAAD‑LLM (higher), prior AAD‑LLM (lower), and multiple NN/ML baselines in Table III (e.g., LSTMCaps, MSET, MSCRED, LSTM/AE variants). RAAD‑LLMv2 ranked 4th by F1 on SKAB in the paper's comparisons.",
            "zero_shot_or_few_shot": "Zero‑shot (no fine‑tuning on target datasets)",
            "limitations_or_failure_cases": "Automated retrieval via LlamaIndex introduced a performance trade‑off: RAAD‑LLMv2 is more scalable but showed lower detection metrics than the manually‑restructured RAAD‑LLM; performance sensitive to LlamaIndex/embedding configurations; still exhibits high FAR relative to some baselines.",
            "computational_cost": null,
            "uuid": "e7395.1",
            "source_info": {
                "paper_title": "RAAD-LLM: Adaptive Anomaly Detection Using LLMs and RAG Integration",
                "publication_date_yy_mm": "2025-03"
            }
        },
        {
            "name_short": "AAD-LLM",
            "name_full": "AAD-LLM: Adaptive Anomaly Detection Using Large Language Models",
            "brief_description": "The authors' prior architecture that repurposed pretrained LLMs for adaptive anomaly detection by enriching time‑series with semantics and applying a frozen LLM for zero‑shot detection (no fine‑tuning); RAAD‑LLM extends this work by adding RAG and other pipeline improvements.",
            "citation_title": "AAD-LLM: Adaptive Anomaly Detection Using Large Language Models",
            "mention_or_use": "mention",
            "model_name": "Unspecified pretrained LLM (prior work)",
            "model_description": "Frozen pretrained LLM repurposed for time‑series anomaly detection via textualization/semantic enrichment and prompting; no fine‑tuning reported in original AAD‑LLM.",
            "model_size": null,
            "anomaly_detection_approach": "Zero‑shot prompting of a frozen LLM with semantic enrichment and an adaptability mechanism; used windowing and SPC methods to define normal baselines prior to prompting.",
            "prompt_template": "Templates that inject statistical summaries of time‑series segments and domain semantics into prompts for the LLM (similar style to RAAD‑LLM but without RAG); exact templates described in prior work (referenced).",
            "training_data": null,
            "data_type": "Multivariate time‑series sensor data",
            "dataset_name": "Applied to the same plastics manufacturing use‑case (real‑world) and evaluated on SKAB as a comparison baseline",
            "evaluation_metric": "Accuracy, F1‑score reported in comparisons",
            "performance": "Reported prior accuracy on the real‑world plastics use‑case ≈ 70.7% (paper cites improvement from 70.7% to 88.6% when moving to RAAD‑LLM). On SKAB AAD‑LLM reported an F1 ≈ 0.564 in the comparison table.",
            "baseline_comparison": "Served as the predecessor baseline for RAAD‑LLM; compared against classical NN/ML baselines in Table III where AAD‑LLM performed worse than RAAD‑LLM but was notable for requiring no fine‑tuning.",
            "zero_shot_or_few_shot": "Zero‑shot (no fine‑tuning reported)",
            "limitations_or_failure_cases": "Paper stated AAD‑LLM had inconsistent comparative evaluations between historical normal and observed statistics and required a more robust computational mechanism (motivating RAG integration); performance lower than RAAD‑LLM.",
            "computational_cost": null,
            "uuid": "e7395.2",
            "source_info": {
                "paper_title": "RAAD-LLM: Adaptive Anomaly Detection Using LLMs and RAG Integration",
                "publication_date_yy_mm": "2025-03"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "AAD-LLM: Adaptive Anomaly Detection Using Large Language Models",
            "rating": 2,
            "sanitized_title": "aadllm_adaptive_anomaly_detection_using_large_language_models"
        },
        {
            "paper_title": "Skoltech anomaly benchmark (skab)",
            "rating": 2,
            "sanitized_title": "skoltech_anomaly_benchmark_skab"
        },
        {
            "paper_title": "Extended context for instructgpt with llamaindex",
            "rating": 2,
            "sanitized_title": "extended_context_for_instructgpt_with_llamaindex"
        },
        {
            "paper_title": "Retrieval-augmented generation for large language models: A survey",
            "rating": 1,
            "sanitized_title": "retrievalaugmented_generation_for_large_language_models_a_survey"
        },
        {
            "paper_title": "Time-llm: Time series forecasting by reprogramming large language models",
            "rating": 1,
            "sanitized_title": "timellm_time_series_forecasting_by_reprogramming_large_language_models"
        },
        {
            "paper_title": "One fits all: Power general time series analysis by pretrained lm",
            "rating": 1,
            "sanitized_title": "one_fits_all_power_general_time_series_analysis_by_pretrained_lm"
        }
    ],
    "cost": 0.017312249999999998,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>RAAD-LLM: Adaptive Anomaly Detection Using LLMs and RAG Integration
11 Mar 2025</p>
<p>Alicia Russell-Gilbert 
Computer Science &amp; Engineering Department at
Mississippi State University</p>
<p>Sudip Mittal mittal@cse.msstate.edu 
Computer Science &amp; Engineering Department at
Mississippi State University</p>
<p>Shahram Rahimi rahimi@cse.msstate.edu 
Computer Science &amp; Engineering Department at
Mississippi State University</p>
<p>Maria Seale maria.a.seale@erdc.dren.mil 
Development Center at the Department of Defense
Engineer Research</p>
<p>Joseph Jabour joseph.e.jabour@erdc.dren.mil 
Development Center at the Department of Defense
Engineer Research</p>
<p>Thomas Arnold thomas.l.arnold@erdc.dren.mil 
Development Center at the Department of Defense
Engineer Research</p>
<p>Joshua Church joshua.q.church@erdc.dren.mil 
RAAD-LLM: Adaptive Anomaly Detection Using LLMs and RAG Integration
11 Mar 2025D204915B505D34E21F6C7910CFE91FB3arXiv:2503.02800v3[cs.LG]large language modelsLLMs for time series taskspredictive maintenanceadaptive anomaly detectionexpert systems
Anomaly detection in complex industrial environments poses unique challenges, particularly in contexts characterized by data sparsity and evolving operational conditions.Predictive maintenance (PdM) in such settings demands methodologies that are adaptive, transferable, and capable of integrating domain-specific knowledge.In this paper, we present RAAD-LLM, a novel framework for adaptive anomaly detection, leveraging large language models (LLMs) integrated with Retrieval-Augmented Generation (RAG).This approach addresses the aforementioned PdM challenges.By effectively utilizing domain-specific knowledge, RAAD-LLM enhances the detection of anomalies in time series data without requiring finetuning on specific datasets.The framework's adaptability mechanism enables it to adjust its understanding of normal operating conditions dynamically, thus increasing detection accuracy.We validate this methodology through a real-world application for a plastics manufacturing plant and the Skoltech Anomaly Benchmark (SKAB).Results show significant improvements over our previous model with an accuracy increase from 70.7% to 88.6% on the real-world dataset.By allowing for the enriching of input series data with semantics, RAAD-LLM incorporates multimodal capabilities that facilitate more collaborative decision-making between the model and plant operators.Overall, our findings support RAAD-LLM's ability to revolutionize anomaly detection methodologies in PdM, potentially leading to a paradigm shift in how anomaly detection is implemented across various industries.</p>
<p>INTRODUCTION</p>
<p>In the rapidly evolving landscape of AI and knowledgebased systems, expert systems have emerged as powerful tools for incorporating domain expertise and specialized knowledge into models.Furthermore, they continue to be applied across domains such as engineering, agriculture, and manufacturing [1]- [4].These systems aim to emulate the decision-making capabilities of human experts and they offer the potential to improve the performance of other approaches in many ways.</p>
<p>In particular, domain knowledge integration helps identify relevant features and patterns that might be missed by purely This material is based upon work supported by the Engineering Research and Development Center -Information Technology Laboratory (ERDC-ITL) under Contract No. W912HZ23C0013.Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the ERDC-ITL.data-driven approaches.In addition, expert-guided rules and thresholds enable more accurate anomaly detection by incorporating industry-specific maintenance criteria.Lastly, expert knowledge supports more robust fault detection by considering equipment-specific degradation patterns and maintenance history.These performance improvements lead to more accurate and reliable predictive maintenance models that better reflect real-world operational conditions.However, a persistent challenge is the gap between expert systems and the domain experts whose knowledge they aim to capture and apply.</p>
<p>This gap manifests itself in multiple ways such as communication barriers between AI developers and subject matter experts, difficulties in accurately translating complex human expertise into computational models, and resistance from experts who may view such systems as threats rather than aids.These issues can have significant consequences, leading to expert systems that fail to capture the nuanced decisionmaking processes of human experts, are difficult to update and maintain, or face limited adoption in real-world settings.</p>
<p>Bridging this gap is crucial because it can lead to more accurate and comprehensive expert systems that truly reflect the depth and breadth of human expertise.In addition, it can facilitate more effective knowledge transfer and preservation.Lastly, it can promote greater acceptance and integration of expert systems in professional practice.This integration has the potential to revolutionize fields such as healthcare, network security, environmental sciences, and manufacturing.</p>
<p>While expert systems can be applied across various domains, one critical area where they are particularly valuable is in maintaining complex engineered systems.Engineered systems that are vital to our daily operations degrade over time and can fail.These failures often lead to consequences that range from minor inconveniences to catastrophic events.To prevent such failures, maintenance practices such as conditionbased maintenance (CBM) and predictive maintenance (PdM) are used.While CBM involves performing maintenance based on system conditions, PdM enhances this approach by using machine learning (ML) to make more proactive and targeted decision-making.This research focuses on developing an expert system for PdM that integrates domain expertise to enhance model performance and bridge the gap between automated systems and human experts in real-world applications.</p>
<p>PdM is challenging under real-world conditions as a re-sult of non-stationary sensor data.Factors such as varying operational settings and individual machine deterioration are common causes of non-stationary sensor readings [5].This heterogeneity in the relationship between operational data and system health requires regular updates of the normative profile used for the identification of degradation [6], [7].To address these challenges, an adaptive approach rather than traditional PdM methods should be employed.This would allow for better accommodation of shifts in sensor data characteristics while maintaining high fault detection accuracy.Unique production systems and domain constraints require tailored PdM approaches across industries.Integrating expert knowledge enables robust domain-specific implementations.Yet, this knowledge often limits the applicability across domains.Therefore, retraining or fine-tuning on the applied dataset with related domain-specific knowledge would typically be required.However, event data needed to fine-tune or retrain may be scarce [8].This is because some critical assets are not allowed to run to failure.Therefore, ideally, PdM models should be transferable in data-sparse scenarios.</p>
<p>Transferable models that excel in "few-shot" and "zeroshot" scenarios can perform well on limited training data across diverse systems and domains.Recent work suggests that pretrained large language models (LLMs) offer notable few/zero-shot capabilities and transferability [9]- [11].The extension of LLMs beyond natural language to the time series domain showcases their broader potential [12], [13].Repurposing pretrained LLMs for the PdM use-case can improve the transferability of other approaches in data-constrained environments.</p>
<p>In light of the given challenges, PdM represents a particularly difficult application area of expert systems where domain expertise is crucial.These challenges underscore that for dataconstrained, complex and dynamic industrial environments; there is a critical need for adaptable and transferable methodologies to enhance anomaly detection and therefore, prevent costs associated with system failures.Furthermore, multimodal strategies would more easily allow for the enriching of input series data with domain-specific knowledge.Consequently, expert systems would more accurately translate complex subject matter expertise into its computational models, be easier to update and maintain, and be more accepted in real-world settings.</p>
<p>This paper examines the application of RAAD-LLM (AAD-LLM with RAG integration), a novel expert system for anomaly detection in PdM scenarios that builds off of our previous work titled "AAD-LLM: Adaptive Anomaly Detection Using Large Language Models" [14].Specifically, this framework utilizes pretrained LLMs for anomaly detection in complex and data-sparse manufacturing systems.The proposed methodology does not require any training or fine-tuning on the dataset it is applied to.In addition, the architecture overcomes the issue of concept drift in dynamic industrial settings by integrating an adaptability mechanism.Furthermore, the framework is multimodal; thereby enabling more collaborative decision-making between the expert system and plant operators by allowing for the enriching of input time series data with semantics.Therefore, RAAD-LLM is shown to be a robust, transferable, and more widely adoptable expert system that supports rather than replaces human expertise.</p>
<p>The main contributions of this work are as follows:</p>
<p>• We present a novel anomaly detection framework (RAAD-LLM) and explore the integration of a Retrieval-Augmented Generation (RAG) pipeline into the AAD-LLM architecture to improve its performance.• We show that by leveraging pretrained LLMs, RAAD-LLM is transferable with zero-shot capabilities in comparison to other anomaly detection methodologies.• RAAD-LLM is shown to be effective by applying it to a real-world use-case at a plastics manufacturing plant.• We show that the adaptability mechanism of RAAD-LLM enables the model to adjust to evolving conditions, consequently enhancing detection accuracy.• RAAD-LLM is shown to be multimodal; thereby delivering more context-aware detection to enable robust, domain-specific implementations in collaboration with plant operators.The remaining sections of this paper are as follows.Section 2 discusses the background and foundational work for our proposed methodology.Section 3 examines the state-of-theart in LLM time series tasks and adaptive anomaly detection methods.Section 4 provides insight on the RAAD-LLM architecture and methodology.Section 5 explains evaluation results and implications of findings.Finally, Section 6 concludes the paper and discusses limitations for future work.</p>
<p>BACKGROUND</p>
<p>This section serves as a background for understanding LLMs and adaptive anomaly detection as presented in this paper.It aims to provide key terms, baseline definitions, and relevant mathematical notations that are essential for comprehending the concepts discussed.Additionally, this section briefly discusses the initial stages of our research endeavor.It describes the preliminary investigations conducted to lay the groundwork for our current work.</p>
<p>Fundamental Concepts and Terminology</p>
<p>A large language model (LLM) is trained on sequences of tokens and encodes an auto-regressive distribution, where the probability of each token depends on the preceding ones [13].More simply, an LLM is trained on sequences of words or word pieces, and the output is the likelihood of the next word in a sequence given the previous words (i.e., context-aware embeddings).Each model includes a tokenizer that converts input strings into token sequences.Models like GPT-3 and LLaMA-2 can perform zero-shot generalization, effectively handling tasks without specific training [13].For this work, we repurpose an LLM for time series anomaly detection while keeping the backbone language model intact [15].A binarization function is then applied to the outputs of the LLM to map them to {0, 1} to obtain the final predictions.The exact binarization function is use-case specific.</p>
<p>Transfer learning is a ML technique where the knowledge gained through one task is applied to a related task with low/no retraining [16].Specifically, in transfer learning, we train a Fig. 1: SPC technique of MAMR to set control limits for process stability in a query series Q i .Figure A and Figure B are moving average and moving range, respectively.UCL is the defined upper control limit and LCL is the defined lower control limit.Series data points outside of control limits are deemed "out of statistical control" and are labeled as anomalous.Out of control points can be seen before line (1).Points between lines (1) and ( 2) represent a stable process.Points after line (2) also represent a stable process, however, they are trending towards out of control.These points, therefore, are potentially problematic.RAAD-LLM is applied to all points within control limits to enhance anomaly detection.model to perform a specific task on the source domain and then make certain modifications to give us good predictions for a related task on the target domain where data is (usually) scarce or a fast training is needed [17].For this work, we leverage a pretrained LLMs' text synthesizing and reasoning abilities acquired through training on a source domain by transferring this task knowledge to our PdM use-case.Specifically, we show that pretrained LLMs can effectively predict anomalies in time series data by transferring its text synthesizing and reasoning knowledge to our target manufacturing domain.</p>
<p>Concept drift is the phenomenon where the statistical properties of a domain changes over time, which can then result in a deterioration of models that have previously been trained within that domain [18], [19].In particular, it can lead to a degradation of performance of static models as they become less effective in detecting anomalies.For example, in manufacturing, the statistical properties of raw material attributes change over time.Therefore, if these variables are used as product quality predictors, the resulting models may decrease in validity.</p>
<p>Adaptive anomaly detection (AAD) encompasses techniques that can detect anomalies in data streams or in situations where concept drift is present.These techniques make models capable of automatically adjusting their detection behavior to changing conditions in the deployment environment or system configuration while still accurately recognizing anomalies [6], [7].For this work, the adaptability mechanism refers to the feature that enables the model's definition of normality and related statistical measures to adjust with each new data instance.</p>
<p>Windowing refers to dividing a time series into smaller, manageable segments, which are then processed individually.Windowing (or sliding window technique) is used extensively for anomaly detection in time series data due to its many benefits [20].For our use-case, dividing the time series into windows helps to preserve local information that might be lost when considering the entire time series as a whole and reduce computational load since models can handle smaller inputs more efficiently.</p>
<p>A process is said to be "in statistical control" if it is not experiencing out of control signals or significant variations beyond normal statistical variations [21].Statistical process control (SPC) techniques are commonly used in manufacturing for monitoring sequential processes (e.g., production lines) to make sure that they work stably and satisfactorily [22].In monitoring the stability of a process, SPC plays an essential role [23], [24].The idea is that processes that are in statistical control are deemed to be stable processes [21].For this work, stable processes form a baseline for normal process behavior.The selection of SPC techniques are usecase specific.For this work, moving average moving range (MAMR) is implemented.</p>
<p>The univariate MAMR charts are plotted for each process variable in a time-series instance as shown in Figure 1.This aspect of plotting and analyzing the MAMR charts for all process variables in parallel will cause an increase in the Type I error rate.Upper (UCL) and lower (LCL) control limits for the moving average (X) and moving range (mR) charts are calculated as follows.</p>
<p>X Chart:
U CL = X + 2.66R(1)LCL = X − 2.66R(2)
mR Chart:
U CL = 3.27R(3)
The values 2.66 and 3.27 are often used as multipliers for estimating control limits in the MAMR chart.However, these multipliers can significantly widen the control limits, making them less sensitive to minor shifts or variations in the process.Therefore, it is important to analyze historical data to determine the typical variability in the process under consideration and select multipliers that reflect the process's actual behavior while maintaining sensitivity.</p>
<p>Investigated Approaches in Expert Systems for PdM</p>
<p>The need for effective methodologies in predictive maintenance (PdM) is critical in complex and evolving industrial environments.In prior research, we explored the challenges inherent in conventional PdM approaches, particularly emphasizing their limitations in transferability across varied operational contexts and their lack of multimodality.Our foundational work, AAD-LLM, leveraged the capabilities of LLMs to establish a novel framework for anomaly detection in manufacturing settings characterized by sparse data.</p>
<p>In the development of AAD-LLM, we focused on the inherent strengths of pretrained LLMs and their capacity for zero-shot learning, which does not require extensive retraining on domain-specific datasets.The model was designed to convert anomaly detection into a language-based task by enriching time series data with semantic context derived from domain knowledge.Results from our implementation on real-world data (shown in Table II) demonstrated an accuracy of 70.7%.Evaluation metrics showed the model's potential in detecting anomalies effectively, even in data-constrained scenarios.However, we recognized that the model's performance in making comparative evaluations between the historical normal and the observed statistics was inconsistent, pointing to the necessity for a more robust computational mechanism.</p>
<p>RAG</p>
<p>RAG stands for Retrieval-Augmented Generation, a technique that enhances LLMs by integrating external, reliable, and up-to-date knowledge during the generation process [26].Specifically, RAG first invokes the retriever to search and extract the relevant documents from external databases, which are then leveraged as the context to enhance the generation process [26], [27].In practice, RAG requires minimal or even no additional training [26], [28].</p>
<p>The RAG approach has been shown to improve the baseline performance of LLMs.For example, RAG has been shown to improve the performance of the question and answering task [29].In another paper, Melz [30] showed that RAG improves the problem-solving abilities of LLMs.In addition to these works, a comprehensive review paper examined various RAG paradigms and emphasized RAG's significant advancement in enhancing the capabilities of LLMs [31].</p>
<p>Interim results for the AAD-LLM framework revealed that LLMs hold considerable promise in anomaly detection tasks for the PdM use-case.In addition to enhancing anomaly detection through the repurposing of LLMs, the current work introduces RAG.We hypothesize that integrating RAG into our existing framework would improve its performance.By facilitating the retrieval of relevant data for mathematical comparisons, RAG could enhance both the accuracy and applicability of AAD-LLM in industrial settings, where domain expertise is critical for interpreting complex scenarios.Thus, this work seeks to expand upon the insights gained from our earlier research, potentially leading to a paradigm shift in how anomaly detection is implemented across various industries.</p>
<p>PRIOR ART</p>
<p>This section examines recent advancements in applying LLMs to time series tasks, including forecasting, classification, anomaly detection, and imputation.It highlights the strengths and weaknesses of state-of-the-art methods.Additionally, it reviews prior research in AAD techniques that combine semantics with ML.</p>
<p>LLMs for Time Series Tasks</p>
<p>Traditional analytical methods that rely on statistical models and deep learning methods based on recurrent neural networks (RNNs) have dominated the domain of time series forecasting.However, LLMs have recently emerged in the arena of time series forecasting and have made significant progress in various fields such as healthcare, finance, and transportation [12].Time-LLM [15] proposed a novel framework repurposing LLMs for time series forecasting without requiring any fine-tuning of the backbone model.This was achieved by "reprogramming" time series data inputs for compatibility with LLMs; thereby, converting time series forecasting into a "language" task.An LLM's advanced reasoning and pattern recognition capabilities could then be leveraged to achieve high precision and efficiency in forecasts.Time-LLM was shown to outperform specialized models in few-shot and zero-shot scenarios.</p>
<p>Similarly, Chronos [32] proposed the use of LLMs for time series forecasting.However, it avoided reprogramming the time series data, which requires training on each input dataset separately.Instead, time-series data was tokenized into a fixed vocabulary via scaling and quantization.The Chronos model outperformed statistical baselines and other pretrained models in both in-domain and zero-shot scenarios across multiple benchmarks.</p>
<p>LLMTime [13] also proposed the use of LLMs for time series forecasting.Rather than requiring learned input transformations or prompt engineering as Time-LLM did, time series data were tokenized like with Chronos but with a different scheme.In fact, for this framework, effective numerical tokenization was essential in ensuring accurate and efficient forecasting by the LLMs.LLMTime outperformed traditional statistical models and models from the Monash forecasting archive.Furthermore, it was competitive with and sometimes outperformed efficient transformer models.</p>
<p>PromptCast [33] also introduced a novel approach to time series forecasting using LLMs.Like Time-LLM, numerical sequences are described and transformed to natural language sentences.However, PrompCast used manually-defined template-based prompting rather than learning input transformations for automatic prompting.While explored for only unistep forecasting, the results indicated that the PromptCast approach not only achieved performance that was comparable to traditional numerical methods but sometimes even surpassed them.</p>
<p>These prior works suggest the emergence of multimodal models that excel in both language and time series forecasting tasks.However, these works presented LLMs for use in only time series forecasting and did not explore other time series tasks like anomaly detection.However, in separate works, LLMs have emerged for other time series tasks and have been shown to excel.Time series tasks typically include four main analytical tasks: forecasting, classification, anomaly detection, and imputation [12].</p>
<p>Zhou et al. [34] introduced a unified framework (referred to as One Size Fits All (OFA) [12]) that uses frozen pretrained LLMs for performing various time series analysis tasks.Like Time-LLM, OFA required training the input embedding layer to acquire learned time series representations.However, rather than only time series forecasting, it explored the use of LLMs for univariate anomaly detection.OFA achieved superior or comparable results in classification, forecasting, anomaly detection, and few-shot/zero-shot learning.</p>
<p>Sun et al. [35] proposed an embedding method for TimE Series tokens to align the Text embedding space of LLM (TEST).TEST's embeddings alignment methodology enhances LLMs' ability to perform time series tasks without losing language processing abilities.Although the exact embedding function was not specified, learning input transformations typically involves neural network training.Therefore, like Time-LLM, TEST also required training the input embedding layer.However, like OFA, TEST explored the use of LLMs for other time series tasks.Compared to state-of-the-art models, TEST demonstrated superior performance on various tasks including univariate time series forecasting, as well as multivariate classification tasks.</p>
<p>While achieving good performance on multiple time series tasks, neither OFA nor TEST explored multivariate anomaly detection.Multivariate analysis allows for joint reasoning across the time series.Joint reasoning enables a model to blend and merge the understanding from different sensors and data sources to make decisions that are impossible when considering data in isolation.For example, in our usecase, the temperature alone may not sufficiently indicate a problem since operators might adjust the temperature to try and maintain material flow despite a screen pack blockage.By monitoring both pressure and temperature, it is possible to detect joint anomaly events that are more indicative of clogging.Furthermore, there were no papers exploring LLMs for the PdM use-case.</p>
<p>Enriching Time-Series Data With Semantics for AAD in PdM</p>
<p>Advancement in anomaly detection through adaptability has been explored extensively.Traditionally, most AAD algorithms have been designed for data sets in which all observations are available at one time (i.e., static datasets).However, over the last two decades, many algorithms have been proposed to detect anomalies in "evolving" data (i.e., data streams) [36].Although the proposed methodology could possibly be modified for data streams, we only focus on static datasets in this paper.</p>
<p>ML and NN techniques have been used for AAD implementation and have been shown to improve the performance baselines of non-adaptive models in various scenarios such as industrial applications [37], network security [38], and environmental science [36].However, these techniques focus only on the data themselves.Although effective, these approaches may overlook contextual information and domainspecific knowledge crucial for accurate anomaly detection.</p>
<p>A system that combines ML and semantics improves the accuracy of anomaly detection in the data by reducing the number of false positives [6], [7].This is because integrating semantics into the anomaly detection process allows for a more comprehensive analysis that considers both the data patterns and their contextual relevance.A system like this would enable for more collaborative decision-making between the model and plant operators.</p>
<p>Semantics such as the following could greatly enhance anomaly detection, as it provides insight into the severity of the anomaly: Domain-specific knowledge indicates that there are correlations between process variables.Specifically, increased melt pressure at the screen pack inlet may lead to increased melt temperature at the screen pack inlet.Additionally, increased melt pressure at the screen pack inlet may lead to decreased melt pressure at the screen pack outlet.If these correlations are observed, it indicates a high level of criticality for potential failures.In this case, plant operators may want to imply that if an anomaly is not severe enough, then it is a false positive; and therefore, should not trigger a manual shutdown.Unlike ML models, LLMs can easily integrate this knowledge for the anomaly detection task.</p>
<p>Few previous works have incorporated expert knowledge with ML algorithms for anomaly detection within time-series data.Ontology-based LSTM (OntoLSTM) [39] integrates ontology-driven representations with DL to model manufacturing time-series data.Its framework combines a hierarchical ontology-based NN with stacked dense layers for "learning" representations of manufacturing lines and machines, and an LSTM module for capturing temporal dependencies in production process data.Adaptability in OntoLSTM stems from its ability to dynamically integrate domain-specific semantics into its deep architecture, allowing it to align with varying manufacturing processes.However, the model requires extensive training due to its hybrid nature, as it must optimize both the representation-learning dense layers and the LSTM's temporal learning component to accurately detect anomalies.</p>
<p>Fused-AI interpretabLe Anomaly Generation System (FLAGS) [6] integrated data-driven and knowledge-driven approaches to deliver adaptive, context-aware anomaly detection.The Semantic Mapping module is responsible for enriching the incoming data streams with expert rules and context information.Adaptability here refers to the merging, deleting, or relabeling of anomalies to cope with user-provided feedback; and dynamic rule extracting.FLAGS is an ensemble architecture that uses one ML model to detect anomalies and another that fuses semantics to determine whether they are true anomalies.Although the FLAGS architecture allows for the use of any appropriate ML models, non-LLM models are largely statistical without much innate reasoning [15].</p>
<p>Notably, LLMs demonstrate advanced abilities in reasoning and data synthesis [40], [41], and offer few/zero shot capabilities and transferability [9]- [11].Since pretrained LLMs have been shown to perform well on various time-series tasks, leveraging their learned higher level concepts could enable highly precise and synergistic detection across multiple modalities [15].Furthermore, while traditional ML or NN models typically require more specialized training, LLMs have the ability to perform well with less data and without extensive retraining.This is extremely advantageous in data-constrained operational settings.</p>
<p>METHODOLOGY</p>
<p>This section overviews the RAAD-LLM methodology and outlines the proposed enhancement of the AAD-LLM framework through the incorporation of a RAG pipeline.The goal of this enhancement is to improve the model's capacity to perform complex reasoning tasks that require computational support.The integration of the RAG pipeline into the AAD-LLM framework allows the model to access external knowledge bases dynamically and incorporate relevant information into its decision-making process.This combination enhances the LLM's performance in recognizing and classifying anomalies.As a result, this integration will strengthen RAAD-LLM's ability to detect anomalies in data-sparse industrial environments.</p>
<p>The RAAD-LLM Framework</p>
<p>The following subsections provide a detailed description of the RAAD-LLM architecture as shown in Figure 2. It discusses the key components, domain-specific knowledge integration, data processing workflow, and the methodology for combining prompting, RAG, and model inference to enhance anomaly detection capabilities.</p>
<p>System Architecture</p>
<p>The integrated architecture, referred to as RAAD-LLM, consists of the following key components: dates the baseline normal behavior as each new time series window is processed.The LLM hosting environment is built around Ollama, which supports the Llama 3.1 8b model.This server acts as the central endpoint for processing context-aware prompts.The server's base URL is specified, and parameters like request timeout and maximum tokens are configured to ensure steady communication and manage resource usage.</p>
<p>Domain-Specific Knowledge and Text Templates</p>
<p>To enhance collaboration with plant operators, we develop a domain-specific context file that enables the LLM to comprehend the specifics of our time series data.This file integrates expert rules, domain knowledge, and constraints to establish acceptable ranges for process variable variations, guide feature selection, and describe in detail causal relationships among variables.In our manufacturing use case, comprising 580 sensors per line, operators can correlate these readings with failure modes.Furthermore, fluctuations in raw materials necessitate adjustments in process parameters, which polymer scientists can specify.By utilizing this expertise, we can refine thresholds, select relevant features, and identify interactions; thereby improving anomaly detection.The context file is imported and should be persisted for efficiency.</p>
<p>To enable structured understanding and improved performance, we create text templates with placeholders that align with essential statistical values such as mean, standard deviation, and maximum.In this work, only the z-score is used, as prior research found it sufficient to yield good results.When actual data is available, these placeholders are populated through data injection.Injected statistical measures for both normal system behavior and the current query window under consideration will guide the LLM's reasoning, enhancing its anomaly detection capabilities.</p>
<p>INSTRUCTIONS:</p>
<p>You are a helpful assistant that can use these rules to answer queries.The following sensor data was collected over the last 15 minutes and represent current process conditions.Strictly based on the context and RAG information provided below, please answer the following questions.Do not modify, interpret, or apply logic beyond these instructions.* Is high deviation present for Melt Pressure 1? * Is high deviation present for Melt Pressure Differential?For each question, avoid explaining.Just print only the output and nothing else.CONTEXT: <cached info> DATA: Melt Pressure 1 has a z-score of <val>.Melt Pressure Differential has a z-score of <val>.RAG: The z-score for Melt Pressure 1 is <greater than / less than / equal to> acceptable process variable conditions.The z-score for Melt Pressure Differential is <greater than / less than / equal to> acceptable process variable conditions.Fig. 3: Prompt example.<cached info> is the domain context information.<val> are calculated statistical measures injected into respective text templates.<greater than / less than / equal to> is the relevant z-score comparison information from the RAG retriever.Note that although each Q i is processed independently, prompts include text templates for all i ∈ N where N is the number of input variables in instance Q from the dataset D under consideration.Therefore, multivariate anomaly detection is explored.</p>
<p>Data Processing Workflow</p>
<p>Defining normal process behavior is crucial for effective anomaly detection, as it establishes a baseline against which potential anomalies can be compared and identified.This baseline is determined in a manner akin to the AAD-LLM methodology.From the dataset D under consideration, a multivariate time series instance Q ∈ R N ×T is partitioned into N univariate time series where N is the number of input variables and T is the number of time steps.This is done so that each input variable is processed independently [15].Each i th series Q i , i ∈ N , is then processed using SPC techniques.For this work, the univariate MAMR charts are plotted for each process variable as shown in Figure 1.This aspect of plotting and analyzing the MAMR charts for all process variables in parallel will cause an increase in the Type I error rate.Time series points deemed "out of statistical control" are labeled as anomalous and filtered out of Q i before further processing.SPC is applied again after the first set of outliers (or anomalies) are removed.This is done to ensure extreme values do not affect control limits.Therefore, it can be assumed that time series Q i represents a stable process.We use this assumption in initializing our comparison dataset C i as our baseline for normal behavior as explained in the next paragraph.The idea is that once the comparison dataset is initialized, the model then updates its understanding of normalcy as each new query window is ingested.</p>
<p>Rather than processing the entire time series at once, Q i then undergoes windowing as shown in Figure 2.For each i ∈ N , windowing divides time series Q i into P consecutive non-overlapping segments of length L, Q (P ) i ∈ R P ×L .By analyzing data within sliding windows, anomaly detection can focus on smaller segments of the time series data.This provides a more granular and detailed view of abnormal patterns.Processing the entire time series as a single entity might obscure localized anomalies within the data.Finally, for each i ∈ N , a baseline dataset C i ∈ R 1×L of normal behavior is defined as the first Q i window.</p>
<p>Unlike AAD-LLM, for each i ∈ N , both the current
Q i window Q (p) i
where p ∈ P and the baseline data set, C i undergo additional processing through the DFT.Since sensor signals are sampled discretely, the DFT is very useful in their analyses [43].Specifically, the DFT can be used to isolate the most prominent frequency component from the noise, thereby enhancing the discernibility of the signal.After applying the DFT, we then construct a sinusoidal representation of the dominant frequency component for both Q (p) i and C i .The steps to apply the DFT and then construct a sinusoidal representation are as follows.</p>
<p>The DFT for signal s(t) is computed as:
F (k) = N −1 t=0 s(t) • e −i•2π k•t N for k = 0, 1, . . . , N 2(4)
Here, F (k) represents the frequency components, with the focus on the real part of the spectrum.The amplitude spectrum is computed as the scaled magnitude of the Fourier coefficients:
A k = 2 N |F k | for k = 0, 1, . . . , N 2(5)
where:</p>
<p>• A k is the amplitude corresponding to the k-th frequency component, • F k is the k-th Fourier coefficient from the DFT output.The dominant frequency and amplitude are determined as:
f max = f k where k = arg max k A k(6)
A max = A k for the same k (7) where:</p>
<p>• f max is the dominant frequency in the signal,</p>
<p>• A max is the amplitude of the dominant frequency.Using f max and A max , a sine wave is fitted to represent the dominant signal component:
ŝ(t) = A max • sin(2πf max • t) + |s|
where:</p>
<p>• ŝ(t) is the reconstructed sine wave signal, • A max is the amplitude of the dominant frequency, • f max is the dominant frequency, • s is the mean value of the original signal that is added to account for offset adjustments, • t represents time.Subsequently, selected statistical measures for the sinusoidal representations of Q (p) i and C i are calculated and then injected into the corresponding text templates.This approach is advantageous because it allows for a clearer differentiation between signal and noise, making it easier to identify patterns and anomalies in the data.By focusing on frequency components, we gain a deeper understanding of the underlying dynamics of the signal.</p>
<p>Prompting, RAG, and Model Inference</p>
<p>Prompts are then created via prompt engineering and combined with the templates.To further enrich the inputs, the domain context is added to the prompt before being fed forward through the frozen LLM.For our methodology, the domain context was manually restructured from the "raw" domain context to reduce the complexity of the input prompt.Consequently, this better guided the LLM's decision making, thereby enabling more consistent predictions.Effective prompt engineering is essential in ensuring accurate, context-aware anomaly detection.</p>
<p>Prior to predicting anomalies, the statistical measures for all input variables are sent to the RAG component to retrieve relevant z-score comparison information from the knowledge base.The retrieved information is then combined with the prompt, allowing the LLM to better understand the relationship between the historical normal and the observed statistics of the process being monitored.A prompt example is shown in Figure 3.The resultant enriched prompt is fed forward through the frozen LLM.* High deviation is present for Melt Pressure 1. * High deviation is not present for Melt Pressure Differential.Fig. 4: LLM output example.Outputs are an itemized list of process variables and their anomaly status.The text-based outputs use domain-specific terminology, enabling subject matter experts to interpret findings more easily than numerical results and fostering better collaboration and knowledge transfer.</p>
<p>An example output of the LLM is shown in Figure 4.The LLM outputs an itemized list indicating whether an anomaly is present for each process variable.The textual outputs of the LLM enhance collaboration with subject matter experts because they are more accessible and easier to interpret than purely numerical results.These text-based outputs incorporate domain-specific terminology that allow experts to understand findings without the need to decode complex numbers.This enhancement fosters better communication and feedback loops between technical and non-technical team members.Consequently, experts can validate or challenge the model's conclusions more effectively.Ultimately, this approach promotes improved knowledge transfer and bridges the gap between expert systems and domain expertise, making the outputs significantly more actionable and user-friendly.</p>
<p>Lastly, we apply a binarization function to the LLM's outputs to map them to {0, 1} to get the final classification (0 = non-anomalous, 1 = anomalous).The exact binarization function is use-case specific.For our use-case, one anomaly alone does not sufficiently indicate a problem.To avoid false positives that trigger an unnecessary shutdown, our binarization function only maps to 1 if anomalies in the output are correlated as indicated by domain-specific knowledge.Let x be the LLM output.Then
f (x) = 1, if anomalies in x are correlated 0, otherwise(8)
The final classification is what is used for determining updates to C i before moving to the next
Q (p) i . If the output prediction indicates no anomalies in Q (p) i , window Q (p) i
series data is combined with the preceding windows series data to gradually refine the dataset of what constitutes "normal" behavior C i .Therefore, for each i ∈ N , C i is guaranteed to be representative of normal behavior and is constantly evolving.</p>
<p>Adaptability Mechanism</p>
<p>The adaptability mechanism of AAD-LLM is preserved in the RAAD-LLM framework.In addition to C i constantly updating as each new query window is ingested, the process of re-initializing C i is done for each new instance Q.This continuous redefining of the normal baseline enables the model to progressively refine its knowledge in response to shifts in the system's operational conditions process after process.Therefore, the model is enabled to maintain an up-to-date and broad perspective of normality.</p>
<p>The RAAD-LLMv2 Framework With LlamaIndex Integration</p>
<p>The RAAD-LLM architecture requires that all domain context be added to the prompt before being fed through the frozen LLM.This made the query too complex, leading to inconsistent responses that often did not align with expectations.To address this issue, we manually restructured the "raw" domain context as described in subsubsection 4.1.4.This restructuring better guided the LLM's decision-making, but it took a lot of time and effort.</p>
<p>The RAAD-LLMv2 variant extends RAAD-LLM by integrating an additional RAG module powered by LlamaIndex.LlamaIndex is open-sourced and has been proposed as a method to expand the context capabilities of LLMs by enabling them to utilize extensive documents and databases during response generation [44]- [46].The new architecture dynamically retrieves relevant domain context rather than Fig. 5: The LlamaIndex flowchart representation.Raw domain context information is loaded as input.Each data chunk is processed using an embedding model (in this case, LLama 3.1 8b from the Ollama server).Parameters such as temperature (0.2), max tokens (250), and mirostat (disabled) are set to ensure robust and consistent embeddings are generated for the context.The generated embeddings are then stored as vectors in a vector database.Finally, LlamaIndex organizes and indexes the embeddings into a retrievable format.The vector store then becomes accessible to the RAG component, allowing dynamic retrieval of relevant context as needed.incorporating all the provided context into the prompt.Consequently, this new architecture enhances the model's decisionmaking by providing more accurate and consistent responses without manual context restructuring.Additionally, it is more scalable under real-world scenarios.Figure 5 is a visual representation of the LlamaIndex process.</p>
<p>LlamaIndex and Ollama System Configuration</p>
<p>The configuration of the LlamaIndex and Ollama system is designed to enable effective interaction between the RAG component and the LLM for domain context retrieval and embedding generation.The following provides technical details about the integration, including the configuration of the LlamaIndex and Ollama system. 1) Ollama LLM Server: The LLM hosting environment is the same as for the RAAD-LLM framework.This server acts as the central endpoint for processing both contextaware prompts and embeddings for vector stores.2) Embedding Model: The LlamaIndex relies on Ollama's embedding capabilities, using the same Llama 3.1 model as an embedding generator for the knowledge base.3) Parameter Tuning: Both the LLM and embedding configurations include custom parameters optimized to balance accuracy and computational efficiency.These parameters govern model output behaviors, such as temperature (for controlling randomness), maximum token count (to limit the size of outputs), and the request timeout duration.</p>
<p>Table I details the LlamaIndex and Ollama system configuration used for this work.This configuration facilitates the retrieval of relevant information from a vector store to complement input prompts, thereby improving the LLM's contextual understanding.The LLM is utilized to generate embeddings for domain-specific vector stores for efficient context retrieval.
Component Details LLM Model Meta Llama 3
TABLE I: Configuration summary table of the LlamaIndex and Ollama system.This setup facilitates seamless retrieval of relevant domain knowledge from the vector store using LlamaIndex.Rather than all the domain context, only the retrieved content is added to the prompt before being fed forward through the frozen LLM.</p>
<p>RESULTS AND DISCUSSION</p>
<p>This section discusses the analyses of the datasets and experimental outcomes of RAAD-LLM and RAAD-LLMv2.The focus is on their performance improvements and limitations when applied to anomaly detection tasks.These discussions aim to provide deeper insights into the frameworks' effectiveness and areas for future enhancement.</p>
<p>Data and Analysis for the PdM Use-Case</p>
<p>Our use-case dataset was for screen pack failures in the extrusion process since shutdowns due to these failures were well documented by the plastics manufacturing plant providing the data.An example of a screen pack changer can be seen in Figure 7 and an overview of the plastics extrusion process for our use-case can be seen in Figure 6.For two downtime events with screen pack failure mode, we obtained 65 hours of historical run-to-failure sensor readings (6.5 hours for 5 components for each downtime event).The readings were semi-labeled and for process variables that were deemed good indicators of screen pack failures.These process variables are Melt Pressure 1, Temperature 1, and Melt Pressure Differential.</p>
<p>• Melt Pressure 1 -The melt viscosity at the screen inlet.</p>
<p>• Temperature 1 -The melt temperature at the screen pack inlet.</p>
<p>• Melt Pressure Differential -The melt pressure across the screen pack inlet and outlet.For any of these, sudden spikes from expected profile could signal significant process variable deviations; and therefore, could lead to a screen pack failure.Since Temperature 1 did not contain enough sample data, it was not used for input into RAAD-LLM and RAAD-LLMv2 for anomaly detection.The domain context was meticulously collected from maintenance logs and plant operators.Maintenance logs provided detailed records of prior screen pack failures and anomalies.Additionally, plant operators contributed their expertise and firsthand knowledge, which helped define acceptable ranges for fluctuations and establish causal relationships among process variables.This collaborative approach ensured that the domain context effectively captured the operational intricacies of the manufacturing process.</p>
<p>Data and Analysis for the SKAB Dataset</p>
<p>The Skoltech Anomaly Benchmark (SKAB) is a publically accessible dataset designed for evaluating the performance of anomaly detection algorithms.The benchmark includes labeled signals captured by several sensors installed on the SKAB testbed.The SKAB testbed was specifically developed to study anomalies in a testbed.The focus of this work is to develop methods for detecting anomalies in these signals, which can be relevant for various applications.</p>
<p>A description of the columns in the SKAB dataset is as follows [47].The anomaly column contains the labels.A Mann-Whitney-Wilcoxon test was used to determine whether any of the data features affected the labels.This test combined with a correlation matrix to detect relationships between variables resulted in Accelerometer1RMS, Accelerometer2RMS, Temperature, and RateRMS as selected inputs for RAAD-LLM and RAAD-LLMv2 to make the predictions.See Figure 8 for further processing details.</p>
<p>Experiments on the SKAB dataset were conducted to determine the optimal fluctuation ranges for each of the selected features.Domain context was determined without using any prior domain knowledge.As a result, the context was built solely on a single statistical measure, which may have limited the accuracy of anomaly detection in this highly specialized system.Incorporating domain expertise could have enabled better feature selection, threshold setting, and understanding of variable interactions.Consequently, the model's performance on the SKAB dataset may have been constrained, highlighting the potential for improvement through informed context creation.See subsection 5.3 for model results on SKAB.The baseline model is one that predicts every observation to belong to the positive class.The RAG pipeline for both RAAD-LLM and RAAD-LLMv2 integrate a CSV-based knowledge base to dynamically retrieve relevant information for z-score comparisons, allowing for responses that reflect either exact matches for input values or the closest matches when exact values are not found.RAAD-LLMv2 integrates LlamaIndex for seamless retrieval of relevant domain knowledge from the vector store.Unlike RAAD-LLM, RAAD-LLMv2 adds only the retrieved content to the prompt before being fed forward through the frozen LLM.</p>
<p>Evaluation of Model Performance</p>
<p>To assess the performance of the frameworks, we applied RAAD-LLM and RAAD-LLMv2 to both the SKAB and usecase datasets.Evaluation metrics include accuracy, precision, recall, and F1-score, with a particular focus on the model's ability to reduce false positives and improve anomaly detection rates when compared to the original AAD-LLM.</p>
<p>The brief results are shown in Table II.With 95% confidence, for the use-case dataset, RAAD-LLM achieved an accuracy of 88.6 ± 2.1%, which is a significant improvement over the baseline model.Furthermore, RAAD-LLM's precision of 92.6 ± 0.1%, recall of 91.1 ± 3.3% and F1 score of 91.9 ± 1.7% are all notable improvements over the previous architecture.For the SKAB dataset, RAAD-LLM achieved an accuracy of 71.6 ± 0.4%, F1 score of 73.dataset, all evaluation metrics for the SKAB dataset show a significant improvement over the previous architecture.While RAAD-LLMv2 injects only relevant information and eliminates the need for manual context restructuring, it exhibited lower performance metrics for both datasets when compared to RAAD-LLM.This performance trade-off highlights the challenges posed by dynamic knowledge retrieval in the RAAD-LLMv2 framework.Although RAAD-LLM is shown to be highly effective in controlled scenarios where manual context restructuring is feasible, RAAD-LLMv2 is a more scalable alternative for real-world scenarios requiring automated domain knowledge retrieval.These findings reveal opportunities for further optimization to improve RAAD-LLMv2's overall performance.</p>
<p>Table III summarizes the scores for algorithms on 3 application benchmarks using the SKAB dataset, sorted by F1 score.For F1 score, bigger is better.For both FAR and MAR, less is better.While our previous architecture ranked 8 th among all NN and ML based methods, RAAD-LLM and RAAD-LLMv2 ranked 1 st and 4 th , respectively in F1 score.Although, both RAAD-LLM and RAAD-LLMv2 ranked last in FAR, they ranked 1 st and 2 nd , respectively in MAR.In industrial applications where there is potential for severe safety implications and the risk of catastrophic failure, the MAR is generally considered more important and is often prioritized.Effective anomaly detection systems should strive to minimize both FAR and MAR, but special attention should be given to ensuring that real anomalies are not overlooked, as the consequences of such oversights can far outweigh the inconveniences posed by false alarms.</p>
<p>The integration of the RAG component into the RAAD-LLM and RAAD-LLMv2 frameworks has led to marked improvements in anomaly detection performance compared to the previous AAD-LLM architecture.Results indicate that RAG enhances the model's performance in detecting anomalies within time series data.Our findings affirm the efficacy of RAG in augmenting the capabilities of LLMs in PdM applications.With RAAD-LLM outperforming all presented fault detection methods, repurposing LLMs with RAG integration is shown effective in detecting anomalies in time series data accurately.Overall, our findings support the use of LLMs for anomaly detection for the PdM use-case, underlining their capability and potential in handling challenges in time series anomaly detection in data-constrained industrial applications.This work significantly advances anomaly detection methodologies, potentially leading to a paradigm shift in how anomaly detection is implemented across various industries.</p>
<p>CONCLUSION AND FUTURE WORK</p>
<p>In conclusion, the RAAD-LLM framework demonstrates significant advancements in anomaly detection by leveraging the integration of the RAG pipeline, multimodal capabilities, and zero-shot transferability to address the challenges of datasparse industrial environments.By accessing external knowledge bases and enriching data inputs, the model enhances interpretability and has been shown to be superior to baseline methods in identifying and classifying anomalies.Furthermore, RAAD-LLM's emphasis on minimizing MAR ensures its suitability for safety-critical industrial applications.</p>
<p>Despite these achievements, areas for improvement remain.Future work should prioritize automating domain context restructuring to reduce the reliance on manual intervention, which can be time-intensive.RAAD-LLMv2 was designed to address this issue and be more scalable in real-world settings.However, it exhibited slightly lower performance compared to RAAD-LLM.Fine-tuning LlamaIndex configurations or developing hybrid approaches that blend manual context restructuring with automated retrieval should be explored.Ad-ditionally, RAAD-LLM was applied to only static datasets to better understand how processes failed after the failure had already occurred.Transitioning from static datasets to realtime data streams would expand RAAD-LLM's applicability to online anomaly detection.This would enable more proactive and dynamic monitoring systems.Lastly, further exploration into extending the methodology beyond sensor data to other domains could broaden the impact of this framework across diverse industries.This methodology could be extended to areas such as financial fraud detection (transaction data) or healthcare diagnostics (image and medical data).This extension could involve reconfiguring the RAG process or adaptability mechanism to handle these new data types and scenarios.</p>
<p>Ultimately, RAAD-LLM represents a promising shift in how anomaly detection is approached, balancing interpretability, accuracy, and adaptability to meet the growing demands of modern industrial applications.</p>
<p>Fig. 2 :
2
Fig. 2: The model framework of RAAD-LLM.Given an input time series Q from the dataset D under consideration, we first preprocess it using SPC techniques.Then (1) Q is partitioned into a comparison dataset C and query windows Q (p) , where p ∈ P and P is the number of segmented windows.Next, statistical measures for C and Q (p) are calculated and (2) injected into text templates.These templates are combined with task instructions to create the input prompt.To enhance the LLM's reasoning ability, (3) domain context is added to the prompt.Statistical measures for all input variables are sent to the RAG component (4) to retrieve relevant z-score comparison information from the knowledge base.Retrieved information is combined with the prompt before being fed forward through the frozen LLM.The output from the LLM is (5) mapped to {0, 1} via a binarization function to obtain the final prediction.(6) Updates to C are determined before moving to the next Q (p) .</p>
<p>Fig. 6 :
6
Fig. 6: Process flow diagram of major components in our usecase extrusion process.The major components in the extrusion process are in a series configuration.The number of Feed and Screw/Barrel Systems depends on the manufacturing line number and can be 3, 4, or 5.</p>
<p>Fig. 7 :
7
Fig. 7: The die head system for our use-case.The screen pack changer is identified by a red box.Within the screen pack changer, screens are used to prevent impurities from getting into the extruder together with the resin and thus clogging the die gap.The number of screen packs depend on the number of Screw/Barrel Systems.Each screen pack is arranged between the Screw/Barrel System and the Die Head System.During production, the resin melts flow through the screen pack.</p>
<p>Fig. 8 :
8
Fig. 8: Processed sensor data from the SKAB dataset.The selected signals are preprocessed to include only those experiments that were 20 minutes in duration.The first 3 minutes were discarded as process start-up.Each signal begins in a non-anomalous experimental state and continues until the end of the experiment.Non-anomalous states are shown in blue and anomalous states are shown in orange.Processed signals are then input into the frameworks.</p>
<p>TABLE II :
II
Average evaluation metrics over the best 5 model runs.</p>
<p>5 ± 0.8%, FAR of 42.1 ± 0.9%, and MAR of 11.4 ± 2.3%.As with the use-case
AlgorithmF1 FAR, % MAR, % No Training or Fine-tuning MultimodalPerfect detector100RAAD-LLM0.7442.0511.43yesyesLSTMCaps [48]0.7421.518.74nonoMSET [49]0.7320.8220.08nonoLSTMCapsV2 [48] 0.7114.5130.59nonoRAAD-LLMv20.7042.0518.67yesyesMSCRED [50]0.7016.230.87nonoVanilla LSTM [51] 0.6715.4236.02nonoConv-AE [52]0.665.5846.05nonoLSTM-AE [53]0.6514.5939.42nonoAAD-LLM0.5647.631.7yesyesLSTM-VAE [54]0.569.254.81nonoVanilla AE [55]0.457.5566.57nonoIsolation forest [56] 0.46.8672.09nonoNull detector0100100</p>
<p>TABLE III :
III
[48] outlier detection scores for each anomaly detection method implemented on the SKAB dataset, sorted by F1 score[48].A selection of NNs and ML based fault detection methods were chosen to compare on the benchmarks.RAAD-LLM and RAAD-LLMv2 metrics are averaged over the best 5 model runs.Multimodality allows for the enriching of input series data with semantics to enable more collaborative decision-making between the model and plant operators.For this work, multimodality refers to a model being optimized to detect anomalies across both time-series data and text.A model that requires no training or fine-tuning on the data it is applied to is considered transferable with zero-shot capabilities.Unlike all other methods, AAD-LLM, RAAD-LLM, and RAAD-LLMv2 are not trained or fine-tuned on the dataset they are applied to and are multimodal without requiring any additional strategies.</p>
<p>Development of databases of intelligent expert systems for automatic control of product quality indicators. I G Blagoveshchenskiy, V G Blagoveshchenskiy, E M Besfamilnaya, V A Sumerin, Journal of Physics: Conference Series. 170512019dec 2020</p>
<p>A review on monitoring and advanced control strategies for precision irrigation. E A Abioye, M S Z Abidin, M S A Mahmud, S Buyamin, M H I Ishak, M K I A Rahman, A O Otuoze, P Onotu, M S A Ramli, Computers and Electronics in Agriculture. 1731054412020</p>
<p>Expert systems for food safety. M Filter, B Appel, A Buschulte, Food Toxicology • Food Safety. 20156</p>
<p>Internet of things based expert system for smart agriculture. R Shahzadi, J Ferzund, M Tausif, M A Suryani, International Journal of Advanced Computer Science and Applications. 792016</p>
<p>Online anomaly detection with concept drift adaptation using recurrent neural networks. S Saurav, P Malhotra, V Tv, N Gugulothu, L Vig, P Agarwal, G Shroff, Proceedings of the acm india joint international conference on data science and management of data. the acm india joint international conference on data science and management of data2018</p>
<p>Flags: A methodology for adaptive anomaly detection and root cause analysis on sensor data streams by fusing expert knowledge with machine learning. B Steenwinckel, D D Paepe, S V Hautte, P Heyvaert, M Bentefrit, P Moens, A Dimou, B V D Bossche, F D Turck, S V Hoecke, F Ongenae, Future Gener. Comput. Syst. 1162021</p>
<p>Adaptive anomaly detection and root cause analysis by fusing semantics and machine learning. B Steenwinckel, Extended Semantic Web Conference. 2018</p>
<p>Recent advances in prognostics and health management for advanced manufacturing paradigms. T Xia, Y Dong, L Xiao, S Du, E Pan, L Xi, Reliability Engineering and System Safety. 1782018</p>
<p>Language models are few-shot learners. T B Brown, B Mann, N Ryder, M Subbiah, J Kaplan, P Dhariwal, A Neelakantan, P Shyam, G Sastry, A Askell, S Agarwal, A Herbert-Voss, G Krueger, T Henighan, R Child, A Ramesh, D M Ziegler, J Wu, C Winter, C Hesse, M Chen, E Sigler, M Litwin, S Gray, B Chess, J Clark, C Berner, S Mccandlish, A Radford, I Sutskever, D Amodei, ArXiv. 2005.14165. 2020</p>
<p>Large language models are few-shot health learners. X Liu, D J Mcduff, G Kovács, I R Galatzer-Levy, J Sunshine, J Zhan, M.-Z Poh, S Liao, P D Achille, S N Patel, abs/2305.15525ArXiv. 2023</p>
<p>Language models are few-shot learners for prognostic prediction. Z Chen, M M Balan, K Brown, abs/2302.12692ArXiv. 2023</p>
<p>Large models for time series and spatio-temporal data: A survey and outlook. M Jin, Q Wen, Y Liang, C Zhang, S Xue, X Wang, J Y Zhang, Y Wang, H Chen, X Li, S Pan, V S Tseng, Y Zheng, L Chen, H Xiong, ArXiv. 2023</p>
<p>Large language models are zero-shot time series forecasters. N Gruver, M Finzi, S Qiu, A G Wilson, abs/2310.07820ArXiv. 2023</p>
<p>AAD-LLM: Adaptive Anomaly Detection Using Large Language Models. A Russell-Gilbert, A Sommers, A Thompson, L Cummins, S Mittal, S Rahimi, M Seale, J Jaboure, T Arnold, J Church, 2024 IEEE International Conference on Big Data (BigData). Los Alamitos, CA, USAIEEE Computer SocietyDec. 2024</p>
<p>Time-llm: Time series forecasting by reprogramming large language models. M Jin, S Wang, L Ma, Z Chu, J Y Zhang, X L Shi, P.-Y Chen, Y Liang, Y.-F Li, S Pan, Q Wen, abs/2310.01728ArXiv. 2023</p>
<p>E S Olivas, J D M Guerrero, M M Sober, J R M Benedito, A J S Lopez, Handbook Of Research On Machine Learning Applications and Trends: Algorithms, Methods and Techniques. </p>
<p>PA: Information Science Reference -Imprint of. Volumes, Hershey, 2009IGI Publishing</p>
<p>What is being transferred in transfer learning?. B Neyshabur, H Sedghi, C Zhang, ArXiv. 2008.11687, 2020</p>
<p>Repository: Personality research and assessment in the era of machine learning. C Stachl, F Pargent, S Hilbert, G M Harari, R Schoedel, S S Vaid, S D Gosling, M Bühner, 2019</p>
<p>The generalizability of machine learning models of personality across two text domains. M Berggren, L Kaati, B Pelzer, H Stiff, L Lundmark, N Akrami, Personality and Individual Differences. 2171124652024</p>
<p>Anomaly detection using a sliding window technique and data imputation with machine learning for hydrological time series. L Kulanuwat, C Chantrapornchai, M Maleewong, P Wongchaisuwat, S Wimala, K Sarinnapakorn, S Boonya-Aroonnet, Water. 13132021</p>
<p>The ASQ Certified Six Sigma Black Belt Handbook. M Mcshane-Vaughn, 2023ASQ Quality Press</p>
<p>Some perspectives on nonparametric statistical process control. P Qiu, Journal of Quality Technology. 502018</p>
<p>Introduction to statistical process control. P Qiu, 2013CRC press</p>
<p>Two robust multivariate exponentially weighted moving average charts to facilitate distinctive product quality features assessment. Z Song, A Mukherjee, P Qiu, M Zhou, Computers and Industrial Engineering. 1831094692023</p>
<p>A multivariate exponentially weighted moving average control. C A Lowry, W H Woodall, C W Champ, S E Rigdon, 199234Technometrics</p>
<p>A survey on rag meeting llms: Towards retrieval-augmented large language models. W Fan, Y Ding, L Ning, S Wang, H Li, D Yin, T.-S Chua, Q Li, 2024</p>
<p>Leveraging passage retrieval with generative models for open domain question answering. G Izacard, E Grave, ArXiv. 2007.01282, 2020</p>
<p>In-context retrieval-augmented language models. O Ram, Y Levine, I Dalmedigos, D Muhlgay, A Shashua, K Leyton-Brown, Y Shoham, Transactions of the Association for Computational Linguistics. 112023</p>
<p>Baleen: Robust multi-hop reasoning at scale via condensed retrieval. O Khattab, C Potts, M A Zaharia, abs/2101.00436ArXiv. 2021</p>
<p>Enhancing llm intelligence with arm-rag: Auxiliary rationale memory for retrieval augmented generation. E Melz, abs/2311.04177ArXiv. 2023</p>
<p>Retrieval-augmented generation for large language models: A survey. Y Gao, Y Xiong, X Gao, K Jia, J Pan, Y Bi, Y Dai, J Sun, Q Guo, M Wang, H Wang, abs/2312.10997ArXiv. 2023</p>
<p>Chronos: Learning the language of time series. A F Ansari, L Stella, C Turkmen, X Zhang, P Mercado, H Shen, O Shchur, S S Rangapuram, S P Arango, S Kapoor, J Zschiegner, D C Maddix, M W Mahoney, K Torkkola, A G Wilson, M Bohlke-Schneider, Y Wang, abs/2403.07815ArXiv. 2024</p>
<p>Promptcast: A new prompt-based learning paradigm for time series forecasting. H Xue, F D Salim, IEEE Transactions on Knowledge and Data Engineering. 2022</p>
<p>One fits all: Power general time series analysis by pretrained lm. T Zhou, P Niu, X Wang, L Sun, R Jin, Neural Information Processing Systems. 2023</p>
<p>Test: Text prototype aligned embedding to activate llm's ability for time series. C Sun, Y Li, H Li, Linda Qiao, abs/2308.08241ArXiv. 2023</p>
<p>A survey on anomaly detection in evolving data. M Salehi, L Rashidi, SIGKDD Explor. 202018with application to forest fire risk prediction</p>
<p>Adaptive anomaly detection in sensor data: A comprehensive approach. T Singh, S Nigam, E Vijay, R Rathore, S Bhosale, A Deogirikar, 2023 IEEE Technology &amp; Engineering Management Conference -Asia Pacific (TEMSCON-ASPAC). 2023</p>
<p>Adtcd: An adaptive anomaly detection approach toward concept drift in iot. L Xu, X Ding, H Peng, D Zhao, X Li, IEEE Internet of Things Journal. 102023</p>
<p>Enhancing deep learning with semantics: an application to manufacturing time series analysis. X Huang, C Zanni-Merk, B Crémilleux, Knowledge-Based and Intelligent Information and Engineering Systems: Proceedings of the 23rd International Conference KES2019. 2019159</p>
<p>Enhancing recommender systems with large language model reasoning graphs. Y Wang, Z Chu, X Ouyang, S Wang, H Hao, Y Shen, J Gu, S Xue, J Y Zhang, Q Cui, L Li, J Zhou, S Li, 2024</p>
<p>Leveraging large language models for pre-trained recommender systems. Z Chu, H Hao, X Ouyang, S Wang, Y Wang, Y Shen, J Gu, Q Cui, L Li, S Xue, J Y Zhang, S Li, 2023</p>
<p>Instruction tuning for large language models: A survey. S Zhang, L Dong, X Li, S Zhang, X Sun, S Wang, J Li, R Hu, T Zhang, F Wu, G Wang, abs/2308.10792ArXiv. 2023</p>
<p>Troubleshooting the Extrusion Process: A Systematic Approach to Solving Plastic Extrusion Problems. M E , C , 2019Carl Hanser Verlag GmbH &amp; Company KG</p>
<p>Extended context for instructgpt with llamaindex. B Zirnstein, 2023</p>
<p>Scalability and performance benchmarking of langchain, llamaindex, and haystack for enterprise ai customer support systems. R K Malviya, V Javalkar, R Malviya, IJGIS Fall of 2024 Conference, The New World Foundation. 2024</p>
<p>R K Malviya, V Javalkar, R Malviya, The new world foundation• ijgis fall of 2024 conference. </p>
<p>Skoltech anomaly benchmark (skab). I D Katser, V O Kozitsin, 2020</p>
<p>Multi-channel lstm-capsule autoencoder network for anomaly detection on multivariate data. A Elhalwagy, T Kalganova, Applied Sciences. 1211393Nov. 2022</p>
<p>Application of a model-based fault detection system to nuclear plant signals. K Gross, R Singer, S Wegerich, J Herzog, R Vanalstine, F Bockhorst, 1997</p>
<p>A deep neural network for unsupervised anomaly detection and diagnosis in multivariate time series data. C Zhang, D Song, Y Chen, X Feng, C Lumezanu, W Cheng, J Ni, B Zong, H Chen, N V Chawla, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial IntelligenceJul. 201933</p>
<p>Multivariate industrial time series with cyber-attack simulation: Fault detection using an lstmbased predictive data model. P Filonov, A Lavrentyev, A Vorontsov, 2016</p>
<p>Timeseries anomaly detection using an autoencoder. P Vijay, 2020</p>
<p>Building autoencoders in keras. F Chollet, 2016</p>
<p>Generating sentences from a continuous space. S R Bowman, L Vilnis, O Vinyals, A M Dai, R Józefowicz, S Bengio, Conference on Computational Natural Language Learning. 2015</p>
<p>Outlier detection with autoencoder ensembles. J Chen, S K Sathe, C C Aggarwal, D S Turaga, SDM. 2017</p>
<p>Isolation forest. F T Liu, K M Ting, Z.-H Zhou, 2008 Eighth IEEE International Conference on Data Mining. 2008</p>            </div>
        </div>

    </div>
</body>
</html>