<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1243 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1243</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1243</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-26.html">extraction-schema-26</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <p><strong>Paper ID:</strong> paper-235476723</p>
                <p><strong>Paper Title:</strong> Nobel Turing Challenge: creating the engine for scientific discovery</p>
                <p><strong>Paper Abstract:</strong> Scientific discovery has long been one of the central driving forces in our civilization. It uncovered the principles of the world we live in, and enabled us to invent new technologies reshaping our society, cure diseases, explore unknown new frontiers, and hopefully lead us to build a sustainable society. Accelerating the speed of scientific discovery is therefore one of the most important endeavors. This requires an in-depth understanding of not only the subject areas but also the nature of scientific discoveries themselves. In other words, the “science of science” needs to be established, and has to be implemented using artificial intelligence (AI) systems to be practically executable. At the same time, what may be implemented by “AI Scientists” may not resemble the scientific process conducted by human scientist. It may be an alternative form of science that will break the limitation of current scientific practice largely hampered by human cognitive limitation and sociological constraints. It could give rise to a human-AI hybrid form of science that shall bring systems biology and other sciences into the next stage. The Nobel Turing Challenge aims to develop a highly autonomous AI system that can perform top-level science, indistinguishable from the quality of that performed by the best human scientists, where some of the discoveries may be worthy of Nobel Prize level recognition and beyond.</p>
                <p><strong>Cost:</strong> 0.023</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1243.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1243.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AI Scientist (Nobel Turing Challenge)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>AI Scientist (as proposed by the Nobel Turing Challenge)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A proposed highly autonomous constellation of software and hardware modules that can generate hypotheses, plan and execute experiments, reason, learn from data and interactions, and communicate results with the goal of making top-level scientific discoveries (Nobel-Prize level) autonomously.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>AI Scientist (Nobel Turing Challenge)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A multiplexed, multi-agent system combining: (1) hypothesis generation modules (deep learning, generative models, qualitative physics), (2) automated experimental platforms and robotics (microfluidics, organs-on-chips, cloud robotic labs), (3) planning and decision modules (model-based and model-free RL, Bayesian experimental design), (4) knowledge representation and truth/argumentation maintenance (knowledge graphs, non-monotonic reasoning, argumentation modules), and (5) human-in-the-loop interfaces; designed for unbiased, exhaustive exploration of hypothesis space at scale and for long-term autonomous research selection and execution.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_domain</strong></td>
                            <td>Cross-domain (primarily life sciences/systems biology emphasized, but applicable to chemistry, materials science, mathematics, etc.)</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_description</strong></td>
                            <td>The envisioned system will autonomously generate massive sets of hypotheses (from molecular mechanisms to systems-level conceptual hypotheses), prioritize and design experiments, execute automated high-throughput and precision experiments, maintain evolving probabilistic knowledge graphs and argumentation chains, and iterate to produce validated discoveries at scale; the stated target is to produce discoveries comparable to top human scientists, including discoveries of "Nobel Prize level" significance.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type</strong></td>
                            <td>transformative; "alternative form of scientific discovery" (paper's terminology)</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type_justification</strong></td>
                            <td>The paper explicitly frames the AI Scientist as creating an "alternative form of scientific discovery" and a "transformative paradigm" by enabling unbiased, exhaustive exploration of hypothesis space at scales and in ways infeasible for human scientists; the goal is to produce continuous, high-impact discoveries up to Nobel-Prize level.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>Evaluation envisioned in multiple layers: (1) scientific quality of produced hypotheses and claims assessed via experimental verification and consistency with existing bodies of knowledge, (2) significance assessed against human-centered criteria (e.g., potential impact, novelty, community acceptance), (3) performance of submodules measured by standard ML/AI metrics (e.g., predictive accuracy, reinforcement-learning returns), and (4) system-level benchmarks such as reproducible closed-loop experiments, throughput (hypotheses tested per time), and ability to generate discoveries that humans would recognize as top-level (symbolically framed as "winning the Nobel Prize"). The paper emphasizes using experimental validation, truth-maintenance/argumentation scoring, and comparisons to human scientists as evaluation anchors.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approaches</strong></td>
                            <td>Primary validation via experimental verification (closed-loop hypothesis generation → protocol generation → experiments → data-based acceptance/rejection), reproduction and reproducibility tests, comparison to existing knowledge/databases, formal argumentation (theory of argumentation) and non-monotonic reasoning to track and falsify hypotheses, and peer/community acceptance (publications). The paper also notes use of knowledge graph forks and probabilistic scores to represent and validate which knowledge sets survive falsification.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment</strong></td>
                            <td>Novelty is assessed by (a) whether the hypothesis/claim is novel relative to existing knowledge corpora (text/databases), (b) whether experimental verification reveals previously unknown mechanisms or functions, and (c) whether the discovery enables new conceptual understanding or technologies. The paper stresses that exhaustive/unbiased search can find discoveries that humans would not have considered (over-the-horizon discoveries) and that novelty must be tracked via evolving knowledge graphs and argumentation.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_metrics</strong></td>
                            <td>Qualitative and system-level metrics discussed include: number of hypotheses generated/tested (throughput), ability to find discoveries of high significance (conceptually framed as "Nobel Prize level"), reproducibility and traceability of experiments, and adoption/use by human scientists. No single numeric thresholds are given; instead, the paper emphasizes continuous flow of discoveries and community recognition as impact measures.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_discoveries</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_details</strong></td>
                            <td>The paper repeatedly contrasts the AI Scientist with human scientists: humans are characterized as value-driven and intuition-limited, focusing on high-probability significant discoveries, while AI Scientist is exploration-driven, unbiased, and able to exhaustively search hypothesis space; the paper's aim is to build AI Scientists that are (almost) comparable to top human scientists and may pass variants of the Turing/Feigenbaum tests. It also argues that AI can explore low-expected-significance regions that humans avoid, potentially enabling transformational discoveries.</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Key challenges identified: (1) hypothesis space is vast/open-ended/infinite, (2) scientific descriptions are often noisy/incomplete, (3) experimental validation is costly/time-consuming, (4) reproducibility and reliability of published data are imperfect, (5) representing probabilistic/non-monotonic scientific knowledge is hard, (6) ethical/safety/ownership issues, (7) integrating diverse automation and data standards, and (8) distinguishing incremental vs transformational discoveries (the 'over-the-horizon' problem). These complicate evaluation and validation.</td>
                        </tr>
                        <tr>
                            <td><strong>has_incremental_transformational_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Nobel Turing Challenge: creating the engine for scientific discovery', 'publication_date_yy_mm': '2021-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1243.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e1243.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Adam</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Adam (Robot Scientist Adam)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A closed-loop 'robot scientist' system that performs automated hypothesis generation and experimental execution to discover orphan enzyme functions in budding yeast; an early proof-of-concept for automated discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Functional genomic hypothesis generation and experimentation by a robot scientist.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Adam (Robot Scientist)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Closed-loop system that automatically generates hypotheses from genomic data, designs experimental protocols, executes experiments using laboratory automation, and analyzes results to accept or reject hypotheses; optimized for functional genomics in yeast.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_domain</strong></td>
                            <td>Biology — functional genomics / enzymology (budding yeast)</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_description</strong></td>
                            <td>Adam generated and experimentally tested hypotheses about orphan enzymes and gene functions in yeast by automating assay execution and analysis, leading to functional annotations that were previously unknown.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type</strong></td>
                            <td>pioneering (paper uses term 'pioneering works') / special-purpose machine</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type_justification</strong></td>
                            <td>The paper calls Adam a 'pioneering' closed-loop system and emphasizes it as state-of-the-art demonstration of automated hypothesis generation and verification, but also notes it is 'highly automated, but not autonomous' and 'special-purpose'—i.e., a targeted, incremental step toward full AI Scientist capabilities rather than a paradigm-shift by itself.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>Experimental verification of hypotheses via laboratory assays; consistency checks against existing genomic knowledge; throughput and automation capability as system metrics were used to evaluate the system's utility.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approaches</strong></td>
                            <td>Direct experimental assays run by the system; validation by comparison of assay results to expected biochemical activities and by expert human inspection/publication; reproducibility improved via automation and traceability.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment</strong></td>
                            <td>Novelty assessed by whether a gene/enzyme function was previously unknown and experimentally demonstrated by Adam's assays; novelty is therefore grounded in experimental confirmation of previously orphan annotations.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_metrics</strong></td>
                            <td>Qualitative impacts: demonstration of closed-loop automated discovery and ability to handle genomic-scale hypothesis testing; no numeric discovery counts or success rates are given in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_discoveries</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_details</strong></td>
                            <td>Adam is presented as an advancement beyond human-run low-throughput pipelines by automating exhaustive hypothesis testing, but it is explicitly described as not fully autonomous and specialized; the paper positions Adam as an incremental, enabling technology rather than a human-level replacement.</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Domain specificity (yeast functional genomics), limited autonomy, dependence on human-specified problem framing, cost and throughput limitations relative to the full-scale vision, and the broader issues of integrating with evolving, noisy knowledge bases.</td>
                        </tr>
                        <tr>
                            <td><strong>has_incremental_transformational_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Nobel Turing Challenge: creating the engine for scientific discovery', 'publication_date_yy_mm': '2021-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1243.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e1243.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Eve</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Eve (Automated drug-repositioning system)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An automated system designed for drug repositioning screens for neglected diseases; identified drugs repurposed through automated screening and analysis.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Cheaper faster drug development validated by the repositioning of drugs against neglected tropical diseases.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Eve</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>An automated experimental pipeline for drug repositioning: generates candidate compounds/hypotheses, performs automated high-throughput assays, analyzes results, and surfaces repositioning opportunities; optimized for phenotypic screening workflows.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_domain</strong></td>
                            <td>Drug discovery / pharmacology (neglected tropical diseases)</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_description</strong></td>
                            <td>Eve performed automated repositioning screens and identified TP-470 (originally an angiogenesis inhibitor) as effective against malaria via DHFR inhibition—an instance of automated discovery through exhaustive screening and analysis.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type</strong></td>
                            <td>pioneering / special-purpose machine</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type_justification</strong></td>
                            <td>The paper describes Eve as a pioneering automated system enabling exhaustive verification for drug repositioning and notes it is 'highly automated, but not autonomous' and designed as a 'special-purpose' machine, implying an incremental but important technical advance.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>Experimental screening metrics (assay readouts, activity against pathogens), downstream mechanistic assays (e.g., binding or target inhibition), and cross-validation against known compound activities and literature.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approaches</strong></td>
                            <td>Laboratory assay confirmation, mechanistic follow-up experiments (identifying irreversible binding and DHFR inhibition), and comparison to previously published pharmacology data; peer-reviewed publication of findings.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment</strong></td>
                            <td>Novelty determined by identifying a new therapeutic use for an existing compound (drug repositioning) validated experimentally; novelty is therefore operationally defined by new, validated mechanism–disease links.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_metrics</strong></td>
                            <td>Qualitative impact: demonstrated reduced cost/time for repositioning screens; no system-level numeric success rates provided in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_discoveries</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_details</strong></td>
                            <td>Eve is framed as automating parts of what human researchers do in drug screens, enabling exhaustive verification beyond typical human-limited screening; nonetheless, it is a tool rather than an autonomous rival to top human scientists.</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Limited autonomy, specialized to drug-repositioning tasks, dependency on assay design and prior human specification of screening space, and reproducibility/data-quality considerations.</td>
                        </tr>
                        <tr>
                            <td><strong>has_incremental_transformational_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Nobel Turing Challenge: creating the engine for scientific discovery', 'publication_date_yy_mm': '2021-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1243.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e1243.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AlphaGo family</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>AlphaGo / AlphaGo Zero / AlphaZero / MuZero</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A series of deep-learning and reinforcement-learning based game-playing systems (AlphaGo, AlphaGo Zero, AlphaZero, MuZero) that achieved superhuman performance by combining neural networks with planning/search (MCTS) and, in some variants, self-play without human data.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Mastering the game of Go with deep neural networks and tree search.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>AlphaGo family (AlphaGo / AlphaGo Zero / AlphaZero / MuZero)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Combines deep neural networks (policy and value networks), reinforcement learning (self-play), and Monte Carlo Tree Search to explore state spaces: AlphaGo used supervised learning from human games + RL + MCTS; AlphaGo Zero learned from self-play without human data, exploring state space more broadly; AlphaZero generalized the approach across multiple games; MuZero learns a model of environment dynamics.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_domain</strong></td>
                            <td>Games (Go, Chess, Shogi, Atari) — used in paper as an analogy for strategies of exploration in scientific discovery</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_description</strong></td>
                            <td>These systems discovered superhuman strategies for board games; in this paper they are used as conceptual and algorithmic analogies demonstrating the power of unbiased exploration (AlphaGo Zero) and combined learning+search approaches that could be adapted to hypothesis generation and exploration in science.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type</strong></td>
                            <td>demonstration of 'unbiased exploration' leading to superhuman performance (paper's phrasing)</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type_justification</strong></td>
                            <td>The paper uses AlphaGo/AlphaGo Zero as examples showing that unbiased exploration (AlphaGo Zero's strategy) can outperform human-knowledge-tuned approaches and argues this illustrates a potential approach for exhaustive hypothesis exploration in science.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>Win-rate and head-to-head matches versus best human players and earlier programs; performance metrics for policy/value networks; success demonstrated by outperforming human champions and prior systems.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approaches</strong></td>
                            <td>Benchmark matches against human professionals and prior AIs, ablation studies, and statistical performance comparisons; in the paper these are analogical validations for using similar methods in science.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment</strong></td>
                            <td>Novelty demonstrated by learning to play without human knowledge (AlphaGo Zero) and generalizing learning across multiple games (AlphaZero/MuZero), indicating novel algorithms for exploration and learning that the paper suggests could be ported to scientific discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_metrics</strong></td>
                            <td>Practical impact metrics cited in original works are head-to-head wins and demonstrated superior performance; in this paper the impact is conceptual: showing the value of exploration-driven approaches versus value-driven human-centric approaches.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_discoveries</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_details</strong></td>
                            <td>Paper contrasts AlphaGo (which learned from human play and stayed near human strategies) with AlphaGo Zero (which started from random play and explored the full state space), using this to argue that exhaustive/unbiased exploration can produce strategies beyond human intuition—analogous to potentially transformative scientific discoveries.</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Key limits when mapping to science: scientific hypothesis space is open-ended/infinite (unlike finite game state spaces), scientific descriptions are noisier and evaluations (experiments) are costly/time-consuming, and hierarchical/continuous state representations complicate direct transfer.</td>
                        </tr>
                        <tr>
                            <td><strong>has_incremental_transformational_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Nobel Turing Challenge: creating the engine for scientific discovery', 'publication_date_yy_mm': '2021-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1243.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e1243.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Ramanujan Machine</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Ramanujan Machine (automated conjecture generation)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An automated system that generates conjectures (analytic formulae) for mathematical constants, offering a new perspective on machine-generated mathematical discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Generating conjectures on fundamental constants with the Ramanujan Machine.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Ramanujan Machine</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A computational approach that searches for formulae/conjectures for mathematical constants by combining number-theoretic search heuristics and pattern generation to propose conjectures (candidate identities) for human mathematicians to examine and prove.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_domain</strong></td>
                            <td>Mathematics (conjecture generation about constants)</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_description</strong></td>
                            <td>Automatically generated conjectures about fundamental constants (e.g., new identities) that can inspire human mathematicians to prove or further investigate; presented as an example of automation generating conceptual-level contributions.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type</strong></td>
                            <td>automated conjecture generation; 'added a new perspective' (paper's wording)</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type_justification</strong></td>
                            <td>The perspective paper cites the Ramanujan Machine as evidence that machines can generate conceptual-level mathematical conjectures, adding a new angle beyond parameter search—framed as novel but not yet fully autonomous discovery of proved theorems.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>Conjectures are evaluated by plausibility (numerical verification to high precision), by whether they are novel relative to published results, and ultimately by whether they can be proved by mathematicians.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approaches</strong></td>
                            <td>Numerical testing to very high precision, human mathematical proof or subsequent verification, and peer review of generated conjectures; the paper implies human follow-up is necessary to validate conjectures.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment</strong></td>
                            <td>Novelty assessed by whether the conjectures are previously unknown and whether they suggest new mathematical relationships; the system's contribution is in hypothesis/conjecture generation rather than final proofs.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_metrics</strong></td>
                            <td>Qualitative: ability to generate previously unknown conjectures and stimulate mathematical research; no numerical success rates provided in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_discoveries</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_details</strong></td>
                            <td>The paper treats Ramanujan Machine as an example of automated conceptual discovery that complements human mathematicians (machines generate conjectures; humans prove them), indicating a hybrid model rather than full replacement.</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Conjectures require human proof for acceptance; numerical evidence is necessary but insufficient; evaluating significance of conjectures is subjective and depends on mathematical community uptake.</td>
                        </tr>
                        <tr>
                            <td><strong>has_incremental_transformational_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Nobel Turing Challenge: creating the engine for scientific discovery', 'publication_date_yy_mm': '2021-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1243.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e1243.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Self-driving laboratory (MacLeod et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Self-driving laboratory for accelerated discovery of thin-film materials</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An autonomous experimental platform combining robotics, automated characterization, and machine-learning-guided experimental design to accelerate materials discovery (thin-film materials).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Self-driving laboratory for accelerated discovery of thin-film materials.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Self-driving laboratory (thin-film materials)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Integrates automated synthesis/characterization hardware with machine-learning algorithms (Bayesian optimization, active learning) to iteratively propose experiments, run them, and update models to accelerate discovery of target properties in materials science.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_domain</strong></td>
                            <td>Materials science (thin-film materials discovery)</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_description</strong></td>
                            <td>Accelerated discovery of thin-film materials with targeted properties by iteratively optimizing experimental parameters using machine-learning-guided closed-loop experimentation.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type</strong></td>
                            <td>accelerated autonomous discovery through automated workflows (paper frames as transformative in experimental throughput)</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type_justification</strong></td>
                            <td>Cited as evidence that automated closed-loop systems can greatly speed up discovery by enabling large-scale, efficient exploration of parameter spaces that would be time-prohibitive manually, supporting the paper's argument for exploration-driven discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>Performance measured by time-to-discovery, number of experiments required to achieve target performance versus human-guided search, and measured material properties from automated characterization.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approaches</strong></td>
                            <td>Experimental reproducibility and physical characterization of discovered materials; comparison with known results and human-guided baselines; efficacy of ML-guided optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment</strong></td>
                            <td>Novelty in demonstrating that closed-loop autonomous platforms can find desirable compositions/processes faster than traditional workflows, and in applying ML-guided design to complex experimental spaces.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_metrics</strong></td>
                            <td>Typical metrics include reduced experiments to target, acceleration factor versus manual search, and quality of materials found; the perspective paper cites such systems as exemplars but does not provide numeric multipliers itself.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_discoveries</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_details</strong></td>
                            <td>The paper uses self-driving labs to argue automation enables exploration of larger parameter spaces than human experimenters typically undertake, changing the balance from heuristic human search to exhaustive/ML-guided exploration.</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Integration complexity, domain-specific engineering of experimental hardware and assays, costly setup, and transferability across labs and domains; evaluation limited by experimental cost and reproducibility.</td>
                        </tr>
                        <tr>
                            <td><strong>has_incremental_transformational_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Nobel Turing Challenge: creating the engine for scientific discovery', 'publication_date_yy_mm': '2021-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1243.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e1243.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Robotic RPE cell-culture optimization (Kanda et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Robotic search for optimal cell culture in regenerative medicine (RPE cell culture optimization)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A robotic experimental system that searched ~200 million parameter combinations via Bayesian optimization with local penalization to identify conditions for medical-grade iPS-derived retinal pigment epithelial cell culture.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Robotic search for optimal cell culture in regenerative medicine.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Robotic RPE cell-culture optimization</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A high-throughput robotic platform combined with Bayesian optimization (with local penalization) to explore an extremely large experimental parameter space (hundreds of millions of combinations) and identify optimal culture conditions.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_domain</strong></td>
                            <td>Regenerative medicine / cell culture optimization</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_description</strong></td>
                            <td>Identified proper conditions for medical-grade iPS-derived retinal pigment epithelial (RPE) cell culture by searching an enormous combinatorial parameter space algorithmically and experimentally, demonstrating scalable robotic optimization in biology.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type</strong></td>
                            <td>demonstration of large-scale automated optimization (paper treats as exemplar of automated discovery capability)</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type_justification</strong></td>
                            <td>The paper uses this concrete numeric example (200 million parameter combinations searched) to illustrate how automated systems can explore far larger experimental spaces than feasible manually, supporting the exploration-driven model for discoveries.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>Bayesian optimization performance (convergence to optimal conditions), experimental readouts of RPE cell quality (biological assays), and comparison of found conditions to previously known protocols.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approaches</strong></td>
                            <td>Experimental confirmation of cell culture quality metrics under the recommended conditions; reproducibility through automated protocols; potentially downstream functional testing of cells.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment</strong></td>
                            <td>Novel because of scale (200M combinations) and demonstration that automated Bayesian-guided robotic search can find clinically relevant process conditions that would be infeasible to locate manually.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_metrics</strong></td>
                            <td>Numeric: ~200 million parameter combinations searched (paper cites this number); impact assessed by successful identification of medical-grade culture conditions.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_discoveries</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_details</strong></td>
                            <td>Paper emphasizes that such scale of search is infeasible for humans, positioning robotic optimization as enabling discoveries unreachable by manual exploration.</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>High computational and experimental cost, need for precise robotic control and assay robustness, potential overfitting to specific experimental contexts, and challenges in generalizing optimized protocols across labs.</td>
                        </tr>
                        <tr>
                            <td><strong>has_incremental_transformational_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Nobel Turing Challenge: creating the engine for scientific discovery', 'publication_date_yy_mm': '2021-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1243.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e1243.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Maholo LabDroids</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Maholo LabDroids (robotic crowd biology)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A robotic laboratory platform that enables reproducible, automated biological experiments and supports 'robotic crowd biology' approaches.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Robotic crowd biology with Maholo LabDroids.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Maholo LabDroids</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Robotic laboratory systems (LabDroids) that can execute standardized biological experimental protocols with high reproducibility and connectivity, enabling distributed and automated experimental campaigns.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_domain</strong></td>
                            <td>Biology — experimental automation / reproducibility</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_description</strong></td>
                            <td>Enables automated replication and execution of biological experiments at scale, facilitating reproducible discovery workflows and allowing distributed robotic experiments that can accelerate verification of hypotheses.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type</strong></td>
                            <td>automation for reproducibility and scaling of experiments (presented as enabling technology)</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type_justification</strong></td>
                            <td>Used as an example of technologies that increase reproducibility and throughput, thereby supporting exhaustive hypothesis verification crucial to the exploration-driven discovery approach described in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>Metrics for reproducibility, throughput, and fidelity of protocol execution; ability to run standardized experiments across sites.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approaches</strong></td>
                            <td>Experimental reproducibility tests, cross-laboratory comparisons, and traceable execution logs for auditing and verification.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment</strong></td>
                            <td>Novelty lies in combining robotic precision, cloud connectivity, and reproducibility to enable large-scale automated biological experimentation.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_metrics</strong></td>
                            <td>Qualitative: improved reproducibility and capacity to perform closed-loop experiments; no numeric success rates provided in the perspective.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_discoveries</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_details</strong></td>
                            <td>Paper contrasts automated, traceable, and reproducible robotic labs with human-run labs where reproducibility issues are common; positions systems like Maholo as solutions that enable reliable validation of automated discoveries.</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Cost, integration with diverse assays, standardization across laboratories, and the need to expand the repertoire of automatable protocols beyond the current majority (~86-89% automatable in one literature analysis).</td>
                        </tr>
                        <tr>
                            <td><strong>has_incremental_transformational_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Nobel Turing Challenge: creating the engine for scientific discovery', 'publication_date_yy_mm': '2021-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1243.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e1243.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Autonomous debating / Argumentation systems</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Autonomous debating systems / computational argumentation modules (e.g., Project Debater, autonomous debating system)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Automated argumentation and debating systems that can generate, present, and evaluate arguments for and against claims; proposed to support hypothesis evaluation, falsification, and explanation in AI Scientist pipelines.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>An autonomous debating system.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Autonomous debating / argumentation systems</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Systems that generate structured argumentation (supporting and rebutting arguments) using natural language processing, knowledge graphs, and debate-style reasoning to clarify evidence, assumptions, and counterarguments around scientific claims.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_domain</strong></td>
                            <td>Cross-domain (argumentation module for scientific discovery validation and explanation)</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_description</strong></td>
                            <td>Used as a proposed submodule for AI Scientists: generate arguments to support or falsify hypotheses, regenerate justifications, and present human-understandable explanations; helps maintain and update probabilistic knowledge graphs and perform falsification.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type</strong></td>
                            <td>evaluation/validation submodule (enabling technology rather than a discovery-maker itself)</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type_justification</strong></td>
                            <td>The paper cites computational debate systems as initial steps to implement mechanisms that automatically generate argumentations to support or falsify existing hypotheses, strengthening justification through experiments and reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>Quality of generated arguments assessed by coherence, logical structure, consistency with data, and human interpretability; may be benchmarked by debate outcomes or human expert evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approaches</strong></td>
                            <td>Human expert review, alignment with experimental data and knowledge graphs, and eventual experimental follow-up to resolve contested claims raised by debates.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment</strong></td>
                            <td>Novelty is in applying adversarial argumentation to the problem of scientific hypothesis maintenance and falsification, enabling automated generation of rebuttals and supporting experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_metrics</strong></td>
                            <td>Qualitative: ability to produce useful falsifications and to guide further verification experiments; no numeric metrics provided in the perspective.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_discoveries</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_details</strong></td>
                            <td>Paper suggests argumentation systems can augment human reasoning by systematically generating counterarguments and clarifying assumptions—this supports more rigorous validation than ad hoc human debate alone.</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Quality of generated arguments depends on the underlying knowledge base and NLP systems; risk of generating plausible-sounding but incorrect arguments; evaluation of argumentative value remains a research challenge.</td>
                        </tr>
                        <tr>
                            <td><strong>has_incremental_transformational_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Nobel Turing Challenge: creating the engine for scientific discovery', 'publication_date_yy_mm': '2021-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Functional genomic hypothesis generation and experimentation by a robot scientist. <em>(Rating: 2)</em></li>
                <li>Cheaper faster drug development validated by the repositioning of drugs against neglected tropical diseases. <em>(Rating: 2)</em></li>
                <li>Mastering the game of Go with deep neural networks and tree search. <em>(Rating: 2)</em></li>
                <li>Mastering the game of Go without human knowledge. <em>(Rating: 2)</em></li>
                <li>A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play. <em>(Rating: 2)</em></li>
                <li>Mastering Atari, Go, chess and shogi by planning with a learned model. <em>(Rating: 2)</em></li>
                <li>Generating conjectures on fundamental constants with the Ramanujan Machine. <em>(Rating: 2)</em></li>
                <li>Self-driving laboratory for accelerated discovery of thin-film materials. <em>(Rating: 2)</em></li>
                <li>Robotic crowd biology with Maholo LabDroids. <em>(Rating: 2)</em></li>
                <li>Robotic search for optimal cell culture in regenerative medicine. <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1243",
    "paper_id": "paper-235476723",
    "extraction_schema_id": "extraction-schema-26",
    "extracted_data": [
        {
            "name_short": "AI Scientist (Nobel Turing Challenge)",
            "name_full": "AI Scientist (as proposed by the Nobel Turing Challenge)",
            "brief_description": "A proposed highly autonomous constellation of software and hardware modules that can generate hypotheses, plan and execute experiments, reason, learn from data and interactions, and communicate results with the goal of making top-level scientific discoveries (Nobel-Prize level) autonomously.",
            "citation_title": "here",
            "mention_or_use": "mention",
            "system_name": "AI Scientist (Nobel Turing Challenge)",
            "system_description": "A multiplexed, multi-agent system combining: (1) hypothesis generation modules (deep learning, generative models, qualitative physics), (2) automated experimental platforms and robotics (microfluidics, organs-on-chips, cloud robotic labs), (3) planning and decision modules (model-based and model-free RL, Bayesian experimental design), (4) knowledge representation and truth/argumentation maintenance (knowledge graphs, non-monotonic reasoning, argumentation modules), and (5) human-in-the-loop interfaces; designed for unbiased, exhaustive exploration of hypothesis space at scale and for long-term autonomous research selection and execution.",
            "discovery_domain": "Cross-domain (primarily life sciences/systems biology emphasized, but applicable to chemistry, materials science, mathematics, etc.)",
            "discovery_description": "The envisioned system will autonomously generate massive sets of hypotheses (from molecular mechanisms to systems-level conceptual hypotheses), prioritize and design experiments, execute automated high-throughput and precision experiments, maintain evolving probabilistic knowledge graphs and argumentation chains, and iterate to produce validated discoveries at scale; the stated target is to produce discoveries comparable to top human scientists, including discoveries of \"Nobel Prize level\" significance.",
            "discovery_type": "transformative; \"alternative form of scientific discovery\" (paper's terminology)",
            "discovery_type_justification": "The paper explicitly frames the AI Scientist as creating an \"alternative form of scientific discovery\" and a \"transformative paradigm\" by enabling unbiased, exhaustive exploration of hypothesis space at scales and in ways infeasible for human scientists; the goal is to produce continuous, high-impact discoveries up to Nobel-Prize level.",
            "evaluation_methods": "Evaluation envisioned in multiple layers: (1) scientific quality of produced hypotheses and claims assessed via experimental verification and consistency with existing bodies of knowledge, (2) significance assessed against human-centered criteria (e.g., potential impact, novelty, community acceptance), (3) performance of submodules measured by standard ML/AI metrics (e.g., predictive accuracy, reinforcement-learning returns), and (4) system-level benchmarks such as reproducible closed-loop experiments, throughput (hypotheses tested per time), and ability to generate discoveries that humans would recognize as top-level (symbolically framed as \"winning the Nobel Prize\"). The paper emphasizes using experimental validation, truth-maintenance/argumentation scoring, and comparisons to human scientists as evaluation anchors.",
            "validation_approaches": "Primary validation via experimental verification (closed-loop hypothesis generation → protocol generation → experiments → data-based acceptance/rejection), reproduction and reproducibility tests, comparison to existing knowledge/databases, formal argumentation (theory of argumentation) and non-monotonic reasoning to track and falsify hypotheses, and peer/community acceptance (publications). The paper also notes use of knowledge graph forks and probabilistic scores to represent and validate which knowledge sets survive falsification.",
            "novelty_assessment": "Novelty is assessed by (a) whether the hypothesis/claim is novel relative to existing knowledge corpora (text/databases), (b) whether experimental verification reveals previously unknown mechanisms or functions, and (c) whether the discovery enables new conceptual understanding or technologies. The paper stresses that exhaustive/unbiased search can find discoveries that humans would not have considered (over-the-horizon discoveries) and that novelty must be tracked via evolving knowledge graphs and argumentation.",
            "impact_metrics": "Qualitative and system-level metrics discussed include: number of hypotheses generated/tested (throughput), ability to find discoveries of high significance (conceptually framed as \"Nobel Prize level\"), reproducibility and traceability of experiments, and adoption/use by human scientists. No single numeric thresholds are given; instead, the paper emphasizes continuous flow of discoveries and community recognition as impact measures.",
            "comparison_to_human_discoveries": true,
            "comparison_details": "The paper repeatedly contrasts the AI Scientist with human scientists: humans are characterized as value-driven and intuition-limited, focusing on high-probability significant discoveries, while AI Scientist is exploration-driven, unbiased, and able to exhaustively search hypothesis space; the paper's aim is to build AI Scientists that are (almost) comparable to top human scientists and may pass variants of the Turing/Feigenbaum tests. It also argues that AI can explore low-expected-significance regions that humans avoid, potentially enabling transformational discoveries.",
            "success_rate": null,
            "challenges_limitations": "Key challenges identified: (1) hypothesis space is vast/open-ended/infinite, (2) scientific descriptions are often noisy/incomplete, (3) experimental validation is costly/time-consuming, (4) reproducibility and reliability of published data are imperfect, (5) representing probabilistic/non-monotonic scientific knowledge is hard, (6) ethical/safety/ownership issues, (7) integrating diverse automation and data standards, and (8) distinguishing incremental vs transformational discoveries (the 'over-the-horizon' problem). These complicate evaluation and validation.",
            "has_incremental_transformational_comparison": true,
            "uuid": "e1243.0",
            "source_info": {
                "paper_title": "Nobel Turing Challenge: creating the engine for scientific discovery",
                "publication_date_yy_mm": "2021-06"
            }
        },
        {
            "name_short": "Adam",
            "name_full": "Adam (Robot Scientist Adam)",
            "brief_description": "A closed-loop 'robot scientist' system that performs automated hypothesis generation and experimental execution to discover orphan enzyme functions in budding yeast; an early proof-of-concept for automated discovery.",
            "citation_title": "Functional genomic hypothesis generation and experimentation by a robot scientist.",
            "mention_or_use": "mention",
            "system_name": "Adam (Robot Scientist)",
            "system_description": "Closed-loop system that automatically generates hypotheses from genomic data, designs experimental protocols, executes experiments using laboratory automation, and analyzes results to accept or reject hypotheses; optimized for functional genomics in yeast.",
            "discovery_domain": "Biology — functional genomics / enzymology (budding yeast)",
            "discovery_description": "Adam generated and experimentally tested hypotheses about orphan enzymes and gene functions in yeast by automating assay execution and analysis, leading to functional annotations that were previously unknown.",
            "discovery_type": "pioneering (paper uses term 'pioneering works') / special-purpose machine",
            "discovery_type_justification": "The paper calls Adam a 'pioneering' closed-loop system and emphasizes it as state-of-the-art demonstration of automated hypothesis generation and verification, but also notes it is 'highly automated, but not autonomous' and 'special-purpose'—i.e., a targeted, incremental step toward full AI Scientist capabilities rather than a paradigm-shift by itself.",
            "evaluation_methods": "Experimental verification of hypotheses via laboratory assays; consistency checks against existing genomic knowledge; throughput and automation capability as system metrics were used to evaluate the system's utility.",
            "validation_approaches": "Direct experimental assays run by the system; validation by comparison of assay results to expected biochemical activities and by expert human inspection/publication; reproducibility improved via automation and traceability.",
            "novelty_assessment": "Novelty assessed by whether a gene/enzyme function was previously unknown and experimentally demonstrated by Adam's assays; novelty is therefore grounded in experimental confirmation of previously orphan annotations.",
            "impact_metrics": "Qualitative impacts: demonstration of closed-loop automated discovery and ability to handle genomic-scale hypothesis testing; no numeric discovery counts or success rates are given in this paper.",
            "comparison_to_human_discoveries": true,
            "comparison_details": "Adam is presented as an advancement beyond human-run low-throughput pipelines by automating exhaustive hypothesis testing, but it is explicitly described as not fully autonomous and specialized; the paper positions Adam as an incremental, enabling technology rather than a human-level replacement.",
            "success_rate": null,
            "challenges_limitations": "Domain specificity (yeast functional genomics), limited autonomy, dependence on human-specified problem framing, cost and throughput limitations relative to the full-scale vision, and the broader issues of integrating with evolving, noisy knowledge bases.",
            "has_incremental_transformational_comparison": true,
            "uuid": "e1243.1",
            "source_info": {
                "paper_title": "Nobel Turing Challenge: creating the engine for scientific discovery",
                "publication_date_yy_mm": "2021-06"
            }
        },
        {
            "name_short": "Eve",
            "name_full": "Eve (Automated drug-repositioning system)",
            "brief_description": "An automated system designed for drug repositioning screens for neglected diseases; identified drugs repurposed through automated screening and analysis.",
            "citation_title": "Cheaper faster drug development validated by the repositioning of drugs against neglected tropical diseases.",
            "mention_or_use": "mention",
            "system_name": "Eve",
            "system_description": "An automated experimental pipeline for drug repositioning: generates candidate compounds/hypotheses, performs automated high-throughput assays, analyzes results, and surfaces repositioning opportunities; optimized for phenotypic screening workflows.",
            "discovery_domain": "Drug discovery / pharmacology (neglected tropical diseases)",
            "discovery_description": "Eve performed automated repositioning screens and identified TP-470 (originally an angiogenesis inhibitor) as effective against malaria via DHFR inhibition—an instance of automated discovery through exhaustive screening and analysis.",
            "discovery_type": "pioneering / special-purpose machine",
            "discovery_type_justification": "The paper describes Eve as a pioneering automated system enabling exhaustive verification for drug repositioning and notes it is 'highly automated, but not autonomous' and designed as a 'special-purpose' machine, implying an incremental but important technical advance.",
            "evaluation_methods": "Experimental screening metrics (assay readouts, activity against pathogens), downstream mechanistic assays (e.g., binding or target inhibition), and cross-validation against known compound activities and literature.",
            "validation_approaches": "Laboratory assay confirmation, mechanistic follow-up experiments (identifying irreversible binding and DHFR inhibition), and comparison to previously published pharmacology data; peer-reviewed publication of findings.",
            "novelty_assessment": "Novelty determined by identifying a new therapeutic use for an existing compound (drug repositioning) validated experimentally; novelty is therefore operationally defined by new, validated mechanism–disease links.",
            "impact_metrics": "Qualitative impact: demonstrated reduced cost/time for repositioning screens; no system-level numeric success rates provided in this paper.",
            "comparison_to_human_discoveries": true,
            "comparison_details": "Eve is framed as automating parts of what human researchers do in drug screens, enabling exhaustive verification beyond typical human-limited screening; nonetheless, it is a tool rather than an autonomous rival to top human scientists.",
            "success_rate": null,
            "challenges_limitations": "Limited autonomy, specialized to drug-repositioning tasks, dependency on assay design and prior human specification of screening space, and reproducibility/data-quality considerations.",
            "has_incremental_transformational_comparison": true,
            "uuid": "e1243.2",
            "source_info": {
                "paper_title": "Nobel Turing Challenge: creating the engine for scientific discovery",
                "publication_date_yy_mm": "2021-06"
            }
        },
        {
            "name_short": "AlphaGo family",
            "name_full": "AlphaGo / AlphaGo Zero / AlphaZero / MuZero",
            "brief_description": "A series of deep-learning and reinforcement-learning based game-playing systems (AlphaGo, AlphaGo Zero, AlphaZero, MuZero) that achieved superhuman performance by combining neural networks with planning/search (MCTS) and, in some variants, self-play without human data.",
            "citation_title": "Mastering the game of Go with deep neural networks and tree search.",
            "mention_or_use": "mention",
            "system_name": "AlphaGo family (AlphaGo / AlphaGo Zero / AlphaZero / MuZero)",
            "system_description": "Combines deep neural networks (policy and value networks), reinforcement learning (self-play), and Monte Carlo Tree Search to explore state spaces: AlphaGo used supervised learning from human games + RL + MCTS; AlphaGo Zero learned from self-play without human data, exploring state space more broadly; AlphaZero generalized the approach across multiple games; MuZero learns a model of environment dynamics.",
            "discovery_domain": "Games (Go, Chess, Shogi, Atari) — used in paper as an analogy for strategies of exploration in scientific discovery",
            "discovery_description": "These systems discovered superhuman strategies for board games; in this paper they are used as conceptual and algorithmic analogies demonstrating the power of unbiased exploration (AlphaGo Zero) and combined learning+search approaches that could be adapted to hypothesis generation and exploration in science.",
            "discovery_type": "demonstration of 'unbiased exploration' leading to superhuman performance (paper's phrasing)",
            "discovery_type_justification": "The paper uses AlphaGo/AlphaGo Zero as examples showing that unbiased exploration (AlphaGo Zero's strategy) can outperform human-knowledge-tuned approaches and argues this illustrates a potential approach for exhaustive hypothesis exploration in science.",
            "evaluation_methods": "Win-rate and head-to-head matches versus best human players and earlier programs; performance metrics for policy/value networks; success demonstrated by outperforming human champions and prior systems.",
            "validation_approaches": "Benchmark matches against human professionals and prior AIs, ablation studies, and statistical performance comparisons; in the paper these are analogical validations for using similar methods in science.",
            "novelty_assessment": "Novelty demonstrated by learning to play without human knowledge (AlphaGo Zero) and generalizing learning across multiple games (AlphaZero/MuZero), indicating novel algorithms for exploration and learning that the paper suggests could be ported to scientific discovery.",
            "impact_metrics": "Practical impact metrics cited in original works are head-to-head wins and demonstrated superior performance; in this paper the impact is conceptual: showing the value of exploration-driven approaches versus value-driven human-centric approaches.",
            "comparison_to_human_discoveries": true,
            "comparison_details": "Paper contrasts AlphaGo (which learned from human play and stayed near human strategies) with AlphaGo Zero (which started from random play and explored the full state space), using this to argue that exhaustive/unbiased exploration can produce strategies beyond human intuition—analogous to potentially transformative scientific discoveries.",
            "success_rate": null,
            "challenges_limitations": "Key limits when mapping to science: scientific hypothesis space is open-ended/infinite (unlike finite game state spaces), scientific descriptions are noisier and evaluations (experiments) are costly/time-consuming, and hierarchical/continuous state representations complicate direct transfer.",
            "has_incremental_transformational_comparison": true,
            "uuid": "e1243.3",
            "source_info": {
                "paper_title": "Nobel Turing Challenge: creating the engine for scientific discovery",
                "publication_date_yy_mm": "2021-06"
            }
        },
        {
            "name_short": "Ramanujan Machine",
            "name_full": "Ramanujan Machine (automated conjecture generation)",
            "brief_description": "An automated system that generates conjectures (analytic formulae) for mathematical constants, offering a new perspective on machine-generated mathematical discovery.",
            "citation_title": "Generating conjectures on fundamental constants with the Ramanujan Machine.",
            "mention_or_use": "mention",
            "system_name": "Ramanujan Machine",
            "system_description": "A computational approach that searches for formulae/conjectures for mathematical constants by combining number-theoretic search heuristics and pattern generation to propose conjectures (candidate identities) for human mathematicians to examine and prove.",
            "discovery_domain": "Mathematics (conjecture generation about constants)",
            "discovery_description": "Automatically generated conjectures about fundamental constants (e.g., new identities) that can inspire human mathematicians to prove or further investigate; presented as an example of automation generating conceptual-level contributions.",
            "discovery_type": "automated conjecture generation; 'added a new perspective' (paper's wording)",
            "discovery_type_justification": "The perspective paper cites the Ramanujan Machine as evidence that machines can generate conceptual-level mathematical conjectures, adding a new angle beyond parameter search—framed as novel but not yet fully autonomous discovery of proved theorems.",
            "evaluation_methods": "Conjectures are evaluated by plausibility (numerical verification to high precision), by whether they are novel relative to published results, and ultimately by whether they can be proved by mathematicians.",
            "validation_approaches": "Numerical testing to very high precision, human mathematical proof or subsequent verification, and peer review of generated conjectures; the paper implies human follow-up is necessary to validate conjectures.",
            "novelty_assessment": "Novelty assessed by whether the conjectures are previously unknown and whether they suggest new mathematical relationships; the system's contribution is in hypothesis/conjecture generation rather than final proofs.",
            "impact_metrics": "Qualitative: ability to generate previously unknown conjectures and stimulate mathematical research; no numerical success rates provided in this paper.",
            "comparison_to_human_discoveries": true,
            "comparison_details": "The paper treats Ramanujan Machine as an example of automated conceptual discovery that complements human mathematicians (machines generate conjectures; humans prove them), indicating a hybrid model rather than full replacement.",
            "success_rate": null,
            "challenges_limitations": "Conjectures require human proof for acceptance; numerical evidence is necessary but insufficient; evaluating significance of conjectures is subjective and depends on mathematical community uptake.",
            "has_incremental_transformational_comparison": true,
            "uuid": "e1243.4",
            "source_info": {
                "paper_title": "Nobel Turing Challenge: creating the engine for scientific discovery",
                "publication_date_yy_mm": "2021-06"
            }
        },
        {
            "name_short": "Self-driving laboratory (MacLeod et al.)",
            "name_full": "Self-driving laboratory for accelerated discovery of thin-film materials",
            "brief_description": "An autonomous experimental platform combining robotics, automated characterization, and machine-learning-guided experimental design to accelerate materials discovery (thin-film materials).",
            "citation_title": "Self-driving laboratory for accelerated discovery of thin-film materials.",
            "mention_or_use": "mention",
            "system_name": "Self-driving laboratory (thin-film materials)",
            "system_description": "Integrates automated synthesis/characterization hardware with machine-learning algorithms (Bayesian optimization, active learning) to iteratively propose experiments, run them, and update models to accelerate discovery of target properties in materials science.",
            "discovery_domain": "Materials science (thin-film materials discovery)",
            "discovery_description": "Accelerated discovery of thin-film materials with targeted properties by iteratively optimizing experimental parameters using machine-learning-guided closed-loop experimentation.",
            "discovery_type": "accelerated autonomous discovery through automated workflows (paper frames as transformative in experimental throughput)",
            "discovery_type_justification": "Cited as evidence that automated closed-loop systems can greatly speed up discovery by enabling large-scale, efficient exploration of parameter spaces that would be time-prohibitive manually, supporting the paper's argument for exploration-driven discovery.",
            "evaluation_methods": "Performance measured by time-to-discovery, number of experiments required to achieve target performance versus human-guided search, and measured material properties from automated characterization.",
            "validation_approaches": "Experimental reproducibility and physical characterization of discovered materials; comparison with known results and human-guided baselines; efficacy of ML-guided optimization.",
            "novelty_assessment": "Novelty in demonstrating that closed-loop autonomous platforms can find desirable compositions/processes faster than traditional workflows, and in applying ML-guided design to complex experimental spaces.",
            "impact_metrics": "Typical metrics include reduced experiments to target, acceleration factor versus manual search, and quality of materials found; the perspective paper cites such systems as exemplars but does not provide numeric multipliers itself.",
            "comparison_to_human_discoveries": true,
            "comparison_details": "The paper uses self-driving labs to argue automation enables exploration of larger parameter spaces than human experimenters typically undertake, changing the balance from heuristic human search to exhaustive/ML-guided exploration.",
            "success_rate": null,
            "challenges_limitations": "Integration complexity, domain-specific engineering of experimental hardware and assays, costly setup, and transferability across labs and domains; evaluation limited by experimental cost and reproducibility.",
            "has_incremental_transformational_comparison": true,
            "uuid": "e1243.5",
            "source_info": {
                "paper_title": "Nobel Turing Challenge: creating the engine for scientific discovery",
                "publication_date_yy_mm": "2021-06"
            }
        },
        {
            "name_short": "Robotic RPE cell-culture optimization (Kanda et al.)",
            "name_full": "Robotic search for optimal cell culture in regenerative medicine (RPE cell culture optimization)",
            "brief_description": "A robotic experimental system that searched ~200 million parameter combinations via Bayesian optimization with local penalization to identify conditions for medical-grade iPS-derived retinal pigment epithelial cell culture.",
            "citation_title": "Robotic search for optimal cell culture in regenerative medicine.",
            "mention_or_use": "mention",
            "system_name": "Robotic RPE cell-culture optimization",
            "system_description": "A high-throughput robotic platform combined with Bayesian optimization (with local penalization) to explore an extremely large experimental parameter space (hundreds of millions of combinations) and identify optimal culture conditions.",
            "discovery_domain": "Regenerative medicine / cell culture optimization",
            "discovery_description": "Identified proper conditions for medical-grade iPS-derived retinal pigment epithelial (RPE) cell culture by searching an enormous combinatorial parameter space algorithmically and experimentally, demonstrating scalable robotic optimization in biology.",
            "discovery_type": "demonstration of large-scale automated optimization (paper treats as exemplar of automated discovery capability)",
            "discovery_type_justification": "The paper uses this concrete numeric example (200 million parameter combinations searched) to illustrate how automated systems can explore far larger experimental spaces than feasible manually, supporting the exploration-driven model for discoveries.",
            "evaluation_methods": "Bayesian optimization performance (convergence to optimal conditions), experimental readouts of RPE cell quality (biological assays), and comparison of found conditions to previously known protocols.",
            "validation_approaches": "Experimental confirmation of cell culture quality metrics under the recommended conditions; reproducibility through automated protocols; potentially downstream functional testing of cells.",
            "novelty_assessment": "Novel because of scale (200M combinations) and demonstration that automated Bayesian-guided robotic search can find clinically relevant process conditions that would be infeasible to locate manually.",
            "impact_metrics": "Numeric: ~200 million parameter combinations searched (paper cites this number); impact assessed by successful identification of medical-grade culture conditions.",
            "comparison_to_human_discoveries": true,
            "comparison_details": "Paper emphasizes that such scale of search is infeasible for humans, positioning robotic optimization as enabling discoveries unreachable by manual exploration.",
            "success_rate": null,
            "challenges_limitations": "High computational and experimental cost, need for precise robotic control and assay robustness, potential overfitting to specific experimental contexts, and challenges in generalizing optimized protocols across labs.",
            "has_incremental_transformational_comparison": true,
            "uuid": "e1243.6",
            "source_info": {
                "paper_title": "Nobel Turing Challenge: creating the engine for scientific discovery",
                "publication_date_yy_mm": "2021-06"
            }
        },
        {
            "name_short": "Maholo LabDroids",
            "name_full": "Maholo LabDroids (robotic crowd biology)",
            "brief_description": "A robotic laboratory platform that enables reproducible, automated biological experiments and supports 'robotic crowd biology' approaches.",
            "citation_title": "Robotic crowd biology with Maholo LabDroids.",
            "mention_or_use": "mention",
            "system_name": "Maholo LabDroids",
            "system_description": "Robotic laboratory systems (LabDroids) that can execute standardized biological experimental protocols with high reproducibility and connectivity, enabling distributed and automated experimental campaigns.",
            "discovery_domain": "Biology — experimental automation / reproducibility",
            "discovery_description": "Enables automated replication and execution of biological experiments at scale, facilitating reproducible discovery workflows and allowing distributed robotic experiments that can accelerate verification of hypotheses.",
            "discovery_type": "automation for reproducibility and scaling of experiments (presented as enabling technology)",
            "discovery_type_justification": "Used as an example of technologies that increase reproducibility and throughput, thereby supporting exhaustive hypothesis verification crucial to the exploration-driven discovery approach described in the paper.",
            "evaluation_methods": "Metrics for reproducibility, throughput, and fidelity of protocol execution; ability to run standardized experiments across sites.",
            "validation_approaches": "Experimental reproducibility tests, cross-laboratory comparisons, and traceable execution logs for auditing and verification.",
            "novelty_assessment": "Novelty lies in combining robotic precision, cloud connectivity, and reproducibility to enable large-scale automated biological experimentation.",
            "impact_metrics": "Qualitative: improved reproducibility and capacity to perform closed-loop experiments; no numeric success rates provided in the perspective.",
            "comparison_to_human_discoveries": true,
            "comparison_details": "Paper contrasts automated, traceable, and reproducible robotic labs with human-run labs where reproducibility issues are common; positions systems like Maholo as solutions that enable reliable validation of automated discoveries.",
            "success_rate": null,
            "challenges_limitations": "Cost, integration with diverse assays, standardization across laboratories, and the need to expand the repertoire of automatable protocols beyond the current majority (~86-89% automatable in one literature analysis).",
            "has_incremental_transformational_comparison": true,
            "uuid": "e1243.7",
            "source_info": {
                "paper_title": "Nobel Turing Challenge: creating the engine for scientific discovery",
                "publication_date_yy_mm": "2021-06"
            }
        },
        {
            "name_short": "Autonomous debating / Argumentation systems",
            "name_full": "Autonomous debating systems / computational argumentation modules (e.g., Project Debater, autonomous debating system)",
            "brief_description": "Automated argumentation and debating systems that can generate, present, and evaluate arguments for and against claims; proposed to support hypothesis evaluation, falsification, and explanation in AI Scientist pipelines.",
            "citation_title": "An autonomous debating system.",
            "mention_or_use": "mention",
            "system_name": "Autonomous debating / argumentation systems",
            "system_description": "Systems that generate structured argumentation (supporting and rebutting arguments) using natural language processing, knowledge graphs, and debate-style reasoning to clarify evidence, assumptions, and counterarguments around scientific claims.",
            "discovery_domain": "Cross-domain (argumentation module for scientific discovery validation and explanation)",
            "discovery_description": "Used as a proposed submodule for AI Scientists: generate arguments to support or falsify hypotheses, regenerate justifications, and present human-understandable explanations; helps maintain and update probabilistic knowledge graphs and perform falsification.",
            "discovery_type": "evaluation/validation submodule (enabling technology rather than a discovery-maker itself)",
            "discovery_type_justification": "The paper cites computational debate systems as initial steps to implement mechanisms that automatically generate argumentations to support or falsify existing hypotheses, strengthening justification through experiments and reasoning.",
            "evaluation_methods": "Quality of generated arguments assessed by coherence, logical structure, consistency with data, and human interpretability; may be benchmarked by debate outcomes or human expert evaluation.",
            "validation_approaches": "Human expert review, alignment with experimental data and knowledge graphs, and eventual experimental follow-up to resolve contested claims raised by debates.",
            "novelty_assessment": "Novelty is in applying adversarial argumentation to the problem of scientific hypothesis maintenance and falsification, enabling automated generation of rebuttals and supporting experiments.",
            "impact_metrics": "Qualitative: ability to produce useful falsifications and to guide further verification experiments; no numeric metrics provided in the perspective.",
            "comparison_to_human_discoveries": true,
            "comparison_details": "Paper suggests argumentation systems can augment human reasoning by systematically generating counterarguments and clarifying assumptions—this supports more rigorous validation than ad hoc human debate alone.",
            "success_rate": null,
            "challenges_limitations": "Quality of generated arguments depends on the underlying knowledge base and NLP systems; risk of generating plausible-sounding but incorrect arguments; evaluation of argumentative value remains a research challenge.",
            "has_incremental_transformational_comparison": true,
            "uuid": "e1243.8",
            "source_info": {
                "paper_title": "Nobel Turing Challenge: creating the engine for scientific discovery",
                "publication_date_yy_mm": "2021-06"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Functional genomic hypothesis generation and experimentation by a robot scientist.",
            "rating": 2,
            "sanitized_title": "functional_genomic_hypothesis_generation_and_experimentation_by_a_robot_scientist"
        },
        {
            "paper_title": "Cheaper faster drug development validated by the repositioning of drugs against neglected tropical diseases.",
            "rating": 2,
            "sanitized_title": "cheaper_faster_drug_development_validated_by_the_repositioning_of_drugs_against_neglected_tropical_diseases"
        },
        {
            "paper_title": "Mastering the game of Go with deep neural networks and tree search.",
            "rating": 2,
            "sanitized_title": "mastering_the_game_of_go_with_deep_neural_networks_and_tree_search"
        },
        {
            "paper_title": "Mastering the game of Go without human knowledge.",
            "rating": 2,
            "sanitized_title": "mastering_the_game_of_go_without_human_knowledge"
        },
        {
            "paper_title": "A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play.",
            "rating": 2,
            "sanitized_title": "a_general_reinforcement_learning_algorithm_that_masters_chess_shogi_and_go_through_selfplay"
        },
        {
            "paper_title": "Mastering Atari, Go, chess and shogi by planning with a learned model.",
            "rating": 2,
            "sanitized_title": "mastering_atari_go_chess_and_shogi_by_planning_with_a_learned_model"
        },
        {
            "paper_title": "Generating conjectures on fundamental constants with the Ramanujan Machine.",
            "rating": 2,
            "sanitized_title": "generating_conjectures_on_fundamental_constants_with_the_ramanujan_machine"
        },
        {
            "paper_title": "Self-driving laboratory for accelerated discovery of thin-film materials.",
            "rating": 2,
            "sanitized_title": "selfdriving_laboratory_for_accelerated_discovery_of_thinfilm_materials"
        },
        {
            "paper_title": "Robotic crowd biology with Maholo LabDroids.",
            "rating": 2,
            "sanitized_title": "robotic_crowd_biology_with_maholo_labdroids"
        },
        {
            "paper_title": "Robotic search for optimal cell culture in regenerative medicine.",
            "rating": 2,
            "sanitized_title": "robotic_search_for_optimal_cell_culture_in_regenerative_medicine"
        }
    ],
    "cost": 0.023186,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>PERSPECTIVE Nobel Turing Challenge: creating the engine for scientific discovery</p>
<p>Hiroaki Kitano 
The Systems Biology Institute
Okinawa Institute of Science and Technology Graduate School
Tokyo, OkinawaJapan, Japan</p>
<p>Sony Computer Science Laboratories, Inc
TokyoSonyJapan</p>
<p>AI, Inc
TokyoJapan</p>
<p>The Alan Turing Institute
LondonUK. ✉</p>
<p>PERSPECTIVE Nobel Turing Challenge: creating the engine for scientific discovery
10.1038/s41540-021-00189-3OPEN
Scientific discovery has long been one of the central driving forces in our civilization. It uncovered the principles of the world we live in, and enabled us to invent new technologies reshaping our society, cure diseases, explore unknown new frontiers, and hopefully lead us to build a sustainable society. Accelerating the speed of scientific discovery is therefore one of the most important endeavors. This requires an in-depth understanding of not only the subject areas but also the nature of scientific discoveries themselves. In other words, the "science of science" needs to be established, and has to be implemented using artificial intelligence (AI) systems to be practically executable. At the same time, what may be implemented by "AI Scientists" may not resemble the scientific process conducted by human scientist. It may be an alternative form of science that will break the limitation of current scientific practice largely hampered by human cognitive limitation and sociological constraints. It could give rise to a human-AI hybrid form of science that shall bring systems biology and other sciences into the next stage. The Nobel Turing Challenge aims to develop a highly autonomous AI system that can perform top-level science, indistinguishable from the quality of that performed by the best human scientists, where some of the discoveries may be worthy of Nobel Prize level recognition and beyond.npj Systems Biology and Applications (2021) 7:29 ; https://doi.</p>
<p>npj Systems Biology and Applications (2021) 7:29 ; https://doi.org/10.1038/s41540-021-00189-3 NOBEL TURING CHALLENGE AS AN ULTIMATE GRAND CHALLENGE Understanding, reformulating, and accelerating the process of scientific discovery is critical in solving problems we are facing and exploring the future. Building the machine to make it happen could be one of the most important contribution to society, and it will transform many areas of science and technology including systems biology. Since scientific research has been one of the most important activities that drove our civilization forward, the implications of such development will be profound.</p>
<p>Attempts to understand the process of scientific discoveries have a long tradition in the philosophy of science as well as artificial intelligence. Karl Popper introduced a concept of falsifiability as a criterion and process of solid scientific process but the process of hypothesis and concept generation do not have particular logic behind it 1 . Thomas Kuhn proposed a concept of a Paradigm shift where two competing paradigms are incommensurable and a set of knowledge, rather than a single knowledge, has to be switched with the transition of paradigm 2 . Imre Lakatos reconciles them by proposing actual science makes progress based on a "research program" composed of a hardcore that is immune to revision and flexible peripheral theories 3 . Contrary to these positions, Paul Feyerabend argued that there are no methodological rules in the scientific process 4 . Although these arguments are important thoughts in the philosophy of science, ideas are philosophical and not concrete to be implemented computationally. In addition, these studies are focused on how science is carried out as a part of human social activities. A rare example of implementing such concepts can be seen in the model inference system implemented by Ehud Shapiro that reflects Popper's falsifiability 5 .</p>
<p>Not surprisingly, scientific discovery has been a major topic in artificial intelligence research that dates back to DENDRAL 6 and META-DENDRAL, followed by MYCIN, BEACON 7 , AM, and EURISKO 6,8 . It continues to be one of the main topics of AI 9,10 . Recently, an automated experimental system that closed-the-loop of hypothesis generation, experimental planning, and execution has developed for budding yeast genetics that clearly marks the next step towards an AI Scientist [11][12][13] . While these pioneering works have focused on a single data set or a specific task using limited resources, it signifies the state-of-the-art of technology today that can be the basis of more ambitious challenges.</p>
<p>The obvious next step is to develop a system that makes scientific discoveries that shall truly impact the way we do science and aim for major discoveries. Therefore, I propose the launch of a grand challenge to develop AI systems that can make significant scientific discoveries that can outperform the best human scientist, with the ultimate purpose of creating the alternative form of scientific discovery 14 . Such a system, or systems, may be called "AI Scientist" that is most likely a constellation of software and hardware modules dynamically interacting to accomplish tasks. Since the critical feature that distinguishes it from conventional laboratory automation is its capability to generate hypotheses, learn from data and interactions with humans and other parts of the system, reasoning, and a high level of autonomous decision-making, the term "AI Scientist" best represents the characteristics of the system to be developed. The best way to accelerate the grand challenge of this nature is to define a clear mission statement with an audacious yet provocative goal such as winning the Nobel Prize 14 . Therefore, I propose the Nobel Turing Challenge as a grand challenge for artificial intelligence that aims at "developing AI Scientists capable of autonomously carrying out research to make major scientific discoveries and win a Nobel Prize by 2050". While the previous article 14 focused on rationales for such a challenge with emphasis on human cognitive limitations and needs for exhaustive search of hypothesis space, this article formulates the vision as the Nobel Turing Challenge and implications of massive and unbiased search 1 of hypothesis space and verification, architectural issues, and interaction with human scientists are discussed as a transformative paradigm in science. The distinct characteristic of this challenge is to field the system into an open-ended domain to explore significant discoveries rather than rediscovering what we already know or trying to mimic speculated human thought processes. The vision is to reformulate scientific discovery itself and to create an alternative form of scientific discovery.</p>
<p>The accomplishment of this challenge requires two goals to be achieved that are: (1) to develop an AI Scientist that performs scientific research highly autonomously enabling scientific discoveries at scale, and (2) to develop an AI Scientist capable of making strategic choices on the topic of research, that can communicate in the form of publications and other means to explain the value, methods, reasoning behind the discovery, and their applications and social implications. When both goals are met, the machine will be (almost) comparable to the top-level human scientist as well as being scientific collaborators. The question and challenge is whether the machine will be indistinguishable from the top-level human scientists and most likely pass the Feigenbaum Test which is a variation of the Turing Test 15 , or whether it will exhibit patterns of scientific discovery that are different from human scientists.</p>
<p>It should be noted "winning the Nobel Prize" is used as a symbolic target illustrating the level of discoveries the challenge is aiming at. The value lies in the development of machines that can make discoveries continuously and autonomously, rather than winning any award including the Nobel Prize. It is used as a symbolism that triggers inspiration and controversy.</p>
<p>At the same time, the implication of the statement that explicitly aims to win the Nobel Prize poses a series of interesting questions whether such AI systems making a decisive discovery may also evolve to be indistinguishable from the top human scientist (passing the Feigenbaum Test 16 ). As witness in case of Satoshi Nakamoto's blockchain and bitcoin, there is a case where a decisive contribution was simply published as a blogpost 17 and taken seriously, yet no one ever met him and his identity (at the time of writing) is a complete mystery. Given the possibility of creating a highly sophisticated virtual agent to interact with a human, with natural language capability to generate professional article, it will be non-trivial to distinguish whether such a scientist is human or AI. If a developer of an AI Scientist determined to create a virtual persona of a scientist with an ORCID iD, for demonstration of technological achievement, product promotion, or for another motivation, it would be almost impossible to distinguish between the AI and human scientist. The challenge shall be considered practically achieved when the Nobel Prize committee is alerted for any confusion on potential recipients. We might expect an AI Scientist detection system to be developed to identify who is an AI Scientist or not, that may resemble Deckard's interrogation of Rachael in Blade Runner.</p>
<p>It shall be made clear that this goal does not state or imply that "all major discoveries will be made by AI Scientists", nor that completeness of hypotheses or discoveries made by AI Scientist will be achieved. The challenge is fundamentally different from any attempts to prove the completeness of the system, including the Hilbert Program intended to prove axiomatic completeness of mathematic where feasibility is debunked by Incompleteness theorems by Kurt Gödel. It simply implies: "among discoveries made by AI Scientists, there should be discoveries that are considered very significant at the level worthy of the Nobel Prize or beyond". The challenge is initiated based on the belief any significant acceleration of scientific discovery would benefits our civilization. This will be achieved by creating an alternative form of scientific discovery, and will change the form of science as we know as well as uncovering the essence of scientific discovery. The utility of such technology shall benefit broader areas of science, industry, and society.</p>
<p>The core of the research program shall be about "Science of Science" rather than "Science of the process of science by human scientists". As in the case of past AI grand challenges, the best and perhaps the only way to demonstrate that scientific discovery can be reformulated computationally is to develop an AI system that outperforms the best human scientists. Furthermore, it is not sufficient to have AI Scientist make one discovery, it shall generate a continuous flow of discoveries at scale. The fundamental purpose behind this challenge is to uncover and reformulate the process of scientific discovery and develop a scalable system to perform it that may result in an alternative form of scientific discovery that we have not seen before.</p>
<p>Case studies: scientific discovery as a problem-solving Herbert Simon argued that science is problem-solving in his article "The Scientist as Problem Solver" 18 . Scientists set themselves tasks of solving significant scientific problems. If this postulation holds, defining the problem and strategy and tactics to solve these problems is the essence of scientific discoveries.</p>
<p>An example of the discovery of cellular reprogramming leading to iPS cell and regenerative medicine by Shinya Yamanaka is consistent with this framework 19,20 . It has a well-defined goal with obvious scientific and medical implications, and search and optimization has been performed beautifully to discover cellular reprogramming capability using four transcription factors, now known to be Yamanaka factors 21 .</p>
<p>Another example is the discovery of conducting polymer by Hideki Shirakawa, Alan MacDiarmid, and Alan Heeger. It started with an accident that an intern researcher at Shirakawa's Lab mistakenly used an abnormally high concentration of chemicals that formed thin film. Shikawaka noticed this accidental discovery and optimized the condition of thin-film formation. Then, with MacDiarmiad and Heeger, they identified a condition for conducting polymer formation. The initial experiments with an accidentally high dose of the chemical can be view as a stochastic search process where search space was extended beyond normal scope followed by extensive search and optimization for stable thin-film formation 22 .</p>
<p>The very simplified processes of these discoveries are shown in Fig. 1. These examples, among many other cases, exemplify the process of scientific discovery as problems solving and typical tactics are search and optimization.</p>
<p>Deep and unbiased exploration of hypothesis space as an alternative form of science Discovery with an exhaustive search of hypothesis space is what characterizes AI Scientist. In the traditional approach, scientists wish to maximize the probability that the discovery they make will be significant under certain criteria. In other words, scientists are focusing on making significant discoveries and are not interested in the number of discoveries made. This is the value-driven approach. In the alternative approach, the system will learn to maximize the probability that discovery at any level of significance can be made without imposing any value-driven criteria. This is an exploration-driven approach that is an unbiased exploration of hypotheses and makes sharp contrast against the current practice of science. This approach subsumes the problem-solving approach because specific problems will be included in hypotheses generated by an unbiased search of hypothesis space and their verification. This means AI Scientist will generate-and-verify as many hypotheses as possible, expecting some of them may lead to major discoveries by themselves or be a basis of major discoveries. A capability to generate hypotheses exhaustively and efficiently verify them is the core of the system and it can be the engine that gives horsepower to the system. This transition of a value-based approach to exploration-based approach driven by the unbiased search of hypotheses space may resemble a transition from the intuition-driven design of experiments to unbiased exhaustive measurements represented by omics-approach made possible with microarray and highthroughput genome sequencers, combined with bioinformatics supported by powerful computing resources. Unbiased hypotheses generation and verification will be built on the unbiased measurement of the well-established omics-approach, hypothesis generation system, a series of machine learning and reasoning systems, and robotics-based experimental systems. This is a logical evolution of the modality of science where a vast hypothesis space is searched in an unbiased manner rather than depending on human intuition.</p>
<p>A potential argument against this approach is that such a brute force approach is too inefficient and may not lead to any significant discoveries. Furthermore, one may argue that asking the right question is most important in science rather than brute force exploration. It is interesting to note that in the early days of AI research, it was widely accepted that a brute force approach would not work for complex problems such as chess, and that heuristic programming was essential for very large and complex problems 23 . The actual history of AI clearly demonstrated massive computing and machine learning is the key to success as seen in DeepBlue 24 and AlphaGo 25 .</p>
<p>Does that lessen apply to scientific discovery? There are three notable differences that are: (1) hypothesis space in scientific discovery is vast, open-ended, and possibly infinite as opposed to huge but finite space as in most games, (2) description in science, either knowledge or data, is not well-defined and often inaccurate whereas the well-defined description of game states and records exist in most games, and (3) evaluating hypothesis is likely to be more costly and time-consuming in science due to involvement of experiments. However, these issues can be made manageable and series of technologies to make them manageable will transform science and bring it to the next stage.</p>
<p>The exploration of hypothesis space in scientific discovery The hypothesis space for scientific discovery is huge and complex as opposed to very big but finite, well-defined, and monolithic state-space in games. State-space for games such as Chess, Shogi, and Go are finite, quantized, completely observable, and monolithic. For example, the game of Go is known to have a state-space complexity in order of 10 170 and a game tree complexity in order of 10 360 . Every state of the game can be fully and unambiguously describable with a set of coordinates. There is no hierarchical structure in the state space. This is not the case in scientific discovery. The size of an entire hypothesis space is infinite or undefinable. States of objects involve substantial continuous values of higher-order dimensions. Nested hierarchical structures are prevalent. While it appears to be fundamentally different, much can be learned and adapted from experiences in building AI systems for gaming.</p>
<p>The most recent and significant success of building AI system for a board game is AlphaGo series that beat the best human players. AlphaGo combined deep learning, reinforcement learning, and Monte-Carlo Tree Search (MCTS) to explore possible state space and game tree to learn best possible play within an explored state space 25 . State spaces are explored based on predictions of possible next moves generated by networks trained through supervised learning of past records of Game of Go (SL policy network) and MCTS expanded a search space. Reinforcement learning using self-play improves policy network and a value network is trained to properly evaluate game status. This approach enabled AlphaGo to learn how humans played, and how humans may play in the possible game state that has proximity to the past game ( Fig. 2a, orange circle). AlphaGo Zero starts from a random move and learns to play purely using reinforcement learning without human knowledge 26 . Interestingly, AlphaGo Zero not only outperforms the best human players, it outperforms AlphaGo as well. This demonstrates the strength of unbiased exploration of state space as AlphaGo Zero explores an entire state space of Go where AlphaGo incrementally searches the vicinity of human play styles (Fig. 2a, green space). AlphaZero 27 and MuZero 28 further extend such approaches to be able to learn and exhibit superhuman capability in multiple different games by learning game dynamics with model-free and mode-based reinforcement learning, respectively.</p>
<p>A part of such an approach can be applied to scientific discovery. With AlphaGo levels of approach, a set of hypotheses can be generated using a body of knowledge accumulated to date, and it can be tested against a body of knowledge for their consistency and verified experimentally (Fig. 2b, orange circle). Enhancing the level of complexity of hypothesis and automation of experimental verification, exploration can be extended to hypothesis space where it was not practical with an incremental extension of current scientific practice (Fig. 2b, blue circle). The challenge would be to implement AlphaGo Zero strategy to randomly generate hypotheses for an entire hypothesis space because the hypothesis space can be infinite and undefinable (Fig.  2b, green zone). However, practical approaches may exist to solve this issue by leveraging the intrinsic structure of problem domains.  Fig. 1 Very simplified process of scientific discoveries of iPS and conducting polymer. Search and optimization plays a critical role in the process of discovery. Yamanaka's case is interesting because a search was conducted in bioinformatics followed by experiment-driven optimization that may be well suited for AI Scientist in the future.</p>
<p>In biomedical sciences, any biological phenomena are the result of molecular interactions. It can be a simple interaction or involve a very complex network composed of very large numbers of molecules. Interactions among cells or even individuals can be attributed to molecular interactions. Information of any kind will be received by receptors to be meaningful for a biological system, therefore converted into molecular interactions. The explorationdriven approach in biomedical science leverages such intrinsic characteristics of application domains and may start from generating and testing hypotheses for basic biological mechanisms such as molecular interactions, genetic functions, metabolic reactions, material properties, and so forth and explore them at an unprecedented scale. Since most discoveries in biomedical science are on mechanisms behind diseases or specific biological phenomena exhaustive and unbiased exploration of molecular mechanisms shall be a building block for uncovering complex mechanisms for more complex biological phenomena (Fig. 3).</p>
<p>Therefore, it is reasonable to assume that the first stage of the project focuses on the hypothesis of a particular form, rather than unlimited and complex forms, specifically to identify molecular mechanisms behind biological processes. By focusing on the specific type of canonical form of knowledge, the problem is now relatively well-defined which is important as an opening game of the challenge. While the omics-approach uncovered massive data on genomes, transcriptomes, metabolomes, and interactomes, detailed and exhaustive characterization and precision measurements using low-throughput methods are required to verify specific molecular characteristics and nature interactions. Such processes are generally time-consuming and often not automated thus experiments are performed only for high priority targets. Automating such processes to match omics-scale enables exhaustive search and verification of a broader range of hypotheses, which shall lead to discoveries with high-impact biomedical and biotechnology applications.</p>
<p>There are pioneering works to turn this idea into reality. Adam, the first closed-loop system for scientific discovery, is designed to execute the discovery of orphan enzymes in budding yeast 11,13 . Eve was designed to perform an automated drug repositioning screen for neglected diseases and identified TP-470, originally developed as an angiogenesis inhibiting anti-cancer drug for its irreversible binding to methionine aminopeptidase-2, to be as effective as an anti-Malaria drug as a DHFR inhibitor 29 . These systems automated low-throughput assay processes and enabled exhaustive verification based on the hypothesis generated. These systems are highly automated, but not autonomous, as the problem to be solved and the process are fully designed by humans to the detail. These are special-purpose machines optimized for specific types of problems.</p>
<p>This process can be applied iteratively (Fig. 4a). A biological process in questions (h 1 ) may be explained by hypothesis h 2 or a combination of h 3 and h 4 , where h 2 , h 3 , and h 4 may have possible underlying molecular mechanisms of h 5 and h 6 , h 6 and h 7 , and h 8 , respectively. In such a case, a process of hypothesis generation and verification will be performed iteratively to verify or reject h 1 with a verified supporting mechanism either h 2 , h 3 , and h 4 . Generating experimental protocols and executing them is rather straightforward.</p>
<p>There are cases where a biological process can be only understood from a system dynamics perspective such as bifurcation and phase transition. A simple application of the iterative procedure to identify molecular mechanism is not sufficient. It requires reconstruction of molecular interaction network and analysis of their dynamical behaviors possibly underlying the process in question (Fig. 4b). This is more challenging as it requires the generation of hypothesis that link biological process with mathematical concepts and verifying them through experimental verification of network behaviors and molecular mechanisms composing the network.</p>
<p>Exhaustive exploration of hypothesis means a set of hypotheses is generated and verified rather than a single hypothesis. Thus, nodes of a hypothesis dependency tree in Fig. 4 shall be sets, rather than an element (Fig. 4c). Experiments shall be executed to verify an entire set of hypotheses, and protocols enabling such a  Fig. 2 A possible space of exploration by AI Scientists. Search space structures for a perfect information games as represented by the Game of GO and b scientific discovery are illustrated with commonalities and differences. While the search space for the Game of GO is well-defined, the search space for scientific discovery is open-ended. A practical initial strategy is to augment search space based on current scientific knowledge with human-centric AI-Human Hybrid system. An extreme option is to set search space broadly into distant hypothesis spaces where AI Scientist may discover knowledge that was unlikely to be discovered by the human scientist.</p>
<p>Explaining mechanisms of biological phenomena</p>
<p>Combinations of molecular mechanisms</p>
<p>Molecules involved</p>
<p>System dynamics context Experimental context Fig. 3 A basic structure of discovery in biology. Most discoveries in biology and medicine are concerned with the identification of mechanisms behind important biological processes. It can be fundamental processes such as cell cycle and cellular reprogramming or clinically relevant processes such as mechanisms of disease outbreak and progression. In many cases, this basic structure will be nested into multiple levels. It should be noted that "Molecular mechanisms" are biological processes by themselves, thus multilayer construction of this basic structure of discovery are inevitable.</p>
<p>H. Kitano process shall be generated. This may also include the generation of sub-hypothesis to be verified (Fig. 5).</p>
<p>The value of exhaustive generation of hypothesis and verification is in its potential capability to overcome the horizon problem. Assume that hypotheses are generated to maximize the expected significance of the discovery and tuned to focus highly expected value, such a strategy would work when the landscape is monotonically increasing (Fig. 6a). However, it may avert exploring paths to significant discovery, when a series of discoveries precondition to the significant one was low in expected significance (Fig. 6b). Searches may be terminated before reaching a significant discovery that may be located over-the-horizon. The landscape of discovery significance may be complex and nonmonotonic. By enabling exhaustive exploration of hypothesis space, AI Scientist can go beyond the area that is over-the-horizon without it. At the same time, AI Scientist is not free from resource limitation. One of the most important areas of research would be to find out how to sample hypothesis space to effectively identify its landscape. Machine learning-guided experimental design was shown to be effective in chemistry 30 and some of the principles can be applied here.</p>
<p>Knowledge of the world that science deals with is composed of multiple layers of abstraction, generally corresponding to the layers of systems in the domain. Discussions so far are centered around exploring and verifying hypothesis at molecular mechanisms, although it can be complex and nested. The next step shall be to uncover more complex phenomena and their dynamics that are interlinked with multiple layers of interaction, cells, organs, and individuals. This level further requires the identification of design principles and concepts behind complex systems (Fig. 7a). As discussed already, system dynamics play a central role in discoveries of this level, hence mathematical concept shall be  Fig. 4 Hypothesis dependency tree. a Each hypothesis is dependent upon other hypotheses that are related to molecular mechanisms. b A hypothesis in question can be verified only at the system-level analysis of molecular interaction network behaviors, c a set of hypotheses and their dependency tree where each element is also a set (e.g.,
H 1 ¼ h 0 1 ; h 1 1 ; h 2 1 ; Á Á Á ; h n 1 È É )
. In massive and exhaustive search of hypothesis space, a set of hypotheses, rather than a single hypothesis, is generated to cover specific hypothesis space and verified.  Fig. 5 Hypothesis tree. A hierarchical generation of hypothesis sets and data to verify them will be automatically generated and executed. Verification of Hypothesis set C requires both Hypothesis sets A and B to be verified. Verification data for Hypothesis sets A and B shall be obtained from experiments in general. In general, multiple data sets are required to fill various parameters of elements in Hypothesis set before finally tested in the verification process. This requires Data Set 1 for Hypothesis set A, and Data Sets 2 and 3 for Hypothesis set B need to be collected. Data sets 1, 2, and 3 can be obtained from databases, or through automated experiments. Verified Hypothesis sets A and B mean a set of elements of Hypothesis sets A and B that are verified to be true or entire sets with a score for each element. Given the hypothesis set to be verified, this process automatically generates hypothesis sets that need to be verified first and specifies the data sets required.</p>
<p>linked to biological processes (Fig. 4b). At the same time, actual biological systems are constrained by fundamental principles such as biochemistry and physics, systems principles such as feedback theory and information theory, selected through evolution and manifested in the context of the environment it lives (Fig. 7b). AI Scientist need to learn what are possible and impossible and what possible biology exist at present, and this could be potentially similar to learning models of game dynamics 28 , but in open-ended and a highly complex environment. The challenge is to find a way for the system to generate and test conceptual level hypotheses and test them. This shall be done in an unbiased manner. Methods such as model-based reinforcement learning and generative adversarial learning can be applied initially to investigate how to develop system that learn laws of nature at scale. Some recent studies demonstrate deep learning networks trained over millions of articles generate extensive molecular interactions 31 and the potential relationship between molecules and disease only using articles a year (or years) before such a relationship was discovered 32 . Deep learning was also used to uncover hierarchical structure and functions of cells 33 , deep generative models for discovering hidden structures 34 , precision phenotyping to predict genetic anomalies 35 , and many more. The outcome of such approaches is a set of hypotheses generated by deep learning and other AI methods from unbiased data, and hypotheses are generated in an unbiased manner. Such predictions can be a basis for the search for in-depth molecular relationships and functions. Furthermore, recent success in the Ramanujan Machine 36 in mathematics and the project Debater 37 in adversarial reasoning augmented possible approach that can be incorporated in the hypothesis generation process. Qualitative physics offers the opportunity to generate, match, and explain physical and mathematical concepts such as bifurcation and phase transition 38,39 . Combined with the capability of deep learning neural network to learn, classify, and generate nonlinear dynamics 40,41 , qualitative physics approach can be a powerful method for hypothesis generation and verification at the level of dynamical system concept. There are studies to use qualitative physics for biological processes 42,43 . This illustrates the potential of AI to be able to generate conceptual model exhaustively, assemble basic knowledge to be consistent with the conceptual model, and experimentally verify them. This approach essentially forces us to create a set of possible substructures of systems and search for structural matching with reality. With unbiased exploration at this level, AI Scientist shall be capable of exploring the complex dynamical system and may be able to discover new knowledge that is less likely to be discovered by human scientists.</p>
<p>The multiverse of knowledge in scientific discovery Generating hypotheses and maintaining a set of consistent body of knowledge in science is a formidable task due to the vast number of hypothesis generated and maintained, complexity and non-monotonicity, and unreliability of knowledge and data published. While publications and data already available today will be the initial foundation of hypothesis generation, the problem is that this initial foundation is not necessarily a solid ground; they contain substantial errors, missing information, and even fabrications. Manually checking statements with misinterpretation and biased interpretation of data individually and Temporal order of discoveries Temporal order of discoveries Estimated significance of discoveries Estimated significance of discoveries a b Fig. 6 The landscape of estimated significance of the discovery. a The landscape is monotonic, and b the landscape is non-monotonic. A simplified illustration on why there are cases that research outcomes not immediately recognized to be significant lead to a major discovery. "Estimated significance of discoveries" is used only as a conceptual index. There is no rigid method to estimate the significance of the discovery. The numbers of citations and their temporal changes can be an interesting index, but it may be biased toward short-term popularity unless the time horizon is set appropriately.  Fig. 7 Layers of knowledge for unbiased exploration. a In scientific discovery, knowledge is layered from tangible knowledge to conceptual knowledge. Properties of molecules and their interactions are tangible and knowledge of systems dynamics and design principles are conceptual as they are not directly associated with tangible objects such as molecules and cells. Conceptual knowledge is often backed by mathematical and system-oriented theories. b Biology that we observe ("existing biology") is constrained by multiple factors such as fundamental principles, systems principles, environmental constraints, and evolutionary selection. "Possible biology" meets all constraints but has not been observed or realized yet.</p>
<p>exhaustively is not practical given the volume of publications that shall be processed by AI Scientist. Currently, certain types of experimental results are known to be difficult to reproduce 44 , where some aspects of reproducibility issues shall be reduced by automated, transparent, and traceable experimental systems [45][46][47] . Intrinsic variability of biological systems due to noise and individual variations are treated as intrinsic features 48,49 and shall be treated separately from ambiguities and inaccuracy caused by the process of research itself. Aside from the immediate reproducibility problem, some observations may hold true in some contexts but may not be applicable in the other context as an intrinsic nature of the complex system. Scientific knowledge is probabilistic and non-monotonic and a representation system shall be able to reflect this reality 50 . Knowledge shall be contextualized, and a new context can be added incrementally. While this is a nature of scientific research, this poses a serious issue in the computational process as hypothesis will be generated using a body of knowledge that is sure to be revised constantly. It is like making reasoning in the twilight zone where what is correct or not is always ambiguous. In this regard, hypothesis and knowledge cannot be clearly distinguished. It is a matter of degree of confidence. Verification in the context of inductive reasoning means that "a certain hypothesis is still surviving against all falsifiability challenges, thus considered most likely so far". This implies for all hypotheses, survived or not, the trace of tests and their outcome need to be recorded. Unless errors are obvious, every statement in publications shall be converted into knowledge graph and the knowledge graph shall be constantly updated (Fig. 8). Obviously, inconsistencies will emerge which will trigger forks of knowledge graph, each of them consistent internally. Whenever some of the assumptions are altered, the relevant hypothesis shall be automatically reevaluated. This can be accomplished by maintaining a very large number of multiple consistent set of knowledge and data with explicit breaking point which set to be considered more probable.</p>
<p>Truth maintenance system, brief revision system, and nonmonotonic reasoning can be applied to maintain consistency with multiple contexts [51][52][53] . Given the nature of scientific knowledge that is essentially probabilistic, multiple sets of knowledge graph shall be maintained persistently, unless sets are proven to be inconsistent, and likelihood of each knowledge set to be most probable change dynamically. To evaluate the probability and possibly eliminate inconsistent knowledge sets, mechanisms to resolve ambiguities and falsify hypothesis need to be implemented. When a hypothesis is generated and verified, it always associated with data and justification why data support or reject the hypothesis. Theory of argumentation 54 and non-monotonic reasoning shall be the basis of argumentation structure generation and processing 55,56 . Hypothesis, or claim, can be rejected or needs further delineation with multiple cases such as (a) data is fabricated, inaccurate, or incomplete, or (b) interpretation of data/assumption is not sufficient to justify the hypothesis, (c) scope of the hypothesis shall be limited, and (d) effective rebuttle exists that denies reasoning connecting data/assumptions and the claim. It is possible that reasoning presented in publications are insufficient to justify hypothesis, and detailed justification may need to be regenerated or argument against the claim to be created to make knowledge set complete. Recent progress in computational debate may be a first step to implement mechanisms to generate such argumentations 37,56,57 . The argumentation module shall generate argumentation to support or falsify existing hypothesis thereby justification can be strengthened through additional experiments and reasoning. At the same time, argumentation generated need to be understood by the human scientist. Qualitative simulation 38,58-60 should be able to generate qualitative explanations consistent with human reasoning 39 . A closedloop system involving such a process shall be developed that can incrementally improve confidence and consistency of knowledge and data thereby incrementally building up rigidly fortified data, argumentations, and hypotheses.</p>
<p>Challenges in technology platform: automation, precision, and efficiency Development of high precision, fast, and low operation cost experimental system and data analysis system is mandatory for this challenge. Unbiased search of hypothesis space means an unprecedented number of hypotheses will be generated and tested. The test requires both computational and experimental tests. The volume of experiments required to execute unbiased exploration would be a magnitude larger than current scientific practices. The revolutionary precise, cost-effective, and fast experimental systems need to be developed and deployed. Since the cycle of hypothesis generation and verification is the ratelimiting factor of the entire process, how fast and accurately perform experiments will determine the chance of success of the challenge. Some experiments will involve hypothesis exploring unusual conditions such as 1000 times off from the conventional parameters such as the concentration of chemicals. The first step would be to make laboratories fully connected and automated. Then, equipment will be replaced over time for high precision and efficient devices including microfluidics, followed by the use AI modules for each process before reaching the high level of autonomy expected in the AI Scientist.</p>
<p>Therefore, experimental systems shall be less resourcedemanding and accurate yet reliable, reproducible, and integrated. While automation of various experimental processes has been commercialized already these are fragments of an entire process. The challenge requires an entire process of various types of experiments to be automated and part of such system may be installed as robotics cloud laboratory 46   ) with the addition of a new data "d1" and associated arguments. Further addition of data "d2" resulted in the additional split of KGs. Data d3 and associated argumentation contextualized conflicting interpretations separating two KGs (KG 1 4 and KG 1 5 ) that resulted in the merger of them. Such a merge happens when KG 1 4 and KG 1 5 are not compatible due to conflicting interpretation of data d2, but data d3 and associated argumentation clarified conflict can be resolved that two interpretation of data d2 is contextdependent thus both interpretations hold in a different context. For two competing KGs (KG 1 6 and KG 1   7 ), d4 and associated argumentation eliminated KG 1 7 , and KG 1 6 survived and augmented to be KG 1 10 . H. Kitano penalization 47 . Optimization of lycopene biosynthesis pathway and biofuels for synthetic biology-based bio-manufacturing are other examples automated search of design space was shown to be effective 61,62 . Such success demonstrates the introduction of robotics-AI systems for each process shall improve the quality and efficiency of experiments. Automated closed-loop system impacts synthetic biology as well due to its quality and reproducibility 63 . Currently, only a system closed-the-loop of hypothesis generation and experimental verification is on budding yeast genetics 13 .</p>
<p>Variety of experiments and their complexity shall be significantly augmented to cope with an extensive set of hypotheses to be verified. A literature analysis of over 1628 papers indicates 86-89% of experimental protocols in these papers can be automated by readily available commercial robotics systems 64 . This implies the progress can be quick initially, and what matters will be how to integrate different processes, data management, and how to automate processes that are not automated at this moment as well as novel protocols in future.</p>
<p>To achieve this, precise process management shall be imposed for the flows of control, materials, data, and physical agents. Due to vast numbers of experiments required for verification, experimental systems shall be compact and requirements for experimental samples and reagents shall be minimized. Organson-Chips is a recent addition to technologies that can reproduce experimental context closer to in vivo condition while maintaining controllability, traceability, and requires smaller amounts of experimental materials 65,66 . A novel origami-inspired surgical robot has interesting characteristics of being compact and high precision that can be applied for a range of experiments 67 . In future, the combination of microfluidics and robotics system will be used extensively in biological experiments to meet the demands of large numbers of experiments and requirements for controllability, accuracy, and traceability 68 .</p>
<p>Experimental devices shall be controlled by a platform that combines software tools, data access, and experimental systems embedded in the closed loop. Machine learning-guided experimental design was shown to be effective in chemistry 30 and some of the principles can be applied to broader domains. Some of the technological platforms are readily available today, as seen in Garuda Connectivity and Automation Platform 69 , Wings workflow management tool 70,71 , and DISK Data Analysis and Hypothesis Evolution framework 72 , but many have to be developed as a part of the technology challenge. Extensive efforts are made to develop bioinformatics and systems biology analysis and modeling software and data standard that are fundamental to obtain data, analyze them properly, make accurate curation, and enabling dynamical simulations. Annual workshops such as COMBINE and HARMONY drive the development and adaptation of standards (http://co.mbine.org/home). Interoperability of software and data is mandatory to ensure connectivity of laboratory that is essential to automation of not only experimental processes but also analysis and modeling processes. More effort shall be made on the representation of hypothesis and knowledge reflecting the reality of scientific knowledge.</p>
<p>Evolving relationship between AI Scientists, human scientists, and society How does AI Scientist evolve and transform scientific activities? It is clear superhuman-AI Scientist would not emerge out of blue. It will co-evolve with the scientific community over time. A possible, and logical, evolutional path of AI Scientist is to increase the level of automation first, followed by the increase of autonomy level (Fig. 9). Most current use of AI for research is a tool for specific tasks such as image classification, text-mining, and other tasks that are isolated and fully instructed by the human scientist. This is an AI tool stage. An early stage of AI scientist will take a form of a group of useful and highly competent software, including hypothesis generation module, and robotics to execute complex but pre-define tasks as instructed. Robot Scientist Adam and Eve are pioneering examples of this stage. Increasing repertoire of experiments and complexity of hypothesis are the next step. Substantial investment and user feedback are essential to make such systems useful and widely adapted.</p>
<p>Evolutionary pressure imposed on AI Scientist is whether it will be used by human scientists and widely adopted. Investment to develop AI Scientist, either by public funding or private sources, will be driven by the utility of such systems for human scientists. Therefore, AI Scientist will be inevitably interlocked with the research ecosystem of human scientists, and highly competent and user-friendly systems will survive for further development. This path inevitably make AI Scientist designed to be highly interactive with human scientists. Researchers will quickly understand the value and the power of AI Scientist, and will soon start asking questions that require the exhaustive generation of hypotheses and verification that exploits the full potential of AI Scientist at each stage of evolution. This will trigger the transformative change in biology as we witness in genomics when the unbiased measurement of genome sequence and transcriptome uncovered new realities in biology such as noncoding RNA 73,74 . Even without large-scale experiments, hypothesis generation capability of AI Scientist shall help researchers to explore hypotheses that may not be considered without such AI Scientist as well as being an extremely effective dialog-based creativity and discovery support system. Institutions without AI Scientist will no longer be competitive in science and technology.</p>
<p>With an increasing level of autonomy, AI Scientists are expected to make an autonomous decision on what to investigate next. While mechanisms to make it possible is yet to be seen, multiple strategies can be considered such as (1) goal-oriented approach of defining very high-level goals and find multiples paths to best achieve such goals or (2) bottom-up approach of exploring hypothesis search space based on discoveries already made by a specific AI Scientist. In either case, questions to be asked can be automatically extracted from publication, defined by human researchers, or randomly generating questions to be answered.</p>
<p>With an increased level of connectivity and flexibility to generate hypotheses and their verification process, instruction from human scientist will be more abstract, and AI Scientist will  Fig. 9 A possible path towards the Nobel Turing Challenge. AI Scientist requires a highly automated and connected laboratory to be able to design and execute experiments, as well as extensive access to databases and publication archives to process, extract, and evaluate current knowledge. Sophisticated laboratory automation is mandatory. Robot Scientist, Adam &amp; Eve, is highly specialized automation with a certain level of intelligence for hypothesis generation and experimental protocol generation. The next step is to fully automate and connect laboratory equipment with layers of control for data flow, material flow, and physical control flow.</p>
<p>Numbers of AI assistants shall be installed for each task initially, but need to be integrated as an integrated and highly autonomous system. The transition of automated system to autonomous system will be one of the most challenging part of the initiative.</p>
<p>have an increased autonomous process to make decision of priorities of hypotheses to be tested and experimental protocols to be performed. This is a semi-autonomous stage because instruction on what to investigate is provided from outside although how to investigate them may be generated internally by AI Scientist. The level of abstraction of instruction by Human scientists need to be carefully chosen so that AI Scientist can execute the task with success. Instruction such as "find a set of protocols (transcription factors, chemicals, procedures) that can transform types of somatic cell (X) into defined cell types (Y)" is a difficult but tangible one. For such an instruction, multiple experimental protocol shall be generated, and prioritize choice of source and target cell types, interventions to use tested, and analysis procedures. However, much higher goals, such as "cure cancer", "increase human life span to 150 years", or "minimize climate change" would be problematic as some of these goals are too abstract, at least at the initial phase of AI Scientist. With the evolution of AI Scientist over years, some these questions may be addressed in future, still it requires user understanding on capability of AI Scientist to utilize its power. With potentially expensive running cost of AI Scientists, especially when large-scale experiments are required, a certain level of monitoring will be enforced in most institutions. AI Scientist may include a function to generate questions more relevant to its owner or to the society. At least, it is highly plausible larger investment will be made to deliver high return on investment outcome. In this case, the choice of problem and evaluation of the significance of discoveries will reflect humancentric value system, most specifically the value of the stakeholders.</p>
<p>However, AI Scientists under this circumstance are less likely to make unexpected discoveries since the problems to be solved are pre-defined. Researchers with a priori expectations may sometime miss the big picture when one without such expectation may notice 75 . There are many cases discoveries initially received minor attention led to major discoveries later. It is extremely difficult, if not impossible, to evaluate the significance of the discovery when a few more discoveries may be needed to translate the discovery into high-impact outcome due to the over-the-horizon problem. The real value of AI Scientist is its capability to explore hypothesis space magnitude more efficiently into seemingly low-value domains with expectation that may eventually leads to major outcomes. Such systematic explorations into seemingly low-value hypothesis space are infeasible to be performed by human scientists. Both aspects of discovery are important that implies two roles for AI Scientist can be assumed that are "AI Scientist as a Problem Solver" aligned with the value of the stakeholders and "AI Scientist as an Explorer" that boldly explore hypothesis space nobody have gone before. However, in either cases, exhaustive hypothesis generation and verification will be the core of the AI Scientist that distinguishes it from the traditional approach. AI Scientist will be a multiplexed multi-agent system generating multiple instances of AI Scientist (Fig. 10). It is comprised of many software and hardware agents (highly functional modules with a certain level of autonomy) with a high level of interactions, interoperability, and scalability in problem size and complexity. There may be two characteristics for an architecture of AI Scientist.</p>
<p>First, it may be a multiplexing multi-agent system. It is possible multiple instances of AI Scientist are created each specialized in a certain area extensively exploring hypothesis space organically. They are almost identical in components but differ in hypothesis space exploring. Communication among AI Scientists may enable them to merge discoveries for further exploration. This may take a form of communication between AI Scientists through a series of inquiries or the creation of a new synthetic new AI Scientist. Therefore, AI Scientist as a whole entails multiple instances of AI Scientist with focused areas. In this case, discoveries may be made systematically centered around initial core domains and eventually as a combination of multiple domains forming specific pathdependencies in discoveries. In the community of AI Scientist, a series of discoveries and publications made by AI Scientist may resemble that of the successful scientist. Interaction between AI Scientists is equivalent to the search and exchange of new knowledge and style of discovery specialized by each AI Scientist. When the critical mass of knowledge and data is required to generate significant hypothesis combining multiple domains, forming the community of AI Scientist would make sense. The discovery of CRISPR-Cas9 may be one of the examples of revolutionary discoveries coming from the combination of basic research seemingly distant areas of research 76 . It is well recognized that many discoveries considered groundbreaking was triggered by connecting two or more seemingly unrelated ideas. If AI Scientist shall be able to make discoveries of this nature, it must be able to access and connect very broad and less related domains where there is already a sufficient accumulation of knowledge and data by each AI Scientist.</p>
<p>Second, it may be a human-in-the-loop system. From AI Scientist perspective, agents composing them do not have to be exclusively software or hardware, it can be human expert as far as it can interface with the rest of the system. Human experts can be in the role of domain experts or in the commanding and monitoring role. The commanding and monitoring role is important to avoid misuse of the system. Potentially, AI Scientist can make discoveries that are harmful to human and our planet. What to discover fully depends on how the owner uses such capability. A strict ethical guideline and enforcement may be required with increased level of autonomy of AI Scientist. Ultimately, it will impact national security of the highest level.</p>
<p>There will be multiple AI Scientists either by institutions, academic community, country, or other societal boundaries. Some of them may communicate each other, some may be configured in isolation, and some would form local networks. Such   Fig. 10 A possible configuration of AI Scientists: AI Scientist is a multiplexed multi-agent system where multiple instances of AI Scientist will be created. They evolve, merge, and interact with humans. Human experts can be a part of the system as human-in-the-loop system. Scientists who wish to work with AI Scientist are most likely to work with instances of AI Scientist.</p>
<p>configuration may be decided based on ownership of data and intellectual properties generated. Some modules and databases will be publicly maintained, and some would be proprietary. Although the level of autonomy can be very high, intellectual property is still retained with human researchers who run this system because human researchers make the decision to run AI Scientist and monitor their progress, and are responsible for the outcome. Some institutions may run AI Scientist at free-run modes with very high levels of autonomy, to let it explore hypothesis space that human researchers may not think of. Even in such a case, completely autonomous may not be achievable, as the intention of the owner will influence the running of the system. AI Scientist to transform systems biology and broader area of sciences Automating the process of hypothesis generation and verification shall transform broad areas of sciences. Systems biology is one of the representative areas most affected by such technology, not only because it enables researchers to cope with massive data and publications otherwise under-utilized, but also it enables researchers to develop large-scale high-precision models as well as performing investigation significantly broader in scope and more extensively in parameter space than current approaches.</p>
<p>One of the initial expectations of systems biology was to develop a high-precision large-scale model of biological systems such as virtual humans that can be used as digital-twin of patients with in-depth molecular mechanisms behind 77,78 . While it is a holy grail of systems biology, it was proven to be extremely challenging as anticipated. There are fundamental difficulties for such a task partly due to the limitation of our cognitive capabilities and sociological constraints 14 . The research landscape of systems biology is clustered around two modalities that are; (1) a highprecision mechanistic model for the smaller and tractable system and (2) a large-scale network model based on omics data but less on detailed mechanisms. There is an inherent trade-off between these two modalities and attempts to overcome such trade-off have fallen short of expectations. First, there are human cognitive constraints. A vast amount of data and complexity of the system often goes beyond human comprehension and non-linear nature of biological process make things more difficult. Second, there are practical constraints as well. Building a large-scale precision model requires details of almost every interaction and molecular behavior to be investigated both computationally and experimentally which is beyond the capability of most research groups. Investigating each of such interactions and molecular behavior would require major efforts while many of them may not result in immediate major discoveries by itself. While interesting discoveries shall spring out from some of such efforts, tasks are designed to fill in every detail of a large model, rather than speculating the potential importance of interactions and molecules. It is not practical to assume dedicated efforts by members of the research group to be sustainable for many years unless most of such process is automated.</p>
<p>Perhaps, systems biology, particularly studies for large-scale precision models, is not a research field for human alone to investigate as possible causes of difficulties lies in human cognitive and sociological limitations. Once we accept the reality such a trade-off is inherent in human cognitive limitations and sociological constraints, the path to overcoming the trade-off is obvious. It is a field suitable for AI or AI-human hybrid system. Building high-precision large-scale models and efficiently exploit such models and aggregated knowledge to back it up requires powerful AI systems to support our scientific activities.</p>
<p>The AI system is not only useful for building large-scale in-depth models but will exhibit its power to discover new mechanisms and principles we have not imagined as well as discovering novel drug targets efficiently with a significantly extended search of target candidates. Extensive use of AI for drug discovery has been discussed with the implication of dramatically improving its efficiency and the transformation of the process 79 . Early successful cases including rapid identification of kinase inhibitor for DDR1 are encouraging 80 . A recent success of AlphaFold represents how AI technologies impact biomedical studies 81 . Studies on the relationship between drug target proteins and numbers of interactions of proteins demonstrate there is a low but reasonable probability that proteins with small numbers of identified interactions to be drug targets 82 . Although chances each protein can be a drug target may be small because the total numbers of such proteins are huge, exhaustive search of this class of proteins may result in abundant novel drug targets. With the same issues that arose in high-precision large-scale models, automation of the research process is essential to explore such opportunities.</p>
<p>Extending such an approach to synthetic biology to automate design and verification processes 63,83,84 .</p>
<p>Ultimately, a series of new discoveries will be integrated into an integrated model that is large-scale, high-precision, and in-depth. The implication is massive. It does not only mean researchers use AI Scientist as one of the tools, but it implies the practice of scientific discovery will be transformed dramatically with AI Scientist because discoveries will be made at scale and autonomously. At the same time, this will be a golden opportunity for systems biology since it will transform system biology into the next stage.</p>
<p>AI Scientist can be transformative not only in life science but also for broader science and technology domains. This is especially the case that requires hypothesis generation and verification to broader range parameter search of chemical synthesis and material discovery. Already, there are emerging interests in chemistry and material science for automation of experiments coupled with machine learning guide experimental design at various levels 30,46,[85][86][87][88][89][90] . The idea of massive search of hypothesis space and verification applies to these domains as well. However, if such efforts can be applied to the discovery of novel concepts are yet to be seen. Recently, The Ramanujan Machine was announced for automated generation of conjectures in mathematics 36 . The Ramanujan Machine added a new perspective as it is not a parameter search and extensive generation of conjectures. With the rapid advances in robotics, sensors, AI with the increasing availability of computing powers, AI Scientists for broader domains of science will be inevitable. Research institutions without such capability will no longer be competitive in the coming decade.</p>
<p>The Nobel Turing Challenge is the ultimate challenge for AI and systems biology. Any progress toward achieving the goal will generate high utility technologies that shall accelerate science. Due to its breadth of expertise required and possible length of duration to achieve the goal, it may best be organized as a virtual big science 91 . Once the initiative taking off, it will uncover the essence of scientific discovery, and results in the creation of an alternative form of science. AI Scientist and human scientists will work together to solve formidable problems and to explore new intellectual territories where no one have gone before.</p>
<p>. Recently, a robotics experimental system successfully identified proper condition for cell culture of medical-grade iPS-derived retinal pigment epithelial (RPE) cells after searching 200 million possible parameter combinations through Bayesian optimization with local</p>
<p>Fig. 8
8Evolving multiverse of knowledge graphs. The original knowledge graph (KG 1 0 ) is split into two incompatible KGs (</p>
<p>A</p>
<p>new synthetic Instance An instance augmented by knowledge exchange Stakeholders: Scientific Community, Funding Agency, Industry, ELSIAI Scientist 
Development 
Community </p>
<p>A Community 
of Scientists 
(Users) </p>
<p>Instances of 
AI Scientist </p>
<p>AI Scientist as Multiplex 
Multi-Agent System </p>
<p>Published in partnership with the Systems Biology Institute npj Systems Biology and Applications (2021) 29
H. Kitano
© The Author(s) 2021
npj Systems Biology and Applications (2021)29 Published in partnership with the Systems Biology Institute
ACKNOWLEDGEMENTSI would like to thank members of the Systems Biology Institute, Okinawa Institute of Science and Technology Graduate School, Sony CSL, and Sony AI for fruitful discussions. Ross King and Yolanda Gil for working together in starting the challenge in reality. Special thanks to Ed Feigenbaum for insightful discussions and encouragements. This work was supported, in part, through an Office of Naval Research Global (ONRG) grant awarded to the Alan Turing Institute.COMPETING INTERESTSThe author is Editor-in-Chief of npj Systems Biology and Applications. The author was not involved in the review and decision on publication of this article.ADDITIONAL INFORMATIONCorrespondence and requests for materials should be addressed to H.K.Reprints and permission information is available at http://www.nature.com/ reprintsPublisher's note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this license, visit http://creativecommons. org/licenses/by/4.0/.
The Logic of Scientific Discovery. K Popper, Taylor &amp; FrancisPopper, K. The Logic of Scientific Discovery (Taylor &amp; Francis, 1959).</p>
<p>. T S Kuhn, The Structure of Scientific Revolution. University of Chicago PressKuhn, T. S. The Structure of Scientific Revolution (University of Chicago Press, 1962).</p>
<p>I Lakatos, The Methodology of Scientific Research Programmes. Cambridge University PressLakatos, I. The Methodology of Scientific Research Programmes (Cambridge Uni- versity Press, 1978).</p>
<p>P Feyerabend, Method, Outline of an Anarchistic Theory of Knowledge. Humanities PressFeyerabend, P. Against Method: Outline of an Anarchistic Theory of Knowledge (Humanities Press, 1975).</p>
<p>Inductive Inference of Theories From Facts. E Shapiro, Yale UniversityShapiro, E. Inductive Inference of Theories From Facts (Yale University, 1981).</p>
<p>DENDRAL: a case study of the first expert system for scientific hypothesis formation. R Lindsay, B Buchanan, E Feigenbaum, J Lederberg, Artif. Intell. 61Lindsay, R., Buchanan, B., Feigenbaum, E. &amp; Lederberg, J. DENDRAL: a case study of the first expert system for scientific hypothesis formation. Artif. Intell. 61, 209-261 (1993).</p>
<p>P Langley, H Simon, Scientific, Discovery, Computational Exploration of the Creative Processes. The MIT PressLangley, P. &amp; Simon, H. Scientific Discovery: Computational Exploration of the Creative Processes (The MIT Press, 1987).</p>
<p>Why AM and EURISKO appear to work. D Lenat, J Brown, Artif. Intell. 23Lenat, D. &amp; Brown, J. Why AM and EURISKO appear to work. Artif. Intell. 23, 269-294 (1984).</p>
<p>. Y Gil, H Hirsh, Discovery Informatics: AI Opportunities in Scientific Discovery. AAAIGil, Y. &amp; Hirsh, H. Discovery Informatics: AI Opportunities in Scientific Discovery (AAAI, 2012).</p>
<p>Artificial Intelligence. Amplify scientific discovery with artificial intelligence. Y Gil, M Greaves, J Hendler, H Hirsh, Science. 346Gil, Y., Greaves, M., Hendler, J. &amp; Hirsh, H. Artificial Intelligence. Amplify scientific discovery with artificial intelligence. Science 346, 171-172 (2014).</p>
<p>Functional genomic hypothesis generation and experimentation by a robot scientist. R D King, Nature. 427King, R. D. et al. Functional genomic hypothesis generation and experimentation by a robot scientist. Nature 427, 247-252 (2004).</p>
<p>Make way for robot scientists. R D King, Science. 325945King, R. D. et al. Make way for robot scientists. Science 325, 945 (2009).</p>
<p>The automation of science. R D King, Science. 324King, R. D. et al. The automation of science. Science 324, 85-89 (2009).</p>
<p>Artificial intelligence to win the nobel prize and beyond: creating the engine for scientific discovery. H Kitano, AI Mag. 37Kitano, H. Artificial intelligence to win the nobel prize and beyond: creating the engine for scientific discovery. AI Mag. 37, 39-49 (2016).</p>
<p>Computing machinery and intelligence. A M Turing, Mind. 59Turing, A. M. Computing machinery and intelligence. Mind 59, 433-460 (1950).</p>
<p>Some challenges and grand challenges for computational intelligence. E Feigenbaum, J. ACM. 50Feigenbaum, E. Some challenges and grand challenges for computational intel- ligence. J. ACM 50, 32-40 (2003).</p>
<p>Bitcoin: A Peer-to-Peer Electronic Cash System. S Nakamoto, Nakamoto, S. Bitcoin: A Peer-to-Peer Electronic Cash System, http://www.bitcoin. org/bitcoin.pdf (2008).</p>
<p>Complex Information Processing: The Impact of. H A Simon, Klahr, D. &amp; Kotovsky. K.Lawrence Erlbaum Associates, PublishersSimon, H. A. in Complex Information Processing: The Impact of Herbert A. Simon (eds Klahr, D. &amp; Kotovsky. K.) 375-398 (Lawrence Erlbaum Associates, Publishers, 1989).</p>
<p>Induction of pluripotent stem cells from mouse embryonic and adult fibroblast cultures by defined factors. K Takahashi, S Yamanaka, Cell. 126Takahashi, K. &amp; Yamanaka, S. Induction of pluripotent stem cells from mouse embryonic and adult fibroblast cultures by defined factors. Cell 126, 663-676 (2006).</p>
<p>Induction of pluripotent stem cells from adult human fibroblasts by defined factors. K Takahashi, Cell. 131Takahashi, K. et al. Induction of pluripotent stem cells from adult human fibro- blasts by defined factors. Cell 131, 861-872 (2007).</p>
<p>The Nobel Prize in Physiology or Medicine. S Yamanaka, Shinya Yamanaka -Biographical. Yamanaka, S. The Nobel Prize in Physiology or Medicine 2012 -Shinya Yamanaka - Biographical, https://www.nobelprize.org/prizes/medicine/2012/yamanaka/ biographical/ (2012).</p>
<p>The Nobel Prize in Chemistry. H Shirakawa, Hideki Shirakawa -Biographical. Shirakawa, H. The Nobel Prize in Chemistry 2000 -Hideki Shirakawa -Biographical, https://www.nobelprize.org/prizes/chemistry/2000/shirakawa/biographical/ (2000).</p>
<p>. E Feigenbaum, Feldman, J. Computers and Thought. McGraw-Hill Book CompanyFeigenbaum, E. &amp; Feldman, J. Computers and Thought (McGraw-Hill Book Com- pany, 1963).</p>
<p>. M Campbell, J HoaneJr, F.-H. Deep Hsu, Blue, Artif. Intell. 134Campbell, M., Hoane, J. Jr. &amp; Hsu, F.-H. Deep blue. Artif. Intell. 134, 57-83 (2002).</p>
<p>Mastering the game of Go with deep neural networks and tree search. D Silver, Nature. 529Silver, D. et al. Mastering the game of Go with deep neural networks and tree search. Nature 529, 484-489 (2016).</p>
<p>Mastering the game of Go without human knowledge. D Silver, Nature. 550Silver, D. et al. Mastering the game of Go without human knowledge. Nature 550, 354-359 (2017).</p>
<p>A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play. D Silver, Science. 362Silver, D. et al. A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play. Science 362, 1140-1144 (2018).</p>
<p>Mastering Atari, Go, chess and shogi by planning with a learned model. J Schrittwieser, Nature. 588Schrittwieser, J. et al. Mastering Atari, Go, chess and shogi by planning with a learned model. Nature 588, 604-609 (2020).</p>
<p>Cheaper faster drug development validated by the repositioning of drugs against neglected tropical diseases. K Williams, J. R. Soc. Interface. 1220141289Williams, K. et al. Cheaper faster drug development validated by the reposi- tioning of drugs against neglected tropical diseases. J. R. Soc. Interface 12, 20141289 (2015).</p>
<p>Machine-learning-assisted materials discovery using failed experiments. P Raccuglia, Nature. 533Raccuglia, P. et al. Machine-learning-assisted materials discovery using failed experiments. Nature 533, 73-76 (2016).</p>
<p>. M Spranger, S Palaniappan, S Ghosh, BioNLP. Association of Computaitonal LinguisticsSpranger, M., Palaniappan, S. &amp; Ghosh, S. in BioNLP 2016 Vol. BioNLP 2016, 119-127 (Association of Computaitonal Linguistics, Germany, 2016).</p>
<p>Temporal node-pair embedding for automatic biomedical hypothesis generation. U Akujuobi, M Spranger, S Palaniappan, X Zhang, T-Pair, 10.1109/TKDE.2020.3017687IEEE Transactions on Knowledge and Data Engineering. Akujuobi, U., Spranger, M., Palaniappan, S., Zhang, X. T-PAIR: Temporal node-pair embedding for automatic biomedical hypothesis generation. In IEEE Transactions on Knowledge and Data Engineering https://doi.org/10.1109/TKDE.2020.3017687 (2020).</p>
<p>Using deep learning to model the hierarchical structure and function of a cell. J Ma, Nat. Methods. 15Ma, J. et al. Using deep learning to model the hierarchical structure and function of a cell. Nat. Methods 15, 290-298 (2018).</p>
<p>Enhancing scientific discoveries in molecular biology with deep generative models. R Lopez, A Gayoso, N Yosef, Mol. Syst. Biol. 169198Lopez, R., Gayoso, A. &amp; Yosef, N. Enhancing scientific discoveries in molecular biology with deep generative models. Mol. Syst. Biol. 16, e9198 (2020).</p>
<p>Deep phenotyping predicts Huntington's genotype. D M Ruderfer, J T Dudley, Nat. Biotechnol. 34Ruderfer, D. M. &amp; Dudley, J. T. Deep phenotyping predicts Huntington's genotype. Nat. Biotechnol. 34, 823-824 (2016).</p>
<p>Generating conjectures on fundamental constants with the Ramanujan Machine. G Raayoni, Nature. 590Raayoni, G. et al. Generating conjectures on fundamental constants with the Ramanujan Machine. Nature 590, 67-73 (2021).</p>
<p>An autonomous debating system. N Slonim, Nature. 591Slonim, N. et al. An autonomous debating system. Nature 591, 379-384 (2021).</p>
<p>Qualitative modeling. K D Forbus, 10.1002/wcs.115Wiley Interdiscip. Rev. 2Forbus, K. D. Qualitative modeling. Wiley Interdiscip. Rev. 2, 374-391, https://doi. org/10.1002/wcs.115 (2011).</p>
<p>Representations: How People Reason and Learn About the Continuous World. K D Forbus, Qualiatative, The MIT PressForbus, K. D. Qualiatative Representations: How People Reason and Learn About the Continuous World (The MIT Press, 2019).</p>
<p>Deep hidden physics models: deep learning of nonlinear partial differential equations. M Raissi, J. Mach. Learn. Res. 19Raissi, M. Deep hidden physics models: deep learning of nonlinear partial dif- ferential equations. J. Mach. Learn. Res. 19, 1-24 (2018).</p>
<p>Data driven nonlinear dynamical systems identification using multi-step CLDNN. Q Teng, L Zhang, AIP Advances. 985311Teng, Q. &amp; Zhang, L. Data driven nonlinear dynamical systems identification using multi-step CLDNN. AIP Advances 9, 085311 (2019).</p>
<p>SBML qualitative models: a model representation format and infrastructure to foster interactions between qualitative modelling formalisms and tools. C Chaouiya, BMC Syst. Biol. 7135Chaouiya, C. et al. SBML qualitative models: a model representation format and infrastructure to foster interactions between qualitative modelling formalisms and tools. BMC Syst. Biol. 7, 135 (2013).</p>
<p>Constructing explanatory process models from biological data and knowledge. P Langley, O Shiran, J Shrager, L Todorovski, A Pohorille, Artif. Intell. Med. 37Langley, P., Shiran, O., Shrager, J., Todorovski, L. &amp; Pohorille, A. Constructing explanatory process models from biological data and knowledge. Artif. Intell. Med. 37, 191-201 (2006).</p>
<p>Believe it or not: how much can we rely on published data on potential drug targets?. F Prinz, T Schlange, K Asadullah, Nat. Rev. Drug Discov. 10712Prinz, F., Schlange, T. &amp; Asadullah, K. Believe it or not: how much can we rely on published data on potential drug targets? Nat. Rev. Drug Discov. 10, 712 (2011).</p>
<p>Achieving reproducibility and closed-loop automation in biological experimentation with an IoT-enabled lab of the future. B Miles, P L Lee, SLAS Technol. 23Miles, B. &amp; Lee, P. L. Achieving reproducibility and closed-loop automation in biological experimentation with an IoT-enabled lab of the future. SLAS Technol. 23, 432-439 (2018).</p>
<p>Robotic crowd biology with Maholo LabDroids. N Yachie, C Robotic Biology, T Natsume, Nat. Biotechnol. 35Yachie, N., Robotic Biology, C. &amp; Natsume, T. Robotic crowd biology with Maholo LabDroids. Nat. Biotechnol. 35, 310-312 (2017).</p>
<p>Robotic search for optimal cell culture in regenerative medicine. G N Kanda, 10.1101/2020.11.25.392936Preprint at bioRxivKanda, G. N. et al. Robotic search for optimal cell culture in regenerative medi- cine. Preprint at bioRxiv https://doi.org/10.1101/2020.11.25.392936 (2020).</p>
<p>Identifying noise sources governing cell-to-cell variability. S Mitchell, A Hoffmann, Curr. Opin. Syst. Biol. 8Mitchell, S. &amp; Hoffmann, A. Identifying noise sources governing cell-to-cell variability. Curr. Opin. Syst. Biol. 8, 39-45 (2018).</p>
<p>Cell-to-cell variability in the propensity to transcribe explains correlated fluctuations in gene expression. M S Sherman, K Lorenz, M H Lanier, B A Cohen, Cell Syst. 1Sherman, M. S., Lorenz, K., Lanier, M. H. &amp; Cohen, B. A. Cell-to-cell variability in the propensity to transcribe explains correlated fluctuations in gene expression. Cell Syst. 1, 315-325 (2015).</p>
<p>Representation of probabilistic scientific knowledge. L N Soldatova, A Rzhetsky, K De Grave, R D King, J. Biomed. Semant. 47Soldatova, L. N., Rzhetsky, A., De Grave, K. &amp; King, R. D. Representation of prob- abilistic scientific knowledge. J. Biomed. Semant. 4, S7 (2013).</p>
<p>A truth maintenance system. J Doyle, Artif. Intell. 12Doyle, J. A truth maintenance system. Artif. Intell. 12, 251-272 (1979).</p>
<p>An assumption-based TMS. J De Kleer, Artif. Intell. 28de Kleer, J. An assumption-based TMS. Artif. Intell. 28, 127-162 (1986).</p>
<p>M V Martinez, I Varzinczak, NMR-2020: Workshop Notes of the 18th International Workshop on Non-Monotonic Reasoning. Buenos Aires and LensMartinez, M. V. &amp; Varzinczak, I., NMR-2020: Workshop Notes of the 18th Inter- national Workshop on Non-Monotonic Reasoning, (Buenos Aires and Lens, 2020).</p>
<p>S Toulmin, The Uses of Argument. Cambridge University PressToulmin, S. The Uses of Argument (Cambridge University Press, 1958).</p>
<p>Epistemic graphs for representing and reasoning with positive and negative influences of arguments. A Hunter, S Polberg, M Thimm, Artif. Intell. 281103236Hunter, A., Polberg, S. &amp; Thimm, M. Epistemic graphs for representing and rea- soning with positive and negative influences of arguments. Artif. Intell. 281, 103236 (2020).</p>
<p>Toward artificial argumentation. AI Magazine. K Atkinson, Atkinson, K. et al. Toward artificial argumentation. AI Magazine 25-36 (Fall, 2017).</p>
<p>Argumentation in artificial intelligence. T J M Bench-Capon, P Dunne, Artif. Intell. 171Bench-Capon, T. J. M. &amp; Dunne, P. Argumentation in artificial intelligence. Artif. Intell. 171, 619-641 (2007).</p>
<p>Qualitative simulation. B Kuipers, Artif. Intell. 29Kuipers, B. Qualitative simulation. Artif. Intell. 29, 289-338 (1986).</p>
<p>Qualitative simulation: then and now. B Kuipers, Artif. Intell. 59Kuipers, B. Qualitative simulation: then and now. Artif. Intell. 59, 133-140 (1993).</p>
<p>The scope and limits of simulation in automated reasoning. E Davis, G Marcus, Artif. Intell. 233Davis, E. &amp; Marcus, G. The scope and limits of simulation in automated reasoning. Artif. Intell. 233, 60-72 (2016).</p>
<p>Accelerating strain engineering in biofuel research via build and test automation of synthetic biology. J Zhang, Curr. Opin. Biotechnol. 67Zhang, J. et al. Accelerating strain engineering in biofuel research via build and test automation of synthetic biology. Curr. Opin. Biotechnol. 67, 88-98 (2021).</p>
<p>Towards a fully automated algorithm driven platform for biosystems design. M Hamedirad, Nat. Commun. 105150HamediRad, M. et al. Towards a fully automated algorithm driven platform for biosystems design. Nat. Commun. 10, 5150 (2019).</p>
<p>Improving reproducibility in synthetic biology. M M Jessop-Fabre, N Sonnenschein, Front. Bioeng. Biotechnol. 718Jessop-Fabre, M. M. &amp; Sonnenschein, N. Improving reproducibility in synthetic biology. Front. Bioeng. Biotechnol. 7, 18 (2019).</p>
<p>Indicators for the use of robotic labs in basic biomedical research: a literature analysis. P Groth, J Cox, PeerJ. 53997Groth, P. &amp; Cox, J. Indicators for the use of robotic labs in basic biomedical research: a literature analysis. PeerJ 5, e3997 (2017).</p>
<p>Organs-onchips: into the next decade. L A Low, C Mummery, B R Berridge, C P Austin, D A Tagle, Nat. Rev. Drug Discov. 20Low, L. A., Mummery, C., Berridge, B. R., Austin, C. P. &amp; Tagle, D. A. Organs-on- chips: into the next decade. Nat. Rev. Drug Discov. 20, 345-361 (2020).</p>
<p>Scaling and systems biology for integrating multiple organson-a-chip. J P Wikswo, Lab Chip. 13Wikswo, J. P. et al. Scaling and systems biology for integrating multiple organs- on-a-chip. Lab Chip 13, 3496-3511 (2013).</p>
<p>Origami-inspired miniature manipulator for teleoperated microsurgery. H Suzuki, R J Wood, Nat. Mach. Intell. 2Suzuki, H. &amp; Wood, R. J. Origami-inspired miniature manipulator for teleoperated microsurgery. Nat. Mach. Intell. 2, 437-446 (2020).</p>
<p>When robotics met fluidics. J Zhong, Lab Chip. 20Zhong, J. et al. When robotics met fluidics. Lab Chip 20, 709-716 (2020).</p>
<p>Software for systems biology: from tools to integrated platforms. S Ghosh, Y Matsuoka, Y Asai, K Y Hsin, H Kitano, Nat. Rev. Genet. 12Ghosh, S., Matsuoka, Y., Asai, Y., Hsin, K. Y. &amp; Kitano, H. Software for systems biology: from tools to integrated platforms. Nat. Rev. Genet. 12, 821-832 (2011).</p>
<p>Y Gil, V Ratnakar, E Deelman, G Mehta, J Kim, Innovative Applications of Artificial Intelligence (IAAI-07). Vancouver, British Columbia, CanadaGil, Y., Ratnakar, V., Deelman, E., Mehta, G. &amp; Kim, J. In Innovative Applications of Artificial Intelligence (IAAI-07) (Vancouver, British Columbia, Canada, 2007).</p>
<p>Wings: intelligent workflow-based design of computational experiments. Y Gil, IEEE Intell. Syst. 26Gil, Y. et al. Wings: intelligent workflow-based design of computational experi- ments. IEEE Intell. Syst. 26, 62-72 (2011).</p>
<p>Y Gil, The Thirty-First AAAI Conference on Artificial Intelligence (AAAI-17) (The Association for the Advancement of Artificial Intelligence. Gil, Y. et al. in The Thirty-First AAAI Conference on Artificial Intelligence (AAAI-17) (The Association for the Advancement of Artificial Intelligence, 2017).</p>
<p>Paradigm shifts in genomics through the FANTOM projects. M De Hoon, J W Shin, P Carninci, Mamm. Genome. 26de Hoon, M., Shin, J. W. &amp; Carninci, P. Paradigm shifts in genomics through the FANTOM projects. Mamm. Genome 26, 391-402 (2015).</p>
<p>FANTOM enters 20th year: expansion of transcriptomic atlases and functional annotation of non-coding RNAs. I Abugessaisa, Nucleic Acids Res. 49Abugessaisa, I. et al. FANTOM enters 20th year: expansion of transcriptomic atlases and functional annotation of non-coding RNAs. Nucleic Acids Res. 49, D892-D898 (2021).</p>
<p>A hypothesis is a liability. I Yanai, M Lercher, Genome Biol. 21231Yanai, I. &amp; Lercher, M. A hypothesis is a liability. Genome Biol. 21, 231 (2020).</p>
<p>A Crack in Creation: Gene Editing and the Unthinkable Power to Control Evolution. J Doudna, S Sternberg, Houghton Mifflin HarcourtDoudna, J. &amp; Sternberg, S. A Crack in Creation: Gene Editing and the Unthinkable Power to Control Evolution (Houghton Mifflin Harcourt, 2017).</p>
<p>All systems go. D Jones, Nat. Rev. Drug Discov. 7Jones, D. All systems go. Nat. Rev. Drug Discov. 7, 128-129 (2008).</p>
<p>Pharma 2020: Virtual R&amp;D ---Which Path Will You Take?. Pricewaterhousecoopers, PricewaterhouseCoopers. Pharma 2020: Virtual R&amp;D ---Which Path Will You Take? (2007).</p>
<p>Rethinking drug design in the artificial intelligence era. P Schneider, Nat. Rev. Drug Discov. 19Schneider, P. et al. Rethinking drug design in the artificial intelligence era. Nat. Rev. Drug Discov. 19, 353-364 (2020).</p>
<p>Deep learning enables rapid identification of potent DDR1 kinase inhibitors. A Zhavoronkov, Nat. Biotechnol. 37Zhavoronkov, A. et al. Deep learning enables rapid identification of potent DDR1 kinase inhibitors. Nat. Biotechnol. 37, 1038-1040 (2019).</p>
<p>Improved protein structure prediction using potentials from deep learning. A W Senior, Nature. 577Senior, A. W. et al. Improved protein structure prediction using potentials from deep learning. Nature 577, 706-710 (2020).</p>
<p>Structure of protein interaction networks and their implications on drug design. T Hase, H Tanaka, Y Suzuki, S Nakagawa, H Kitano, PLoS Comput. Biol. 51000550Hase, T., Tanaka, H., Suzuki, Y., Nakagawa, S. &amp; Kitano, H. Structure of protein interaction networks and their implications on drug design. PLoS Comput. Biol. 5, e1000550 (2009).</p>
<p>Design automation in synthetic biology. E Appleton, C Madsen, N Roehner, D Densmore, 10.1101/cshperspect.a023978Cold Spring Harb. Perspect. Biol. 9Appleton, E., Madsen, C., Roehner, N. &amp; Densmore, D. Design automation in synthetic biology. Cold Spring Harb. Perspect. Biol. 9, https://doi.org/10.1101/ cshperspect.a023978 (2017).</p>
<p>Needs and opportunities in bio-design automation: four areas for focus. E Appleton, D Densmore, C Madsen, N Roehner, Curr. Opin. Chem. Biol. 40Appleton, E., Densmore, D., Madsen, C. &amp; Roehner, N. Needs and opportunities in bio-design automation: four areas for focus. Curr. Opin. Chem. Biol. 40, 111-118 (2017).</p>
<p>Self-driving laboratory for accelerated discovery of thin-film materials. B P Macleod, Science Adv. 68867MacLeod, B. P. et al. Self-driving laboratory for accelerated discovery of thin-film materials. Science Adv. 6, eaaz8867 (2020).</p>
<p>Next-generation experimentation with self-driving laboratories. F Häse, L M Roch, A Aspuru-Guzik, Trends Chem. 1Häse, F., Roch, L. M. &amp; Aspuru-Guzik, A. Next-generation experimentation with self-driving laboratories. Trends Chem. 1, 282-291 (2019).</p>
<p>Progress and prospects for accelerating materials science with automated and autonomous workflows. H S Stein, J M Gregoire, Chem. Sci. 10Stein, H. S. &amp; Gregoire, J. M. Progress and prospects for accelerating materials science with automated and autonomous workflows. Chem. Sci. 10, 9640-9649 (2019).</p>
<p>Accelerating the discovery of materials for clean energy in the era of smart automation. D P Tabor, Nat. Rev. Mater. 3Tabor, D. P. et al. Accelerating the discovery of materials for clean energy in the era of smart automation. Nat. Rev. Mater. 3, 5-20 (2018).</p>
<p>Autonomy in materials research: a case study in carbon nanotube growth. P Nikolaev, Comput. Mater. 216031Nikolaev, P. et al. Autonomy in materials research: a case study in carbon nanotube growth. npj Comput. Mater. 2, 16031 (2016).</p>
<p>Scientific AI in materials science: a path to a sustainable and scalable paradigm. B L Decost, 10.1088/2632-2153/ab9a20Mach. Learn Sci. Technol. 1DeCost, B. L. et al. Scientific AI in materials science: a path to a sustainable and scalable paradigm. Mach. Learn Sci. Technol. 1, https://doi.org/10.1088/2632- 2153/ab9a20 (2020).</p>
<p>Social engineering for virtual 'big science' in systems biology. H Kitano, S Ghosh, Y Matsuoka, Nat. Chem. Biol. 7Kitano, H., Ghosh, S. &amp; Matsuoka, Y. Social engineering for virtual 'big science' in systems biology. Nat. Chem. Biol. 7, 323-326 (2011).</p>            </div>
        </div>

    </div>
</body>
</html>