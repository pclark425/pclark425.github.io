<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1000 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1000</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1000</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-20.html">extraction-schema-20</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <p><strong>Paper ID:</strong> paper-f844925066c3de9cd9ad662059e25a9d47a59843</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/f844925066c3de9cd9ad662059e25a9d47a59843" target="_blank">Causal Discovery with Reinforcement Learning</a></p>
                <p><strong>Paper Venue:</strong> International Conference on Learning Representations</p>
                <p><strong>Paper TL;DR:</strong> This work proposes to use Reinforcement Learning (RL) to search for a Directed Acyclic Graph (DAG) according to a predefined score function and shows that the proposed approach not only has an improved search ability but also allows a flexible score function under the acyclicity constraint.</p>
                <p><strong>Paper Abstract:</strong> Discovering causal structure among a set of variables is a fundamental problem in many empirical sciences. Traditional score-based casual discovery methods rely on various local heuristics to search for a Directed Acyclic Graph (DAG) according to a predefined score function. While these methods, e.g., greedy equivalence search, may have attractive results with infinite samples and certain model assumptions, they are usually less satisfactory in practice due to finite data and possible violation of assumptions. Motivated by recent advances in neural combinatorial optimization, we propose to use Reinforcement Learning (RL) to search for the DAG with the best scoring. Our encoder-decoder model takes observable data as input and generates graph adjacency matrices that are used to compute rewards. The reward incorporates both the predefined score function and two penalty terms for enforcing acyclicity. In contrast with typical RL applications where the goal is to learn a policy, we use RL as a search strategy and our final output would be the graph, among all graphs generated during training, that achieves the best reward. We conduct experiments on both synthetic and real datasets, and show that the proposed approach not only has an improved search ability but also allows a flexible score function under the acyclicity constraint.</p>
                <p><strong>Cost:</strong> 0.021</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1000.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1000.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RL-BIC / RL-BIC2</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Reinforcement Learning for Score-based Causal Discovery (with BIC score variants)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>This paper's primary method: an encoder-decoder neural graph generator trained with policy-gradient actor-critic RL to search DAG space by maximizing a reward that combines a predefined score (BIC) and acyclicity penalties; final output is the best-scoring DAG seen during training, optionally pruned.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>RL-based score optimization for causal discovery (RL-BIC, RL-BIC2)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>An attention-based encoder (Transformer-style) produces node embeddings; a decoder scores each potential directed edge and samples an adjacency matrix via independent Bernoulli draws. The RL reward equals the negative of a chosen score function (here BIC or variants) plus two acyclicity penalties: an indicator penalty for non-DAGs and a smooth penalty h(A)=trace(exp(A))-d. Policy gradients (REINFORCE/actor-critic) with entropy regularization train the network; during training many graphs are generated and the method returns the acyclic graph with the best (lowest) score encountered. Post-processing includes greedy pruning (see separate entry) and coefficient thresholding. The method allows any regression-based score (linear, quadratic, Gaussian process regression) to estimate local conditional fits.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Synthetic and real observational datasets (LiNGAM, linear-Gaussian, quadratic, GP-sampled functions; Sachs protein-signaling observational data)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Passive observational datasets (synthetic data generated from specified SEMs and a real biology observational dataset). Not an interactive / intervention-driven virtual lab; the method treats different random minibatches of observational samples as inputs for the encoder and searches graph space via RL sampling rather than performing active interventions.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Regularized score-based model selection (BIC penalty on number of edges), acyclicity penalties to constrain search, post-hoc greedy pruning based on regression performance/score, coefficient thresholding; selection of regression model (quadratic/GPR) and kernel-bandwidth heuristics to avoid overfitting (thus reducing spurious edges).</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Irrelevant variables producing spurious edges (false positives), overfitting-induced spurious associations (e.g., from flexible regressors), cyclic graphs mistaken for causal structure.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Detection is implicit via the score: spurious parent-child relations increase BIC (via RSS and edge penalty) or fail to improve regression performance when removed; pruning tests the effect of removing a parent on score/regression fit and accepts removal if performance does not degrade beyond tolerance. For GP models, overfitting-driven spurious edges were diagnosed empirically and alleviated by kernel-bandwidth (median heuristic) and normalization.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>BIC penalty on number of edges (log m term) downweights complex graphs; acyclicity penalties discourage cyclic structures; entropy regularization in policy prevents premature convergence to overfitted graph distributions. For GPR models, median-heuristic kernel bandwidth reduces overfitting that would otherwise upweight spurious dependencies.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Greedy post-processing: iteratively remove a parental variable and accept the removal if the regression performance / score does not worsen beyond a preset tolerance; threshold coefficients in linear/quadratic models to remove weak edges. Also equivalence via comparing rewards across generated graphs (select best-scoring DAG seen).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>Reported across multiple benchmarks in the paper: on 12-node LiNGAM and linear-Gaussian synthetic data RL-BIC2 achieved FDR=0.00, TPR=1.00, SHD=0.00 (perfect recovery in those experiments after pruning/thresholding); on 10-node quadratic nonlinear SEM RL-BIC2: FDR=0.02 ± 0.04, TPR=0.98 ± 0.04, SHD=0.6 ± 1.20; on 10-node GP-sampled functions RL-BIC: FDR=0.14 ± 0.03, TPR=0.96 ± 0.03, SHD=6.2 ± 1.33 (RL-BIC2 slightly worse on that setting). On the Sachs real dataset RL-BIC achieved 10 total edges, 6 correct edges, SHD=12 (RL-BIC2: 10 total, 7 correct, SHD=11). These metrics reflect the method as used with its pruning/regularization choices described in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td>The paper compares against baseline algorithms (GES, PC, NOTEARS, DAG-GNN, GraN-DAG, CAM, ICA-LiNGAM) on the same datasets; e.g., on 12-node linear-Gaussian NOTEARS had FDR≈0.02, TPR≈0.98, SHD≈1.0 while GES and PC performed substantially worse on dense synthetic graphs. Ablated variants RL-BIC (without certain choices such as the RL-BIC2 normalization/assumptions) showed higher FDR and SHD in some settings (tables in paper show RL-BIC often worse than RL-BIC2), demonstrating the contribution of score normalization, penalty schedules, and regression choices. The paper also notes that using fixed GPR bandwidth without median heuristic leads to heavy overfitting and many spurious edges (graph with highest reward often cyclic).</td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Using RL as a global search strategy over DAGs plus flexible score functions yields improved search ability and, when combined with model-appropriate regressors and explicit pruning/regularization, substantially reduces false discoveries. Practical techniques that improved robustness to spurious edges include: (1) using BIC which penalizes extra edges; (2) adding both an indicator and a smooth acyclicity penalty to the reward (helps guide search toward DAGs); (3) post-hoc greedy pruning based on regression performance/score; (4) choosing appropriate local regression models (quadratic, GPR) and kernel-bandwidth heuristics to avoid overfitting; and (5) thresholding small coefficients in linear/quadratic fits. These components collectively reduced FDR and SHD in the experiments reported.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Causal Discovery with Reinforcement Learning', 'publication_date_yy_mm': '2019-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1000.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e1000.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Greedy pruning (regression/score-based)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Greedy pruning of inferred causal edges based on regression performance or score function</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A post-processing used in this paper (and commonly used elsewhere): iteratively test removal of each parent edge and accept the removal if the overall predictive performance or the chosen score does not degrade beyond tolerance, thereby removing spurious edges.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Greedy post-hoc pruning via leave-one-parent-out score/regression test</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>For each inferred parental relationship, remove the edge and recompute either the regression fit (e.g., RSS or log-likelihood) or the global score (BIC). If performance does not degrade or degrades within a pre-defined tolerance, permanently remove the edge and continue iteratively. For linear models, a simple coefficient thresholding is also used to prune weak edges.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Same observational synthetic/real datasets used for graph discovery in the paper</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Passive observational datasets; pruning is applied offline after model search and scoring (no active interventions).</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Model-selection based refutation: edges that do not contribute to predictive performance (or that increase penalized score) are removed; coefficient thresholding for linear/quadratic fits.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Irrelevant parents producing false positive edges, weak/low-effect-size dependencies, overfitting-induced spurious associations.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Comparative test: measure change in regression performance or score when an edge is removed; if removal does not worsen performance beyond tolerance the edge is marked spurious.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Explicit refutation by demonstrating that the model without the edge is not worse (or is better) under the score/regression metric; then accept edge removal.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>In the quadratic SEM experiments, applying quadratic-regression-based pruning to NOTEARS (creating NOTEARS-2) reduced FDR from 0.35 to 0.15 while retaining similar TPR, demonstrating pruning reduces false positives with little TPR loss; RL-BIC methods also relied on pruning/thresholding to obtain low FDR and SHD in several experiments (e.g., perfect recovery in some linear experiments after pruning/thresholding).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td>Without pruning (or without suitable thresholding), many methods exhibited substantially higher FDR (e.g., NOTEARS FDR=0.35 on quadratic SEMs before pruning). The paper reports that pruning 'further reduces FDR with little effect on TPR.'</td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Greedy pruning based on regression performance or score is an effective and simple post-processing to eliminate many spurious edges introduced by flexible regression models or imperfect search; it typically reduces FDR significantly with minimal loss in TPR according to the paper's experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Causal Discovery with Reinforcement Learning', 'publication_date_yy_mm': '2019-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1000.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e1000.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CAM pruning / significance testing</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Causal Additive Models (CAM) significance-based pruning</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>CAM is an additive-noise-based causal discovery pipeline that includes a post-selection step using significance testing of covariates (p-value based) to prune spurious edges; the paper uses CAM-style pruning settings for some comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>CAM: Causal additive models, high-dimensional order search and penalized regression</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>CAM (with significance-test-based pruning)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>CAM separates order search from edge selection under additive-noise assumptions and applies significance testing (generalized additive models) to determine if candidate parent covariates are significant; edges with p-values above a threshold are pruned. The paper follows CAM authors' pruning choice (p ≤ 0.001) for comparable post-processing.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Synthetic SEM datasets and real Sachs dataset (as used in experiments)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Passive observational datasets with additive noise and assumed nonlinearity (CAM assumes nonlinear functional relationships).</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Significance testing of covariates (p-value thresholding) to remove spurious parent variables.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Irrelevant covariates that appear predictive due to chance or multiple-testing; false-positive edges.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Statistical hypothesis testing on covariate coefficients in (generalized) additive models; p-value comparison against a strict threshold (authors' recommended 0.001).</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Rejecting edges whose covariate p-values exceed the threshold (i.e., failing to be statistically significant) — thereby removing spurious causal claims.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>In experiments reported in the paper, CAM's pruning procedure produced moderate FDR/TPR tradeoffs depending on the data model: e.g., in the quadratic SEM experiment CAM had FDR≈0.32, TPR≈0.78, SHD≈14.1; on GP models CAM reported FDR≈0.15, TPR≈0.82, SHD≈10.2. The pruning helps control false positives but performance depends on model assumptions (additive nonlinearity).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>CAM-style significance testing is an explicit, hypothesis-test-based approach to remove spurious edges; in the paper it is used as a standard pruning baseline and reduces false discoveries when its modeling assumptions (additive noise and sufficient data) hold.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Causal Discovery with Reinforcement Learning', 'publication_date_yy_mm': '2019-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1000.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e1000.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PC algorithm (conditional independence)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>PC algorithm (constraint-based causal discovery using conditional independence tests)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A classic constraint-based algorithm that uses conditional independence tests to recover the undirected skeleton and then orients edges up to the Markov equivalence class; conditional independence testing can detect and eliminate many spurious associations under faithfulness.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>PC algorithm (with Fisher-z tests in experiments)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Conducts pairwise and conditional independence tests (e.g., partial correlation Fisher-z tests) to build an undirected skeleton: if X independent of Y given some set S, no edge is placed; orientation rules (v-structures and propagation) then orient as many edges as allowed. Multiple-testing and conflicting test outcomes are a known practical issue.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Synthetic SEM datasets used in experiments (LiNGAM, linear-Gaussian, etc.)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Passive observational datasets; PC performs conditional independence testing on observed samples to infer edges and orientations; not an active/interventional method.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Conditional independence testing (kernel-based or parametric tests) to detect relationships that disappear when conditioning on appropriate sets, thereby removing associations due to confounding or indirect paths under faithfulness.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Spurious associations due to indirect paths or marginal correlation (i.e., association but not direct causation), some confounding under assumptions; multiple-testing-induced false positives are discussed as a problem.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Statistical conditional independence tests (e.g., Fisher-z partial correlation in experiments, kernel-based CI in related work) detect lack of direct dependence once conditioning variables are included.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Edges are not included if independence cannot be rejected for the corresponding conditional sets; conflicts between tests may leave some edges unoriented or require resolution strategies.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>In the paper's dense synthetic graphs, PC performed poorly: on 12-node LiNGAM PC had FDR≈0.06, TPR≈0.25, SHD≈31.8; on 12-node linear-Gaussian PC had FDR≈0.52, TPR≈0.31, SHD≈29.6, showing that CI-testing alone can struggle under finite-sample/noise/dense-graph conditions.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Conditional-independence-based methods can detect and remove many spurious marginal associations but are sensitive to sample size, multiple-testing, and faithfulness violations; the paper cites these limitations and notes conflict-resolution is nontrivial (see Hyttinen et al. 2014).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Causal Discovery with Reinforcement Learning', 'publication_date_yy_mm': '2019-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1000.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e1000.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Conflict-resolution (Hyttinen et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Conflict resolution for constraint-based causal discovery using answer set programming</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A referenced approach that attempts to resolve conflicting conditional independence test outputs (a source of spurious or inconsistent edges) using answer set programming to find consistent graph structures.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Answer-set-programming-based conflict resolution in constraint-based causal discovery</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Constraint-based pipelines rely on many conditional independence tests; Hyttinen et al. (2014) propose encoding CI constraints and conflicts into an answer set program to find graph structures that best reconcile conflicting test outcomes, thereby addressing inconsistencies that can lead to spurious edges.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Constraint-based causal discovery on observational datasets (general)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Not an interactive environment; solves consistency issues arising from multiple dependent statistical tests on observational data.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Conflict resolution among CI tests outputs via combinatorial optimization (answer set programming) rather than simple independent acceptance/rejection of tests.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Conflicting CI test outcomes that can produce spurious edges or inconsistent skeletons due to finite-sample error and multiple testing.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Detects inconsistent sets of CI decisions by global encoding and uses ASP to find a consistent selection of edges/tests.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Resolves conflicts by selecting a globally consistent set of CI results, effectively refuting test-based spurious edges that cannot be reconciled.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Cited as an approach addressing conflicts and inconsistencies in CI-testing frameworks; the paper notes such conflict-resolution work exists but does not evaluate it empirically.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Causal Discovery with Reinforcement Learning', 'publication_date_yy_mm': '2019-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1000.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e1000.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>NOTEARS</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>DAGs with NO TEARS (continuous optimization for structure learning)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A continuous optimization approach that reformulates DAG-constrained structure learning with a smooth acyclicity constraint (trace(exp(W◦W))−d=0) and optimizes a weighted adjacency matrix with least-squares loss and augmented Lagrangian techniques; thresholding is applied to obtain a binary graph.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>DAGs with NO TEARS: Continuous optimization for structure learning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>NOTEARS (smooth acyclicity continuous optimization)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Formulates structure learning as minimizing a loss (e.g., least-squares) over a real-valued weighted adjacency matrix subject to a smooth acyclicity constraint h(W)=0 (using trace of matrix exponential). Solved with augmented Lagrangian and standard optimizers; final binary graph obtained by thresholding weights. Has variants for nonlinear/local regressors.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Synthetic SEM datasets (linear, nonlinear variants) used in experiments</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Passive observational datasets; NOTEARS performs continuous optimization on a weighted adjacency matrix rather than combinatorial graph sampling.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Implicit regularization via least-squares loss and (optionally) penalty terms; final thresholding of weights removes weak edges; variants combined with suitable regressors can reduce spurious edges.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Weak/low-weight edges that can arise from overfitting or indirect associations; cyclic structures improperly represented in weighted matrices.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Penalized loss and final thresholding of small weights; augmented Lagrangian penalty on acyclicity shapes solution space.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Thresholding weak coefficients to zero; in experimenters' variants (NOTEARS-2) additional regression-based pruning further reduces spurious edges.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>In experiments NOTEARS performs well on many settings (e.g., linear-Gaussian: FDR≈0.02, TPR≈0.98, SHD≈1.0 in Table 1), but can be outperformed by RL-based search in some nonlinear settings when combined with appropriate pruning.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td>Base NOTEARS (without quadratic pruning) had worse FDR on the quadratic SEM (FDR≈0.35, TPR≈0.71, SHD≈14.8) compared to NOTEARS-2 (after quadratic-regression-based pruning: FDR≈0.15, TPR≈0.70, SHD≈8.8), illustrating the benefit of pruning.</td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>NOTEARS' continuous formulation is flexible and effective in many settings, but proper choice of local regressors and post-processing (thresholding or pruning) is important to control spurious edges; applying pruning or problem-specific regressors (quadratic) reduces FDR substantially in nonlinear settings.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Causal Discovery with Reinforcement Learning', 'publication_date_yy_mm': '2019-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Causal discovery with continuous additive noise models <em>(Rating: 2)</em></li>
                <li>DAGs with NO TEARS: Continuous optimization for structure learning <em>(Rating: 2)</em></li>
                <li>Constraint-based causal discovery: Conflict resolution with answer set programming <em>(Rating: 2)</em></li>
                <li>CAM: Causal additive models, high-dimensional order search and penalized regression <em>(Rating: 2)</em></li>
                <li>Generalized score functions for causal discovery <em>(Rating: 1)</em></li>
                <li>Gradient-based neural DAG learning <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1000",
    "paper_id": "paper-f844925066c3de9cd9ad662059e25a9d47a59843",
    "extraction_schema_id": "extraction-schema-20",
    "extracted_data": [
        {
            "name_short": "RL-BIC / RL-BIC2",
            "name_full": "Reinforcement Learning for Score-based Causal Discovery (with BIC score variants)",
            "brief_description": "This paper's primary method: an encoder-decoder neural graph generator trained with policy-gradient actor-critic RL to search DAG space by maximizing a reward that combines a predefined score (BIC) and acyclicity penalties; final output is the best-scoring DAG seen during training, optionally pruned.",
            "citation_title": "here",
            "mention_or_use": "use",
            "method_name": "RL-based score optimization for causal discovery (RL-BIC, RL-BIC2)",
            "method_description": "An attention-based encoder (Transformer-style) produces node embeddings; a decoder scores each potential directed edge and samples an adjacency matrix via independent Bernoulli draws. The RL reward equals the negative of a chosen score function (here BIC or variants) plus two acyclicity penalties: an indicator penalty for non-DAGs and a smooth penalty h(A)=trace(exp(A))-d. Policy gradients (REINFORCE/actor-critic) with entropy regularization train the network; during training many graphs are generated and the method returns the acyclic graph with the best (lowest) score encountered. Post-processing includes greedy pruning (see separate entry) and coefficient thresholding. The method allows any regression-based score (linear, quadratic, Gaussian process regression) to estimate local conditional fits.",
            "environment_name": "Synthetic and real observational datasets (LiNGAM, linear-Gaussian, quadratic, GP-sampled functions; Sachs protein-signaling observational data)",
            "environment_description": "Passive observational datasets (synthetic data generated from specified SEMs and a real biology observational dataset). Not an interactive / intervention-driven virtual lab; the method treats different random minibatches of observational samples as inputs for the encoder and searches graph space via RL sampling rather than performing active interventions.",
            "handles_distractors": true,
            "distractor_handling_technique": "Regularized score-based model selection (BIC penalty on number of edges), acyclicity penalties to constrain search, post-hoc greedy pruning based on regression performance/score, coefficient thresholding; selection of regression model (quadratic/GPR) and kernel-bandwidth heuristics to avoid overfitting (thus reducing spurious edges).",
            "spurious_signal_types": "Irrelevant variables producing spurious edges (false positives), overfitting-induced spurious associations (e.g., from flexible regressors), cyclic graphs mistaken for causal structure.",
            "detection_method": "Detection is implicit via the score: spurious parent-child relations increase BIC (via RSS and edge penalty) or fail to improve regression performance when removed; pruning tests the effect of removing a parent on score/regression fit and accepts removal if performance does not degrade beyond tolerance. For GP models, overfitting-driven spurious edges were diagnosed empirically and alleviated by kernel-bandwidth (median heuristic) and normalization.",
            "downweighting_method": "BIC penalty on number of edges (log m term) downweights complex graphs; acyclicity penalties discourage cyclic structures; entropy regularization in policy prevents premature convergence to overfitted graph distributions. For GPR models, median-heuristic kernel bandwidth reduces overfitting that would otherwise upweight spurious dependencies.",
            "refutation_method": "Greedy post-processing: iteratively remove a parental variable and accept the removal if the regression performance / score does not worsen beyond a preset tolerance; threshold coefficients in linear/quadratic models to remove weak edges. Also equivalence via comparing rewards across generated graphs (select best-scoring DAG seen).",
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": "Reported across multiple benchmarks in the paper: on 12-node LiNGAM and linear-Gaussian synthetic data RL-BIC2 achieved FDR=0.00, TPR=1.00, SHD=0.00 (perfect recovery in those experiments after pruning/thresholding); on 10-node quadratic nonlinear SEM RL-BIC2: FDR=0.02 ± 0.04, TPR=0.98 ± 0.04, SHD=0.6 ± 1.20; on 10-node GP-sampled functions RL-BIC: FDR=0.14 ± 0.03, TPR=0.96 ± 0.03, SHD=6.2 ± 1.33 (RL-BIC2 slightly worse on that setting). On the Sachs real dataset RL-BIC achieved 10 total edges, 6 correct edges, SHD=12 (RL-BIC2: 10 total, 7 correct, SHD=11). These metrics reflect the method as used with its pruning/regularization choices described in the paper.",
            "performance_without_robustness": "The paper compares against baseline algorithms (GES, PC, NOTEARS, DAG-GNN, GraN-DAG, CAM, ICA-LiNGAM) on the same datasets; e.g., on 12-node linear-Gaussian NOTEARS had FDR≈0.02, TPR≈0.98, SHD≈1.0 while GES and PC performed substantially worse on dense synthetic graphs. Ablated variants RL-BIC (without certain choices such as the RL-BIC2 normalization/assumptions) showed higher FDR and SHD in some settings (tables in paper show RL-BIC often worse than RL-BIC2), demonstrating the contribution of score normalization, penalty schedules, and regression choices. The paper also notes that using fixed GPR bandwidth without median heuristic leads to heavy overfitting and many spurious edges (graph with highest reward often cyclic).",
            "has_ablation_study": false,
            "number_of_distractors": null,
            "key_findings": "Using RL as a global search strategy over DAGs plus flexible score functions yields improved search ability and, when combined with model-appropriate regressors and explicit pruning/regularization, substantially reduces false discoveries. Practical techniques that improved robustness to spurious edges include: (1) using BIC which penalizes extra edges; (2) adding both an indicator and a smooth acyclicity penalty to the reward (helps guide search toward DAGs); (3) post-hoc greedy pruning based on regression performance/score; (4) choosing appropriate local regression models (quadratic, GPR) and kernel-bandwidth heuristics to avoid overfitting; and (5) thresholding small coefficients in linear/quadratic fits. These components collectively reduced FDR and SHD in the experiments reported.",
            "uuid": "e1000.0",
            "source_info": {
                "paper_title": "Causal Discovery with Reinforcement Learning",
                "publication_date_yy_mm": "2019-06"
            }
        },
        {
            "name_short": "Greedy pruning (regression/score-based)",
            "name_full": "Greedy pruning of inferred causal edges based on regression performance or score function",
            "brief_description": "A post-processing used in this paper (and commonly used elsewhere): iteratively test removal of each parent edge and accept the removal if the overall predictive performance or the chosen score does not degrade beyond tolerance, thereby removing spurious edges.",
            "citation_title": "here",
            "mention_or_use": "use",
            "method_name": "Greedy post-hoc pruning via leave-one-parent-out score/regression test",
            "method_description": "For each inferred parental relationship, remove the edge and recompute either the regression fit (e.g., RSS or log-likelihood) or the global score (BIC). If performance does not degrade or degrades within a pre-defined tolerance, permanently remove the edge and continue iteratively. For linear models, a simple coefficient thresholding is also used to prune weak edges.",
            "environment_name": "Same observational synthetic/real datasets used for graph discovery in the paper",
            "environment_description": "Passive observational datasets; pruning is applied offline after model search and scoring (no active interventions).",
            "handles_distractors": true,
            "distractor_handling_technique": "Model-selection based refutation: edges that do not contribute to predictive performance (or that increase penalized score) are removed; coefficient thresholding for linear/quadratic fits.",
            "spurious_signal_types": "Irrelevant parents producing false positive edges, weak/low-effect-size dependencies, overfitting-induced spurious associations.",
            "detection_method": "Comparative test: measure change in regression performance or score when an edge is removed; if removal does not worsen performance beyond tolerance the edge is marked spurious.",
            "downweighting_method": null,
            "refutation_method": "Explicit refutation by demonstrating that the model without the edge is not worse (or is better) under the score/regression metric; then accept edge removal.",
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": "In the quadratic SEM experiments, applying quadratic-regression-based pruning to NOTEARS (creating NOTEARS-2) reduced FDR from 0.35 to 0.15 while retaining similar TPR, demonstrating pruning reduces false positives with little TPR loss; RL-BIC methods also relied on pruning/thresholding to obtain low FDR and SHD in several experiments (e.g., perfect recovery in some linear experiments after pruning/thresholding).",
            "performance_without_robustness": "Without pruning (or without suitable thresholding), many methods exhibited substantially higher FDR (e.g., NOTEARS FDR=0.35 on quadratic SEMs before pruning). The paper reports that pruning 'further reduces FDR with little effect on TPR.'",
            "has_ablation_study": false,
            "number_of_distractors": null,
            "key_findings": "Greedy pruning based on regression performance or score is an effective and simple post-processing to eliminate many spurious edges introduced by flexible regression models or imperfect search; it typically reduces FDR significantly with minimal loss in TPR according to the paper's experiments.",
            "uuid": "e1000.1",
            "source_info": {
                "paper_title": "Causal Discovery with Reinforcement Learning",
                "publication_date_yy_mm": "2019-06"
            }
        },
        {
            "name_short": "CAM pruning / significance testing",
            "name_full": "Causal Additive Models (CAM) significance-based pruning",
            "brief_description": "CAM is an additive-noise-based causal discovery pipeline that includes a post-selection step using significance testing of covariates (p-value based) to prune spurious edges; the paper uses CAM-style pruning settings for some comparisons.",
            "citation_title": "CAM: Causal additive models, high-dimensional order search and penalized regression",
            "mention_or_use": "use",
            "method_name": "CAM (with significance-test-based pruning)",
            "method_description": "CAM separates order search from edge selection under additive-noise assumptions and applies significance testing (generalized additive models) to determine if candidate parent covariates are significant; edges with p-values above a threshold are pruned. The paper follows CAM authors' pruning choice (p ≤ 0.001) for comparable post-processing.",
            "environment_name": "Synthetic SEM datasets and real Sachs dataset (as used in experiments)",
            "environment_description": "Passive observational datasets with additive noise and assumed nonlinearity (CAM assumes nonlinear functional relationships).",
            "handles_distractors": true,
            "distractor_handling_technique": "Significance testing of covariates (p-value thresholding) to remove spurious parent variables.",
            "spurious_signal_types": "Irrelevant covariates that appear predictive due to chance or multiple-testing; false-positive edges.",
            "detection_method": "Statistical hypothesis testing on covariate coefficients in (generalized) additive models; p-value comparison against a strict threshold (authors' recommended 0.001).",
            "downweighting_method": null,
            "refutation_method": "Rejecting edges whose covariate p-values exceed the threshold (i.e., failing to be statistically significant) — thereby removing spurious causal claims.",
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": "In experiments reported in the paper, CAM's pruning procedure produced moderate FDR/TPR tradeoffs depending on the data model: e.g., in the quadratic SEM experiment CAM had FDR≈0.32, TPR≈0.78, SHD≈14.1; on GP models CAM reported FDR≈0.15, TPR≈0.82, SHD≈10.2. The pruning helps control false positives but performance depends on model assumptions (additive nonlinearity).",
            "performance_without_robustness": null,
            "has_ablation_study": false,
            "number_of_distractors": null,
            "key_findings": "CAM-style significance testing is an explicit, hypothesis-test-based approach to remove spurious edges; in the paper it is used as a standard pruning baseline and reduces false discoveries when its modeling assumptions (additive noise and sufficient data) hold.",
            "uuid": "e1000.2",
            "source_info": {
                "paper_title": "Causal Discovery with Reinforcement Learning",
                "publication_date_yy_mm": "2019-06"
            }
        },
        {
            "name_short": "PC algorithm (conditional independence)",
            "name_full": "PC algorithm (constraint-based causal discovery using conditional independence tests)",
            "brief_description": "A classic constraint-based algorithm that uses conditional independence tests to recover the undirected skeleton and then orients edges up to the Markov equivalence class; conditional independence testing can detect and eliminate many spurious associations under faithfulness.",
            "citation_title": "here",
            "mention_or_use": "use",
            "method_name": "PC algorithm (with Fisher-z tests in experiments)",
            "method_description": "Conducts pairwise and conditional independence tests (e.g., partial correlation Fisher-z tests) to build an undirected skeleton: if X independent of Y given some set S, no edge is placed; orientation rules (v-structures and propagation) then orient as many edges as allowed. Multiple-testing and conflicting test outcomes are a known practical issue.",
            "environment_name": "Synthetic SEM datasets used in experiments (LiNGAM, linear-Gaussian, etc.)",
            "environment_description": "Passive observational datasets; PC performs conditional independence testing on observed samples to infer edges and orientations; not an active/interventional method.",
            "handles_distractors": true,
            "distractor_handling_technique": "Conditional independence testing (kernel-based or parametric tests) to detect relationships that disappear when conditioning on appropriate sets, thereby removing associations due to confounding or indirect paths under faithfulness.",
            "spurious_signal_types": "Spurious associations due to indirect paths or marginal correlation (i.e., association but not direct causation), some confounding under assumptions; multiple-testing-induced false positives are discussed as a problem.",
            "detection_method": "Statistical conditional independence tests (e.g., Fisher-z partial correlation in experiments, kernel-based CI in related work) detect lack of direct dependence once conditioning variables are included.",
            "downweighting_method": null,
            "refutation_method": "Edges are not included if independence cannot be rejected for the corresponding conditional sets; conflicts between tests may leave some edges unoriented or require resolution strategies.",
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": "In the paper's dense synthetic graphs, PC performed poorly: on 12-node LiNGAM PC had FDR≈0.06, TPR≈0.25, SHD≈31.8; on 12-node linear-Gaussian PC had FDR≈0.52, TPR≈0.31, SHD≈29.6, showing that CI-testing alone can struggle under finite-sample/noise/dense-graph conditions.",
            "performance_without_robustness": null,
            "has_ablation_study": false,
            "number_of_distractors": null,
            "key_findings": "Conditional-independence-based methods can detect and remove many spurious marginal associations but are sensitive to sample size, multiple-testing, and faithfulness violations; the paper cites these limitations and notes conflict-resolution is nontrivial (see Hyttinen et al. 2014).",
            "uuid": "e1000.3",
            "source_info": {
                "paper_title": "Causal Discovery with Reinforcement Learning",
                "publication_date_yy_mm": "2019-06"
            }
        },
        {
            "name_short": "Conflict-resolution (Hyttinen et al.)",
            "name_full": "Conflict resolution for constraint-based causal discovery using answer set programming",
            "brief_description": "A referenced approach that attempts to resolve conflicting conditional independence test outputs (a source of spurious or inconsistent edges) using answer set programming to find consistent graph structures.",
            "citation_title": "here",
            "mention_or_use": "mention",
            "method_name": "Answer-set-programming-based conflict resolution in constraint-based causal discovery",
            "method_description": "Constraint-based pipelines rely on many conditional independence tests; Hyttinen et al. (2014) propose encoding CI constraints and conflicts into an answer set program to find graph structures that best reconcile conflicting test outcomes, thereby addressing inconsistencies that can lead to spurious edges.",
            "environment_name": "Constraint-based causal discovery on observational datasets (general)",
            "environment_description": "Not an interactive environment; solves consistency issues arising from multiple dependent statistical tests on observational data.",
            "handles_distractors": true,
            "distractor_handling_technique": "Conflict resolution among CI tests outputs via combinatorial optimization (answer set programming) rather than simple independent acceptance/rejection of tests.",
            "spurious_signal_types": "Conflicting CI test outcomes that can produce spurious edges or inconsistent skeletons due to finite-sample error and multiple testing.",
            "detection_method": "Detects inconsistent sets of CI decisions by global encoding and uses ASP to find a consistent selection of edges/tests.",
            "downweighting_method": null,
            "refutation_method": "Resolves conflicts by selecting a globally consistent set of CI results, effectively refuting test-based spurious edges that cannot be reconciled.",
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "Cited as an approach addressing conflicts and inconsistencies in CI-testing frameworks; the paper notes such conflict-resolution work exists but does not evaluate it empirically.",
            "uuid": "e1000.4",
            "source_info": {
                "paper_title": "Causal Discovery with Reinforcement Learning",
                "publication_date_yy_mm": "2019-06"
            }
        },
        {
            "name_short": "NOTEARS",
            "name_full": "DAGs with NO TEARS (continuous optimization for structure learning)",
            "brief_description": "A continuous optimization approach that reformulates DAG-constrained structure learning with a smooth acyclicity constraint (trace(exp(W◦W))−d=0) and optimizes a weighted adjacency matrix with least-squares loss and augmented Lagrangian techniques; thresholding is applied to obtain a binary graph.",
            "citation_title": "DAGs with NO TEARS: Continuous optimization for structure learning",
            "mention_or_use": "use",
            "method_name": "NOTEARS (smooth acyclicity continuous optimization)",
            "method_description": "Formulates structure learning as minimizing a loss (e.g., least-squares) over a real-valued weighted adjacency matrix subject to a smooth acyclicity constraint h(W)=0 (using trace of matrix exponential). Solved with augmented Lagrangian and standard optimizers; final binary graph obtained by thresholding weights. Has variants for nonlinear/local regressors.",
            "environment_name": "Synthetic SEM datasets (linear, nonlinear variants) used in experiments",
            "environment_description": "Passive observational datasets; NOTEARS performs continuous optimization on a weighted adjacency matrix rather than combinatorial graph sampling.",
            "handles_distractors": true,
            "distractor_handling_technique": "Implicit regularization via least-squares loss and (optionally) penalty terms; final thresholding of weights removes weak edges; variants combined with suitable regressors can reduce spurious edges.",
            "spurious_signal_types": "Weak/low-weight edges that can arise from overfitting or indirect associations; cyclic structures improperly represented in weighted matrices.",
            "detection_method": null,
            "downweighting_method": "Penalized loss and final thresholding of small weights; augmented Lagrangian penalty on acyclicity shapes solution space.",
            "refutation_method": "Thresholding weak coefficients to zero; in experimenters' variants (NOTEARS-2) additional regression-based pruning further reduces spurious edges.",
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": "In experiments NOTEARS performs well on many settings (e.g., linear-Gaussian: FDR≈0.02, TPR≈0.98, SHD≈1.0 in Table 1), but can be outperformed by RL-based search in some nonlinear settings when combined with appropriate pruning.",
            "performance_without_robustness": "Base NOTEARS (without quadratic pruning) had worse FDR on the quadratic SEM (FDR≈0.35, TPR≈0.71, SHD≈14.8) compared to NOTEARS-2 (after quadratic-regression-based pruning: FDR≈0.15, TPR≈0.70, SHD≈8.8), illustrating the benefit of pruning.",
            "has_ablation_study": false,
            "number_of_distractors": null,
            "key_findings": "NOTEARS' continuous formulation is flexible and effective in many settings, but proper choice of local regressors and post-processing (thresholding or pruning) is important to control spurious edges; applying pruning or problem-specific regressors (quadratic) reduces FDR substantially in nonlinear settings.",
            "uuid": "e1000.5",
            "source_info": {
                "paper_title": "Causal Discovery with Reinforcement Learning",
                "publication_date_yy_mm": "2019-06"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Causal discovery with continuous additive noise models",
            "rating": 2
        },
        {
            "paper_title": "DAGs with NO TEARS: Continuous optimization for structure learning",
            "rating": 2
        },
        {
            "paper_title": "Constraint-based causal discovery: Conflict resolution with answer set programming",
            "rating": 2
        },
        {
            "paper_title": "CAM: Causal additive models, high-dimensional order search and penalized regression",
            "rating": 2
        },
        {
            "paper_title": "Generalized score functions for causal discovery",
            "rating": 1
        },
        {
            "paper_title": "Gradient-based neural DAG learning",
            "rating": 1
        }
    ],
    "cost": 0.0207685,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>CAUSAL DISCOVERY WITH REINFORCEMENT LEARNING</h1>
<p>Shengyu Zhu ${ }^{\dagger}$ Ignavier $\mathbf{N g}^{\S *}$ Zhitang Chen ${ }^{\dagger}$<br>${ }^{\dagger}$ Huawei Noah's Ark Lab ${ }^{\S}$ University of Toronto<br>${ }^{\dagger}{$ zhushengyu, chenzhitang2}@huawei.com ${ }^{\S}$ ignavierng@cs.toronto.edu</p>
<h4>Abstract</h4>
<p>Discovering causal structure among a set of variables is a fundamental problem in many empirical sciences. Traditional score-based casual discovery methods rely on various local heuristics to search for a Directed Acyclic Graph (DAG) according to a predefined score function. While these methods, e.g., greedy equivalence search, may have attractive results with infinite samples and certain model assumptions, they are less satisfactory in practice due to finite data and possible violation of assumptions. Motivated by recent advances in neural combinatorial optimization, we propose to use Reinforcement Learning (RL) to search for the DAG with the best scoring. Our encoder-decoder model takes observable data as input and generates graph adjacency matrices that are used to compute rewards. The reward incorporates both the predefined score function and two penalty terms for enforcing acyclicity. In contrast with typical RL applications where the goal is to learn a policy, we use RL as a search strategy and our final output would be the graph, among all graphs generated during training, that achieves the best reward. We conduct experiments on both synthetic and real datasets, and show that the proposed approach not only has an improved search ability but also allows a flexible score function under the acyclicity constraint.</p>
<h2>1 INTRODUCTION</h2>
<p>Discovering and understanding causal mechanisms underlying natural phenomena are important to many disciplines of sciences. An effective approach is to conduct controlled randomized experiments, which however is expensive or even impossible in certain fields such as social sciences (Bollen, 1989) and bioinformatics (Opgen-Rhein and Strimmer, 2007). Causal discovery methods that infer causal relationships from passively observable data are hence attractive and have been an important research topic in the past decades (Pearl, 2009; Spirtes et al., 2000; Peters et al., 2017).</p>
<p>A major class of such causal discovery methods are score-based, which assign a score $\mathcal{S}(\mathcal{G})$, typically computed with the observed data, to each directed graph $\mathcal{G}$ and then search over the space of all Directed Acyclic Graphs (DAGs) for the best scoring:</p>
<p>$$
\min _{\mathcal{G}} \mathcal{S}(\mathcal{G}), \text { subject to } \mathcal{G} \in \text { DAGs. }
$$</p>
<p>While there have been well-defined score functions such as the Bayesian Information Criterion (BIC) or Minimum Description Length (MDL) score (Schwarz, 1978; Chickering, 2002) and the Bayesian Gaussian equivalent (BGe) score (Geiger and Heckerman, 1994), Problem (1) is generally NP-hard to solve (Chickering, 1996; Chickering et al., 2004), largely due to the combinatorial nature of its acyclicity constraint with the number of DAGs increasing super-exponentially in the number of graph nodes. To tackle this problem, most existing approaches rely on local heuristics to enforce the acyclicity. For example, Greedy Equivalence Search (GES) enforces acyclicity one edge at a time, explicitly checking for the acyclicity constraint when an edge is added. GES is known to find global minimizer with infinite samples under suitable assumptions (Chickering, 2002; Nandy et al., 2018), but this is not guaranteed in the finite sample regime. There are hybrid methods, e.g., the max-min hill climbing method (Tsamardinos et al., 2006), which use constraint-based approaches to reduce</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>the search space before applying score-based methods. However, this methodology generally lacks a principled way of choosing a problem-specific combination of score functions and search strategies.</p>
<p>Recently, Zheng et al. (2018) introduced a smooth characterization for the acyclicity. With linear models, Problem (1) was then formulated as a continuous optimization problem w.r.t. the weighted graph adjacency matrix by picking a proper loss function, e.g., the least squares loss. Subsequent works Yu et al. (2019) and Lachapelle et al. (2019) have also adopted the evidence lower bound and the negative log-likelihood as loss functions, respectively, and used Neural Networks (NNs) to model the causal relationships. Note that the loss functions in these methods must be carefully chosen in order to apply continuous optimization methods. Unfortunately, many effective score functions, e.g., the generalized score function proposed by Huang et al. (2018) and the independence based score function from Peters et al. (2014), either cannot be represented in closed forms or have very complicated equivalent loss functions, and thus cannot be easily combined with this approach.</p>
<p>We propose to use Reinforcement Learning (RL) to search for the DAG with the best score according to a predefined score function, as outlined in Figure 1. The insight is that an RL agent with stochastic policy can determine automatically where to search given the uncertainty information of the learned policy, which can be updated promptly by the stream of reward signals. To apply RL to causal discovery, we use an encoder-decoder NN model to generate directed graphs from the observed data, which are then used to compute rewards consisting of the predefined score function as well as two penalty terms to enforce acyclicity. We resort to policy gradient and stochastic optimization methods to train the weights of the NNs, and our output is the graph that achieves the best reward, among all graphs generated in the training process. Experiments on both synthetic and real datasets show that our approach has a much improved search ability without sacrificing any flexibility in choosing score functions. In particular, the proposed approach with BIC score outperforms GES with the same score function on Linear Non-Gaussian Acyclic Model (LiNGAM) and linear-Gaussian datasets, and also outperforms recent gradient based methods when the causal relationships are nonlinear.
<img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: Reinforcement learning for score-based causal discovery.</p>
<h1>2 Related Work</h1>
<p>Constraint-based causal discovery methods first use conditional independence tests to find causal skeleton and then determine the orientations of the edges up to the Markov equivalence class, which usually contains DAGs that can be structurally diverse and may still have many unoriented edges. Examples include Sun et al. (2007); Zhang et al. (2012) that use kernel-based conditional independence criteria and the well-known PC algorithm (Spirtes et al., 2000). This class of methods involve a multiple testing problem where the tests are usually conducted independently. The testing results may have conflicts and handling them is not easy, though there are certain works, e.g., Hyttinen et al. (2014), attempting to tackle this problem. These methods are also not robust as small errors in building the graph skeleton can result in large errors in the inferred Markov equivalence class.</p>
<p>Another class of causal discovery methods are based on properly defined functional causal models. Unlike constraint-based methods that assume faithfulness and identify only the Markov equivalence class, these methods are able to distinguish between different DAGs in the same equivalence class, thanks to the additional assumptions on data distribution and/or functional classes. Examples include LiNGAM (Shimizu et al., 2006; 2011), the nonlinear additive noise model (Hoyer et al., 2009; Peters et al., 2014; 2017), and the post-nonlinear causal model (Zhang and Hyvärinen, 2009).</p>
<p>Besides Yu et al. (2019); Lachapelle et al. (2019), other recent NN based approaches to causal discovery include Goudet et al. (2018) that proposes causal generative NNs to functional causal</p>
<p>modeling with a prior knowledge of initial skeleton of the causal graph and <em>Kalainathan et al. (2018)</em> that learns causal generative models in an adversarial way but does not guarantee acyclicity.</p>
<p>Recent advances in sequence-to-sequence learning <em>(Sutskever et al., 2014)</em> have motivated the use of NNs for optimization in various domains <em>(Vinyals et al., 2015; Zoph and Le, 2017; Chen et al., 2017)</em>. A particular example is the traveling salesman problem that was revisited in the work of pointer networks <em>(Vinyals et al., 2015)</em>. Authors proposed a recurrent NN with nonparametric softmaxes trained in a supervised manner to predict the sequence of visited cities. <em>Bello et al. (2016)</em> further proposed to use the RL paradigm to tackle the combinatorial problems due to their relatively simple reward mechanisms. It was shown that an RL agent can have a better generalization even when the optimal solutions are used as labeled data in the previous supervised approach. Alternatively, the RL based approach in <em>Dai et al. (2017)</em> considered combinatorial optimization problems on (undirected) graphs and achieved a promising performance by exploiting graph structures, in contrast with the general sequence-to-sequence modeling.</p>
<p>There are many other successful RL applications in recent years, e.g., AlphaGo <em>(Silver et al., 2017)</em>, where the goal is to learn a policy for a given task. As an exception, <em>Zoph and Le (2017)</em> applied RL to neural architecture search. While we use a similar idea as the RL paradigm can naturally include the search task, our work is different in the actor and reward designs: our actor is an encoder-decoder model that generates graph adjacency matrices (cf. Section 4) and the reward is tailored for causal discovery by incorporating a score function and the acyclicity constraint (cf. Section 5.1).</p>
<h2>3 Model Definition</h2>
<p>We assume the following model for data generating procedure, as in <em>Hoyer et al. (2009); Peters et al. (2014)</em>. Each variable $x_{i}$ is associated with a node $i$ in a $d$-node $\operatorname{DAG}\mathcal{G}$, and the observed value of $x_{i}$ is obtained as a function of its parents in the graph plus an independent additive noise $n_{i}$, i.e.,</p>
<p>$x_{i}:=f_{i}(\mathbf{x}<em i="i">{\mathrm{pa}(i)})+n</em>,i=1,2,\ldots,d,$</p>
<p>where $\mathbf{x}<em j="j">{\mathrm{pa}(i)}$ denotes the set of variables $x</em>$ is not a constant in any of its arguments }$ so that there is an edge from $x_{j}$ to $x_{i}$ in the graph, and the noises $n_{i}$ are assumed to be jointly independent. We also assume causal minimality, which in this case reduces to that each function $f_{i<em>(Peters et al., 2014)</em>. Without further assumption on the forms of functions and/or noises, the above model can be identified only up to Markov equivalence class under the usual Markov and faithful assumptions <em>(Spirtes et al., 2000; Peters et al., 2014)</em>; in our experiments we will consider synthetic datasets that are generated from fully identifiable models so that it is practically meaningful to evaluate the estimated graph w.r.t. the true DAG. If all the functions $f_{i}$ are linear and the noises $n_{i}$ are Gaussian distributed, the above model yields the class of standard linear-Gaussian model that has been studied in <em>Bollen (1989); Geiger and Heckerman (1994); Spirtes et al. (2000); Peters et al. (2017)</em>. When the functions are linear but the noises are non-Gaussian, one can obtain the LiNGAM described in <em>Shimizu et al. (2006, 2011)</em> and the true DAG can be uniquely identified under favorable conditions.</p>
<p>In this paper, we consider that all the variables $x_{i}$ are scalars; extending to more complex cases is straightforward, provided with a properly defined score function. The observed data $\mathbf{X}$, consisting of a number of vectors $\mathbf{x}:=[x_{1},x_{2},\ldots,x_{d}]^{T}\in\mathbb{R}^{d}$, are then sampled independently according to the above model on an unknown DAG, with fixed functions $f_{i}$ and fixed distributions for $n_{i}$. The objective of causal discovery is to use the observed data $\mathbf{X}$, which gives the empirical version of the joint distribution of $\mathbf{x}$, to infer the underlying causal $\operatorname{DAG}\mathcal{G}$.</p>
<h2>4 Neural Network Architecture for Graph Generation</h2>
<p>Given a dataset $\mathbf{X}={\mathbf{x}^{k}}_{k=1}^{m}$ where $\mathbf{x}^{k}$ denotes the $k$-th observed sample, we want to infer the causal graph that best describes the data generating procedure. We would like to use NNs to infer the causal graph from the observed data; specifically, we aim to design an NN based graph generator whose input is the observed data and the output is a graph adjacency matrix. A naive choice would be using feed-forward NNs to output $d^{2}$ scalars and then reshape them to an adjacency matrix in $\mathbb{R}^{d \times d}$. However, this NN structure failed to produce promising results, possibly because the feed-forward NNs could not provide sufficient interactions amongst variables to capture the causal relations.</p>
<p>Motivated by recent advances in neural combinatorial optimization, particularly the pointer networks (Bello et al., 2016; Vinyals et al., 2015), we draw $n$ random samples (with replacement) $\left{\mathbf{x}^{i}\right}<em i="i">{i=1}^{n}$ from $\mathbf{X}$ and reshape them as $\mathbf{s}:=\left{\tilde{\mathbf{x}}</em>\right}<em i="i">{i=1}^{d}$ where $\tilde{\mathbf{x}}</em>$ so that the corresponding graph is acyclic and achieves the best score. In this work we consider encoder-decoder models for graph generation:} \in \mathbb{R}^{n}$ is the vector concatenating all the $i$-th entries of the vectors in $\left{\mathbf{x}^{i}\right}_{i=1}^{n}$. In an analogy to the traveling salesman problem, this represents a sequence of $d$ cities lying in an $n$-dim space. We are concerned with generating a binary adjacency matrix $A \in{0,1}^{d \times d</p>
<p>Encoder We use the attention based encoder in the Transformer structure proposed by Vaswani et al. (2017). We believe that the self-attention scheme, together with structural DAG constraint, is capable of finding the causal relations amongst variables. Other attention based models such as graph attention network (Veličković et al., 2018) may also be used, which will be considered in a future work. Denote the outputs of the encoder by $e n c_{i}, i=1,2, \ldots, d$, with dimension $d_{e}$.</p>
<p>Decoder Our decoder generates the graph adjacency matrix in an element-wise manner, by building relationships between two encoder outputs $e n c_{i}$ and $e n c_{j}$. We consider the single layer decoder</p>
<p>$$
g_{i j}\left(W_{1}, W_{2}, u\right)=u^{T} \tanh \left(W_{1} e n c_{i}+W_{2} e n c_{j}\right)
$$</p>
<p>where $W_{1}, W_{2} \in \mathbb{R}^{d_{h} \times d_{e}}, u \in \mathbb{R}^{d_{h} \times 1}$ are trainable parameters and $d_{h}$ is the hidden dimension associated with the decoder. To generate a binary adjacency matrix $A$, we pass each entry $g_{i j}$ into a logistic sigmoid function $\sigma(\cdot)$ and then sample according to a Bernoulli distribution with probability $\sigma\left(g_{i j}\right)$ that indicates the probability of existing an edge from $x_{i}$ to $x_{j}$. To avoid self-loops, we simply mask the $(i, i)$-th entry in the adjacency matrix.</p>
<p>Other decoder choices include the neural tensor network model (Socher et al., 2013) and the bilinear model that build the pairwise relationships between encoder outputs. Another choice is the Transformer decoder which can generate an adjacency matrix in a row-wise manner. Empirically, we find that the single layer decoder performs the best, possibly because it contains less parameters and is easier to train to find better DAGs while the self-attention based encoder has provided sufficient interactions amongst the variables for causal discovery. Appendix A provides more details regarding these decoders and their empirical results with linear-Gaussian data models.</p>
<h1>5 REINFORCEMENT LEARNING FOR SEARCH</h1>
<p>In this section, we use RL as our search strategy to find the DAG with the best score, as outlined in Figure 1. As one will see, the proposed method possesses an improved search ability over traditional score-based methods and also allows flexible score functions subject to the acyclicity constraint.</p>
<h3>5.1 Score Function, Acyclicity, and Reward</h3>
<p>Score Function In this work, we consider only existing score functions to construct the reward that will be maximized by an RL agent. Often score-based methods assume a parametric model for causal relationships (e.g., linear-Gaussian equations or multinomial distribution), which introduces a set of parameters $\theta$. Among all score functions that can be directly included here, we focus on the BIC score that is not only consistent (Haughton et al., 1988) but also locally consistent for its decomposability (Chickering, 1996).
The BIC score for a given directed graph $\mathcal{G}$ is</p>
<p>$$
\mathcal{S}<em _theta="\theta">{\mathrm{BIC}}(\mathcal{G})=-2 \log p(\mathbf{X} ; \hat{\theta}, \mathcal{G})+d</em> \log m
$$</p>
<p>where $\hat{\theta}$ is the maximum likelihood estimator and $d_{\theta}$ denotes the dimensionality of the parameter $\theta$. We assume i.i.d. Gaussian additive noises throughout this paper. If we apply linear models to each causal relationship and let $\hat{x}<em i="i">{i}^{k}$ be the corresponding estimate for $x</em>$, the $i$-th entry in the $k$-th observed sample, then we have the BIC score being (up to some additive constant)}^{k</p>
<p>$$
\mathcal{S}<em i="1">{\mathrm{BIC}}(\mathcal{G})=\sum</em>) \log m
$$}^{d}\left(m \log \left(\mathrm{RSS}_{i} / m\right)\right)+#(\text { edges </p>
<p>where $\operatorname{RSS}<em k="1">{i}=\sum</em>$ denotes the residual sum of squares for the $i$-th variable. The first term in Eq. (2) is equivalent to the log-likelihood objective used by GraN-DAG (Lachapelle et al.,}^{m}\left(x_{i}^{k}-\hat{x}_{i}^{k}\right)^{2</p>
<p>2019) and the second term adds penalty on the number of edges in the graph $\mathcal{G}$. Further assuming that the noise variances are equal (despite the fact that they may be different), we have</p>
<p>$$
\mathcal{S}<em i="1">{\mathrm{BIC}}(\mathcal{G})=m d \log \left(\left(\sum</em>) \log m
$$}^{d} \mathrm{RSS}_{i}\right) /(m d)\right)+#(\text { edges </p>
<p>We notice that $\sum_{i} \mathrm{RSS}<em i="i">{i}$ is the least squares loss used in NOTEARS (Zheng et al., 2018). Besides assuming linear models, other regression methods can also be used to estimate $x</em>$. In Section 6, we will use quadratic regression and Gaussian Process Regression (GPR) to model causal relationships based on the observed data.}^{k</p>
<p>Acyclicity A remaining issue is the acyclicity constraint. Other than GES that explicitly checks for acyclicity each time an edge is added, we add penalty terms w.r.t. acyclicity to the score function to enforce acyclicity in an implicit manner and allow the generated graph to change more than one edges at each iteration. In this work, we use a recent result from Zheng et al. (2018): a directed graph $\mathcal{G}$ with binary adjacency matrix $A$ is acyclic if and only if</p>
<p>$$
h(A):=\operatorname{trace}\left(e^{A}\right)-d=0
$$</p>
<p>where $e^{A}$ is the matrix exponential of $A$. We find that $h(A)$, which is non-negative, can be small for cyclic graphs and the minimum over all non-DAGs is not easy to find. We would require a very large penalty weight to guarantee acyclicity if only $h(A)$ is used. We thus add another penalty term, the indicator function w.r.t. acyclicity, to induce exact DAGs. We remark that other functions (e.g., the total length of all cyclic paths in the graph), which compute some 'distance' from a directed graph to DAGs and need not be smooth, may also be used to construct the acyclicity penalty in our approach.</p>
<p>Reward Our reward incorporates both the score function and the acyclicity constraint:</p>
<p>$$
\text { reward }:=-\left[\mathcal{S}(\mathcal{G})+\lambda_{1} \mathbf{I}(\mathcal{G} \notin \text { DAGs })+\lambda_{2} h(A)\right]
$$</p>
<p>where $\mathbf{I}(\cdot)$ denotes the indicator function and $\lambda_{1}, \lambda_{2} \geq 0$ are two penalty parameters. It is not hard to see that the larger $\lambda_{1}$ and $\lambda_{2}$ are, the more likely a generated graph with a high reward is acyclic. We then aim to maximize the reward over all possible directed graphs, or equivalently, we have</p>
<p>$$
\min <em 1="1">{\mathcal{G}}\left[\mathcal{S}(\mathcal{G})+\lambda</em> h(A)\right]
$$} \mathbf{I}(\mathcal{G} \notin \text { DAGs })+\lambda_{2</p>
<p>An interesting question is whether this new formulation is equivalent to the original problem with hard acyclicity constraint. Fortunately, the following proposition guarantees that Problems (1) and (6) are equivalent with properly chosen $\lambda_{1}$ and $\lambda_{2}$, which can be verified by showing that a minimizer of one problem is also a solution to the other. A proof is provided in Appendix B for completeness.
Proposition 1. Let $h_{\min }&gt;0$ be the minimum of $h(A)$ over all directed cyclic graphs, i.e., $h_{\min }=$ $\min <em U="U">{\mathcal{G} \notin \text { DAGs }} h(A)$. Let $\mathcal{S}^{<em>}$ denote the optimal score achieved by some DAG in Problem (1). Assume that $\mathcal{S}<em L="L">{L} \in \mathbb{R}$ is a lower bound of the score function over all possible directed graphs, i.e., $S</em> \leq$ $\min <em U="U">{\mathcal{G}} \mathcal{S}(\mathcal{G})$, and $S</em>^{} \in \mathbb{R}$ is an upper bound on the optimal score with $\mathcal{S</em>} \leq \mathcal{S}</em>$. Then Problems (1) and (6) are equivalent if</p>
<p>$$
\lambda_{1}+\lambda_{2} h_{\min } \geq \mathcal{S}<em L="L">{U}-\mathcal{S}</em>
$$</p>
<p>For practical use, we need to find respective quantities in order to choose proper penalty parameters. An upper bound $\mathcal{S}<em L="L">{U}$ can be easily found by drawing some random DAGs or using the results from other methods like NOTEARS. A lower bound $\mathcal{S}</em>}$ depends on the particular score function. With BIC score, we can fit each variable $x_{i}$ against all the rest variables, and use only the $\mathrm{RSS<em L="L">{i}$ terms but ignore the additive penalty on the number of edges. With the independence based score function proposed by Peters et al. (2014), we may simply set $\mathcal{S}</em>}=0$. The minimum term $h_{\min }$, as previously mentioned, may not be easy to find. Fortunately, with $\lambda_{1}=\mathcal{S<em L="L">{U}-\mathcal{S}</em>$, which helps to generate directed graphs that become closer to DAGs.}$, Proposition 1 guarantees the equivalence of Problems (1) and (6) for any $\lambda_{2} \geq 0$. However, simply setting $\lambda_{2}=0$ could only get good performance with very small graphs (see a discussion in Appendix C). We will pick a relatively small value for $\lambda_{2</p>
<p>Empirically, we find that if the initial penalty weights are set too large, the score function would have little effect on the reward, which then limits the exploration of the RL agent and usually results in DAGs with high scores. Similar to Lagrangian methods, we can start with small penalty weights and gradually increase them so that the condition in Proposition 1 is satisfied. Meanwhile, we notice that</p>
<div class="codehilite"><pre><span></span><code><span class="nt">Algorithm</span><span class="w"> </span><span class="nt">1</span><span class="w"> </span><span class="nt">The</span><span class="w"> </span><span class="nt">proposed</span><span class="w"> </span><span class="nt">RL</span><span class="w"> </span><span class="nt">approach</span><span class="w"> </span><span class="nt">to</span><span class="w"> </span><span class="nt">score-based</span><span class="w"> </span><span class="nt">causal</span><span class="w"> </span><span class="nt">discovery</span>
<span class="nt">Require</span><span class="o">:</span><span class="w"> </span><span class="nt">score</span><span class="w"> </span><span class="nt">parameters</span><span class="o">:</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="err">\</span><span class="nt">mathcal</span><span class="p">{</span><span class="err">S</span><span class="p">}</span><span class="nt">_</span><span class="p">{</span><span class="err">L</span><span class="p">}</span><span class="o">,</span><span class="w"> </span><span class="err">\</span><span class="nt">mathcal</span><span class="p">{</span><span class="err">S</span><span class="p">}</span><span class="nt">_</span><span class="p">{</span><span class="err">U</span><span class="p">}</span><span class="err">\</span><span class="o">),</span><span class="w"> </span><span class="nt">and</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="err">\</span><span class="nt">mathcal</span><span class="p">{</span><span class="err">S</span><span class="p">}</span><span class="nt">_</span><span class="p">{</span><span class="err">0</span><span class="p">}</span><span class="w"> </span><span class="o">;</span><span class="err">\</span><span class="o">)</span><span class="w"> </span><span class="nt">penalty</span><span class="w"> </span><span class="nt">parameters</span><span class="o">:</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="err">\</span><span class="nt">lambda_</span><span class="p">{</span><span class="err">1</span><span class="p">}</span><span class="o">,</span><span class="w"> </span><span class="err">\</span><span class="nt">Delta_</span><span class="p">{</span><span class="err">1</span><span class="p">}</span><span class="o">,</span><span class="w"> </span><span class="err">\</span><span class="nt">lambda_</span><span class="p">{</span><span class="err">2</span><span class="p">}</span><span class="o">,</span><span class="w"> </span><span class="err">\</span><span class="nt">Delta_</span><span class="p">{</span><span class="err">2</span><span class="p">}</span><span class="err">\</span><span class="o">),</span><span class="w"> </span><span class="nt">and</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="err">\</span><span class="nt">Lambda_</span><span class="p">{</span><span class="err">2</span><span class="p">}</span><span class="w"> </span><span class="o">;</span><span class="err">\</span><span class="o">)</span><span class="w"> </span><span class="nt">iteration</span>
<span class="w">    </span><span class="nt">number</span><span class="w"> </span><span class="nt">for</span><span class="w"> </span><span class="nt">parameter</span><span class="w"> </span><span class="nt">update</span><span class="o">:</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="nt">t_</span><span class="p">{</span><span class="err">0</span><span class="p">}</span><span class="err">\</span><span class="o">).</span>
<span class="w">    </span><span class="nt">for</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="nt">t</span><span class="o">=</span><span class="nt">1</span><span class="o">,</span><span class="nt">2</span><span class="o">,</span><span class="w"> </span><span class="err">\</span><span class="nt">ldots</span><span class="err">\</span><span class="o">)</span><span class="w"> </span><span class="nt">do</span>
<span class="w">        </span><span class="nt">Run</span><span class="w"> </span><span class="nt">actor-critic</span><span class="w"> </span><span class="nt">algorithm</span><span class="o">,</span><span class="w"> </span><span class="nt">with</span><span class="w"> </span><span class="nt">score</span><span class="w"> </span><span class="nt">adjustment</span><span class="w"> </span><span class="nt">by</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="err">\</span><span class="nt">mathcal</span><span class="p">{</span><span class="err">S</span><span class="p">}</span><span class="w"> </span><span class="err">\</span><span class="nt">leftarrow</span><span class="w"> </span><span class="err">\</span><span class="nt">mathcal</span><span class="p">{</span><span class="err">S</span><span class="p">}</span><span class="nt">_</span><span class="p">{</span><span class="err">0</span><span class="p">}</span><span class="err">\</span><span class="nt">left</span><span class="o">(</span><span class="err">\</span><span class="nt">mathcal</span><span class="p">{</span><span class="err">S</span><span class="p">}</span><span class="nt">-</span><span class="err">\</span><span class="nt">mathcal</span><span class="p">{</span><span class="err">S</span><span class="p">}</span><span class="nt">_</span><span class="p">{</span><span class="err">L</span><span class="p">}</span><span class="err">\</span><span class="nt">right</span><span class="o">)</span><span class="w"> </span><span class="o">/</span><span class="err">\</span><span class="nt">left</span><span class="o">(</span><span class="err">\</span><span class="nt">mathcal</span><span class="p">{</span><span class="err">S</span><span class="p">}</span><span class="nt">_</span><span class="p">{</span><span class="err">U</span><span class="p">}</span><span class="nt">-</span><span class="err">\</span><span class="nt">mathcal</span><span class="p">{</span><span class="err">S</span><span class="p">}</span><span class="nt">_</span><span class="p">{</span><span class="err">L</span><span class="p">}</span><span class="err">\</span><span class="nt">right</span><span class="o">)</span><span class="err">\</span><span class="o">)</span>
<span class="w">        </span><span class="nt">if</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="nt">t</span><span class="err">\</span><span class="nt">left</span><span class="o">(</span><span class="err">\</span><span class="nt">bmod</span><span class="w"> </span><span class="nt">t_</span><span class="p">{</span><span class="err">0</span><span class="p">}</span><span class="err">\</span><span class="nt">right</span><span class="o">)=</span><span class="nt">0</span><span class="err">\</span><span class="o">)</span><span class="w"> </span><span class="nt">then</span>
<span class="w">            </span><span class="nt">if</span><span class="w"> </span><span class="nt">the</span><span class="w"> </span><span class="nt">maximum</span><span class="w"> </span><span class="nt">reward</span><span class="w"> </span><span class="nt">corresponds</span><span class="w"> </span><span class="nt">to</span><span class="w"> </span><span class="nt">a</span><span class="w"> </span><span class="nt">DAG</span><span class="w"> </span><span class="nt">with</span><span class="w"> </span><span class="nt">score</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="err">\</span><span class="nt">mathcal</span><span class="p">{</span><span class="err">S</span><span class="p">}</span><span class="nt">_</span><span class="p">{</span><span class="err">\text</span><span class="w"> </span><span class="err">{min</span><span class="w"> </span><span class="p">}</span><span class="err">}\</span><span class="o">)</span><span class="w"> </span><span class="nt">then</span>
<span class="w">                </span><span class="nt">update</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="err">\</span><span class="nt">mathcal</span><span class="p">{</span><span class="err">S</span><span class="p">}</span><span class="nt">_</span><span class="p">{</span><span class="err">U</span><span class="p">}</span><span class="w"> </span><span class="err">\</span><span class="nt">leftarrow</span><span class="w"> </span><span class="err">\</span><span class="nt">min</span><span class="w"> </span><span class="err">\</span><span class="nt">left</span><span class="o">(</span><span class="err">\</span><span class="nt">mathcal</span><span class="p">{</span><span class="err">S</span><span class="p">}</span><span class="nt">_</span><span class="p">{</span><span class="err">U</span><span class="p">}</span><span class="o">,</span><span class="w"> </span><span class="err">\</span><span class="nt">mathcal</span><span class="p">{</span><span class="err">S</span><span class="p">}</span><span class="nt">_</span><span class="p">{</span><span class="err">\text</span><span class="w"> </span><span class="err">{min</span><span class="w"> </span><span class="p">}</span><span class="err">}\</span><span class="nt">right</span><span class="o">)</span><span class="err">\</span><span class="o">)</span>
<span class="w">            </span><span class="nt">end</span><span class="w"> </span><span class="nt">if</span>
<span class="w">            </span><span class="nt">update</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="err">\</span><span class="nt">lambda_</span><span class="p">{</span><span class="err">1</span><span class="p">}</span><span class="w"> </span><span class="err">\</span><span class="nt">leftarrow</span><span class="w"> </span><span class="err">\</span><span class="nt">min</span><span class="w"> </span><span class="err">\</span><span class="nt">left</span><span class="o">(</span><span class="err">\</span><span class="nt">lambda_</span><span class="p">{</span><span class="err">1</span><span class="p">}</span><span class="o">+</span><span class="err">\</span><span class="nt">Delta_</span><span class="p">{</span><span class="err">1</span><span class="p">}</span><span class="o">,</span><span class="w"> </span><span class="err">\</span><span class="nt">mathcal</span><span class="p">{</span><span class="err">S</span><span class="p">}</span><span class="nt">_</span><span class="p">{</span><span class="err">U</span><span class="p">}</span><span class="err">\</span><span class="nt">right</span><span class="o">)</span><span class="err">\</span><span class="o">)</span><span class="w"> </span><span class="nt">and</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="err">\</span><span class="nt">lambda_</span><span class="p">{</span><span class="err">2</span><span class="p">}</span><span class="w"> </span><span class="err">\</span><span class="nt">leftarrow</span><span class="w"> </span><span class="err">\</span><span class="nt">min</span><span class="w"> </span><span class="err">\</span><span class="nt">left</span><span class="o">(</span><span class="err">\</span><span class="nt">lambda_</span><span class="p">{</span><span class="err">2</span><span class="p">}</span><span class="w"> </span><span class="err">\</span><span class="nt">Delta_</span><span class="p">{</span><span class="err">2</span><span class="p">}</span><span class="o">,</span><span class="w"> </span><span class="err">\</span><span class="nt">Lambda_</span><span class="p">{</span><span class="err">2</span><span class="p">}</span><span class="err">\</span><span class="nt">right</span><span class="o">)</span><span class="err">\</span><span class="o">)</span>
<span class="w">            </span><span class="nt">update</span><span class="w"> </span><span class="nt">recorded</span><span class="w"> </span><span class="nt">rewards</span><span class="w"> </span><span class="nt">according</span><span class="w"> </span><span class="nt">to</span><span class="w"> </span><span class="nt">new</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="err">\</span><span class="nt">lambda_</span><span class="p">{</span><span class="err">1</span><span class="p">}</span><span class="err">\</span><span class="o">)</span><span class="w"> </span><span class="nt">and</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="err">\</span><span class="nt">lambda_</span><span class="p">{</span><span class="err">2</span><span class="p">}</span><span class="err">\</span><span class="o">)</span>
<span class="w">        </span><span class="nt">end</span><span class="w"> </span><span class="nt">if</span>
<span class="w">    </span><span class="nt">end</span><span class="w"> </span><span class="nt">for</span>
</code></pre></div>

<p>different score functions may have different ranges while the acyclicity penalty terms are independent of the particular range of the score function. We hence also adjust the predefined scores to a certain range by using $\mathcal{S}<em L="L">{0}\left(\mathcal{S}-\mathcal{S}</em>}\right) /\left(\mathcal{S<em L="L">{U}-\mathcal{S}</em>}\right)$ for some $\mathcal{S<em 0="0">{0}&gt;0$ and the optimal score will lie in $\left[0, \mathcal{S}</em>}\right] .{ }^{1}$ Our algorithm is summarized in Algorithm 1, where $\Delta_{1}$ and $\Delta_{2}$ are the updating parameters associated with $\lambda_{1}$ and $\lambda_{2}$, respectively, and $t_{0}$ denotes the updating frequency. The weight $\lambda_{2}$ is updated in a similar manner to the updating rule on the Lagrange multiplier used by NOTEARS and we set $\Lambda_{2}$ as an upper bound on $\lambda_{2}$, as previously discussed. In all our experiments that use BIC as score function, $\mathcal{S<em U="U">{L}$ is obtained from a complete directed graph and $\mathcal{S}</em>}$ is from an empty graph. Since $\mathcal{S<em 0="0">{U}$ with the empty graph can be very high for large graphs, we also update it by keeping track of the lowest score achieved by DAGs generated during training. Other parameter choices in this work are $\mathcal{S}</em>=0.01$. We comment that these parameter choices may be further tuned for specific applications, and the inferred causal graph would be the one that is acyclic and achieves the best score, among all the final outputs (cf. Section 5.3) of the RL approach with different parameter choices.}=5$, $t_{0}=1,000, \lambda_{1}=0, \Delta_{1}=1, \lambda_{2}=10^{-\lceil d / 3\rceil}, \Delta_{2}=10$ and $\Lambda_{2</p>
<h1>5.2 Actor-Critic Algorithm</h1>
<p>We believe that the exploitation and exploration scheme in the RL paradigm provides an appropriate way to guide the search. Let $\pi(\cdot \mid \mathbf{s})$ and $\psi$ denote the policy and NN parameters for graph generation, respectively. Our training objective is the expected reward defined as</p>
<p>$$
J(\psi \mid \mathbf{s})=\mathbb{E}<em 1="1">{A \sim \pi(\cdot \mid \mathbf{s})}\left{-[\mathcal{S}(\mathcal{G})+\lambda</em> h(A)]\right}
$$} \mathbf{I}(\mathcal{G} \notin \text { DAGs })+\lambda_{2</p>
<p>During training, the input $\mathbf{s}$ is constructed by randomly drawing samples from the observed dataset $\mathbf{X}$, as described in Section 4.</p>
<p>We resort to policy gradient methods and stochastic methods to optimize the parameters $\psi$. The gradient $\nabla_{\psi} J(\psi \mid \mathbf{s})$ can be obtained by the well-known REINFORCE algorithm (Williams, 1992; Sutton et al., 2000). We draw $B$ samples $\mathbf{s}<em 2="2">{1}, \mathbf{s}</em>}, \ldots, \mathbf{s<em i="i">{B}$ as a batch to estimate the gradient which is then used to train the NNs through stochastic optimization methods like Adam (Kingma and Ba, 2014). Using a parametric baseline to estimate the reward can also help training (Konda and Tsitsiklis, 2000). For the present work, our critic is a simple 2-layer feed-forward NN with ReLU units, with the input being the encoder outputs $\left{e n c</em>$. The critic is trained with Adam on a mean squared error between its predictions and the true rewards. An entropy regularization term (Williams and Peng, 1991; Mnih et al., 2016) is also added to encourage exploration of the RL agent. Although policy gradient methods only guarantee local convergence under proper conditions (Sutton et al., 2000), we remark that the inferred graphs from the actor-critic algorithm are all DAGs in our experiments.}\right}_{i=1}^{t</p>
<p>Training an RL agent typically requires many iterations. In the present work, we find that computing the rewards for generated graphs is much more time-consuming than training NNs. Therefore, we record the computed rewards corresponding to different graph structures. Moreover, the BIC score can be decomposed according to single causal relationships and we also record the corresponding $\mathrm{RSS}_{i}$ to avoid repeated computations.</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<h1>5.3 Final Output</h1>
<p>Since we are concerned with finding a DAG with the best score rather than a policy, we record all the graphs generated during the training process and output the one with the best reward. In practice, the graph may contain spurious edges and further processing is needed.
To this end, we can prune the estimated edges in a greedy way, according to either the regression performance or the score function. For an inferred causal relationship, we remove a parental variable and calculate the performance of the resulting graph, with all other causal relationships unchanged. If the performance does not degrade or degrade within a predefined tolerance, we accept pruning and continue this process with the pruned causal relationship. For linear models, pruning can be simply done by thresholding the estimated coefficients.</p>
<p>Related to the above pruning process is to add to the score function an increased penalty weight on the number of edges of a graph. However, this weight is not easy to choose, as a large weight may incur missing edges. In this work, we stick to the penalty weight $\log m$ that is included in the BIC score and then apply pruning to the inferred graph in order to reduce false discoveries.</p>
<h2>6 EXPERIMENTAL ReSULTS</h2>
<p>We report empirical results on synthetic and real datasets to compare our approach against both traditional and recent gradient based approaches, including GES (with BIC score) (Chickering, 2002; Ramsey et al., 2017), the PC algorithm (with Fisher-z test and $p$-value 0.01 ) (Spirtes et al., 2000), ICA-LiNGAM (Shimizu et al., 2006), the Causal Additive Model (CAM) based algorithm proposed by Bühlmann et al. (2014), NOTEARS (Zheng et al., 2018), DAG-GNN (Yu et al., 2019), and GraNDAG (Lachapelle et al., 2019), among others. All these algorithms have available implementations and we give a brief description on these algorithms and their implementations in Appendix D. Default hyper-parameters of these implementations are used unless otherwise stated. For pruning, we use the same thresholding method for ICA-LiNGAM, NOTEARS, and DAG-GNN. Since the authors of CAM and GraN-DAG propose to apply significance testing of covariates based on generalized additive models and then declare significance if the reported $p$-values are lower than or equal to 0.001 , we stick to the same pruning method for CAM and GraN-DAG.</p>
<p>The proposed RL based approach is implemented based on an existing Tensorflow (Abadi et al., 2016) implementation of neural combinatorial optimizer (see Appendix D for more details). The decoder is modified as described in Section 4 and the RL algorithm related hyper-parameters are left unchanged. We pick $B=64$ as batch size at each iteration and $d_{h}=16$ as the hidden dimension with the single layer decoder. Our approach is combined with the BIC scores under Gaussianity assumption given in Eqs. (2) and (3), and are denoted as RL-BIC and RL-BIC2, respectively.</p>
<p>We evaluate the estimated graphs using three metrics: False Discovery Rate (FDR), True Positive Rate (TPR), and Structural Hamming Distance (SHD) which is the smallest number of edge additions, deletions, and reversals to convert the estimated graph into the true DAG. The SHD takes into account both false positives and false negatives and a lower SHD indicates a better estimate of the causal graph. Since GES and PC may output unoriented edges, we follow Zheng et al. (2018) to treat GES and PC favorably by regarding undirected edges as true positives as long as the true graph has a directed edge in place of the undirected edge.</p>
<h3>6.1 Linear Model with Gaussian and Non-Gaussian Noise</h3>
<p>Given number of variables $d$, we generate a $d \times d$ upper triangular matrix as the graph binary adjacency matrix, in which the upper entries are sampled independently from $\operatorname{Bern}(0.5)$. We assign edge weights independently from Unif $([-2,-0.5] \cup[0.5,2])$ to obtain a weight matrix $W \in \mathbb{R}^{d \times d}$, and then sample $\mathbf{x}=W^{T} \mathbf{x}+\mathbf{n} \in \mathbb{R}^{d}$ from both Gaussian and non-Gaussian noise models. The non-Gaussian noise is the same as the one used for ICA-LiNGAM (Shimizu et al., 2006), which generates samples from a Gaussian distribution and passes them through a power nonlinearity to make them non-Gaussian. We pick unit noise variances in both models and generate $m=5,000$ samples as our datasets. A random permutation of variables is then performed. This data generating procedure is similar to that used by NOTEARS and DAG-GNN and the true causal graphs in both cases are known to be identifiable (Shimizu et al., 2006; Peters and Bühlmann, 2013).</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: Learning process of the proposed method RL-BIC2 on a linear-Gaussian dataset.</p>
<p>Table 1: Empirical results on LiNGAM and linear-Gaussian data models with 12-node graphs.</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">RL-BIC</th>
<th style="text-align: center;">RL-BIC2</th>
<th style="text-align: center;">PC</th>
<th style="text-align: center;">GES</th>
<th style="text-align: center;">ICA-LiNGAM</th>
<th style="text-align: center;">CAM</th>
<th style="text-align: center;">NOTEARS</th>
<th style="text-align: center;">DAG-GNN</th>
<th style="text-align: center;">GraN-DAG</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">FDR</td>
<td style="text-align: center;">$0.28 \pm 0.11$</td>
<td style="text-align: center;">$0 \pm 0$</td>
<td style="text-align: center;">$0.06 \pm 0.04$</td>
<td style="text-align: center;">$0.62 \pm 0.06$</td>
<td style="text-align: center;">$0 \pm 0$</td>
<td style="text-align: center;">$0.67 \pm 0.08$</td>
<td style="text-align: center;">$0.04 \pm 0.03$</td>
<td style="text-align: center;">$0.11 \pm 0.03$</td>
<td style="text-align: center;">$0.63 \pm 0.10$</td>
</tr>
<tr>
<td style="text-align: center;">LiNGAM</td>
<td style="text-align: center;">TPR</td>
<td style="text-align: center;">$0.71 \pm 0.17$</td>
<td style="text-align: center;">$1 \pm 0$</td>
<td style="text-align: center;">$0.25 \pm 0.03$</td>
<td style="text-align: center;">$0.25 \pm 0.04$</td>
<td style="text-align: center;">$1 \pm 0$</td>
<td style="text-align: center;">$0.49 \pm 0.07$</td>
<td style="text-align: center;">$0.95 \pm 0.05$</td>
<td style="text-align: center;">$0.94 \pm 0.04$</td>
<td style="text-align: center;">$0.37 \pm 0.15$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">SHD</td>
<td style="text-align: center;">$17.4 \pm 7.50$</td>
<td style="text-align: center;">$0 \pm 0$</td>
<td style="text-align: center;">$31.8 \pm 2.04$</td>
<td style="text-align: center;">$32.8 \pm 2.93$</td>
<td style="text-align: center;">$0 \pm 0$</td>
<td style="text-align: center;">$40.4 \pm 5.92$</td>
<td style="text-align: center;">$2.4 \pm 2.42$</td>
<td style="text-align: center;">$5.00 \pm 1.41$</td>
<td style="text-align: center;">$36.0 \pm 5.33$</td>
</tr>
<tr>
<td style="text-align: center;">Linear- <br> Gaussian</td>
<td style="text-align: center;">FDR</td>
<td style="text-align: center;">$0.38 \pm 0.13$</td>
<td style="text-align: center;">$0 \pm 0$</td>
<td style="text-align: center;">$0.52 \pm 0.07$</td>
<td style="text-align: center;">$0.63 \pm 0.06$</td>
<td style="text-align: center;">$0.65 \pm 0.02$</td>
<td style="text-align: center;">$0.70 \pm 0.08$</td>
<td style="text-align: center;">$0.02 \pm 0.02$</td>
<td style="text-align: center;">$0.10 \pm 0.05$</td>
<td style="text-align: center;">$0.70 \pm 0.17$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">TPR</td>
<td style="text-align: center;">$0.66 \pm 0.12$</td>
<td style="text-align: center;">$1 \pm 0$</td>
<td style="text-align: center;">$0.31 \pm 0.03$</td>
<td style="text-align: center;">$0.24 \pm 0.04$</td>
<td style="text-align: center;">$0.73 \pm 0.05$</td>
<td style="text-align: center;">$0.44 \pm 0.11$</td>
<td style="text-align: center;">$0.98 \pm 0.02$</td>
<td style="text-align: center;">$0.95 \pm 0.05$</td>
<td style="text-align: center;">$0.27 \pm 0.13$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">SHD</td>
<td style="text-align: center;">$22.2 \pm 6.34$</td>
<td style="text-align: center;">$0 \pm 0$</td>
<td style="text-align: center;">$29.6 \pm 3.01$</td>
<td style="text-align: center;">$33.2 \pm 2.48$</td>
<td style="text-align: center;">$46.2 \pm 2.79$</td>
<td style="text-align: center;">$40.8 \pm 4.53$</td>
<td style="text-align: center;">$1.0 \pm 0.89$</td>
<td style="text-align: center;">$4.40 \pm 2.06$</td>
<td style="text-align: center;">$38.2 \pm 6.68$</td>
</tr>
</tbody>
</table>
<p>We first consider graphs with $d=12$ nodes. We use $n=64$ for constructing the input sample and set the maximum number of iterations to 20,000 . We use a threshold 0.3 , same as NOTEARS and DAG-GNN with this data model, to prune the estimated edges. Figure 2 shows the learning process of the proposed method RL-BIC2 on a linear-Gaussian dataset. In this example, RL-BIC2 generates 683, 784 different graphs during training, much lower than the total number (around $5.22 \times 10^{26}$ ) of DAGs. The pruned DAG turns out to be exactly the same as the underlying causal graph.
We report the empirical results on LiNGAM and linear-Gaussian data models in Table 1. Both PC and GES perform poorly, possibly because we consider relatively dense graphs for our data generating procedure. CAM does not perform well either, as it assumes nonlinear causal relationships. ICA-LiNGAM recovers all the true causal graphs for LiNGAM data but performs poorly on linearGaussian data. This is not surprising because ICA-LiNGAM works for non-Gaussian noise and does not provide guarantee for linear-Gaussian datasets. Both NOTEARS and DAG-GNN have good causal discovery results whereas GraN-DAG performs much worse. We believe that it is because GraN-DAG uses 2-layer feed-forward NNs to model the causal relationships, which may not be able to learn a good linear relationship in this experiment. Modifying the feed-forward NNs to linear functions reduces to NOTEARS with negative log-likelihood as loss function, which yields similar performance on these datasets (see Appendix E. 1 for detailed results). As to our proposed methods, we observe that RL-BIC2 recovers all the true causal graphs on both data models in this experiment while RL-BIC has a worse performance. One may wonder whether this observation is due to the same noise variances that are used in our data models; we conduct additional experiments where the noise variances are randomly sampled and RL-BIC2 still outperforms RL-BIC by a large margin (see also Appendix E.1). Nevertheless, with the same BIC score, RL-BIC performs much better than GES on both datasets, indicating that the RL approach brings in a greatly improved search ability.
Finally, we test the proposed method on larger graphs with $d=30$ nodes, where the upper entries are sampled independently from $\operatorname{Bern}(0.2)$. This edge probability choice corresponds to the fact that large graphs usually have low edge degrees in practice; see, e.g., the experiment settings of Zheng et al. (2018); Yu et al. (2019); Lachapelle et al. (2019). To incorporate this prior information in our approach, we add to each $g_{i j}$ a common bias term initialized to -10 (see Appendix E. 1 for details). Considering the much increased search space, we also choose a larger number of observed samples, $n=128$, to construct the input for graph generator and increase the training iterations to 40,000 . On LiNGAM datasets, RL-BIC2 has FDR, TPR, and SHD being $0.14 \pm 0.15,0.94 \pm 0.07$, and $19.8 \pm 23.0$, respectively, comparable to NOTEARS with $0.13 \pm 0.09,0.94 \pm 0.04$, and $17.2 \pm 13.12$.</p>
<h1>6.2 Nonlinear Model with Quadratic Functions</h1>
<p>We now consider nonlinear causal relationships with quadratic functions. We generate an upper triangular matrix in a similar way to the first experiment. For a causal relationship with parents $\mathbf{x}<em i__1="i_{1">{\mathrm{pa}(i)}=\left[x</em>$ to contain both first- and second-order features. The coefficient for each term is then either 0 or sampled from Unif $([-1,-0.5] \cup[0.5,1])$, with equal probability. If a parent variable does not appear in any feature term with a non-zero coefficient, then we remove the corresponding edge in the causal graph. The rest follows the same as in first experiment and here we use the non-Gaussian noise model with 10-node graphs and 5,000 samples. The true causal graph is identifiable according to Peters et al. (2014). For this quadratic model, there may exist very large variable values which cause computation issues for quadratic regression. We treat these samples as outliers and detailed processing is given in Appendix E.2.}}, x_{i_{2}}, \ldots\right]^{T}$ at the $i$-th node, we expand $\mathbf{x}_{\mathrm{pa}(i)</p>
<p>We use quadratic regression for a given causal relationship and calculate the BIC score (assuming equal noise variances) in Eq. (3). For pruning, we simply apply thresholding, with threshold as 0.3 , to the estimated coefficients of both first- and second-order terms. If the coefficient of a second-order term, e.g., $x_{i_{1}} x_{i_{2}}$, is non-zero after thresholding, then we have two directed edges that are from $x_{i_{1}}$ to $x_{i}$ and from $x_{i_{2}}$ to $x_{i}$, respectively. We do not consider PC and GES in this experiment due to their poor performance in the first experiment. Our results with 10-node graphs are reported in Table 2, which shows that RL-BIC2 achieves the best performance.</p>
<p>Table 2: Empirical results on nonlinear models with quadratic functions.</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: center;">RL-BIC2</th>
<th style="text-align: center;">NOTEARS</th>
<th style="text-align: center;">NOTEARS-2</th>
<th style="text-align: center;">NOTEARS-3</th>
<th style="text-align: center;">ICA-LiNGAM</th>
<th style="text-align: center;">CAM</th>
<th style="text-align: center;">DAG-GNN</th>
<th style="text-align: center;">GraN-DAG</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">FDR</td>
<td style="text-align: center;">$0.02 \pm 0.04$</td>
<td style="text-align: center;">$0.35 \pm 0.06$</td>
<td style="text-align: center;">$0.15 \pm 0.10$</td>
<td style="text-align: center;">$0 \pm 0$</td>
<td style="text-align: center;">$0.47 \pm 0.06$</td>
<td style="text-align: center;">$0.32 \pm 0.17$</td>
<td style="text-align: center;">$0.39 \pm 0.04$</td>
<td style="text-align: center;">$0.40 \pm 0.17$</td>
</tr>
<tr>
<td style="text-align: left;">TPR</td>
<td style="text-align: center;">$0.98 \pm 0.04$</td>
<td style="text-align: center;">$0.71 \pm 0.16$</td>
<td style="text-align: center;">$0.70 \pm 0.15$</td>
<td style="text-align: center;">$0.79 \pm 0.20$</td>
<td style="text-align: center;">$0.76 \pm 0.09$</td>
<td style="text-align: center;">$0.78 \pm 0.05$</td>
<td style="text-align: center;">$0.55 \pm 0.14$</td>
<td style="text-align: center;">$0.73 \pm 0.16$</td>
</tr>
<tr>
<td style="text-align: left;">SHD</td>
<td style="text-align: center;">$0.6 \pm 1.20$</td>
<td style="text-align: center;">$14.8 \pm 3.37$</td>
<td style="text-align: center;">$8.8 \pm 3.82$</td>
<td style="text-align: center;">$5.2 \pm 5.19$</td>
<td style="text-align: center;">$20.4 \pm 5.00$</td>
<td style="text-align: center;">$14.1 \pm 5.12$</td>
<td style="text-align: center;">$18.0 \pm 2.45$</td>
<td style="text-align: center;">$39.6 \pm 5.85$</td>
</tr>
</tbody>
</table>
<p>For fair comparison, we apply the same quadratic regression based pruning method to the outputs of NOTEARS, denoted as NOTEARS-2. We see that this pruning further reduces FDR, i.e., removes spurious edges, with little effect on TPR. Since pruning does not help discover additional positive edges or increase TPR, we will not apply this pruning method to other methods as their TPRs are much lower than that of RL-BIC2. Finally, with prior knowledge that the function form is quadratic, we can modify NOTEARS to apply quadratic functions to modeling the causal relationships, with an equivalent weighted adjacency matrix constructed using the coefficients of the first- and second-order terms, similar to the idea used by GraN-DAG (detailed derivations are given in Appendix E.2). The problem then becomes a nonconvex optimization problem with $(d-1) d^{2} / 2$ parameters (which are the coefficients of both first- and second-order features), compared to the original NOTEARS with $d^{2}$ parameters. This method corresponds to NOTEARS-3 in Table 2. Despite the fact that NOTEARS-3 did not achieve a better overall performance than RL-BIC2, we comment that it discovered almost correct causal graphs (with SHD $\leq 2$ ) on more than half of the datasets, but performed poorly on the rest datasets. We believe that it is due to the increased number of optimization parameters and the more complicated equivalent adjacency matrix which make the optimization problem harder to solve. Meanwhile, we do not exclude that NOTEARS-3 can achieve a better causal discovery performance with other optimization algorithms.</p>
<h3>6.3 Nonlinear Model with Gaussian Processes</h3>
<p>Given a randomly generated causal graph, we consider another nonlinear model where each causal relationship $f_{i}$ is a function sampled from a Gaussian process with RBF kernel of bandwidth one. The additive noise $n_{i}$ is normally distributed with variance sampled uniformly. This setting is known to be identifiable according to Peters et al. (2014). We use a setup that is also considered by GraN-DAG (Lachapelle et al., 2019): 10-node and 40-edge graphs with 1,000 generated samples.</p>
<p>The empirical results are reported in Table 3. One can see that ICA-LiNGAM, NOTEARS, and DAG-GNN perform poorly on this data model. A possible reason is that they may not be able to model this type of causal relationship. More importantly, these methods operate on a notion of weighted adjacency matrix, which is not obvious here. For our method, we apply Gaussian Process Regression (GPR) with RBF kernel to model the causal relationships. Notice that even though the observed data are from a function sampled from Gaussian process, it is not guaranteed that GPR</p>
<p>with the same kernel can achieve a good performance. Indeed, using a fixed kernel bandwidth would lead to severe overfitting that incurs many spurious edges and the graph with the highest reward is usually not a DAG. To proceed, we normalize the observed data and apply median heuristics for kernel bandwidth. Both our methods perform reasonably well, with RL-BIC outperforming all the other methods.</p>
<p>Table 3: Empirical results on nonlinear models with Gaussian processes.</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: center;">RL-BIC</th>
<th style="text-align: center;">RL-BIC2</th>
<th style="text-align: center;">ICA-LiNGAM</th>
<th style="text-align: center;">NOTEARS</th>
<th style="text-align: center;">DAG-GNN</th>
<th style="text-align: center;">GraN-DAG</th>
<th style="text-align: center;">CAM</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">FDR</td>
<td style="text-align: center;">$0.14 \pm 0.03$</td>
<td style="text-align: center;">$0.17 \pm 0.12$</td>
<td style="text-align: center;">$0.48 \pm 0.04$</td>
<td style="text-align: center;">$0.48 \pm 0.19$</td>
<td style="text-align: center;">$0.36 \pm 0.11$</td>
<td style="text-align: center;">$0.12 \pm 0.08$</td>
<td style="text-align: center;">$0.15 \pm 0.07$</td>
</tr>
<tr>
<td style="text-align: left;">TPR</td>
<td style="text-align: center;">$0.96 \pm 0.03$</td>
<td style="text-align: center;">$0.80 \pm 0.09$</td>
<td style="text-align: center;">$0.63 \pm 0.07$</td>
<td style="text-align: center;">$0.18 \pm 0.09$</td>
<td style="text-align: center;">$0.07 \pm 0.03$</td>
<td style="text-align: center;">$0.81 \pm 0.05$</td>
<td style="text-align: center;">$0.82 \pm 0.04$</td>
</tr>
<tr>
<td style="text-align: left;">SHD</td>
<td style="text-align: center;">$6.2 \pm 1.33$</td>
<td style="text-align: center;">$12.0 \pm 5.18$</td>
<td style="text-align: center;">$30.4 \pm 2.50$</td>
<td style="text-align: center;">$33.8 \pm 2.56$</td>
<td style="text-align: center;">$34.6 \pm 1.36$</td>
<td style="text-align: center;">$10.2 \pm 2.39$</td>
<td style="text-align: center;">$10.2 \pm 2.93$</td>
</tr>
</tbody>
</table>
<h1>6.4 Real Data</h1>
<p>We consider a real dataset to discover a protein signaling network based on expression levels of proteins and phospholipids (Sachs et al., 2005). This dataset is a common benchmark in graphical models, with experimental annotations well accepted by the biological community. Both observational and interventional data are contained in this dataset. Since we are interested in using observational data to infer causal mechanisms, we only consider the observational data with $m=853$ samples. The ground truth causal graph given by Sachs et al. (2005) has 11 nodes and 17 edges.
Notice that the true graph is indeed sparse and an empty graph can have an SHD as low as 17. Therefore, we report more detailed results regarding the estimated graph: number of total edges, number of correct edges, and the SHD. Both PC and GES output too many unoriented edges, and we will not report their results here. We apply GPR with RBF kernel to modeling the causal relationships, with the same data normalization and median heuristics for kernel bandwidth as in Section 6.3. We also use CAM pruning on the inferred graph from the training process. The empirical results are given in Table 4. Both RL-BIC and RL-BIC2 achieve promising results, compared with other methods.</p>
<p>Table 4: Empirical results on Sachs dataset.</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;">RL-BIC</th>
<th style="text-align: center;">RL-BIC2</th>
<th style="text-align: center;">ICA-LiNGAM</th>
<th style="text-align: center;">CAM</th>
<th style="text-align: center;">NOTEARS</th>
<th style="text-align: center;">DAG-GNN</th>
<th style="text-align: center;">GraN-DAG</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Total Edges</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">20</td>
<td style="text-align: center;">15</td>
<td style="text-align: center;">10</td>
</tr>
<tr>
<td style="text-align: center;">Correct Edges</td>
<td style="text-align: center;">6</td>
<td style="text-align: center;">7</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">6</td>
<td style="text-align: center;">6</td>
<td style="text-align: center;">6</td>
<td style="text-align: center;">5</td>
</tr>
<tr>
<td style="text-align: center;">SHD</td>
<td style="text-align: center;">12</td>
<td style="text-align: center;">11</td>
<td style="text-align: center;">14</td>
<td style="text-align: center;">12</td>
<td style="text-align: center;">19</td>
<td style="text-align: center;">16</td>
<td style="text-align: center;">13</td>
</tr>
</tbody>
</table>
<h2>7 Concluding Remarks and Future Works</h2>
<p>We have proposed to use RL to search for the DAG with the optimal score. Our reward is designed to incorporate a predefined score function and two penalty terms to enforce acyclicity. We use the actor-critic algorithm as our RL algorithm, where the actor is constructed based on recently developed encoder-decoder models. Experiments are conducted on both synthetic and real datasets to show the advantages of our method over other causal discovery methods.</p>
<p>We have also shown the effectiveness of the proposed method with 30-node graphs, yet dealing with large graphs (with more than 50 nodes) is still challenging. Nevertheless, many real applications, like Sachs dataset (Sachs et al., 2005), have a relatively small number of variables. Furthermore, it is possible to decompose large causal discovery problems into smaller ones; see, e.g., Ma et al. (2008). Prior knowledge or constraint-based methods is also applicable to reduce the search space.</p>
<p>There are several future directions from the present work. In our current implementation, computing scores is much more time consuming than training NNs. We believe that developing a more efficient and effective score function will further improve the proposed approach. Other powerful RL algorithms may also be used. For example, the asynchronous advantage actor-critic algorithm has been shown to be effective in many applications (Mnih et al., 2016; Zoph and Le, 2017). In addition, we observe that the total iteration numbers used in our experiments are usually more than needed (see, e.g., Figure 2(b)). A proper early stopping criterion will be favored.</p>
<h1>ACKNOWLEDGMENTS</h1>
<p>The authors are grateful to the anonymous reviewers for valuable comments and suggestions. The authors would also like to thank Prof. Jiji Zhang from Lingnan University, Dr. Yue Liu from Huawei Noah's Ark Lab, and Zhuangyan Fang from Peking University for many helpful discussions.</p>
<h2>REFERENCES</h2>
<p>M. Abadi, P. Barham, J. Chen, Z. Chen, A. Davis, J. Dean, M. Devin, S. Ghemawat, G. Irving, M. Isard, et al. Tensorflow: A system for large-scale machine learning. In 12th USENIX Symposium on Operating Systems Design and Implementation (OSDI), 2016.
I. Bello, H. Pham, Q. V. Le, M. Norouzi, and S. Bengio. Neural combinatorial optimization with reinforcement learning. arXiv preprint arXiv:1611.09940, 2016.
K. A. Bollen. Structural Equations with Latent Variables. Wiley, 1989.
P. Bühlmann, J. Peters, J. Ernest, et al. CAM: Causal additive models, high-dimensional order search and penalized regression. The Annals of Statistics, 42(6):2526-2556, 2014.
Y. Chen, M. W. Hoffman, S. G. Colmenarejo, M. Denil, T. P. Lillicrap, M. Botvinick, and N. de Freitas. Learning to learn without gradient descent by gradient descent. In International Conference on Machine Learning, 2017.
D. M. Chickering. Learning Bayesian networks is NP-complete. In Learning from Data, pages 121-130. Springer, 1996.
D. M. Chickering. Optimal structure identification with greedy search. Journal of Machine Learning Research, 3(Nov):507-554, 2002.
D. M. Chickering, D. Heckerman, and C. Meek. Large-sample learning of Bayesian networks is NP-hard. Journal of Machine Learning Research, 5(Oct):1287-1330, 2004.
H. Dai, E. Khalil, Y. Zhang, B. Dilkina, and L. Song. Learning combinatorial optimization algorithms over graphs. In Advances in Neural Information Processing Systems, 2017.
D. Geiger and D. Heckerman. Learning Gaussian networks. In Conference on Uncertainty in Artificial Intelligence, 1994.
O. Goudet, D. Kalainathan, P. Caillou, I. Guyon, D. Lopez-Paz, and M. Sebag. Learning functional causal models with generative neural networks. In Explainable and Interpretable Models in Computer Vision and Machine Learning, pages 39-80. Springer, 2018.
S. W. Han, G. Chen, M.-S. Cheon, and H. Zhong. Estimation of directed acyclic graphs through twostage adaptive LASSO for gene network inference. Journal of the American Statistical Association, 111(515):1004-1019, 2016.
D. M. Haughton et al. On the choice of a model to fit data from an exponential family. The Annals of Statistics, 16(1):342-355, 1988.
P. O. Hoyer, D. Janzing, J. M. Mooij, J. Peters, and B. Schölkopf. Nonlinear causal discovery with additive noise models. In Advances in Neural Information Processing Systems 21, 2009.
B. Huang, K. Zhang, Y. Lin, B. Schölkopf, and C. Glymour. Generalized score functions for causal discovery. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \&amp; Data Mining, 2018.
A. Hyttinen, F. Eberhardt, and M. Järvisalo. Constraint-based causal discovery: Conflict resolution with answer set programming. In Conference on Uncertainty in Artificial Intelligence, 2014.
D. Kalainathan, O. Goudet, I. Guyon, D. Lopez-Paz, and M. Sebag. Structural agnostic modeling: Adversarial learning of causal graphs. arXiv preprint arXiv:1803.04929, 2018.
D. P. Kingma and J. Ba. Adam: A method for stochastic optimization. ICLR, 2014.</p>
<p>V. R. Konda and J. N. Tsitsiklis. Actor-critic algorithms. In Advances in Neural Information Processing Systems, 2000.
S. Lachapelle, P. Brouillard, T. Deleu, and S. Lacoste-Julien. Gradient-based neural DAG learning. arXiv preprint arXiv:1906.02226, 2019.
Z. Ma, X. Xie, and Z. Geng. Structural learning of chain graphs via decomposition. Journal of Machine Learning Research, 9(Dec):2847-2880, 2008.
V. Mnih, A. P. Badia, M. Mirza, A. Graves, T. Lillicrap, T. Harley, D. Silver, and K. Kavukcuoglu. Asynchronous methods for deep reinforcement learning. In ICML, 2016.
P. Nandy, A. Hauser, M. H. Maathuis, et al. High-dimensional consistency in score-based and hybrid structure learning. The Annals of Statistics, 46(6A):3151-3183, 2018.
R. Opgen-Rhein and K. Strimmer. From correlation to causation networks: a simple approximate learning algorithm and its application to high-dimensional plant gene expression data. BMC Systems Biology, 1(1):37, 2007.
J. Pearl. Causality. Cambridge University Press, 2009.
J. Peters and P. Bühlmann. Identifiability of gaussian structural equation models with equal error variances. Biometrika, 101(1):219-228, 2013.
J. Peters, J. M. Mooij, D. Janzing, and B. Schölkopf. Causal discovery with continuous additive noise models. The Journal of Machine Learning Research, 15(1):2009-2053, 2014.
J. Peters, D. Janzing, and B. Schölkopf. Elements of Causal Inference - Foundations and Learning Algorithms. The MIT Press, Cambridge, MA, 2017.
J. Ramsey, M. Glymour, R. Sanchez-Romero, and C. Glymour. A million variables and more: the fast greedy equivalence search algorithm for learning high-dimensional graphical causal models, with an application to functional magnetic resonance images. International Journal of Data Science and Analytics, 3(2):121-129, 2017.
K. Sachs, O. Perez, D. Pe'er, D. A. Lauffenburger, and G. P. Nolan. Causal protein-signaling networks derived from multiparameter single-cell data. Science, 308(5721):523-529, 2005.
G. Schwarz. Estimating the dimension of a model. The Annals of Statistics, 6(2):461-464, 1978.
S. Shimizu, P. O. Hoyer, A. Hyvärinen, and A. Kerminen. A linear non-Gaussian acyclic model for causal discovery. Journal of Machine Learning Research, 7(Oct):2003-2030, 2006.
S. Shimizu, T. Inazumi, Y. Sogawa, A. Hyvärinen, Y. Kawahara, T. Washio, P. O. Hoyer, and K. Bollen. Directlingam: A direct method for learning a linear non-Gaussian structural equation model. Journal of Machine Learning Research, 12(Apr):1225-1248, 2011.
D. Silver, J. Schrittwieser, K. Simonyan, I. Antonoglou, A. Huang, A. Guez, T. Hubert, L. Baker, M. Lai, A. Bolton, et al. Mastering the game of go without human knowledge. Nature, 550(7676): 354, 2017.
R. Socher, D. Chen, C. D. Manning, and A. Ng. Reasoning with neural tensor networks for knowledge base completion. In Advances in Neural Information Processing Systems, pages 926-934, 2013.
P. Spirtes, C. Glymour, and R. Scheines. Causation, Prediction, and Search. MIT press, Cambridge, MA, USA, 2nd edition, 2000.
X. Sun, D. Janzing, B. Schölkopf, and K. Fukumizu. A kernel-based causal learning algorithm. In International Conference on Machine Learning, 2007.
I. Sutskever, O. Vinyals, and Q. V. Le. Sequence to sequence learning with neural networks. In Advances in Neural Information Processing Systems, 2014.</p>
<p>R. S. Sutton, D. A. McAllester, S. P. Singh, and Y. Mansour. Policy gradient methods for reinforcement learning with function approximation. In Advances in Neural Information Processing Systems, 2000.
I. Tsamardinos, L. E. Brown, and C. F. Aliferis. The max-min hill-climbing Bayesian network structure learning algorithm. Machine learning, 65(1):31-78, 2006.
A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, Ł. Kaiser, and I. Polosukhin. Attention is all you need. In Advances in Neural Information Processing Systems, 2017.
P. Veličković, G. Cucurull, A. Casanova, A. Romero, P. Liò, and Y. Bengio. Graph attention networks. International Conference on Learning Representations, 2018.
O. Vinyals, M. Fortunato, and N. Jaitly. Pointer networks. In Advances in Neural Information Processing Systems, 2015.
R. J. Williams. Simple statistical gradient-following algorithms for connectionist reinforcement learning. Machine Learning, 8(3-4):229-256, 1992.
R. J. Williams and J. Peng. Function optimization using connectionist reinforcement learning algorithms. Connection Science, 3(3):241-268, 1991.
Y. Yu, J. Chen, T. Gao, and M. Yu. DAG-GNN: DAG structure learning with graph neural networks. In ICML, 2019.
K. Zhang and A. Hyvärinen. On the identifiability of the post-nonlinear causal model. In Conference on Uncertainty in Artificial Intelligence, 2009.
K. Zhang, J. Peters, D. Janzing, and B. Schölkopf. Kernel-based conditional independence test and application in causal discovery. In Conference on Uncertainty in Artificial Intelligence, 2012.
X. Zheng, B. Aragam, P. Ravikumar, and E. P. Xing. DAGs with NO TEARS: Continuous optimization for structure learning. In Advances in Neural Information Processing Systems, 2018.
B. Zoph and Q. V. Le. Neural architecture search with reinforcement learning. In ICLR, 2017.</p>
<h1>APPENDIX</h1>
<h2>A MORE DETAILS ABOUT DECOdERS</h2>
<p>We briefly describe the NN based decoders for generating binary adjacency matrices:</p>
<ul>
<li>Single layer decoder:</li>
</ul>
<p>$$
g_{i j}\left(W_{1}, W_{2}, u\right)=u^{T} \tanh \left(W_{1} e n c_{i}+W_{2} e n c_{j}\right)
$$</p>
<p>where $W_{1}, W_{2} \in \mathbb{R}^{d_{h} \times d_{e}}, u \in \mathbb{R}^{d_{h} \times 1}$ are trainable parameters and $d_{h}$ denotes the hidden dimension associated with the decoder.</p>
<ul>
<li>Bilinear decoder:</li>
</ul>
<p>$$
g_{i j}(W)=e n c_{i}^{T} W e n c_{j}
$$</p>
<p>where $W \in \mathbb{R}^{d_{e} \times d_{e}}$ is a trainable parameter.</p>
<ul>
<li>Neural Tensor Network (NTN) decoder (Socher et al., 2013):</li>
</ul>
<p>$$
g_{i j}\left(W^{[1: K]}, V, b\right)=u^{T} \tanh \left(\operatorname{enc}<em j="j">{i}^{T} W^{[1: K]} e n c</em>+b\right)
$$}+V\left[e n c_{i}^{T}, e n c_{j}^{T}\right]^{T</p>
<p>where $W^{[1: k]} \in \mathbb{R}^{d_{e} \times d_{e} \times K}$ is a tensor and the bilinear tensor product $\operatorname{enc}<em j="j">{i}^{T} W^{[1: K]} e n c</em>$.}$ results in a vector with each entry being $e n c_{i}^{T} W^{[k]} e n c_{j}$ for $k=1,2, \ldots, K, V \in \mathbb{R}^{K \times 2 d_{e}}$, $u \in \mathbb{R}^{K \times 1}$, and $b \in \mathbb{R}^{K \times 1</p>
<ul>
<li>Transformer decoder uses the multi-head attention module to obtain the decoder outputs $\left{d e c_{i}\right}$, followed by a feed-forward NN whose weights are shared across all $d e c_{i}$ (Vaswani et al., 2017). The output consists of $d$ vectors in $\mathbb{R}^{d}$ which are treated as the row vectors of a $d \times d$ matrix. We then pass each element of this matrix into sigmoid functions and sample a binary adjacency matrix accordingly.</li>
</ul>
<p>Table 5 provides the empirical results on linear-Gaussian data models with 12-node graphs and unit variances (see Section 6.1 for more details on this data generating procedure). In our implementation, we pick $d_{e}=64$ as the dimension of the encoder output, $d_{h}=16$ for the single layer decoder, and $K=2$ for the NTN decoder. We find that single layer decoder performs the best, possibly because it has less parameters and is easier to train to find better DAGs, while the Transformer encoder has provided sufficient interactions amongst variables.</p>
<p>Table 5: Empirical results of different decoders on linear-Gaussian data models with 12-node graphs.</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Single layer</th>
<th style="text-align: center;">Bilinear</th>
<th style="text-align: center;">NTN</th>
<th style="text-align: center;">Transformer</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Linear- <br> Gaussian</td>
<td style="text-align: center;">FDR</td>
<td style="text-align: center;">$0 \pm 0$</td>
<td style="text-align: center;">$0.07 \pm 0.13$</td>
<td style="text-align: center;">$0.12 \pm 0.14$</td>
<td style="text-align: center;">$0.67 \pm 0.07$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">TPR</td>
<td style="text-align: center;">$1 \pm 0$</td>
<td style="text-align: center;">$0.95 \pm 0.08$</td>
<td style="text-align: center;">$0.90 \pm 0.11$</td>
<td style="text-align: center;">$0.32 \pm 0.09$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">SHD</td>
<td style="text-align: center;">$0 \pm 0$</td>
<td style="text-align: center;">$4.0 \pm 7.04$</td>
<td style="text-align: center;">$7.4 \pm 8.52$</td>
<td style="text-align: center;">$38.2 \pm 3.12$</td>
</tr>
</tbody>
</table>
<h2>B Equivalence of Problems (1) and (6)</h2>
<p>Proof of Proposition 1. Let $\mathcal{G}$ be a solution to Problem (1). Then we have $\mathcal{S}^{*}=\mathcal{S}(\mathcal{G})$ and $\mathcal{G}$ must be a DAG due to the hard acyclicity constraint. Assume that $\mathcal{G}$ is not a solution to Problem (6), which indicates that there exists a directed graph $\mathcal{G}^{\prime}$ (with binary adjacency matrix $A^{\prime}$ ) so that</p>
<p>$$
\mathcal{S}^{*}&gt;\mathcal{S}\left(\mathcal{G}^{\prime}\right)+\lambda_{1} \mathbf{I}\left(\mathcal{G}^{\prime} \notin \mathrm{DAGs}\right)+\lambda_{2} h\left(A^{\prime}\right)
$$</p>
<p>Clearly, $\mathcal{G}^{\prime}$ cannot be a DAG, for otherwise we would have a DAG that achieves a lower score than the minimum $\mathcal{S}^{*}$. By our assumption, it follows that</p>
<p>$$
\text { r.h.s. of Eq. (8) } \geq \mathcal{S}<em 1="1">{L}+\lambda</em>
$$}+\lambda_{2} h_{\min } \geq \mathcal{S}_{U</p>
<p>which contradicts the fact that $\mathcal{S}_{U}$ is an upper bound on $\mathcal{S}^{*}$.</p>
<p>For the other direction, let $\mathcal{G}$ be a solution to Problem (6) but not a solution to Problem (1). This indicates that either $\mathcal{G}$ is not a DAG or $\mathcal{G}$ is a DAG but has a higher score than the minimum score, i.e., $\mathcal{S}(\mathcal{G})&gt;\mathcal{S}^{*}$. The latter case clearly contradicts the definition of the minimum score. For the former case, assume that some DAG $\mathcal{G}^{\prime}$ achieves the minimum score. Then plugging $\mathcal{G}^{\prime}$ into the negative reward, we can get the same inequality in Eq. (8) since both penalty terms are zeros for a DAG. This then contradicts the assumption that $\mathcal{G}$ minimizes the negative reward.</p>
<h1>C Penalty Weight Choice</h1>
<p>Although setting $\lambda_{2}=0$, or equivalently using only the indicator function w.r.t. acyclicity, can still make Problem (6) equivalent to the original problem with hard acyclicity constraint, we remark that this choice usually does not result in good performance of the RL approach, largely due to that the reward with only the indicator term is likely to fail to guide the RL agent to generate DAGs.
To see why it is the case, consider two cyclic directed graphs, one with all the possible directed edges in place and the other with only two edges (i.e., $x_{i} \rightarrow x_{j}$ and $x_{j} \rightarrow x_{i}$ for some $i \neq j$ ). The latter is much 'closer' to acyclicity in many senses, such as $h(A)$ given in Eq. (4) and number of edge deletion, addition, and reversal to make a directed graph acyclic. Assume a linear data model that has a relatively dense graph. Then the former graph will have a lower BIC score when using linear regression for fitting causal relations, yet the penalty terms of acyclicity are the same with only the indicator function. The former graph then has a higher reward, which does not help the agent to tend to generate DAGs. Also notice that the graphs in our approach are generated according to Bernoulli distributions determined by NN parameters that are randomly initialized. Without loss of generality, consider that each edge is drawn independently according to $\operatorname{Bern}(0.5)$. For small graphs (with less than or equal to 6 nodes or so), a few hundreds of samples of directed graphs are very likely to contain a DAG. Yet for large graphs, the probability of sampling a DAG is much lower. If no DAG is generated during training, the RL agent can hardly learn to generate DAGs. The above facts indeed motivate us to choose a small value of $\lambda_{2}$ so that the agent can be trained to produce graphs closer to acyclicity and finally to generate exact DAGs.
A question is then what if the RL approach starts with a DAG, e.g., by initializing the probability of generating each edge to be nearly zero. This setting did not lead to good performance, either. The generated directed graphs at early iterations can be very different from the true graphs in that many true edges do not exist, and the resulting score is much higher than the minimum under the DAG constraint. With small penalty weights of the acyclicity terms, the agent could be trained to produce cyclic graphs with better scores, similar to the case with randomly initialized NN parameters. On the other hand, large initial penalty weights, as we have discussed in the paper, limit exploration of the RL agent and usually result in DAGs whose scores are far from optimum.</p>
<h2>D IMPLEMENTATION DETAILS</h2>
<p>We use existing implementations of causal discovery algorithms in comparison, listed below:</p>
<ul>
<li>ICA-LiNGAM (Shimizu et al., 2006) assumes linear non-Gaussian additive model for data generating procedure and applies Independent Component Analysis (ICA) to recover the weighted adjacency matrix, followed by thresholding on the weights before outputting the inferred graph. A Python implementation is available at the first author's website https://sites.google.com/site/sshimizu06/lingam.</li>
<li>GES and PC: we use the fast greedy search implementation of GES (Ramsey et al., 2017) which has been reported to outperform other techniques such as max-min hill climbing (Han et al., 2016; Zheng et al., 2018). Implementations of both methods are available through the py-causal package at https://github.com/bd2kccd/py-causal, written in highly optimized Java codes.</li>
<li>
<p>CAM (Peters et al., 2014) decouples the causal order search among the variables from feature or edge selection in a DAG. CAM also assumes additive noise as in our work, with an additional condition that each function is nonlinear. Codes are available through the CRAN R package repository at https://cran.r-project.org/web/packages/CAM.</p>
</li>
<li>
<p>NOTEARS (Zheng et al., 2018) recovers the causal graph by estimating the weighted adjacency matrix with the least squares loss and the smooth characterization for acyclicity constraint, followed by thresholding on the estimated weights. Codes are available at the first author's github repository https://github.com/xunzheng/notears. We also re-implement the augmented Lagrangian method following the same updating rule on the Lagrange multiplier and the penalty parameter in Tensorflow, so that the augmented Lagrangian at each iteration can be readily minimized without the need of obtaining closedform gradients. We use this implementation in Sections 6.2 and 6.3 when the objective function and/or the acyclicity constraint are modified.</p>
</li>
<li>DAG-GNN (Yu et al., 2019) formulates causal discovery in the framework of variational autoencoder, where the encoder and decoder are two shallow graph NNs. With a modified smooth characterization on acyclicity, DAG-GNN optimizes a weighted adjacency matrix with the evidence lower bound as loss function. Python codes are available at the first author's github repository https://github.com/fishmoon1234/DAG-GNN.</li>
<li>GraN-DAG (Lachapelle et al., 2019) uses feed-foward NNs to model each causal relationship and chooses the sum of all product paths between variables $x_{i}$ and $x_{j}$ as the $(i, j)$-th element of an equivalent weighted adjacency matrix. GraN-DAG uses the same smooth constraint from Zheng et al. (2018) to find a DAG that maximizes the log-likelihood of the observed samples. Codes are available at the first author's github repository https : //github.com/kurowasan/GraN-DAG.</li>
</ul>
<p>Our implementation is based on an existing Tensorflow implementation of neural combinatorial optimizer available at https://github.com/MichelDeudon/ neural-combinatorial-optimization-rl-tensorflow. We add an entropy regularization term, and modify the reward and decoder as described in Sections 4 and 5.1, respectively. Our codes have been made available at https://github.com/ huawei-noah/trustworthyAI/tree/master/Causal_Structure_Learning/ Causal_Discovery_RL.</p>
<h1>E FURTHER EXPERIMENT DETAILS AND RESULTS</h1>
<h2>E. 1 EXPERIMENT 1 IN SECTION 6.1</h2>
<p>We replace the feed-forward NNs with linear functions in GraN-DAG and obtain similar experimental results as NOTEARS (FDR, TPR, SHD): $0.05 \pm 0.04,0.93 \pm 0.06,3.2 \pm 2.93$ and $0.05 \pm 0.04$, $0.95 \pm 0.03,2.40 \pm 1.85$ for LiNGAM and linear-Gaussian data models, respectively.</p>
<p>We conduct additional experiments with linear models where the noise variances are uniformly sampled according to Unif $([0.5,2])$. Results are given in Table 6. ${ }^{2}$</p>
<p>Table 6: Empirical results on LiNGAM and linear-Gaussian data models with 12-node graphs and different noise variances.</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">RL-BIC</th>
<th style="text-align: center;">RL-BIC2</th>
<th style="text-align: center;">PC</th>
<th style="text-align: center;">GES</th>
<th style="text-align: center;">ICA-LiNGAM</th>
<th style="text-align: center;">CAM</th>
<th style="text-align: center;">NOTEARS</th>
<th style="text-align: center;">DAG-GNN</th>
<th style="text-align: center;">GraN-DAG</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">LiNGAM</td>
<td style="text-align: center;">FDR</td>
<td style="text-align: center;">$0.29 \pm 0.12$</td>
<td style="text-align: center;">$0.09 \pm 0.06$</td>
<td style="text-align: center;">$0.57 \pm 0.10$</td>
<td style="text-align: center;">$0.59 \pm 0.13$</td>
<td style="text-align: center;">$0 \pm 0$</td>
<td style="text-align: center;">$0.70 \pm 0.07$</td>
<td style="text-align: center;">$0.08 \pm 0.10$</td>
<td style="text-align: center;">$0.14 \pm 0.07$</td>
<td style="text-align: center;">$0.71 \pm 0.10$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">TPR</td>
<td style="text-align: center;">$0.77 \pm 0.15$</td>
<td style="text-align: center;">$0.94 \pm 0.03$</td>
<td style="text-align: center;">$0.28 \pm 0.06$</td>
<td style="text-align: center;">$0.27 \pm 0.10$</td>
<td style="text-align: center;">$1 \pm 0$</td>
<td style="text-align: center;">$0.45 \pm 0.12$</td>
<td style="text-align: center;">$0.94 \pm 0.07$</td>
<td style="text-align: center;">$0.91 \pm 0.04$</td>
<td style="text-align: center;">$0.25 \pm 0.09$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">SHD</td>
<td style="text-align: center;">$14.4 \pm 7.17$</td>
<td style="text-align: center;">$4.0 \pm 2.61$</td>
<td style="text-align: center;">$30.4 \pm 4.13$</td>
<td style="text-align: center;">$32.0 \pm 5.18$</td>
<td style="text-align: center;">$0 \pm 0$</td>
<td style="text-align: center;">$41.6 \pm 3.32$</td>
<td style="text-align: center;">$3.20 \pm 3.97$</td>
<td style="text-align: center;">$6.6 \pm 1.02$</td>
<td style="text-align: center;">$38.7 \pm 4.86$</td>
</tr>
<tr>
<td style="text-align: center;">Linear- <br> Gaussian</td>
<td style="text-align: center;">FDR</td>
<td style="text-align: center;">$0.36 \pm 0.07$</td>
<td style="text-align: center;">$0.10 \pm 0.07$</td>
<td style="text-align: center;">$0.54 \pm 0.10$</td>
<td style="text-align: center;">$0.61 \pm 0.14$</td>
<td style="text-align: center;">$0.67 \pm 0.05$</td>
<td style="text-align: center;">$0.65 \pm 0.10$</td>
<td style="text-align: center;">$0.07 \pm 0.09$</td>
<td style="text-align: center;">$0.12 \pm 0.04$</td>
<td style="text-align: center;">$0.71 \pm 0.12$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">TPR</td>
<td style="text-align: center;">$0.68 \pm 0.09$</td>
<td style="text-align: center;">$0.93 \pm 0.04$</td>
<td style="text-align: center;">$0.29 \pm 0.05$</td>
<td style="text-align: center;">$0.26 \pm 0.11$</td>
<td style="text-align: center;">$0.75 \pm 0.06$</td>
<td style="text-align: center;">$0.51 \pm 0.14$</td>
<td style="text-align: center;">$0.95 \pm 0.06$</td>
<td style="text-align: center;">$0.94 \pm 0.04$</td>
<td style="text-align: center;">$0.21 \pm 0.08$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">SHD</td>
<td style="text-align: center;">$18.8 \pm 3.43$</td>
<td style="text-align: center;">$4.6 \pm 3.07$</td>
<td style="text-align: center;">$30.0 \pm 2.83$</td>
<td style="text-align: center;">$32.2 \pm 5.42$</td>
<td style="text-align: center;">$49.0 \pm 4.82$</td>
<td style="text-align: center;">$37.8 \pm 6.31$</td>
<td style="text-align: center;">$3.0 \pm 3.58$</td>
<td style="text-align: center;">$5.4 \pm 2.06$</td>
<td style="text-align: center;">$39.6 \pm 5.85$</td>
</tr>
</tbody>
</table>
<p>Knowing a sparse true causal graph a priori is also helpful. To incorporate this information in our experiment with 30-node graphs, we add an additional biased term $\hat{c} \in \mathbb{R}$ to each decoder output: for</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>the single layer decoder, we have</p>
<p>$$
g_{i j}\left(W_{1}, W_{2}, u\right)=u^{T} \tanh \left(W_{1} \operatorname{enc}<em 2="2">{i}+W</em>
$$} \operatorname{enc}_{j}\right)+\tilde{c</p>
<p>where we let $\tilde{c}$ be trainable and other parameters have been defined in Appendix A. In our experiments, $\tilde{c}$ is initialized to be -10 ; this choice aims to set a good starting point for generating graph adjacency matrices, motivated by the fact that a good starting point is usually helpful to locally convergent algorithms.</p>
<h1>E. 2 EXPERIMENT 2 IN SECTION 6.2</h1>
<p>To remove 'outlier' samples with large values that may cause computation issues for quadratic regression, we sort the samples in ascending order according to their $\ell_{2}$-norms and then pick the first 3,000 samples for causal discovery.</p>
<p>We use a similar idea from GraN-DAG to build an equivalent weighted adjacency matrix for NOTEARS. Take the first variable $x_{1}$ for example. We first expand the rest variables $x_{2}, \ldots, x_{d}$ to contain both first- and second-order features: $x_{2}, \ldots, x_{d}, x_{2} x_{3}, \ldots, x_{i} x_{j}, \ldots, x_{d-1} x_{d}$ with $i, j=2, \ldots, d$ and $i \leq j$. There are in total $d(d-1) / 2$ terms and we use $\mathbf{x}<em i="i">{1}$ to denote the vector that concatenates these feature terms. Correspondingly, we use $c</em>}$ and $c_{i j}$ to denote the coefficients associated with these features and $\mathbf{c<em l="l">{1}$ to denote the concatenating vector of the coefficients. Notice that the variable $x</em>}, l \neq 1$ affects $x_{1}$ only through the terms $x_{l}, x_{i} x_{l}$ with $i \leq l$, and $x_{l} x_{j}$ with $j&gt;l$. Therefore, an equivalent weighted adjacency matrix $W$ lying in $\mathbb{R}^{d \times d}$ can be constructed with the $(l, 1)$-th entry $W_{l 1}:=\left|c_{l}\right|+\sum_{i=2}^{l}\left|c_{i l}\right|+\sum_{j=l+1}^{d}\left|c_{l j}\right|$; in this way, $W_{l 1}=0$ implies that $x_{l}$ has no effect on $x_{1}$. The least squares term, corresponding to variable $x_{1}$, in the loss function will become $\sum_{k=1}^{m}\left(x_{1}^{k}-\mathbf{c<em 1="1">{1}^{T} \mathbf{x}</em>$ where $m$ is the total number of samples. In summary, we have the following optimization problem}^{k}\right)^{2</p>
<p>$$
\begin{array}{ll}
\min <em 1="1">{\mathbf{c}</em>}, \mathbf{c<em d="d">{2}, \ldots, \mathbf{c}</em>}} &amp; \sum_{i=1}^{d} \sum_{k=1}^{m}\left(x_{i}^{k}-\mathbf{c<em i="i">{i}^{T} \mathbf{x}</em> \
\text { subject to } &amp; \operatorname{trace}\left(e^{W \circ W}\right)-d=0
\end{array}
$$}^{k}\right)^{2</p>
<p>where $\circ$ denotes the element-wise product and the constraint enforces acyclicity w.r.t. a weighted adjacency matrix (Zheng et al., 2018). The problem has $(d-1) d^{2} / 2$ parameters to optimize, while the original NOTEARS optimizes $d^{2}$ parameters. We solve this problem with augmented Lagrangian method where at each iteration the augmented Lagrangian is approximately minimized by Adam (Kingma and Ba, 2014) with Tensorflow. The Lagrange multiplier and the penalty parameter are updated in the same fashion as in the original NOTEARS.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{2}$ Notice that linear-Gaussian data models with different noise variances are generally not identifiable. It turns out that the Markov equivalence class is small and has at most 5 DAGs for the datasets considered here. Moreover, the SHD between the DAGs in the Markov equivalence class and the true DAG is bounded by 3, across all the datasets. Consequently, we may still use the true causal graph to evaluate the estimation performance. We thank Sebastien Lachapelle from Mila for pointing this out.&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>