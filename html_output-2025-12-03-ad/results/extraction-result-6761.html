<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-6761 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-6761</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-6761</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-130.html">extraction-schema-130</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models solving spatial puzzle games, including details about the model, the puzzle, the reasoning or prompting method, performance metrics, internal representations, use of external tools, and any analysis or limitations reported.</div>
                <p><strong>Paper ID:</strong> paper-bcc752bf6c3d696892c44e2e2ac9b6348fcdfd42</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/bcc752bf6c3d696892c44e2e2ac9b6348fcdfd42" target="_blank">LGPSolver - Solving Logic Grid Puzzles Automatically</a></p>
                <p><strong>Paper Venue:</strong> Findings</p>
                <p><strong>Paper TL;DR:</strong> This work proposes a solution that uses a DistilBERT-based classifier to classify a clue into one of the predefined predicate types for logic grid puzzles and utilizes a semantic framework to catch comparative quantifiers, ensuring conversion to correct logic representation.</p>
                <p><strong>Paper Abstract:</strong> Logic grid puzzle (LGP) is a type of word problem where the task is to solve a problem in logic. Constraints for the problem are given in the form of textual clues. Once these clues are transformed into formal logic, a deductive reasoning process provides the solution. Solving logic grid puzzles in a fully automatic manner has been a challenge since a precise understanding of clues is necessary to develop the corresponding formal logic representation. To meet this challenge, we propose a solution that uses a DistilBERT-based classifier to classify a clue into one of the predefined predicate types for logic grid puzzles. Another novelty of the proposed solution is the recognition of comparison structures in clues. By collecting comparative adjectives from existing dictionaries and utilizing a semantic framework to catch comparative quantifiers, the semantics of clues concerning comparison structures are better understood, ensuring conversion to correct logic representation. Our approach solves logic grid puzzles in a fully automated manner with 100% accuracy on the given puzzle datasets and outperforms state-of-the-art solutions by a large margin.</p>
                <p><strong>Cost:</strong> 0.003</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <p class="empty-note">No extracted data.</p>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <p class="empty-note">No potentially relevant new papers extracted.</p>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-6761",
    "paper_id": "paper-bcc752bf6c3d696892c44e2e2ac9b6348fcdfd42",
    "extraction_schema_id": "extraction-schema-130",
    "extracted_data": [],
    "potentially_relevant_new_papers": [],
    "cost": 0.00265325,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>LGPSolver - Solving Logic Grid Puzzles Automatically</h1>
<p>Elgun Jabrayilzade<br>Department of Computer Engineering Izmir Institute of Technology<br>elgun1999@gmail.com</p>
<p>Selma Tekir<br>Department of Computer Engineering<br>Izmir Institute of Technology<br>selmatekir@iyte.edu.tr</p>
<h4>Abstract</h4>
<p>Logic grid puzzle (LGP) is a type of word problem where the task is to solve a problem in logic. Constraints for the problem are given in the form of textual clues. Once these clues are transformed into formal logic, a deductive reasoning process provides the solution.</p>
<p>Solving logic grid puzzles in a fully automatic manner has been a challenge since a precise understanding of clues is necessary to develop the corresponding formal logic representation. To meet this challenge, we propose a solution that uses a DistilBERT-based classifier to classify a clue into one of the predefined predicate types for logic grid puzzles. Another novelty of the proposed solution is the recognition of comparison structures in clues. By collecting comparative adjectives from existing dictionaries and utilizing a semantic framework to catch comparative quantifiers, the semantics of clues concerning comparison structures are better understood, ensuring conversion to correct logic representation. Our approach solves logic grid puzzles in a fully automated manner with $100 \%$ accuracy on the given puzzle datasets and outperforms state-of-the-art solutions by a large margin.</p>
<h2>1 Introduction</h2>
<p>Logic grid puzzle (LGP) is a type of word problem where the task is to solve a problem in logic. LGP can be on any domain. Constraints for an LGP are provided as textual clues. The precise understanding of these clues is crucial to correctly solve the puzzle because the representation of clues leads the logical reasoning process.</p>
<p>Automatically solving any word problem paves the way for more equipped digital assistants that take textual commands. Both word algebra problems and logic puzzles appear in admission tests such as the Graduate Record Exam (GRE). Thus, automation improves the understanding of these
problems and can be used in the training of students.</p>
<p>In the field of Natural Language Processing (NLP), semantic representations are improved day by day. State-of-the-art BERT (Devlin et al., 2019) representations have boosted performance in a wide variety of NLP tasks. The rising interest is on frameworks that combine neural network-driven representations with logic representations to reason about language and predict correct outputs for tasks such as natural language inference (NLI) ( Li et al., 2019). Logic puzzle solving is a task that is considered in this direction, as well.</p>
<p>LGPs are usually defined by a description and clues. The description part introduces categories and instances associated with each of them, and clues provide the definitions of constraints on the relationships between instances. The description can be represented by an $N \times M$ matrix where $N$ is the number of categories, and $M$ is the number of instances of a category. The main rule of logic grid puzzles is that one instance of a category should match only one instance of another category. The solution is provided as a tuple of instances for each category. Here is an example of a simple $3 \times 4$ logic grid puzzle taken from puzzlebaron ${ }^{1}$ :</p>
<ul>
<li>Students: {Alex, Emma, Alice, Taylor},</li>
<li>Scholarships: ${\$ 25 \mathrm{k}, \$ 30 \mathrm{k}, \$ 35 \mathrm{k}, \$ 40 \mathrm{k}}$,</li>
<li>Majors: {Astronomy, English, Philosophy, Physics}
with sample clues such as:</li>
</ul>
<p>The student who studies Astronomy gets a smaller scholarship than Alice,
Alice is either the one who studies English or the one who studies Philosophy,</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>The student who studies Physics has a \$5000 bigger scholarship than Alex.</p>
<p>There has been some work that can automatically solve an LGP. Puzzler (Milicevic et al., 2012) uses an architecture that is composed of a parser and an inference module. In the parser module, clues are parsed using a Link Grammar parser, and the resultant parse trees are converted into logic representations by a semantic translator. Puzzler runs constraints in logic representation through the Alloy language to provide the solution. The system is designed around the Zebra puzzle and tested on a small dataset. Baral and Dzifcak (2012) use a trained model that consists of clues along with their desired representations in the form of $\lambda$-calculus rules to translate clues into Answer Set Programming (ASP). To distinguish between the multiple meanings of words, their system governs word to $\lambda$-ASP-Calculus rule association through probabilities. Logicia (Mitra and Baral, 2015) introduces a Maximum-Entropy based model for categorizing clues using features such as dependency trees, POS tags, etc. With the use of Answer Set Programming, it correctly solves 71 puzzles out of 100. LogicSolver (Nordstrom, 2017) generalizes and improves Puzzler's (Milicevic et al., 2012) parser method by adding more regular expression rules. In the solver module, puzzle is solved using custom first-order predicate logic parser on the predicates of type is, not, xor, and comparison predicates. He uses a dataset of 68 puzzles with various difficulties to evaluate LogicSolver.</p>
<p>LGPSolver differs from the aforementioned systems in two ways. In LGPs, semantic representation of clues is crucial because it leads the logical reasoning process to solve the puzzle. Considering this, we use a DistilBERT-based (Sanh et al., 2019) classifier, where a transformer model is combined with a Feed-Forward Layer and Softmax to perform clue classification. Language models like DistilBERT take word order and context into account, which are distinctive features of clues. Another notable characteristic of clues is that they consist of comparison structures. In general, a comparison is given among locations, times, or some numbers in the selected domain. We use a collected set of comparative adjectives and a semantic framework to identify comparative quantifiers. By categorizing these comparison quantifiers, LGPSolver can parse comparison clues.</p>
<p>Our experimental results show that our approach outperforms state-of-the-art solutions by a large margin by reaching $100 \%$ accuracy on the given puzzle datasets.</p>
<h2>2 Methodology</h2>
<p>Our approach to solving LGPs consists of four steps: parsing and classifying the given clues, defining the category instances in Prolog, converting the parsed clues into logic representations, and solving puzzles using the reasoning module. The source code with dependencies is provided as a downloadable link ${ }^{2}$.</p>
<h3>2.1 Parsing and Classifying the Given Clues</h3>
<p>First of all, LGPSolver takes the category information and puzzle clues as input. A custom category recognizer is used to extract the category instances that the clue refers to. In the sentence, "Emma has a \$10000 bigger scholarship than Alex", the extracted instances are "Emma" and "Alex". The category recognizer returns category instances in clues with the assumption that the given input is in the correct form, meaning that in the description part, each category is given in different lines, and each line contains only those instances that correspond to that category. Thus, LGPSolver does not need to know if Alice is actually a Person or a Subject as long as Alex, Emma, Alice, and Taylor (i.e., people) are given in the same line of input.</p>
<p>The date and time related category instances are tagged using the TimeML (Pustejovsky et al., 2003) annotations provided by HeidelTime (Strötgen and Gertz, 2013) temporal tagger. TimeML provides time expressions as $h h: m m$. These expressions are normalized to minutes $(60 *$ hour + minute $)$ to make their Prolog representations invariant.</p>
<p>The next step is the classification of clues. Generally, logic grid puzzles contain only a specific set of clue types. All the clues we have in our dataset can be represented by one of these clue types, as shown in Table 1.</p>
<p>Our observations state that clue types can be classified using some keywords and the order of words in the sentences. For example, the "Pair different" clue type usually starts with the "Of" keyword, whereas the "Comparison" type has a comparative adjective, quantifier, or "than" keyword most of the time. Successful classification of clues requires a model that takes these features into</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<table>
<thead>
<tr>
<th style="text-align: left;">Clue Type</th>
<th style="text-align: left;">Example</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Is</td>
<td style="text-align: left;">The Worul is made by Techtrin.</td>
</tr>
<tr>
<td style="text-align: left;">Either</td>
<td style="text-align: left;">Alice is either the one who studies English or the one who studies Philosophy.</td>
</tr>
<tr>
<td style="text-align: left;">All different</td>
<td style="text-align: left;">The four pandas were "A", "B", "C", and "D".</td>
</tr>
<tr>
<td style="text-align: left;">Pair different</td>
<td style="text-align: left;">Of Wade's computer and Jack's build, one has "A", other has "B".</td>
</tr>
<tr>
<td style="text-align: left;">Comparison</td>
<td style="text-align: left;">The student who studies Physics has a $\$ 5000$ bigger scholarship than Alex.</td>
</tr>
</tbody>
</table>
<p>Table 1: Clue types.
<img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: The classification algorithm.
account. Thus, we utilized the fine-tuned version of DistilBERT (Sanh et al., 2019) for the classification method as it can capture the word order and distinctive features of the types of clues. Ktrain (Maiya, 2020) Python package is used for this task as it contains the adjusted algorithm for classification tasks (Feed-forward neural network with Softmax activation on top). The classification workflow is shown in Figure 1.</p>
<p>The DistilBERT-based classifier is a fundamental component of our workflow because it can capture the context of clues. Traditional machine learning classifiers are behind DistilBERT in performance, and generally, they misclassify some Comparison type clues as Is type. For example, those classifiers encounter difficulty in distinguishing the following clues of Is and Comparison type respectively:</p>
<p>Jed Jarvis is the teacher.
Ed Ewing finished before the teacher.</p>
<p>DistilBERT is still a better choice than a rulebased classifier since every little variation in clues introduces an update to the rule base. Instead, a pretrained language model is quite robust and able to classify a clue even there are small variations in the sentence structure. Moreover, DistilBERT easily adapts to a new clue type by increasing the number of clue types in the output layer, while in the case of a rule-based classifier, an explicit regex rule must be written.</p>
<h3>2.2 Representation of Category Instances</h3>
<p>The designed architecture is implemented so that the instance of one category is defined as the pair of matched instances of other categories. This representation simplifies the solver part described in Section 2.4. For our example scenario, the Prolog statements that represent the instances are:</p>
<p>Alex $=[A l e x _s c h o l a r s h i p, A l e x _m a j o r]$, Emma $=[$ Emma_scholarship, Emma_major], Alice $=[$ Alice_scholarship, Alice_major], Taylor $=[$ Taylor_scholarship, Taylor_major $]$</p>
<p>Here, Alex_scholarship and Alex_major define the scholarship and the major associated with Alex. Additionally, we have an all_members rule that ensures each student has a different scholarship and major. The predicates for our example are shown below:
all_members([25000, 30000, 35000, 40000], [Alex_scholarship, Emma_scholarship, Alice_scholarship, Taylor_scholarship])
all_members([astronomy, english, philosophy, physics], [Alex_major, Emma_major, Alice_major, Taylor_major])</p>
<p>These Prolog predicates are automatically generated by LGPSolver using the information given in input files.</p>
<h3>2.3 Logic Representation of Clues</h3>
<p>After defining the instances, clues need to be translated into Prolog statements. The translation method is shown in Table 2. $I_{k}$ represents the $k^{t h}$ referenced instance in the clue. Is relationship matches the given two instances. Other clue types are represented using the combination of $I s$ relationship with and, or, not logical operators.</p>
<p>Comparison clues need additional consideration. They usually contain two instances, a quantifier,</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Clue</th>
<th style="text-align: left;">Prolog description</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Is $\left(I_{1}, I_{2}\right)$</td>
<td style="text-align: left;">$I_{1}=:=I_{2}$</td>
</tr>
<tr>
<td style="text-align: left;">Either $\left(I_{1}, I_{2}, I_{3}\right)$</td>
<td style="text-align: left;">$A=\mathbf{I s}\left(I_{1}, I_{2}\right), B=\mathbf{I s}\left(I_{1}, I_{3}\right)$ <br> and $(o r(A, B), \operatorname{not}(\operatorname{and}(A, B)))$</td>
</tr>
<tr>
<td style="text-align: left;">All-diff $\left(I_{1}, I_{2}, I_{3}, \ldots\right)$</td>
<td style="text-align: left;">$A=\mathbf{I s}\left(I_{1}, I_{2}\right), B=\mathbf{I s}\left(I_{1}, I_{3}\right), C=\mathbf{I s}\left(I_{2}, I_{3}\right), \ldots$ <br> $\operatorname{not}(A), \operatorname{not}(B), \operatorname{not}(C), \ldots$</td>
</tr>
<tr>
<td style="text-align: left;">Pair-diff $\left(I_{1}, I_{2}, I_{3}, I_{4}\right)$</td>
<td style="text-align: left;">$A=\mathbf{I s}\left(I_{1}, I_{3}\right), B=\mathbf{I s}\left(I_{2}, I_{4}\right), C=\mathbf{I s}\left(I_{1}, I_{4}\right), D=\mathbf{I s}\left(I_{2}, I_{3}\right)$ <br> or $(\operatorname{and}(A, B), \operatorname{and}(C, D))$</td>
</tr>
<tr>
<td style="text-align: left;">Comparison $\left(I_{1}, I_{2},&gt;,\right.$ quant $)$</td>
<td style="text-align: left;">$I_{1} . v a l-I_{2} . v a l=:=$ quant</td>
</tr>
</tbody>
</table>
<p>Table 2: Clue to Prolog translation table.
and a comparative adjective. These clues are divided into two types: less and more (e.g. "lower than" is a less type while "bigger than" is of more type). These types represent whether the first referenced instance's corresponding value is less or more than the value of the second instance. Types are defined as ' $&lt;$ ' (smaller sign) and ' $&gt;$ ' (greater sign) in Prolog. We have gathered a list of comparative adjectives in English from curso-ingles ${ }^{3}$ and with the help of Semantic Framework for comparison structures (Bakhshandeh and Allen, 2015), they are categorized as less type, more type, or none of them. In total, we acquired 41 comparative adjectives that are commonly used in LGPs.</p>
<p>Comparison quantifiers (e.g. $\$ 5000$ ) in clues are recognized using the regex patterns and expressions provided by HeidelTime (Strötgen and Gertz, 2013). Furthermore, due to the limitation of the HeidelTime tagger in capturing fractional time units (e.g., half an hour), we have extended the tagger's ruleset to include them.</p>
<p>The comparison clue's Prolog description includes $I_{k}$.val keyword to represent the matched instance of the compared category with the $I_{k}$. In our case, the compared category is the scholarship. Generally, the compared category in LGPs is the one that has numerical instances. In the case of multiple numerical categories, the instances of comparison clues are analyzed. LGPSolver chooses the unmentioned category as the compared one (the subject of comparison). For example, in clue "The student who studies Astronomy gets a smaller scholarship than Alice", the categories of mentioned instances are students and majors. In contrast, no instance of the scholarships category is mentioned.</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<h3>2.4 Solving the Puzzle</h3>
<p>To get the puzzle's solution, the instances of one category should be given as a query to the Prolog. For example, the query of (Alex, Emma, Alice, Taylor) will return the matched scholarships and majors for each of these students. For a given query, Prolog recursively binds the query parameters to their possible values and returns the matched values if all the predicates are true. This is accomplished by the Prolog's builtin backtracking search algorithm. Pyswip (Tekol, 2020) package is used to execute the generated Prolog scripts inside a Python code.</p>
<h2>3 Results</h2>
<p>For the work's evaluation, we have used the datasets provided by Logicia (Mitra and Baral, 2015) and LogicSolver (Nordstrom, 2017). Logicia dataset has 150 LGPs, whereas LogicSolver has 68 LGPs. We have used the 50 LGPs (the training set in Logicia) from the Logicia dataset for DistilBERT training, and the remaining 100 LGPs are used for the testing purposes. The 68 LGPs in the LogicSolver dataset are also used as a test set without additional training. In brief, there are 50 training and 168 test samples. The details of these datasets are given in Table 3 and Table 4.</p>
<p>The evaluation is based on two factors: parser and solver accuracies. Parser accuracy is defined as the percentage of the correctly parsed clues (including classification), while solver accuracy is the percentage of correctly solved puzzles. The performance of LGPSolver was compared to LogicSolver and Logicia. The experimental results are shown in Table 5.</p>
<p>The DistilBERT-based classifier successfully classified all the clues in the test puzzle sets, and LGPSolver has correctly solved all the LGPs in the given datasets. It should also be noted that to solve</p>
<table>
<thead>
<tr>
<th style="text-align: left;"># of puzzles</th>
<th style="text-align: left;">50</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"># of clues</td>
<td style="text-align: left;">245</td>
</tr>
<tr>
<td style="text-align: left;"># of category instances in clues</td>
<td style="text-align: left;">584</td>
</tr>
<tr>
<td style="text-align: left;">Avg. # of clues / category instance</td>
<td style="text-align: left;">0.42</td>
</tr>
<tr>
<td style="text-align: left;">Avg. # of clues / puzzle</td>
<td style="text-align: left;">4.9</td>
</tr>
<tr>
<td style="text-align: left;"># of Is clue type</td>
<td style="text-align: left;">57</td>
</tr>
<tr>
<td style="text-align: left;"># of Either clue type</td>
<td style="text-align: left;">36</td>
</tr>
<tr>
<td style="text-align: left;"># of Comparison clue type</td>
<td style="text-align: left;">120</td>
</tr>
<tr>
<td style="text-align: left;"># of All-diff clue type</td>
<td style="text-align: left;">16</td>
</tr>
<tr>
<td style="text-align: left;"># of Pair-diff clue type</td>
<td style="text-align: left;">16</td>
</tr>
</tbody>
</table>
<p>Table 3: Details of the training set.</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: left;">LogicSolver</th>
<th style="text-align: left;">Logicia</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"># of puzzles</td>
<td style="text-align: left;">68</td>
<td style="text-align: left;">100</td>
</tr>
<tr>
<td style="text-align: left;"># of clues</td>
<td style="text-align: left;">297</td>
<td style="text-align: left;">457</td>
</tr>
<tr>
<td style="text-align: left;"># of category instances in clues</td>
<td style="text-align: left;">756</td>
<td style="text-align: left;">1112</td>
</tr>
<tr>
<td style="text-align: left;">Avg. # of clues / category instance</td>
<td style="text-align: left;">0.39</td>
<td style="text-align: left;">0.41</td>
</tr>
<tr>
<td style="text-align: left;">Avg. # of clues / puzzle</td>
<td style="text-align: left;">4.36</td>
<td style="text-align: left;">4.57</td>
</tr>
<tr>
<td style="text-align: left;"># of Is clue type</td>
<td style="text-align: left;">65</td>
<td style="text-align: left;">114</td>
</tr>
<tr>
<td style="text-align: left;"># of Either clue type</td>
<td style="text-align: left;">53</td>
<td style="text-align: left;">74</td>
</tr>
<tr>
<td style="text-align: left;"># of Comparison clue type</td>
<td style="text-align: left;">125</td>
<td style="text-align: left;">203</td>
</tr>
<tr>
<td style="text-align: left;"># of All-diff clue type</td>
<td style="text-align: left;">15</td>
<td style="text-align: left;">22</td>
</tr>
<tr>
<td style="text-align: left;"># of Pair-diff clue type</td>
<td style="text-align: left;">39</td>
<td style="text-align: left;">40</td>
</tr>
</tbody>
</table>
<p>Table 4: Details of the test set.</p>
<p>LGPs successfully with the reasoning module of Prolog; the puzzle description should be parsed without any errors.</p>
<h2>4 Conclusion and Future Work</h2>
<p>This paper presents a system that automatically solves logic grid puzzles. Better identification of comparison structures in clues and using a DistilBERT-based clue classification solution are the two highlights of the system. LGPSolver achieves full accuracy in a fully automated manner.</p>
<p>The DistilBERT-based classifier is a fundamental component of our workflow because it can capture the context of clues. The traditional classifiers (e.g., Naive Bayes, SVM, Logistic Regression) have a lower accuracy, which can be attributed mostly to the misclassification of Comparison type clues as Is type clues. Furthermore, rule-based classifiers (e.g., regex patterns) were not preferred due to their generalizability issues as every little variation in clues introduces an update to the rule base. On the other hand, a pretrained language model is quite robust and able to classify a clue even there are small variations in the sentence structure.</p>
<p>The parser module requires to recognize and normalize time and date related information in clues</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: left;">LGPSolver</th>
<th style="text-align: left;">LogicSolver</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Parser</td>
<td style="text-align: left;">$100 \%(297 / 297)$</td>
<td style="text-align: left;">$74.4 \%(221 / 297)$</td>
</tr>
<tr>
<td style="text-align: left;">Solver</td>
<td style="text-align: left;">$100 \%(68 / 68)$</td>
<td style="text-align: left;">$83 \%(\approx 56 / 68)$</td>
</tr>
</tbody>
</table>
<p>(a) 297 clues and 68 puzzles.</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: left;">LGPSolver</th>
<th style="text-align: left;">Logicia</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Parser</td>
<td style="text-align: left;">$100 \%(450 / 450)$</td>
<td style="text-align: left;">$90.9 \%(410 / 450)$</td>
</tr>
<tr>
<td style="text-align: left;">Solver</td>
<td style="text-align: left;">$100 \%(100 / 100)$</td>
<td style="text-align: left;">$71 \%(71 / 100)$</td>
</tr>
</tbody>
</table>
<p>(b) 450 clues and 100 puzzles.</p>
<p>Table 5: Accuracy of parser and solver modules.
to process comparisons in the correct way. Temporal taggers can be used for this purpose. However, temporal taggers' numeric normalizers have limitations in capturing fractional time units (Chang and Manning, 2012)(Angeli and Uszkoreit, 2013). Thus, we have extended the rule set of HeidelTime (Strötgen and Gertz, 2013) to resolve the issue.</p>
<p>As LGPs contain only a specific set of clue types, the problem of clue classification is formulated on a fixed number of clue types. A more sophisticated system would be able to learn the number of clue types automatically by the processing of clues. Thus, to further reason about language, seeking an automatic mapping between an NLP-based semantic representation and a logic representation is an important future direction.</p>
<h2>Acknowledgments</h2>
<p>We thank Tuğkan Tuğlular for his helpful suggestions on an earlier version of this paper.</p>
<p>We also thank anonymous reviewers for their valuable comments.</p>
<h2>References</h2>
<p>Gabor Angeli and Jakob Uszkoreit. 2013. Languageindependent discriminative parsing of temporal expressions. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, ACL 2013, 4-9 August 2013, Sofia, Bulgaria, Volume 1: Long Papers, pages 83-92. The Association for Computer Linguistics.</p>
<p>Omid Bakhshandeh and James Allen. 2015. Semantic framework for comparison structures in natural language. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 993-1002, Lisbon, Portugal. Association for Computational Linguistics.</p>
<p>Chitta Baral and Juraj Dzifcak. 2012. Solving puzzles described in english by automated translation to answer set programming and learning how to do that translation. In Proceedings of the Thirteenth International Conference on Principles of Knowledge Representation and Reasoning, KR'12, page 573-577. AAAI Press.</p>
<p>Angel X. Chang and Christopher D. Manning. 2012. Sutime: A library for recognizing and normalizing time expressions. In Proceedings of the Eighth International Conference on Language Resources and Evaluation, LREC 2012, Istanbul, Turkey, May 2325, 2012, pages 3735-3740. European Language Resources Association (ELRA).</p>
<p>Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long and Short Papers), pages 4171-4186. Association for Computational Linguistics.</p>
<p>Tao Li, Vivek Gupta, Maitrey Mehta, and Vivek Srikumar. 2019. A logic-driven framework for consistency of neural models. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019, Hong Kong, China, November 3-7, 2019, pages 3922-3933. Association for Computational Linguistics.</p>
<p>Arun S. Maiya. 2020. ktrain: A low-code library for augmented machine learning. CoRR, abs/2004.10703.</p>
<p>Aleksandar Milicevic, Joseph P Near, and Rishabh Singh. 2012. Puzzler: An automated logic puzzle solver. Technical report, Massachusetts Institute of Technology (MIT).</p>
<p>Arindam Mitra and Chitta Baral. 2015. Learning to automatically solve logic grid puzzles. In Proceedings of the 2015 Conference on Empirical Methods
in Natural Language Processing, EMNLP 2015, Lisbon, Portugal, September 17-21, 2015, pages 10231033. The Association for Computational Linguistics.</p>
<p>Ross Nordstrom. 2017. Logicsolver - solving logic grid puzzles with part-of-speech tagging and firstorder logic. Technical report, University of Colorado, Colorado Springs.</p>
<p>James Pustejovsky, José M. Castaño, Robert Ingria, Roser Saurí, Robert J. Gaizauskas, Andrea Setzer, Graham Katz, and Dragomir R. Radev. 2003. Timeml: Robust specification of event and temporal expressions in text. In New Directions in Question Answering, Papers from 2003 AAAI Spring Symposium, Stanford University, Stanford, CA, USA, pages 28-34. AAAI Press.</p>
<p>Victor Sanh, Lysandre Debut, Julien Chaumond, and Thomas Wolf. 2019. Distilbert, a distilled version of BERT: smaller, faster, cheaper and lighter. CoRR, abs/1910.01108.</p>
<p>Jannik Strötgen and Michael Gertz. 2013. Multilingual and cross-domain temporal tagging. Lang. Resour. Evaluation, 47(2):269-298.</p>
<p>Yüce Tekol. 2020. Pyswip v0.2.9. https://github. com/yuce/pyswip.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{3}$ https://www.curso-ingles.com/en/resources/cheatsheets/adjectives/list-of-comparatives-and-superlatives&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>