<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-9525 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-9525</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-9525</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-165.html">extraction-schema-165</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used to distill, extract, or synthesize qualitative laws, principles, or generalizable rules from large numbers of scholarly input papers, including details of the methods, domains, evaluation, and results.</div>
                <p><strong>Paper ID:</strong> paper-279155102</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2506.03587v1.pdf" target="_blank">Preface to the Special Issue of the TAL Journal on Scholarly Document Processing</a></p>
                <p><strong>Paper Abstract:</strong> The rapid growth of scholarly literature makes it increasingly difficult for researchers to keep up with new knowledge. Automated tools are now more essential than ever to help navigate and interpret this vast body of information. Scientific papers pose unique difficulties, with their complex language, specialized terminology, and diverse formats, requiring advanced methods to extract reliable and actionable insights. Large language models (LLMs) offer new opportunities, enabling tasks such as literature reviews, writing assistance, and interactive exploration of research. This special issue of the TAL journal highlights research addressing these challenges and, more broadly, research on natural language processing and information retrieval for scholarly and scientific documents.</p>
                <p><strong>Cost:</strong> 0.011</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e9525.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e9525.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used to distill, extract, or synthesize qualitative laws, principles, or generalizable rules from large numbers of scholarly input papers, including details of the methods, domains, evaluation, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Laï-king & Paroubek (CONSORT QA)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Évaluation de la qualité de rapport des essais cliniques avec des larges modèles de langue (Evaluating clinical trials research article quality with large language models)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An applied study using large language models to automatically evaluate the reporting quality of randomized controlled trial (RCT) research articles by casting the CONSORT checklist assessment as a question-answering task for LLMs; reported high effectiveness in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Évaluation de la qualité de rapport des essais cliniques avec des larges modèles de langue (Evaluating clinical trials research article quality with large language models)</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Medicine / Biomedical research (Randomized Controlled Trials)</td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_description</strong></td>
                            <td>Not specified in this preface; described generically as RCT research articles (corpus size and source not provided here).</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_law_type</strong></td>
                            <td>Reporting-standards compliance rules (CONSORT checklist items; i.e., presence/absence of required reporting elements)</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_law_example</strong></td>
                            <td>Framed as assessing whether articles satisfy CONSORT checklist items (e.g., whether required trial-reporting elements are present or adequately described).</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_methodology</strong></td>
                            <td>Framed the task as question-answering: prompt LLMs to evaluate articles against the CONSORT framework (prompting-based QA).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Extensive experiments comparing LLM outputs to reference judgments (details not provided in the preface); reported accuracy metric.</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>Reported high effectiveness, achieving up to 85% accuracy in the CONSORT-based QA evaluation; demonstrates potential for automating quality assessment of clinical research articles.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reported_limitations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>bias_or_hallucination_issues</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Preface to the Special Issue of the TAL Journal on Scholarly Document Processing', 'publication_date_yy_mm': '2025-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9525.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e9525.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used to distill, extract, or synthesize qualitative laws, principles, or generalizable rules from large numbers of scholarly input papers, including details of the methods, domains, evaluation, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ArxivDIGESTables</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ArxivDIGESTables: Synthesizing Scientific Literature into Tables using Language Models</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A referenced study that uses language models to synthesize scientific literature into tabular summaries, enabling condensed multi-paper synthesis; mentioned in the preface as an example of LLM-based literature reviewing/synthesis.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>ArxivDIGESTables: Synthesizing Scientific Literature into Tables using Language Models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>General scholarly literature (multi-domain; implied arXiv corpus)</td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_description</strong></td>
                            <td>Not specified in the preface; title implies use of arXiv papers but no corpus size, filtering, or preprocessing details are provided here.</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_law_type</strong></td>
                            <td>Thematic/pattern synthesis into structured tabular summaries (aggregated insights across papers)</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_law_example</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>extraction_methodology</strong></td>
                            <td>Use of language models to synthesize information from many papers into tables (details such as prompting, RAG, or fine-tuning not specified in the preface).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Not specified in the preface.</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>Mentioned as a promising development for reviewing literature and synthesizing insights; no quantitative results given in the preface.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reported_limitations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>bias_or_hallucination_issues</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Preface to the Special Issue of the TAL Journal on Scholarly Document Processing', 'publication_date_yy_mm': '2025-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9525.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e9525.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used to distill, extract, or synthesize qualitative laws, principles, or generalizable rules from large numbers of scholarly input papers, including details of the methods, domains, evaluation, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SciMON</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>SciMON: Scientific Inspiration Machines Optimized for Novelty</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A referenced system that leverages methods (including LLMs) to generate novel scientific research directions; cited as an LLM-enabled approach to accelerate scientific discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>SciMON: Scientific Inspiration Machines Optimized for Novelty</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Scientific discovery / idea generation across scientific domains</td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_description</strong></td>
                            <td>Not specified in the preface (corpus details absent).</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_law_type</strong></td>
                            <td>Generation of novel hypotheses or research directions (heuristic/creative patterns rather than formal physical/chemical laws)</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_law_example</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>extraction_methodology</strong></td>
                            <td>Referenced as an inspiration machine optimized for novelty; specific use of LLMs (prompting, retrieval, agent architecture) not detailed in the preface.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Not specified in the preface.</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>Cited as a promising development for generating novel research directions; no evaluation numbers or methodological details provided here.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reported_limitations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>bias_or_hallucination_issues</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Preface to the Special Issue of the TAL Journal on Scholarly Document Processing', 'publication_date_yy_mm': '2025-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9525.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e9525.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used to distill, extract, or synthesize qualitative laws, principles, or generalizable rules from large numbers of scholarly input papers, including details of the methods, domains, evaluation, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>OpenResearcher</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>OpenResearcher: Unleashing AI for Accelerated Scientific Research</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A referenced system demonstration that uses AI/LLM technologies to accelerate scientific research and enable interactive exploration of papers; included as an example of new LLM-driven scholarly applications.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>OpenResearcher: Unleashing AI for Accelerated Scientific Research</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Interactive scholarly document exploration / research acceleration (general scientific domains)</td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_description</strong></td>
                            <td>Not specified in the preface.</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_law_type</strong></td>
                            <td>Interactive synthesis and exploration of multi-paper insights (not explicitly framed as extraction of formal laws)</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_law_example</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>extraction_methodology</strong></td>
                            <td>Described as a system demonstration leveraging LLMs for interactive exploration; specific extraction/synthesis mechanisms not provided in the preface.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Not specified in the preface.</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>Mentioned as enabling interactive exploration of papers; no quantitative outcomes reported in this preface.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reported_limitations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>bias_or_hallucination_issues</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Preface to the Special Issue of the TAL Journal on Scholarly Document Processing', 'publication_date_yy_mm': '2025-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9525.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e9525.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used to distill, extract, or synthesize qualitative laws, principles, or generalizable rules from large numbers of scholarly input papers, including details of the methods, domains, evaluation, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Zhang et al. (survey)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>A Comprehensive Survey of Scientific Large Language Models and Their Applications in Scientific Discovery</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A referenced comprehensive survey of scientific LLMs and their applications to scientific discovery, cited to contextualize LLM developments for accelerating discovery and synthesizing insights across papers.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>A Comprehensive Survey of Scientific Large Language Models and Their Applications in Scientific Discovery</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Survey covering multiple scientific domains where LLMs are applied</td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_description</strong></td>
                            <td>Not applicable / not specified in the preface (survey paper).</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_law_type</strong></td>
                            <td>Survey-level synthesis of applications (discusses methods for discovery and synthesis rather than reporting a single extracted law type).</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_law_example</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>extraction_methodology</strong></td>
                            <td>Survey; collates and summarizes existing LLM methods and applications across domains (details would be in the survey itself, not in this preface).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>Cited as documenting LLM developments that accelerate scientific discovery; no primary experimental results are described in the preface.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reported_limitations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>bias_or_hallucination_issues</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Preface to the Special Issue of the TAL Journal on Scholarly Document Processing', 'publication_date_yy_mm': '2025-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9525.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e9525.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used to distill, extract, or synthesize qualitative laws, principles, or generalizable rules from large numbers of scholarly input papers, including details of the methods, domains, evaluation, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>HoneyComb</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>HoneyComb: A Flexible LLM-Based Agent System for Materials Science</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A referenced system applying LLM-based agents in materials science, cited as an example of domain-specific LLM applications (materials discovery/workflows).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>HoneyComb: A Flexible LLM-Based Agent System for Materials Science</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Materials science (domain-specific LLM agent system)</td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_description</strong></td>
                            <td>Not specified in the preface.</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_law_type</strong></td>
                            <td>Domain-specific agent-enabled synthesis/assistance (potentially extracting heuristics or patterns in materials research, but not detailed here).</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_law_example</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>extraction_methodology</strong></td>
                            <td>Described as an LLM-based agent system; specific extraction/synthesis methodology is not detailed in the preface.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>Referenced as part of domain-specialized LLM developments; no quantitative performance details are provided in this preface.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reported_limitations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>bias_or_hallucination_issues</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Preface to the Special Issue of the TAL Journal on Scholarly Document Processing', 'publication_date_yy_mm': '2025-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>ArxivDIGESTables: Synthesizing Scientific Literature into Tables using Language Models <em>(Rating: 2)</em></li>
                <li>SciMON: Scientific Inspiration Machines Optimized for Novelty <em>(Rating: 2)</em></li>
                <li>OpenResearcher: Unleashing AI for Accelerated Scientific Research <em>(Rating: 2)</em></li>
                <li>A Comprehensive Survey of Scientific Large Language Models and Their Applications in Scientific Discovery <em>(Rating: 2)</em></li>
                <li>HoneyComb: A Flexible LLM-Based Agent System for Materials Science <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-9525",
    "paper_id": "paper-279155102",
    "extraction_schema_id": "extraction-schema-165",
    "extracted_data": [
        {
            "name_short": "Laï-king & Paroubek (CONSORT QA)",
            "name_full": "Évaluation de la qualité de rapport des essais cliniques avec des larges modèles de langue (Evaluating clinical trials research article quality with large language models)",
            "brief_description": "An applied study using large language models to automatically evaluate the reporting quality of randomized controlled trial (RCT) research articles by casting the CONSORT checklist assessment as a question-answering task for LLMs; reported high effectiveness in experiments.",
            "citation_title": "Évaluation de la qualité de rapport des essais cliniques avec des larges modèles de langue (Evaluating clinical trials research article quality with large language models)",
            "mention_or_use": "use",
            "llm_model_name": null,
            "llm_model_description": null,
            "application_domain": "Medicine / Biomedical research (Randomized Controlled Trials)",
            "input_corpus_description": "Not specified in this preface; described generically as RCT research articles (corpus size and source not provided here).",
            "qualitative_law_type": "Reporting-standards compliance rules (CONSORT checklist items; i.e., presence/absence of required reporting elements)",
            "qualitative_law_example": "Framed as assessing whether articles satisfy CONSORT checklist items (e.g., whether required trial-reporting elements are present or adequately described).",
            "extraction_methodology": "Framed the task as question-answering: prompt LLMs to evaluate articles against the CONSORT framework (prompting-based QA).",
            "evaluation_method": "Extensive experiments comparing LLM outputs to reference judgments (details not provided in the preface); reported accuracy metric.",
            "results_summary": "Reported high effectiveness, achieving up to 85% accuracy in the CONSORT-based QA evaluation; demonstrates potential for automating quality assessment of clinical research articles.",
            "comparison_to_baseline": null,
            "reported_limitations": null,
            "bias_or_hallucination_issues": null,
            "uuid": "e9525.0",
            "source_info": {
                "paper_title": "Preface to the Special Issue of the TAL Journal on Scholarly Document Processing",
                "publication_date_yy_mm": "2025-06"
            }
        },
        {
            "name_short": "ArxivDIGESTables",
            "name_full": "ArxivDIGESTables: Synthesizing Scientific Literature into Tables using Language Models",
            "brief_description": "A referenced study that uses language models to synthesize scientific literature into tabular summaries, enabling condensed multi-paper synthesis; mentioned in the preface as an example of LLM-based literature reviewing/synthesis.",
            "citation_title": "ArxivDIGESTables: Synthesizing Scientific Literature into Tables using Language Models",
            "mention_or_use": "mention",
            "llm_model_name": null,
            "llm_model_description": null,
            "application_domain": "General scholarly literature (multi-domain; implied arXiv corpus)",
            "input_corpus_description": "Not specified in the preface; title implies use of arXiv papers but no corpus size, filtering, or preprocessing details are provided here.",
            "qualitative_law_type": "Thematic/pattern synthesis into structured tabular summaries (aggregated insights across papers)",
            "qualitative_law_example": null,
            "extraction_methodology": "Use of language models to synthesize information from many papers into tables (details such as prompting, RAG, or fine-tuning not specified in the preface).",
            "evaluation_method": "Not specified in the preface.",
            "results_summary": "Mentioned as a promising development for reviewing literature and synthesizing insights; no quantitative results given in the preface.",
            "comparison_to_baseline": null,
            "reported_limitations": null,
            "bias_or_hallucination_issues": null,
            "uuid": "e9525.1",
            "source_info": {
                "paper_title": "Preface to the Special Issue of the TAL Journal on Scholarly Document Processing",
                "publication_date_yy_mm": "2025-06"
            }
        },
        {
            "name_short": "SciMON",
            "name_full": "SciMON: Scientific Inspiration Machines Optimized for Novelty",
            "brief_description": "A referenced system that leverages methods (including LLMs) to generate novel scientific research directions; cited as an LLM-enabled approach to accelerate scientific discovery.",
            "citation_title": "SciMON: Scientific Inspiration Machines Optimized for Novelty",
            "mention_or_use": "mention",
            "llm_model_name": null,
            "llm_model_description": null,
            "application_domain": "Scientific discovery / idea generation across scientific domains",
            "input_corpus_description": "Not specified in the preface (corpus details absent).",
            "qualitative_law_type": "Generation of novel hypotheses or research directions (heuristic/creative patterns rather than formal physical/chemical laws)",
            "qualitative_law_example": null,
            "extraction_methodology": "Referenced as an inspiration machine optimized for novelty; specific use of LLMs (prompting, retrieval, agent architecture) not detailed in the preface.",
            "evaluation_method": "Not specified in the preface.",
            "results_summary": "Cited as a promising development for generating novel research directions; no evaluation numbers or methodological details provided here.",
            "comparison_to_baseline": null,
            "reported_limitations": null,
            "bias_or_hallucination_issues": null,
            "uuid": "e9525.2",
            "source_info": {
                "paper_title": "Preface to the Special Issue of the TAL Journal on Scholarly Document Processing",
                "publication_date_yy_mm": "2025-06"
            }
        },
        {
            "name_short": "OpenResearcher",
            "name_full": "OpenResearcher: Unleashing AI for Accelerated Scientific Research",
            "brief_description": "A referenced system demonstration that uses AI/LLM technologies to accelerate scientific research and enable interactive exploration of papers; included as an example of new LLM-driven scholarly applications.",
            "citation_title": "OpenResearcher: Unleashing AI for Accelerated Scientific Research",
            "mention_or_use": "mention",
            "llm_model_name": null,
            "llm_model_description": null,
            "application_domain": "Interactive scholarly document exploration / research acceleration (general scientific domains)",
            "input_corpus_description": "Not specified in the preface.",
            "qualitative_law_type": "Interactive synthesis and exploration of multi-paper insights (not explicitly framed as extraction of formal laws)",
            "qualitative_law_example": null,
            "extraction_methodology": "Described as a system demonstration leveraging LLMs for interactive exploration; specific extraction/synthesis mechanisms not provided in the preface.",
            "evaluation_method": "Not specified in the preface.",
            "results_summary": "Mentioned as enabling interactive exploration of papers; no quantitative outcomes reported in this preface.",
            "comparison_to_baseline": null,
            "reported_limitations": null,
            "bias_or_hallucination_issues": null,
            "uuid": "e9525.3",
            "source_info": {
                "paper_title": "Preface to the Special Issue of the TAL Journal on Scholarly Document Processing",
                "publication_date_yy_mm": "2025-06"
            }
        },
        {
            "name_short": "Zhang et al. (survey)",
            "name_full": "A Comprehensive Survey of Scientific Large Language Models and Their Applications in Scientific Discovery",
            "brief_description": "A referenced comprehensive survey of scientific LLMs and their applications to scientific discovery, cited to contextualize LLM developments for accelerating discovery and synthesizing insights across papers.",
            "citation_title": "A Comprehensive Survey of Scientific Large Language Models and Their Applications in Scientific Discovery",
            "mention_or_use": "mention",
            "llm_model_name": null,
            "llm_model_description": null,
            "application_domain": "Survey covering multiple scientific domains where LLMs are applied",
            "input_corpus_description": "Not applicable / not specified in the preface (survey paper).",
            "qualitative_law_type": "Survey-level synthesis of applications (discusses methods for discovery and synthesis rather than reporting a single extracted law type).",
            "qualitative_law_example": null,
            "extraction_methodology": "Survey; collates and summarizes existing LLM methods and applications across domains (details would be in the survey itself, not in this preface).",
            "evaluation_method": null,
            "results_summary": "Cited as documenting LLM developments that accelerate scientific discovery; no primary experimental results are described in the preface.",
            "comparison_to_baseline": null,
            "reported_limitations": null,
            "bias_or_hallucination_issues": null,
            "uuid": "e9525.4",
            "source_info": {
                "paper_title": "Preface to the Special Issue of the TAL Journal on Scholarly Document Processing",
                "publication_date_yy_mm": "2025-06"
            }
        },
        {
            "name_short": "HoneyComb",
            "name_full": "HoneyComb: A Flexible LLM-Based Agent System for Materials Science",
            "brief_description": "A referenced system applying LLM-based agents in materials science, cited as an example of domain-specific LLM applications (materials discovery/workflows).",
            "citation_title": "HoneyComb: A Flexible LLM-Based Agent System for Materials Science",
            "mention_or_use": "mention",
            "llm_model_name": null,
            "llm_model_description": null,
            "application_domain": "Materials science (domain-specific LLM agent system)",
            "input_corpus_description": "Not specified in the preface.",
            "qualitative_law_type": "Domain-specific agent-enabled synthesis/assistance (potentially extracting heuristics or patterns in materials research, but not detailed here).",
            "qualitative_law_example": null,
            "extraction_methodology": "Described as an LLM-based agent system; specific extraction/synthesis methodology is not detailed in the preface.",
            "evaluation_method": null,
            "results_summary": "Referenced as part of domain-specialized LLM developments; no quantitative performance details are provided in this preface.",
            "comparison_to_baseline": null,
            "reported_limitations": null,
            "bias_or_hallucination_issues": null,
            "uuid": "e9525.5",
            "source_info": {
                "paper_title": "Preface to the Special Issue of the TAL Journal on Scholarly Document Processing",
                "publication_date_yy_mm": "2025-06"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "ArxivDIGESTables: Synthesizing Scientific Literature into Tables using Language Models",
            "rating": 2,
            "sanitized_title": "arxivdigestables_synthesizing_scientific_literature_into_tables_using_language_models"
        },
        {
            "paper_title": "SciMON: Scientific Inspiration Machines Optimized for Novelty",
            "rating": 2,
            "sanitized_title": "scimon_scientific_inspiration_machines_optimized_for_novelty"
        },
        {
            "paper_title": "OpenResearcher: Unleashing AI for Accelerated Scientific Research",
            "rating": 2,
            "sanitized_title": "openresearcher_unleashing_ai_for_accelerated_scientific_research"
        },
        {
            "paper_title": "A Comprehensive Survey of Scientific Large Language Models and Their Applications in Scientific Discovery",
            "rating": 2,
            "sanitized_title": "a_comprehensive_survey_of_scientific_large_language_models_and_their_applications_in_scientific_discovery"
        },
        {
            "paper_title": "HoneyComb: A Flexible LLM-Based Agent System for Materials Science",
            "rating": 1,
            "sanitized_title": "honeycomb_a_flexible_llmbased_agent_system_for_materials_science"
        }
    ],
    "cost": 0.01059275,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Preface to the Special Issue of the TAL Journal on Scholarly Document Processing
4 Jun 2025</p>
<p>Florian Boudin 
JFLI
CNRS
Nantes University
France</p>
<p>Akiko Aizawa 
National Institute of Informatics
Japan</p>
<p>Preface to the Special Issue of the TAL Journal on Scholarly Document Processing
4 Jun 202541F16CB88D7E3BD5A12DFCDDE286FDD4arXiv:2506.03587v1[cs.DL]Scholarly Document ProcessingNatural Language Processing for ScienceLarge Language Models (LLMs) MOTS-CLÉS : Traitement automatique de documents scientifiquesTraitement Automatique des Langue pour la scienceGrands modèles de langues (LLMs)
The rapid growth of scholarly literature makes it increasingly difficult for researchers to keep up with new knowledge.Automated tools are now more essential than ever to help navigate and interpret this vast body of information.Scientific papers pose unique difficulties, with their complex language, specialized terminology, and diverse formats, requiring advanced methods to extract reliable and actionable insights.Large language models (LLMs) offer new opportunities, enabling tasks such as literature reviews, writing assistance, and interactive exploration of research.This special issue of the TAL journal highlights research addressing these challenges and, more broadly, research on natural language processing and information retrieval for scholarly and scientific documents.RÉSUMÉ.La croissance rapide de la littérature scientifique rend de plus en plus difficile pour les chercheurs de suivre l'évolution des connaissances.Le recours à des outils automatisés est aujourd'hui indispensable pour naviguer et interpréter cette immense masse d'informations.Les articles scientifiques posent des difficultés uniques en raison de leur langage complexe, de leur terminologie spécialisée et de leurs formats variés, ce qui nécessite des méthodes avancées pour extraire des informations fiables et exploitables.Les grands modèles de langage (LLMs) ouvrent de nouvelles perspectives, permettant des tâches telles que les revues de littérature, l'assistance à la rédaction et l'exploration interactive des travaux scientifiques.Ce numéro spécial de la revue TAL met en lumière des recherches qui s'attaquent à ces défis et, plus largement, des recherches sur le traitement automatique des langues et la recherche d'information appliqués aux documents scientifiques et académiques.</p>
<p>Introduction</p>
<p>The volume of scholarly literature is expanding rapidly.A compelling example is the ACL Anthology 1 , a repository for scientific contributions within the fields of computational linguistics and Natural Language Processing (NLP), which recently surpassed 100,000 papers, doubling its size in just four years (Bollmann et al., 2023).As the rate of publication continues to accelerate, researchers and institutions face increasing challenges in keeping up with the flood of new knowledge.This highlights the critical need for automated methods to help navigate, understand and distill the growing body of scientific information.</p>
<p>To address this pressing challenge, researchers across various fields-including computational linguistics, NLP, text mining, information retrieval, digital libraries and scientometrics-have dedicated significant efforts into developing methods and resources designed to process scientific documents.This led to a surge in publications on the matter, alongside the successful hosting of numerous international events, such as the workshops Scholarly Document Processing (SDP) (Ghosal et al., 2024), SCIentific DOCument Analysis (SCIDOCA) (Nguyen and Matsumoto, 2024), Natural Language Processing for Scientific Text (SciNLP) (Cohan et al., 2021) and Bibliometricenhanced Information Retrieval (BIR) (Frommholz et al., 2024).</p>
<p>At the national level in France, scholarly document processing is also gaining momentum.This interest is exemplified by the success of the workshop Analyse et Recherche de Textes Scientifiques (ARTS) 2 (Boudin et al., 2023), held at the TALN-CORIA 2023 conference.The event, which saw the presentation of 12 papers and attracted over 40 participants, highlighted the relevance of the topic and prompted the call for this special issue of the TAL journal.</p>
<p>Scientific papers present unique challenges for document processing methods due to their inherent complexity.They are characterized by intricate technical language, discipline-specific terminology, distinct structural conventions, and frequent use of mathematical expressions, all of which pose significant challenges for current methods (Ramesh Kashyap et al., 2023).Additionally, the multi-modal nature of scientific papers, with their tables, figures and diagrams, further complicates their processing (Shen et al., 2022).Beyond these document-level challenges, effective methods should also account for features present at the collection level, such as citation networks, and leverage rich metadata, including authors, keywords, and publication venues, each introducing its own set of difficulties.</p>
<p>Developing methods to extract reliable, valuable and verifiable information from scientific papers is crucial for many downstream applications, including retrieval (Boudin et al., 2020;Wang et al., 2023), recommendation (Kreutz and Schenkel, 2022;Huang et al., 2024), summarization (Luo et al., 2023), questionanswering (Saikh et al., 2022;Auer et al., 2023) and document understanding (Wright and Augenstein, 2021;Veyseh et al., 2021).With the rise of large language models (LLMs) and their enhanced ability to analyze and synthetize insights across multiple scientific papers, new applications are continuously emerging.Promising developments include accelerating scientific discovery (Zhang et al., 2024b), generating novel research directions (Wang et al., 2024), reviewing of the literature (Newman et al., 2024), assisting scientific writing (Jourdan et al., 2024) and enabling interactive exploration of papers (Zheng et al., 2024).</p>
<p>LLMs are also being developed for specialized scientific domains, such as healthcare and medicine (Labrak et al., 2024) or material sciences (Zhang et al., 2024a).These domain-specific models assist experts and researchers with complex tasks, including drug discovery (Savage, 2023), diagnosis generation (Abdullahi et al., 2024), and science education (Cooper, 2023).</p>
<p>Efforts are also underway to reduce the growing computational and environmental costs associated with training and deploying LLMs (Hershcovich et al., 2022;Sadat Moosavi et al., 2023).At the same time, ethical concerns are being addressed, with research focused on the responsible use of LLMs in science, including issues of bias, fairness, and transparency in AI-driven research (Peled-Cohen et al., 2024).This special issue of the TAL journal focuses on research addressing these challenges, with an emphasis on NLP and information retrieval for scholarly and scientific documents.</p>
<p>Call, Reviewing and Selection of Papers</p>
<p>The call for submissions to this special issue of the TAL journal on scholarly document processing was announced in December 2023, and the submission platform 3 closed in March 2024.The scope of relevant topics extended beyond NLP and information retrieval tasks, tools, and resources designed for scientific documents, encompassing areas such as bibliometrics, scientometrics, citation analysis and recommendation, claim verification, plagiarism detection and scientific writing assistance.</p>
<p>A total of five articles were submitted (two in French and three in English) by authors from Iran, India and France.Each article was reviewed by three experts, two members of the scientific committee and one member of the Editorial Board.In May 2024, the Editorial Board and the guest editors met to discuss the first round of reviews and notified the authors of the outcomes.One paper was selected for a second round of reviews and was ultimately accepted, resulting in a selection rate of 20%.</p>
<ol>
<li>https://tal-65-2.sciencesconf.org/3.Accepted paperThis issue of the TAL journal features one paper: Évaluation de la qualité de rapport des essais cliniques avec des larges modèles de langue (Evaluating clinical trials research article quality with large language models) by Mathieu Laï-king and Patrick Paroubek.The paper focuses on the biomedical domain, specifically investigating the use of LLMs to evaluate the quality of Randomized Controlled Trials (RCTs), a type of clinical research article.The authors frame the evaluation task as a questionanswering problem, prompting LLMs to assess articles according to the Consolidated Standards of Reporting Trials (CONSORT) framework.Through extensive experiments, the study demonstrates the high effectiveness of LLMs, achieving an accuracy of up to 85%, thus paving the way for advancements in automating quality assessment in clinical research.</li>
</ol>
<p>AcknowledgementsWe would like to thank the editorial committee of the TAL journal for inviting us to coordinate the scientific committee for this special issue.We are especially grateful to the editors-in-chief for their support and invaluable assistance throughout this process.Finally, we would like to thank all the reviewers and members of the scientific committee who joined us for this special issue and generously volunteered their time to help us select the articles published here.
Learning to Make Rare and Complex Diagnoses With Generative AI Assistance: Qualitative Study of Popular Large Language Models. References Abdullahi, T Singh, R Eickhoff, C , JMIR Med Educ. 10e51391Feb, 2024</p>
<p>The sciqa scientific question answering benchmark for scholarly knowledge. S Auer, D A Barone, C Bartz, E G Cortes, M Y Jaradeh, O Karras, M Koubarakis, D Mouromtsev, D Pliukhin, D Radyush, Scientific Reports. 1372402023</p>
<p>M Bollmann, N Schneider, A Köhn, M Post, Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023). L Tan, D Milajevs, G Chauhan, J Gwinnup, E Rippeth, the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023)SingaporeAssociation for Computational LinguisticsDecember, 2023Two Decades of the ACL Anthology: Development, Impact, and Open Challenges</p>
<p>F Boudin, B Daille, R Dufour, O El, M Houbre, L Jourdan, N Kooli, Actes de CORIA-TALN 2023. Actes de l'atelier "Analyse et Recherche de Textes Scientifiques" (ARTS)@TALN 2023. s de CORIA-TALN 2023. s de l'atelier "Analyse et Recherche de Textes Scientifiques" (ARTS)@TALN 2023Paris, France, 62023</p>
<p>Keyphrase Generation for Scientific Document Retrieval. F Boudin, Y Gallina, A Aizawa, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. D Jurafsky, J Chai, N Schluter, J Tetreault, the 58th Annual Meeting of the Association for Computational LinguisticsAssociation for Computational LinguisticsJuly, 2020</p>
<p>A Cohan, P Dasigi, T Hope, K Lo, S Mohan, A Wade, L Wang, I Williams, D Zhang, Proceedings of the 2nd Workshop on Natural Language Processing for Scientific Text. the 2nd Workshop on Natural Language Processing for Scientific TextSciNLP 2021. August, 2021</p>
<p>Examining science education in ChatGPT: An exploratory study of generative artificial intelligence. G Cooper, Journal of Science Education and Technology. 322023</p>
<p>I Frommholz, P Mayr, G Cabanac, Proceedings of the 14th International Workshop on Bibliometric-enhanced Information Retrieval (BIR 2024). S Verberne, the 14th International Workshop on Bibliometric-enhanced Information Retrieval (BIR 2024)Glasgow, ScotlandMarch, 2024</p>
<p>T Ghosal, A Singh, A Waard, P Mayr, A Naik, O Weller, Y Lee, S Shen, Y Qin, Proceedings of the Fourth Workshop on Scholarly Document Processing (SDP 2024). the Fourth Workshop on Scholarly Document Processing (SDP 2024)Bangkok, ThailandAugust, 2024</p>
<p>Towards Climate Awareness in NLP Research. D Hershcovich, N Webersinke, M Kraus, J Bingler, M Leippold, Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing. Y Goldberg, Z Kozareva, Y Zhang, the 2022 Conference on Empirical Methods in Natural Language ProcessingAbu Dhabi, United Arab EmiratesAssociation for Computational LinguisticsDecember, 2022</p>
<p>A scientific paper recommendation method using the time decay heterogeneous graph. Z Huang, D Tang, R Zhao, W Rao, Scientometrics. 1292024</p>
<p>CASIMIR: A Corpus of Scientific Articles Enhanced with Multiple Author-Integrated Revisions. Jourdan L Boudin, F Hernandez, N Dufour, R , Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024), ELRA and ICCL. N Calzolari, M.-Y Kan, V Hoste, A Lenci, S Sakti, N Xue, the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024), ELRA and ICCLTorino, ItaliaMay, 2024</p>
<p>Scientific paper recommendation systems: a literature review of recent publications. C K Kreutz, R Schenkel, International journal on digital libraries. 232022</p>
<p>BioMistral: A Collection of Open-Source Pretrained Large Language Models for Medical Domains. Y Labrak, A Bazoge, E Morin, P.-A Gourraud, M Rouvier, R Dufour, in L.-W</p>
<p>Findings of the Association for Computational Linguistics: ACL 2024. A Ku, V Martins, Srikumar, Bangkok, ThailandAssociation for Computational LinguisticsAugust, 2024</p>
<p>CitationSum: Citation-aware Graph Contrastive Learning for Scientific Paper Summarization. Z Luo, Q Xie, S Ananiadou, Proceedings of the ACM Web Conference 2023, WWW '23. the ACM Web Conference 2023, WWW '23New York, NY, USAAssociation for Computing Machinery2023</p>
<p>ArxivDIGESTables: Synthesizing Scientific Literature into Tables using Language Models. B Newman, Y Lee, A Naik, P Siangliulue, R Fok, J Kim, D S Weld, J C Chang, K Lo, Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing. Y Al-Onaizan, M Bansal, Y.-N Chen, the 2024 Conference on Empirical Methods in Natural Language ProcessingMiami, Florida, USAAssociation for Computational LinguisticsNovember, 2024</p>
<p>M L Nguyen, Y Matsumoto, Proceedings of the Eighth International Workshop on SCIentific DOCument Analysis (SCIDOCA 2024). the Eighth International Workshop on SCIentific DOCument Analysis (SCIDOCA 2024)Hamamatsu, Shizuoka, JapanAugust, 2024</p>
<p>L Peled-Cohen, N Calderon, S Lissak, Proceedings of the 1st Workshop on NLP for Science (NLP4Science). R Reichart, the 1st Workshop on NLP for Science (NLP4Science)Miami, FL, USAAssociation for Computational LinguisticsNovember, 2024</p>
<p>Scientific document processing: challenges for modern learning methods. Ramesh Kashyap, A Yang, Y Kan, M.-Y , Int. J. Digit. Libr. 24mar, 2023</p>
<p>Sadat Moosavi, N Gurevych, I Hou, Y Kim, G Kim, Y J Schuster, T , Proceedings of The Fourth Workshop on Simple and Efficient Natural Language Processing (SustaiNLP). A Agrawal, The Fourth Workshop on Simple and Efficient Natural Language Processing (SustaiNLP)Toronto, CanadaAssociation for Computational LinguisticsJuly, 2023</p>
<p>Scienceqa: A novel resource for question answering on scholarly articles. T Saikh, T Ghosal, A Mittal, A Ekbal, P Bhattacharyya, International Journal on Digital Libraries. 2332022</p>
<p>Drug discovery companies are customizing ChatGPT: here's how. N Savage, Nat Biotechnol. 4152023</p>
<p>VILA: Improving Structured Content Extraction from Scientific PDFs Using Visual Layout Groups. Z Shen, K Lo, L L Wang, B Kuehl, D S Weld, D Downey, Transactions of the Association for Computational Linguistics. 102022</p>
<p>Acronym Identification and Disambiguation Shared Tasks for Scientific Document Understanding. A P B Veyseh, F Dernoncourt, T H Nguyen, W Chang, L A Celi, 2021</p>
<p>Scientific Document Retrieval using Multi-level Aspect-based Queries. J A Wang, K Wang, X Wang, P Naidu, L Bergen, R Paturi, Advances in Neural Information Processing Systems. A Oh, T Naumann, A Globerson, K Saenko, M Hardt, S Levine, Curran Associates, Inc202336</p>
<p>SciMON: Scientific Inspiration Machines Optimized for Novelty. Q Wang, D Downey, H Ji, T Hope, Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics. Long Papers. L.-W Ku, A Martins, V Srikumar, the 62nd Annual Meeting of the Association for Computational LinguisticsBangkok, ThailandAssociation for Computational LinguisticsAugust, 20241</p>
<p>CiteWorth: Cite-Worthiness Detection for Improved Scientific Document Understanding. D Wright, I Augenstein, Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021. C Zong, F Xia, W Li, R Navigli, Association for Computational LinguisticsAugust, 2021</p>
<p>HoneyComb: A Flexible LLM-Based Agent System for Materials Science. H Zhang, Y Song, Z Hou, S Miret, B Liu, Findings of the Association for Computational Linguistics: EMNLP 2024. Y Al-Onaizan, M Bansal, Y.-N Chen, Miami, Florida, USAAssociation for Computational LinguisticsNovember, 2024a</p>
<p>A Comprehensive Survey of Scientific Large Language Models and Their Applications in Scientific Discovery. Y Zhang, X Chen, B Jin, S Wang, S Ji, W Wang, J Han, Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing. Y Al-Onaizan, M Bansal, Y.-N Chen, the 2024 Conference on Empirical Methods in Natural Language ProcessingMiami, Florida, USAAssociation for Computational LinguisticsNovember, 2024b</p>
<p>OpenResearcher: Unleashing AI for Accelerated Scientific Research. Y Zheng, S Sun, L Qiu, D Ru, C Jiayang, X Li, J Lin, B Wang, Y Luo, R Pan, Y Xu, Q Min, Z Zhang, Y Wang, W Li, P Liu, Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing: System Demonstrations. D I Hernandez Farias, T Hope, M Li, the 2024 Conference on Empirical Methods in Natural Language Processing: System DemonstrationsMiami, Florida, USAAssociation for Computational LinguisticsNovember, 2024</p>            </div>
        </div>

    </div>
</body>
</html>