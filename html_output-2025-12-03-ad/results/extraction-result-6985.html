<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-6985 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-6985</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-6985</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-135.html">extraction-schema-135</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of graph-to-text representations used to convert graphs into textual sequences for language model training, including their description, encoding method, properties, datasets, models, evaluation metrics, performance outcomes, and any reported advantages or limitations.</div>
                <p><strong>Paper ID:</strong> paper-3674fd8b6327fd655e1cc57e4053bec47185f2d1</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/3674fd8b6327fd655e1cc57e4053bec47185f2d1" target="_blank">Ontology-Free General-Domain Knowledge Graph-to-Text Generation Dataset Synthesis using Large Language Model</a></p>
                <p><strong>Paper Venue:</strong> arXiv.org</p>
                <p><strong>Paper TL;DR:</strong> Wikipedia Ontology-Free Graph-text dataset (WikiOFGraph), a new large-scale G2T dataset generated using a novel method that leverages Large Language Model (LLM) and Data-QuestEval, proves to be a scalable and effective solution for generating high-quality G2T data, significantly advancing the field of G2T generation.</p>
                <p><strong>Paper Abstract:</strong> Knowledge Graph-to-Text (G2T) generation involves verbalizing structured knowledge graphs into natural language text. Recent advancements in Pretrained Language Models (PLMs) have improved G2T performance, but their effectiveness depends on datasets with precise graph-text alignment. However, the scarcity of high-quality, general-domain G2T generation datasets restricts progress in the general-domain G2T generation research. To address this issue, we introduce Wikipedia Ontology-Free Graph-text dataset (WikiOFGraph), a new large-scale G2T dataset generated using a novel method that leverages Large Language Model (LLM) and Data-QuestEval. Our new dataset, which contains 5.85M general-domain graph-text pairs, offers high graph-text consistency without relying on external ontologies. Experimental results demonstrate that PLM fine-tuned on WikiOFGraph outperforms those trained on other datasets across various evaluation metrics. Our method proves to be a scalable and effective solution for generating high-quality G2T data, significantly advancing the field of G2T generation.</p>
                <p><strong>Cost:</strong> 0.014</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e6985.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e6985.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of graph-to-text representations used to convert graphs into textual sequences for language model training, including their description, encoding method, properties, datasets, models, evaluation metrics, performance outcomes, and any reported advantages or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Serialized triplet sequence</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Serialized RDF-style triplet sequence with special tokens (<S>, <P>, <O>)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Graph instances are linearized as a sequence of subject–predicate–object triplets, where each triplet element is prefixed by special tokens (<S>, <P>, <O>) to produce a plain-text sequence consumable by text-only LMs; used both as the input representation for model fine-tuning and as the output of LLM-based graph extraction in this work.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Ontology-Free General-Domain Knowledge Graph-to-Text Generation Dataset Synthesis using Large Language Model</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representation_name</strong></td>
                            <td>Serialized triplet sequence (<S>/<P>/<O>)</td>
                        </tr>
                        <tr>
                            <td><strong>representation_description</strong></td>
                            <td>Each graph is encoded as an ordered list of triplets written as text; every triplet element is delimited by explicit special tokens ' <S> ', ' <P> ', and ' <O> ' so that the model can distinguish subjects, predicates and objects in the linearized sequence (e.g., '<S> Arròs negre <P> country <O> Spain').</td>
                        </tr>
                        <tr>
                            <td><strong>representation_type</strong></td>
                            <td>sequential, token-based (triplet list); preserves triplet content</td>
                        </tr>
                        <tr>
                            <td><strong>encoding_method</strong></td>
                            <td>edge-list serialization produced by LLM graph extraction (LLM generates a list of triplets for each sentence); ordering is the output order from the extractor (no DFS/BFS traversal reported).</td>
                        </tr>
                        <tr>
                            <td><strong>canonicalization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>average_token_length</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>WikiOFGraph (new dataset produced in this paper); also used with WebNLG, GenWiki, TekGen, LAGRANGE for comparison</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>graph-to-text generation (knowledge-graph verbalization) and LM fine-tuning for G2T</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>T5-large (770M) for generation; Llama-3-70b-instruct-awq used for graph extraction; vLLM used for inference batching</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>T5-large (770M parameters) encoder-decoder Transformer fine-tuned to map serialized triplet sequences into target text; Llama-3-70b-instruct-awq (70B) used to extract triplets from source sentences via in-context learning.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>BLEU, ChrF++, METEOR, TER, BLEURT, ROUGE-L, BERTScore-F1; Data-QuestEval used for referenceless graph-text consistency filtering.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>Fine-tuned T5-large on WikiOFGraph: on GenWiki test set BLEU 45.85, ChrF++ 69.61, METEOR 42.17, TER 43.38, BLEURT 0.46, ROUGE-L 70.10, BERTScore-F1 95.89 (Table 2). On WikiOFGraph test set BLEU 69.27, ChrF++ 82.63, METEOR 51.59, TER 17.44, BLEURT 0.71, ROUGE-L 86.46, BERTScore-F1 98.29 (Table 3).</td>
                        </tr>
                        <tr>
                            <td><strong>impact_on_training</strong></td>
                            <td>Using serialized triplet sequences from the large WikiOFGraph corpus substantially improved T5-large G2T performance across automatic fluency and semantic metrics versus models trained on ontology-derived datasets or smaller human-crafted sets; Data-QuestEval curation of serialized triplet–text pairs further improved final model metrics (Table 5 shows gradual gains as curated:noise ratio increases).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Canonicalization and deterministic ordering not reported; average token length per instance not reported; relies on quality of LLM extraction (errors arise from incomplete sentences and ambiguous pronouns); potential data contamination because LLMs may have been pretrained on Wikipedia; serialization may omit graph-level structural cues beyond flat triplets (not explicitly addressed).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other</strong></td>
                            <td>Outperforms ontology-aligned training corpora (GenWiki, TekGen, LAGRANGE) and small human-crafted WebNLG when used to fine-tune T5-large in this study, due to better graph–text consistency and larger scale; benefit amplified when combined with Data-QuestEval filtering.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Ontology-Free General-Domain Knowledge Graph-to-Text Generation Dataset Synthesis using Large Language Model', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6985.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e6985.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of graph-to-text representations used to convert graphs into textual sequences for language model training, including their description, encoding method, properties, datasets, models, evaluation metrics, performance outcomes, and any reported advantages or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Ontology-aligned triplet datasets</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Ontology-aligned graph triplet representations from DBpedia/Wikidata (e.g., GenWiki, TekGen, LAGRANGE, WebNLG)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Automatically or semi-automatically derived graph representations produced by aligning Wikipedia text with existing ontologies (DBpedia, Wikidata) and representing knowledge as ontology triplets; typically serialized as triplet lists for G2T training but often suffer from graph–text misalignment.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representation_name</strong></td>
                            <td>Ontology-aligned triplet lists (ontology-based graphs)</td>
                        </tr>
                        <tr>
                            <td><strong>representation_description</strong></td>
                            <td>Graphs are represented as sets of ontology triples (subject, predicate, object) derived from knowledge bases (DBpedia, Wikidata) using alignment heuristics; these triplets are packaged into a textual or structured format (commonly serialized) for training graph-to-text models.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_type</strong></td>
                            <td>sequential/token-based when serialized (triplet list); semantically lossless relative to the ontology but may be effectively lossy relative to target text meaning due to misalignment.</td>
                        </tr>
                        <tr>
                            <td><strong>encoding_method</strong></td>
                            <td>Ontology-driven extraction/distant supervision and alignment algorithms (matching Wikipedia spans/entities to ontology triples); datasets used include GenWiki (distant alignment), TekGen (Wikidata+Wikipedia distant supervision), LAGRANGE (aligned Wikidata/Wikipedia with augmentation), WebNLG (human-crafted from DBpedia).</td>
                        </tr>
                        <tr>
                            <td><strong>canonicalization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>average_token_length</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>GenWiki, TekGen, LAGRANGE, WebNLG (used as baselines in experiments)</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>graph-to-text generation (benchmark training/evaluation)</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>T5-large (770M) fine-tuned on each dataset as baseline comparisons</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Same T5-large backbone as used for WikiOFGraph baselines; models were fine-tuned separately on each ontology-aligned dataset to compare downstream generation performance.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>BLEU, ChrF++, METEOR, TER, BLEURT, ROUGE-L, BERTScore-F1 (same set as for serialized triplet experiments).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>Reported baseline results (Table 2, GenWiki test): WebNLG BLEU 35.97, GenWiki BLEU 36.14, TekGen BLEU 39.25, LAGRANGE BLEU 40.40. (Table 3, WikiOFGraph test): WebNLG BLEU 21.91, GenWiki BLEU 23.42, TekGen BLEU 38.45, LAGRANGE BLEU 39.37. These values show lower performance than models trained on WikiOFGraph in this study.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_on_training</strong></td>
                            <td>When used to fine-tune T5-large, ontology-derived datasets produced weaker general-domain G2T performance compared to WikiOFGraph, largely attributed to graph-text misalignment and limited predicate/entity diversity for some datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Frequently suffer from graph–text misalignment (texts contain information not present in ontology triplets and vice versa), limited predicate/expression variety tied to ontology vocabulary, and in some cases short/trivial triplets that map poorly to fluent text; these problems reduce downstream generation fidelity.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other</strong></td>
                            <td>Compared to LLM-extracted serialized triplets (WikiOFGraph), ontology-aligned triplet datasets show more misalignment and lower downstream performance; WebNLG (human-crafted) has high alignment but small scale and limited domain diversity.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Ontology-Free General-Domain Knowledge Graph-to-Text Generation Dataset Synthesis using Large Language Model', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6985.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e6985.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of graph-to-text representations used to convert graphs into textual sequences for language model training, including their description, encoding method, properties, datasets, models, evaluation metrics, performance outcomes, and any reported advantages or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Template-based linearization</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Template-based predicate verbalization and slot-filling linearization</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Traditional method converting graph predicates into pre-defined textual templates that realize predicates and entities as filled slots; mentioned as a prior approach for G2T with low hallucination but limited flexibility and high engineering cost.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>representation_name</strong></td>
                            <td>Template-based triplet-to-text linearization</td>
                        </tr>
                        <tr>
                            <td><strong>representation_description</strong></td>
                            <td>Predicates and arguments are converted into human-crafted sentence templates (or fragments) which are concatenated/filled to form output text; templates map specific predicate labels to fixed natural language realizations.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_type</strong></td>
                            <td>sequential, template-driven (rule-based); effectively lossless for intended content but rigid and limited in fluency and coverage.</td>
                        </tr>
                        <tr>
                            <td><strong>encoding_method</strong></td>
                            <td>Hand-crafted predicate-to-template mappings and slot-filling; not an algorithmic graph traversal but rule application per triplet or predicate group.</td>
                        </tr>
                        <tr>
                            <td><strong>canonicalization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>average_token_length</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>Mentioned historically (e.g., prior work such as Wiseman et al. etc.), not directly evaluated in this paper's experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>graph-to-text generation (rule/template baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>N/A (rule-based templates rather than learned LM)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Template methods produce text deterministically via rules; cited in background as contrast to neural/PLM-based approaches.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Not reported here; paper notes template methods have low hallucination but struggle with fluency and complex graphs.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>impact_on_training</strong></td>
                            <td>Not used for LM fine-tuning in this paper; referenced as low-hallucination baseline but less adaptable and labor-intensive to scale.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Requires manual effort to craft templates; brittle to predicate diversity and complex graph compositions; produces less fluent or natural outputs on complex inputs.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other</strong></td>
                            <td>Compared to neural PLM fine-tuning on serialized triplets, templates reduce hallucination but cannot match fluency/scalability of learned models and are costly to design across many predicates/domains.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Ontology-Free General-Domain Knowledge Graph-to-Text Generation Dataset Synthesis using Large Language Model', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>The WebNLG challenge: Generating text from RDF data <em>(Rating: 2)</em></li>
                <li>GenWiki: A dataset of 1.3 million content-sharing text and graphs for unsupervised graph-to-text generation <em>(Rating: 2)</em></li>
                <li>Knowledge graph based synthetic corpus generation for knowledge-enhanced language model pre-training <em>(Rating: 1)</em></li>
                <li>Construction of paired knowledge graph - text datasets informed by cyclic evaluation <em>(Rating: 2)</em></li>
                <li>Data-QuestEval: A referenceless metric for data-to-text semantic evaluation <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-6985",
    "paper_id": "paper-3674fd8b6327fd655e1cc57e4053bec47185f2d1",
    "extraction_schema_id": "extraction-schema-135",
    "extracted_data": [
        {
            "name_short": "Serialized triplet sequence",
            "name_full": "Serialized RDF-style triplet sequence with special tokens (&lt;S&gt;, &lt;P&gt;, &lt;O&gt;)",
            "brief_description": "Graph instances are linearized as a sequence of subject–predicate–object triplets, where each triplet element is prefixed by special tokens (&lt;S&gt;, &lt;P&gt;, &lt;O&gt;) to produce a plain-text sequence consumable by text-only LMs; used both as the input representation for model fine-tuning and as the output of LLM-based graph extraction in this work.",
            "citation_title": "Ontology-Free General-Domain Knowledge Graph-to-Text Generation Dataset Synthesis using Large Language Model",
            "mention_or_use": "use",
            "representation_name": "Serialized triplet sequence (&lt;S&gt;/&lt;P&gt;/&lt;O&gt;)",
            "representation_description": "Each graph is encoded as an ordered list of triplets written as text; every triplet element is delimited by explicit special tokens ' &lt;S&gt; ', ' &lt;P&gt; ', and ' &lt;O&gt; ' so that the model can distinguish subjects, predicates and objects in the linearized sequence (e.g., '&lt;S&gt; Arròs negre &lt;P&gt; country &lt;O&gt; Spain').",
            "representation_type": "sequential, token-based (triplet list); preserves triplet content",
            "encoding_method": "edge-list serialization produced by LLM graph extraction (LLM generates a list of triplets for each sentence); ordering is the output order from the extractor (no DFS/BFS traversal reported).",
            "canonicalization": null,
            "average_token_length": null,
            "dataset_name": "WikiOFGraph (new dataset produced in this paper); also used with WebNLG, GenWiki, TekGen, LAGRANGE for comparison",
            "task_name": "graph-to-text generation (knowledge-graph verbalization) and LM fine-tuning for G2T",
            "model_name": "T5-large (770M) for generation; Llama-3-70b-instruct-awq used for graph extraction; vLLM used for inference batching",
            "model_description": "T5-large (770M parameters) encoder-decoder Transformer fine-tuned to map serialized triplet sequences into target text; Llama-3-70b-instruct-awq (70B) used to extract triplets from source sentences via in-context learning.",
            "performance_metric": "BLEU, ChrF++, METEOR, TER, BLEURT, ROUGE-L, BERTScore-F1; Data-QuestEval used for referenceless graph-text consistency filtering.",
            "performance_value": "Fine-tuned T5-large on WikiOFGraph: on GenWiki test set BLEU 45.85, ChrF++ 69.61, METEOR 42.17, TER 43.38, BLEURT 0.46, ROUGE-L 70.10, BERTScore-F1 95.89 (Table 2). On WikiOFGraph test set BLEU 69.27, ChrF++ 82.63, METEOR 51.59, TER 17.44, BLEURT 0.71, ROUGE-L 86.46, BERTScore-F1 98.29 (Table 3).",
            "impact_on_training": "Using serialized triplet sequences from the large WikiOFGraph corpus substantially improved T5-large G2T performance across automatic fluency and semantic metrics versus models trained on ontology-derived datasets or smaller human-crafted sets; Data-QuestEval curation of serialized triplet–text pairs further improved final model metrics (Table 5 shows gradual gains as curated:noise ratio increases).",
            "limitations": "Canonicalization and deterministic ordering not reported; average token length per instance not reported; relies on quality of LLM extraction (errors arise from incomplete sentences and ambiguous pronouns); potential data contamination because LLMs may have been pretrained on Wikipedia; serialization may omit graph-level structural cues beyond flat triplets (not explicitly addressed).",
            "comparison_with_other": "Outperforms ontology-aligned training corpora (GenWiki, TekGen, LAGRANGE) and small human-crafted WebNLG when used to fine-tune T5-large in this study, due to better graph–text consistency and larger scale; benefit amplified when combined with Data-QuestEval filtering.",
            "uuid": "e6985.0",
            "source_info": {
                "paper_title": "Ontology-Free General-Domain Knowledge Graph-to-Text Generation Dataset Synthesis using Large Language Model",
                "publication_date_yy_mm": "2024-09"
            }
        },
        {
            "name_short": "Ontology-aligned triplet datasets",
            "name_full": "Ontology-aligned graph triplet representations from DBpedia/Wikidata (e.g., GenWiki, TekGen, LAGRANGE, WebNLG)",
            "brief_description": "Automatically or semi-automatically derived graph representations produced by aligning Wikipedia text with existing ontologies (DBpedia, Wikidata) and representing knowledge as ontology triplets; typically serialized as triplet lists for G2T training but often suffer from graph–text misalignment.",
            "citation_title": "",
            "mention_or_use": "use",
            "representation_name": "Ontology-aligned triplet lists (ontology-based graphs)",
            "representation_description": "Graphs are represented as sets of ontology triples (subject, predicate, object) derived from knowledge bases (DBpedia, Wikidata) using alignment heuristics; these triplets are packaged into a textual or structured format (commonly serialized) for training graph-to-text models.",
            "representation_type": "sequential/token-based when serialized (triplet list); semantically lossless relative to the ontology but may be effectively lossy relative to target text meaning due to misalignment.",
            "encoding_method": "Ontology-driven extraction/distant supervision and alignment algorithms (matching Wikipedia spans/entities to ontology triples); datasets used include GenWiki (distant alignment), TekGen (Wikidata+Wikipedia distant supervision), LAGRANGE (aligned Wikidata/Wikipedia with augmentation), WebNLG (human-crafted from DBpedia).",
            "canonicalization": null,
            "average_token_length": null,
            "dataset_name": "GenWiki, TekGen, LAGRANGE, WebNLG (used as baselines in experiments)",
            "task_name": "graph-to-text generation (benchmark training/evaluation)",
            "model_name": "T5-large (770M) fine-tuned on each dataset as baseline comparisons",
            "model_description": "Same T5-large backbone as used for WikiOFGraph baselines; models were fine-tuned separately on each ontology-aligned dataset to compare downstream generation performance.",
            "performance_metric": "BLEU, ChrF++, METEOR, TER, BLEURT, ROUGE-L, BERTScore-F1 (same set as for serialized triplet experiments).",
            "performance_value": "Reported baseline results (Table 2, GenWiki test): WebNLG BLEU 35.97, GenWiki BLEU 36.14, TekGen BLEU 39.25, LAGRANGE BLEU 40.40. (Table 3, WikiOFGraph test): WebNLG BLEU 21.91, GenWiki BLEU 23.42, TekGen BLEU 38.45, LAGRANGE BLEU 39.37. These values show lower performance than models trained on WikiOFGraph in this study.",
            "impact_on_training": "When used to fine-tune T5-large, ontology-derived datasets produced weaker general-domain G2T performance compared to WikiOFGraph, largely attributed to graph-text misalignment and limited predicate/entity diversity for some datasets.",
            "limitations": "Frequently suffer from graph–text misalignment (texts contain information not present in ontology triplets and vice versa), limited predicate/expression variety tied to ontology vocabulary, and in some cases short/trivial triplets that map poorly to fluent text; these problems reduce downstream generation fidelity.",
            "comparison_with_other": "Compared to LLM-extracted serialized triplets (WikiOFGraph), ontology-aligned triplet datasets show more misalignment and lower downstream performance; WebNLG (human-crafted) has high alignment but small scale and limited domain diversity.",
            "uuid": "e6985.1",
            "source_info": {
                "paper_title": "Ontology-Free General-Domain Knowledge Graph-to-Text Generation Dataset Synthesis using Large Language Model",
                "publication_date_yy_mm": "2024-09"
            }
        },
        {
            "name_short": "Template-based linearization",
            "name_full": "Template-based predicate verbalization and slot-filling linearization",
            "brief_description": "Traditional method converting graph predicates into pre-defined textual templates that realize predicates and entities as filled slots; mentioned as a prior approach for G2T with low hallucination but limited flexibility and high engineering cost.",
            "citation_title": "",
            "mention_or_use": "mention",
            "representation_name": "Template-based triplet-to-text linearization",
            "representation_description": "Predicates and arguments are converted into human-crafted sentence templates (or fragments) which are concatenated/filled to form output text; templates map specific predicate labels to fixed natural language realizations.",
            "representation_type": "sequential, template-driven (rule-based); effectively lossless for intended content but rigid and limited in fluency and coverage.",
            "encoding_method": "Hand-crafted predicate-to-template mappings and slot-filling; not an algorithmic graph traversal but rule application per triplet or predicate group.",
            "canonicalization": null,
            "average_token_length": null,
            "dataset_name": "Mentioned historically (e.g., prior work such as Wiseman et al. etc.), not directly evaluated in this paper's experiments.",
            "task_name": "graph-to-text generation (rule/template baseline)",
            "model_name": "N/A (rule-based templates rather than learned LM)",
            "model_description": "Template methods produce text deterministically via rules; cited in background as contrast to neural/PLM-based approaches.",
            "performance_metric": "Not reported here; paper notes template methods have low hallucination but struggle with fluency and complex graphs.",
            "performance_value": null,
            "impact_on_training": "Not used for LM fine-tuning in this paper; referenced as low-hallucination baseline but less adaptable and labor-intensive to scale.",
            "limitations": "Requires manual effort to craft templates; brittle to predicate diversity and complex graph compositions; produces less fluent or natural outputs on complex inputs.",
            "comparison_with_other": "Compared to neural PLM fine-tuning on serialized triplets, templates reduce hallucination but cannot match fluency/scalability of learned models and are costly to design across many predicates/domains.",
            "uuid": "e6985.2",
            "source_info": {
                "paper_title": "Ontology-Free General-Domain Knowledge Graph-to-Text Generation Dataset Synthesis using Large Language Model",
                "publication_date_yy_mm": "2024-09"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "The WebNLG challenge: Generating text from RDF data",
            "rating": 2,
            "sanitized_title": "the_webnlg_challenge_generating_text_from_rdf_data"
        },
        {
            "paper_title": "GenWiki: A dataset of 1.3 million content-sharing text and graphs for unsupervised graph-to-text generation",
            "rating": 2,
            "sanitized_title": "genwiki_a_dataset_of_13_million_contentsharing_text_and_graphs_for_unsupervised_graphtotext_generation"
        },
        {
            "paper_title": "Knowledge graph based synthetic corpus generation for knowledge-enhanced language model pre-training",
            "rating": 1,
            "sanitized_title": "knowledge_graph_based_synthetic_corpus_generation_for_knowledgeenhanced_language_model_pretraining"
        },
        {
            "paper_title": "Construction of paired knowledge graph - text datasets informed by cyclic evaluation",
            "rating": 2,
            "sanitized_title": "construction_of_paired_knowledge_graph_text_datasets_informed_by_cyclic_evaluation"
        },
        {
            "paper_title": "Data-QuestEval: A referenceless metric for data-to-text semantic evaluation",
            "rating": 2,
            "sanitized_title": "dataquesteval_a_referenceless_metric_for_datatotext_semantic_evaluation"
        }
    ],
    "cost": 0.014031249999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Ontology-Free General-Domain Knowledge Graph-to-Text Generation Dataset Synthesis using Large Language Model</h1>
<p>Daehee Kim ${ }^{1}$, Deokhyung Kang ${ }^{1}$, Sangwon Ryu ${ }^{1}$ and Gary Geunbae Lee ${ }^{12}$<br>${ }^{1}$ Graduate School of Artificial Intelligence, POSTECH, South Korea<br>${ }^{2}$ Department of Computer Science and Engineering, POSTECH, South Korea<br>{andrea0119, deokhk, ryusangwon, gblee}@postech.ac.kr</p>
<h4>Abstract</h4>
<p>Knowledge Graph-to-Text (G2T) generation involves verbalizing structured knowledge graphs into natural language text. Recent advancements in Pretrained Language Models (PLMs) have improved G2T performance, but their effectiveness depends on datasets with precise graph-text alignment. However, the scarcity of high-quality, general-domain G2T generation datasets restricts progress in the generaldomain G2T generation research. To address this issue, we introduce Wikipedia OntologyFree Graph-text dataset (WikiOFGraph), a new large-scale G2T dataset generated using a novel method that leverages Large Language Model (LLM) and Data-QuestEval. Our new dataset, which contains 5.85 M general-domain graph-text pairs, offers high graph-text consistency without relying on external ontologies. Experimental results demonstrate that PLM fine-tuned on WikiOFGraph outperforms those trained on other datasets across various evaluation metrics. Our method proves to be a scalable and effective solution for generating high-quality G2T data, significantly advancing the field of G2T generation. ${ }^{1}$</p>
<h2>1 Introduction</h2>
<p>Knowledge Graph-to-Text Generation (G2T) is a task aimed at verbalizing knowledge graphs represented as a set of triplets in the form of (subject, predicate, object) into natural language text (Gatt and Krahmer, 2018; Lin et al., 2024). Recent advancements in Pretrained Language Models (PLMs), such as T5 (Raffel et al., 2020) and BART (Lewis et al., 2020) have led to significant improvement in G2T when fine-tuned on G2T datasets (Kale and Rastogi, 2020).</p>
<p>However, fine-tuning PLMs requires a substantial amount of well-aligned G2T data (Kasner</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: An example of a Graph-Text pair from existing ontology-based datasets. Although (a) and (b) are paired, the graph in (a) does not contain the information of the underlined text in (b), illustrating a common misalignment problem.
et al., 2023). Constructing G2T datasets is laborintensive and expensive because understanding structured graph representations for various natural language sentences is challenging for human annotators. Therefore, previous research has mainly focused on small-scale domain-specific datasets (Gardent et al., 2017; Koncel-Kedziorski et al., 2019; Castro Ferreira et al., 2020; Nan et al., 2021).</p>
<p>To address this issue, researchers have attempted to automatically align Wikipedia texts with their corresponding graphs from ontologies to construct large-scale, general-domain G2T datasets (Elsahar et al., 2018; Jin et al., 2020; Agarwal et al., 2021; Wang et al., 2021; Mousavi et al., 2024). However, ontology-based datasets often suffer from graphtext misalignment, making it challenging to generate text accurately. For example, in Figure 1 (b), the phrase "from 1899 to 1965 on the Strathspey railway" cannot be inferred solely from the graph shown in Figure 1 (a). Such discrepancy can be a major cause of the decline in G2T performance (Mousavi et al., 2024).</p>
<p>Recent advances in Large Language Models (LLMs) offer promising potential to address these challenges. Many studies have successfully lever-</p>
<p>aged LLMs to synthesize high-quality data for various tasks (Long et al., 2024). Several studies have attempted to generate graph-text paired data using LLMs (Josifoski et al., 2023; Han et al., 2024; Chen et al., 2024), but these attempts have yet to be thoroughly explored for the G2T generation task.</p>
<p>To address this issue, we introduce an effective method for generating high-quality G2T dataset that integrates LLM with Data-QuestEval (Rebuffel et al., 2021). We select three examples from the human-crafted dataset to facilitate In-Context Learning (ICL) for the LLM, enabling it to extract graph representations from the given sentences. To ensure high consistency between the extracted graph representations and text, we utilize DataQuestEval for data curation. Through this method, we create a new dataset called Wikipedia OntologyFree Graph-Text dataset (WikiOFGraph), a 5.85M G2T data that covers a broad range of Wikipedia articles without relying on ontologies.</p>
<p>Through comprehensive analyses, we demonstrate that our dataset achieves graph-text consistency comparable to that of a fully humancrafted dataset while significantly surpassing other ontology-based general-domain G2T datasets. Experimental results demonstrate that a PLM finetuned on WikiOFGraph outperforms those trained on existing datasets across the human expertcrafted GenWiki (Jin et al., 2020) test set and LLM-synthesized WikiOFGraph test set. This highlights the suitability of our dataset for building G2T systems that perform well across general domains, making it more effective than other datasets. We further demonstrate the effectiveness of DataQuestEval filtering through additional experiments. In summary, our key contributions are as follows:
(i) We introduce an effective method for synthesizing high-quality G2T dataset. Our approach is independent of proprietary LLMs or ontologies, making it reproducible and easily adaptable for various domains.
(ii) We release a new G2T generation dataset called WikiOFGraph. Our comprehensive analyses indicate that it offers high graph-text consistency, comparable to a human-crafted dataset, with 5.85 M samples covering the entire spectrum of Wikipedia.
(iii) We demonstrate the effectiveness of DataQuestEval filtering through additional experiments and case study.</p>
<h2>2 Background and Related Work</h2>
<p>Graph-to-Text generation Traditionally, researchers tackled G2T generation using templates designed to expressing predicates into pre-defined statements (Wiseman et al., 2018; Kasner and Dusek, 2022; Xiang et al., 2022; Vejvar and Fujimoto, 2023). Template-based approaches have low hallucination rates but are labor-intensive in creating various templates, and they often struggle with producing fluent sentences from complex graphs (Kasner and Dušek, 2020).</p>
<p>To address these limitations, researchers have leveraged neural encoder-decoder architectures (Wiseman et al., 2017; Beck et al., 2018; Nie et al., 2018; Puduppully et al., 2019; Iso et al., 2019) which convert graph representations into vector embeddings interpretable by neural models. Unlike previous approaches, these approaches leverage an end-to-end G2T generation paradigm that does not require pre-defined templates.</p>
<p>The introduction of transformer (Vaswani et al., 2017)-based PLMs has significantly advanced G2T generation, leading to much better performance than earlier methods. Kale and Rastogi demonstrated substantial improvements by fine-tuning these PLMs on G2T generation tasks. This strategy has since been adopted in subsequent studies (Ribeiro et al., 2021; Jolly et al., 2022; Mehta et al., 2022; Han and Shareghi, 2022). However, this new paradigm requires substantial amounts of wellaligned G2T data.</p>
<p>G2T generation datasets WebNLG (Gardent et al., 2017; Castro Ferreira et al., 2020) is a fully human-crafted dataset based on the DBpedia (Mendes et al., 2012), making it a representative benchmark for G2T generation tasks due to its precise graph-text alignment. However, creating human-crafted datasets is resource-intensive and limits scale. These limitations on scale and diversity have led researchers to develop large-scale G2T datasets automatically.</p>
<p>GenWiki (Jin et al., 2020) provides a large-scale, general-domain G2T dataset with 1.3 M samples. It includes fine and full splits, determined by the F1-score-based alignment between text and graph entities, and 1,000 human-crafted test samples. TekGen (Agarwal et al., 2021) combines Wikipedia and Wikidata (Vrandečić and Krötzsch, 2014) to create a large-scale, general-domain G2T dataset using a distant supervision strategy. This approach allowed for the creation of large datasets but led</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: Method for constructing the WikiOFGraph. Source sentences are collected from Wikipedia. Graph representations are then extracted using an LLM through in-context learning, guided by manually selected examples from the WebNLG. Data-QuestEval Filtering curates graph-text pairs compiled into the WikiOFGraph.</p>
<p>to insufficient alignment between graph representations and target texts. LAGRANGE (Mousavi et al., 2024), a 3.0M data, aligns Wikidata and Wikipedia data and incorporates second-hop reasoning and triplet augmentation.</p>
<p>However, these attempts rely on text aligning algorithms based on ontologies with insufficient information, leading to inadequate graph-text alignment. In contrast, our method generates graphs directly from the source text, better capturing the text's content. Our method is simple and scalable, enabling the creation of significantly larger datasets with greater domain diversity than existing ontology-based datasets.</p>
<h3>LLM-driven data generation</h3>
<p>The natural language processing community has recently shifted its focus toward synthesizing high-quality, large-scale data using LLMs (Long et al., 2024). While LLM-generated data is easily applicable to discriminative tasks (Whitehouse et al., 2023; Ghosh et al., 2024), its effectiveness in generative tasks diminishes when the distribution of the generated data differs from existing data (Ding et al., 2024).</p>
<p>While several studies have explored using LLMs for generating graph-text pairs, their primary focus has been on tasks such as Text-to-Graph (T2G) generation rather than on G2T generation (Josifoski et al., 2023; Han et al., 2024; Mousavi et al., 2024; Chen et al., 2024). In contrast, our research focuses on the LLM-driven synthetic graph generation for creating G2T generation dataset. Moreover, our approach leverages Data-QuestEval for data filtering, ensuring high graph-text consistency without manual or heuristic adjustments.</p>
<h2>3 WikiOFGraph</h2>
<p>In this section, we introduce a method for creating WikiOFGraph. We first define the requirements necessary to address the limitations of existing G2T datasets (§3.1). We then outline the rule-based algorithm for gathering source sentences from Wikipedia (§3.2), as well as the process of extracting graphs through LLM (§3.3). Additionally, we describe our approach to utilizing Data-QuestEval (Rebuffel et al., 2021) for curating well-aligned graph-text pairs (§3.4).</p>
<h3>3.1 Requirements</h3>
<h4>Graph-text consistency</h4>
<p>Good G2T data guarantees that the target text includes <em>"all"</em> and <em>"only"</em> information from the graph. If <em>"all"</em> information of the graph is not reflected in the target text, it can cause data omission problems for the model. If the target text does not include <em>"only"</em> information from the graph, it can cause hallucination problems for the model. Therefore, graph-text consistency is essential to prevent omission and hallucination problems in the G2T generation task.</p>
<h4>Domain diversity</h4>
<p>PLMs fine-tuned on datasets limited to a specific domain often struggle to handle samples from unseen domains (Keymanesh et al., 2022). This issue becomes apparent when PLMs are tested on new domains, where performance falls short compared to familiar domains (Castro Ferreira et al., 2020). Therefore, including a wide range of domains is crucial to developing a domain-adaptive G2T generation system.</p>
<h4>Large scale</h4>
<p>The demand for substantial structured datasets is growing with the emergence of</p>
<p>language models trained on extremely large-scale structured data (Zhuang et al., 2024; Li et al., 2024). High-quality structured data, such as knowledge graph representations, is essential for training LLMs for structured data processing. However, creating such data is far more challenging than compiling unstructured corpora. Consequently, providing a large-scale G2T dataset could be key to advancing LLMs in handling structured data effectively.</p>
<h3>3.2 Source Sentences Collection</h3>
<p>To meet the requirements (§3.1), we select Wikipedia as the source of sentences. Wikipedia includes sentences with extensive factual knowledge from diverse domains. We employ a rule-based algorithm to extract the first sentence from every article on English Wikipedia because the first sentence of a Wikipedia article often encapsulates vital factual information. We apply several constraints to enhance the clarity of the factual context in the source sentences. We limit the length of sentences to 10-500 characters, exclude sentences starting with pronouns to avoid ambiguous entity extraction (e.g., 'it,' 'that'), and remove parenthetical explanations to prevent redundant expressions. Through this process, we collect 6.06M source sentences, denoted as $Y=\left{y_{i}\right}_{i=1}^{n}$ in Figure 2, where $n$ represents the total number of source sentences.</p>
<h3>3.3 Graph Extraction</h3>
<p>We utilize the "Llama-3-70b-instruct-awq"2 (Dubey et al., 2024) to extract graph representations directly from $Y$. We manually select three examples from the WebNLG (Castro Ferreira et al., 2020) dataset for in-context examples ${ }^{3}$. We then obtain a set of graph representations for each sentence, denoted as $X=\left{\left{\left(s_{i j}, p_{i j}, o_{i j}\right)\right}<em i="i">{j=1}^{m</em>\right}}} \mid x_{i<em i="i">{i=1}^{n}$ in Figure 2. Here, $n$ represents the total number of sentences, $m</em>\right)$ are the subject, predicate, and object of the $j$-th triplet in the $i$-th sentence, respectively. Through this process, we obtain 6.06M pairs of source sentences and their corresponding generated graph representations.}$ denotes the number of triplets associated with the $i$-th sentence, and $\left(s_{i j}, p_{i j}, o_{i j</p>
<h3>3.4 Data-QuestEval Filtering</h3>
<p>Data-QuestEval (Rebuffel et al., 2021) is a framework that measures the accuracy of predicted texts</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup>in Data-to-Text generation tasks by combining question generation and question-answering techniques to evaluate whether the predicted sentence accurately reflects the content of the source data. Data-QuestEval supports referenceless evaluation by relying solely on the source data and the predicted sentence. We adapt referenceless evaluation by using the $X$ as the source data and the $Y$ as the predicted sentence.</p>
<p>We apply the referenceless Data-QuestEval scoring $f\left(x_{i}, y_{i}\right)$ to evaluate the consistency between the generated graph representations and their corresponding source sentences. Only pairs with a score of $f\left(x_{i}, y_{i}\right) \geq 0.3$ are retained for further curation, as denoted by $D=\left{\left(x_{i}, y_{i}\right) \mid f\left(x_{i}, y_{i}\right) \geq 0.3\right}_{i=1}^{n^{\prime}}$ in Figure 2, where $n^{\prime}$ represents the total number of curated graph-text pairs. Through this process, we obtain $5.95 \mathrm{M}^{4}$ samples, with less than $2 \%$ of the samples being filtered out. This result implies that a robust LLM can reliably extract graph representations containing "all" and "only" information from given texts.</p>
<h2>4 Data Analysis</h2>
<p>We compare WikiOFGraph with existing datasets. We explore the scale and domain diversity of the data through quantitative analysis (§4.1). We then assess the graph-text consistency using human evaluators and GPT-4o (OpenAI et al., 2024) (§4.2).</p>
<p>We utilize four representative G2T datasets for our comparative analysis: human-crafted WebNLG (Castro Ferreira et al., 2020) and three automatically generated ontology-based datasets-GenWiki ${ }^{5}$ (Jin et al., 2020), TekGen (Agarwal et al., 2021), and LAGRANGE (Mousavi et al., 2024). Details of the datasets are provided in the appendix (§Appendix D).</p>
<h3>4.1 Quantitative Analysis</h3>
<table>
<thead>
<tr>
<th>Dataset</th>
<th># samples</th>
<th># unique predicate</th>
<th># unique entity</th>
<th># triplet (m/M/avg)</th>
</tr>
</thead>
<tbody>
<tr>
<td>WebNLG</td>
<td>35 K</td>
<td>372</td>
<td>3.2 K</td>
<td>$1 / 7 / 2.96$</td>
</tr>
<tr>
<td>GenWiki</td>
<td>680 K</td>
<td>287</td>
<td>86.6 K</td>
<td>$1 / 10 / 2.84$</td>
</tr>
<tr>
<td>TekGen</td>
<td>$\mathbf{6 . 3 1 5 M}$</td>
<td>50,861</td>
<td>4.3 M</td>
<td>$1 / 54 / 1.73$</td>
</tr>
<tr>
<td>LAGRANGE</td>
<td>3.07 M</td>
<td>1,167</td>
<td>2.9 M</td>
<td>$1 / 135 / 4.02$</td>
</tr>
<tr>
<td>WikiOFGraph (Ours)</td>
<td>5.85 M</td>
<td>$\mathbf{1 4 0 . 7 3 3}$</td>
<td>$\mathbf{8 . 2 M}$</td>
<td>$1 / 17 / 3.62$</td>
</tr>
</tbody>
</table>
<p>Table 1: Training set statistics for comparative analysis. # triplet (m/M/avg) indicates the minimum, maximum, and average number of triplets per sample.</p>
<p><sup id="fnref:1"><a class="footnote-ref" href="#fn:1">2</a></sup> <sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup>: ${ }^{2}$ Available at: casperhansen/llama-3-70b-instruct-awq ${ }^{3}$ For implementation details, see the Appendix A</p>
<p>Domain diversity \&amp; dataset volume Table 1 provides a detailed comparison of statistics across various G2T datasets. WikiOFGraph includes a remarkably higher number of unique predicates and unique entities than other datasets. This diversity in predicates and entities is anticipated to enhance domain generalization in G2T generation tasks. In addition, WikiOFGraph is advantageous in terms of scale, containing a substantial 5.85 M data pairs, which makes it a valuable resource for future research in G2T generation tasks.</p>
<p>In contrast, WebNLG contains the smallest number of unique predicates, entities, and samples. This limitation is primarily due to its entirely human-crafted nature, which makes it challenging to produce a large volume of data.</p>
<p>GenWiki and LAGRANGE also have fewer unique predicates and entities. This is because the underlying ontology graphs in these datasets cover a relatively narrow scope. Also, these datasets are designed to support G2T and T2G generation tasks, limiting the variety of available predicate expressions.
<img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3: Normalized distribution of the number of triplets in each dataset.
<img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 4: Normalized distribution of the number of words in each dataset.</p>
<p>Statistical comparison of dataset compositions To provide more detailed comparisons, we conduct a statistical analysis of these datasets. Figure</p>
<p>3 shows the distribution of samples categorized by the number of triplets, while Figure 4 presents the distribution of samples categorized by word count in increments of five. WikiOFGraph demonstrates a balanced and consistent dataset structure, with the distribution of triplets and word counts closely aligning. The similarity in the shapes of these two distributions, which differs from those of other datasets, suggests a consistent alignment between the graph and the target text.</p>
<p>Despite TekGen showing good alignment between triplet and word count distributions, most of its samples consist of two or fewer triplets or contain fewer than ten words, indicating that most samples are relatively short. GenWiki predominantly consists of samples with three or fewer triplets; however, the relatively high proportion of samples with more than 20 words suggests a surface-level inconsistency between the graph representations and the corresponding texts.
<img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Figure 5: Average number of words per number of triplets across different datasets.</p>
<p>Average words per triplet We also visualize the average number of words per sample for each dataset, categorized by the number of triplets, as shown in Figure 5. WikiOFGraph exhibits an average word increase rate of 3.22 per triplet, which closely aligns with the average of 3.62 triplets per sample, as reported in Table 1. This suggests that WikiOFGraph provides consistent information with minimal bias relative to the number of triplets.</p>
<p>WebNLG exhibits a relatively high word increase rate of 5.76 per triplet compared to other datasets. However, this rate contrasts with the average of 2.96 triplets per sample, as reported in Table 1. This discrepancy arises because most WebNLG samples consist of short sentences and few triplets.</p>
<p>On the other hand, the automatically generated ontology-based datasets show much lower word increase rates per triplet, ranging from 0.87 to 1.66 .</p>
<p>These lower rates suggest that each triplet in these datasets is associated with fewer words, leading to less detailed representations per triplet.</p>
<h3>4.2 Qualitative Analysis</h3>
<p>To further analyze graph-text consistency, we conduct a qualitative analysis employing human and GPT-4o. We provide 30 samples per dataset, each evaluated by five human reviewers who assess the same set of samples, and an additional 1,000 samples per dataset are evaluated by GPT-4o. Since some datasets have a high ratio of samples with a low number of triplets, we categorize the samples by the number of triplets and randomly sample them within each range to ensure a diverse evaluation across different sample lengths.</p>
<p>Our focus is to assess whether the information of graph representations (triplets) are accurately reflected in the target text. To achieve this, we ask evaluators to review graph-text pairs and identify 1) unused triplets that are not used to generate the text and 2) parts of the text that could not be guessed from the triplets.
<img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Figure 6: Number of unused triplet ratio
<img alt="img-6.jpeg" src="img-6.jpeg" /></p>
<p>Figure 7: Length of unguessable text ratio
Graph-text consistency Figure 6 presents the average ratio of unused triplets across different datasets. The plain bars represent the evaluations
conducted by human evaluators, while the hatched bars indicate the assessment results from GPT-4o. When comparing automatically generated datasets, the average ratio of unused triplets is highest in GenWiki, followed by TekGen, LAGRANGE, and WikiOFGraph. Notably, WikiOFGraph is comparable to WebNLG, a fully human-crafted dataset. This observation suggests that WikiOFGraph incorporates triplet information into the text better than automaticaly generated ontology-based datasets.</p>
<p>Figure 7 presents the average ratio of unguessable text across different datasets. Similarly, GenWiki, TekGen, and LAGRANGE exhibit relatively high amounts of unguessable text, indicating a significant presence of text that cannot be generated from the graph information alone. In contrast, WikiOFGraph contains a low amount of unguessable text, even comparable to WebNLG. This observation suggests that WikiOFGraph has significantly higher graph-text consistency than automaticaly generated ontology-based G2T datasets. Details regarding the evaluation process can be found in the appendix (§Appendix B).</p>
<h2>5 Experiments</h2>
<p>We provide a comprehensive overview of our experimental setup and results. We first outline our experimental settings (§5.1). We then describe the evaluation metrics used to assess the model's G2T generation performance (§5.2). We describe the evaluation data selection, focusing on ensuring a broad topic range and high reliability (§5.3).</p>
<h3>5.1 Experimental Settings</h3>
<p>We choose the T5-large (Raffel et al., 2020), which has 770M parameters, for our backbone model. The backbone model is trained to take source triplets as input and predict a target text. We use special tokens such as ' $&lt;\mathrm{S}&gt;$ ', ' $&lt;\mathrm{P}&gt;$ ', and ' $&lt;\mathrm{O}&gt;$ ' to distinguish triplet elements. For example, a source triplets like "( $<S>$ Arròs negre $\mid<P>$ country $\mid<O>$ Spain), ( $<S>$ Spain $\mid<P>$ ethnic Group $\mid$ $<O>$ Spaniards)" is used to predict a target text such as "Arros negre is from Spain where Spaniards are an ethnic group." We utilize Huggingface's transformers (Wolf et al., 2020) library for our experiments. We use the cross-entropy loss function during training. Implementation details and hyperparameter settings are provided in the appendix (§Appendix C).</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;">BLEU (↑)</th>
<th style="text-align: center;">ChrF++ (↑)</th>
<th style="text-align: center;">METEOR (↑)</th>
<th style="text-align: center;">TER (↓)</th>
<th style="text-align: center;">BLEURT (↑)</th>
<th style="text-align: center;">ROUGE-L (↑)</th>
<th style="text-align: center;">BertScore-F1 (↑)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">WebNLG</td>
<td style="text-align: center;">35.97</td>
<td style="text-align: center;">65.76</td>
<td style="text-align: center;">39.69</td>
<td style="text-align: center;">49.71</td>
<td style="text-align: center;">0.44</td>
<td style="text-align: center;">64.41</td>
<td style="text-align: center;">95.56</td>
</tr>
<tr>
<td style="text-align: center;">GenWiki</td>
<td style="text-align: center;">36.14</td>
<td style="text-align: center;">56.96</td>
<td style="text-align: center;">33.80</td>
<td style="text-align: center;">89.77</td>
<td style="text-align: center;">0.13</td>
<td style="text-align: center;">58.13</td>
<td style="text-align: center;">92.85</td>
</tr>
<tr>
<td style="text-align: center;">TekGen</td>
<td style="text-align: center;">39.25</td>
<td style="text-align: center;">63.43</td>
<td style="text-align: center;">38.19</td>
<td style="text-align: center;">75.15</td>
<td style="text-align: center;">0.30</td>
<td style="text-align: center;">64.16</td>
<td style="text-align: center;">94.13</td>
</tr>
<tr>
<td style="text-align: center;">LAGRANGE</td>
<td style="text-align: center;">40.40</td>
<td style="text-align: center;">67.51</td>
<td style="text-align: center;">40.70</td>
<td style="text-align: center;">47.15</td>
<td style="text-align: center;">0.43</td>
<td style="text-align: center;">65.26</td>
<td style="text-align: center;">95.71</td>
</tr>
<tr>
<td style="text-align: center;">WikiOFGraph (Ours)</td>
<td style="text-align: center;">$\mathbf{4 5 . 8 5}$</td>
<td style="text-align: center;">$\mathbf{6 9 . 6 1}$</td>
<td style="text-align: center;">$\mathbf{4 2 . 1 7}$</td>
<td style="text-align: center;">$\mathbf{4 3 . 3 8}$</td>
<td style="text-align: center;">0.46</td>
<td style="text-align: center;">$\mathbf{7 0 . 1 0}$</td>
<td style="text-align: center;">$\mathbf{9 5 . 8 9}$</td>
</tr>
</tbody>
</table>
<p>Table 2: Evaluation result on GenWiki test set.</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;">BLEU (↑)</th>
<th style="text-align: center;">ChrF++ (↑)</th>
<th style="text-align: center;">METEOR (↑)</th>
<th style="text-align: center;">TER (↓)</th>
<th style="text-align: center;">BLEURT (↑)</th>
<th style="text-align: center;">ROUGE-L (↑)</th>
<th style="text-align: center;">BertScore-F1 (↑)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">WebNLG</td>
<td style="text-align: center;">21.91</td>
<td style="text-align: center;">35.97</td>
<td style="text-align: center;">39.69</td>
<td style="text-align: center;">49.71</td>
<td style="text-align: center;">0.44</td>
<td style="text-align: center;">62.88</td>
<td style="text-align: center;">93.81</td>
</tr>
<tr>
<td style="text-align: center;">GenWiki</td>
<td style="text-align: center;">23.42</td>
<td style="text-align: center;">48.30</td>
<td style="text-align: center;">33.17</td>
<td style="text-align: center;">74.89</td>
<td style="text-align: center;">0.14</td>
<td style="text-align: center;">61.92</td>
<td style="text-align: center;">92.14</td>
</tr>
<tr>
<td style="text-align: center;">TekGen</td>
<td style="text-align: center;">38.45</td>
<td style="text-align: center;">62.28</td>
<td style="text-align: center;">41.39</td>
<td style="text-align: center;">55.01</td>
<td style="text-align: center;">0.45</td>
<td style="text-align: center;">73.08</td>
<td style="text-align: center;">94.62</td>
</tr>
<tr>
<td style="text-align: center;">LAGRANGE</td>
<td style="text-align: center;">39.37</td>
<td style="text-align: center;">63.33</td>
<td style="text-align: center;">42.85</td>
<td style="text-align: center;">46.04</td>
<td style="text-align: center;">0.51</td>
<td style="text-align: center;">74.68</td>
<td style="text-align: center;">95.08</td>
</tr>
<tr>
<td style="text-align: center;">WikiOFGraph (Ours)</td>
<td style="text-align: center;">$\mathbf{6 9 . 2 7}$</td>
<td style="text-align: center;">$\mathbf{8 2 . 6 3}$</td>
<td style="text-align: center;">$\mathbf{5 1 . 5 9}$</td>
<td style="text-align: center;">$\mathbf{1 7 . 4 4}$</td>
<td style="text-align: center;">$\mathbf{0 . 7 1}$</td>
<td style="text-align: center;">$\mathbf{8 6 . 4 6}$</td>
<td style="text-align: center;">$\mathbf{9 8 . 2 9}$</td>
</tr>
</tbody>
</table>
<p>Table 3: Evaluation result on WikiOFGraph test setin.</p>
<h3>5.2 Evaluation Metrics</h3>
<p>We employ representative metrics commonly used to evaluate the performance of G2T generation tasks. We utilize several metrics, including BLEU (Papineni et al., 2002), METEOR (Banerjee and Lavie, 2005), ChrF++ (Popović, 2015), TER (Snover et al., 2006), BLEURT (Sellam et al., 2020) and ROUGE-L (Lin, 2004), specifically to evaluate the fluency of the predicted sentences. To assess semantic accuracy, we employ BERTScore-F1 (Zhang et al., 2020).</p>
<h3>5.3 Evaluation Data Selection</h3>
<p>We utilize evaluation datasets that cover a broad range of topics while maintaining high reliability to assess the model's general domain G2T capabilities. First, we choose the GenWiki(Jin et al., 2020) test set, consisting of 1,000 samples generated by human experts, for its high level of trustworthiness. Next, we select 100,000 samples from the WikiOFGraph dataset not included in the training split as an additional evaluation dataset. Although WikiOFGraph consists of synthesized data, our earlier analyses indicate that it possesses high domain diversity and strong graph-text consistency. This makes it an appropriate choice for evaluating the model's G2T generation capabilities in the general domain.</p>
<h2>6 Results and Discussions</h2>
<p>Table 2 and 3 present the performances of the T5large model fine-tuned on five different datasets, with the best values highlighted in bold. The results demonstrate that fine-tuning with WikiOF-</p>
<p>Graph consistently achieves the highest performance across various metrics on both test sets.</p>
<p>Training on domain-specific, human-crafted datasets like WebNLG leads to lower performance in general domain G2T generation tasks due to the limited size and narrow coverage of the training data. On the other hand, training on datasets that cover a broader range of domains but are automatically generated based on ontology also leads to lower performance due to reduced graph-to-text consistency. This highlights the importance of dataset scale, domain diversity, and graph-text consistency in achieving robust performance in general domain G2T generation as mentioned in $\S 3.1$.</p>
<p>Table 3 highlights a more apparent performance gap between the T5-large model fine-tuned on WikiOFGraph and those fine-tuned on other datasets. This performance gap is anticipated due to the similar distribution of test samples to WikiOFGraph, yet the difference is considerably significant. These results demonstrate that WikiOFGraph is significantly more effective than other G2T datasets for general domain G2T generation.</p>
<h2>7 Effectiveness of Data-QuestEval</h2>
<p>Due to the extremely low ratio of filtered samples (less than 2\%), observing significant performance differences from Data-QuestEval curation is challenging. To further investigate the impact of DataQuestEval, we conduct additional experiments with controlled sample sizes (\$7.1). We then conduct a case study to verify whether Data-QuestEval effectively excludes misaligned graph-text pairs (\$7.2).</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Status</th>
<th style="text-align: center;">Graph Representations</th>
<th style="text-align: center;">Text</th>
<th style="text-align: center;">Data-QuestEval Score</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Incomplete Text Error</td>
<td style="text-align: center;">(<S>Piano sonata no.</td>
<td style="text-align: center;"><P>Type</td>
<td style="text-align: center;"><O>Music composition)</td>
</tr>
<tr>
<td style="text-align: center;">Incomplete Text Error</td>
<td style="text-align: center;">(<S>Dibs crane tank</td>
<td style="text-align: center;"><P>Modell <O>No.)</td>
<td style="text-align: center;">Dibs crane tank No.</td>
</tr>
<tr>
<td style="text-align: center;">Ambiguous Pronoun Error</td>
<td style="text-align: center;">(<S>Mel-2</td>
<td style="text-align: center;"><P>Round</td>
<td style="text-align: center;"><O>Qualification round)</td>
</tr>
<tr>
<td style="text-align: center;">Ambiguous Pronoun Error</td>
<td style="text-align: center;">(<S>0</td>
<td style="text-align: center;"><P>Name</td>
<td style="text-align: center;"><O>O) <br> (<S>0</td>
</tr>
<tr>
<td style="text-align: center;">Properly Generated</td>
<td style="text-align: center;">(<S>Domenico Puccini</td>
<td style="text-align: center;"><P>studied Under</td>
<td style="text-align: center;"><O>Giovanni Paisiello)</td>
</tr>
<tr>
<td style="text-align: center;">Properly Generated</td>
<td style="text-align: center;">(<S>Dennis Hamilton</td>
<td style="text-align: center;"><P>signed Data</td>
<td style="text-align: center;"><O>October 21, 1967) <br> (<S>Dennis Hamilton</td>
</tr>
<tr>
<td style="text-align: center;">Properly Generated</td>
<td style="text-align: center;">(<S>Double Hill Station</td>
<td style="text-align: center;"><P>location</td>
<td style="text-align: center;"><O>up the Rakaia River)</td>
</tr>
</tbody>
</table>
<p>Table 4: Examples of Graph-Text pairs with corresponding Data-QuestEval Scores, ranging from 0 to 1. Text highlighted in red indicates potential errors or areas of concern.</p>
<h3>7.1 Impact of Filtered Sample Ratios</h3>
<table>
<thead>
<tr>
<th style="text-align: center;">Curated:Noise</th>
<th style="text-align: center;">BLEU ( $\uparrow$ )</th>
<th style="text-align: center;">METEOR ( $\uparrow$ )</th>
<th style="text-align: center;">Rouge-L ( $\uparrow$ )</th>
<th style="text-align: center;">BertScore-F1 ( $\uparrow$ )</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">0:100</td>
<td style="text-align: center;">43.21</td>
<td style="text-align: center;">40.62</td>
<td style="text-align: center;">66.11</td>
<td style="text-align: center;">95.56</td>
</tr>
<tr>
<td style="text-align: center;">25:75</td>
<td style="text-align: center;">44.25</td>
<td style="text-align: center;">41.01</td>
<td style="text-align: center;">67.47</td>
<td style="text-align: center;">95.79</td>
</tr>
<tr>
<td style="text-align: center;">50:50</td>
<td style="text-align: center;">44.57</td>
<td style="text-align: center;">41.22</td>
<td style="text-align: center;">67.88</td>
<td style="text-align: center;">95.77</td>
</tr>
<tr>
<td style="text-align: center;">75:25</td>
<td style="text-align: center;">44.75</td>
<td style="text-align: center;">41.16</td>
<td style="text-align: center;">68.38</td>
<td style="text-align: center;">95.83</td>
</tr>
<tr>
<td style="text-align: center;">100:0</td>
<td style="text-align: center;">$\mathbf{4 5 . 0 0}$</td>
<td style="text-align: center;">$\mathbf{4 1 . 3 7}$</td>
<td style="text-align: center;">$\mathbf{6 9 . 3 2}$</td>
<td style="text-align: center;">$\mathbf{9 6 . 0 0}$</td>
</tr>
</tbody>
</table>
<p>Table 5: Impact of Curated:Noise sample ratios on model performance.</p>
<p>We define 'curated' samples as those scoring 0.3 or higher in the Data-QuestEval filtering, while samples scoring below 0.3 are classified as 'noise'. We randomly select these 'curated' samples from WikiOFGraph, while the 'noise' samples are from the filtered-out samples. Given WikiOFGraph's large scale, increasing the ratio of noise directly in the dataset is challenging. Therefore, we fix the train split at 50,000 samples and vary the ratio of 'curated' to 'noise' samples. The experimental settings used for these experiments follows the procedure outlined in $\S 5.1$.</p>
<p>As shown in Table 5, the evaluation result of the fine-tuned T5-large model improves proportionally as the ratio of curated samples increases. Notably, all key metrics-including BLEU, METEOR, Rouge-L, and BertScore-F1-exhibit consistent improvement, indicating a comprehensive enhancement in model performance. This result indicates that our approach to measuring graphtext consistency through Data-QuestEval filtering is effective and highly practical, particularly in scenarios with limited access to high-quality training data.</p>
<h3>7.2 Case Study</h3>
<p>We conduct a case study to understand the low graph-text consistency problems in samples filtered-out by Data-QuestEval. Through the case study, we recognize that the filtered-out samples
exhibit two representative types of problems. We highlight these error types with examples along with their corresponding Data-QuestEval scores in Table 4.</p>
<p>The first error type arises from incomplete source sentences. For instance, a sentence like "Piano Sonata No. 1, the default title for a composer's first (or only) piano sonata, may refer to:" can be split as an incomplete sentence such as "Piano Sonata No." due to its punctuation mark, which causes confusion in the sentence splitter. These incomplete sentences make it difficult to extract graph representations accurately.</p>
<p>The second error type occurs due to the use of ambiguous demonstratives or pronouns in the source sentence. Sentences containing demonstratives like "This" or other ambiguous pronouns make it challenging to determine the subject-object structure accurately.</p>
<p>Lastly, we observe that most well-structured sentences, like "October 21, 1967 The Los Angeles Lakers signed Dennis Hamilton as a free agent.", generally result in consistent graph representations.</p>
<p>These results highlight the importance of using complete and unambiguous sentences for graph extraction while demonstrating that Data-QuestEval filtering effectively identifies 'noise' samples from the G2T dataset.</p>
<h2>8 Conclusion</h2>
<p>This study introduces WikiOFGraph, a large-scale G2T generation dataset with 5.85 M samples covering the entire Wikipedia domain. To address the issue of graph-text misalignment commonly found in ontology-based datasets, we propose a novel method leveraging LLM and Data-QuestEval to generate high-quality graph-text pairs. Comprehensive analyses reveal that WikiOFGraph achieves graph-text consistency comparable to the fully human-crafted dataset, while also exhibiting large</p>
<p>scale and extensive domain diversity. Comparisons with representative G2T datasets demonstrate that fine-tuning PLMs with WikiOFGraph significantly enhances their ability to perform general domain G2T tasks. Additional experiments and a case study demonstrate the effectiveness of Data-QuestEval in ensuring high-quality graphtext alignments, reinforcing its value in data curation. Our approach provides a scalable and efficient method for generating high-quality G2T data without relying on proprietary LLMs, external ontologies or extensive human involvement, making it reproducible for advancing G2T generation.</p>
<h2>Acknowledgements</h2>
<p>This work was supported by Smart HealthCare Program(www.kipot.or.kr) funded by the Korean National Police Agency(KNPA, Korea) [Project Name: Development of an Intelligent Big Data Integrated Platform for Police Officers’ Personalized Healthcare / Project Number: 220222M01].</p>
<p>This research was supported by the MSIT(Ministry of Science and ICT), Korea, under the ITRC(Information Technology Research Center) support program(IITP-2024-2020-001789) supervised by the IITP(Institute for Information \&amp; Communications Technology Planning \&amp; Evaluation).</p>
<h2>Limitations</h2>
<p>Multilingual extension Although our method is easily reproducible across various domains using open-source LLMs and public source texts, the scope of our study focuses mainly on English. Future research could extend the study's multilingual capabilities by employing LLMs with multilingual capabilities and utilizing source texts from multilingual corpora.</p>
<p>Room for improvement We apply various empirical rules of thumb, particularly in areas such as prompt engineering and sampling strategies. While our approach significantly outperforms existing datasets in meeting key requirements, there remains room for improvement, particularly in refining prompts, optimizing sampling parameters for graph extraction, and selecting the most effective LLM. Additionally, since Data-QuestEval might not be the most optimal measure, exploring alternative methods to assess the consistency between the generated graph representations and the source text could be a valuable direction for future work.</p>
<p>Expanding directions Our work focuses primarily on the direction of G2T generation. Building a dataset that also supports T2G generation poses challenges, such as the need to select predicate expressions from a predefined vocabulary, which could limit flexibility. Future work could address this by reassigning predicate expressions within the WikiOFGraph dataset, potentially creating a more adaptable framework for T2G tasks.</p>
<p>Data contamination concerns One important limitation not yet addressed in our study is the potential for data contamination. Since the LLMs used in our experiments are pre-trained on publicly accessible datasets like Wikipedia, they may already be familiar with the data used in our graph extraction tasks. To thoroughly assess whether our method is robust against data contamination, future research should replicate our experiments on a large corpus that is not part of the LLM's pretraining data.</p>
<h2>Ethical Considerations</h2>
<p>We prioritize transparency and reproducibility in our research by using widely accessible resources. We utilize the open-source LLM Llama3-70b-instruct-awq ${ }^{6}$ and the publicly available Wikipedia ${ }^{7}$ dataset, adhering to their respective licenses.</p>
<p>For human evaluation, we conduct the assessments through Upwork ${ }^{8}$, ensuring participants receive appropriate compensation for their efforts. Each evaluator is paid a fixed rate of $\$ 60$ for their work, which involves evaluating five datasets for approximately three hours. This compensation is determined to be fair and in line with industry standards, reflecting our commitment to ethical research practices and the fair treatment of participants.</p>
<h2>References</h2>
<p>Oshin Agarwal, Heming Ge, Siamak Shakeri, and Rami Al-Rfou. 2021. Knowledge graph based synthetic corpus generation for knowledge-enhanced language</p>
<p><sup id="fnref4:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>model pre-training. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 3554-3565, Online. Association for Computational Linguistics.</p>
<p>Satanjeev Banerjee and Alon Lavie. 2005. METEOR: An automatic metric for MT evaluation with improved correlation with human judgments. In Proceedings of the ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization, pages 65-72, Ann Arbor, Michigan. Association for Computational Linguistics.</p>
<p>Daniel Beck, Gholamreza Haffari, and Trevor Cohn. 2018. Graph-to-sequence learning using gated graph neural networks. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 273-283, Melbourne, Australia. Association for Computational Linguistics.</p>
<p>Thiago Castro Ferreira, Claire Gardent, Nikolai Ilinykh, Chris van der Lee, Simon Mille, Diego Moussallem, and Anastasia Shimorina. 2020. The 2020 bilingual, bi-directional WebNLG+ shared task: Overview and evaluation results (WebNLG+ 2020). In Proceedings of the 3rd International Workshop on Natural Language Generation from the Semantic Web (WebNLG+), pages 55-76, Dublin, Ireland (Virtual). Association for Computational Linguistics.</p>
<p>Hanzhu Chen, Xu Shen, Qitan Lv, Jie Wang, Xiaoqi Ni, and Jieping Ye. 2024. SAC-KG: Exploiting large language models as skilled automatic constructors for domain knowledge graph. In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 43454360, Bangkok, Thailand. Association for Computational Linguistics.</p>
<p>Bosheng Ding, Chengwei Qin, Ruochen Zhao, Tianze Luo, Xinze Li, Guizhen Chen, Wenhan Xia, Junjie Hu, Anh Tuan Luu, and Shafiq Joty. 2024. Data augmentation using large language models: Data perspectives, learning paradigms and challenges.</p>
<p>Abhimanyu Dubey et al. 2024. The llama 3 herd of models.</p>
<p>Hady Elsahar, Pavlos Vougiouklis, Arslen Remaci, Christophe Gravier, Jonathon Hare, Frederique Laforest, and Elena Simperl. 2018. T-REx: A large scale alignment of natural language with knowledge base triples. In Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018), Miyazaki, Japan. European Language Resources Association (ELRA).</p>
<p>Claire Gardent, Anastasia Shimorina, Shashi Narayan, and Laura Perez-Beltrachini. 2017. The WebNLG challenge: Generating text from RDF data. In Proceedings of the 10th International Conference on</p>
<p>Natural Language Generation, pages 124-133, Santiago de Compostela, Spain. Association for Computational Linguistics.</p>
<p>Albert Gatt and Emiel Krahmer. 2018. Survey of the state of the art in natural language generation: core tasks, applications and evaluation. J. Artif. Int. Res., 61(1):65-170.</p>
<p>Sreyan Ghosh, Utkarsh Tyagi, Sonal Kumar, Chandra Kiran Evuru, Ramaneswaran S, S Sakshi, and Dinesh Manocha. 2024. ABEX: Data augmentation for low-resource NLU via expanding abstract descriptions. In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 726-748, Bangkok, Thailand. Association for Computational Linguistics.</p>
<p>Jiuzhou Han, Nigel Collier, Wray Buntine, and Ehsan Shareghi. 2024. PiVe: Prompting with iterative verification improving graph-based generative capability of LLMs. In Findings of the Association for Computational Linguistics ACL 2024, pages 6702-6718, Bangkok, Thailand and virtual meeting. Association for Computational Linguistics.</p>
<p>Jiuzhou Han and Ehsan Shareghi. 2022. Self-supervised graph masking pre-training for graph-to-text generation. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 4845-4853, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.</p>
<p>Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes, and Yejin Choi. 2020. The curious case of neural text degeneration. In 8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020. OpenReview.net.</p>
<p>Hayate Iso, Yui Uehara, Tatsuya Ishigaki, Hiroshi Noji, Eiji Aramaki, Ichiro Kobayashi, Yusuke Miyao, Naoaki Okazaki, and Hiroya Takamura. 2019. Learning to select, track, and generate for data-to-text. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 21022113, Florence, Italy. Association for Computational Linguistics.</p>
<p>Zhijing Jin, Qipeng Guo, Xipeng Qiu, and Zheng Zhang. 2020. GenWiki: A dataset of 1.3 million contentsharing text and graphs for unsupervised graph-totext generation. In Proceedings of the 28th International Conference on Computational Linguistics, pages 2398-2409, Barcelona, Spain (Online). International Committee on Computational Linguistics.</p>
<p>Shailza Jolly, Zi Zhang, Andreas Dengel, and Lili Mou. 2022. Search and learn: Improving semantic coverage for data-to-text generation. Proceedings of the AAAI Conference on Artificial Intelligence, 36:1085810866.</p>
<p>Martin Josifoski, Marija Sakota, Maxime Peyrard, and Robert West. 2023. Exploiting asymmetry for synthetic training data generation: SynthIE and the case</p>
<p>of information extraction. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 1555-1574, Singapore. Association for Computational Linguistics.</p>
<p>Mihir Kale and Abhinav Rastogi. 2020. Text-to-text pre-training for data-to-text tasks. In Proceedings of the 13th International Conference on Natural Language Generation, pages 97-102, Dublin, Ireland. Association for Computational Linguistics.</p>
<p>Zdeněk Kasner and Ondřej Dušek. 2020. Data-to-text generation with iterative text editing. In Proceedings of the 13th International Conference on Natural Language Generation, pages 60-67, Dublin, Ireland. Association for Computational Linguistics.</p>
<p>Zdeněk Kasner and Ondrej Dusek. 2022. Neural pipeline for zero-shot data-to-text generation. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 3914-3932, Dublin, Ireland. Association for Computational Linguistics.</p>
<p>Zdeněk Kasner, Ioannis Konstas, and Ondrej Dusek. 2023. Mind the labels: Describing relations in knowledge graphs with pretrained models. In Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics, pages 2398-2415, Dubrovnik, Croatia. Association for Computational Linguistics.</p>
<p>Moniba Keymanesh, Adrian Benton, and Mark Dredze. 2022. What makes data-to-text generation hard for pretrained language models? In Proceedings of the 2nd Workshop on Natural Language Generation, Evaluation, and Metrics (GEM), pages 539-554, Abu Dhabi, United Arab Emirates (Hybrid). Association for Computational Linguistics.</p>
<p>Rik Koncel-Kedziorski, Dhanush Bekal, Yi Luan, Mirella Lapata, and Hannaneh Hajishirzi. 2019. Text Generation from Knowledge Graphs with Graph Transformers. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 2284-2293, Minneapolis, Minnesota. Association for Computational Linguistics.</p>
<p>Woosuk Kwon, Zhuohan Li, Siyuan Zhuang, Ying Sheng, Lianmin Zheng, Cody Hao Yu, Joseph Gonzalez, Hao Zhang, and Ion Stoica. 2023. Efficient memory management for large language model serving with pagedattention. In Proceedings of the 29th Symposium on Operating Systems Principles, SOSP '23, page 611-626, New York, NY, USA. Association for Computing Machinery.</p>
<p>Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, and Luke Zettlemoyer. 2020. BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,
pages 7871-7880, Online. Association for Computational Linguistics.</p>
<p>Shujie Li, Liang Li, Ruiying Geng, Min Yang, Binhua Li, Guanghu Yuan, Wanwei He, Shao Yuan, Can Ma, Fei Huang, and Yongbin Li. 2024. Unifying structured data as graph for data-to-text pre-training. Transactions of the Association for Computational Linguistics, 12:210-228.</p>
<p>Chin-Yew Lin. 2004. ROUGE: A package for automatic evaluation of summaries. In Text Summarization Branches Out, pages 74-81, Barcelona, Spain. Association for Computational Linguistics.</p>
<p>Yupian Lin, Tong Ruan, Jingping Liu, and Haofen Wang. 2024. A survey on neural data-to-text generation. IEEE Transactions on Knowledge and Data Engineering, 36(4):1431-1449.</p>
<p>Lin Long, Rui Wang, Ruixuan Xiao, Junbo Zhao, Xiao Ding, Gang Chen, and Haobo Wang. 2024. On LLMs-driven synthetic data generation, curation, and evaluation: A survey. In Findings of the Association for Computational Linguistics ACL 2024, pages 11065-11082, Bangkok, Thailand and virtual meeting. Association for Computational Linguistics.</p>
<p>Ilya Loshchilov and Frank Hutter. 2019. Decoupled weight decay regularization. In 7th International Conference on Learning Representations, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019. OpenReview.net.</p>
<p>Sanket Vaibhav Mehta, Jinfeng Rao, Yi Tay, Mihir Kale, Ankur Parikh, and Emma Strubell. 2022. Improving compositional generalization with self-training for data-to-text generation. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 42054219, Dublin, Ireland. Association for Computational Linguistics.</p>
<p>Pablo Mendes, Max Jakob, and Christian Bizer. 2012. DBpedia: A multilingual cross-domain knowledge base. In Proceedings of the Eighth International Conference on Language Resources and Evaluation (LREC'12), pages 1813-1817, Istanbul, Turkey. European Language Resources Association (ELRA).</p>
<p>Ali Mousavi, Xin Zhan, He Bai, Peng Shi, Theodoros Rekatsinas, Benjamin Han, Yunyao Li, Jeffrey Pound, Joshua M. Susskind, Natalie Schluter, Ihab F. Ilyas, and Navdeep Jaitly. 2024. Construction of paired knowledge graph - text datasets informed by cyclic evaluation. In Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LRECCOLING 2024), pages 3782-3803, Torino, Italia. ELRA and ICCL.</p>
<p>Linyong Nan, Dragomir Radev, Rui Zhang, Amrit Rau, Abhinand Sivaprasad, Chiachun Hsieh, Xiangru Tang, Aadit Vyas, Neha Verma, Pranav Krishna, Yangxiaokang Liu, Nadia Irwanto, Jessica Pan, Faiaz Rahman, Ahmad Zaidi, Mutethia Mutuma,</p>
<p>Yasin Tarabar, Ankit Gupta, Tao Yu, Yi Chern Tan, Xi Victoria Lin, Caiming Xiong, Richard Socher, and Nazneen Fatema Rajani. 2021. DART: Opendomain structured data record to text generation. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 432-447, Online. Association for Computational Linguistics.</p>
<p>Feng Nie, Jinpeng Wang, Jin-Ge Yao, Rong Pan, and Chin-Yew Lin. 2018. Operation-guided neural networks for high fidelity data-to-text generation. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 38793889, Brussels, Belgium. Association for Computational Linguistics.</p>
<p>OpenAI et al. 2024. Gpt-4 technical report.
Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. Bleu: a method for automatic evaluation of machine translation. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pages 311-318, Philadelphia, Pennsylvania, USA. Association for Computational Linguistics.</p>
<p>Maja Popović. 2015. chrF: character n-gram F-score for automatic MT evaluation. In Proceedings of the Tenth Workshop on Statistical Machine Translation, pages 392-395, Lisbon, Portugal. Association for Computational Linguistics.</p>
<p>Ratish Puduppully, Li Dong, and Mirella Lapata. 2019. Data-to-text generation with content selection and planning. Proceedings of the AAAI Conference on Artificial Intelligence, 33(01):6908-6915.</p>
<p>Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. 2020. Exploring the limits of transfer learning with a unified text-to-text transformer. Journal of Machine Learning Research, 21(140):1-67.</p>
<p>Jeff Rasley, Samyam Rajbhandari, Olatunji Ruwase, and Yuxiong He. 2020. Deepspeed: System optimizations enable training deep learning models with over 100 billion parameters. In Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery \&amp; Data Mining, KDD '20, page 3505-3506, New York, NY, USA. Association for Computing Machinery.</p>
<p>Clement Rebuffel, Thomas Scialom, Laure Soulier, Benjamin Piwowarski, Sylvain Lamprier, Jacopo Staiano, Geoffrey Scoutheeten, and Patrick Gallinari. 2021. Data-QuestEval: A referenceless metric for data-to-text semantic evaluation. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 8029-8036, Online and Punta Cana, Dominican Republic. Association for Computational Linguistics.</p>
<p>Leonardo F. R. Ribeiro, Martin Schmitt, Hinrich Schütze, and Iryna Gurevych. 2021. Investigating pretrained language models for graph-to-text generation. In Proceedings of the 3rd Workshop on Natural Language Processing for Conversational AI, pages 211-227, Online. Association for Computational Linguistics.</p>
<p>Thibault Sellam, Dipanjan Das, and Ankur Parikh. 2020. BLEURT: Learning robust metrics for text generation. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 7881-7892, Online. Association for Computational Linguistics.</p>
<p>Matthew Snover, Bonnie Dorr, Rich Schwartz, Linnea Micciulla, and John Makhoul. 2006. A study of translation edit rate with targeted human annotation. In Proceedings of the 7th Conference of the Association for Machine Translation in the Americas: Technical Papers, pages 223-231, Cambridge, Massachusetts, USA. Association for Machine Translation in the Americas.</p>
<p>Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Ł ukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in Neural Information Processing Systems, volume 30. Curran Associates, Inc.</p>
<p>Martin Vejvar and Yasutaka Fujimoto. 2023. ASPIRO: Any-shot structured parsing-error-induced ReprOmpting for consistent data-to-text generation. In Findings of the Association for Computational Linguistics: EMNLP 2023, pages 3550-3563, Singapore. Association for Computational Linguistics.</p>
<p>Denny Vrandečić and Markus Krötzsch. 2014. Wikidata: a free collaborative knowledgebase. Commun. ACM, 57(10):78-85.</p>
<p>Luyu Wang, Yujia Li, Ozlem Aslan, and Oriol Vinyals. 2021. WikiGraphs: A Wikipedia text - knowledge graph paired dataset. In Proceedings of the Fifteenth Workshop on Graph-Based Methods for Natural Language Processing (TextGraphs-15), pages 67-82, Mexico City, Mexico. Association for Computational Linguistics.</p>
<p>Chenxi Whitehouse, Monojit Choudhury, and Alham Fikri Aji. 2023. LLM-powered data augmentation for enhanced cross-lingual performance. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 671686, Singapore. Association for Computational Linguistics.</p>
<p>Sam Wiseman, Stuart Shieber, and Alexander Rush. 2017. Challenges in data-to-document generation. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 2253-2263, Copenhagen, Denmark. Association for Computational Linguistics.</p>
<p>Sam Wiseman, Stuart Shieber, and Alexander Rush. 2018. Learning neural templates for text generation.</p>
<p>In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 3174-3187, Brussels, Belgium. Association for Computational Linguistics.</p>
<p>Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Remi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, and Alexander Rush. 2020. Transformers: State-of-the-art natural language processing. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, pages 38-45, Online. Association for Computational Linguistics.</p>
<p>Jiannan Xiang, Zhengzhong Liu, Yucheng Zhou, Eric Xing, and Zhiting Hu. 2022. ASDOT: Any-shot data-to-text generation with pretrained language models. In Findings of the Association for Computational Linguistics: EMNLP 2022, pages 1886-1899, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.</p>
<p>Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q. Weinberger, and Yoav Artzi. 2020. Bertscore: Evaluating text generation with bert. In Proceedings of the International Conference on Learning Representations.</p>
<p>Alex Zhuang, Ge Zhang, Tianyu Zheng, Xinrun Du, Junjie Wang, Weiming Ren, Stephen W. Huang, Jie Fu, Xiang Yue, and Wenhu Chen. 2024. Structlm: Towards building generalist models for structured knowledge grounding.</p>
<h2>A Details of Graph Extraction</h2>
<p>We utilize the vLLM (Kwon et al., 2023) for efficient inference using GPUs with at least 40 GB of VRAM. We perform graph extraction using nucleus sampling (Holtzman et al., 2020) based decoding strategy with a temperature set to 0.5 and a top-p value of 0.9 , which are determined experimentally. Total inference time for processing 6 M data samples was approximately 600 hours when utilizing 4 GPUs in parallel. Therefore, we divided the data into divisions that contain 100 K samples each to generate the outputs in parallel. Detailed prompts are provided in Table 8.</p>
<h2>B Details of Qualitative Analysis</h2>
<p>We describe details of human evaluation process and results (§B.1). We then describe GPT-4o evaluation process and prompts (§B.2).</p>
<h2>B. 1 Details of human evaluation</h2>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">GenWiki</th>
<th style="text-align: center;">TEKGEN</th>
<th style="text-align: center;">LAGRANGE</th>
<th style="text-align: center;">WANiLG</th>
<th style="text-align: center;">WikiOFGraph</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">1</td>
<td style="text-align: center;">Triplet <br> Text</td>
<td style="text-align: center;">$\begin{aligned} &amp; 63.52 \ &amp; 78.38 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 33.26 \ &amp; 56.66 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 24.42 \ &amp; 37.88 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 2.25 \ &amp; 1.26 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 7.45 \ &amp; 4.61 \end{aligned}$</td>
</tr>
<tr>
<td style="text-align: center;">2</td>
<td style="text-align: center;">Triplet <br> Text</td>
<td style="text-align: center;">$\begin{aligned} &amp; 67.19 \ &amp; 72.83 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 32.80 \ &amp; 13.61 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 16.78 \ &amp; 5.03 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 2.38 \ &amp; 0.96 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 4.29 \ &amp; 3.33 \end{aligned}$</td>
</tr>
<tr>
<td style="text-align: center;">3</td>
<td style="text-align: center;">Triplet <br> Text</td>
<td style="text-align: center;">$\begin{aligned} &amp; 43.00 \ &amp; 71.80 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 20.77 \ &amp; 47.59 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 10.29 \ &amp; 28.26 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.00 \ &amp; 0.23 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 2.78 \ &amp; 6.27 \end{aligned}$</td>
</tr>
<tr>
<td style="text-align: center;">4</td>
<td style="text-align: center;">Triplet <br> Text</td>
<td style="text-align: center;">$\begin{aligned} &amp; 47.28 \ &amp; 67.61 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 17.46 \ &amp; 34.65 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 30.71 \ &amp; 28.85 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 4.16 \ &amp; 0.80 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 10.00 \ &amp; 2.78 \end{aligned}$</td>
</tr>
<tr>
<td style="text-align: center;">5</td>
<td style="text-align: center;">Triplet <br> Text</td>
<td style="text-align: center;">$\begin{aligned} &amp; 69.63 \ &amp; 35.00 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 33.39 \ &amp; 52.45 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 12.84 \ &amp; 35.39 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.00 \ &amp; 0.25 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 1.67 \ &amp; 2.52 \end{aligned}$</td>
</tr>
<tr>
<td style="text-align: center;">Average</td>
<td style="text-align: center;">Triplet <br> Text</td>
<td style="text-align: center;">$\begin{aligned} &amp; 58.12 \pm 12.14 \ &amp; 65.12 \pm 17.27 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 27.54 \pm 7.78 \ &amp; 40.99 \pm 17.4 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 19.01 \pm 8.44 \ &amp; 27.08 \pm 13 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 1.76 \pm 1.77 \ &amp; 0.7 \pm 0.45 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 5.24 \pm 3.44 \ &amp; 3.9 \pm 1.55 \end{aligned}$</td>
</tr>
</tbody>
</table>
<p>Table 6: Individual scores of 5 different human evaluators. The Average row includes the mean and standard deviation in the form of mean $\pm$ standard deviation</p>
<p>The human evaluators consist of a diverse group of five individuals from various professional backgrounds. All evaluators, with their native English proficiency or advanced English language certifications, have prior experience in AI data labeling. We provide the human evaluators with an overview of the guideline and examples to validate graphtext pairs. Evaluators are tasked with assessing whether the target text accurately reflects the information contained within the corresponding triplets. Part of the evaluation guideline ${ }^{9}$ provided with the human evaluators is shown in Figure 8. We give detailed examples and step-by-step instructions to ensure consistency and accuracy to the human evaluators. Some examples of an actual evaluation task completed by the evaluators are shown in Figure 9. Following this process, we collect responses from five human evaluators. The aggregated results, showing the response results for each evaluator, are presented in Table 6.</p>
<h2>B. 2 Details of GPT-4o evaluation</h2>
<p>For the GPT-4o evaluation, we craft a prompt that closely mirrored the guideline provided to the human evaluators, ensuring that the LLM could comprehend and process the task effectively. Using the gpt-4o-2024-05-13 model, we evaluated 1,000 samples across five different datasets, resulting in a total cost of $\$ 39.04$. The actual prompt used in this evaluation can be found in Table 9. We set the temperature to 1 and allowed it to generate up to 700 tokens. The results to assess the consistency of 5 different datasets are shown in Table 7.</p>
<p><sup id="fnref5:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: center;">GenWiki</th>
<th style="text-align: center;">TEKGEN</th>
<th style="text-align: center;">LAGRANGE</th>
<th style="text-align: center;">WebNLG</th>
<th style="text-align: center;">WikiOFGraph</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Triplet</td>
<td style="text-align: center;">58.74</td>
<td style="text-align: center;">43.62</td>
<td style="text-align: center;">34.64</td>
<td style="text-align: center;">4.93</td>
<td style="text-align: center;">6.71</td>
</tr>
<tr>
<td style="text-align: left;">Text</td>
<td style="text-align: center;">48.56</td>
<td style="text-align: center;">37.37</td>
<td style="text-align: center;">45.06</td>
<td style="text-align: center;">6.03</td>
<td style="text-align: center;">12.23</td>
</tr>
</tbody>
</table>
<p>Table 7: Scores of GPT-4o evaluation.</p>
<h2>C Details of Fine-Tuning</h2>
<p>In the section 5, we apply bf16 precision, a cosine learning rate decay function with 2 k warmup steps, and utilize ZeRO stage 3 optimization through DeepSpeed (Rasley et al., 2020) while employing the AdamW optimizer (Loshchilov and Hutter, 2019). We employ beam search decoding for training and inference, with a temperature set to 1 and beam size set to 5 , to ensure a controlled search space exploration while maintaining the diversity of generated outputs. The specific hyperparameters vary depending on the dataset to ensure adequate optimization steps.</p>
<p>For WebNLG (Castro Ferreira et al., 2020), we set the gradient accumulation steps and the number of parallel GPUs to achieve an effective batch size of 8 with a maximum learning rate of 0.3 . We evaluate every 4 K steps and selected the model with the lowest loss. Total training time was approximately 13 hours using 4 GPUs in parallel ( 52 GPU hours).</p>
<p>For other datasets, we use an effective batch size of 192 with a maximum learning rate of 0.5 . Evaluations are performed every 20k steps, and the model with the minimum loss is selected. Total training time was approximately 70 hours using 4 GPUs in parallel ( 280 GPU hours).</p>
<p>In the experiments described in section 7, we limit the number of data samples to 50 K , similar to the size of WebNLG. Therefore, we conduct the experiments using the same hyperparameter settings as those applied to WebNLG. We select the model based on the one with the lowest loss as determined by evaluations conducted every 4 K steps. Total training time was approximately 10 hours using 4 GPUs in parallel ( 40 GPU hours).</p>
<h2>D Details of datasets</h2>
<p>In this section, we provide information on the sources of the datasets used in our study and detailed statistics for each dataset.</p>
<ol>
<li>Wikipedia: We use Wikipedia from Huggingface datasets. Specifically, we utilize the 20220301.en split, which can be accessed at Wikipedia dataset.</li>
<li>WebNLG: We use WebNLG obtained from the official repository. We utilize the English data from version 3.0, which is available at WebNLG repository.</li>
<li>GenWiki: We obtain GenWiki from GenWiki repository. We use the data found in the 'fine' split. Since there is no separate evaluation split, we reserve $10 \%$ of the training samples for evaluation purposes.</li>
<li>TekGen: We obtain TekGen from Tekgen repository. We convert the data into triplets according to the JSON object rules specified in the official repository.</li>
<li>LAGRANGE: We obtain LAGRANGE from the footnotes of the paper (Mousavi et al., 2024).</li>
</ol>
<p>We also provide a detailed comparison of the specific statistics and characteristics of each dataset, offering a clear overview of their unique features and differences in Table 10.</p>
<h1>[Triplet-Text Pair Validation]</h1>
<p>Now, let's explain how to validate Triplet-Text pairs. As mentioned earlier, a triplet includes a subject, predicate, and object. The Al's task involves generating sentences from multiple triplets, making it essential to understand the meaning of each triplet when validating the Triplet-Text pairs.</p>
<p>We will now explain how to determine whether a Triplet-Text pair is correctly or incorrectly aligned, along with some examples.</p>
<h2>[Examples]</h2>
<p>When you open up a file named as "number.docx", you can see 30 tables per each file. One example is followed.</p>
<div class="codehilite"><pre><span></span><code><span class="o">&lt;</span><span class="n">Triplet</span><span class="w"> </span><span class="n">Set</span><span class="o">&gt;</span>
<span class="mf">1.</span><span class="w"> </span><span class="p">(</span><span class="o">&lt;</span><span class="n">S</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Glyphostoma</span><span class="w"> </span><span class="n">epicasta</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="o">&lt;</span><span class="n">P</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Family</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="o">&lt;</span><span class="n">O</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Clathurellidae</span><span class="p">)</span>
<span class="mf">2.</span><span class="w"> </span><span class="p">(</span><span class="o">&lt;</span><span class="n">S</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Glyphostoma</span><span class="w"> </span><span class="n">epicasta</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="o">&lt;</span><span class="n">P</span><span class="o">&gt;</span><span class="w"> </span><span class="kt">Class</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="o">&lt;</span><span class="n">O</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Marine</span><span class="w"> </span><span class="n">gastropod</span><span class="w"> </span><span class="n">mollusk</span><span class="p">)</span>
<span class="mf">3.</span><span class="w"> </span><span class="p">(</span><span class="o">&lt;</span><span class="n">S</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Glyphostoma</span><span class="w"> </span><span class="n">epicasta</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="o">&lt;</span><span class="n">P</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Type</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="o">&lt;</span><span class="n">O</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Sea</span><span class="w"> </span><span class="n">snail</span><span class="p">)</span>
<span class="o">&lt;</span><span class="n">Reference</span><span class="w"> </span><span class="n">Text</span><span class="o">&gt;</span>
<span class="n">Glyphostoma</span><span class="w"> </span><span class="n">epicasta</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">species</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">sea</span><span class="w"> </span><span class="n">snail</span><span class="p">,</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">marine</span><span class="w"> </span><span class="n">gastropod</span><span class="w"> </span><span class="n">mollusk</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">family</span>
<span class="n">Clathurellidae</span><span class="p">.</span>
<span class="o">&lt;</span><span class="n">Error</span><span class="o">&gt;</span>
<span class="p">[</span><span class="n">Unused</span><span class="w"> </span><span class="n">triplets</span><span class="p">]</span><span class="o">:</span><span class="w"> </span><span class="n">x</span>
<span class="p">[</span><span class="n">Unguessable</span><span class="w"> </span><span class="n">text</span><span class="p">]</span><span class="o">:</span><span class="w"> </span><span class="n">x</span>
</code></pre></div>

<p>Each table contains three distinct fields, described as follows:</p>
<h2><Triplet Set></h2>
<p>This field includes multiple triplets, ranging from 1 to more than 10 triplets. Each triplet is a structured representation of a subject, predicate, and object. Single or multiple triplets together describe a single sentence.</p>
<p>Every triplet has its ID at the beginning(1.(<S> Alice | <P> Occupation | <O> Writer) 1 is ID of this triplet)</p>
<h2><Reference Text></h2>
<p>This field contains the text that corresponds to the <Triplet Set>. The text is generated by understanding the structure and meaning of the triplets in the <Triplet Set>. It should clearly and accurately contain "Only and Every" information from <Triplet Set>.</p>
<p>Figure 8: Part of the guidelines for human evaluators.</p>
<ol>
<li></li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="o">&lt;</span><span class="n">Triplet</span><span class="w"> </span><span class="n">Set</span><span class="o">&gt;</span>
<span class="mf">1.</span><span class="p">(</span><span class="o">&lt;</span><span class="n">S</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Schruns</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="o">&lt;</span><span class="n">P</span><span class="o">&gt;</span><span class="w"> </span><span class="n">state</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="o">&lt;</span><span class="n">O</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Vorarlberg</span><span class="p">)</span>
<span class="mf">2.</span><span class="p">(</span><span class="o">&lt;</span><span class="n">S</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Schruns</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="o">&lt;</span><span class="n">P</span><span class="o">&gt;</span><span class="w"> </span><span class="n">district</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="o">&lt;</span><span class="n">O</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Bludenz</span><span class="p">)</span>
<span class="mf">3.</span><span class="p">(</span><span class="o">&lt;</span><span class="n">S</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Schruns</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="o">&lt;</span><span class="n">P</span><span class="o">&gt;</span><span class="w"> </span><span class="n">country</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="o">&lt;</span><span class="n">O</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Austria</span><span class="p">)</span>
<span class="o">&lt;</span><span class="n">Reference</span><span class="w"> </span><span class="n">Text</span><span class="o">&gt;</span>
<span class="n">Schruns</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">Vorarlberg</span><span class="p">,</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">westernmost</span><span class="w"> </span><span class="n">area</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">Austria</span><span class="w"> </span><span class="p">,</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">vicinity</span><span class="w"> </span><span class="n">of</span>
<span class="n">Bludenz</span><span class="w"> </span><span class="n">at</span><span class="w"> </span><span class="mi">690</span><span class="w"> </span><span class="n">meters</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">Montafon</span><span class="w"> </span><span class="n">valley</span><span class="w"> </span><span class="n">on</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">Litz</span><span class="w"> </span><span class="n">river</span><span class="w"> </span><span class="p">,</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">tributary</span><span class="w"> </span><span class="n">of</span>
<span class="n">the</span><span class="w"> </span><span class="n">Ill</span><span class="w"> </span><span class="n">river</span><span class="p">.</span>
<span class="o">&lt;</span><span class="n">Error</span><span class="o">&gt;</span>
<span class="p">[</span><span class="n">Unused</span><span class="w"> </span><span class="n">triplets</span><span class="p">]</span><span class="o">:</span>
<span class="p">[</span><span class="n">Unguessable</span><span class="w"> </span><span class="n">text</span><span class="p">]</span><span class="o">:</span>
</code></pre></div>

<ol>
<li></li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="o">&lt;</span><span class="n">Triplet</span><span class="w"> </span><span class="n">Set</span><span class="o">&gt;</span>
<span class="mf">1.</span><span class="p">(</span><span class="o">&lt;</span><span class="n">S</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Benedito</span><span class="w"> </span><span class="n">de</span><span class="w"> </span><span class="n">Lira</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="o">&lt;</span><span class="n">P</span><span class="o">&gt;</span><span class="w"> </span><span class="n">birthPlace</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="o">&lt;</span><span class="n">O</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Alagoas</span><span class="p">)</span>
<span class="o">&lt;</span><span class="n">Reference</span><span class="w"> </span><span class="n">Text</span><span class="o">&gt;</span>
<span class="n">Benedito</span><span class="w"> </span><span class="n">de</span><span class="w"> </span><span class="n">Lira</span><span class="w"> </span><span class="p">(</span><span class="w"> </span><span class="n">born</span><span class="w"> </span><span class="n">May</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1942</span><span class="w"> </span><span class="p">)</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">Brazilian</span><span class="w"> </span><span class="n">politician</span><span class="w"> </span><span class="p">.</span><span class="w"> </span><span class="n">He</span><span class="w"> </span><span class="n">has</span>
<span class="n">represented</span><span class="w"> </span><span class="n">Alagoas</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">Federal</span><span class="w"> </span><span class="n">Senate</span><span class="w"> </span><span class="n">since</span><span class="w"> </span><span class="mf">2011.</span><span class="w"> </span><span class="n">Previously</span><span class="p">,</span><span class="w"> </span><span class="n">he</span><span class="w"> </span><span class="n">was</span><span class="w"> </span><span class="n">a</span>
<span class="n">Deputy</span><span class="w"> </span><span class="n">from</span><span class="w"> </span><span class="n">Alagoas</span><span class="w"> </span><span class="n">from</span><span class="w"> </span><span class="mi">1995</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="mf">1999.</span>
<span class="o">&lt;</span><span class="n">Error</span><span class="o">&gt;</span>
<span class="p">[</span><span class="n">Unused</span><span class="w"> </span><span class="n">triplets</span><span class="p">]</span><span class="o">:</span>
<span class="p">[</span><span class="n">Unguessable</span><span class="w"> </span><span class="n">text</span><span class="p">]</span><span class="o">:</span>
</code></pre></div>

<ol>
<li></li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="o">&lt;</span><span class="n">Triplet</span><span class="w"> </span><span class="n">Set</span><span class="o">&gt;</span>
<span class="mf">1.</span><span class="p">(</span><span class="o">&lt;</span><span class="n">S</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Ian</span><span class="w"> </span><span class="n">Hornak</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="o">&lt;</span><span class="n">P</span><span class="o">&gt;</span><span class="w"> </span><span class="n">birthPlace</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="o">&lt;</span><span class="n">O</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Philadelphia</span><span class="p">)</span>
<span class="mf">2.</span><span class="p">(</span><span class="o">&lt;</span><span class="n">S</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Ian</span><span class="w"> </span><span class="n">Hornak</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="o">&lt;</span><span class="n">P</span><span class="o">&gt;</span><span class="w"> </span><span class="n">nationality</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="o">&lt;</span><span class="n">O</span><span class="o">&gt;</span><span class="w"> </span><span class="n">American</span><span class="p">)</span>
<span class="mf">3.</span><span class="p">(</span><span class="o">&lt;</span><span class="n">S</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Ian</span><span class="w"> </span><span class="n">Hornak</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="o">&lt;</span><span class="n">P</span><span class="o">&gt;</span><span class="w"> </span><span class="n">birthPlace</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="o">&lt;</span><span class="n">O</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Pennsylvania</span><span class="p">)</span>
<span class="o">&lt;</span><span class="n">Reference</span><span class="w"> </span><span class="n">Text</span><span class="o">&gt;</span>
<span class="n">Ian</span><span class="w"> </span><span class="n">Hornak</span><span class="w"> </span><span class="n">was</span><span class="w"> </span><span class="n">born</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">Philadelphia</span><span class="w"> </span><span class="p">,</span><span class="w"> </span><span class="n">Pennsylvania</span><span class="w"> </span><span class="p">,</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">parents</span><span class="w"> </span><span class="n">who</span>
<span class="n">immigrated</span><span class="w"> </span><span class="n">from</span><span class="w"> </span><span class="n">Slovakia</span><span class="w"> </span><span class="p">.</span>
<span class="o">&lt;</span><span class="n">Error</span><span class="o">&gt;</span>
<span class="p">[</span><span class="n">Unused</span><span class="w"> </span><span class="n">triplets</span><span class="p">]</span><span class="o">:</span>
<span class="p">[</span><span class="n">Unguessable</span><span class="w"> </span><span class="n">text</span><span class="p">]</span><span class="o">:</span>
</code></pre></div>

<p>Figure 9: Some examples of human evaluation tasks.</p>
<h1>Instruction</h1>
<p>Your task is to create a set of triplets that can represent all the entities that appear in the given text. Triplet is consist of three parts $(&lt;\mathrm{S}\rangle,&lt;\mathrm{P}\rangle,&lt;\mathrm{O}\rangle)$.
$&lt;\mathrm{S}&gt;$ means subject, $&lt;\mathrm{P}&gt;$ means predicate (relation), $&lt;\mathrm{O}&gt;$ means object.
You can not simply copy the entities from the text, you need to create a set of triplets that can represent all the entities in the text.
For example, you cannot just use "is" or "are" in $&lt;\mathrm{P}&gt;$ part, you need to find a more specific predicate that can represent the relationship between the subject and the object.
Complete the $\llbracket$ TRIPLET $\rrbracket$ to represent $\llbracket$ TEXT $\rrbracket$, as shown in the Examples.
Please just complete $\llbracket$ TRIPLET $\rrbracket$ without saying anything else.</p>
<h2>Example 1</h2>
<p>$\llbracket$ TEXT $\rrbracket$ : The Acharya Institute of Technology is located in Soldevanahalli, Acharya Dr. Sarvapalli Radhakrishnan Road, Hessarghatta Main Road, Bangalore - 560090, Karnataka, India. It is affiliated with the Visvesvaraya Technological University in Belgaum.
$\llbracket$ TRIPLETS $\rrbracket$ : (<S>Acharya Institute of Technology| <P>affiliation| <O>Visvesvaraya Technological University), (<S>Visvesvaraya Technological University| <P>city| <O>Belgaum), (<S>Acharya Institute of Technology| <P>state| <O>Karnataka), (<S>Acharya Institute of Technology| <P>country| $&lt;\mathrm{O}&gt;$ India), (<S>Acharya Institute of Technology| <P>campus| <O>In Soldevanahalli, Acharya Dr. Sarvapalli Radhakrishnan Road, Hessarghatta Main Road, Bangalore - 560090.)</p>
<h2>Example 2</h2>
<p>$\llbracket$ TEXT $\rrbracket$ : Albert Jennings Fountain was born in Staten Island in New York City and died in Dona Ana County, New Mexico.
$\llbracket$ TRIPLETS $\rrbracket$ : (<S>Albert Jennings Fountain| <P>death Place| <O>Doña Ana County, New Mexico), (<S>Albert Jennings Fountain| <P>birth Place| <O>New York City), (<S>Albert Jennings Fountain| $&lt;\mathrm{P}&gt;$ birth Place| <O>Staten Island)</p>
<h2>Example 3</h2>
<p>$\llbracket$ TEXT $\rrbracket$ : Abilene, Texas is in Jones County in the United States. Washington, D.C. is the capital of the U.S. with New York City being the largest city. English is their native language.
$\llbracket$ TRIPLETS $\rrbracket$ : (<S>United States| <P>capital| <O>Washington, D.C.), (<S>Abilene, Texas| <P>is Part Of| <O>Jones County, Texas), (<S>Jones County, Texas| <P>country| <O>United States), (<S>United States| <P>largest City| <O>New York City), (<S>United States| <P>language| $&lt;$ O&gt;English language)</p>
<h2>Query</h2>
<p>$\llbracket$ TEXT $\rrbracket: \quad{$ text $}$
$\llbracket$ TRIPLETS $\rrbracket$ :
Table 8: Actual prompt used for Graph Extraction. The text in blue indicates where we have inserted the source sentences.</p>
<h1>Instruction</h1>
<p>Your job is to validate Triplet-Text pair data for Triplet-to-Text generation task. Based on the provided instructions and examples, write all errors in the Triplet-Text pairs present in the given query.</p>
<h2>Triplet Composition:</h2>
<p>Format: ( $&lt;\mathrm{S}&gt;$ subject $&lt;\mathrm{P}&gt;$ predicate $\mid&lt;\mathrm{O}&gt;$ object $)$
A triplet is composed of three elements: subject, predicate, and object. Each of these elements is delineated by specific symbols with capital letters such as $&lt;\mathrm{S}&gt;,&lt;\mathrm{P}&gt;$, and $&lt;\mathrm{O}&gt;$. These symbols help to clearly identify the role of each element within the triplet.</p>
<ul>
<li>$&lt;\mathrm{S}&gt;$ stands for the subject, which represents the entity that is performing an action or being described.</li>
<li>$&lt;\mathrm{P}&gt;$ stands for the predicate, which illustrates the relationship or action that connects the subject to the object.</li>
<li>$&lt;\mathrm{O}&gt;$ stands for the object, which is the entity that is receiving the action or being described in relation to the subject.</li>
</ul>
<h2>Error Types:</h2>
<p>A. Unused Triplet
{Example}
{Explanation}
B. Unguessable Text
{Example}
{Explanation}
Please just fill the format below. No need to write any extra explanations.</p>
<h2>Query</h2>
<p>$\llbracket$ TRIPLET SET $\rrbracket$ : {triplet}
$\llbracket$ TEXT $\rrbracket$ : ${$ text $}$
$\llbracket$ ERRORS $\rrbracket$ :</p>
<ul>
<li>[Unused Triplets]:</li>
<li>[Unguessable Text]:</li>
</ul>
<p>Table 9: Actual prompt for validating triplet-text pairs. {Example} and {Explanation} are omitted due to the length of the prompt. The text in blue indicates where we have inserted the examples.</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;">WebNLG</th>
<th style="text-align: center;">TekGen</th>
<th style="text-align: center;">GenWiki</th>
<th style="text-align: center;">LAGRANGE</th>
<th style="text-align: center;">WIkiOFGraph (Ours)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"># of samples</td>
<td style="text-align: center;">35,426</td>
<td style="text-align: center;">6,310,061</td>
<td style="text-align: center;">681,436</td>
<td style="text-align: center;">3,075,058</td>
<td style="text-align: center;">5,851,776</td>
</tr>
<tr>
<td style="text-align: center;"># of unique predicate</td>
<td style="text-align: center;">372</td>
<td style="text-align: center;">50,861</td>
<td style="text-align: center;">287</td>
<td style="text-align: center;">1,167</td>
<td style="text-align: center;">140,733</td>
</tr>
<tr>
<td style="text-align: center;"># of unique entity</td>
<td style="text-align: center;">3,211</td>
<td style="text-align: center;">4,249,337</td>
<td style="text-align: center;">866,373</td>
<td style="text-align: center;">2,904,407</td>
<td style="text-align: center;">8,217,819</td>
</tr>
<tr>
<td style="text-align: center;"># of triples (m/M/avg)</td>
<td style="text-align: center;">$1 / 7 / 2.96$</td>
<td style="text-align: center;">$1 / 54 / 1.73$</td>
<td style="text-align: center;">$1 / 10 / 2.64$</td>
<td style="text-align: center;">$1 / 135 / 4.02$</td>
<td style="text-align: center;">$1 / 17 / 3.62$</td>
</tr>
<tr>
<td style="text-align: center;">Human Annotator</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">x</td>
<td style="text-align: center;">x</td>
<td style="text-align: center;">x</td>
<td style="text-align: center;">x</td>
</tr>
<tr>
<td style="text-align: center;">Domain Diversity</td>
<td style="text-align: center;">$\downarrow$</td>
<td style="text-align: center;">$\uparrow$</td>
<td style="text-align: center;">$\uparrow$</td>
<td style="text-align: center;">$\uparrow$</td>
<td style="text-align: center;">$\uparrow$</td>
</tr>
<tr>
<td style="text-align: center;">Chracteristic</td>
<td style="text-align: center;">Crowdsourcing</td>
<td style="text-align: center;">Distant supervision</td>
<td style="text-align: center;">For unsupervised learning</td>
<td style="text-align: center;">Second-hop matching, <br> Triple Augmentation</td>
<td style="text-align: center;">LLM graph extraction</td>
</tr>
<tr>
<td style="text-align: center;">Ontology</td>
<td style="text-align: center;">DBPedia</td>
<td style="text-align: center;">Wikidata</td>
<td style="text-align: center;">DBPedia</td>
<td style="text-align: center;">Wikidata</td>
<td style="text-align: center;">x</td>
</tr>
</tbody>
</table>
<p>Table 10: Detailed comparison of dataset statistics and characteristics.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{9}$ The full guideline is available at https://github.com/ daehuikim/WikiOFGraph.&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref4:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref5:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
<li id="fn:1">
<p>${ }^{4}$ We employ 5.85M samples for the training split and 100 K samples for the test split. ${ }^{5}$ We employ the GenWiki ${ }_{\text {TONE }}$ training split&#160;<a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 2 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>