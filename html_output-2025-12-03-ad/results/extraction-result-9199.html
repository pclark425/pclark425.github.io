<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-9199 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-9199</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-9199</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-162.html">extraction-schema-162</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <p><strong>Paper ID:</strong> paper-258887852</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2305.16114v1.pdf" target="_blank">Fascinating Supervisory Signals and Where to Find Them: Deep Anomaly Detection with Scale Learning</a></p>
                <p><strong>Paper Abstract:</strong> Due to the unsupervised nature of anomaly detection, the key to fueling deep models is finding supervisory signals. Different from current reconstruction-guided generative models and transformation-based contrastive models, we devise novel data-driven supervision for tabular data by introducing a characteristic -- scale -- as data labels. By representing varied sub-vectors of data instances, we define scale as the relationship between the dimensionality of original sub-vectors and that of representations. Scales serve as labels attached to transformed representations, thus offering ample labeled data for neural network training. This paper further proposes a scale learning-based anomaly detection method. Supervised by the learning objective of scale distribution alignment, our approach learns the ranking of representations converted from varied subspaces of each data instance. Through this proxy task, our approach models inherent regularities and patterns within data, which well describes data"normality". Abnormal degrees of testing instances are obtained by measuring whether they fit these learned patterns. Extensive experiments show that our approach leads to significant improvement over state-of-the-art generative/contrastive anomaly detection methods.</p>
                <p><strong>Cost:</strong> 0.006</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <p class="empty-note">No extracted data.</p>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <p class="empty-note">No potentially relevant new papers extracted.</p>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-9199",
    "paper_id": "paper-258887852",
    "extraction_schema_id": "extraction-schema-162",
    "extracted_data": [],
    "potentially_relevant_new_papers": [],
    "cost": 0.00590775,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Fascinating Supervisory Signals and Where to Find Them: Deep Anomaly Detection with Scale Learning</p>
<p>Hongzuo Xu 
Yijie Wang 
Juhui Wei 
Songlei Jian 
Yizhou Li 
Ning Liu 
Fascinating Supervisory Signals and Where to Find Them: Deep Anomaly Detection with Scale Learning</p>
<p>Due to the unsupervised nature of anomaly detection, the key to fueling deep models is finding supervisory signals. Different from current reconstruction-guided generative models and transformation-based contrastive models, we devise novel data-driven supervision for tabular data by introducing a characteristic -scale -as data labels. By representing varied sub-vectors of data instances, we define scale as the relationship between the dimensionality of original sub-vectors and that of representations. Scales serve as labels attached to transformed representations, thus offering ample labeled data for neural network training. This paper further proposes a scale learningbased anomaly detection method. Supervised by the learning objective of scale distribution alignment, our approach learns the ranking of representations converted from varied subspaces of each data instance. Through this proxy task, our approach models inherent regularities and patterns within data, which well describes data "normality". Abnormal degrees of testing instances are obtained by measuring whether they fit these learned patterns. Extensive experiments show that our approach leads to significant improvement over state-of-the-art generative/contrastive anomaly detection methods.</p>
<p>Introduction</p>
<p>Anomaly detection, the task of discovering exceptional data that deviate significantly from the majority (Aggarwal, 2017), has been successfully applied in many real-world domains when there is a need to identify both negative and pos-itive rare events (e.g., diseases, cyberspace intrusions, financial frauds, industrial faults, and marketing opportunities). Deep learning has shown strong modeling capability, which enables deep anomaly detection methods to yield drastic performance improvement over traditional methods (Pang et al., 2021). Due to the unsupervised nature of anomaly detection, designing deep anomaly detection models is a journey of finding reasonable supervisory signals .</p>
<p>Many deep anomaly detection methods (Xia et al., 2015;Chen et al., 2017;Zhou &amp; Paffenroth, 2017;Liu et al., 2019;2021) construct various kinds of autoencoders, generative adversarial networks, or prediction models. Their learning objectives are adapted to anomaly detection by treating reconstruction errors of incoming data as abnormal degrees. These generative methods are intuitive and show favorable performance on several popular benchmarks. However, as has been discussed in (Larsen et al., 2016;Ruff et al., 2018;Wang et al., 2022), one imperfection is that their learning target is primarily designed to reconstruct/generate the whole data. That is, they are forced to focus on reducing errors in each fine-grained point, but overemphasizing low-level details may make the model hard to converge when the normal class is complicated. Besides, some underlying hard anomalies can be only identified by investigating high-level pattern information in inlier data.</p>
<p>To address this limitation, recent efforts (Golan &amp; El-Yaniv, 2018;Li et al., 2021;Wang et al., 2022;Ristea et al., 2022) have been made to liberate deep anomaly detection from the above reconstruction-based pipeline. They define various transformations and design pretext tasks, learning to classify, compare, or map these transformations. They either use the learned representations for independent abnormality estimators or utilize loss values as anomaly scores. These models can embed high-level semantic information into the learned representations, thus leading to stronger anomaly detectors with promising detection accuracy. However, most popular transformation operations (e.g., rotations, cropping, and flip) can be only applied to image data. As for nonperceptual tabular data, it is still a non-trivial task to define suitable supervisory signals to actuate deep learning models.</p>
<p>To this end, we introduce a new data characteristic -scaleto devise a novel kind of data-driven supervision. Generally, Figure 1. A toy example of scales in tabular data. For a tabular data instance described by four features, sub-vectors with varied feature subspaces are randomly sampled from the original space and then transformed into h-dimensional representations. Scale is computed as the mathematical relationship G between sub-vector length and the representation dimensionality h. scale indicates the ratio between the real size of something and its size on a map, model, or diagram. This naturally inspires us to define the scale concept in tabular data as: Definition 1.1 (Scale in Tabular Data). Sub-vectors of tabular data instances are transformed to representations. Scale is defined as the mathematical relationship between the dimensionality of sub-vectors and that of the representations, which indicates the level of detail in representations. Figure 1 delineates a toy example. Scales serve as labels attached to these transformed data, thereby supplying labeled data for driving neural networks on tabular data. However, it is still challenging to harness these labeled data. Due to the feature diversity, some sub-vectors with lower dimensionality are with more details than higherdimensional sub-vectors. Also, some randomly sampled subspaces might be irrelevant or even noisy. These notorious problems suggest that it is unfeasible to define canonical proxy tasks like classification or simple prediction. Instead, we define scale learning as follows. Definition 1.2 (Scale Learning). Each individual data sample in scale learning is defined as a group of representations transformed from varied sub-vectors of a data instance. The predictions and corresponding labels are converted to two distributions, and scale learning is defined as a distribution alignment task. Through optimizing distributions, the learning model is forced to focus on the relative ranking of scales rather than raw absolute values, and the increased sampling times also dilute ineffective irrelevant/noisy subspaces. Our model essentially learns the listwise ranking of representations transformed from varied subspaces of each original data instance, during which our model can capture inherent regularities and patterns related to the data structure. This is a novel kind of data-driven supervision that is different from current point-wise generative methods and discriminative models based on classification, comparison, or mapping.</p>
<p>Based on this supervision, this paper introduces a Scale Learning-based deep Anomaly Detection method (termed SLAD). Concretely, SLAD first specifies a transformation function to represent sub-vectors and a labeling function to calculate data scales. After creating scale-based labeled data, SLAD performs scale learning, optimized by a distributional divergence-based loss function. Through this proxy task, SLAD embeds high-level information (i.e., underlying regularities and patterns related to the data structure) into the learned scale-based ranking mechanism. It is similar to selfsupervised learning models in vision and natural language domains that embed data semantics into representations. Such high-level information helps our model to tame data complexity and reveal hard anomalies. We extend the inlierpriority property proposed in (Wang et al., 2022) to our model. That is, due to the imbalanced nature of anomaly detection, the learning process can prioritize inliers, and the learned regularities reflect "normality" shared in inliers. Anomalies, by definition, show deviated behaviors, and they cannot comply with these learned models. Hence, for identifying anomalies, errors computed by the loss function are directly exploited to indicate abnormal degrees.</p>
<p>Our contributions are summarized as follows:</p>
<p>• Conceptually, we introduce the scale concept in tabular data. By defining scale learning as a distribution alignment task, we appropriately harness scale-based labeled data to actuate neural networks for tabular data. Essentially, we devise a novel kind of data-driven supervision, and neural networks can model intrinsic regularities pertaining to the data structure.</p>
<p>• Methodologically, we propose SLAD, a scale learningbased deep anomaly detection method. The loss values are directly exploited to indicate abnormal degrees, thus allowing SLAD to produce anomaly scores in an end-to-end fashion. Our method also contributes a novel self-supervised strategy to other tasks like representation learning in tabular data.</p>
<p>• Theoretically, we analyze the shape of the created data sample in scale learning to ensure its effectiveness in revealing anomalies. To back up the application of scale learning in anomaly detection, we examine gradient magnitude to illustrate the inlier-priority property.</p>
<p>• Empirically, extensive experiments validate both the contributions in detection accuracy and the superiority in handling complicated training data. For example, SLAD raised the state-of-the-art AUC-PR from 0.82 to 0.92 (+10 points) on a popular Thyroid benchmark.</p>
<p>Related work</p>
<p>Deep learning-empowered anomaly detection has garnered much interest recently (Pang et al., 2021;Ruff et al., 2021). Due to the unsupervised nature of anomaly detection, without readily accessible labeled training data, finding supervisory signals becomes one crucial step to fuel deep learning models for anomaly detection. This section reviews how existing studies define their learning tasks.</p>
<p>One typical pipeline is based on generative methods. They take reconstruction as the learning objective to construct various kinds of autoencoders, generative adversarial networks, or prediction models and treat reconstruction errors as anomaly scores (Chen et al., 2017;Zhou &amp; Paffenroth, 2017;Liu et al., 2019;2021;Wang et al., 2021). Albeit intuitive, these methods overemphasize fine-grained reconstruction errors at the point-wise level, and they may fail to access high-level semantic information.</p>
<p>An alternative manner is to use one-class classification to obtain a model (e.g., hypersphere or hyperplane) that can accurately describe the "normality". Many anomaly detectors (Ruff et al., 2018;Goyal et al., 2020;Zhang &amp; Deng, 2021;Liznerski et al., 2021) train neural networks to learn a new representation space by posing one-class constraints. However, the underlying one-class assumption might be vulnerable since there is often more than one prototype in inliers. Besides, some methods resort to additional label information. Self-training models exploit iteratively predicted results of training data as supervisory signals while updating the model parameters (Pang et al., 2020;Qiu et al., 2022), whereas this process might be disturbed by mislabeled data. It is also noteworthy that a recent method named outlier exposure introduces labeled data from other datasets, thus forming synthetically labeled data (Hendrycks et al., 2019).</p>
<p>The success of contrastive self-supervised learning in vision and natural language domains sheds light on the potential of discriminative models for embedding rich semantic information into representations. By using various transformation operations in image data (e.g., rotations, cropping, flip, cutout, and interpolation), many insightful approaches (Golan &amp; El-Yaniv, 2018;Tack et al., 2020;Sehwag et al., 2021;Li et al., 2021;Wang et al., 2022;Ristea et al., 2022) create different views of initial data and employ classification, comparison, or mapping as pretext tasks. To identify anomalies, these methods perform independent abnormality measurements upon the learned representations or directly leverage the loss function. However, it is still non-trivial to define transformation operations for non-image data.</p>
<p>There are very limited attempts that generalize the above contrastive strategy to tabular data. GOAD (Bergman &amp; Hoshen, 2020) is the pioneer transformation-based method that can handle non-image data, which generalizes the spa-tial transformation to random affine transformation. Neu-TraL (Qiu et al., 2021) employs learnable neural transformations and proposes a noise-free, deterministic contrastive loss. The literature (Shenkar &amp; Wolf, 2022) learns mappings that maximize the mutual information between each sampled sub-vector and the part that is masked out.</p>
<p>We finally review a related field, i.e., self-supervised pretraining for tabular data. These models also perform contrastive learning upon different views created by corrupting random feature sub-spaces based on respective empirical marginal distribution (Bahri et al., 2022) or feature correlations (Yao et al., 2021). In addition to the corruption, the study (Yoon et al., 2020) proposes "mask estimator" and "feature estimator" heads on top of the encoder state.</p>
<p>Scale Learning for Anomaly Detection</p>
<p>Problem Formulation. Let X be the input tabular data described by a D-dimensional feature space. Each data instance x ∈ X is a vector x ∈ R D . By training on X , a deep anomaly detection model builds a scoring function τ : R D → R to quantitatively measure abnormal degrees of incoming data instances.</p>
<p>Overview. Figure 2 depicts the overall framework of SLAD. We take one data instance x as an example to illustrate the procedure of SLAD. There are two main components in SLAD. The creation of scale-based supervisory signals consists of a transformation function T and a labeling function G, which respectively define how to transform subvectors of an original data instance x to representations U and how to compute scales as labels y. SLAD treats each U matrix that contains c transformed vectors as an individual training sample, and labeled data O ×Y = {(U j , y j )} r j=1 offer supervisory signals for neural network training. In terms of scale learning, we construct a neural network Φ, and network parameters are optimized via a distribution alignment loss function L.</p>
<p>The Creation of Scale-based Supervisory Signals</p>
<p>Transformation Function T . T yields representations of sub-vectors. A unified h-dimensional representation frame is set since these transformed data serve as training samples for downstream scale learning. T can be also understood as a data preprocessing step. Some popular padding methods or dimensionality reduction techniques may change information contained in original sub-vectors. Instead, SLAD employs neural transformation to define T . Complicated neural transformations with non-linear activation may also modify the intrinsic data structure of the input. Random linear projection is a simple yet effective feature mapping technique, which can achieve dimensionality modification. Thus, T is defined as simple feed-forward layers that are via random sampling, where x (S i ) is the sub-vector of x on the subspace Si ⊆ {1, · · · , D}. These sub-vectors are then transformed to a unified h-dimensional representation frame by a Transformation function T , yielding a matrix U ∈ R c×h . Labeling function G measures scales as data labels y ∈ R c of transformed data in U. Each U and corresponding y are treated as one training sample, and the above process is repeated r times, which produces O ∈ R r×c×h attached with labels Y ∈ R r×c . A neural network Φ : R r×c×h → R r×c is trained via the loss function L to predict scale-based distributions of transformed data.</p>
<p>randomly initialized, and each feature subspace corresponds to a transformation layer. For a ν-dimensional sub-vector x (Si) ∈ R ν , its representation is obtained via a weight matrix W ν ∈ R h×ν and bias b ∈ R h , i.e.,
T (x (Si) ) = W ν x (Si) + b.(1)
For c randomly sampled sub-vectors of a data instance x, their transformations are denoted in a matrix U ∈ R c×h . U is treated as an individual data sample for scale learning.</p>
<p>Labeling Function G. SLAD further computes scales. Each dimension derived via neural transformation T is with equal status, so the representation dimensionality can be directly exploited. However, as original tabular features are varied, we intend to weigh each feature to capture this kind of difference. For ease of learning, we also increase the spacing of each scale value via a magnification factor. Therefore, given the representation dimension h and the feature subspace S i of a sub-vector, G is defined as
G(S i , h) = γ k∈Si ω k h ,(2)
where ω k is the weight of the kth feature and γ is a magnification factor. The γ factor is a hyper-parameter. In terms of the feature weight, a feature is more informative if it has strong interactions with other features. Thus, Pearson product-moment correlation coefficient is
employed. Let u k = {x (i,k) } |X | i=1
denote the values of the kth feature. The weight of kth feature is computed as
ω k = 1 |F | |F | k ′ =1 cov(u k ,u k ′ ) dev(u k )dev(u k ′ )
, where cov(·, ·) and dev(·) denote the covariance and the standard deviation. ω ranges from 0 to 1. High-dimensional feature space is often contaminated by noisy/irrelevant features, and this calculation function might be biased. This function also induces considerably heavy computational overhead when handling highdimensional data. Therefore, SLAD omits this step and sets ω = 1 for all features when the dimensionality of the original feature space is high.</p>
<p>For the U matrix deriving from a group of sub-vectors with feature subspaces {S 1 , · · · , S c }, its label is defined as a list of scales, i.e., y = {G(S 1 , h), · · · , G(S c , h)}.</p>
<p>Scale Learning</p>
<p>The above process is repeated r times for an original data instance, creating labeled data O×Y = {(U j , y j )} r j=1 . SLAD constructs a neural network Φ : R c×h → R c that maps each newly created data sample to a scale list, i.e., p = Φ(U). Scale learning is defined as a distribution alignment task to handle the feature diversity and irrelevant/noisy sampled subspaces. Specifically, the predictions are processed by a softmax layer σ, i.e., σ(p) = { exp(pi) j exp(pj ) } c i=1 , which generates a probability distribution. y is also processed by a softmax function σ to produce target distribution. Listwise prediction of c transformed vectors in U can be optimized uniformly. This way allows the optimization to be supervised by the relative values. The distribution alignment task substantially teaches the network to rank representations transformed from different feature subspaces of the original data instance via the predicted scale values.</p>
<p>After obtaining the predictionp = σ(Φ(U)) and the target y = σ(y), loss value ℓ is defined by a distributional divergence measure. We employ Jensen-Shannon divergence in our implementation, i.e.,
ℓ(p∥ỹ) = 1 2 c i=1p i log(p i 1 2 (pi +ỹi) )+ 1 2 c i=1ỹ i log(ỹ i 1 2 (pi +ỹi)
).</p>
<p>(3)</p>
<p>The overall loss function of SLAD can be further defined as
L = E x∼X E (U,y)∼Ox×Yx ℓ σ(Φ(U)) σ(y) ,(4)
where O x and Y x denote the supervisory signals created by an original data instance x.</p>
<p>Anomaly Detection</p>
<p>Scale learning is not directly related to anomaly detection, and this is essentially a surrogate learning task to drive neural network training. SLAD embeds feature interactions, patterns, and inherent regularities related to the data structure into the learned scale-based ranking mechanism. What SLAD leverages for anomaly detection are these high-level data abstractions.</p>
<p>We further present an inlier-priority property. It suggests that the update of the neural network is inclined to prioritize inliers due to the imbalanced nature of anomaly detection, i.e., what SLAD derives are normal, common regularities in inliers. Anomalies, by definition, are rare events and behave differently, thereby showing deviation from these learned regularities. This property is first proposed by (Wang et al., 2022) in which a classification-based pretext task is defined. We extend this property from the cross-entropy loss to our distributional divergence loss (theoretical analysis and empirical study in Section 3.4 and 4.2), which further supports the application of scale learning in anomaly detection.</p>
<p>Therefore, errors computed through the loss function can indicate abnormal degrees of incoming data. For a testing data instance x, SLAD also creates transformed data samples O and corresponding supervisory labels Y, and its anomaly score is obtained via
τ (x) = (U,y)∈O×Y ℓ σ(Φ(U)) σ(y) .(5)</p>
<p>Theoretical Analysis</p>
<p>We explore two questions: (Q1) How to ensure the effectiveness of the created data sample of scale learning in revealing anomalies? (Q2) Does scale learning model normal regularities of inliers, thus exposing anomalies? The training sample in scale learning (the U matrix) is generated from randomly sampled feature subspaces. Thus, to solve Q1, we consider how to determine the shape of each transformed data sample (the sampling times c) such that real anomalies can still stand out in the transformed form. As for Q2, we examine the inlier-priority property by analyzing the gradients that determine the neural network optimization.</p>
<p>The Shape of the Data Sample of Scale Learning and its Effectiveness in Revealing Anomalies. Let x a be an anomaly, and U indicates its transformed matrix. We below derive the relationship between the size of U and the probability that U is useful to reveal x a as an anomaly. We assume the abnormality of x a is reflected in a subspace G of the whole feature space F, i.e., G ⊆ F, and |G| = β|F|, β ∈ (0, 1]. The elements in G are effective features. Generally, a subset of G is sufficient to discover the anomaly, and we denote this minimum size as α|G|, α ∈ (0, 1]. Let S be one of the sampled subspaces when creating U. The dimensionality of S is uniformly sampled from 1 to |F|.</p>
<p>We first give the following Lemma (proof in Appendix A) to show the probability of S being effective. Lemma 3.1. The probability of S containing at least α|G| effective features of G (i.e., S is effective) is:
P r(S is useful) = 1 |F| |F | j=α|G| j k=α|G| j k |G| |F| k 1− |G| |F | j−k .(6)
Based on the above Lemma, we further present an intriguing fact in the following Theorem (proof in Appendix B), which bounds the above probability. Theorem 3.2. Given the effective feature space G and the minimum size α|G| to reveal the anomaly , the lower bound of the probability of the randomly sampled subspace S being useful is inf P r(S is useful) = 1 − α.</p>
<p>Let the success probability of an individual sampling be the lower bound, i.e., 1 − α. We assume U is useful to disclose the anomaly if it has at least one element that is transformed from the effective sub-vectors. Consequently, similar to Lemma 3.1, the probability of U being useful is:
P r(U is useful) = c k=1 c k (1 − α) k (α) c−k . (7)
P r(U is useful) and c are positively related, whereas a large number of useless elements in U may also disrupt the identification of x a . Thus, we use a size that is as small as possible while ensuring P r(U is useful) is large enough. In our default setting, we use c = 10, which makes the probability exceed 0.999 when α = 0.5 and 0.99 when α = 0.6.</p>
<p>Inlier-priority Property in Scale Learning. The inlierpriority property indicates that the network optimization is inclined to prioritize inliers. Since the theoretical analysis of DNNs is still intractable, we consider the same analyzable case that has been used in (Wang et al., 2022), i.e., a feedforward structure with sigmoid activation. The penultimate layer outputs u units, and the final softmax layer contains c nodes. Network weights are initialized by a uniform distribution [−1, 1]. Considering the kth element (1 ≤ k ≤ c) of the prediction, the gradients w.r.t. the weights (denoted as w k = {w (s,k) } u s=1 ) are directly responsible for this output. Let L k be the kth position of the loss function of N training data objects, and we can derive the expectation of gradient magnitude of updating w k as follows: E ∥∇ w k L k ∥ 2 2 essentially quantifies the influence of training data on network optimization. We respectively denote the gradients induced by inliers and anomalies as ∇ inlier w k L k and ∇ anom w k L k . Based on Taylor series expansion and gradients computation, we derive the following approximation (detailed derivation in Appendix D ):
E ∇w k L k 2 2 = u s=1 E N i=1 ∇w (s,k) ℓ (i) k 2 = u s=1 N i=1 N j=1 E ∇w (s,k) ℓ (i) k ∇w (s,k) ℓ (j) k .(8)E ∥∇ inlier w k L k ∥ 2 2 E ∥∇ anom w k L k ∥ 2 2 ≈ N 2 inlier N 2 anom .(9)
Due to the imbalanced nature (i.e., N inlier ≫ N anom ), inliers govern the optimization process by inducing a significantly larger gradient magnitude. Therefore, the neural network can learn normal regularities and patterns in inliers, thereby exposing anomalies in the inference stage.</p>
<p>Experiments</p>
<p>Datasets. Ten datasets are employed in our experiments.</p>
<p>Thyroid and Arrhythmia are two medical datasets out of four popular benchmarks used in existing studies of this research line (Bergman &amp; Hoshen, 2020;Qiu et al., 2021). The other two datasets in this suite are from KDD99, while KDD99 is broadly abandoned as virtually all anomalies can be detected via one-dimensional marginal distributions. Instead, a modern intrusion detection dataset, UNSW-NB15, is exploited. Besides, our experiments also base on several datasets from different domains including Waveform (physics), Bank (marketing), Thrombin (biology), and PageBlocks (web). These datasets are commonly used in anomaly detection literature (Pang et al., 2021;Campos et al., 2016). We employ tabular version of three vision/NLP datasets including MVTec (tab), Amazon (tab), and Yelp (tab), which are provided by a recent anomaly detection benchmark study (Han et al., 2022). </p>
<p>Anomaly Detection Performance</p>
<p>Effectiveness in Real-world Datasets. Table 1 illustrates the detection performance in terms of AUC-ROC and AUC-PR, of our model SLAD and the competing methods. SLAD outperforms its state-of-the-art competing methods on eight out of ten datasets according to both two evaluation metrics. SLAD averagely obtains 7%-21% AUC-ROC improvement and 15%-61% AUC-PR gain over its seven contenders. Par- ticularly, on the popular benchmark Thyroid, SLAD raises the state-of-the-art AUC-PR by 10 points from 0.82 to 0.92. We also achieve over 190% AUC-PR leap (from 0.15 to 0.43) on Waveform. Contrastive self-supervised counterparts also show more competitive performance than reconstruction-or one-class-based methods. The superiority of SLAD validates the effectiveness of our scale learning task in accurately modeling normal regularities of the inherent data structure. Note that SLAD performs less effectively on Arrhythmia that has limited data instances (less than 500) since the success of neural networks generally relies on sufficient training data. Nevertheless, SLAD still obtains the best AUC-ROC performance on Arrhythmia.</p>
<p>Capability to Handle Complicated Normal Data. This experiment investigates whether discriminative models can better handle complicated normal data than reconstructionor one-class-based baselines. Following (Qiu et al., 2021), this question is empirically studied by increasing the variability of inliers. We use F-MNIST, a popular multi-class dataset, by treating each pixel as one feature. A suite of datasets is created by sampling data from one class as anomalies and increasing the number of classes considered to be inliers. For each case, we use nine different combinations of selected normal classes and five random seeds per class combination, producing 405 (9×9×5) datasets in total. Figure 3 illustrates the AUC-ROC results and the decline proportion w.r.t. the increasing of class numbers in normal data. As each case corresponds to a group of datasets, we also report the 95% confidence interval in addition to the average performance in the left panel. Each detector has a comparably good performance when only one original class appears in inliers. The increased variety in the normal class makes the task more challenging. SLAD downgrades by about 10% and still achieves over 0.8 AUC-ROC when the normal class contains nine prototypes, while over 30% decline is shown in generative models. Reducing errors in point-wise details is hard to converge when the normal class is complicated. The one-class assumption also does not hold when there are more than two original classes considered to be inliers. By contrast, SLAD, ICL, NeuTraL, and GOAD better handle the increased complexity of the normal class. The superiority over contrastive self-supervised counterparts validates the technical advantages of learning to rank subspace-based transformed data compared to only learning the discrimination between transformations.</p>
<p>A Closer Look at Scale Learning</p>
<p>This experiment further investigates why scale learning can be used for anomaly detection by specifically validating the inlier-priority property and examining whether the learned regularities and patterns are class-dependent.</p>
<p>Validating the Inlier-priority Property. To look into the optimization process of scale learning, we illustrate loss values of testing inliers and anomalies per training epoch, which empirically examines the inlier-priority property. Training data are contaminated by 2% anomalies. Loss values ℓ of testing inliers and anomalies are respectively calculated, and Figure 4 shows box plots of loss values. Neural network inclines to model the inlier class, and testing inliers generally yield lower errors. Compared to inliers, anomalies present significantly higher distributional divergence between derived predictions and targets, and thus two classes can be gradually separated. On datasets Amazon (tab) and Yelp (tab), anomalies also yield clearly reduced loss values. It might be because we employ the adapted tabular version of these two datasets, and their tabular representations are not embedded with informative features to distinguish anomalies. Other state-of-the-art competitors also fail to produce good detection results on these two datasets as shown in Table 1.</p>
<p>Validating the Class-dependency. The anomaly detection performance on the used ten datasets validates that the learned regularities cannot apply to anomalies. We further delve into this question by employing the multi-class F- MNIST dataset. After training on one class, if data instances from new classes do not comply with the learned regularities and patterns embedded in the scale-ranking mechanism, the learned network cannot make expected predictions for data instances from new classes. Therefore, this experiment tests whether the learned network generalizes to other classes by calculating loss values of data instances in new classes compared to the trained class. Two cases are set by employing different original classes, i.e., class 0 (T-shirts) and class 1 (trousers), for training. As shown in Figure 5, loss values ℓ per class are denoted in box plots. The data instances from the trained class can well fit the learned network, deriving obviously lower errors. By contrast, the loss values of other classes are higher. The lower quartile of new classes is much higher than or comparable to the upper quartile of the trained class. These results further validate that our scale learning is class-dependent, thus further supporting its application in anomaly detection. Please note that, in the left panel of Figure 5, loss values in class 3 are much lower than that in other new classes since T-shirts in class 0 are semantically similar to pullovers in class 3. It is more challenging to distinguish this class. Nonetheless, data instances from this new class still show observable higher divergence than the trained class.</p>
<p>Ablation Study</p>
<p>This experiment answers two questions: (Q1) Can several designs in the transformation function T and the labeling function G be replaced with alternatives? (Q2) Is it necessary to define scale learning as a distribution alignment task? We first validate the choice of our random affine transformation function T by replacing it with a zero padding function in w/ T Zero and deeper feed-forward network structure in w/ T MLP , and the feature weight of the labeling function is removed in w/o G ω . We design another three ablated versions (w/ L ce , w/ L mse , and w/ L dcl ), which define scale learning as classification, regression, and contrastive learning using the cross-entropy loss, the mean-squared error, and the deterministic contrastive loss (Qiu et al., 2021), respectively. SLAD is compared with the above six ablated versions. Table 2 reports the AUC-ROC results. SLAD outperforms w/ T Zero and w/ T MLP on most of the used datasets, which validates the choice of random affine transformation when creating representations. Feature weights bring an approximate 5% improvement on the popular Thyroid benchmark. Besides, our distribution alignment-based scale learning illustrates better results than other canonical proxy tasks, which illustrates its superiority. It is interesting to note that w/ L mse obtains superior average performance than w/ L ce , which implies that using clear quantitative labels may better teach the network than qualitative learning in classification. w/ L dcl achieves relatively better performance since it also treats a group of transferred data as one training sample and uses the contrastive loss, i.e., it also optimizes predictions in a relative manner.</p>
<p>Conclusions</p>
<p>This paper introduces SLAD, a deep anomaly detection method for tabular data. The core novelty of our work includes the scale concept in tabular data and a new kind of data-driven supervisory signals based on scales. This supervision essentially learns the ranking of representations transformed from varied feature subspaces. It is different from current point-wise generative models and classification-, comparison-, and mapping-based discriminative models, presenting a new manner of self-supervised learning. By harnessing this supervision, our model learns inherent regularities and patterns related to the data structure, which of-fers valuable high-level information for identifying anomalies. Theoretically, we analyze how to ensure the effectiveness of the created data sample in revealing anomalies by determining its shape, and we also examine the inlierpriority property to support the application of scale learning in anomaly detection. Extensive experiments manifest that SLAD significantly outperforms various kinds of state-ofthe-art anomaly detectors (including generative, contrastive, and one-class methods) and shows clear superiority when handling complicated data with highly varied inliers. A. Proof of Lemma 3.1</p>
<p>Proof. The subspace S is uniformly sampled from the full feature space F. We assume the sampling process is with replacement, and the probability of sampling one effective feature is |G| |F | . The number of effective features in a subspace with j elements is a variable that follows a binominal distribution, i.e., X ∼ b(j, |G| |F | ), and the probability function of X is:
P r j (X = k) = j k ( |G| |F| ) k (1 − |G| |F| ) j−k ,(10)
The length of the sampled subspace follows a discrete uniform distribution of {1, · · · , |F|}. Therefore, the probability of the subspace S being useful (i.e., S contains at least α|G| effective features of G) can be derived as follows.
P r(S is useful) = 1 |F| |F | j=1 P r j (X ≥ α|G|).(11)
As P r j (X ≥ α|G|) is zero when j &lt; α|G|, based on Equation 10, the probability of the sampled subspace S containing at least α|G| effective features is:
P r(S is useful) = 1 |F| |F | j=α|G| j k=α|G| P r j (X = k) = 1 |F| |F | j=α|G| j k=α|G| j k ( |G| |F| ) k (1 − |G| |F| ) j−k .(12)
B. Proof of Theorem 3.2</p>
<p>Proof. In this proof, for the simplicity of notation, we write |F|, |G|, α|G| as n, m, and q, repetitively, and P r(S is useful) is abbreviated as P r.</p>
<p>We first show that P r monotonically decreases with the increase of n.
P r n − P r n+1 = 1 n n j=q j k=q j k ( m n ) k (1 − m n ) j−k − 1 n + 1 n+1 j=q j k=q j k ( m n + 1 ) k (1 − m n + 1 ) j−k = 1 n n j=q j k=q j k ( m n ) k (1 − m n ) j−k − 1 n + 1 n j=q j k=q j k ( m n + 1 ) k (1 − m n + 1 ) j−k − 1 n + 1 n+1 k=q n + 1 k ( m n + 1 ) k (1 − m n + 1 ) n+1−k ≥ 1 n n j=q j k=q j k 1 n ( m n ) k (1 − m n ) n−k − n k=q n k 1 n + 1 ( m n + 1 ) k (1 − m n + 1 ) n−k − 1 n + 1 n k=q n + 1 k ( m n + 1 ) k (1 − m n + 1 ) n+1−k − 1 n + 1 ( m n + 1 ) n+1 ≥ 1 n ( m n ) n (1 − m n ) n−n − 1 n + 1 ( m n + 1 ) n (1 − m n + 1 ) n−n − n + 1 n + 1 − n 1 n + 1 ( m n + 1 ) n (1 − m n + 1 ) n+1−n − 1 n + 1 ( m n + 1 ) n+1 ≥0(13)
Therefore, we have
1 n n j=q j k=q j k ( m n ) k (1 − m n ) j−k ≥ lim n→∞ 1 n n j=q j k=q j k ( m n ) k (1 − m n ) j−k .(14)
We note that
lim n→∞ 1 n n j=q q−1 k=0 j k ( m n ) k (1 − m n ) j−k = lim n→∞ n j=q q−1 k=0 j!m k (j − k)!k!n k+1 (1 − m n ) j .(15)
In addition,
lim n→∞ n j=q j!m k (j − k)!k!n k+1 (1 − m n ) j = 1 k!m lim n→∞ n j=1 j! (j − k)! ( m n ) k+1 (1 − m n ) j = 1 k!m lim n→∞ n j=1 j k ( m n ) k+1 (1 − m n ) j = e −m k!m k!e m − k! − k!m − m k − O(m k−1 ) ≤ 1 m .(16)
According to the above inequality, we can derive the following results from Equation (15):
lim n→∞ 1 n n j=q q−1 k=0 j k ( m n ) k (1 − m n ) j−k ≤ q−1 k=0 1 m ≤ q m .(17)
Hence,
lim n→∞ − 1 n n j=q q−1 k=0 j k ( m n ) k (1 − m n ) j−k ≥ − q m lim n→∞ 1 n n j=q 1 − q−1 k=0 j k ( m n ) k (1 − m n ) j−k ≥ 1 − q m lim n→∞ 1 n n j=q j k=q j k ( m n ) k (1 − m n ) j−k ≥ 1 − q m ,(18)
As
lim n→∞ 1 n n j=q j k=q j k ( m n ) k (1 − m n ) j−k − (1 − q m ) = e −m (q! + m q−1 + O(m q−1 )) (q − 1)!m ,(19)
i.e., Equation (19) monotonically decreases when m is a large number.</p>
<p>Also,
lim m→∞ lim n→∞ 1 n n j=q j k=q j k ( m n ) k (1 − m n ) j−k − (1 − q m ) = 0.(20)
Based on Equation (18)(19)(20), we finally show the lower bound of the probability is 
inf(P r) = 1 − q m = 1 − α.(21)</p>
<p>C. Empirical Validation of Theorem 3.2</p>
<p>We further empirically inspect the lower bound of P r(S is useful) in Theorem 3.2. Two ratios α and β are chosen from {0.25, 0.5, 0.75, 1.0}, and the data dimensionality |F| ranges from 0 to 400. Figure 6 shows how probability P r changes w.r.t. different α, β, and |F|. The probability P r monotonically decreases with the increase of |F|, which is also proved in Appendix B. The function curves of P r show a clear lower bound that is determined by the α value. As shown in four represented α cases, the lower bound is shown to be 1 − α, which is the same result as proved in Appendix B</p>
<p>D. Theoretical Derivation of the Inlier-Priority Property in Scale Learning</p>
<p>We first consider the gradient ∇ w (s,k) ℓ k in Equation (8). ℓ k is the kth part of the summation in Equation (3), i.e.,
ℓ k = 1 2p k log(p k 1 2 (p k +ỹ k ) ) + 1 2ỹ k log(ỹ k 1 2 (p k +ỹ k ) ).(22)
Thus, ∇ w (s,k) ℓ k is given by
∇ w (s,k) ℓ k = ∂ℓ k ∂p k ∂p k ∂p k ∂p k ∂w (s,k) = 1 2 log 2+logp k −log(ỹ k +p k ) ·p k (1−p k ) · h s ,(23)
where p k is the prediction before the softmax layer, and h s is the output of the sth node in the penultimate layer.</p>
<p>We then consider E ∇ w (s,k) ℓ
(i) k ∇ w (s,k) ℓ (j) k . Let g (s,k) i,j (w k ) = ∇ w (s,k) ℓ (i) k ∇ w (s,k) ℓ (j)
k . To simplify computation, we drive the following function according to the second-order Taylor series expansion:
g (s,k) i,j (w k ) ≈ g (s,k) i,j (µ) + ∇ w k g (s,k) i,j (µ) · (w k − µ) + 1 2 (w k − µ) T · ∇ 2 w k g (s,k) i,j (µ) · (w k − µ).(24)
where µ is the expectation of w k .</p>
<p>Given that the weights are initialized by a uniform distribution [−1, 1], we have µ (s,k) = 0 and µ = 0, Hence,
E g (s,k) i,j (w k ) ≈ E g (s,k) i,j (0) + E ∇ w k g (s,k) i,j (0)w k + E 1 2 w T k ∇ 2 w k g (s,k) i,j (0)w k .(25)
The prediction p k is zero when network weights w k = 0, and after a softmax layer,p k = 1 c . Asỹ k is a constant number, we assumeỹ k = 1 c here. In addition, E(w 2 (s,k) ) = 1 3 and E(w (s,k) w (t,k) ) = 0 when s ̸ = t. Hence, we have
E g (s,k) i,j (w k ) ≈ 1 6 u t=1 c l=1 ∇ 2 w t,l g (s,k) i,j (0).(26)≈ 1 4 , E (h (i) s ) 2 (h (j) s ) 2 ≈ 1 16 , and E (h (i) s ) 3 (h (j) s ) ≈ 1 16 . Therefore, E ∥∇ w k L k ∥ 2 2 ≈ N 2 u (c 3 + 1)(c − 1) 3 1536c 6 (c + 1) + (c − 1)(3c 3 − 14c 2 + 16c − 9) 768c 4 ≜ QN 2 ,(33)
where Q is a constant related to c. The gradient magnitude is proportional to the size of training data.</p>
<p>We can then compare the magnitude induced by inliers and anomalies, i.e.,
E ∥∇ inlier w k L k ∥ 2 2 E ∥∇ anom w k L k ∥ 2 2 ≈ N inlier N anom .(34)</p>
<p>E. Algorithms Details</p>
<p>We outline the detailed training procedure of SLAD in Algorithm 1. SLAD uses interactions between features to calculate feature weights for the subsequent labeling function in Steps 4-5. This process is omitted by using a threshold δ in Steps 6-7 when handling high-dimensional data due to the huge computational overhead and the inaccuracy caused by irrelevant/noisy features. SLAD creates scale-based supervisory signals via the transformation function T and labeling function G in Steps 9-20. Every c transformed vectors are contained in a U matrix in Steps 14-16, and finally creates r matrices in O attached with labels in Y via Step 18. SLAD further trains a neural network Φ to rank scale values via the loss values ℓ and the loss function L in Steps 21-28.</p>
<p>Algorithm 1 Training Procedure of SLAD 1: Input: Dataset X . 2: Output: Trained neural network Φ * 3: Initialize ω ∈ R D as the a feature weight list. 4: if D &lt; δ then 5: until Reach maximum number of mini-batches 28: until Reach maximum training epochs 29: return: Φ * Table 3 reports the domains of the used datasets and their statistical information including data size, dimensionality, the number of anomalies (#anom), and anomaly percentage to the whole data size (ratio). These datasets are publicly available and they are broadly used in related literature (Han et al., 2022;Shenkar &amp; Wolf, 2022;Bergman &amp; Hoshen, 2020;Qiu et al., 2021;Xu et al., 2023). In UNSW-NB15, we use the network traffic of "DoS" attack as anomalies. 
ω ← 1 |F | |F | k ′ =1 cov(u k ,u k ′ ) dev(u k )dev(u k ′ )</p>
<p>F. Datasets</p>
<p>G. Implementation Details</p>
<p>For SLAD, we use h = 128 in the transformation function to represent sub-vectors to a unified 128-dimensional frame. Our transformation function uses c and r to respectively control the number of transferred data in each training sample and the repeat times. We use c = 10 and r = 20 by default. In the labeling function G, we use δ = 50 as the threshold to omit the correlation-based weighting function. The magnification factor γ in G is set as 200 by default. All the deep anomaly detectors use a 1e-3 learning rate, and the mini-batch size is 128. Multi-layer perceptron network is exploited for these deep detectors except GOAD which uses the default convolutional network. We use the LeakyReLU function as the non-linear activation layer, and the hidden layer contains 100 neural units. For ICL, NeuTraL, GOAD, and RCA, the representation dimensionality is set as 128, which is the same as h in SLAD. These datasets are split into three groups, i.e., datasets with smaller sizes including Thyroid, Arrhythmia, and Waveform, transferred CV dataset MVTec (tab), and other datasets. We vary the number of training epochs from {10, 20, 50, 100} for three categories and report empirically good results. </p>
<p>H. Additional Empirical Results</p>
<p>H.1. Effectiveness on ADBench</p>
<p>We further employ ADBench (Han et al., 2022), the latest anomaly detection benchmark collection of tabular data, which consists of 47 classical tabular datasets. These datasets are from various domains and contain varied sizes, dimensionality, anomaly types, and noise levels. It is very challenging to be the universal winner in all cases, as has been suggested in the no-free-lunch theorem (Wolpert &amp; Macready, 1997). Therefore, we focus on the overall performance on this large-scale benchmark. We employ the average rank and the number/percentage of cases that each anomaly detector ranks within the Top2/Top4 positions among 8 anomaly detector candidates (our model and seven contenders). Table 4 shows the experiment results. Our method SLAD successfully outperforms all of its seven state-of-the-art competing methods according to six evaluation metrics. It is also noteworthy that iForest is a powerful baseline, even if its workflow is very simple. In addition, the advanced self-supervised methods ICL and NeuTraL show competitive AUC-PR performance. Nevertheless, our method still leads to new state-of-the-art detection accuracy across this comprehensive benchmark collection.</p>
<p>H.2. Robustness w.r.t. Different Contamination Levels in Training Data</p>
<p>Recall that we follow the commonly used experimental protocol (half of the normal samples for training and the rest of normal data in addition to all the anomalies for testing) in Section 4.1. However, in real-world applications, training data might be contaminated by unknown anomalies, Thus, we investigate the robustness w.r.t. different contamination ratios  in training data. Half of the anomalies are used for testing, and the other half are candidate anomalies to contaminate the training set. As anomalies are rare events, contamination rates are taken from 2% to 10%. Following (Xu et al., 2023;Pang et al., 2019), if the number of candidate anomalies is insufficient to meet the target contamination ratio, we swap 5% features in two randomly sampled real anomalies to synthesize new anomalies. Figure 7 depicts the AUC-ROC performance of eight anomaly detectors w.r.t. contamination rate in training data. SLAD shows consistent superiority over its contenders in different scenarios. As these deep anomaly detectors essentially model normal conditions and identify anomalies by measuring the deviation to learned models, contaminated anomalies in training data may mislead the modeling process, leading to the overfitting problem. Generally, detection performance is downgraded with the increase of contamination rate. The increased anomalies may contain diverse behaviors, and thus the performance of some anomaly detectors shows fluctuant trends. In addition, almost all anomaly detectors show stable performance on Amazon (tab) and Yelp (tab). These two datasets are challenging, and all the anomaly detectors fail to yield sufficient detection results as reported in Table 1. The anomalies in these data are similar to inliers and hard to distinguish since the transferred tabular features may only describe semantic information and not be informative to identify anomalies. Therefore, anomaly detectors might not suffer from the overfitting problem induced by anomaly contamination.</p>
<p>H.3. Scalability Test</p>
<p>We further conduct a scalability test to examine the time efficiency of SLAD. A group of synthetic datasets is produced containing 5,000 data instances and varied dimensionality (i.e., {64, 128, 256, 1,024, 2,048, 4,096}). We create another suite of data with different data sizes ranging from 4,000 to 256,000 and fixed dimensionality (i.e., 32). These two groups of datasets are used to respectively examine the scalability w.r.t. dimensionality and data size. For the sake of fairness, SLAD is compared with deep anomaly detectors implemented in the PyTorch framework. We report the execution time including the training time of 10 epochs and the inference time. Figure 8 demonstrates the scalability test results. SLAD is less efficient than other anomaly detectors on high-dimensional data. In our implementation, we employ subspaces of the original data, and the neural transformation function T needs to prepare a number of neural layers to handle different subspace lengths. This process may induce relatively heavy overhead. Nevertheless, thanks to the GPU acceleration power, all the anomaly detectors take less than 25 seconds to handle 4,096-dimensional data. In addition, recall that we use a dataset Thrombin that contains over one hundred thousand features, SLAD can process this ultra-high-dimensional data in 6 minutes. In terms of the scalability w.r.t. data size, SLAD and contrastive models (ICL, NeuTraL, and GOAD) have comparable time efficiency. DSVDD is faster since it maps all the input to a representation and poses a distance-based one-class constraint. However, SLAD and contrastive self-supervised models can lead to superior detection accuracy.</p>
<p>H.4. Parameter Sensitivity</p>
<p>This experiment investigates the sensitivity of our model to four key hyper-parameters including c (the number of elements in each created data sample of scale learning), r (the factor that adjusts the total size of training samples), h (the dimensionality of representations), and γ (the magnification factor in the labeling function G), thereby guiding how to set them during practical usages. In each experiment, the tested parameter takes different values, while others are fixed as default. Candidate values for r and c are taken from {2, 5, 10, 20, 30}, the dimensionality h is chosen from 8 to 256, and γ uses values in {1, 50, 100, 200, 500}. Figure 9 reports the AUC-ROC performance of SLAD with different settings. In terms of the parameter c, the increase of c from 2 to 10 brings observable AUC-ROC gain on most of the datasets, while the performance is clearly downgraded on two datasets when c continually raises. SLAD treats a whole list of transferred data as one training sample, but simultaneously optimizing a very long list of predictions (i.e., a large c) may also harm the performance. In terms of r, a larger r generally brings better results, which is also true in many similar ensemble scenarios. Based on the above experimental results, we recommend using n = 10 and r = 20 in practical usage. Lower dimensionality h cannot contain enough information, which downgrades the detection performance, especially on the high-dimensional dataset Thrombin. On the contrary, a large h may be not always feasible. We set h = 128 by default in SLAD, which is frequently used as representation dimensionality in many deep models. As for the magnification factor γ, a larger γ can enlarge the spacing between different scale values. We use a unified representation dimensionality h for datasets with varied feature numbers, and thus raw scale values are very small and are hard to be differentiated when handling low-dimensional data (their sub-vectors are short). By using a magnification factor, detection performance shows notable improvement on Waveform and PageBlocks. SLAD performs stably on other datasets w.r.t. γ.</p>
<p>I. Future Directions</p>
<p>We propose scale learning as a novel self-supervised proxy task for anomaly detection in tabular data. This section notes three future directions that are worth to be explored: (i) SLAD can be generalized to different learning tasks like pre-training representation models on large-scale tabular data, as has been done in (Bahri et al., 2022;Yao et al., 2021;Yoon et al., 2020). (ii) SLAD can be extended to handle other data types like time series, graph data, or even images by defining appropriate sampling operation, the transformation function, and the labeling function. (iii) The intermediate results in SLAD can be further processed for anomaly interpretation (Xu et al., 2021). As empirical errors derived from the loss function indicate the deviation of the target data instance in different feature subspaces, and thus these fine-grained outputs can be further utilized to yield a tailored feature subspace as an interpretation showing the anonymous part of the data instance.</p>
<p>Figure 2 .
2Overall framework of SLAD. For an original data instance x, SLAD first generates a group of c sub-vectors {x (S i ) } c i=1</p>
<p>Evaluation
Protocol. We follow the mainstream experimental setting of this research line(Bergman &amp; Hoshen, 2020; Qiu et al., 2021; Shenkar &amp; Wolf, 2022)  by using 50% of normal samples for training, while the testing set contains the other half of normal samples as well as all the anomalies Following(Campos et al., 2016; Pang et al., 2019;  Wang et al., 2022;Han et al., 2022; Xu et al., 2019), two evaluation metrics, the area under the Receiver-Operating-Characteristic curve (AUC-ROC) and the area under the Precision-Recall curve (AUC-PR), are employed. These two metrics can impartially evaluate the detection performance, while not posing any assumption on the anomaly threshold. Unless otherwise stated, the reported metrics are averaged results over five independent runs.Baseline Methods. Seven state-of-the-art baselines are utilized. ICL(Shenkar &amp; Wolf, 2022), NeuTraL (Qiu et al.,  2021, and GOAD(Bergman &amp; Hoshen, 2020) are contrastive self-supervised methods.RCA (Liu et al., 2021)   andGAAL (Liu et al., 2019)  are reconstruction-based generative methods. We also utilize DSVDD(Ruff et al., 2018), which is a deep anomaly detection method based on oneclass classification. iForest(Liu et al., 2008) is a popular traditional (non-deep) anomaly detection baseline.</p>
<p>Figure 3 .
3(Left) AUC-ROC with 95% confidence intervals on datasets with different numbers of classes considered to be inliers. (Right) The proportion of decline compared to only one class appeared in normal data.</p>
<p>Figure 4 .
4Loss values of testing inliers/anomalies during training.</p>
<p>Figure 5 .
5Loss values of data from the trained class and other new classes that only appear in the testing stage. * indicates the trained class. The red dashed line marks the upper quartile loss values of data instances from the trained class.</p>
<p>Figure 6 .
6P r(S is useful) of different α and β settings w.r.t. the dimensionality of feature space.</p>
<p>U
c × h matrix U for transferred data.13:Initialize a c-dimensional vector y for scale-based labels.(i,·) ← T (x (Si) ), y (i) ← G(S i , h) -batch training data B x ∼ O, B y ∼ Y.25:L ← E U∼Bx,y∼By ℓ σ(Φ(U))∥σ(y)</p>
<p>Our experiments are conducted on a workstation with Intel Xeon Silver 4210R CPU, a single NVIDIA TITAN RTX GPU, and 64 GB RAM. All the anomaly detection methods used in our experiments are implemented in Python. Deep detectors (SLAD, ICL, NeuTraL, GOAD, RCA) use the PyTorch framework (Paszke et al., 2019). We implement them in the DeepOD package (https://github.com/xuhongzuo/deepod). The implementation of GAAL is taken from the PyOD package (Zhao et al., 2019), and the non-deep baseline iForest is implemented in the Scikit-learn package. The source code of SLAD is available at https://github.com/xuhongzuo/scale-learning.</p>
<p>Figure 7 .
7AUC-ROC Performance of SLAD and its competing methods w.r.t. different contamination rate (the percentage of anomalies in training data).</p>
<p>Figure 8 .Figure 9 .
89Scalability Detection performance of SLAD with different hyper-parameter settings.</p>
<p>Table 1 .
1Detection accuracy (AUC-ROC/AUC-PR ± standard deviation) of SLAD and its competing methods. The best detector per dataset is boldfaced. ICL and GAAL run out of memory (OOM) on the ultra-high-dimensional dataset Thrombin. NB15 0.941 ± 0.004 0.918 ± 0.010 0.916 ± 0.017 0.903 ± 0.003 0.935 ± 0.001 0.796 ± 0.060 0.902 ± 0.028 0.758 ± 0.Amazon (tab) 0.605 ± 0.007 0.592 ± 0.005 0.570 ± 0.036 0.500 ± 0.000 0.538 ± 0.008 0.495 ± 0.032 0.539 ± 0.013 0.565 ± 0.tab) 0.120 ± 0.002 0.117 ± 0.001 0.114 ± 0.011 0.095 ± 0.000 0.105 ± 0.003 0.099 ± 0.008 0.107 ± 0.005 0.112 ± 0.DATA 
SLAD 
ICL 
NeuTraL 
GOAD 
RCA 
GAAL 
DSVDD 
iForest </p>
<p>AUC-ROC </p>
<p>Thyroid 
0.995 ± 0.001 0.974 ± 0.015 0.985 ± 0.002 0.952 ± 0.005 0.934 ± 0.005 0.768 ± 0.096 0.930 ± 0.032 0.988 ± 0.002 
Arrthymia 
0.825 ± 0.007 0.784 ± 0.048 0.805 ± 0.025 0.806 ± 0.008 0.767 ± 0.009 0.704 ± 0.082 0.807 ± 0.008 0.814 ± 0.007 
Waveform 
0.812 ± 0.047 0.649 ± 0.048 0.621 ± 0.023 0.604 ± 0.022 0.626 ± 0.019 0.732 ± 0.074 0.516 ± 0.012 0.718 ± 0.019 
UNSW-016 
Bank 
0.730 ± 0.004 0.724 ± 0.014 0.720 ± 0.018 0.587 ± 0.006 0.699 ± 0.003 0.655 ± 0.032 0.608 ± 0.057 0.723 ± 0.008 
Thrombin 
0.939 ± 0.007 
OOM 
0.460 ± 0.033 0.839 ± 0.011 0.916 ± 0.000 
OOM 
0.520 ± 0.046 0.898 ± 0.008 
PageBlocks 
0.972 ± 0.004 0.909 ± 0.025 0.961 ± 0.002 0.670 ± 0.006 0.864 ± 0.002 0.765 ± 0.032 0.904 ± 0.009 0.927 ± 0.005 
008 
Yelp (tab) 
0.658 ± 0.014 0.664 ± 0.009 0.627 ± 0.027 0.501 ± 0.000 0.585 ± 0.008 0.584 ± 0.039 0.593 ± 0.032 0.609 ± 0.007 
MVTec (tab) 
0.812 ± 0.009 0.778 ± 0.010 0.788 ± 0.009 0.666 ± 0.030 0.663 ± 0.022 0.675 ± 0.026 0.806 ± 0.014 0.757 ± 0.011 </p>
<p>AUC-PR </p>
<p>Thyroid 
0.921 ± 0.012 0.726 ± 0.070 0.824 ± 0.018 0.778 ± 0.008 0.654 ± 0.012 0.429 ± 0.133 0.470 ± 0.030 0.783 ± 0.037 
Arrthymia 
0.604 ± 0.006 0.572 ± 0.038 0.589 ± 0.022 0.631 ± 0.005 0.562 ± 0.009 0.505 ± 0.071 0.646 ± 0.008 0.633 ± 0.021 
Waveform 
0.432 ± 0.132 0.123 ± 0.040 0.095 ± 0.014 0.079 ± 0.004 0.088 ± 0.008 0.148 ± 0.060 0.059 ± 0.002 0.111 ± 0.005 
UNSW-NB15 0.858 ± 0.003 0.859 ± 0.005 0.811 ± 0.014 0.813 ± 0.005 0.542 ± 0.009 0.470 ± 0.230 0.794 ± 0.028 0.111 ± 0.006 
Bank 
0.470 ± 0.003 0.468 ± 0.015 0.445 ± 0.018 0.300 ± 0.006 0.423 ± 0.002 0.370 ± 0.050 0.315 ± 0.059 0.449 ± 0.013 
Thrombin 
0.625 ± 0.014 
OOM 
0.038 ± 0.002 0.648 ± 0.013 0.587 ± 0.003 
OOM 
0.074 ± 0.023 0.421 ± 0.017 
PageBlocks 
0.872 ± 0.016 0.799 ± 0.033 0.871 ± 0.008 0.449 ± 0.010 0.739 ± 0.004 0.500 ± 0.034 0.746 ± 0.017 0.705 ± 0.015 
Amazon (002 
Yelp (tab) 
0.153 ± 0.005 0.153 ± 0.003 0.153 ± 0.015 0.097 ± 0.000 0.127 ± 0.005 0.125 ± 0.012 0.135 ± 0.013 0.132 ± 0.003 
MVTec (tab) 
0.778 ± 0.009 0.740 ± 0.009 0.751 ± 0.011 0.606 ± 0.032 0.604 ± 0.022 0.618 ± 0.028 0.771 ± 0.017 0.698 ± 0.011 </p>
<p>Table 2 .
2AUC-ROC performance with improvement rates of SLAD over its ablation variants per dataset. Positive rates are boldfaced. w/ TZero cannot handle the ultra-high-dimensional data Thrombin. As SLAD only calculates feature weights on low-dimensional data, w/o Gω is performed on three datasets.Ablation on the Creation of Supervisory Signals </p>
<p>Data 
SLAD 
w/ T Zero 
w/ T MLP 
w/o G ω </p>
<p>Thyroid 
0.995 0.992 (0.3%) 
0.995 (0.0%) 
0.950 (4.7%) 
Arrthymia 
0.825 0.814 (1.4%) 
0.821 (0.5%) 
-
Waveform 
0.812 0.759 (7.0%) 
0.767 (5.9%) 
0.800 (1.5%) 
UNSW-NB15 0.937 0.933 (0.4%) 
0.907 (3.3%) 
-
Bank 
0.730 0.724 (0.8%) 
0.717 (1.8%) 
-
Thrombin 
0.941 
0.698 (34.8%) -
PageBlocks 
0.972 0.971 (0.1%) 
0.967 (0.5%) 
0.966 (0.6%) 
Amazon (tab) 0.608 0.552 (10.1%) 0.599 (1.5%) 
-
Yelp (tab) 
0.661 0.612 (8.0%) 
0.654 (1.1%) 
-
MVTec (tab) 
0.812 0.775 (4.8%) 
0.787 (3.2%) 
-</p>
<p>Ablation on Scale Learning </p>
<p>Data 
SLAD 
w/ L ce 
w/ L mse 
w/ L dcl </p>
<p>Thyroid 
0.995 0.674 (47.6%) 0.983 (1.2%) 
0.978 (1.7%) 
Arrthymia 
0.825 0.728 (13.3%) 0.813 (1.5%) 
0.805 (2.5%) 
Waveform 
0.812 0.527 (54.1%) 0.473 (71.7%) 0.770 (5.5%) 
UNSW-NB15 0.937 0.914 (2.5%) 
0.900 (4.1%) 
0.922 (1.6%) 
Bank 
0.730 0.517 (41.2%) 0.732 (-0.3%) 
0.714 (2.2%) 
Thrombin 
0.941 0.704 (33.7%) 0.493 (90.9%) 0.626 (50.3%) 
PageBlocks 
0.972 0.742 (31.0%) 0.979 (-0.7%) 
0.976 (-0.4%) 
Amazon (tab) 0.608 0.536 (13.4%) 0.602 (1.0%) 
0.610 (-0.3%) 
Yelp (tab) 
0.661 0.556 (18.9%) 0.666 (-0.8%) 
0.676 (-2.2%) 
MVTec (tab) 
0.812 0.646 (25.7%) 0.764 (6.3%) 
0.776 (4.6%) </p>
<p>Xu, H., Pang, G., Wang, Y., and Wang, Y. Deep isolation forest for anomaly detection. IEEE Transactions on Knowledge and Data Engineering, pp. 1-14, 2023. doi: 10.1109/TKDE.2023.3270293.Hendrycks, D., Mazeika, M., and Dietterich, T. Deep 
anomaly detection with outlier exposure. In International 
Conference on Learning Representations, 2019. </p>
<p>Larsen, A. B. L., Sønderby, S. K., Larochelle, H., and 
Winther, O. Autoencoding beyond pixels using a learned 
similarity metric. In Proceedings of the 33rd Interna-
tional Conference on Machine Learning, volume 48, pp. 
1558-1566. PMLR, 2016. </p>
<p>Li, C.-L., Sohn, K., Yoon, J., and Pfister, T. Cutpaste: 
Self-supervised learning for anomaly detection and lo-
calization. In Proceedings of the IEEE/CVF Conference 
on Computer Vision and Pattern Recognition, pp. 9664-
9674, 2021. </p>
<p>Liu, B., Wang, D., Lin, K., Tan, P.-N., and Zhou, J. Rca: A 
deep collaborative autoencoder approach for anomaly de-
tection. In Proceedings of the Thirtieth International 
Joint Conference on Artificial Intelligence, pp. 1505-
1511, 2021. </p>
<p>Liu, F. T., Ting, K. M., and Zhou, Z.-H. Isolation forest. In 
International Conference on Data Mining, pp. 413-422. 
IEEE, 2008. </p>
<p>Liu, Y., Li, Z., Zhou, C., Jiang, Y., Sun, J., Wang, M., and 
He, X. Generative adversarial active learning for unsuper-
vised outlier detection. IEEE Transactions on Knowledge 
and Data Engineering, 32(8):1517-1528, 2019. </p>
<p>Liznerski, P., Ruff, L., Vandermeulen, R. A., Franks, B. J., 
Kloft, M., and Muller, K. R. Explainable deep one-class 
classification. In International Conference on Learning 
Representations, 2021. </p>
<p>Pang, G., Shen, C., and van den Hengel, A. Deep anomaly 
detection with deviation networks. In Proceedings of the 
25th ACM SIGKDD International Conference on Knowl-
edge Discovery &amp; Data Mining, pp. 353-362, 2019. </p>
<p>Pang, G., Yan, C., Shen, C., Hengel, A. v. d., and Bai, X. 
Self-trained deep ordinal regression for end-to-end video 
anomaly detection. In Proceedings of the IEEE/CVF 
Conference on Computer Vision and Pattern Recognition, 
pp. 12173-12182, 2020. 
Pang, G., Shen, C., Cao, L., and Hengel, A. V. D. Deep 
learning for anomaly detection: A review. ACM Comput-
ing Surveys, 54(2), 2021. </p>
<p>Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., 
Chanan, G., Killeen, T., Lin, Z., Gimelshein, N., Antiga, 
L., et al. Pytorch: An imperative style, high-performance 
deep learning library. Advances in Neural Information 
Processing Systems, 32, 2019. </p>
<p>Qiu, C., Pfrommer, T., Kloft, M., Mandt, S., and Rudolph, 
M. Neural transformation learning for deep anomaly 
detection beyond images. In Proceedings of the 38th 
International Conference on Machine Learning, volume 
139, pp. 8703-8714. PMLR, 2021. </p>
<p>Qiu, C., Li, A., Kloft, M., Rudolph, M., and Mandt, S. La-
tent outlier exposure for anomaly detection with contami-
nated data. In Proceedings of the 39th International Con-
ference on Machine Learning, volume 162, pp. 18153-
18167. PMLR, 2022. </p>
<p>Ristea, N.-C., Madan, N., Ionescu, R. T., Nasrollahi, K., 
Khan, F. S., Moeslund, T. B., and Shah, M. Self-
supervised predictive convolutional attentive block for 
anomaly detection. In Proceedings of the IEEE/CVF 
Conference on Computer Vision and Pattern Recognition, 
pp. 13576-13586, 2022. </p>
<p>Ruff, L., Vandermeulen, R., Goernitz, N., Deecke, L., Sid-
diqui, S. A., Binder, A., Müller, E., and Kloft, M. Deep 
one-class classification. In Proceedings of the 35th Inter-
national Conference on Machine Learning, volume 80, 
pp. 4393-4402, 2018. </p>
<p>Ruff, L., Kauffmann, J. R., Vandermeulen, R. A., Montavon, 
G., Samek, W., Kloft, M., Dietterich, T. G., and Müller, 
K.-R. A unifying review of deep and shallow anomaly 
detection. Proceedings of the IEEE, 109(5):756-795, 
2021. </p>
<p>Sehwag, V., Chiang, M., and Mittal, P. Ssd: A unified 
framework for self-supervised outlier detection. In Inter-
national Conference on Learning Representations, 2021. </p>
<p>Shenkar, T. and Wolf, L. Anomaly detection for tabular 
data with internal contrastive learning. In International 
Conference on Learning Representations, 2022. </p>
<p>Tack, J., Mo, S., Jeong, J., and Shin, J. Csi: novelty detec-
tion via contrastive learning on distributionally shifted 
instances. In Advances in Neural Information Processing 
Systems, pp. 11839-11852, 2020. </p>
<p>Wang, S., Zeng, Y., Yu, G., Cheng, Z., Liu, X., Zhou, S., 
Zhu, E., Kloft, M., Yin, J., and Liao, Q. E 3 outlier: A 
self-supervised framework for unsupervised deep outlier 
detection. IEEE Transactions on Pattern Analysis and 
Machine Intelligence, 45(3):2952-2969, 2022. </p>
<p>Wang, Z., Wang, Y., Xu, H., and Wang, Y. Effective anomaly 
detection based on reinforcement learning in network 
traffic data. In Proceedings of the IEEE 27th International 
Conference on Parallel and Distributed Systems, pp. 299-
306. IEEE, 2021. </p>
<p>Wolpert, D. H. and Macready, W. G. No free lunch theorems 
for optimization. IEEE Transactions on Evolutionary 
Computation, 1(1):67-82, 1997. </p>
<p>Xia, Y., Cao, X., Wen, F., Hua, G., and Sun, J. Learning 
discriminative reconstructions for unsupervised outlier re-
moval. In International Conference on Computer Vision, 
pp. 1511-1519, 2015. </p>
<p>Xu, H., Wang, Y., Wang, Y., and Wu, Z. Mix: A joint learn-
ing framework for detecting both clustered and scattered 
outliers in mixed-type data. In International Conference 
on Data Mining, pp. 1408-1413. IEEE, 2019. </p>
<p>Xu, H., Wang, Y., Jian, S., Huang, Z., Wang, Y., Liu, N., 
and Li, F. Beyond outlier detection: Outlier interpretation 
by attention-guided triplet deviation network. In Proceed-
ings of the Web Conference, pp. 1328-1339, 2021. </p>
<p>Yao, T., Yi, X., Cheng, D. Z., Yu, F., Chen, T., Menon, 
A., Hong, L., Chi, E. H., Tjoa, S., Kang, J., et al. Self-
supervised learning for large-scale item recommenda-
tions. In Proceedings of the 30th ACM International 
Conference on Information &amp; Knowledge Management, 
pp. 4321-4330, 2021. </p>
<p>Yoon, J., Zhang, Y., Jordon, J., and van der Schaar, M. Vime: 
Extending the success of self-and semi-supervised learn-
ing to tabular domain. Advances in Neural Information 
Processing Systems, 33:11033-11043, 2020. </p>
<p>Zhang, Z. and Deng, X. Anomaly detection using improved 
deep svdd model with data structure preservation. Pattern 
Recognition Letters, 148:1-6, 2021. </p>
<p>Zhao, Y., Nasrullah, Z., and Li, Z. Pyod: A python tool-
box for scalable outlier detection. Journal of Machine 
Learning Research, 20:1-7, 2019. </p>
<p>Zhou, C. and Paffenroth, R. C. Anomaly detection with 
robust deep autoencoders. In Proceedings of the 23rd 
ACM SIGKDD International Conference on Knowledge 
Discovery &amp; Data Mining, pp. 665-674, 2017. </p>
<p>Table 3 .
3Dataset information. Data size and dimensionality indicate the number of data instances, and the number of features. #anom and ratio denote the number of anomalies and the abnormal percentage over all the data instances. The statistical information of MVTec (tab) is the average value over its fifteen sub-datasets.Dataset 
Domain 
Data size Dimensionality #anom ratio </p>
<p>Thyroid 
Healthcare 
3,772 
6 
93 
2.5% 
Arrhythmia 
Healthcare 
452 
274 
66 
14.6% 
Waveform 
Physics 
3,443 
21 
100 
2.9% 
UNSW-NB15 Intrusion detection 96,000 
196 
3,000 
3.1% 
Bank 
Marketing 
41,188 
62 
4,640 
11.3% 
Thrombin 
Biology 
1,909 
139,351 
42 
2.2% 
PageBlocks 
Web 
5,393 
10 
510 
9.5% 
Amazon (tab) NLP 
10,000 
768 
500 
5.0% 
Yelp (tab) 
NLP 
10,000 
768 
500 
5.0% 
MVTec (tab) 
CV 
357 
512 
84 
23.5% </p>
<p>Table 4 .
4Detection performance on a benchmark collection with 47 datasets. Avg. Rank indicates the average ranking of all the datasets. #Top2 and #Top4 respectively count the times that each anomaly detector rank within the Top2 and Top4 positions, and %Top2 and %Top4 denote the corresponding percentage. ↑ indicates that the higher the indicator, the better the detection performance, while ↓ denotes the lower the better.Model 
AUC-ROC 
AUC-PR </p>
<p>Avg. Rank (↓) #Top2 (↑) %Top2 (↑) #Top4 (↑) %Top4 (↑) Avg. Rank (↓) #Top2 (↑) %Top2 (↑) #Top4 (↑) %Top4 (↑) </p>
<p>iForest 
3.77 
16 
34.0% 
27 
57.4% 
4.26 
12 
25.5% 
24 
51.1% 
DSVDD 
4.66 
10 
21.3% 
20 
42.6% 
4.70 
12 
25.5% 
19 
40.4% 
GAAL 
6.23 
4 
8.5% 
9 
19.1% 
6.21 
4 
8.5% 
8 
17.0% 
RCA 
4.13 
13 
27.7% 
26 
55.3% 
4.21 
11 
23.4% 
26 
55.3% 
GOAD 
6.15 
5 
10.6% 
10 
21.3% 
5.85 
5 
10.6% 
10 
21.3% 
NeuTraL 
3.68 
16 
34.0% 
28 
59.6% 
3.77 
17 
36.2% 
31 
66.0% 
ICL 
4.09 
12 
25.5% 
27 
57.4% 
3.64 
16 
34.0% 
33 
70.2% 
SLAD (ours) 
2.98 
22 
46.8% 
39 
83.0% 
2.98 
21 
44.7% 
38 
80.9% </p>
<p>2% 4% 6% 8%10% 
contamination rate </p>
<p>0.7 </p>
<p>0.8 </p>
<p>0.9 </p>
<p>1.0 </p>
<p>AUC-ROC </p>
<p>Thyroid </p>
<p>2% 4% 6% 8%10% 
contamination rate </p>
<p>0.65 </p>
<p>0.70 </p>
<p>0.75 </p>
<p>0.80 </p>
<p>Arrhythmia </p>
<p>2% 4% 6% 8%10% 
contamination rate </p>
<p>0.2 </p>
<p>0.4 </p>
<p>0.6 </p>
<p>0.8 </p>
<p>Waveform </p>
<p>2% 4% 6% 8%10% 
contamination rate </p>
<p>0.2 </p>
<p>0.4 </p>
<p>0.6 </p>
<p>0.8 </p>
<p>1.0 </p>
<p>UNSW-NB15 </p>
<p>2% 4% 6% 8%10% 
contamination rate </p>
<p>0.5 </p>
<p>0.6 </p>
<p>0.7 </p>
<p>0.8 </p>
<p>Bank </p>
<p>2% 4% 6% 8%10% 
contamination rate </p>
<p>0.2 </p>
<p>0.4 </p>
<p>0.6 </p>
<p>0.8 </p>
<p>1.0 </p>
<p>AUC-ROC </p>
<p>Thrombin </p>
<p>2% 4% 6% 8%10% 
contamination rate </p>
<p>0.6 </p>
<p>0.8 </p>
<p>1.0 </p>
<p>PageBlocks </p>
<p>2% 4% 6% 8%10% 
contamination rate </p>
<p>0.40 
0.45 
0.50 
0.55 
0.60 </p>
<p>0.65 Amazon (tab) </p>
<p>2% 4% 6% 8%10% 
contamination rate </p>
<p>0.4 </p>
<p>0.5 </p>
<p>0.6 </p>
<p>0.7 </p>
<p>Yelp (tab) </p>
<p>2% 4% 6% 8%10% 
contamination rate </p>
<p>0.60 
0.65 
0.70 
0.75 
0.80 </p>
<p>0.85 MVTec (tab) </p>
<p>SLAD 
ICL 
NeuTraL 
GOAD 
RCA 
GAAL 
DSVDD 
iForest </p>
<p>National Key Laboratory of Parallel and Distributed Computing 2 College of Computer, National University of Defense Technology 3 College of Science, National University of Defense Technology. Correspondence to: Yijie Wang <a href="&#109;&#97;&#105;&#108;&#116;&#111;&#58;&#119;&#97;&#110;&#103;&#121;&#105;&#106;&#105;&#101;&#64;&#110;&#117;&#100;&#116;&#46;&#101;&#100;&#117;&#46;&#99;&#110;">&#119;&#97;&#110;&#103;&#121;&#105;&#106;&#105;&#101;&#64;&#110;&#117;&#100;&#116;&#46;&#101;&#100;&#117;&#46;&#99;&#110;</a>.
To compute ∇ 2 w k g(s,k)i,j (0), we first compute the following derivatives:where δ outputs whether two inputs are the same, i.e., δ(k, l) = 1 if k = l and δ(k, l) = 0 otherwise. Therefore,andIf k = l and w = 0, we haveIf k ̸ = l and w = 0, we haveHence,The literature(Anand et al., 1993)has proved that the randomly initialized network have: E h
Outlier analysis. C C Aggarwal, 10.1007/978-1-4614-6396-2SpringerAggarwal, C. C. Outlier analysis. Springer, 2017. doi: https://doi.org/10.1007/978-1-4614-6396-2.</p>
<p>An improved algorithm for neural network classification of imbalanced training sets. R Anand, K G Mehrotra, C K Mohan, S Ranka, IEEE Transactions on Neural Networks. 46Anand, R., Mehrotra, K. G., Mohan, C. K., and Ranka, S. An improved algorithm for neural network classification of imbalanced training sets. IEEE Transactions on Neural Networks, 4(6):962-969, 1993.</p>
<p>Scarf: Selfsupervised contrastive learning using random feature corruption. D Bahri, H Jiang, Y Tay, D Metzler, International Conference on Learning Representations. Bahri, D., Jiang, H., Tay, Y., and Metzler, D. Scarf: Self- supervised contrastive learning using random feature cor- ruption. In International Conference on Learning Repre- sentations, 2022.</p>
<p>Classification-based anomaly detection for general data. L Bergman, Y Hoshen, International Conference on Learning Representations. Bergman, L. and Hoshen, Y. Classification-based anomaly detection for general data. In International Conference on Learning Representations, 2020.</p>
<p>On the evaluation of unsupervised outlier detection: measures, datasets, and an empirical study. Data mining and knowledge discovery. G O Campos, A Zimek, J Sander, R J Campello, B Micenková, E Schubert, I Assent, M E Houle, 30Campos, G. O., Zimek, A., Sander, J., Campello, R. J., Mi- cenková, B., Schubert, E., Assent, I., and Houle, M. E. On the evaluation of unsupervised outlier detection: mea- sures, datasets, and an empirical study. Data mining and knowledge discovery, 30(4):891-927, 2016.</p>
<p>Outlier detection with autoencoder ensembles. J Chen, S Sathe, C Aggarwal, D Turaga, SIAM International Conference on Data Mining. SIAMChen, J., Sathe, S., Aggarwal, C., and Turaga, D. Outlier detection with autoencoder ensembles. In SIAM Inter- national Conference on Data Mining, pp. 90-98. SIAM, 2017.</p>
<p>Deep anomaly detection using geometric transformations. I Golan, R El-Yaniv, S Goyal, A Raghunathan, M Jain, H V Simhadri, P Jain, Proceedings of the 37th International Conference on Machine Learning. the 37th International Conference on Machine LearningPMLR119Advances in Neural Information Processing SystemsGolan, I. and El-Yaniv, R. Deep anomaly detection us- ing geometric transformations. In Advances in Neural Information Processing Systems, pp. 9758-9769, 2018. Goyal, S., Raghunathan, A., Jain, M., Simhadri, H. V., and Jain, P. DROCC: Deep robust one-class classification. In Proceedings of the 37th International Conference on Machine Learning, volume 119, pp. 3711-3721. PMLR, 2020.</p>
<p>Adbench: Anomaly detection benchmark. S Han, X Hu, H Huang, M Jiang, Y Zhao, Advances in Neural Information Processing Systems: Datasets and Benchmarks Track. Han, S., Hu, X., Huang, H., Jiang, M., and Zhao, Y. Ad- bench: Anomaly detection benchmark. In Advances in Neural Information Processing Systems: Datasets and Benchmarks Track, 2022.</p>            </div>
        </div>

    </div>
</body>
</html>