<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-7815 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-7815</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-7815</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-143.html">extraction-schema-143</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to distill quantitative laws, equations, or functional relationships from collections of scholarly papers, including details of the models, prompting or fine‑tuning approaches, input corpora, extraction methods, types of laws, representation formats, evaluation datasets, metrics, baseline comparisons, validation procedures, and reported performance or limitations.</div>
                <p><strong>Paper ID:</strong> paper-754826db83d6115674afef73316aeb75b2ae41de</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/754826db83d6115674afef73316aeb75b2ae41de" target="_blank">Knowledge Augmented Machine Learning with Applications in Autonomous Driving: A Survey</a></p>
                <p><strong>Paper Venue:</strong> arXiv.org</p>
                <p><strong>Paper TL;DR:</strong> An overview of existing techniques and methods in the literature that combine data-driven models with existing knowledge, structured according to the categories knowledge integration, extraction and conformity, in the field of autonomous driving is provided.</p>
                <p><strong>Paper Abstract:</strong> The availability of representative datasets is an essential prerequisite for many successful artificial intelligence and machine learning models. However, in real life applications these models often encounter scenarios that are inadequately represented in the data used for training. There are various reasons for the absence of sufficient data, ranging from time and cost constraints to ethical considerations. As a consequence, the reliable usage of these models, especially in safety-critical applications, is still a tremendous challenge. Leveraging additional, already existing sources of knowledge is key to overcome the limitations of purely data-driven approaches. Knowledge augmented machine learning approaches offer the possibility of compensating for deficiencies, errors, or ambiguities in the data, thus increasing the generalization capability of the applied models. Even more, predictions that conform with knowledge are crucial for making trustworthy and safe decisions even in underrepresented scenarios. This work provides an overview of existing techniques and methods in the literature that combine data-driven models with existing knowledge. The identified approaches are structured according to the categories knowledge integration, extraction and conformity. In particular, we address the application of the presented methods in the field of autonomous driving.</p>
                <p><strong>Cost:</strong> 0.008</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <p class="empty-note">No extracted data.</p>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <p class="empty-note">No potentially relevant new papers extracted.</p>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-7815",
    "paper_id": "paper-754826db83d6115674afef73316aeb75b2ae41de",
    "extraction_schema_id": "extraction-schema-143",
    "extracted_data": [],
    "potentially_relevant_new_papers": [],
    "cost": 0.007792,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Knowledge Augmented Machine Learning with Applications in Autonomous Driving: A Survey</h1>
<p>Julian Wörmann ${ }^{7}$, Daniel Bogdoll ${ }^{9}$, Christian Brunner ${ }^{6}$, Etienne Bührle ${ }^{9}$, Han Chen ${ }^{2}$, Evaristus Fuh Chuo ${ }^{2}$, Kostadin Cvejoski ${ }^{8}$, Ludger van Elst ${ }^{4}$, Philip Gottschall ${ }^{8}$, Stefan Griesche ${ }^{10}$, Christian Hellert ${ }^{3}$, Christian Hesels ${ }^{8}$, Sebastian Houben ${ }^{8}$, Tim Joseph ${ }^{9}$, Niklas Keil ${ }^{1}$, Johann Kelsch ${ }^{5}$, Mert Keser ${ }^{3}$, Hendrik Königshof ${ }^{9}$, Erwin Kraft ${ }^{3}$, Leonie Kreuser ${ }^{1}$, Kevin Krone ${ }^{8}$, Tobias Latka ${ }^{6}$, Denny Mattern ${ }^{8}$, Stefan Matthes ${ }^{7}$, Franz Motzkus ${ }^{3}$, Mohsin Munir ${ }^{4}$, Moritz Nekolla ${ }^{9}$, Adrian Paschke ${ }^{8}$, Stefan Pilar von Pilchau ${ }^{6}$, Maximilian Alexander Pintz ${ }^{8}$, Tianming Qiu ${ }^{7}$, Faraz Qureishi ${ }^{12}$, Syed Tahseen Raza Rizvi ${ }^{4}$, Jörg Reichardt ${ }^{3}$, Laura von Rueden ${ }^{8}$, Alexander Sagel ${ }^{7}$, Diogo Sasdelli ${ }^{11}$, Tobias Scholl ${ }^{8}$, Gerhard Schunk ${ }^{12}$, Gesina Schwalbe ${ }^{3}$, Hao Shen ${ }^{7}$, Youssef Shoeb ${ }^{3}$, Hendrik Stapelbroek ${ }^{2}$, Vera Stehr ${ }^{12}$, Gurucharan Srinivas ${ }^{5}$, Anh Tuan Tran ${ }^{10}$, Abhishek Vivekanandan ${ }^{9}$, Ya Wang ${ }^{8}$, Florian Wasserrab ${ }^{1}$, Tino Werner ${ }^{5}$, Christian Wirth ${ }^{3}$, and Stefan Zwicklbauer ${ }^{3}$<br>${ }^{1}$ Alexander Thamm GmbH<br>${ }^{2}$ Capgemini Engineering<br>${ }^{3}$ Continental AG<br>${ }^{4}$ Deutsches Forschungszentrum für Künstliche Intelligenz GmbH (DFKI)<br>${ }^{5}$ Deutsches Zentrum für Luft- und Raumfahrt e.V. (DLR)<br>${ }^{6}$ e:fs TechHub GmbH<br>${ }^{7}$ fortiss GmbH<br>${ }^{8}$ Fraunhofer-Gesellschaft zur Förderung der angewandten Forschung e.V. (FOKUS \&amp; IAIS)<br>${ }^{9}$ FZI Forschungszentrum Informatik<br>${ }^{10}$ Robert Bosch GmbH<br>${ }^{11}$ Universität des Saarlandes<br>${ }^{12}$ Valeo Schalter und Sensoren GmbH</p>
<h4>Abstract</h4>
<p>The availability of representative datasets is an essential prerequisite for many successful artificial intelligence and machine learning models. However, in real life applications these models often encounter scenarios that are inadequately represented in the data used for training. There are various reasons for the absence of sufficient data, ranging from time and cost constraints to ethical considerations. As a consequence, the reliable usage of these models, especially in safety-critical applications, is still a tremendous challenge. Leveraging additional, already existing sources of knowledge is key to overcome the limitations of purely data-driven approaches. Knowledge augmented machine learning approaches offer the possibility of compensating for deficiencies, errors, or ambiguities in the data, thus increasing the generalization capability of the applied models. Even more, predictions that conform with knowledge are crucial for making trustworthy and safe decisions even in underrepresented scenarios. This work provides an overview of existing techniques and methods in the literature that combine data-driven models with existing knowledge. The identified approaches are structured according to the categories knowledge integration, extraction and conformity. In particular, we address the application of the presented methods in the field of autonomous driving.</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>1 Introduction ..... 3
2 Overview use case domains ..... 3
2.1 Perception ..... 3
2.2 Situation Interpretation ..... 5
2.3 Planning ..... 6
3 Knowledge Representations ..... 7
3.1 Symbolic Representations and Knowledge Crafting ..... 8
3.2 Knowledge Representation Learning ..... 10
4 Knowledge Integration ..... 12
4.1 Auxiliary Losses and Constraints ..... 12
4.2 Neural-symbolic Integration ..... 16
4.3 Attention Mechanism ..... 19
4.4 Data Augmentation ..... 20
4.5 State Space Models ..... 23
4.6 Reinforcement Learning ..... 27
4.7 Deep-Learning with Prior Knowledge Maps ..... 30
5 Knowledge Transfer ..... 31
5.1 Transfer Learning ..... 31
5.2 Continual Learning ..... 33
5.3 Meta Learning ..... 36
5.4 Active Learning ..... 38
6 Knowledge Extraction - Symbolic Explanations ..... 42
6.1 Rule Extraction and Rule Learning ..... 42
6.2 Structured Output Prediction ..... 46
6.3 Natural Language Processing for Legal Domain ..... 47
6.4 Question Answering ..... 48
7 Knowledge Extraction - Visual Explanations ..... 49
7.1 Visual Analytics ..... 49
7.2 Saliency Maps ..... 50
7.3 Interpretable Feature Learning ..... 53
8 Knowledge Conformity ..... 54
8.1 Uncertainty Estimation ..... 54
8.2 Causal Reasoning ..... 59
8.3 Rule Conformity ..... 62
8.4 Artificial Intelligence Verification ..... 63
8.5 Run-time Network Verification ..... 68
List of Abbreviations ..... 72
References ..... 73</p>
<h2>1 INTRODUCTION</h2>
<p>Data-driven learning, first and foremost deep learning, has become a key paradigm in the vast majority of current Artificial Intelligence (AI) and Machine Learning (ML) applications. The excellent performance of many models trained in a supervised manner can be predominantly attributed to the availability of huge amounts of labeled data. Prominent examples are image classification and object detection, sequential data processing as well as decision making. On the downside, the unprecedented performance comes at the cost of lacking interpretability and transparency leading to so called black box models that do not allow easy and straightforward verification by humans.</p>
<p>The application of data-driven models in safety-critical applications is therefore a major challenge. On the one hand, labeled data covering both common and critical scenarios are limited due to high acquisition costs or, not least, for ethical reasons. This makes it extremely difficult to learn robust models that can make reliable predictions even in underrepresented scenarios. On the other hand, both, developers and users postulate the requirement to be able to understand the decisions made by the deployed model. Consequently, there is a strong interest in understanding the internal information processing as well as the inputoutput behavior in order to identify and eliminate potential weaknesses of the models used.</p>
<p>In order to tackle the aforementioned challenges, the exploitation of existing knowledge sources in form of, e.g., basic laws of physics, logical databases of facts, common behaviour in certain scenarios, or simply counterexamples is key to evolve purely data-driven models towards robustness against perturbations, better generalization to unseen samples, and conformity to existing principles of safe and reliable behaviour. However, the utilization of knowledge raises fundamental questions. How do we represent and formalize knowledge such that it is machine readable? What kind of interfaces exist such that the knowledge component can be seamlessly integrated into the classic data-driven workflow? Does the learned model itself implicitly follow concepts that resemble existing patterns of knowledge? And finally, how do we assess and measure the impact of knowledge on the intended functional behaviour?</p>
<p>This survey provides a collection of existing methods and procedures from literature that facilitate the augmentation of data-driven models with knowledge, that allow for the extraction of informative concepts and patterns out of given models and that provide mechanisms to compare observed outputs and representations to existing basic assumptions and common understanding about safe, reliable and intuitive behaviour. The goal of this overview is to introduce the reader to existing approaches and methods for linking knowledge and data, paving the way to trustworthy ML models that can be safely used in critical applications.</p>
<p>Autonomous driving can be certainly considered as one of these applications, that require robust and reliable models that enable safe and comfortable driving maneuvers. In our overview, we approach knowledge augmented machine learning from this perspective, highlighting the interfaces to certain base functionalities of autonomous driving. However, we believe that this review can also provide a comprehensive
overview of existing methods for many other applications as well.</p>
<p>This review is structured as follows. In Chapter 2, we first introduce three major tasks that autonomous agents encounter during interaction with their environment, namely perception, situation interpretation and planning. Chapter 3 reviews different perspectives to represent knowledge and to make it machine readable. Subsequently, various general approaches and techniques eligible to combine knowledge with data-driven approaches, as well as more specific methods tailored to the autonomous driving use case, are presented in Chapter 4. Furthermore, Chapter 5 introduces learning paradigms in the context of knowledge transfer.</p>
<p>Besides integration of knowledge, current approaches focusing on the extraction of concepts and structures are outlined in the subsequent chapters. While Chapter 6 summarizes methods that provide symbolic, partly natural language explanations, Chapter 7 puts emphasis on procedures that allow for visual inspection of the decision process. We conclude our survey in Chapter 8 with an overview of techniques that consider conformity to already existing as well as newly discovered knowledge components, which eventually completes the pipeline of knowledge empowered artificial intelligence.</p>
<h2>2 OVERVIEW USE CASE DOMAINS</h2>
<p>The task of automated driving may be sub categorized into the following categories: perception, situation interpretation, planning and control [376]. The foremost task in the autonomous driving is to understand and perceive the environment around the vehicle. Section 2.1 provides an introduction to the perception module with a special focus on image-based pedestrian detection. Once the objects are detected and segmented, the second task in the autonomous driving is to understand the environment along with the road users. In order to perform safe maneuvers, the situation interpretation is a decisive step. In this module, the goal is to answer important questions related to object's states and actions, like what an object could do next. An overview is given in section Section 2.2. After figuring out these situational scenarios, next task in autonomous driving is to plan the motion of ego vehicle. The planning module described in Section 2.3 utilizes the output of the previous two modules and takes high level routing and trajectory planning decisions.</p>
<h3>2.1 Perception</h3>
<p>Authors: Syed Tahseen Raza Rizvi, Mohsin Munir, Ludger van Elst</p>
<h3>2.1.1 Perception in the AD Stack</h3>
<p>Perception plays a crucial role in attaining the goal of autonomous driving. An ego-vehicle is generally equipped with a variety of sensors including cameras, lidar and radar. These sensors serve as the senses of an ego-vehicle and therefore enable the capability of perceiving the environment around the ego-vehicle in different spectrums. Object detection, and in particular pedestrian detection, has significant importance in the perception spectra as it serves as a critical piece of information for the downstream tasks associated with the autonomous driving pipeline.</p>
<h3>2.1.2 Task Formulation</h3>
<p>Autonomous driving systems highly rely on object detection models to identify all the traffic participants. Pedestrians are usually the most common and abundantly found traffic participant. Therefore, the detection of a pedestrian is more prominent and crucial for the perception of an autonomous driving system.</p>
<p>Pedestrian detection deals with the identification of pedestrians in the environment around an ego-vehicle. There exist approaches in the literature which perform pedestrian detection only using lidar sensors [543]. However, such approaches are usually not popular in the community due to fact that the features obtained from camera images are significantly richer as compared to the ones obtained from lidar or radar. On the other hand, [264] uses lidar to incorporate depth information into the image data for the pedestrian detection task. Therefore, the approaches to perform pedestrian detection mainly using camera images are generally widely adopted. The images from the mounted cameras serve as an input from which individual pedestrians are identified and are enclosed in a bounding box. A variety of solutions have been proposed to effectively identify individual pedestrians in the surrounding environment.</p>
<p>The neural network based object detection solutions can be divided into two main categories: One-stage and Twostage approaches. One-stage approaches are generally based on a fully convolutional architecture and consider the object detection problem as a simple regression problem [863]. For a given input image, the One-stage detectors learn class probabilities and the coordinates of a bounding box encompassing an object. On the other hand, Two-stage approaches are more sophisticated where each stage specializes in a sub-task which eventually contributes to the final output of the system. The first stage is responsible for identifying the region of interest and the second stage is responsible for the object classification and bounding box regression. Both types of approaches have certain pros and cons. Most notably, Twostage approaches yield better detection accuracy than Onestage approaches as they have specialized stages where the output of the second stage is built on top of the output of the first stage. However, One-stage approaches are much faster than Two-stage approaches as they do not have an additional stage with supplementary computational overhead.</p>
<p>Single Shot MultiBox Detector (SSD) [554], You Only Look Once (YOLO) [727, 729, 728], RetinaNet [542] and Fully Convolutional One-Stage object detector [897] are the most prominent One-stage object detectors. Generally, these approaches divide the image into a grid followed by predicting the probability of a class object in each grid box along with its bounding box coordinates. However, some of these approaches are slightly different as they employ a unique focal loss or pixel-wise classification to achieve a higher detection accuracy in real-time. On the other hand, Fast Regions with CNN (R-CNN) [301], Faster R-CNN [735], Mask R-CNN [363], MimicDet [567] are the most common examples of a Two-stage object detector. Generally the first stage in these Two-stage object detection model consists of a Region Proposal Network (RPN), where in the second stage the candidate region proposals are classified based on the feature maps. Approaches like Mask R-CNN have a
mask branch which is a small Fully Convolutional Network (FCN) [166] applied to each Region of Interest (ROI), predicting a pixel-wise segmentation mask. Additionally, Feature Pyramid Network (FPN) [541] is generally used in combination with RPN and Faster R-CNN to make bounding box proposal more robust especially for small objects. Recently, Khan et al. [472] proposed a two-stage pedestrian detection architecture that eliminates redundancy of current two-stage detectors by replacing the region proposal network with our focal detection network and bounding box head with our fast suppression head. Furthermore, their method has significantly lesser inference time compared to the current state-of-the-art methods.</p>
<p>Pedestrian detection is applied in various vision-based applications ranging from surveillance to autonomous driving. Despite their good performance, it is still unknown how the detection performs on unseen data. Hasan et al. [352] presented a study in quest of generalization capabilities of pedestrian detectors. In their cross-dataset evaluation, they have tested several backbones with their baseline detector (Cascade R-CNN) [105] on famous autonomous driving datasets including Caltech [199], CityPersons [1068], ECP [90], CrowdHuman [826], and Wider Pedestrian [146]. Crossdataset evaluation is an effective way of evaluating a method on unseen data and checking its generalization capability, otherwise, a method may overfit on a single dataset. The analysis presented in the paper is very interesting. The authors have demonstrated that the existing pedestrian detection methods perform poorly when compared with general object detection methods given larger and diverse datasets. A carefully trained state-of-the-art general-purpose object detector can outperform pedestrian-specific detection methods. The trick lies in the training pipeline and the dataset. In this study, the authors used large datasets that contain more persons per image. These general purpose datasets, generally collected by crawling the web and through surveillance cameras, are likely to have more human poses, appearances, and occlusion cases as compared to pedestrian-specific datasets. It is also shown in this study that by progressively fine-tuning the models from largest (general purpose) to smallest (close to target domain), performance can be improved. The generalization ability of pedestrian detectors has been compromised due to the lack of diversity and density of the pedestrian benchmarks. However, benchmarks such as WiderPerson [1070], Wider Pedestrian [146], and CrowdHuman [826] provide much higher diversity and density.</p>
<p>Pedestrian detection has improved a lot in recent years, however, it is still challenging to detect occluded pedestrians. The pedestrian appearance varies in different scenarios and depends on a wide range of occlusion patterns. To address this issue, Zhang et al. [1069] proposed an architecture for pedestrian detection based on the Faster R-CNN. In contrast to ensemble models for most frequent occlusion patterns, the authors leverage different attention mechanisms to guide the detector in paying more attention to the visible body parts. The authors proposed to employ channel-wise attention in a convolution network that allows the network to learn more representative features for different occluded body parts in one model. The observation that many Convolutional Neural Network (CNN) channels in a pedestrian CNN are</p>
<p>localizable, strongly motivates them to perform re-weighting of channel features to guide the detector to pay more attention to the visible body parts. In order to generate the attention vector, different realizations of attention networks are examined. The attention vector is trained end-to-end for all of the attention networks either through self-attention or guided by some additional external information like convolution features, visible bounding boxes, or part detection heatmaps. Eventually, the features are passed to the classification network for category prediction and bounding box regression. The experimental results are shown on the CityPersons [1068], Caltech [199], and ETH [220] datasets. The results show improvements over the baseline Faster R-CNN detector. Another crucial challenge of pedestrian detection, which is not widely discussed, is to detect pedestrians even with diversities in appearance. Most of the current detectors learn these diverse appearance features individually, but the training dataset might not comprise of good number of viewpoints or dressing diversities. To address this issue, Lin et al. [546] introduced a pedestrian detection based on contrastive learning. The proposed method guides feature learning in such a way that the semantic distance between pedestrians having different appearances is minimized and the distance between the pedestrians and the background is maximized.</p>
<p>Vulnerable road user detection is another major challenge in pedestrian detection. The safety of road users is and should be the utmost priority in the domain of autonomous driving. In addition to detect occluded pedestrians, another key challenge is to detect pedestrians at long range. When a pedestrian is detected at long range, it increases the security of the pedestrian and driver at the same time, also, it leads to a comfortable driving experience. Fürst et al. [264] introduced an approach that targets long range 3D pedestrians detection. Their approach leverages the density of Red Green Blue (RGB) images and precision of lidar. The symmetrical fusion of RGB and lidar helps them outperform current state-of-theart for long range 3D pedestrian detection.</p>
<h3>2.1.3 Goals and Requirements</h3>
<p>Perception plays a pivotal role in autonomous driving. It enables the ego vehicle to analyze and understand the traffic scene and surrounding circumstances. Detection of traffic participants, i.e., pedestrians, vehicles, cyclists, etc. serve as the core of perception involved in autonomous driving. Additionally, traffic circumstances like road, weather, and light conditions are also important factors in a traffic scenario. For instance, rainy weather results in a wet road which consequently has a direct impact on the decisions like breaking distance, because the braking distance increases in wet conditions as compared to normal drys. Therefore, traffic participants and their surrounding circumstances collectively provide a basis for planning and executing decisions taken by an ego vehicle. The significance of the perception can be understood by the fact that it directly contributes towards use cases like collision avoidance, trajectory planning, etc.</p>
<p>With the rise of deep learning for solving a universe of different tasks, object detection has also benefited from One- and Two-stage deep learning-based models to achieve higher detection performance. The effectiveness of an object detection approaches heavily relies on the efficacy of the
trained object detection model. In other words, it can be said as, provided an effective object detection model, the quality of perception can be ensured. In order to train an effective object detection model, it requires a large amount of high-quality data. For this purpose, several real-life public datasets are available, i.e., Caltech [199], CityPersons [1068], ECP [90], etc. However, certain scenarios are possibly scarce or outright not feasible in such pedestrian detection datasets. For example, it is infeasible to find a dataset that contains a traffic scenario where the ego vehicle is about to collide with another traffic participant. Such a scenario can be helpful to evaluate the performance of an object detection model to detect and evade collision in such a hazardous environment. For this purpose, datasets with simulated custom scenarios can be generated to fill this gap in reallife datasets. Ultimately, a combination of real and simulated data is the key thus enabling the object detection model to effectively perform under several unseen or rarely occurring traffic scenarios.</p>
<h3>2.1.4 Necessity of Knowledge Integration</h3>
<p>Computer vision methods and in general ML methods have significantly improved over the last years. Different methods are able to accurately interpret a situation presented in an image or video. Even with such advancements, there are scenarios where ML methods react differently as humans. The main reason of this gap is the absence of the background knowledge from the learned model. The ML methods only account for patterns present in the training data, whereas humans have implicit knowledge that could help them to interpret a critical situation more robustly. In the context of autonomous driving, and in general too, it is not possible to train a model for every possible scenario that could happen on road. To provide a safer environment for pedestrians and autonomous vehicles, it is important to incorporate knowledge in the module that is responsible for taking important decisions.</p>
<h3>2.2 Situation Interpretation</h3>
<p>Authors: Daniel Bogdoll, Abhishek Vivekanandan, Faraz Qureishi, Gerhard Schunk</p>
<h3>2.2.1 Situation Interpretation in the AD Stack</h3>
<p>Situation interpretation is typically a follow-up module of the perception stage as shown in Section 2.1. Accordingly, this module is aware of objects, their states, and classifications within the surrounding environment. Its main objective is to interpret the situation, which includes questions such as "What is an object doing next?", "Is there an implicit meaning of an object's action?" or "Is a rule exception applicable right now?".</p>
<h3>2.2.2 Task Formulation</h3>
<p>Automated driving relies on accurate perception of the environment. We follow the concept of Gerwien et al. [296], who describe situation interpretation as a module which provides a "situation-aware environment model", that expands an environment model, which is typically the results of the perception stage, by situation recognition and situation prediction. They classify these three modules as Situation</p>
<p>Awareness (SA) levels 1-3. The output of the perception layer can be represented in various forms, for instance with object lists or probabilistic maps. Independent of the structure, the output is critical for the functioning of subsequent Autonomous Driving (AD) layers, which are tasked with situation interpretation, path planning - as shown in Section 2.3 - and vehicle control.</p>
<p>Nevertheless, sometimes raw data in addition to the outputs of the perception layer is relevant to detect intentions or meanings which are typically not addressed by perception systems. Two examples are direction of view [351] and hand gestures [974].</p>
<p>Situation interpretation works in tandem with perception, planning and control. A typical example of situation interpretation may involve cut in scenarios during automated driving using adaptive cruise control [690]. In a cut in scenario, the situation interpretation system shall be able to detect if a collision is imminent (using perception and planning output) and employ mitigation measures (braking in this case) in due time, ensuring the safety of the ego vehicle and its occupants.</p>
<p>In the aforementioned example, the collision detection and avoidance can be designed by using vehicle motion models and traffic rules. In complex situations, however, the task of situation interpretation may not be accomplished by only using a predefined set of rules. Especially for urban scenarios where the number of interactions between the ego vehicle and the objects in the scene are significantly higher. Additionally, there might be situations where a particular rule needs to be violated in order to ensure safety of human life.</p>
<h3>2.2.3 Goals and Requirements</h3>
<p>To be consistent with the previously defined SA levels, level 2 takes in raw data and adds semantic meaning to it in the form of semantic data models. Many works, especially [296], have defined the operational context in regard to adding more semantic structure to identify situations of interest.</p>
<p>As with SA level 3 defined by [296], motion prediction forms the abstract layer for situation understanding, which comprises different actors in the ego space. It plays a crucial role in determining safety critical applications for the autonomous driving stack by providing the service of estimating the future positions of an object. For instance, when driving in a highway scenario, assuming that a lead vehicle suddenly merges or cuts-in to the ego lane; the primary goal of this layer is to mitigate the collision by anticipating the intention of the lead vehicle(s). The crash avoidance maneuver should have safety properties such that the maneuver itself should not cause an additional collision, e.g., while hard braking could prevent the crash it could lead to a rear ended collision with other vehicles. This requires not only a prediction module but also a system that checks for the validity of the planned decision based on dynamic safety reasoning methodologies which could influence the Time-ToCollision (TTC), such as including weather constraints.</p>
<p>Most of the existing behavior prediction approaches perform simultaneous tracking and forecasting with the use of Kalman Filters or in the form of rule based approaches, as can be seen from the previous works [521]. Although variants of Kalman filters are good for short term predictions, their performance degrades for long term motion problems
as they fail to make use of the situation or environmental knowledge [154] which could be obtained via vectored maps. As a result, prediction modules should make use of domain knowledge to forecast reliable predictions [89].</p>
<p>In a typical AD stack, motion prediction is a separate module which does prediction based on the outputs from the previous perception layer. For example, the object detection outputs bounding box coordinates of an object along with the probability score of a class it belongs to such as truck, car, or construction cone. When this is used as an input to the motion prediction, a failure to propagate uncertainty happens due to the softmax outputs [266]. To alleviate those shortcomings, end-to-end networks, which take raw inputs such as lidar point clouds and camera fusion to produce motion predictions directly [993, 198] should be considered. Additionally, knowledge about one's own path planning can be integrated into the prediction component [38].</p>
<h3>2.2.4 Necessity of Knowledge Integration</h3>
<p>Vehicles equipped with a level 4 or 5 driving automation system are expected to master a wide variety of situations within their Operational Design Domain (ODD) [776]. Since many situations do not occur frequently in real life, ML based systems are struggling to extrapolate from their trained domain. Therefore, hybrid approaches that integrate ruleand knowledge based algorithms and insights into ML systems have the potential to combine the best of two worlds - great general performance and improved handling of rare situations, such as corner cases.</p>
<h3>2.3 Planning</h3>
<p>Authors: Etienne Bührle, Hendrik Königshof, Abhishek Vivekanandan, Moritz Nekolla</p>
<h3>2.3.1 Motion Planning in the AD Stack</h3>
<p>The planning module uses the outputs of the perception and prediction modules to plan a trajectory for the vehicle, which is subsequently handed down to the vehicle controls to be executed. This plan considers high-level routing decisions, and follows the rules of the road as well as basic principles of safe and comfortable driving.</p>
<p>A wide range of methods has been developed to tackle the trajectory tracking control problem, and we refer to [662] for an overview. However, the motion planning problem, especially in highly complex and dynamic environments like road traffic, remains largely unsolved and constitutes an area of ongoing research.</p>
<h3>2.3.2 Task Formulation</h3>
<p>Formally, the solution to the trajectory planning problem is a function that assigns every point in time a position in configuration space (typically, planar coordinates and heading). Classical approaches include variational methods (which represent the path as a function of continuously adjustable parameters), graph-search methods (which discretize the configuration space), and incremental search methods (which improve upon graph-search methods by using iterative refinement procedures). An excellent overview is given in [662].</p>
<p>The mentioned approaches are usually modular and interpretable. However, as hand-engineered solutions to difficult problems, they tend to be brittle and require extensive manual fine-tuning. Additionally, isolated changes to parts of the system might reduce or break the overall system performance, requiring careful re-tuning [1051].</p>
<p>These drawbacks motivate the use of deep learning based approaches, which have proven more robust to variations and can be trained in an end-to-end fashion. The current applications of deep learning to autonomous driving can roughly be classified into two groups. Full end-to-end approaches that map raw sensory input directly to vehicle commands (steering, acceleration), and methods that produce or work on intermediate representations. An overview can be found in [884].</p>
<h3>2.3.3 Goals and Requirements</h3>
<p>The motion planning system is in charge of ensuring behavioral safety of the self-driving vehicle [638, 639]. This includes taking the correct behavior and driving decisions, based on the knowledge of traffic rules and the behavior of other traffic participants, as well as the ability to safely navigate expected and unexpected scenarios.</p>
<p>The U.S. Department of Transportation (DOT) has recommended that Level 3, Level 4, and Level 5 self-driving vehicles should be able to demonstrate at least 28 core competencies adapted from research by California Partners for Advanced Transportation Technology (PATH) at the Institute of Transportation Studies at University of California, Berkeley. These basic behavioral competencies include, amongst others, keeping the vehicle in lane, obeying traffic laws, following road etiquette, responding to other vehicles, and responding to hazards [639].</p>
<p>While the majority of these behavioral competencies cover normal driving, i.e., regularly encountered situations, a selfdriving vehicle is also responsible for Object and Event Detection and Response (OEDR), which includes detecting unusual circumstances (emergency vehicles, work zones, ...) as well as planning an appropriate reaction, which typically takes place in the behavior and planning components. Above all, the planning system is responsible for crash avoidance, and should be able to handle control loss, crossing-path crashes, lane changes/merges, head-on/opposite-direction travel, rear-end, road departure, and low speed situations (backing, parking). At any time, the system should be able to execute a fallback action that brings the vehicle to a minimal risk condition. According to [638], "a minimal risk condition will vary according to the type and extent of a given failure, but may include automatically bringing the vehicle to a safe stop, preferably outside of an active lane of traffic."</p>
<p>Finally, the motion planner not only interacts with other traffic participants, but also to a great extent with its passengers. In particular, it must be able to communicate proper function, malfunction, as well as an eventual takeover request to a human driver, who must be able to take over in time.</p>
<h3>2.3.4 Necessity of Knowledge Integration</h3>
<p>Level 5 self-driving vehicles are expected to function in a wide variety of operational design domains (we refer to [94] for a taxonomy). While the basic principles of safe and
comfortable driving remain unchanged, the concrete implementations at the level of traffic laws, customary behavior, and scene structure might be subject to change. We argue that the inclusion of knowledge into a motion planning system will make it easier to handle these situations by increasing traceability (e.g., in the case of crash reconstructions) and reliability. Furthermore, a transparent decision process based on a common understanding between humans and machines will increase interpretability and trust. Finally, we expect the emergence of alternatives to extensive simulation testing, which is at the core of present validation concepts [34, 557, 573].</p>
<p>Emphasizing the advantages of Knowledge Integration, [135] demonstrates many of the aspects mentioned above. Fan Chen et al. integrate rules, in the form of social norms, by extending the agents reward function, e.g., passing objects with a minimum distance. Violating these rules results in a reward penalty. According to their results, agents with such restrictions exhibit behavior more similar to a human level. Therefore, when integrating knowledge into the machine learning pipeline, models become more interpretable and confidential not solely for experts but for ordinary people since these constraints occur in everyday life. Furthermore, their extension of the agent's knowledge reduces learning effort which accelerates training and enables them to outperform their benchmark algorithm in most cases. Despite those promising benefits, integrating knowledge typically narrows down the broad variety of possible solutions while consuming human work force for hand engineering. This shrinks the original, holistic approach of machine learning. Therefore, the trade-off between knowledge integration and self-learning needs to be chosen carefully [135].</p>
<h2>3 KNOWLEDGE REPRESENTATIONS</h2>
<p>The symbolic and the sub-symbolic methods represent two ends of the AI spectrum. The former is more driven by the knowledge and the latter by the data. A plethora of ongoing research can be found in the literature to develop hybrid-AI systems which exploit the strengths of one another. However, there still exists a core challenge in representation of knowledge used in symbolic space to integrate or augment within the data-driven sub-symbolic/statistical world. An overview of formalism and languages for representing symbolic knowledge which exists in the form of facts, rules and structured information is reviewed in Section 3.1. Furthermore, in Section 3.2 a survey on knowledge embedding is presented, which focuses on transforming prior knowledge from the symbolic space to a real-vector space, i.e., embeddings. These embeddings can be leveraged to improve the sub-symbolic methods (Neural Network (NN), Deep Learning (DL)) for effective training, inference and improved reasoning. In addition to it, methods and approaches dealing with injection of hard and soft rules together with embeddings are discussed in Section 3.2.3. Each of the sections in this chapter dealing with different mechanisms in representing knowledge is concluded with an outlook that is more tailored to the field of autonomous driving. Mapping perceived information to semantic concepts and reasoning using symbolic models provides improved understanding of driving situation. Furthermore, formalized traffic rules and</p>
<p>legal concepts are used to derive possible driving actions conditioned on their legal consequences Section 3.1.3.</p>
<h3>3.1 Symbolic Representations and Knowledge Crafting</h3>
<h2>Authors: Denny Mattern, Diogo Sasdelli, Tobias Scholl</h2>
<p>In contrast to numerical representations (e.g., vector embeddings), which focus on quantitative aspects, logic formalisms use symbols to represent things in a logical sense - which include physical things (cars, motorcycles, traffic signs), people (pedestrians, driver, police), abstract concepts (overtake, brake, slow down) and non-physical things (website, blog, god) -, as well as propositions expressing their properties and relations obtaining among them. Symbolic knowledge representations comprise all kinds of logical formalisms, as well as structural knowledge representing entities with their attributes, class hierarchies and relations.</p>
<h3>3.1.1 Logic Formalism</h3>
<p>Logic formalisms are used to express knowledge (mostly facts and rules) through formal logical expressions. Different logic formalisms (or logic systems) may differ in their complexity, which has consequences for their overall expressivity and for their decidability. Choosing an adequate formalism depends on the concrete problem one wishes to model. Among the most widely used formalisms, propositional logic has the simplest structure. It provides a set of symbols for representing individual propositions and a set of operators that can be applied to these propositions in order to generate new propositions. In classic, two-valued propositional logic, a Boolean value-assignment assigns to each proposition one of two values, e.g., 0 or $1, T$ or $F$ or true or false.</p>
<p>For example, the idea that a car does not cause an accident if it is in good condition and is driven carefully can be represented by the expression</p>
<p>$$
(P \wedge Q) \rightarrow R
$$</p>
<p>where $P$ is taken to mean The car drives carefully; $Q$ to mean The car is in good condition, and $R$ to mean The car does not cause an accident.</p>
<p>As the name suggests, propositional logic can only be adequately employed to represent propositions, i.e., apophantic linguistic utterances. In order to model logical structures concerning not only propositions, but also objects, their properties, and their relations, a more complex logic formalism is required, e.g., first-order logic (FOL). FOL is a kind of predicate logic that extends propositional logic by introducing symbols used to represent functions, constants, variables, predicates and quantifiers (e.g., $\forall, \exists$ ). While FOL is more expressive than propositional logic, it is not decidable, i.e., it is not possible to design an algorithm that is able to decide the semantic status of every single FOL-proposition.</p>
<p>For example, the idea that cars are destructible objects, i.e., that they possess the property of being destructible, can be formalised as</p>
<p>$$
\forall x(\operatorname{Car}(x) \rightarrow \text { Destructible }(x))
$$</p>
<p>where Destructible $(x)$ is taken to mean $x$ is destructible and $\operatorname{Car}(x)$ to mean $x$ is a car.</p>
<p>Assuming the validity of the sentence above, it is then possible to infer that a specific car, e.g., Model $T$ is destructible, i.e., it is possible to infer the sentence</p>
<p>$$
(\operatorname{Car}(\text { Model } T) \rightarrow \text { Destructible }(\text { Model } T))
$$</p>
<p>Overall, it is important to notice that the truth-value of FOL-expressions will depend on how their variables are interpreted with respect to some given set of objects, over which the variables range, i.e., to some given domain.</p>
<p>Although predicate logic is more expressive than propositional logic, both share the property of being extensional, i.e., the truth-value of any complex expression depends solely on the truth-values of the expressions it is composed of, and, in the case of systems of predicate logic (e.g., FOL) the definition of any property is reduced to the set of objects containing this property. Hence, these formalisms are unable to adequately represent the distinction between sentences that are true under the same conditions (and of properties that, although distinct, obtain for the same set of objects). For example, the sentences:</p>
<p>1) It is sunny and cold
2) It is sunny, but cold
have slightly different meanings: the word but in the second sentence indicates an opposition between it being sunny and it being cold. Notwithstanding, both sentences share the same extensional meaning: they are true under the same condition, i.e., when it is both cold and sunny. The semantic difference between these sentences concerns their so-called intensional meaning, which cannot be adequately grasped by the formalisms discussed above.</p>
<p>Systems of so-called intensional logic (cf., e.g., [503]) try to model precisely these semantic aspects that do not depend solely on the extension of a given expression (i.e., the intensional semantics). The most well-known examples are systems of alethic logic, which try to model the concepts of possibility and necessity. These concepts are intensional because the possibility (or the necessity) of something depends on more than on whether this something is true or not: while truth does imply possibility (and falseness excludes necessity), falsehood does not exclude impossibility (and truth does not imply necessity).</p>
<p>Systems of intensional logic are usually built on the basis of so-called modal logic (ML) (cf., e.g., [413]). A modality can be defined as a row of zero or more uninterrupted (e.g., by a parenthesis) monadic operators which cannot be reduced to a shorter one, i.e., which is not equivalent to a shorter row. E.g., classic propositional logic has a total of two modalities: $\neg$ and the empty modality. ML-systems introduce new modalities, which are usually defined in a way that does not depend solely on the truth-values assigned to the expressions modulated by them. Semantically, this is usually done be employing so-called possible-world-semantics, which expand the Boolean-assignment of classic propositional logic by introducing a universe, i.e., a set of sets of formulas (or possible worlds), to which truth-values are likewise assigned following Boolean rules. Thus, e.g., the idea of necessity can be represented by truth in all possible worlds; the idea of possibility by truth in at least one possible world.</p>
<p>All of the above-mentioned basic formalisms follow the so-called bivalence principle, i.e., they are systems of two-</p>
<p>valued-logic. Suppressing this principle leads to so-called many-valued-logic (MVL), which encompasses formalisms with three or more values (cf., e.g., [312, 250]. Systems with infinitely many values are sometimes called fuzzy logic.</p>
<p>An analysis of the literature in the area of logic of norms, which involves an interdisciplinary debate between philosophers, legal scholars and computer scientists, shows that, over the last decades, several different logical systems for representing (legal) norms have been proposed. Structurally, these systems are based on one of the formalisms discussed above (i.e., PL, FOL, ML, MVL). Among these, the most widely employed formalisms are based on ML (especially among philosophers, cf., e.g., [265, 622]) or on FOL, in particular so-called temporal logics [582] (especially among legal scholars and computer scientists, cf., e.g., [581, 750, 785]). For formalisms based on MVL, cf., e.g., [594, 595, 868, 249, 775]</p>
<p>When built on the basis of modal logic, logic of norms is usually called deontic logic. It introduces so-called deontic modalities, e.g., $[O B L],[P E R M],[F O R]$, respectively corresponding to the intuitive ideas of obligation, permission and prohibition. As monadic operators, these modalities qualify the content of respective proposition they operate on. E.g., $[O B L] p$ represents the intuitive notion that $p$ is obligatory. In many systems of deontic logic, the deontic operators satisfy the classic Aristotelian duality relations (see, e.g., [265], [35] for more details):</p>
<ul>
<li>$[O B L] p \equiv \neg[P E R M] \neg p$ : if $p$ is obligatory, then its negation, i.e., $\neg p$, is not permitted.</li>
<li>$[F O R] p \equiv[O B L] \neg p$ : if $p$ is forbidden, then its negationm i.e., $\neg p$, is obligatory.</li>
<li>$[P E R M] p \equiv \neg[F O R] p$ : if p is permitted, then $p$ is not forbidden.</li>
</ul>
<p>Sometimes, the modality $[P E R M]$, which is subaltern to $[O B L]$ (i.e., $[O B L] p \rightarrow[P E R M] p$ is valid] is called weak or negative permission, and another modality $\left[P E R M^{\prime}\right]$ is introduced to represent a stronger sense of permission, which usually excludes both obligation and prohibition.</p>
<p>While these relations seem intuitively reasonable, they are difficult to represent in a FOL-based formalism, for if the ideas of obligation, permission and prohibition are to be modeled as properties qualifying actions (modeled as abstract objects), then it would be improper to speak of the negation of an action, because negation, as a linguistic operation, cannot be reasonably applied to abstract objects. In other words, one cannot write $\forall x(O b l(x) \equiv \neg O b l(\neg x))$, for $\neg x$ is not syntactically well-formed.</p>
<p>A promising approach involves combining modal and predicate logic, i.e., employed a formalism based on reified modal logic. However, this comes at the cost of augmented semantic complexity, leading to practical and philosophical problems (for more details, see [285]).</p>
<p>While it is difficult to determine which formalism is better suited for representing (legal) norms, one can nonetheless identify certain desired properties that systems of logic of norms should ideally possess. One such property is, e.g., defeasibility. In more technical terms, defeasibility involves suppressing (at least partially) so-called monotonicity with respect to normative inferences. Intuitively, Defeasibility can be defined as being the property that a formalism possess
when a possible conclusion is, in principle, open to revision in case more evidence to the contrary is provided [35]. This is important when formalising (legal) norms because norms often contradict and/or override one another.</p>
<p>Overall, computer-readable formalisation of legal norms is an active research topic in the field of legal informatics. Literature offers multiple examples of logic formalisms for formalising legal rules and norms. Notwithstanding, there is still no consensus concerning the "best" formalism for modeling norms. In order to keep the formalised legal rules agnostic to the rules of the underlying logic formalism, an intermediate formal representation can be used. LegalRuleML ( $[664,36,35])$ aims to provide such an interchange format for legal rules, supporting deontic operators and defeasiblity among other features for formalizing legal norms. This intermediary representation can then be mapped to a specific logic in a standard format such as the TPTP [876].</p>
<p>As open as the question of the "best" logic formalism for norm representation is the question of a good interface for legal experts who want to represent legal norms computer understandable. A recent work proposes a dedicated editor allowing for intuitive formalization of legal texts and featuring consistency checks as well [538]. Another approach proposes an agile and repetitive process [53].</p>
<h3>3.1.2 Relational Knowledge</h3>
<p>Knowledge concerning entities, concepts, their hierarchies and properties as well as their relations to another is naturally represented by graph structures. Prominent examples for graph structured representations of structural knowledge are Taxonomies, Ontologies and Knowledge Graphs.</p>
<p>Taxonomies categorize entities into a hierarchy of classes and sub-classes represented as a directed acyclic graph with nodes representing the entities, classes and sub-classes, and edges representing the relations. Taxonomies categorize objects regarding one specific aspect and commonly use only one type of relation - the "is-a" relation. E.g., a car is a vehicle, which is a machine.</p>
<p>An Ontology is a formal, explicit specification of a shared conceptualization [871]. This means an Ontology is an abstract model of explicitly defined, relevant concepts of the specific domain of discourse and their relations which is constructed in a computer understandable manner. The definitions of the meaning of the relevant concepts and relations reflect the common sense of domain experts. Exemplarily, the OpenXOntology [33] is a conceptualization of traffic sceneries. It features different kinds of traffic participants, infrastructures, events, hierarchies and relations between them. The given definition of what an Ontology actually is, implies that the development of a specific Ontology is a process which involves different persons (e.g the knowledge engineer, the domain experts, maybe also the users) and that it takes a certain communication effort to develop a shared understanding of the concepts, the formalizations of those concepts as well as the usability of the Ontology for the user. Hence, Ontology building is ideally an iterative and repetitive design process for which multiple process patterns had been developed $[650,179,284]$.</p>
<p>Concrete Ontologies consist of classes and sub-classes which refer to domain concepts as well as the properties and relations between those, which is referred to as terminological</p>
<p>knowledge. Additionally to the class definitions, relations and constraints for concrete instances of classes are also defined in an Ontology and referred to as assertional knowledge. These definitions and constraints are expressed in description logic which is a decidable fragment of predicate logic, where the terminology TBox and ABox are often used instead of terminological knowledge and assertional knowledge. The logic is commonly represented in the Web Ontology Language (OWL), which is a computational language based on description logic that allows for formalizing complex knowledge such that it can be exploited by computer programs [661]. An Ontology can be interpreted as a meta-schema for domain-specific data, that not only specifies the relational structure and semantics of the data but also allows, e.g., to verify the consistency of that knowledge or to infer implicit knowledge through its strong logical foundation. Ontologies have been developed for a wide range of domains and applications.</p>
<p>In literature Knowledge Graphs and Ontologies had often been used as synonyms until [215] proposed the following definition: "A knowledge graph acquires and integrates information into an Ontology and applies a reasoner to derive new knowledge." In a Knowledge Graph data from heterogeneous data sources is integrated, linked, enriched with contextual information and meta-data (e.g., information about provenience or versioning) and semantically described with an Ontology. Through their linked structure Knowledge Graphs are prominently used in semantic search applications and recommender systems but also allow for logical reasoning when featuring a formal meta-schema in form of an Ontology. Surveys on Knowledge Graphs and their general applications are provided by [433, 1099] and Knowledge Graphs for recommender systems specifically by [329].</p>
<h3>3.1.3 Applications</h3>
<p>Symbolic representations improve scene understanding by mapping detected objects to a formal semantic representation of the current traffic scene (e.g., as a scene graph ([7, 121])). To integrate knowledge into machine learning algorithms, a representation of this knowledge is essential. While this knowledge is in form of embeddings, a symbolic representation allows traceability and makes it understandable for humans.</p>
<p>Given a sound formalization of traffic rules and a semantic representation of the entities, actions and legal concepts in traffic scenes (analogue to the legal ontology modeling the concepts of privacy proposed by [665]), we can derive the current legal state of an AD vehicle. An example where knowledge graphs are used as embeddings is [654]. In this case a knowledge graph is build upon a road scene ontology to recognize similar situations that are visually different. Using this technique to integrate legal knowledge and derive the legal state of different situations is a possible approach.</p>
<p>Analogue to the application of symbolic representations for situation understanding we make use of formal representations of traffic rules and legal concepts as well as symbolic scene descriptions for planning tasks by ranking possible alternative trajectories and actions, e.g., according to their legal consequences.</p>
<h3>3.2 Knowledge Representation Learning</h3>
<h2>Author: Stefan Zwicklbauer</h2>
<p>Complementary strength and weaknesses of data-driven and knowledge-driven AI systems have led to a plethora of research works that focus on combining both symbolic (e.g., Knowledge Graphs (KGs)) and statistical (e.g., NNs) methods [170]. One promising approach is the conversion of symbolic knowledge into embeddings, i.e., dense, real-vector representations of prior knowledge, that can be naturally processed by NNs. Typical examples of symbolic knowledge are textual descriptions, graph-based definitions or propositional logical rules. The research area of Knowledge Representation Learning (KRL) aims to represent prior knowledge, e.g., entities, relations or rules into embeddings that can be used to improve or solve inference or reasoning tasks ([544], [529]). Most existing literature narrows down the problem by defining KRL as converting prior knowledge from KGs only [544]. Thus, our focus in this survey also lies on knowledge modeled in graph-based structures.</p>
<h3>3.2.1 Textual Embeddings</h3>
<p>With the development and advances in DL, Natural Language Representation Learning has become a hot topic over the last couple of years. Natural Language Models, such as proposed in [188], [694], [91] are capable of directly converting natural language text, e.g., common sense text like Wikipedia articles or textual rules like road traffic regulations into embeddings that implicitly represent the syntactic or semantic features of the language [710]. Those embeddings are mostly used for specific downstream tasks like Question Answering (QA) [1089], Neural Machine Translation (NMT) [1022] or Common Sense Reasoning [869], but probably lack power of expressiveness when it comes to representing specific rules and logic. As a consequence, most research works extract entities, relations and rules from sentences first and model them in a more expressive representation format, e.g., KGs, afterwards. In the following, we do not further elaborate literature regarding Natural Language Representation Learning but refer to the respective surveys ([710], [153]) and assume that knowledge has already been converted to an expressive format like KGs or another logical system.</p>
<h3>3.2.2 Knowledge Graph Embeddings</h3>
<p>Many research works described how to create dense-vector representation for either homogeneous (i.e., graphs with a single type of edge) and heterogeneous (i.e., graph with multiple types of edges) graphs [167]. Graphs with auxiliary information ([643], [332]) and graphs constructed from nonrelational data [1056] are out of scope in this survey. For homogeneous graphs, the authors of [693] made a significant progress in KRL. They created a node corpus by randomly walking over the graph and applied Word2Vec [601] to generate node embeddings. The authors of [1100] further improved and used this approach for heterogeneous graphs. Tang et al. [888] and especially Grover at al. [320] proposed state-of-the-art works which intelligently explore the specific and varying neighborhoods of nodes and consider the respective node order to create their embeddings. Most research works however, focus on heterogeneous graphs since they are best</p>
<p>suited for rule and relation modeling. We first focus on pure node (entity) and edge (relation) representation learning, also called Triplet Fact-based Representation Learning Models. Hereby, we further distinguish between Translation-Based Models, Tensor Factorization-Based Models and NN-Based Models.</p>
<p>Starting with Translation-Based Models, the first influential work proposed TransE [85], a framework to create embeddings for heterogeneous graphs. Given a triple $(h, r, t)$, with $h$ and $t$ denoting the head and tail entity and $r$ denoting the respective relation, the idea is to embed each component $h, r$ and $t$ into a low-dimensional space $\mathbf{h}, \mathbf{r}, \mathbf{t}$ in a way that $\mathbf{h}$ and $\mathbf{r}$ translate to $\mathbf{t}: \mathbf{h}+\mathbf{r} \approx \mathbf{t}$. The authenticity of the respective triplet is defined via a specific scoring function, which is the distance under either $\ell_{1}$ or $\ell_{2}$ norm:</p>
<p>$$
f_{r}(h, t)=|\mathbf{h}+\mathbf{r}-\mathbf{t}|_{p}
$$</p>
<p>with $p=1$ or $p=2$. This objective function is minimized with a margin-based hinge ranking loss function over the training process. Since TransE came up with several limitations, such as not being able to model one-to-many, many-toone and many-to-many relations, various authors addressed these shortcomings by using TransE as foundation for their works. For instance, the authors of TransH [965] introduced relation-related projection vectors where the entities are projected onto relation-related hyperplanes. TransH enables different embeddings based on the underlying relation. All entities and relations are still represented in the same feature space. In TransR [545], the entities $h$ and $t$ are projected from their initial entity vector space in to the relation space of the connecting relation $r$. This allows us to render entities that are similar to the head or tail entity in the entity space as distinct in the relation space. Further improvements can be found in the TransD [432] model, which has fewer parameters and replaces matrix-vector multiplication by vector-vector multiplication for an entity-relation pair, which is more scalable and can be applied to large-scale graphs. Another problem of existing approaches is the non-consideration of crossover-interactions, bi-directional effects between entities and relations including interactions from relations to entities and interactions from entities to relations [1072]. To provide an example, predicting a specific relation between two entities typically relies on the entities' relevant topic in form of their connecting entities/relations. Not all connected entities and relations belong to the topic of the relation to be found. This is modeled in CrossE [1072], which simulates crossover interactions between entities and relations by learning an interaction matrix to generate multiple specific interaction embeddings. Another state-of-the-art approach Hake [1076] is capable of modeling a) entities at a different level in the semantic hierarchy, and b) entities on the same level of the semantic hierarchy. This is achieved by mapping the entities in the polar coordinate system. Entities on a different hierarchy level are modeled with a modulus approach, whereas the phase part aims to model the entities at the same level of the semantic hierarchy.</p>
<p>Regarding Tensor Factorization-Based Models, RESCAL [640] represents the foundational work for most follow-up works. RESCAL uses a tensor representation to model the structure of KGs. More specifically, a rank- $d$ factorization is used to obtain the latent semantics: $\mathbf{X}<em k="k">{k} \approx \mathbf{A} \mathbf{R}</em>$, for $k=$
$1,2, \ldots, m$, with $\mathbf{A} \in \mathbb{R}^{n \times d}$ being a matrix that captures the latent semantic representation of entities and $\mathbf{R}} \mathbf{A}^{T<em r="r">{k} \in \mathbb{R}^{d \times d}$ being a matrix that models the pairwise interactions in the $k$-th relation. Based on this principle, the scoring function is defined as $f</em>}(h, t)=\mathbf{h}^{T} \mathbf{M}, \mathbf{t}$, where $\mathbf{h}, \mathbf{t} \in \mathbb{R}^{d}$ denote the entity embeddings and the matrix $\mathbf{M<em r="r">{r} \in \mathbb{R}^{d \times d}$ represents the pairwise interactions in the k-relation ([640], [167]). The work DistMult [1016] improves RESCAL in terms of algorithmic complexity and embedding accuracy by restricting $\mathbf{M}</em>$ to be diagonal matrices. To overcome the problem of DistMult that head and tail entities are symmetric for each relation symmetry, the works Complex [908] and QuatRE [636] satisfy the key desiderata of relational representation learning, i.e., modeling symmetry, anti-symmetry and inversion. Both approaches leverage complex-value embeddings to support asymmetric relations. More recently proposed state-of-the-art models use special tensor factorization methods. For instance, SimplE [464] leverages an adapted and simpler version of Canonical Polyadic Decomposition to allow head and tail entities to have embeddings that are dependent on each other, which would be impossible with the original model. Similar, TuckER [46] is based on the Tucker-Decomposition on a binary entity-relation-entity matrix.</p>
<p>Due to their success in the last decade, NN-Based Models became also a hot topic for KRL. The first shallow NN approaches comprise standard feed-forward networks [85] (with linear layers) and neural tensor networks [860] (with bi-linear tensor layers). Over time deeper variants such as NAM [553] have established to provide more flexibility when it comes to train a network towards the underlying training goal. More recently, graph neural networks [1086] were introduced which strive to explicitly model the peculiarities of (knowledge) graphs. In particular, graph convolutional networks for multi-relational graphs [481] generalize nonvolutional neural networks to non-euclidean data and gather information from the entity's neighborhood and all neighbors contribute equally in the information passing. Graph convolutional networks are mostly built on top of the message passing neural networks framework [300] for node aggregation. Many works are limited to create embeddings for knowledge entities only ([793], [824]), but recent approaches tried to overcome this limitation ([187], [922], [1033], [923]). A neighborhood attention operation in graph attention networks [927] can enhance the representation power of graph neural networks [1010]. Similar to natural language models, these approaches apply a multihead self attention mechanism [924] to focus on specific neighbor interactions when aggregating messages ([1010], [4], [576]). Many authors incorporated mechanisms to improve the overall quality of entity and relation embeddings. For instance, the idea of negative sampling is to intelligently sample specific wrong samples that are needed for marginbased loss functions. Recent methods employed Generative Adversarial Networks (GANs) [308] in which the generator is trained to generate negative samples ([948], [103]). Another work ATransN suggested to improve existing embeddings by leveraging GANs to correctly align the embeddings with those from teacher KGs [942].</p>
<p>In this section, we mostly concentrated on methods that exclusively generated their embeddings on relational data. However, some approaches consider additional information,</p>
<p>such es textual (entity) descriptions (e.g., [261], [966], [335]), path-based information (e.g., [646], [328]) and even hierarchies (e.g., [1076], [1077]) as available in ontologies.</p>
<h3>3.2.3 Knowledge Graph Embeddings with Rule Injection</h3>
<p>So far, we have discussed approaches to embed knowledge that is formalized within KGs. These methods create representations that purely reflect the items' graph-based modeling (e.g., triples). In addition to this, specific rules (soft or hard rules) can be derived from KGs, which is also known as rule learning (e.g., [382], [1073], [655]), or be leveraged in the embeddings learning process, also known as rule injection. In the following, we focus on the former works, how to additionally integrate pre-defined or mined rules into embeddings. The authors of RUGE [331] presented a novel paradigm to leverage horn soft rules mined from the underlying KG in addition to the existing triples. Their iterative training procedure improves the transfer of the knowledge contained in logic rules into the learned embeddings. The framework SLRE [330] also presents an option to leverage horn-based soft rules with confidence scores to improve the accuracy of down-stream tasks. These rules are directly integrated as regularization terms in the training mechanism for relation embeddings. The authors of [646] additionally enriched the horn-based rules with path information to improve the state of the art. A related work [950] mines inference, transitivity and anti-symmetry rules from the given KG first and converts them into firstorder logic rules in the second step. Finally, the proposed rule-enhanced embedding method can be integrated in any translation-based KG embedding model.</p>
<p>Apart from rules directly mined from the underlying knowledge graph, other approaches exist that try to apply more extrinsic rules. For instance, the authors of [195] try to improve the embeddings' capability of modeling rules by using non-negativity and approximate entailment constraints to learn compact entity representations. The former naturally induce sparsity and embedding interpretability, and the latter can encode regularities of logical entailment between relations in their distributed representations. Other works propose to encode knowledge items into geometric regions. For instance, [336] encodes relations into convex regions, which is a natural way to take into account prior knowledge about dependencies between different relations. Query2box [733] encodes entities (and queries) into hyper-rectangles, also called box embeddings to overcome the problem of point queries, i.e., a complex query represents a potentially large set of its answer entities, but it is unclear how such a set can be represented as a single point. Box Embeddings have also been used to model the hierarchical nature of ontology concepts with uncertainty [534].</p>
<p>Most approaches described above rely on common-sense knowledge bases like DBPedia [37] or Freebase [82] and leverage their developed embedding approaches for knowledge base link prediction or inference / reasoning tasks. However, we believe that existing models and algorithms can be similarly applied to special domain knowledge bases, e.g., knowledge bases with data for AD [981].</p>
<h3>3.2.4 Applications</h3>
<p>The application of KGs in the AD domain has not received too much attention at the current point of time, albeit it can be an effective way to help situation or scene understanding [913]. For instance, the authors of [347] built a specific ontology to represent all core concepts that are essential to model the driving concept. The built KG CoSi models information about driver, vehicle, road infrastructure, driving situation and interacting traffic participants [347]. To classify the underlying traffic situation with a NN, a relational graph convolutional network [793] is used to convert the underlying KG into embeddings first. Similar, the work by Buechel et al. [95] presented a framework for driving scene representation and incorporated traffic regulations. Wickramarachchi et al. [981] focused on embedding AD data and investigated the quality of the trained embeddings given various degrees of AD scene details in the KG. Moreover, the authors evaluated the created embeddings on two relevant use cases, namely Scene Distinction and Scene Similarity.</p>
<h2>4 KNOWLEDGE INTEGRATION</h2>
<p>A plethora of methods and approaches have been proposed in literature that focus on augmenting data driven models and algorithms with additional prior knowledge. Among the most prominent approaches are the modification of the training objective via customized cost functions, especially knowledge affected constraints and penalties. An overview of auxiliary losses and constraints that take into account physical and domain knowledge in various peculiarity is presented in Section 4.1. Often these approaches are accompanied by problem-specific designs of the architecture, leading to hybrid models that leverage symbolic knowledge in form of logical expressions or knowledge graphs. The merging of symbolic and sub-symbolic methods, also referred to as neural-symbolic integration is focus in Section 4.2.</p>
<p>Besides external input, recent methods rely on preferably internal representations in order to focus attention on distinct features and concepts within a network itself. Key weighting and guidance approaches are discussed in Section 4.3. Last but not least, data augmentation techniques form the backbone to integrate additional domain knowledge into the data and thus indirectly into the model. Approaches starting from data transformations to augmentations in feature space up to simulations are discussed in Section 4.4.</p>
<p>In addition to these prevalent general approaches, this chapter concludes with methods and paradigms that are more tailored to the field of autonomous driving, considering multiple agents that interact with specific environments typical for the application under investigation. Especially inferring and predicting the state of an agent plays an essential role in the considered state space models in Section 4.5 and reinforcement learning in Section 4.6. The involvement of positional as well as semantic information is essential part of the information fusion approach outlined in Section 4.7.</p>
<h3>4.1 Auxiliary Losses and Constraints</h3>
<p>Authors: Tino Werner, Maximilian Alexander Pintz, Laura von Rueden, Vera Stehr
The usual Empirical Risk Minimization (ERM) principle in machine learning amounts to replacing the minimization of</p>
<p>an intractable risk, i.e., an expected loss over a ground-truth data distribution, by the minimization of the empirical risk. A mismatch between the expected loss and its empirical approximation causes ERM to result in models that do not generalize well to unseen data. This manifests either in overfitting, where the model represents the training data too closely and fails to capture the overall data distribution, or underfitting, where the model fails to capture the underlying structure of the data. Regularization schemes have been proposed to mitigate the problem of overfitting. The Structural Risk Minimization (SRM) principle [337, 919] extends the ERM principle for regularization. SRM seeks to find models with the best tradeoff between the empirical risk and model complexity as measured by the VapnikChervonenkis dimension or Rademacher complexity. In practice, this encompasses minimizing an empirical risk with an added regularization term. This technique has successfully entered variable selection as done in the path-breaking work of [898] who introduced the Lasso. Regularization in general proved to be indispensable in high-dimensional regression [213, 1097, 106, 1045, 849], classification [672, 918], clustering [986], ranking [510] and sparse covariance or precision matrix estimation [48, 260, 104].</p>
<p>As for knowledge-infusion into AI, a natural strategy is to similarly use regularization terms (so-called auxiliary losses) that correspond to formalized knowledge. However, constraints may also appear in terms of hard constraints, for example, if some logic rule must not be violated so that integrating it in a soft manner via auxiliary losses would not be appropriate, as dependencies or as regularization priors. This section is structured as follows: After describing techniques that integrate physical knowledge or other domain knowledge via auxiliary losses, we review ideas to incorporate constraints into the AI training and the AI architecture, followed by works that propose uncertainty quantification for knowledge-infused networks. At the end, we review applications of knowledge-infused networks for perception and planning in the automotive context.</p>
<p>Let us first point out the advantages of such techniques, besides the stronger adaptation of the model to the knowledge. For example, the authors in [458] highlighted that the knowledge-based regularization term does generally not require labeled inputs, which enables data augmentation with unlabeled instances, saving a large amount of time and money that would be required to generate a large labeled dataset. The approach in [272] does not even require any labeled instance. Moreover, a common result is better generalizability of the model, paralleling the improved generalization ability of models trained with complexity regularization. Each improvement in explainability and interpretability of deep models is especially relevant for autonomous driving in order to increase the public acceptance of self-driving vehicles.</p>
<h3>4.1.1 Knowledge Integration via Auxiliary Losses</h3>
<p>One has to distinguish between common penalty terms that regularize the complexity of the model as outlined in the previous paragraph and knowledge-based penalty terms that integrate formalized knowledge into the model. Surveys on knowledge integration, including auxiliary loss functions, are given by [867, 183, 718, 982, 767, 86]. An
important side effect from knowledge integration, apart from a better generalization performance, is that it increases explainability and interpretability of the model by at least partially explaining the predictions by the knowledge. This is especially true for deep models which are usually black boxes.</p>
<p>Regarding the success of regularization in machine learning, knowledge-based regularization terms have the potential to significantly improve machine learning models by encouraging them to respect existent knowledge without wasting computational effort for learning this knowledge again from scratch during training but more efficiently. It is important to note that knowledge integration via losses and penalties is also possible if the knowledge is not present in the data (for example, if it is related to rare cases) or if it cannot easily be derived from the data. Work in this direction has been done by [867], but note that [490] already had the idea of physics-based regularization when solving inverse problems. The authors in [867] consider the applications of predicting a height curve when throwing an object (constraint: it is a parabola), the location of a walking person (constraint: the velocity should remain constant) and casual relationships (video game) by adding a suitable regularization term to the loss function.</p>
<p>Physical Knowledge: Real-world environments are constrained by physical laws, which need to be considered for realistic modeling. Several approaches have been proposed for infusing such physical knowledge into neural networks. In [721, 720, 719] physics-informed NNs are introduced to reliably solve partial differential equations (i.e., enforcing the solution to respect physical laws) like the Schrödinger equation or discrete time models like RungeKutta models. The authors in [566] describe how to impose soft boundary conditions for Partial Differential Equations (PDEs) via auxiliary loss functions. The authors in [830] use physics-informed CNNs in order to predict physical fields. The authors in [377] propose physics-guided NNs that solve PDEs while satisfying thermodynamical constraints. Further applications in differential equation and dynamics modeling are given for example in [57, 169, 724, 725, 587, 1036, 1067, 956, 957, 272, 429, 428, 1009].</p>
<p>Several works on physics-informed NNs consider the problem of temperature modeling (e.g., of lakes or sea surfaces), such as [458, 71] or [626], who try to encourage a monotonicity constraint by an auxiliary loss term (e.g., the water density increases monotonically with depth). The authors in [435] use physics-guided recurrent graph networks to model the flow and the temperature in rivers and enforce the model to respect local patterns via physics-guided regularization. In [436], an energy conservation constraint is integrated while [917] apply physical regularization in fuel consumption modeling.</p>
<p>Domain Knowledge: The authors in [932] incorporate domain knowledge (here: sentiment dictionary/ontology, linguistic patterns) into DL in the context of sentiment analysis. Medical domain knowledge in terms of priors on abdominal organ sizes is integrated into Deep Neural Network (DNN) models in [1088] for the task of segmenting organs on Computerised Tomography (CT) scans. The authors in [120] propose knowledge-guided GANs that are trained using image data and additional textual</p>
<p>descriptions of (potentially unseen) input images (types of flowers). They train two generators, one for generating images of seen categories and one for unseen categories, and use an auxiliary loss to transfer knowledge between the generators. In [1019] the contribution of domain knowledge is quantified by approximating the Shapley value (see also Section 7.2.2) of a particular knowledge constraint.</p>
<p>Imposing general logical rules (equations, inequalities, orderings) on network outputs is also considered for incorporating domain knowledge in the literature. The authors in [1006] construct a loss function, such that the output of neural network satisfies certain first-order logic sentences upon minimization of the loss. In [248] are more general framework is proposed that turns general first-order sentences into differentiable loss functions using max or logit operators. The training of the constrained NN is simply done using standard optimization techniques like Stochastic Gradient Descent (SGD).</p>
<h3>4.1.2 Integration of other Constraints</h3>
<p>Adding a knowledge-based regularization term to a loss function typically enforces constraints in a soft manner. However, in many cases we would like to ensure that constraints are perfectly satisfied, i.e., enforce hard constraints that correspond to the limit case of auxiliary regularization terms with infinite regularization parameters. In the following, several approaches are introduced that aim at incorporating hard constraints. Besides using auxiliary losses, these often employ other approaches for constraint incorporation such as a change in architecture or use different optimization schemes such as projected gradient descent or conditional gradients [726].</p>
<p>Hard constraints: Methods to train NNs with hard constraints on the output layer are explored in [590], but due to the large dimensionality it is infeasible to apply standard Lagrangian techniques and even worse, if the constraints are incompatible, one will face numerical instabilities. In order to solve the linear system imposed by the Karush Kuhn Tucker (KKT) conditions, they use the Krylov subspace method which iteratively solves linear equations. The required products of Jacobians and vectors are computed using the Pearlmutter trick. It is further discussed how the Krylov method can be improved to cope with ill-posed constraints, how a constrained Adam looks like and how to reduce the number of constraints during learning. The latter is achieved by randomly selecting active constraints on the unlabeled data as SGD selects instances for labeled data. They suggest that randomly choosing them may be replaced by using the ones for which the constraint violation is largest, i.e., it is some kind of active learning approach for the constraints. The authors in [628] show how to perform deep learning with hard constraints by converting hard label constraints to soft logic constraints over distributions. They point out that the work of [194] is similar to theirs but does not use a full Lagrangian for respecting the constraints (logical formulas) but modify the loss functions so that hard constraints cannot be handled. Equality constraints are formulated using the two corresponding inequality constraints. Using the Hinge loss, the constraints can be equivalently written as equality constraints ([469] call it ReLU Lagrangian) which reduces the number of constraints and allows any constraints as long
as they are differentiable. Training is done via subgradient descent. The authors in [247] consider inequality constraints on DNNs and formulate it very similarly to [628] using the Hinge loss, but they consider a primal-dual formalization as [129] for solving the problem. The authors in [469] propose log-barrier extensions to approximate the Lagrangian optimization of constrained CNNs with a sequence of unconstrained losses with an initial feasible set of parameters. The main idea is to first compute any feasible point of the constrained problem with an inequality constraint and to approximate the original problem with the unconstrained problem but where the inequalities enter as penalty terms with a log-barrier function which approximates the Hinge loss. They provide a continuous and twice differentiable logbarrier extension which is no longer restricted to feasible points and therefore does not require to find a feasible initial point. The authors in [677] consider the training of matrix inequality constrained (semidefinitely constrained) NNs that are used for enforcing Lipschitz continuity or stability. Training robust, i.e., Lipschitz NNs has already been considered in [678] who solve the Lipschitz-regularized optimization problem using an Alternating Direction Method of Multipliers (ADMM) scheme. In order to capture even nonlinear matrix inequality constraints, [677] propose to transform the constrained problem into an unconstrained problem using log-det barrier functions. The framework of [248] enforces besides the logic-based soft constraints, also convex hard constraints via projected gradient descent (projecting gradients back into the convex constraint region). Besides enforcing soft boundary conditions of physics-based models, the authors in [566] also propose a NN architecture for encoding hard constraints.</p>
<p>Constraint incorporation via layers: Other techniques address the problem which knowledge constraints to integrate when and to which extent (e.g., how the regularization parameters have to be chosen). The authors in [501] criticize that many existing approaches incorporate the knowledge before or after the learning process by feature extraction or validation and therefore propose a method how to incorporate it within the hidden layers themselves, i.e., by infusing the knowledge between the layers. In order to decide whether knowledge should be incorporated between particular hidden layers and how the latent representation and the knowledge representation merge, they propose two loss functions. As for the knowledge representation, they build knowledge graphs. The knowledge infusion is realized by a knowledge-infusion layer which minimizes the gap between the learned representation and the knowledge representation (called differential knowledge) using a knowledgeaware loss function, i.e., a relative entropy loss quantifying the information gain from the knowledge representation. Finally, a weight matrix based on the differential knowledge is learned and the AI is trained using Backpropagation (BP).</p>
<p>The authors in [23] propose OptNet that uses special DNN layers for solving optimization problems which encode constraints as well as complex dependencies among the hidden nodes. They concentrate on quadratic problems and the solution becomes the output of the respective layer. To enable BP through these layers, the derivatives of the solutions (i.e., of the argmin operator) have to be computed, which is done by differentiating the KKT conditions.</p>
<p>They prove that the OptNet layers are subdifferentiable everywhere and that they can approximate any piecewise linear function but, however, point out that OptNet layers are costly. In [39], a linear complementarity problem for equality- and inequality-constrained reinforcement learning (see Section 4.6) is formulated which, using the results from [23], allows for gradient computation while keeping the BP solution scheme. Their approach can be interpreted as adding a physics-based layer to the network.</p>
<p>There are also efforts to incorporate logic constraints directly into the network architecture. The authors in [532] consider logic rules on the activations of DNNs. To enforce such rules, the pre-activations of the network are augmented with terms that increase when given logical statements are satisfied. A differentiable logic layer for trajectory prediction that can incorporate symbolic priors and temporal logic formulae is proposed in [535]. Since this requires much less labeled data, trajectory predictors can serve as trajectory generators. The parameter adjustment to the rules is done in the BP step. Furthermore, the layer can check whether rules are satisfied/violated. The idea is to define a robustness function based on signal temporal logic formulae so that they are satisfied if and only if the robustness function is greater than zero. Minimum and maximum operators are smoothly approximated. Training is done by BP where the gradients of this robustness function are used. In [401], DNNs are combined with declarative first-order logic rules. This is done by enforcing the NN to predict the outputs of a logic-rule-based teacher and updating both NNs iteratively. For a classification task, the softmax output that the student network assigns to an instance is projected onto the rule subspace where the constraints are satisfied, leading to the softmax output of the teacher network. The parameters of the student network are iteratively updated while the teacher network is trained so that it satisfies the first-order constraints by minimizing the Kullback-Leibler (KL)-divergence.</p>
<p>Posterior regularization: The authors in [592] propose robust RegBayes which does not incorporate knowledge via the priors but by posterior regularization w.r.t. firstorder logic rules (see ??). The idea builds upon regularized Bayesian inference (RegBayes) from [1091]. Robust RegBayes takes the uncertainty about the domain knowledge into account and outputs parameters that reflect the importance of each logic constraint which will be low in cases of large uncertainties about the knowledge. In [400], the method of [401] is generalized by jointly learning both the regularized DNN models as well as the structured knowledge. More precisely, the task is to learn the regularization parameters in the penalized objective function as well as dependency structures of the knowledge constraints. Their technique can be interpreted as regularized Bayes with generalized posterior [1091]. The authors in [1063] also propose posterior regularization (see [271]) for prior knowledge integration in order to handle multiple overlapping prior knowledge sources in the context of neural machine translation. They penalize the likelihood by the KL-divergence of the resulting model and a distribution that encodes prior knowledge. In [689], discrete constraints and regularization priors for CNNs are proposed, leading to discrete-valued regularization terms. The optimization problem is re-formulated as Augmented Lagrangian Method (ALM) and solved using an ADMM
scheme.</p>
<h3>4.1.3 Uncertainty Quantification of Knowledge-based DNNs</h3>
<p>The authors in [176] combine the physics-guided architectures with Monte Carlo (MC) dropout (c.f. Section 8.1) for uncertainty quantification and show that the physics-guided NN approach still yield black-box models and that the random dropping of weights again leads to physically inconsistent predictions. They remedy this issue by introducing physically-informed connections and physical intermediate variables which grant certain neurons a physical interpretation. They consider a monotonicity-preserving Long ShortTerm Memory (LSTM) which extracts temporal features and predicts an intermediate physical quantity (water density) such that the monotonicity is satisfied for this quantity by hard-coding it into the architecture. Then, an MultiLayer Perceptron (MLP) combines these predictions with the inputs to get the predicted responses. The perturbations injected by MC Dropout do not destroy the consistency with the physical knowledge. In [1059], a dropout variant for uncertainty estimation (both approximation and parameter uncertainty) in physics-guided NNs is suggested for the context of forward and inverse stochastic problems by invoking polynomial chaos and MC dropout. The authors in [1027] propose a latent-variable-based adversarial inference procedure for uncertainty quantification of physics-based NNs. In [449, 450], uncertainty quantification for physicsguided NNs in dynamical systems is done by a coarsegraining process which again results in a Bayesian-type approach where an evidence lower bound is maximized.</p>
<h3>4.1.4 Applications</h3>
<p>Knowledge integration has touched upon several perception tasks. As for object detection, [571] integrate prior knowledge about the size of the bounding boxes of vehicles into the model by imposing size constraints for the boxes. The authors in [674] consider equivariance constraints in weakly supervised segmentation in order to cope with affine image transformations. As CNNs are not equivariant in general, they impose an equivariance-preserving loss and extend this technique for shared information between multiple networks. The authors in [1035] propose a knowledgebased attentive Recurrent Neural Network (RNN) (see also Section 4.3) for traffic sign detection, motivated by the fact that small objects are not yet detected reliably by DNNs. The idea is to impose a prior distribution on the location of the traffic signs that represents the domain knowledge that the driver's attention is the bias of the center and the intuitive knowledge that human's attention follows a Gaussian distribution. The former emerged from [152] who automatically learn priors that respect that issue, i.e., it learns the bias from eye fixations. As for semantic segmentation, [468] impose constraints such that each bounding box at least has to contain a foreground pixel (to prevent excessive shrinking) and no background pixel (background emptiness constraint). To solve the resulting problem, they employ log-barrier extensions and optimize the corresponding Lagrangian function directly via SGD as proposed in [469]. The authors in [944] propose a bounding box tightness prior for weakly supervised image segmentation by applying a smooth maximum approximation instead of posing it directly</p>
<p>as constraints as in [468]. In [675], constrained CNNs are proposed to incorporate weak supervision into the learning procedure. The idea is to define linear constraints on the output layer that enforce the output being near the latent distribution from weak supervision. Their formulation covers for example bounds for the expected number of foreground and background pixel labels in a scene, suppression of a label in a scene (object is not allowed to appear) or size constraints. They concretize the problem using a KL-divergence-based loss function which can be solved using SGD on the dual. A related approach is presented by [653] who impose anatomical constraints on a CNN. The authors in [951] propose virtual adversarial training for anatomicallyplausible image segmentation, i.e., they generate adversarial samples that violate the topological constraints and let the network learn to avoid such predictions. They point out that additional losses that correspond to some constraint violation may not exist or may not be differentiable. Even worse, if the constraints are complex relationships, the NN may never violate them during training so that the constraint will always lead to a gradient of zero. They optimize a regularized cross-entropy loss where the context-aware regularizer is the maximum of a KL-divergence, penalized by a constraint loss which encourages adversarial samples. The authors in [689] impose discrete constraints which may be lower and upper bounds for the foreground size and the regularization prior can be a measure of the similarity of the intensity or color of neighboring pixels. [688] experimentally derive that existing Active Learning (AL) methods work poorly for lane detection due to label noise (maybe due to occlusion or unclear lane markings) and due to the fact that the entropy criterion leads to selecting images with no or only few lanes. They propose to train a student model using the same loss as for the teacher model, regularized with a distillation loss. As for mitigating the label noise that may be the reason for large discrepancies of the teacher and the student, they train another student without knowledge distillation. They select samples where the discrepancy of the student's predictions are large but where the discrepancy of the teacher and the distilled student are low (teacher may be erroneous here) or where the latter discrepancy is large and those between the students is low (knowledge is difficult to learn). Experiments are conducted on the LLAMAS and the CULane dataset.</p>
<p>In [590], human pose estimation with hard symmetry constraints is considered while [399] impose a consistency constraint that encourages the body parts of the generated images match the respective parts in the real images. As for image classification, [593] include hierarchical domain knowledge into classification tasks, i.e., that all parts belonging to a certain vehicle or all vehicles that contain a given part are considered. The authors in [1019] incorporate symbolic knowledge in classification, i.e., they consider super-classes that provide information about the potential actual subclasses. Knowledge can also be integrated into tracking and trajectory prediction. In [319], the Yaw loss, an auxiliary differentiable heading loss that penalized angle differences between the optimal and the predicted headings, is proposed, where the case of road intersections is also respected. The authors in [641] propose an off-road loss for improving the movement prediction of traffic participants. This loss is the mean Euclidean distance between each predicted waypoint
and the corresponding nearest feasible (drivable) point. In [89], this approach is extended by using a pre-trained model (according to off-road loss) and by combining it with models like CoverNet from [697] that respect dynamic constraints and that make multimodal probabilistic trajectory predictions or by the method from [162] who predict kinematically feasible trajectories using a kinematic layer. The authors in [867] enhance pedestrian tracking models by the world knowledge that the walking speed is constant. The idea in [43] is to add residuals to knowledge-driven trajectories in order to better reflect the stochastic behavior, to make it more realistic and to let the prediction effectively account for other agent's behaviors. They also consider social rules (world knowledge) concerning the movements of pedestrians. They show that their approach can also be used for multimodal prediction and combined with the kinematic layer from [162]. The authors in [1078] propose STINet for joint pedestrian detection and trajectory prediction. The idea is to model temporal information for each pedestrian so that current and past states are predicted. They also model the interaction of the pedestrians with an interaction graph. A temporalregion proposal network is applied in order to make object proposals in terms of past and current boxes, supervised by the ground truth boxes. In [441], the interaction-aware Kalman NN for predicting interaction-aware trajectories is proposed.</p>
<p>As for planning, knowledge-infused models for semantic segmentation, object recognition and trajectory prediction outlined in the perception subsection can potentially be used for planning the ego-trajectory since they improve the quality of the observed and predicted states respectively. Especially approaches like STINet [1072] that incorporate social interactions are candidates since the interactions with the ego-vehicle can be included. The authors in [773] add different regularization terms corresponding to speed limits, dynamics or lane changes. In [163], the ellipse loss is proposed which penalizes the bounding box regression and orientation loss with an off-road loss computed by a non-drivable region mask which is added to the computed Gaussian raster. Position and heading of the agent enter as regularization terms in the ChauffeurNet of [50]. The authors in [112] consider penalties, for example for trajectory curvature, lateral acceleration and off-road driving.</p>
<p>The authors in [81] propose to use physics-guided NNs for inversion-based feed-forward control applied to linear motors. Two physics-guided NNs are considered, one in which the inputs are transformed according to the feedforward controller (i.e., physics-guided input transformation) and one in which a physics-guided layer is used where the output is transformed according to the physical model (maybe enhanced with a physics-guided input transformation). Their model is applied to tracking tasks.</p>
<h3>4.2 Neural-symbolic Integration</h3>
<p>Authors: Tobias Scholl, Philip Gottschall, Christian Hesels, Gurucharan Srinivas
Machine learning and deep learning techniques (so-called sub-symbolic AI techniques) have proven to be able to achieve great performance in pattern recognition tasks of numerous kinds: image recognition, language translation,</p>
<p>medical diagnosis, speech recognition, recommender systems and many more. While the accuracy in performing those tasks which require dealing with large and noisy input is often on par with human abilities or even beyond that, they come with certain drawbacks: They usually offer no justification for their output, require (too) much data and computational power to be trained, are susceptible to adversarial attacks and are often criticized to generalize weakly beyond their training distribution. On the other hand, "classic" so-called symbolic AI systems such as reasoning engines can provide output that is explainable but performs badly when it comes to handling large or noisy input.</p>
<p>Merging methods from the fields of symbolic and subsymbolic AI is the purpose of neural-symbolic integration. Its goal is to remedy the drawbacks of both approaches and combine their advantages by integrating methods of both fields. A first taxonomy for the types of those integrated systems was proposed by Henry Kautz at AAAI 2020 [462] and provides a quick survey on the kinds of systems in neural-symbolic integration:</p>
<ul>
<li>Neural networks that create symbolic output from symbolic input, e.g., machine translation.</li>
<li>Neural pattern recognition subroutines within a symbolic problem solver, e.g., the Monte-Carlo search in the core neural network of AlphaGo [846].</li>
<li>Systems in which the neural and symbolic are plugged together and utilize the output of the other system(s), e.g., the neuro-symbolic concept learner [586] or a reinforcement agent working together with symbolic planners [416].</li>
<li>Neural networks that have knowledge compiled into the network, e.g., if-then rules [281].</li>
<li>Symbolic logic rules embedded into a neural network that acts as a regularizer.</li>
<li>Neural networks that are capable of symbolic reasoning such as theorem proving.</li>
</ul>
<h3>4.2.1 Methodological Overview</h3>
<p>Neural-symbolic methods for reasoning. In [507] multiple approaches were presented to integrate symbolic systems in Graph Neural Networks (GNNs). GNNs allow for two major advantages in solving reasoning tasks. They apply an inductive bias directly through their architecture and offer permutation invariance because of their update and aggregation functions. Permutation invariance simplifies the representation of literals and clauses. Therefore the order of logical symbols does not impact the learning and understanding of such clauses. For example the GNN handles the logical expression $\left(x_{1} \vee \neg x_{2} \vee x_{3}\right)$ semantically the same as the expression $\left(x_{1} \vee x_{3} \vee \neg x_{2}\right)$. GNNs enable visual scene understanding and reasoning superior to Convolutional Neural Networks as shown in [783].</p>
<p>Tensorization of first-order logic is another approach for solving reasoning tasks utilizing Deep Learning in combination with neural-symbolic integration. Logic Tensor Networks (LTNs) as presented in [817] are able to use full first-order logic with function symbols by embedding these logic symbols into real-valued tensors. They propose a neuralsymbolic formalism called Real Logic in addition to the computational model that is designed for defining logical expressions suited for tensorization in LTNs.</p>
<p>Real Logic is a many-valued, end-to-end differentiable first-order logic. It consists of sets of constant, functional, relational and variable symbols. Formulas build from these symbols can be partially true and therefore Real Logic includes fuzzy semantics. Constants, functions and predicates can also be of different types represented by domain symbols. The logic also includes connectives $\circ \in{\neg}, \circ \in{\wedge, \vee, \rightarrow, \leftrightarrow}$ and quantifiers $Q \in{\forall, \exists}$. Semantically Real Logic interprets every constant, variable and term as a tensor of real values and every function and predicate as a real function or tensor operation. Therefore Logic Tensor Networks are able to efficiently compute an approximate satisfiability by mapping logical expressions to real-valued tensors.</p>
<p>Moreover, [42] presents multiple related approaches that integrate logical reasoning and deep learning while being end-to-end differentiable:</p>
<ul>
<li>Logical Neural Networks [743] use a logical language to define their architecture. By applying a weighted Real Logic a tree-structured neural network is built with different logical operators represented by different activation functions.</li>
<li>DeepProbLog [585] is a probabilistic logic programming language that implements a Neural Network capable of solving reasoning tasks by applying logical inference.</li>
</ul>
<p>Neural-symbolic architectures for context understanding. In [654] two applications for neural-symbolism are demonstrated and evaluated. The first application focuses on autonomous driving and uses Knowledge Graph Embedding Algorithms to translate Knowledge Graphs into a vector space. The Knowledge Graph is generated from the NuScenes dataset and consists of the given Scene Ontology with a formal definition of a scene and a subset of Features-ofInterests and events defined within a taxonomy. By creating the Knowledge Graph and the use of Knowledge Graph Embeddings it is possible to calculate the distances of scenes and to find similar situations that are visually different. Presented methods to create Knowledge Graph Embeddings are TransE, RESCAL and HolE, where TransE shows the most consistent performance on the quantitative Knowledge Graph Embeddings-quality metrics.</p>
<p>The second application is "Neural Question-Answering" with knowledge integration using attention-based injection. The presented method uses knowledge from ConceptNet and ATOMIC and injects it into an Option Comparison Network by fusing the commonsense knowledge into BERT's output. It is evaluated with the CommonsenseQA dataset and the analysis suggests, that attention-based injection is preferable for knowledge injection.</p>
<p>Neural-Symbolic Program Search for Autonomous Driving Decision Module Design. In [872] Neural Architecture Search (NAS) framework is proposed, which automatically synthesizes the Neuro-Symbolic Decision Program (NSDP) to improve the autonomous driving system design. Neuro-Symbolic Program Search (NSPS) synthesizes end-to-end differentiable Neuro-Symbolic Programs (NSPs) by amalgamating neural-symbolic reasoning with representation learning. Symbolic representations of driving decisions are described with Domain-Specific Language</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Fig. 1: The NSPS searches The NSDP, through backpropagation $g$ to update $\alpha$ and $\beta$. The decision policy generated by NSDP is further used for planning and control. Semi-transparent operators shows the candidates for parent operations used in the search from NSPS [872].
(DSL) for autonomous driving. DSL contains both basic primitives for parts with driving, along with conditional statements to enforce higher-level priors. The design of DSL is allowed to specify all the behaviors for autonomous driving in a differentiable neural-symbolic behavior paradigm. Further NSPS is formulated as a stochastic optimization problem allowing to efficiently search for program architecture that integrates the neural-symbolic operations ensuring end-to-end learning possibilities. The NSPS in Figure 1 is combined with Generative Adversarial Imitation Learning (GAIL) to learn in an end-to-end fashion to generate neural-symbolic decision programs to output specific instructions (e.g., target waypoint index, target velocity) to the motion planner and controller.</p>
<p>Integrating Prior Knowledge into Deep Learning. In [194] a Semantic Based Regularization (SBR) [193] framework is used to express prior knowledge as set of First order Logic (FOL) clauses. SBR is a statistical relational learning framework, holding the ability to learn from examples and logic rules. Partial definition of the mapping from input to output is provided through expressed FOL clauses. Statistical relational learning is employed to inject logical knowledge into learning. It transforms logic knowledge into continuous constraints which are integrated with cost functions as a regularizer. Experimental analysis of the proposed work is focused on image classification problems. A subset of ImageNet dataset [769] is used for the classification task.</p>
<h3>4.2.2 Applications in Perception</h3>
<p>Reasoning. A neural-symbolic reasoning engine could employ world knowledge or common sense knowledge to make sense of the scenery of a perception module or a combination of such modules. It could work as a regularizer (semantic loss function) during the training of a perception neural network which describes the scenery and penalizes implausible combinations of the recognized entities and their attributes or relations. Secondly, the same principle could be applicable during inference in which the perception module(s) outputs multiple possible scenery descriptions and the reasoning engine checks for contradictory elements
in the scenery thus assessing the plausibility of the output.
Scene Consistency. As in [654], concepts in labeled driving datasets along with domain experts can be utilized to model SceneOnotology representing spatial relational knowledge among the scene concepts. However, the ontology in [654] is used to generate triplets or facts exhibited in the scene. Vector representation of these facts is performed with Knowledge Graph Embeddings (KGEs). The KGE framework allows translating the triplets to latent vector space for vertical integration of spatial knowledge with deep learning methods for downstream scene understanding task. Qualitative intrinsic evaluation of KGEs for complete encoding of all knowledge facts is challenging and is subject to the different score functions utilized in KGEs [654]. Therefore, one could use SBR [194] a statistical relational learning framework that can represent these facts as FOL clauses and transforms these clauses into continuous constraints. These constraints could be integrated into the cost functions as a regularizer term, allowing to find optimal parameters for the learning algorithm by restricting the solution space. The downstream deep learning task such as object detection could use this relational knowledge expressed with SBR framework to improve the precision and accuracy by integrating the knowledge of the object's spatial-relational existence.</p>
<h3>4.2.3 Applications in Situation Interpretation</h3>
<p>Neural-symbolic architectures for context understanding. Because the application of Knowledge Graph Embeddings in [654] is already used in the autonomous driving context, it is applicable as it is. Discovering similar situations that are visually different helps to understand certain scenarios and could be useful as an input to help classifying dangerous situations.</p>
<p>The attention-based injection approach can be useful for reasoning in certain situations, for example by injecting the Straßenverkehrsordnung (StVO) into a QA network to encode new sentences in BERT.</p>
<p>Behavior prediction of target vehicle. As presented in [872], one could make use of DSL for describing driving maneuvers in symbolic space. DSL could be designed to contain StVO logical rules along with primitive attributes (e.g, velocities, accelerations, pose, associate lane type, lane attributes, road typologies) to enforce higher-level priors for maneuvers.</p>
<p>The NSPS framework proposed in [872] is a stochastic optimization problem. Joined with the mechanism of NAS it can be employed to generate decision policy for downstream motion control and planning tasks. Similarly, NeuralSymbolic Behavior Programs (NSBPs) are generated using the NSPS framework to reason about the target vehicles' behaviors to support cooperative planning in the scene. The synthesized NSBP shall be an operation involving Neural-Symbolic operations (numerical operation and logical operations), rather than plain neural networks. The NSPS framework together with GAIL could be used to learn NSBPs in an end-to-end fashion.</p>
<h3>4.2.4 Applications in Planning</h3>
<p>Reasoning. The creation of formalized knowledge requires a methodology capable of validating the resulting formalization. One such method is querying the formalization against test cases, e.g., check if the current formalization of the StVO entails undesired properties such as it is possible to infer that endangering pedestrians in order to make way for an ambulance is ok. Those queries are also formalized statements and answered by a neural-symbolic reasoning engine that employs the formalized knowledge.</p>
<p>The formalization of legal knowledge is a prerequisite for checking compliance of an already taken or planned action for a certain traffic situation with regulations such as the StVO. Neural-symbolic reasoners could perform such compliance checks enhancing two applications in the autonomous driving domain: Firstly, a planner could use the compliance check to assess several courses of action. Secondly, a compliance check could be employed as a regularizer during the training phase of a planner, forcing the model to prefer legally compliant solutions over non-compliant solutions.</p>
<h3>4.3 Attention Mechanism</h3>
<h2>Author: Tianming Qiu</h2>
<p>Human beings can focus on a specific area in fields of view or recent memories to avoid over-consuming energies. Inspired from the visual attention of human beings, an algorithmic attention mechanism becomes a popular concept in deep learning. NMT [44], a classical Natural Language Processing (NLP) task, is one of the earliest successful attempts which apply attention mechanism. Traditional NMT approaches are based on a sequential encoder-decoder architecture which uses RNN. The encoder maps source sentences word by word to hidden states and the decoder predicts target sentences. One of the drawbacks is that the longer the input sentence is, the more severe forgetting of previous words. The attention mechanism gives specific words (or tokens) more emphasis to avoid long distance forgettings. Similar to NLP's attention concept, many machine learning tasks also require efficient focus on specific data or information. Such specific focus comes from prior knowledge or experience which is very helpful for the objective task. Furthermore, this attentive information is usually intuitive for human understanding and it provides useful interpretability. For example, image captioning tasks look for heatmaps on input images which indicates where caption words refer to [1007]. If the attention mechanism is considered as a form of human knowledge, learning such semantic knowledge is expected to benefit networks performance.</p>
<p>In Computer Vision (CV) tasks, the attention mechanisms are categorized into three different modeling approaches: spatial attention, channel-wise attention, and self-attention.</p>
<h3>4.3.1 Spatial attention</h3>
<p>Spatial attention attempts to imitate how human beings are attracted by significant objects or features visually. Technically, it emphasizes spatial areas in input images with
highlighted heatmaps. The common spatial mechanism is written as</p>
<p>$$
\begin{aligned}
&amp; \alpha_{i}=f_{a t t}\left(\mathbf{v}<em _mathbf_i="\mathbf{i">{\mathbf{i}}\right) \
&amp; \mathbf{v}</em>
\end{aligned}
$$}}^{\prime}=\alpha_{\mathbf{i}} \odot \mathbf{v}_{\mathbf{i}</p>
<p>where $\mathbf{v}<em _att="{att" _text="\text">{\mathbf{i}}$ represents a certain feature map of an input image, $f</em>$ by using Hadamard product so that it emphasizes information beneficial for following classification tasks and weaken less important features. These weighted masks on feature maps are scaled up to the original input image size and visualized by heatmaps to illustrate semantic image pixel-level attention.}}$ is a nonlinear mapping and $\odot$ represents Hadamard product, namely an element-wise product. A tiny two- or three-layer neural network is used to describe a nonlinear mapping of $f_{\text {att }}$, whose parameters are updated during training. The mask assigns different weights on the original feature map $\mathbf{v}_{\mathbf{i}</p>
<p>The key point is to learn a nice attention function $f_{\text {att }}$ which generates a semantic attention heatmap. Such an attention heatmap is integrated again into the neural network for improving final performances and provides semantic meaningful visualizations. Similar to machine translation tasks, the attention on input original sentence words now switch to input image areas. Similar works are seen in HydraPlus-Net [555], which develops a complicated and huge neural network by duplicating Inception networks several times. HydraPlus-Net is designed for pedestrian re-identification so it should be capable to detect detailed features on pedestrians. All the above papers learn attention functions only by standard loss functions which only contain predicting losses for bounding box class and localization, but no predicting loss for attention heatmaps. They design special structures but do not provide extra information for attention function training. The only 'guide' for attention learning comes from the loss functions. Another approach to learn attention is to add an extra auxiliary loss function specifically for $f_{\text {att }}$ training [669, 1069]. In object detection tasks, datasets provide segmentation ground truth which is used to evaluate attention as well. The loss function that measures overlaps between attention heatmap and groundtruth segmentation is used as a very strong guide to learn attention function [669]. Another approach that leverages additional information to train attention networks is to use pre-trained attention layers from other tasks. In a pedestrian detection task, such an additional dataset like MPIf Pose Dataset [26] which provides precise predictions of 14 human body key points demonstrates a good attention result on the primitive task [1069]. Spatial attention is seen as a special feature representation. It learns the spatial knowledge from input images that different spatial areas have different impacts on the final outputs of neural networks.</p>
<h3>4.3.2 Channel-wise attention</h3>
<p>In computer vision tasks, channel-wise attention weighs channels of convolutional layers' outputs differently. Similar to the aforementioned spatial attention, channel-wise attention is still a probability mask. It assigns various weight values for each channel of output separately with the supervision of classification or detection outputs. Convolution layers are considered to be able to show the hierarchical nature of features [1049]. Each convolutional kernel is assumed</p>
<p>to represent a different feature extraction ability. Hence, channels of the output feature map behave differently to various image patterns. Each channel may contain different features which might affect the final output. Channel-wise attention was first used to aggregate information from the entire receptive field for involving more global information than local spatial information [397]. In pedestrian detection tasks, [1069] interprets CNN channel features of a pedestrian detector visually and indicates that different channels activate response for different body parts respectively. An attention mechanism across channels is employed to represent various body parts. By emphasizing detected human body parts, occluded pedestrian detection results are improved.</p>
<h3>4.3.3 Self-attention</h3>
<p>Self-attention is widely used in NLP because it is good at extracting the correlations between words. The relationship between each word plays a significant role of text understanding. Self-attention in CV analyses the correlations between pixels and are formulated as a formal function of query $\mathbf{q}$, value $\mathbf{k}$ and key $\mathbf{v}$ :</p>
<p>$$
\begin{aligned}
\mathbb{R}^{d_{k} \times n_{q}} \times \mathbb{R}^{d_{k} \times n_{k}} \times \mathbb{R}^{d_{v} \times n_{k}} &amp; \rightarrow \mathbb{R}^{d_{v} \times n_{q}} \
\mathbf{q}, \mathbf{k}, \mathbf{v} &amp; \mapsto \operatorname{Attention}(\mathbf{q}, \mathbf{k}, \mathbf{v})
\end{aligned}
$$</p>
<p>Query $\mathbf{q}$, value $\mathbf{v}$ and key $\mathbf{k}$ concepts come from retrieval systems, where the best matched 'value' should be returned according to a certain 'query'. Usually, query is first converted to keys that are connected to values. Here query and key refer to the projected outputs of the decoder and encoder. Sometimes key and value are the same. Attention computes for each query $\mathbf{q}$ an attention vector $\mathbf{a}_{i}$ by returning a weighted sum of all values, i.e.,</p>
<p>$$
\mathbf{a}<em j="0">{i}=\sum</em>
$$}^{n_{k}} \alpha_{i, j} \mathbf{v}_{\mathbf{j}</p>
<p>The weights are determined from some measurements of similarity between the queries and keys. Transformer architecture uses word relevance to improve translation performance [924]. Self-attention represents the image block or pixel relevance in computer vision tasks. Apart from local features within each block, self-attention provides more global features [960, 723]. Alternatively, each pixel in an image is seen as the query $\mathbf{q}$. Self-attention of each query pixel is calculated on the other pixels in an image. Compared with convolution layers, self-attention is also able to extract different levels of features at different layers. Furthermore, due to its ability to extract global features, self-attention is able to achieve better performance than convolution in many tasks [151]. Self-attention mechanism and Transformer architecture are applied to many image-based detection tasks [110, 1092] as well as 3D detection tasks [609].</p>
<h3>4.3.4 Applications</h3>
<p>Attention mechanism in CV is widely used in autonomous driving perception tasks such as pedestrian detection. In Zhang's work [1069], attention is integrated into the network to enhance the potential ability to find more occluded pedestrians. Similarly, integrating attention heatmap to the existing detector backbone improves the detection results as well [669]. Attention mechanism isn't used for planning
directly, but it is used for interpretabilities of planning or decision making. Works [477, 476] from Berkeley Deep Drive use attention heatmap to explain why vehicle takes a certain controller behavior and textual explanations would be generated. Attention is updated during training, meanwhile, it also affects the training results in the end. For scene understanding, it is not considered as a feasible method.</p>
<h3>4.4 Data Augmentation</h3>
<h2>Authors: Stefan Matthes, Tobias Latka</h2>
<p>Data augmentation comprises a number of techniques that increase the amount of data for little additional cost. It provides a way to integrate knowledge about how concrete changes in the input signal affect the model's target output, such as invariance to small perturbations. Training with the additional data usually improves the generalization of the model and can be especially helpful when data is scarce or imbalanced.</p>
<p>Which data augmentation technique can be used depends on the format of the input data (e.g., image, audio, point clouds) and the machine learning task. It is essential that the applied algorithm preserves task-relevant information. For example, color space distortions can be helpful in image-based license plate recognition (by making the model more robust to color changes), but can reduce performance in bird species classification, since color is an important distinguishing feature for many species. For some tasks, such as density estimation, it is inherently difficult to define appropriate data augmentations. On the other hand, data augmentation is even an integral part of some unsupervised models, for example in contrastive learning [132].</p>
<p>In recent years, several surveys have been published on data augmentation [943, 835, 959, 473, 1023]. [943] and [959] review data augmentation methods for image recognition and face recognition, respectively, while Shorten and Khoshgoftaar [835] provide a more general perspective and taxonomy of data augmentation techniques. Khosla and Saini [473] focus on data warping and oversampling, and highlight how these techniques avoid overfitting. More recently, Yang et al. [1023] discuss data augmentation methods for common CV tasks, including object detection, semantic segmentation and image classification based on experimental results. In this chapter, we look at data augmentation from the perspective of knowledge formalization and integration with applications in the field of autonomous driving.</p>
<p>Data augmentation methods can be categorized based on multiple criteria or factors (see Fig. 2). First, they can leverage either invariances or equivariances in the data. The former modifies the input signal in a manner that does not affect the target, while the latter also changes the target based on certain known symmetries. Data transformation (manipulation or warping) techniques modify individual instances, whereas in data synthesis parts of two or more instances are recombined. Generative models, such as a GAN or Auto Encoder (AE), which can be used to generate additional samples, can be seen as an extreme case of the synthesis approach. Finally, we distinguish between augmentations in data space and feature space. Some authors do not consider simulation as data augmentation, but since</p>
<p>simulation is a useful tool for knowledge integration and plays a crucial role in autonomous driving, we will discuss it here as well.</p>
<h3>4.4.1 Invariance and Equivariance</h3>
<p>Many classical approaches using DNNs add random noise to the training data [730][73], motivated by the fact that the learned function should be invariant to noise. Bishop [73] showed that applying small perturbations to the inputs during training leads to a smoothed target function and is equivalent to optimizing with an additional regularization term or constraining the weight updates (see also [730] and [648]). However, it is unknown what the optimal noise distribution is.</p>
<p>A related technique is random erasing, for example, graying out pixels [191] and dropping words in text [976]. This is similar to dropout [865] where instead network weights are masked with some probability in each optimization step.</p>
<p>For image data, the effect of many transformations is well studied. Typical image manipulations include geometric transformations, such as cropping, translations, rotations, reflections, and projections; kernel filters, e.g., sharpening and blurring; and color space transformations, such as random grayscale and color jitter [835, 648]. While these transformations generally have no effect on the labels in image classification, in other tasks such as object detection and semantic segmentation, bounding boxes and segments must be modified equivalent to the input. Thus, how a transformation affects the target also depends on the task.</p>
<p>Permutations are another example of this. Sorting, for instance, is a permutation invariant task, while object tracking is permutation equivariant. However, some architectures, such as transformers [924], are inherently permutation equivariant and implement this type of knowledge much more efficiently. Changing the order of queries or keys affects the order of the output accordingly.</p>
<p>For an input target pair $(x, y) \in \mathcal{X} \times \mathcal{Y}$, we can formalize invariances and equivariances by $(x, y) \mapsto(g(x ; \theta), y)$ and $(x, y) \mapsto(g(x ; \theta), \tilde{g}(y ; \theta))$, respectively, where $\theta$ denotes the type and strength of the applied transformations $g, \tilde{g}$ and is typically a random variable.</p>
<h3>4.4.2 Data Transformation and Synthesis</h3>
<p>Many important transformations for image data have already been mentioned in the previous section. Data types with other properties require different transformations. For instance, audio datasets can be enhanced using scale changes (pitch shifting and time stretching), compression, quantization, equalizing, filtering, reverberation and background noise injection [599]. Moreover, several of these elementary transformations can be combined in a myriad of ways.</p>
<p>A special class of data transformations are adversarial perturbations. These are slightly distorted inputs that lead to incorrect and usually overconfident predictions, but can often not be distinguished from the original by humans [309]. Adversarial training, i.e., feeding these examples back into the model, leads to more robust predictions [309]. Miyato et al. [611] extend this procedure to the semi-supervised setting by computing the adversarial examples using the model's predictions instead of ground truth labels.</p>
<p>In addition to modifying individual instances, new data can be synthesized by combining elements from multiple data points. One of the early approaches is SMOTE [125]. It was developed for imbalanced datasets and can be used to oversample underpopulated classes by interpolating between nearest neighbors from the same class. Mixup [1061] and SamplePairing [419] explore the same technique for image data. The former also interpolates the labels accordingly and uses soft labels, which however cannot be used in the semi-supervised setting.</p>
<p>Another common technique for image datasets is to cut and paste patches from different images [210, 209, 230, 295, 1046]. To avoid that the model cheats by detecting artifacts at the boundary of the inserted patches, various blending techniques and distractors (patches that do not contain any of the relevant objects) can be used [210]. Instead of inserting objects randomly, several techniques were proposed for more realistic object placements, such as using a visual context model [209], depth and semantic information [295], and a heat map for appearance consistency [230]. YOLOv4 [77], a 2D object detector, additionally uses mosaic data augmentation that concatenates multiple images before cropping. This improves the detection of smaller objects.</p>
<p>The previous formulas for invariance and equivariance can be generalized to the case when new data is synthesized from multiple instances: $\left{(x_{i}, y)\right}<em 1="1">{1}^{n} \mapsto\left(g\left(x</em>\right)\right}}, \ldots, x_{n} ; \theta\right), y\right)$ and $\left{\left(x_{i}, y_{i<em 1="1">{1}^{n} \mapsto\left(g\left(x</em> ; \theta\right)\right)$.}, \ldots, x_{n} ; \theta\right), \tilde{g}\left(y_{1}, \ldots, y_{n</p>
<p>A more elaborate approach to create additional data is to first train a generative model with the given data and then sample from it. Neural Style Transfer [288][597] is a technique that can be used to change the appearance of an image while leaving the content unaffected. It has mainly artistic applications, but can also be used to render images with the appearance of different seasons, times of day, and different weather conditions [597]. A major drawback is that these models already require large amounts of training data and may take a long time to sample.</p>
<h3>4.4.3 Data Augmentation in Feature Space</h3>
<p>The methods described so far directly modify the raw data, but it is also possible to augment data in the feature space. In the latter, the input data is fed through the first layers of the DNN and then the intermediate representations are manipulated before being passed through the remaining layers.</p>
<p>New instances can be synthesized either by interpolation, extrapolation or simply by adding noise [190]. Similar to Mixup [1061], Manifold Mixup [928] additionally interpolates between points from different classes by also interpolating the labels accordingly, which can therefore be considered its natural extension. Alternatively, an AE can be used to transform the modified features back into the input space [190], but unlike the other approaches, this already requires a trained decoder. These methods have the advantage of being domain agnostic. However, experiments by Wong et al. [988] suggest that augmentations in the data space, when applicable, are preferable to data augmentation in feature space alone.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>Acknowledgement: The research leading to these results is funded by the German Federal Ministry for Economic Affairs and Climate Action within the project "KI Wissen - Entwicklung von Methoden für die Einbindung von Wissen in maschinelles Lernen". The authors would like to thank the consortium for the successful cooperation.&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>