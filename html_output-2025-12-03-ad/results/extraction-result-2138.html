<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2138 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2138</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2138</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-56.html">extraction-schema-56</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of circuit simulators used for training machine learning or reinforcement learning models, including details about simulation fidelity, component modeling accuracy, and transfer performance to real circuits or hardware.</div>
                <p><strong>Paper ID:</strong> paper-278995968</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2505.22990v1.pdf" target="_blank">MenTeR: A fully-automated Multi-agenT workflow for end-to-end RF/Analog Circuits Netlist Design</a></p>
                <p><strong>Paper Abstract:</strong> RF/Analog design is essential for bridging digital technologies with real-world signals, ensuring the functionality and reliability of a wide range of electronic systems. However, analog design procedures are often intricate, time-consuming and reliant on expert intuition, and hinder the time and cost efficiency of circuit development. To overcome the limitations of the manual circuit design, we introduce MenTeR - a multi-agent workflow integrated into an end-to-end analog design framework. By employing multiple specialized AI agents that collaboratively address different aspects of the design process, such as specification understanding, circuit optimization, and test bench validation, MenTeR reduces the dependency on frequent trial-and-error-style intervention. MenTeR not only accelerates the design cycle time but also facilitates a broader exploration of the design space, demonstrating robust capabilities in handling real-world analog systems. We believe that MenTeR lays the groundwork for future "RF/Analog Copilots" that can collaborate seamlessly with human designers.</p>
                <p><strong>Cost:</strong> 0.01</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2138.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2138.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of circuit simulators used for training machine learning or reinforcement learning models, including details about simulation fidelity, component modeling accuracy, and transfer performance to real circuits or hardware.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PySpice</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>PySpice (Python SPICE interface)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A Python interface used to run SPICE-compatible circuit simulations (via NGSpice or similar engines); in this work it executes Testbench Agent generated simulations to validate AI-generated netlists.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>circuit_type</strong></td>
                            <td>analog / RF (examples: single-stage op-amp, Bandgap Reference (BGR), VCO, PLL, Schmitt trigger, op-amp-based adder)</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_tool</strong></td>
                            <td>PySpice (Python front-end to NGSpice/SPICE engine)</td>
                        </tr>
                        <tr>
                            <td><strong>component_models</strong></td>
                            <td>Primitive SPICE component models as shown in generated netlists: Level=1 MOSFET models (.model nmos_model nmos (kp=... level=1 vto=...)), resistors, voltage sources; no mention of industry-level BSIM or extracted parasitic models.</td>
                        </tr>
                        <tr>
                            <td><strong>parasitics_modeled</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>nonlinearities_modeled</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>tolerances_variations</strong></td>
                            <td>none (no Monte Carlo or process-corner simulations reported)</td>
                        </tr>
                        <tr>
                            <td><strong>ml_model_type</strong></td>
                            <td>transformer LLM (GPT-4o) used to generate netlists and orchestrate agents (not an RL agent trained in the simulator)</td>
                        </tr>
                        <tr>
                            <td><strong>training_task</strong></td>
                            <td>generation of circuit netlists / automated analog circuit design (LLM-based code/netlist generation and validation)</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_performance</strong></td>
                            <td>MenTeR-generated netlists achieved average Pass@1 = 84.2% and Pass@5 = 89.2% across 24 analog design tasks (netlists that 'pass' met specified performance criteria and executed in PySpice without errors); no numerical analog performance metrics (e.g., gain, noise) reported in aggregate beyond task pass/fail.</td>
                        </tr>
                        <tr>
                            <td><strong>real_hardware_tested</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>real_hardware_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>minimal_requirements_discussed</strong></td>
                            <td>Testbench Agent requires syntactically runnable netlists and performs basic validation (DC sweep checker, MOSFET/primitive connection checker, functionality verifier) prior to acceptance; the paper does not specify minimum physics fidelity (e.g., BSIM-level models or parasitics) required for sim-to-real transfer.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_failure_cases</strong></td>
                            <td>No sim-to-real transfer experiments performed. At system-level, a PLL netlist passed benchmark/DC simulations for subcircuits but failed integration due to incorrectly defined hierarchical subcircuits and missing wire connections — indicating that passing isolated DC checks is insufficient for correct system integration, but not a sim-to-real fidelity gap.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_randomization_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>physics_informed_approach</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>frequency_range</strong></td>
                            <td>Varied: DC checks and circuits that imply RF/time-varying behavior (VCO, PLL) — no explicit numeric frequency ranges reported</td>
                        </tr>
                        <tr>
                            <td><strong>electromagnetic_effects</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>thermal_effects</strong></td>
                            <td>False</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2138.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2138.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of circuit simulators used for training machine learning or reinforcement learning models, including details about simulation fidelity, component modeling accuracy, and transfer performance to real circuits or hardware.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SPICE (NGSpice via PySpice)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>SPICE simulation engine (NGSpice accessed via PySpice)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The underlying SPICE engine used to run circuit simulations produced by the framework; used for functional simulation and basic electrical-rule checks of generated netlists.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>circuit_type</strong></td>
                            <td>analog / RF (BGR, PLL, VCO, op-amps, Schmitt trigger, etc.)</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_tool</strong></td>
                            <td>SPICE engine (invoked through PySpice; likely NGSpice or equivalent)</td>
                        </tr>
                        <tr>
                            <td><strong>component_models</strong></td>
                            <td>SPICE primitive device models (Level=1 MOSFETs in example netlists), resistors, ideal sources; no mention of advanced foundry BSIM models or extracted parasitics</td>
                        </tr>
                        <tr>
                            <td><strong>parasitics_modeled</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>nonlinearities_modeled</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>tolerances_variations</strong></td>
                            <td>none reported</td>
                        </tr>
                        <tr>
                            <td><strong>ml_model_type</strong></td>
                            <td>LLM (GPT-4o) orchestrating generation/validation; not an ML policy trained inside SPICE</td>
                        </tr>
                        <tr>
                            <td><strong>training_task</strong></td>
                            <td>netlist validation and functional verification of generated designs</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_performance</strong></td>
                            <td>Used to determine whether generated netlists meet specification (contributes to Pass@ metrics: average Pass@1 = 84.2%, Pass@5 = 89.2%); no low-level simulator accuracy metrics provided.</td>
                        </tr>
                        <tr>
                            <td><strong>real_hardware_tested</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>real_hardware_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>minimal_requirements_discussed</strong></td>
                            <td>Authors require runnable netlists and basic electrical checks (syntax, DC sweep, connectivity, functionality) but do not prescribe detailed physics/modeling fidelity for correct real-world transfer.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_failure_cases</strong></td>
                            <td>Integration-level failures (e.g., PLL missing interconnections or misdefined subcircuits) occurred despite SPICE/DC checks on isolated subcircuits; these are structural/definition errors rather than explicit simulation-fidelity mismatches.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_randomization_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>physics_informed_approach</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>frequency_range</strong></td>
                            <td>DC to circuits implying RF/time-varying operation (no explicit numeric bands provided)</td>
                        </tr>
                        <tr>
                            <td><strong>electromagnetic_effects</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>thermal_effects</strong></td>
                            <td>False</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2138.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2138.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of circuit simulators used for training machine learning or reinforcement learning models, including details about simulation fidelity, component modeling accuracy, and transfer performance to real circuits or hardware.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Testbench Agent (TBA)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Testbench Agent (part of MenTeR multi-agent workflow)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An agent that generates PySpice testbench code and performs three specialized validation checks (DC sweep checker, MOSFET/primitive connection checker, and functionality verifier) to verify generated netlists before acceptance.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>circuit_type</strong></td>
                            <td>analog / RF (used to validate a broad set of analog tasks including BGR, VCO, PLL, op-amps, Schmitt triggers)</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_tool</strong></td>
                            <td>PySpice (generates Python simulation scripts for SPICE engine)</td>
                        </tr>
                        <tr>
                            <td><strong>component_models</strong></td>
                            <td>Validates usage of SPICE primitive devices (transistors, resistors, sources); expects syntactically correct model declarations (example netlists show Level=1 MOSFET models).</td>
                        </tr>
                        <tr>
                            <td><strong>parasitics_modeled</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>nonlinearities_modeled</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>tolerances_variations</strong></td>
                            <td>none (no Monte Carlo/process corners reported for validation)</td>
                        </tr>
                        <tr>
                            <td><strong>ml_model_type</strong></td>
                            <td>LLM-driven agent workflow (GPT-4o used as backbone); not an RL policy trained in the simulator</td>
                        </tr>
                        <tr>
                            <td><strong>training_task</strong></td>
                            <td>automated netlist validation and functional testing of AI-generated circuit designs</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_performance</strong></td>
                            <td>Operates as the gate for functional validation used to compute Pass@ metrics; no additional numerical performance (e.g., accuracy of analog metrics) reported beyond pass/fail outcomes.</td>
                        </tr>
                        <tr>
                            <td><strong>real_hardware_tested</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>real_hardware_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>minimal_requirements_discussed</strong></td>
                            <td>The TBA performs DC sweep, connectivity checks, and functionality verification as minimal validation steps; authors note future extension to steady-state large-signal operating point checks for system-level design but do not claim those are currently required for transfer.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_failure_cases</strong></td>
                            <td>The PLL example passed isolated DC checks for subcircuits but failed at the integrated schematic level (incorrect subcircuit definitions and missing interconnects), showing that the TBA's present checks can miss system-integration errors.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_randomization_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>physics_informed_approach</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>frequency_range</strong></td>
                            <td>DC and circuits implying dynamic/RF operation (no explicit numeric ranges)</td>
                        </tr>
                        <tr>
                            <td><strong>electromagnetic_effects</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>thermal_effects</strong></td>
                            <td>False</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Analogcoder: Analog circuit design via training-free code generation <em>(Rating: 2)</em></li>
                <li>Ampagent: An llm-based multi-agent system for multi-stage amplifier schematic design from literature for process and performance porting <em>(Rating: 2)</em></li>
                <li>AMSnet-KG: A Netlist Dataset for LLMbased AMS Circuit Auto-Design Using Knowledge Graph RAG <em>(Rating: 2)</em></li>
                <li>LayoutCopilot: An LLM-Powered Multi-Agent Collaborative Framework for Interactive Analog Layout Design <em>(Rating: 1)</em></li>
                <li>Chipnemo: Domain-adapted llms for chip design <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2138",
    "paper_id": "paper-278995968",
    "extraction_schema_id": "extraction-schema-56",
    "extracted_data": [
        {
            "name_short": "PySpice",
            "name_full": "PySpice (Python SPICE interface)",
            "brief_description": "A Python interface used to run SPICE-compatible circuit simulations (via NGSpice or similar engines); in this work it executes Testbench Agent generated simulations to validate AI-generated netlists.",
            "citation_title": "",
            "mention_or_use": "use",
            "circuit_type": "analog / RF (examples: single-stage op-amp, Bandgap Reference (BGR), VCO, PLL, Schmitt trigger, op-amp-based adder)",
            "simulator_tool": "PySpice (Python front-end to NGSpice/SPICE engine)",
            "component_models": "Primitive SPICE component models as shown in generated netlists: Level=1 MOSFET models (.model nmos_model nmos (kp=... level=1 vto=...)), resistors, voltage sources; no mention of industry-level BSIM or extracted parasitic models.",
            "parasitics_modeled": null,
            "nonlinearities_modeled": true,
            "tolerances_variations": "none (no Monte Carlo or process-corner simulations reported)",
            "ml_model_type": "transformer LLM (GPT-4o) used to generate netlists and orchestrate agents (not an RL agent trained in the simulator)",
            "training_task": "generation of circuit netlists / automated analog circuit design (LLM-based code/netlist generation and validation)",
            "simulation_performance": "MenTeR-generated netlists achieved average Pass@1 = 84.2% and Pass@5 = 89.2% across 24 analog design tasks (netlists that 'pass' met specified performance criteria and executed in PySpice without errors); no numerical analog performance metrics (e.g., gain, noise) reported in aggregate beyond task pass/fail.",
            "real_hardware_tested": false,
            "real_hardware_performance": null,
            "fidelity_comparison": false,
            "fidelity_comparison_details": null,
            "minimal_requirements_discussed": "Testbench Agent requires syntactically runnable netlists and performs basic validation (DC sweep checker, MOSFET/primitive connection checker, functionality verifier) prior to acceptance; the paper does not specify minimum physics fidelity (e.g., BSIM-level models or parasitics) required for sim-to-real transfer.",
            "transfer_failure_cases": "No sim-to-real transfer experiments performed. At system-level, a PLL netlist passed benchmark/DC simulations for subcircuits but failed integration due to incorrectly defined hierarchical subcircuits and missing wire connections — indicating that passing isolated DC checks is insufficient for correct system integration, but not a sim-to-real fidelity gap.",
            "domain_randomization_used": null,
            "physics_informed_approach": null,
            "frequency_range": "Varied: DC checks and circuits that imply RF/time-varying behavior (VCO, PLL) — no explicit numeric frequency ranges reported",
            "electromagnetic_effects": false,
            "thermal_effects": false,
            "uuid": "e2138.0"
        },
        {
            "name_short": "SPICE (NGSpice via PySpice)",
            "name_full": "SPICE simulation engine (NGSpice accessed via PySpice)",
            "brief_description": "The underlying SPICE engine used to run circuit simulations produced by the framework; used for functional simulation and basic electrical-rule checks of generated netlists.",
            "citation_title": "",
            "mention_or_use": "use",
            "circuit_type": "analog / RF (BGR, PLL, VCO, op-amps, Schmitt trigger, etc.)",
            "simulator_tool": "SPICE engine (invoked through PySpice; likely NGSpice or equivalent)",
            "component_models": "SPICE primitive device models (Level=1 MOSFETs in example netlists), resistors, ideal sources; no mention of advanced foundry BSIM models or extracted parasitics",
            "parasitics_modeled": null,
            "nonlinearities_modeled": true,
            "tolerances_variations": "none reported",
            "ml_model_type": "LLM (GPT-4o) orchestrating generation/validation; not an ML policy trained inside SPICE",
            "training_task": "netlist validation and functional verification of generated designs",
            "simulation_performance": "Used to determine whether generated netlists meet specification (contributes to Pass@ metrics: average Pass@1 = 84.2%, Pass@5 = 89.2%); no low-level simulator accuracy metrics provided.",
            "real_hardware_tested": false,
            "real_hardware_performance": null,
            "fidelity_comparison": false,
            "fidelity_comparison_details": null,
            "minimal_requirements_discussed": "Authors require runnable netlists and basic electrical checks (syntax, DC sweep, connectivity, functionality) but do not prescribe detailed physics/modeling fidelity for correct real-world transfer.",
            "transfer_failure_cases": "Integration-level failures (e.g., PLL missing interconnections or misdefined subcircuits) occurred despite SPICE/DC checks on isolated subcircuits; these are structural/definition errors rather than explicit simulation-fidelity mismatches.",
            "domain_randomization_used": null,
            "physics_informed_approach": null,
            "frequency_range": "DC to circuits implying RF/time-varying operation (no explicit numeric bands provided)",
            "electromagnetic_effects": false,
            "thermal_effects": false,
            "uuid": "e2138.1"
        },
        {
            "name_short": "Testbench Agent (TBA)",
            "name_full": "Testbench Agent (part of MenTeR multi-agent workflow)",
            "brief_description": "An agent that generates PySpice testbench code and performs three specialized validation checks (DC sweep checker, MOSFET/primitive connection checker, and functionality verifier) to verify generated netlists before acceptance.",
            "citation_title": "here",
            "mention_or_use": "use",
            "circuit_type": "analog / RF (used to validate a broad set of analog tasks including BGR, VCO, PLL, op-amps, Schmitt triggers)",
            "simulator_tool": "PySpice (generates Python simulation scripts for SPICE engine)",
            "component_models": "Validates usage of SPICE primitive devices (transistors, resistors, sources); expects syntactically correct model declarations (example netlists show Level=1 MOSFET models).",
            "parasitics_modeled": null,
            "nonlinearities_modeled": true,
            "tolerances_variations": "none (no Monte Carlo/process corners reported for validation)",
            "ml_model_type": "LLM-driven agent workflow (GPT-4o used as backbone); not an RL policy trained in the simulator",
            "training_task": "automated netlist validation and functional testing of AI-generated circuit designs",
            "simulation_performance": "Operates as the gate for functional validation used to compute Pass@ metrics; no additional numerical performance (e.g., accuracy of analog metrics) reported beyond pass/fail outcomes.",
            "real_hardware_tested": false,
            "real_hardware_performance": null,
            "fidelity_comparison": false,
            "fidelity_comparison_details": null,
            "minimal_requirements_discussed": "The TBA performs DC sweep, connectivity checks, and functionality verification as minimal validation steps; authors note future extension to steady-state large-signal operating point checks for system-level design but do not claim those are currently required for transfer.",
            "transfer_failure_cases": "The PLL example passed isolated DC checks for subcircuits but failed at the integrated schematic level (incorrect subcircuit definitions and missing interconnects), showing that the TBA's present checks can miss system-integration errors.",
            "domain_randomization_used": null,
            "physics_informed_approach": null,
            "frequency_range": "DC and circuits implying dynamic/RF operation (no explicit numeric ranges)",
            "electromagnetic_effects": false,
            "thermal_effects": false,
            "uuid": "e2138.2"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Analogcoder: Analog circuit design via training-free code generation",
            "rating": 2
        },
        {
            "paper_title": "Ampagent: An llm-based multi-agent system for multi-stage amplifier schematic design from literature for process and performance porting",
            "rating": 2
        },
        {
            "paper_title": "AMSnet-KG: A Netlist Dataset for LLMbased AMS Circuit Auto-Design Using Knowledge Graph RAG",
            "rating": 2
        },
        {
            "paper_title": "LayoutCopilot: An LLM-Powered Multi-Agent Collaborative Framework for Interactive Analog Layout Design",
            "rating": 1
        },
        {
            "paper_title": "Chipnemo: Domain-adapted llms for chip design",
            "rating": 1
        }
    ],
    "cost": 0.01028475,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>MenTeR: A fully-automated Multi-agenT workflow for end-to-end RF/Analog Circuits Netlist Design
3 Jun 2025</p>
<p>Pin-Han Chen 
Yu-Sheng Lin 
Mediatek Hsinchu 
Taiwan 
Wei-Cheng Lee wei-cheng.lee@mediatek.com 
Yu Leu 
Po-Hsiang Hsu 
Anjana Dissanayake anjana.dissanayake@mediatek.com 
Sungjin Oh sungjin.oh@mediatek.com 
Chinq-Shiun Chiu cs.chiu@mediatek.com </p>
<p>MediaTek Technology West Lafayette
Indiana</p>
<p>MediaTek Hsinchu
Taiwan</p>
<p>MediaTek Technology West Lafayette
Indiana</p>
<p>MediaTek Technology West Lafayette
Indiana</p>
<p>MediaTek USA West Lafayette
Indiana</p>
<p>MenTeR: A fully-automated Multi-agenT workflow for end-to-end RF/Analog Circuits Netlist Design
3 Jun 2025CE03A259E8BBF27B461A7E55AD68AD00arXiv:2505.22990v2[cs.AI]RF/Analog DesignLarge Language Models (LLMs)Multi-AgentSchematic DesignChain-of-Stage (CoS)Diagram-Aware Retrieval-Augmented Generation (DA-RAG)
RF/Analog design is essential for bridging digital technologies with real-world signals, ensuring the functionality and reliability of a wide range of electronic systems.However, analog design procedures are often intricate, time-consuming and reliant on expert intuition, and hinder the time and cost efficiency of circuit development.To overcome the limitations of the manual circuit design, we introduce MenTeR -a multiagent workflow integrated into an end-to-end analog design framework.By employing multiple specialized AI agents that collaboratively address different aspects of the design process, such as specification understanding, circuit optimization, and test bench validation, MenTeR reduces the dependency on frequent trial-and-error-style intervention.MenTeR not only accelerates the design cycle time but also facilitates a broader exploration of the design space, demonstrating robust capabilities in handling real-world analog systems.We believe that MenTeR lays the groundwork for future "RF/Analog Copilots" that can collaborate seamlessly with human designers.</p>
<p>I. INTRODUCTION</p>
<p>The recent progress of Large Language Models (LLMs) has led to an increasing numbers of LLM applications in scientific and engineering fields such as mathematical reasoning, pharmaceutical development, and chip design.For instance, in the field of digital circuit design, Liu et al. [1] introduced the first domain-adapted LLM, which demonstrated the potential of using legacy chip design documents to increase the design capabilities of LLM.BlockLove et al. [2] investigated the applications of LLMs in translating natural languages into Hardware Description Languages (HDL), showing the design example of an 8-bit microprocessor.In the field of RF/Analog circuit design, Lai et al. [3] proposed the first training-free LLM application to automate design of elementary circuit blocks through Python code generation.Liu et al. [4] introduced another LLM-based multi-agent system that automates multi-stage amplifier schematic design by integrating literature analysis, mathematical reasoning, and device sizing agents.</p>
<p>While these works have established a good foundation for LLM applications in circuit design, there are still significant challenges for practical industrial deployment.For example, [3] leveraged LLMs to solve simplified analog design tasks and built a corresponding benchmark; however, there still exist several gaps between the benchmark problem sets of [3] and industrial-scale design problems.While [4] demonstrated that a multi-stage amplifier can be designed with a multiagent system, the scalability of the approach to more complex amplifier designs or different circuit architectures is not yet explored.</p>
<p>To mitigate these gaps, we aim to build an AI-based solution for RF/Analog design, with the ultimate goal of assisted system-to-transistor-level implementation of complex circuits and systems such as Bandgap Reference (BGR) and Phase-Locked Loop (PLL).To achieve this goal, there are several questions that should be answered:</p>
<p>• What are the capabilities and limitations of current LLMs in RF/Analog circuits design?What techniques and data can we use to improve LLMs in reasoning required for practical designs?• RF/Analog circuits design is an intricate process that relies on the designer's intuitions and years of experience; how can we decompose this into multiple stages and integrate into an automated design flow?• How can we ensure the scalability and reliability of LLMbased systems for practical RF/Analog circuit designs?</p>
<p>To address these challenges, we propose MenTeR: A fullyautomated multi-agent workflow for end-to-end RF/Analog circuits netlist design, illustrated in Figure 1.MenTeR is designed to facilitate analog designers with specification reasoning, document search, testbench generation, and schematic design.Our contributions are:</p>
<p>1) To the best of our knowledge, MenTeR is the first fully-automated multi-agent framework for end-to-end RF/Analog design using LLM, which can generate analog circuit netlists of a single-block, multi-blocks, and</p>
<p>II. BACKGROUND</p>
<p>A. Enhancing Reasoning Capabilities of LLMs</p>
<p>In this section, we review key techniques for enhancing LLMs' reasoning capabilities, which inform our approach to improving LLMs' RF/Analog design performance.</p>
<p>Prompt Engineering.Deng et al. [6] proposed a "Rephrase and Respond" (RaR) method that enables language models to rephrase input questions for better clarity, significantly improving models' performance by resolving ambiguities in human-LLM communication.Wei et al. [7] introduced Chainof-Thought (CoT) prompting, where models were guided to generate step-by-step reasoning processes before producing final answers, improving their performance on complex reasoning tasks.Based on this approach, Yao et al. [8] proposed Tree of Thoughts (ToT) prompting, improving performance over CoT prompting in complex reasoning tasks by allowing models to explore and evaluate multiple reasoning paths.</p>
<p>These prompting techniques provide efficient mechanisms for us to evaluate and enhance LLMs' capabilities in analog design, where structured reasoning and alternative solution explorations are particularly valuable.</p>
<p>Retrieval-Augmented Generation.Retrieval-Augmented Generation (RAG) proposed by Lewis et al. [9] has been a widely used technique to increase the ability of LLMs in knowledge-intensive language tasks.By combining a pretrained seq2seq model with a dense vector retrieval system over text-based documents, it enables knowledge updates without model retraining.In analog design, [4] and [10] have used the basic RAG technique with analog design documents to enhance LLMs' capabilities in a complex design task.</p>
<p>Fine Tuning.Moreover, aligning language models with human preferences has proven to be effective in enhancing reasoning capabilities.Ouyang et al. [11] demonstrated that fine-tuning language models with Reinforcement Learning from Human Feedback (RLHF) significantly improves model alignment with user intentions.However, RLHF is a complex and often unstable procedure that involves two main steps:</p>
<p>1) Fitting a reward model to reflect human preferences.</p>
<p>2) Fine-tuning a language model with reinforcement learning to maximize this estimated reward.To address these challenges, Rafailov et al. [12] introduced Direct Preference Optimization (DPO), a method that bypasses explicit reward modeling and reinforcement learning by directly training language models from human preferences through a simple classification loss.Building on this approach, Meng et al. [13] proposed SimPO, a simplified preference optimization approach that improved DPO by using a reference-free reward formulation based on the average logarithmic probability of a sequence.Most recently, DeepSeek [14] demonstrated that reasoning capabilities can be significantly enhanced by large-scale reinforcement learning on highquality Chain-of-Thought (CoT) data.</p>
<p>When we take a closer look at these fine-tuning methodologies, it becomes apparent that effective RF/Analog design finetuning requires either sophisticated reward modeling tailored to circuit designers' preferences or the development of a highquality CoT dataset specific to the designs.Both approaches represent substantial long-term commitments.In this paper, we pay attention to the latter direction.By integrating our multi-agent workflow into daily design processes, we aim to not only solve fundamental RF/Analog circuit problems but also collect the reasoning paths employed in analog circuit design systematically.This helps us prepare the necessary steps for building a domain-adapted reasoning model to assist with more complex circuit designs.</p>
<p>B. The Necessity of a Multi-Agent Workflow</p>
<p>Here, we investigate the importance of a multi-agent workflow to achieve the aforementioned goal.Wu et al. [15] developed AutoGen, an open-source framework that facilitated multi-agent conversations between customizable LLMpowered agents, human inputs, and tools to tackle complex tasks across mathematics, coding, and decision-making domains.Building on this concept, Song et al. [16] proposed Captain Agent, an adaptive framework that dynamically assembled and managed teams throughout the task-solving process, providing a valuable reference for formulating our multiagent workflow.Based on these insights, we have implemented a simplified multi-agent framework and compared it with a single-agent approach, as illustrated in Figure 2.</p>
<p>While a single-agent approach offers implementation simplicity for analog design tasks, it inevitably encounters bottlenecks limited by the capabilities of the underlying Large Language Model.As we attempted to solve complex design challenges using LLM-based methodologies, our proposed multi-agent system demonstrated significant benefits.</p>
<p>In our simplified multi-agent framework, we implemented a Meta Agent serving as the central orchestrator, which analyzes incoming design tasks to determine which specialized domain experts are required.Upon receiving an analog design specification, the Meta Agent decomposes complex problems into manageable sub-tasks, delegates these components to appropriate domain specialist agents, and oversees the entire workflow.</p>
<p>With this simplified multi-agent approach, our method already outperformed single-agent work such as [3] (see Table I for more details).However, the structure of this framework can be further optimized to integrate into contemporary design flows.The detail of our proposed MenTeR framework will be interpreted in detail in Section III.</p>
<p>III. OVERVIEW OF MENTER</p>
<p>In this section, we introduce the proposed MenTeR framework, which decomposes an analog design task into multiple stages, including specification understanding, document search, circuit netlist design, and test bench generation.The overview of MenTeR is illustrated in Figure 1, and the flow of each agent is illustrated in Figure 3.</p>
<p>A. PI Agent</p>
<p>PI agent is designed to play the role of the "Primary Investigator," who interacts with the users, manages the workflow, and assigns tasks to corresponding agents.Given an analog design task, the PI agent should leverage the DA-RAG agent to process design requirements using multiple knowledge sources: technical papers (e.g., [18], [20]), Rapid Adoption Kit (RAK), and textbook chapters (e.g., [17]).</p>
<p>After retrieving the knowledge, PI agent defines the tasks and assigns them to different agents respectively.This paradigm transforms abstract user requirements into welldefined specifications, which bridges the semantic gap between human design intent and formal circuit requirements.</p>
<p>B. Circuit Agent</p>
<p>Upon receiving processed requirements from the PI Agent, the Circuit Agent (CA) functions as a "senior analog designer," generating the actual circuit design in PySpice1 format.The CA's internal architecture consists of two primary components: the Chain-of-Stage (CoS) agent and the Executor agent.The CoS agent manages design stage reasoning, identifies familiar circuit blocks, and conducts self-referential iteration for design refinement.</p>
<p>When tasked with a design challenge, the Circuit Agent first determines the necessary design stages required for the desired circuit implementation.For familiar design blocks, it can consult domain experts in the Circuit Think Tank to leverage established design patterns.After formulating the initial design, the Circuit Agent produces a netlist draft which is then passed to the Executor agent.This secondary agent performs essential validation checks including syntax verification and other critical error detection processes.Any errors identified during this preliminary validation are routed back to the CoS agent for targeted refinement.</p>
<p>Once the netlist passes these basic verification checks, the validated draft is forwarded to the Testbench Agent for comprehensive simulation and testing.</p>
<p>C. Testbench Agent</p>
<p>By leveraging DA-RAG (refers to Section III-E2), the Test-Bench Agent (TBA) defines appropriate simulations required for the specific circuit, implementing three specialized validation components: DC sweep checker, MOSFET (and other primitive elements such as resistors) connection checker, and functionality verifier.TBA generates corresponding Python code to validate the PySpice implementation.In the future, more advanced check agents such as steady-state large-signal operating point check can be included to facilitate system-level design.</p>
<p>Similar to the Circuit Agent's workflow, the testbench code is passed to an Executor agent to verify syntax correctness and ensure proper simulation.Upon completion of the validation process, it either confirms successful design verification or produces detailed error messages that are routed back to the Circuit Agent for targeted design refinement.</p>
<p>D. Circuit Think Tank (CTT)</p>
<p>As we deploy MenTeR in real-world applications, we anticipate encountering increasingly diverse circuits that share fundamental design concepts.To leverage these similarities and reduce complexity, we established the Circuit Think Tank-a knowledge repository of specialized circuit expertise.</p>
<p>After a circuit design is successfully completed and validated by the Testbench Agent, we capture its critical attributes including circuit name, specifications, reasoning stages, netlist implementation, and relevant interaction history.This repository serves dual purposes: it facilitates accelerated reasoning for new analog design tasks by providing access to established design patterns, and it constitutes a valuable dataset for future domain-adapted fine-tuning of our agents.</p>
<p>E. Sub-Agents</p>
<p>Moreover, we construct several sub-agents to equip techniques for each agent, including:</p>
<p>1) CoS Reasoning Agent: In contrast to conventional one-pass approaches, we propose a CoS reasoning agent to decompose the RF/Analog design problem into a sequence of specialized sub-tasks, or "stages." Figure 4 illustrates this methodology through the reasoning stages developed for a Bandgap Reference circuit.By treating each stage as an independent task that feeds its intermediate outputs into the subsequent stage, CoS ensures that critical design stages and constraints are addressed during the generation process.</p>
<p>For example, the first stage of our CoS reasoning agent leverages task-relevant information (e.g. from textbooks or prior designs know-how from agents in CTT) to establish the fundamental design requirements.The system then transitions into a parameter synthesis stage, where CoT will be used to follow this hierarchical system to propose initial component values.Specifically, each stage stores both its prompts and outputs as prior knowledge, allowing for iterative updates and cross-referencing between stages.</p>
<p>2) Diagram-Aware RAG (DA-RAG) Agent: In RF/Analog design, diagrams commonly encapsulate substantial information-such as schematic topologies, performance curves, and intricate design annotations-that cannot be readily conveyed through textual means.To effectively extract such information, we propose a Diagram-Aware RAG (DA-RAG) wherein realworld circuit textbooks [18], often filled with specialized domain expertise, are methodically converted into Markdown format [19], as illustrated in Figure 5. Unlike conventional RAG-based frameworks that primarily process text, DA-RAG leverages a LLM to transform these diagrams into textual representations, thereby enabling downstream retrieval and capture design requirements comprehensively.3) Executor Agent: Similar to a compiler, Executor Agent functions as a self-referential system that syntactically validates generated code and circuit descriptions, ensuring their correctness and executability before passing them to subsequent stages of the workflow.</p>
<p>IV. EXPERIMENT RESULTS</p>
<p>To evaluate the effectiveness of our framework, we compared MenTeR against several baseline approaches, including individual LLMs (single-agent) and multi-agent systems.We evaluated them on 24 standard analog design tasks from [3], ranging from elementary designs to complex multi-block design challenges.Furthermore, we deployed our workflow to solve a CMOS Bandgap Reference circuit, a practical task encountered in real-world implementations, to validate MenTeR's performance in industrial applications.</p>
<p>A. Experimental Setup</p>
<p>We evaluated all methods by generating circuit netlists and checking whether the produced solution passed functional validation.Specifically, we considered the pass@k metric, which measures the probability of obtaining at least one correct solution within k attempts:
pass@k = 1 − n−c k n k(1)
where:</p>
<p>• n is the total number of solutions generated,</p>
<p>• c is the number of correct solutions,</p>
<p>• k is the success threshold (number of attempts).A circuit is deemed "correct" if it meets the specified performance criteria (e.g., gain, power consumption, linearity, bandwidth, etc.) To ensure consistency, all solutions generated were further inspected with basic electrical rule checks and circuit simulations, verifying that the netlists could be functionally simulated without errors.</p>
<p>B. Comparison Results</p>
<p>Table I presents our experimental results, with testing limited to five attempts per task for cost effectiveness.We used GPT-4o as the backbone model for all our approaches to maintain cost efficiency and ensure fair comparison with singleagent methods.For baseline single-agent evaluations, we selected AnalogCoder [3] implemented with distilled model variants (e.g.OpenAI o3-mini [23], DeepSeek-R1 distilled 32B [24]) rather than state-of-the-art reasoning models (e.g.OpenAI o1 [21], DeepSeek-R1 671B [22]), considering the substantial inference costs associated with the latter.</p>
<p>1) Overall Performance: MenTeR demonstrates strong performance in various analog design tasks, achieving an average Pass@1 rate of 84.2%.Specifically, MenTeR consistently solves basic circuits (e.g., Task 1-6) within a single attempt and outperforms other methods in many advanced tasks requiring multi-block circuit interplay.This significantly outperforms the single-agent baseline, even when the baseline is given multiple attempts (at least five tries per task), as illustrated in Figure 6.</p>
<p>Remarkably, MenTeR achieves a successful Pass@1 rate of at least 80% and a perfect 100% at Pass@5 rate for complex tasks (e.g., Task 16-24) such as Schmitt trigger, Voltage-Controlled Oscillator, and low-voltage BGR circuit.This indicates its potential to assist real-world complex analog design tasks.Task Pass@1 Pass@5 Pass@1 Pass@5 Pass@1 Pass@5 Pass@1 Pass@5 Pass@1 Pass@5 Pass@1 Pass@5 Pass@1 Pass@5 1</p>
<p>C. Ablation Studies</p>
<p>To isolate the contribution of each MenTeR component, we conducted our ablation study to examine the contributions of MenTeR's key components, as demonstrated in Table II.</p>
<p>• Without DA-RAG: Replacing the DA-RAG agent inside PI Agent and Testbench Agent with a generic approach decreased the average pass@1 by about 9%.This performance degradation highlighted LLM knowledge limitations when operating without specialized domain knowhow.Without access to task-relevant documents, it failed to effectively address advanced analog design tasks that require specific circuit knowledge beyond the model's inherent capabilities.• Without CoS Reasoning: Removing CoS logic left the multi-agent system with a more "flat" approach to design.Pass@1 dropped significantly (maximum by 14%), especially on tasks with multiple nested constraints.Notably, we observed that the Pass@1 rate of MenTeR without CoS fell below the multi-agent baseline, suggesting that without structured reasoning guidance, the system becomes overwhelmed by retrieved document information and fails to prioritize relevant design knowledge.</p>
<p>V. CONCLUSION</p>
<p>In this work, we propose MenTeR, a fully-automated multiagent workflow for RF/Analog circuit design that scales effectively to system-level circuit design.By leveraging techniques including Diagram-Aware Retrieval-Augmented Generation (DA-RAG), Chain-of-Stage (CoS) reasoning, and selfreferential mechanisms, MenTeR successfully addresses various fundamental circuit blocks without requiring human intervention or extensive fine-tuning.Specifically, MenTeR achieves significantly better performance when handling increasingly complex circuits compared to single-agent approaches, validating its potential for scaling up to system-level circuits and integration with contemporary design flows.</p>
<p>Opportunities and Future work.We acknowledge that MenTeR's capabilities remain highly correlated with the underlying large language models that power its agents.For more complex analog design tasks, domain-adapted reasoning models specifically fine-tuned for analog design could be a promising direction for future development.Throughout MenTeR's operation, we have deliberately structured the system to collect high-quality design data, with the goal of building a comprehensive analog design reasoning dataset.We expect this framework will facilitate the development of LLMdriven EDA tools for analog circuits, paving the way towards collaborative teamwork between human analog designers and an RF/Analog copilot.</p>
<p>APPENDIX C ENGINEERING CHALLENGES</p>
<p>In our experiment, we encountered several engineering challenges that impacted efficiency and resource utilization.In this section, we share these challenges and their corresponding solutions to assist future LLM-based analog design research.</p>
<p>Token Limits.The primary issue we encountered when testing on [3] was exceeding the token limits, which led to frequent crashes and interfered with our experimental progress.Upon investigation, we identified that the root cause stemmed from inefficient chat history parsing techniques that included the whole conversation texts in each iteration, which occupied the context window rapidly.To resolve this limitation, we modified our approach to truncate the chat history in each agent, retaining only the initial prompt and the last message.This optimization effectively reduced token consumption and eliminated system crashes.</p>
<p>In addition, we acknowledge the concerns raised by reviewers regarding potential information loss when adopting context truncation techniques.To address this issue, we believe that approaches similar to the memory management system proposed by [26] represent promising avenues to solve the "lost-in-the-middle" issue.</p>
<p>LLM Instability.Another substantial obstacle encountered was the instability introduced by iterative updates to the underlying large language model.Although no official statement has confirmed this phenomenon, there exists a widely discussed concern within the research community regarding sudden shifts in model behavior and performance after platform updates.Our own observations were consistent with these anecdotal at various points in the experimental process, the model's generative consistency and accuracy appeared to deteriorate following version changes and seed randomness.While further investigation is required to systematically verify the extent of this issue, the unanticipated variability in model output poses significant challenges for maintaining reproducibility and fine-tuning results in LLMbased analog design research.</p>
<p>Execution Errors.We experienced a notably high rate of execution errors when reproducing single-agent results.This issue significantly interrupted the workflow as the generated code was often "unrunnable," preventing it from reaching the testbench validation stage.To mitigate this issue, we incorporated a self-referential technique into both multi-agent and MenTeR, ensuring all code is executable before submission.This technique substantially decreased execution error rates, which led to the stability of our methodologies (as illustrated in Figure 6), improving deployment efficiency of the overall system.</p>
<p>Repetitive Error Loops.We observed that certain errors appeared repeatedly during our experimental iterations; LLMs continuously encountering the same issues and becoming stuck, even after receiving specific instructions to avoid them.This cycle led to task failures and resulted in substantial resource waste.We determined this occurred due to inherent limitations of LLMs.Consequently, we implemented an early-detection mechanism to identify such recurring errors, automatically terminating the chat when these patterns are detected.In future work, "preventing LLMs from repeating the same mistakes" represents an important research direction that needs further exploration.</p>
<p>Token Efficiency.Lastly, we compare the token efficiency of the single-agent approach and MenTeR, both utilizing GPT-4o as the backbone model.In this context, prompt tokens refer to the input tokens provided to the model, while completion tokens denote the output tokens generated by the model.As shown in Table IV, MenTeR consumes more tokens for the relatively simple Task 1.However, for the more challenging Task 24, the single-agent method exhibits a substantial increase in token usage, yet still fails to solve the task.</p>
<p>This highlights that while the single-agent approach remains effective for straightforward tasks, its capability diminish as task complexity increases.Balancing token efficiency and problem-solving capability, particularly in RF/Analog design, remains an important direction for future research.</p>
<p>APPENDIX D ALTERNATIVE SCHEMATIC EXPLORATION</p>
<p>During our experiments, we noticed that the same problem specification can yield multiple valid solutions with slightly different transistor arrangements or bias schemes.For instance, in the tasks labeled as "Problem 20," the system generated two distinct netlists (20-0 vs. 20-1), all claiming to meet similar specifications.</p>
<p>We hypothesize that this behavior arises because the given problem constraints are not sufficiently strict to enforce a single unique topology or bias point.Despite leading to multiple functional solutions, such variability also highlights the LLM's capacity to explore alternative schematics.Below, we include two representative netlists, which aim to implement a simple op-amp-based adder.</p>
<p>Fig. 1 :
1
Fig. 1: Overview of MenTeR.A fully-automated multi-agent workflow for RF/Analog circuit design that translates specifications to netlist.MenTeR is designed with interactive checkpoints where human designers can intervene as needed.</p>
<p>Fig. 2 :
2
Fig. 2: Comparison between single-agent and simplified multiagent frameworks.</p>
<p>Fig. 3 :
3
Fig. 3: Overview of MenTeR agents.</p>
<p>Fig. 4 :
4
Fig. 4: CoS reasoning stages for the BGR circuit.</p>
<p>Fig. 5 :
5
Fig. 5: Overview of Diagram-Aware RAG (DA-RAG).</p>
<p>Fig. 6 :
6
Fig. 6: Pass@k comparison between single-agent baseline and MenTeR.</p>
<p>Fig. 7 :
7
Fig. 7: Schematic of an AI generated Phase-Locked Loop (PLL).</p>
<p>Table I :
I
Performance comparison (in percentage) on 24 analog design tasks and a BGR problem.The highest scores for the hard tasks and average performance are highlighted as bold.(Task 1-8: Easy, Task 9-13: Medium, Task 14-24 &amp; BGR: Hard)
MethodAnalogCoder (Single-Agent)Multi-Agent Workflow (ours)MenTeR w/o DA-RAG (ours)MenTeR w/o CoS (ours)MenTeR (ours)ModelDeepSeek R1 Distill 32BGPT-4oGPT-o3-miniGPT-4o</p>
<p>Table II :
II
Ablation Studies Results for MenTeR Components.
and CoS reasoning within the MenTeR framework, demon-strating how each component addresses specific limitations inLLM-based analog circuit design.MethodAvg. Pass@1 (%)Avg. Pass@5 (%)Multi-Agent Workflow70.874.2MenTeR w/o DA-RAG75.080.0MenTeR w/o CoS70.078.3Full MenTeR84.289.2These findings substantiate the necessity of both DA-RAG</p>
<p>Table IV :
IV
Token Comparison between Single-Agent and MenTeR.(<em> means fail)
Single-AgentMenTeRTokenPrompt CompletionPrompt CompletionTask 1 (Easy)1330269539912938Task 24 (Hard)9817343310</em>390382428
https://github.com/PySpice-org/PySpice
ACKNOWLEDGEMENTWe would like to thank Wei-Chen Chien and Min-Chun Wu for their valuable consultation on the agent framework.APPENDIX A MENTER STABILITYWe evaluated MenTeR using different backbone models, as summarized in TableIII.MenTeR achieves at least a 77% pass@1 rate and 85% pass@5 rate across both models, demonstrating its stable performance.Notably, GPT-4o outperforms GPT-4.1, with higher average pass rates in both metrics.The slightly lower performance of GPT-4.1 may be attributed to its relative deficiency in Analog IC knowledge, which we discuss further in Appendix E.APPENDIX B COMPARISON WITH REAL-WORLD DESIGNFor the Phase-Locked Loop (PLL) task, we compared AI-generated results with a human-designed reference.Our analysis revealed discrepancies between circuits that passed the benchmark validation and those that were functionally correct.For instance, Figure7shows a PLL implementation that was deemed correct by the benchmark criteria but contained errors upon schematic inspection.These errors primarily fell into two categories: incorrectly defined subcircuits (Frequency Detector (FD), Voltage Controlled Oscillator (VCO)), and missing wire connections (VCO to FD, FD to Phase Frequency Detector (PFD), and PFD to the reference frequency source).These issues stem from the inherent complexity of the PLL as a hierarchical system-level design.Notably, while individual subcircuits successfully passed DC sweep simulations in isolation, the integrated system as a whole failed to function correctly.This highlights the challenges of fully automating the generation of complex system-level designs using LLMbased RF/Analog design tools.To further deploy MenTeR into real-world design environments, maintaining a "human-in-the-loop" approach remains essential.Such human oversight is particularly critical for complex system-level designs like PLL, where subtle integration errors may escape automated validation.Nevertheless, as the analog design reasoning capabilities of LLMs continue to advance, we can reasonably expect to reduce human intervention significantly, allowing designers to focus their expertise on system-level verification and optimization rather than routine circuit implementation tasks.Although each netlist relies on similar single-stage operational amplifier blocks, the resistor arrangements differ.These differences stem from multiple ways to achieve the same functional requirement (i.e., summing two input signals).Overall, our findings indicate that when problem constraints are loosely defined, LLMs can explore multiple design topologies.While each solution may meet the functional specs at a high level, additional constraints (e.g.output swing requirements, matching conditions, noise margins) would be needed to converge on more uniform design outcomes.APPENDIX E ANALOG IC KNOWLEDGEIn order to investigate the root causes of differing performance among LLM-based analog design approaches, we developed the Analog IC Benchmark (AICB)[25].This dataset consists of 300 multiple-choice questions derived from a standard analog IC (AIC) textbook, with each question providing four possible answers.A. Dataset IntroductionTo illustrate the format of AICB, we can consider the following example question:Question: What is the primary function of a sampleand-hold circuit in an ADC? (A) To amplify the input signal (B) To convert the analog signal to digital (C) To hold the input signal constant in conversion (D) To filter the input signal The correct answer is C, reflecting a key concept in data conversion systems.B. Performance ResultsTableVsummarizes the accuracies achieved by these models on the AICB dataset.As indicated, GPT-o3-mini attained the highest accuracy, closely followed by GPT-4o, while DeepSeek R1 Distill 32B showed noticeably lower performance.C. Key ObservationsInstruction-Following Challenges in DeepSeek R1 Distill 32B.We identify that DeepSeek R1 Distill 32B generates inconsistent output formatting (e.g., generating ** Answer ** : A or ### Answer A instead of the prescribed tag format), which contributes to the poor performance of the model within an agent-based system, as such systems often rely on strict text formats for downstream task coordination.Consequently, DeepSeek R1 Distill 32B's difficulties in adhering to instructions partially explain its poor results in TableIwhen paired with the benchmark[3].D. Limitations and Future DirectionsWhile AICB provides a preliminary means of assessing LLM proficiency in analog IC domains, it does not fully capture the complexities encountered in real-world circuit design.As a result, we plan to expand AICB by incorporating more challenging and open-ended questions, aligned with the multifaceted nature of industrial analog design tasks.Such an enhanced benchmark would offer deeper insights into each model's capabilities and limitations, facilitating more robust research and development of LLM-based analog design tools.
Chipnemo: Domain-adapted llms for chip design. M Liu, T Ene, R Kirby, C Cheng, N Pinckney, R Liang, J Alben, H Anand, S Banerjee, I Bayraktaroglu, B Bhaskaran, B Catanzaro, A Chaudhuri, S Clay, B Dally, L Dang, P Deshpande, S Dhodhi, S Halepete, E Hill, J Hu, S Jain, B Khailany, K Kunal, X Li, H Liu, S Oberman, S Omar, S Pratty, A Sarkar, Z Shao, H Sun, P P Suthar, V Tej, K Xu, H Ren, 2023</p>
<p>Chip-chat: Challenges and opportunities in conversational hardware design. J Blocklove, S Garg, R Karri, H Pearce, arXiv:2305.132432023arXiv preprint</p>
<p>Analogcoder: Analog circuit design via training-free code generation. Y Lai, S Lee, G Chen, S Poddar, M Hu, D Z Pan, P Luo, arXiv:2405.149182024arXiv preprint</p>
<p>Ampagent: An llm-based multi-agent system for multi-stage amplifier schematic design from literature for process and performance porting. C Liu, W Chen, A Peng, Y Du, L Du, J Yang, arXiv:2409.147392024arXiv preprint</p>
<p>AMSnet-KG: A Netlist Dataset for LLMbased AMS Circuit Auto-Design Using Knowledge Graph RAG. Y Shi, Z Tao, Y Gao, T Zhou, C Chang, T Wang, B Chen, G Zhang, A Liu, Z Yu, T Lin, L He, arXiv:2411.135602024arXiv preprint</p>
<p>Y Deng, W Zhang, Z Chen, Q Gu, arXiv:2311.04205Rephrase and respond: Let large language models ask better questions for themselves. arXiv preprint</p>
<p>Chain of thought prompting elicits reasoning in large language models. J Wei, X Wang, D Schuurmans, M Bosma, E Chi, Q Le, D Zhou, arXiv:2201.11903arXiv preprint</p>
<p>Tree of thoughts: Deliberate problem solving with large language models. S Yao, D Yu, J Zhao, I Shafran, T L Griffiths, Y Cao, K Narasimhan, abs/2305.10601CoRR. 2023</p>
<p>Retrieval augmented generation for knowledge-intensive nlp tasks. P Lewis, E Perez, A Piktus, F Petroni, V Karpukhin, N Goyal, H K¨uttler, M Lewis, W -T. Yih, T Rockt¨aschel, Advances in Neural Information Processing Systems. 202033</p>
<p>LayoutCopilot: An LLM-Powered Multi-Agent Collaborative Framework for Interactive Analog Layout Design. B Liu, 10.1109/TCAD.2025.3529805IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems. </p>
<p>Training language models to follow instructions with human feedback. L Ouyang, J Wu, X Jiang, D Almeida, C Wainwright, P Mishkin, C Zhang, S Agarwal, K Slama, A Ray, J Schulman, J Hilton, F Kelton, L Miller, M Simens, A Askell, P Welinder, P F Christiano, J Leike, R Lowe, Advances in Neural Information Processing Systems. S Koyejo, S Mohamed, A Agarwal, D Belgrave, K Cho, A Oh, Curran Associates, Inc202235</p>
<p>Direct preference optimization: Your language model is secretly a reward model. R Rafailov, A Sharma, E Mitchell, S Ermon, C D Manning, C Finn, NeurIPS2023</p>
<p>Simple Preference Optimization with a Reference-Free Reward. Y Meng, M Xia, D Chen, Simpo, NeurIPS2024</p>
<p>D Guo, D Yang, H Zhang, J Song, R Zhang, R Xu, Q Zhu, S Ma, P Wang, X Bi, arXiv:2501.12948Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning. 2025arXiv preprint</p>
<p>Autogen: Enabling next-gen LLM applications via multi-agent conversation. Q Wu, G Bansal, J Zhang, Y Wu, B Li, E Zhu, L Jiang, X Zhang, S Zhang, J Liu, ICLR 2024 Workshop on Large Language Model (LLM) Agents. 2024</p>
<p>L Song, J Liu, J Zhang, S Zhang, A Luo, S Wang, Q Wu, C Wang, arXiv:2405.19425Adaptive in-conversation team building for language model agents. 2024arXiv preprint</p>
<p>Design of Analog CMOS Integrated Circuits. B Razavi, 2017McGraw-Hill, Inc., USA2nd. ed.</p>
<p>The Design of a Low-Voltage Bandgap Reference [The Analog Mind]. B Razavi, 10.1109/MSSC.2021.3088963IEEE Solid-State Circuits Magazine. 1332021</p>
<p>Vik Paruchuri, Marker, GitHub. 2023</p>
<p>CMOS Schmitt trigger design. I M Filanovsky, H Baltes, 10.1109/81.260219IEEE Transactions on Circuits and Systems I: Fundamental Theory and Applications. Jan. 199441</p>
<p>R1 Deepseek, DeepSeek R1 Distilled Qwen 32B. </p>
<p>AICB: Analog Integrated Circuit Benchmark. </p>
<p>C Packer, S Wooder, K Lin, arXiv:2310.08560Towards LLMs as Operating Systems. 2023arXiv preprint</p>
<p>. #20-0A. Problem. 20Op-Amp Adder Netlist</p>
<p>title Opamp Adder 2 .subckt SingleStageOpamp Vinp Vinn Vout. </p>
<p>M1 Voutp Vinp Source3 Source3 nmos_model l=1e-06. </p>
<p>M2 Vout Vinn Source3 Source3 nmos_model l=1e-06 w. </p>
<p>w=0.0001M3 Source3 Vbias 0 0 nmos_model. </p>
<p>=0.0001M4 Voutp Voutp Vdd Vdd pmos_model l=1e-06 w. </p>
<p>kp=5e-05 level=1 vto =-0.5) 12 .ends SingleStageOpamp 13M5 Vout Voutp Vdd Vdd pmos_model l=1e-06 w=0.0001 10 .model nmos_model nmos (kp=0.0001 level=1 vto =0.5) 11 .model pmos_model pmos. </p>
<p>X1 V_bias Vinn Vout SingleStageOpamp 19 R1 Vin1 Vinn 20kOhm. </p>
<p>R2 Vin2 Vinn 20kOhm. </p>
<p>Rf Vout Vinn 20kOhm. </p>
<p>Rref Vref Vinn 20kOhm Netlist. </p>
<p>title Opamp Adder: Vout = -(Vin1+Vin2). </p>
<p>subckt SingleStageOpamp Vinp Vinn Vout. </p>
<p>M1 Voutp Vinp Source3 Source3 nmos_model l=1e-06. </p>
<p>M2 Vout Vinn Source3 Source3 nmos_model l=1e-06 w. </p>
<p>w=0.0001M3 Source3 Vbias 0 0 nmos_model. </p>
<p>=0.0001M4 Voutp Voutp Vdd Vdd pmos_model l=1e-06 w. </p>
<p>model nmos_model nmos (kp=0.0001 level=1 vto =0.5) 11 .model pmos_model pmos (kp=5e-05 level=1 vto =-0.5) 12 .ends SingleStageOpamp 13 14 X1 bias inv Vout SingleStageOpamp 15 Vin1 Vin1. w=0.0001 10M5 Vout Voutp Vdd Vdd pmos_model. 0V</p>
<p>Vin2 Vin2 0 0V 17 Vbias_source bias 0 1. 79V</p>
<p>R1 Vin1 inv 10kOhm. </p>
<p>R2 Vin2 inv 10kOhm. </p>
<p>Rf Vout inv 10kOhm. </p>
<p>. Roffset voffset inv. 33333333333333335</p>            </div>
        </div>

    </div>
</body>
</html>