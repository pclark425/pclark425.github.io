<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-6620 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-6620</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-6620</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-127.html">extraction-schema-127</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents that employ a memory mechanism to solve tasks, including details of the memory type, how it is accessed or updated, the tasks/benchmarks evaluated, performance with and without the memory, and any reported trade‑offs or limitations.</div>
                <p><strong>Paper ID:</strong> paper-50f44ef10335d59cec145b15effae20ff22c1fdb</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/50f44ef10335d59cec145b15effae20ff22c1fdb" target="_blank">ChatDB: Augmenting LLMs with Databases as Their Symbolic Memory</a></p>
                <p><strong>Paper Venue:</strong> arXiv.org</p>
                <p><strong>Paper TL;DR:</strong> This paper seeks inspiration from modern computer architectures to augment LLMs with symbolic memory for complex multi-hop reasoning, and proposes a symbolic memory framework instantiated as an LLM and a set of SQL databases.</p>
                <p><strong>Paper Abstract:</strong> Large language models (LLMs) with memory are computationally universal. However, mainstream LLMs are not taking full advantage of memory, and the designs are heavily influenced by biological brains. Due to their approximate nature and proneness to the accumulation of errors, conventional neural memory mechanisms cannot support LLMs to simulate complex reasoning. In this paper, we seek inspiration from modern computer architectures to augment LLMs with symbolic memory for complex multi-hop reasoning. Such a symbolic memory framework is instantiated as an LLM and a set of SQL databases, where the LLM generates SQL instructions to manipulate the SQL databases. We validate the effectiveness of the proposed memory framework on a synthetic dataset requiring complex reasoning. The project website is available at https://chatdatabase.github.io/ .</p>
                <p><strong>Cost:</strong> 0.018</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e6620.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e6620.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents that employ a memory mechanism to solve tasks, including details of the memory type, how it is accessed or updated, the tasks/benchmarks evaluated, performance with and without the memory, and any reported trade‑offs or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ChatDB</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ChatDB: Augmenting LLMs with Databases as Their SYMBOLIC MEMORY</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A framework that augments an LLM controller with an external symbolic memory implemented as SQL databases; the LLM generates SQL to read/write the database and uses a chain-of-memory (CoM) multi-step decomposition to perform complex, multi-hop reasoning and precise calculations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>ChatDB (LLM + MySQL symbolic memory)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>An LLM controller (used: ChatGPT GPT-3.5 Turbo) generates sequences of intermediate memory-operation steps (SQL statements) which are executed against an external relational database (MySQL). The system iteratively updates operations based on prior SQL results (chain-of-memory) and summarizes final replies based on executed SQL results.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>unspecified (GPT-3.5 Turbo used as the LLM controller)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>symbolic external database (relational SQL database - MySQL)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_representation</strong></td>
                            <td>Structured relational tables (rows/columns) with explicit schema, primary/foreign keys, and typed fields (e.g., sales, customers, fruits, sale_items).</td>
                        </tr>
                        <tr>
                            <td><strong>memory_access_mechanism</strong></td>
                            <td>LLM generates SQL (INSERT/UPDATE/SELECT/DELETE) which is executed on the DB; query results are returned to the LLM; the LLM may update subsequent SQL steps based on previous SQLResults (iterative chain-of-memory control flow).</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Fruit Shop Dataset (synthetic fruit shop record management and question answering)</td>
                        </tr>
                        <tr>
                            <td><strong>task_category</strong></td>
                            <td>multi-hop reasoning / data management / retrieval & calculation</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>82% accuracy (41/50 overall); Easy: 13/15; Hard: 28/35 (Accuracy reported in Table 2)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td>22% accuracy (11/50 overall) when using ChatGPT baseline that ingested records directly in prompt (no external DB memory); Easy: 10/15; Hard: 1/35</td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Accuracy (counts and percentage over 50 questions)</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoffs_reported</strong></td>
                            <td>Paper emphasizes benefits: precise calculations, no error accumulation from symbolic execution, high interpretability, explicit state tracking and rollback capability. Paper contrasts with neural/vector memories being approximate and error-prone. The paper does not present measured latency, memory-footprint, or throughput benchmarks for the DB-based approach; potential practical trade-offs (e.g., IO/API latency, DB scaling) are discussed qualitatively but not quantified.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Evaluations are on a synthetic fruit-shop dataset; authors note schema creation may be manual or LLM-assisted (dependency on correct schema). The paper does not report explicit failure cases of ChatDB in experiments; potential limitations include dependence on correct SQL generation by the LLM and that results are validated only on the synthetic management setting (generalization to other domains not empirically shown).</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Chenxu Hu, Jie Fu, Chenzhuang Du, Simian Luo, Junbo Zhao, Hang Zhao. ChatDB: Augmenting LLMs with Databases as Their SYMBOLIC MEMORY.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'ChatDB: Augmenting LLMs with Databases as Their Symbolic Memory', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6620.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e6620.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents that employ a memory mechanism to solve tasks, including details of the memory type, how it is accessed or updated, the tasks/benchmarks evaluated, performance with and without the memory, and any reported trade‑offs or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ChatGPT (baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ChatGPT (GPT-3.5 Turbo) baseline used in experiments</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Off-the-shelf LLM used as a baseline which consumes the entire record history as part of the prompt (no external symbolic database); produces answers directly from prompt context.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>ChatGPT (GPT-3.5 Turbo)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Standard in-context prompting where the dataset records are concatenated into the model prompt and the model answers questions directly; no external symbolic memory is used in the baseline experiment (records are part of the prompt).</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>unspecified (GPT-3.5 Turbo)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>none (prompt-only; implicitly uses the model context window)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_representation</strong></td>
                            <td>raw text prompt (concatenated records within context window)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_access_mechanism</strong></td>
                            <td>direct attention over prompt tokens within the model's context window; no external read/write API to a memory store.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Fruit Shop Dataset (synthetic)</td>
                        </tr>
                        <tr>
                            <td><strong>task_category</strong></td>
                            <td>multi-hop reasoning / retrieval-in-prompt</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td>22% accuracy (11/50 overall; baseline reported in Table 2)</td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoffs_reported</strong></td>
                            <td>Paper notes prompt-based approach can hit context window limits and suffers from error accumulation and arithmetic mistakes on multi-hop reasoning; no runtime/latency trade-offs measured.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Struggles on hard multi-hop questions with precise calculations; exhibits sequential calculation errors and misses returned transactions; performance degrades when token length exceeds model context window (motivating external memory).</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'ChatDB: Augmenting LLMs with Databases as Their Symbolic Memory', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6620.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e6620.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents that employ a memory mechanism to solve tasks, including details of the memory type, how it is accessed or updated, the tasks/benchmarks evaluated, performance with and without the memory, and any reported trade‑offs or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RMT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Recurrent Memory Transformer (RMT)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A transformer variant that introduces additional memory tokens/memory matrices to store and exchange local and global information across segments of long sequences.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Recurrent memory transformer</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Recurrent Memory Transformer (RMT)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Augments transformer with extra memory tokens/memory matrices that are passed between segments to store longer-range context; memory operations are controlled by the neural network (non-symbolic).</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>unspecified in this paper</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>matrix-based neural memory (memory tokens / memory matrices)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_representation</strong></td>
                            <td>trainable memory tokens or matrices (continuous vectors)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_access_mechanism</strong></td>
                            <td>attention and learned neural updates across segments; the model controls read/write via gradient-trained mechanisms (non-symbolic operations)</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_category</strong></td>
                            <td>long-context modeling / memory-augmented sequence processing</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoffs_reported</strong></td>
                            <td>Paper (this work) contrasts matrix-based memories as semi-structured, non-symbolic, lower interpretability; RMT tracks state but operations are implicit and potentially harder to inspect.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Described as having low interpretability compared to symbolic DBs; neural memory operations can be approximate and may accumulate errors for complex symbolic manipulation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Bulatov, A., Kuratov, Y., and Burtsev, M. (2022). Recurrent memory transformer.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'ChatDB: Augmenting LLMs with Databases as Their Symbolic Memory', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6620.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e6620.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents that employ a memory mechanism to solve tasks, including details of the memory type, how it is accessed or updated, the tasks/benchmarks evaluated, performance with and without the memory, and any reported trade‑offs or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Retrieval-augmented (Khattab et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Demonstrate-Search-Predict / Retrieval-augmented in-context learning</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Retrieval-augmented approaches use a retrieval model to fetch relevant past interactions or documents which are inserted into the prompt as context for the LLM.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Retrieval-augmented in-context retrieval (e.g., Demonstrate-Search-Predict)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>A retrieval model selects relevant past content (documents or stored prompts/embeddings) which is then included in the LLM prompt to aid generation; memory stored as text and/or vector embeddings and accessed via similarity search.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>unspecified</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>prompt-based memory / external vector store (retrieval-augmented generation)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_representation</strong></td>
                            <td>raw text snippets and/or vector embeddings derived from past interactions</td>
                        </tr>
                        <tr>
                            <td><strong>memory_access_mechanism</strong></td>
                            <td>similarity search over embeddings; retrieved items are concatenated into model prompt (non-symbolic selection mechanism)</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_category</strong></td>
                            <td>knowledge-intensive QA / long-context retrieval</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoffs_reported</strong></td>
                            <td>Characterized as semi-structured, non-symbolic execution; limited support for updates/deletes compared to DBs; interpretability is lower than symbolic DBs.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Paper notes retrieval-based methods can be prone to retrieval errors and inaccuracies in downstream reasoning (approximate similarity-based retrieval leading to accumulation of errors in multi-hop tasks).</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Khattab, O., Santhanam, K., Li, X. L., Hall, D., Liang, P., Potts, C., and Zaharia, M. (2022). Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'ChatDB: Augmenting LLMs with Databases as Their Symbolic Memory', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6620.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e6620.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents that employ a memory mechanism to solve tasks, including details of the memory type, how it is accessed or updated, the tasks/benchmarks evaluated, performance with and without the memory, and any reported trade‑offs or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Neural Turing Machines</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Neural Turing Machines (NTM)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A neural model combining an RNN controller with an external differentiable memory, trained end-to-end to learn read/write operations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Neural turing machines</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Neural Turing Machine (NTM)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>RNN-based controller with external trainable memory resources; learns to interact with memory via differentiable read/write heads trained by gradient descent.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>unspecified</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>differentiable neural memory (trainable memory matrix)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_representation</strong></td>
                            <td>continuous key/value-like memory matrices (vectors)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_access_mechanism</strong></td>
                            <td>learned attention-like read/write heads (differentiable addressing), trained end-to-end</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_category</strong></td>
                            <td>algorithmic tasks / sequence processing / memory-augmented learning</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoffs_reported</strong></td>
                            <td>Mentioned as a neural memory approach that can manipulate memory but is non-symbolic and may be approximate; interpretability and precise symbolic operations limited compared to DB approach.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Described generally as having non-symbolic, approximate operations that can accumulate errors for complex symbolic reasoning tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Graves, A., Wayne, G., and Danihelka, I. (2014). Neural turing machines.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'ChatDB: Augmenting LLMs with Databases as Their Symbolic Memory', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6620.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e6620.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents that employ a memory mechanism to solve tasks, including details of the memory type, how it is accessed or updated, the tasks/benchmarks evaluated, performance with and without the memory, and any reported trade‑offs or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Auto-GPT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Auto-GPT (tool-using agent / autonomous agent)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An autonomous tool-using agent that chains LLM prompts and external tools (e.g., search) and keeps a memory module storing text prompts directly to track history.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Auto-GPT (tool-using LLM agent)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Agent framework that uses LLMs to call external tools and stores past and current prompts in a memory module (text-based), which can be re-inserted into prompts; memory is prompt-based and stored as text.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>unspecified</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>prompt-based textual memory (semi-structured text store)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_representation</strong></td>
                            <td>raw text prompts and possibly vector embeddings derived from those prompts</td>
                        </tr>
                        <tr>
                            <td><strong>memory_access_mechanism</strong></td>
                            <td>stores past prompts and re-inserts or retrieves them when needed (retrieval may be via heuristic or similarity), non-symbolic execution</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_category</strong></td>
                            <td>tool-use / autonomous multi-step tasks</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoffs_reported</strong></td>
                            <td>Described as prompt-based memory lacking explicit state-tracking and structured update/delete semantics of DBs; prone to poor scaling as prompts grow.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Paper notes prompt-based memory does not clearly track current state (only records history) and may not support precise updates/deletes like symbolic DBs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'ChatDB: Augmenting LLMs with Databases as Their Symbolic Memory', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6620.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e6620.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents that employ a memory mechanism to solve tasks, including details of the memory type, how it is accessed or updated, the tasks/benchmarks evaluated, performance with and without the memory, and any reported trade‑offs or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Generative Agents</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Generative Agents: Interactive simulacra of human behavior</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A system of generative agents that uses memory to store and retrieve past interactions to simulate persistent agent behavior over time.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Generative agents: Interactive simulacra of human behavior</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Generative Agents (Park et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Agents use a memory module to store textual memories of past events and retrieve relevant memories to guide future actions; a retrieval mechanism selects memories to include in prompts.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>unspecified</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>prompt-based memory / text memory with retrieval</td>
                        </tr>
                        <tr>
                            <td><strong>memory_representation</strong></td>
                            <td>textual event memories and embeddings derived for retrieval</td>
                        </tr>
                        <tr>
                            <td><strong>memory_access_mechanism</strong></td>
                            <td>retrieval based on relevance; retrieved memories provided as context to the LLM when generating behavior/actions</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_category</strong></td>
                            <td>long-term agent simulation / dialogue and behavior simulation</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoffs_reported</strong></td>
                            <td>Mentioned as storing text prompts directly; lacks structured symbolic update semantics; used for persistent agent behavior rather than precise numeric multi-hop reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Paper implies shortcomings for tasks requiring exact numeric/state updates and complex multi-table manipulations compared to symbolic DB memory.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Park, J. S., O’Brien, J. C., Cai, C. J., Morris, M. R., Liang, P., and Bernstein, M. S. (2023). Generative agents: Interactive simulacra of human behavior.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'ChatDB: Augmenting LLMs with Databases as Their Symbolic Memory', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6620.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e6620.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents that employ a memory mechanism to solve tasks, including details of the memory type, how it is accessed or updated, the tasks/benchmarks evaluated, performance with and without the memory, and any reported trade‑offs or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Toolformer</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Toolformer: Language models can teach themselves to use tools</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A method to teach LMs to call external APIs/tools by demonstrating tool use in prompts so that models learn when and how to invoke tools.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Toolformer: Language models can teach themselves to use tools</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Toolformer (tool-using LLM)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Approach trains or demonstrates to the LLM that it can invoke external tools/APIs (e.g., calculators, search) to solve tasks; memory aspects are via external tools rather than dedicated structured DB memory.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>unspecified</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>external tool invocation (not a dedicated memory store)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_representation</strong></td>
                            <td>tool outputs (could be text or structured) returned to the model</td>
                        </tr>
                        <tr>
                            <td><strong>memory_access_mechanism</strong></td>
                            <td>model-initiated API/tool calls guided by prompt demonstrations; tool outputs inserted into prompt context</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_category</strong></td>
                            <td>tool-augmented generation / API use</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoffs_reported</strong></td>
                            <td>Paper referenced as tool-using approach; ChatDB positioned as a tool-using instance where DB acts as a tool enabling symbolic operations.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Tool invocation correctness depends on the model's decision to call tools and the tool responses; not directly targeted at structured stateful memory management like DBs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Schick, T., Dwivedi-Yu, J., Dessì, R., Raileanu, R., Lomeli, M., Zettlemoyer, L., Cancedda, N., and Scialom, T. (2023). Toolformer: Language models can teach themselves to use tools.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'ChatDB: Augmenting LLMs with Databases as Their Symbolic Memory', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6620.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e6620.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents that employ a memory mechanism to solve tasks, including details of the memory type, how it is accessed or updated, the tasks/benchmarks evaluated, performance with and without the memory, and any reported trade‑offs or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SQL-PaLM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>SQL-PaLM (Text-to-SQL with LLMs)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An LLM-based Text-to-SQL approach that uses execution-based self-consistent prompting to generate SQL and improve accuracy on Text-to-SQL tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Sql-palm: Improved large language modeladaptation for text-to-sql</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>SQL-PaLM (Text-to-SQL approach)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Uses LLMs to translate natural language to SQL, leveraging execution feedback and prompting techniques to improve SQL generation quality; related to ChatDB's use of LLM-generated SQL for DB manipulation.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>unspecified</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>symbolic SQL execution (external DB used as target of generated SQL)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_representation</strong></td>
                            <td>structured relational database targeted by generated SQL</td>
                        </tr>
                        <tr>
                            <td><strong>memory_access_mechanism</strong></td>
                            <td>LLM generates SQL which is executed; execution feedback can be used to refine SQL (execution-based prompting)</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_category</strong></td>
                            <td>Text-to-SQL / semantic parsing / SQL execution</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoffs_reported</strong></td>
                            <td>Cited as evidence LLMs can generate executable SQL; ChatDB builds on this capability to treat DB as memory.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Not evaluated in this paper; referenced as prior art enabling LLM->SQL generation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Sun, R., Arik, S. O., Nakhost, H., Dai, H., Sinha, R., Yin, P., and Pfister, T. (2023). Sql-palm: Improved large language modeladaptation for text-to-sql.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'ChatDB: Augmenting LLMs with Databases as Their Symbolic Memory', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6620.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e6620.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents that employ a memory mechanism to solve tasks, including details of the memory type, how it is accessed or updated, the tasks/benchmarks evaluated, performance with and without the memory, and any reported trade‑offs or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BINDER</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>BINDER: Binding language models in symbolic languages</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Framework that maps task inputs to executable programs in a programming language bound with an API to call LLMs for various functionalities.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Binding language models in symbolic languages</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>BINDER</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Maps inputs to executable programs (e.g., Python) and binds them to APIs; demonstrates LLMs can be orchestrated to produce symbolic programmatic interactions with stateful systems (related to using DBs as tools/memory).</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>unspecified</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>symbolic program execution / external toolbinding (not necessarily a DB)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_representation</strong></td>
                            <td>program state or external storage manipulated by generated programs</td>
                        </tr>
                        <tr>
                            <td><strong>memory_access_mechanism</strong></td>
                            <td>LLM-generated program execution to interact with external APIs or storage</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_category</strong></td>
                            <td>program synthesis / tool-augmented execution</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoffs_reported</strong></td>
                            <td>Highlighted as a precedent for treating symbolic execution as a tool for LLMs; ChatDB differs by treating DB specifically as symbolic memory.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Not evaluated here; mentioned as related work enabling symbolic execution by LLMs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Cheng, Z., Xie, T., Shi, P., Li, C., Nadkarni, R., Hu, Y., Xiong, C., Radev, D., Ostendorf, M., Zettlemoyer, L., et al. (2022). Binding language models in symbolic languages.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'ChatDB: Augmenting LLMs with Databases as Their Symbolic Memory', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6620.10">
                <h3 class="extraction-instance">Extracted Data Instance 10 (e6620.10)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents that employ a memory mechanism to solve tasks, including details of the memory type, how it is accessed or updated, the tasks/benchmarks evaluated, performance with and without the memory, and any reported trade‑offs or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ChatExcel</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ChatExcel (LLM-generated spreadsheet commands)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A system where LLMs generate Excel execution commands to manipulate spreadsheet data as a form of external stateful tool use.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>ChatExcel</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Uses LLMs to produce spreadsheet/Excel commands to perform data operations; conceptually similar to using DBs as symbolic memory but targeted at spreadsheets.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>unspecified</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>symbolic spreadsheet (Excel) as external memory/tool</td>
                        </tr>
                        <tr>
                            <td><strong>memory_representation</strong></td>
                            <td>structured cells/tables in a spreadsheet</td>
                        </tr>
                        <tr>
                            <td><strong>memory_access_mechanism</strong></td>
                            <td>LLM emits spreadsheet commands which are executed in the spreadsheet environment; outputs returned to model/user</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_category</strong></td>
                            <td>spreadsheet manipulation / tool-augmented interaction</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoffs_reported</strong></td>
                            <td>Mentioned as a prior example of LLM -> executable structured operations (Excel) similar to ChatDB's LLM -> SQL approach.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'ChatDB: Augmenting LLMs with Databases as Their Symbolic Memory', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Recurrent memory transformer <em>(Rating: 2)</em></li>
                <li>Neural turing machines <em>(Rating: 2)</em></li>
                <li>Generative agents: Interactive simulacra of human behavior <em>(Rating: 2)</em></li>
                <li>Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp <em>(Rating: 2)</em></li>
                <li>Toolformer: Language models can teach themselves to use tools <em>(Rating: 2)</em></li>
                <li>Binding language models in symbolic languages <em>(Rating: 2)</em></li>
                <li>Sql-palm: Improved large language modeladaptation for text-to-sql <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-6620",
    "paper_id": "paper-50f44ef10335d59cec145b15effae20ff22c1fdb",
    "extraction_schema_id": "extraction-schema-127",
    "extracted_data": [
        {
            "name_short": "ChatDB",
            "name_full": "ChatDB: Augmenting LLMs with Databases as Their SYMBOLIC MEMORY",
            "brief_description": "A framework that augments an LLM controller with an external symbolic memory implemented as SQL databases; the LLM generates SQL to read/write the database and uses a chain-of-memory (CoM) multi-step decomposition to perform complex, multi-hop reasoning and precise calculations.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "ChatDB (LLM + MySQL symbolic memory)",
            "agent_description": "An LLM controller (used: ChatGPT GPT-3.5 Turbo) generates sequences of intermediate memory-operation steps (SQL statements) which are executed against an external relational database (MySQL). The system iteratively updates operations based on prior SQL results (chain-of-memory) and summarizes final replies based on executed SQL results.",
            "model_size": "unspecified (GPT-3.5 Turbo used as the LLM controller)",
            "memory_used": true,
            "memory_type": "symbolic external database (relational SQL database - MySQL)",
            "memory_representation": "Structured relational tables (rows/columns) with explicit schema, primary/foreign keys, and typed fields (e.g., sales, customers, fruits, sale_items).",
            "memory_access_mechanism": "LLM generates SQL (INSERT/UPDATE/SELECT/DELETE) which is executed on the DB; query results are returned to the LLM; the LLM may update subsequent SQL steps based on previous SQLResults (iterative chain-of-memory control flow).",
            "task_name": "Fruit Shop Dataset (synthetic fruit shop record management and question answering)",
            "task_category": "multi-hop reasoning / data management / retrieval & calculation",
            "performance_with_memory": "82% accuracy (41/50 overall); Easy: 13/15; Hard: 28/35 (Accuracy reported in Table 2)",
            "performance_without_memory": "22% accuracy (11/50 overall) when using ChatGPT baseline that ingested records directly in prompt (no external DB memory); Easy: 10/15; Hard: 1/35",
            "has_comparative_results": true,
            "performance_metric": "Accuracy (counts and percentage over 50 questions)",
            "tradeoffs_reported": "Paper emphasizes benefits: precise calculations, no error accumulation from symbolic execution, high interpretability, explicit state tracking and rollback capability. Paper contrasts with neural/vector memories being approximate and error-prone. The paper does not present measured latency, memory-footprint, or throughput benchmarks for the DB-based approach; potential practical trade-offs (e.g., IO/API latency, DB scaling) are discussed qualitatively but not quantified.",
            "limitations_or_failure_cases": "Evaluations are on a synthetic fruit-shop dataset; authors note schema creation may be manual or LLM-assisted (dependency on correct schema). The paper does not report explicit failure cases of ChatDB in experiments; potential limitations include dependence on correct SQL generation by the LLM and that results are validated only on the synthetic management setting (generalization to other domains not empirically shown).",
            "citation": "Chenxu Hu, Jie Fu, Chenzhuang Du, Simian Luo, Junbo Zhao, Hang Zhao. ChatDB: Augmenting LLMs with Databases as Their SYMBOLIC MEMORY.",
            "uuid": "e6620.0",
            "source_info": {
                "paper_title": "ChatDB: Augmenting LLMs with Databases as Their Symbolic Memory",
                "publication_date_yy_mm": "2023-06"
            }
        },
        {
            "name_short": "ChatGPT (baseline)",
            "name_full": "ChatGPT (GPT-3.5 Turbo) baseline used in experiments",
            "brief_description": "Off-the-shelf LLM used as a baseline which consumes the entire record history as part of the prompt (no external symbolic database); produces answers directly from prompt context.",
            "citation_title": "",
            "mention_or_use": "use",
            "agent_name": "ChatGPT (GPT-3.5 Turbo)",
            "agent_description": "Standard in-context prompting where the dataset records are concatenated into the model prompt and the model answers questions directly; no external symbolic memory is used in the baseline experiment (records are part of the prompt).",
            "model_size": "unspecified (GPT-3.5 Turbo)",
            "memory_used": false,
            "memory_type": "none (prompt-only; implicitly uses the model context window)",
            "memory_representation": "raw text prompt (concatenated records within context window)",
            "memory_access_mechanism": "direct attention over prompt tokens within the model's context window; no external read/write API to a memory store.",
            "task_name": "Fruit Shop Dataset (synthetic)",
            "task_category": "multi-hop reasoning / retrieval-in-prompt",
            "performance_with_memory": null,
            "performance_without_memory": "22% accuracy (11/50 overall; baseline reported in Table 2)",
            "has_comparative_results": true,
            "performance_metric": "Accuracy",
            "tradeoffs_reported": "Paper notes prompt-based approach can hit context window limits and suffers from error accumulation and arithmetic mistakes on multi-hop reasoning; no runtime/latency trade-offs measured.",
            "limitations_or_failure_cases": "Struggles on hard multi-hop questions with precise calculations; exhibits sequential calculation errors and misses returned transactions; performance degrades when token length exceeds model context window (motivating external memory).",
            "citation": "",
            "uuid": "e6620.1",
            "source_info": {
                "paper_title": "ChatDB: Augmenting LLMs with Databases as Their Symbolic Memory",
                "publication_date_yy_mm": "2023-06"
            }
        },
        {
            "name_short": "RMT",
            "name_full": "Recurrent Memory Transformer (RMT)",
            "brief_description": "A transformer variant that introduces additional memory tokens/memory matrices to store and exchange local and global information across segments of long sequences.",
            "citation_title": "Recurrent memory transformer",
            "mention_or_use": "mention",
            "agent_name": "Recurrent Memory Transformer (RMT)",
            "agent_description": "Augments transformer with extra memory tokens/memory matrices that are passed between segments to store longer-range context; memory operations are controlled by the neural network (non-symbolic).",
            "model_size": "unspecified in this paper",
            "memory_used": true,
            "memory_type": "matrix-based neural memory (memory tokens / memory matrices)",
            "memory_representation": "trainable memory tokens or matrices (continuous vectors)",
            "memory_access_mechanism": "attention and learned neural updates across segments; the model controls read/write via gradient-trained mechanisms (non-symbolic operations)",
            "task_name": null,
            "task_category": "long-context modeling / memory-augmented sequence processing",
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_comparative_results": false,
            "performance_metric": null,
            "tradeoffs_reported": "Paper (this work) contrasts matrix-based memories as semi-structured, non-symbolic, lower interpretability; RMT tracks state but operations are implicit and potentially harder to inspect.",
            "limitations_or_failure_cases": "Described as having low interpretability compared to symbolic DBs; neural memory operations can be approximate and may accumulate errors for complex symbolic manipulation.",
            "citation": "Bulatov, A., Kuratov, Y., and Burtsev, M. (2022). Recurrent memory transformer.",
            "uuid": "e6620.2",
            "source_info": {
                "paper_title": "ChatDB: Augmenting LLMs with Databases as Their Symbolic Memory",
                "publication_date_yy_mm": "2023-06"
            }
        },
        {
            "name_short": "Retrieval-augmented (Khattab et al.)",
            "name_full": "Demonstrate-Search-Predict / Retrieval-augmented in-context learning",
            "brief_description": "Retrieval-augmented approaches use a retrieval model to fetch relevant past interactions or documents which are inserted into the prompt as context for the LLM.",
            "citation_title": "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp",
            "mention_or_use": "mention",
            "agent_name": "Retrieval-augmented in-context retrieval (e.g., Demonstrate-Search-Predict)",
            "agent_description": "A retrieval model selects relevant past content (documents or stored prompts/embeddings) which is then included in the LLM prompt to aid generation; memory stored as text and/or vector embeddings and accessed via similarity search.",
            "model_size": "unspecified",
            "memory_used": true,
            "memory_type": "prompt-based memory / external vector store (retrieval-augmented generation)",
            "memory_representation": "raw text snippets and/or vector embeddings derived from past interactions",
            "memory_access_mechanism": "similarity search over embeddings; retrieved items are concatenated into model prompt (non-symbolic selection mechanism)",
            "task_name": null,
            "task_category": "knowledge-intensive QA / long-context retrieval",
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_comparative_results": false,
            "performance_metric": null,
            "tradeoffs_reported": "Characterized as semi-structured, non-symbolic execution; limited support for updates/deletes compared to DBs; interpretability is lower than symbolic DBs.",
            "limitations_or_failure_cases": "Paper notes retrieval-based methods can be prone to retrieval errors and inaccuracies in downstream reasoning (approximate similarity-based retrieval leading to accumulation of errors in multi-hop tasks).",
            "citation": "Khattab, O., Santhanam, K., Li, X. L., Hall, D., Liang, P., Potts, C., and Zaharia, M. (2022). Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp.",
            "uuid": "e6620.3",
            "source_info": {
                "paper_title": "ChatDB: Augmenting LLMs with Databases as Their Symbolic Memory",
                "publication_date_yy_mm": "2023-06"
            }
        },
        {
            "name_short": "Neural Turing Machines",
            "name_full": "Neural Turing Machines (NTM)",
            "brief_description": "A neural model combining an RNN controller with an external differentiable memory, trained end-to-end to learn read/write operations.",
            "citation_title": "Neural turing machines",
            "mention_or_use": "mention",
            "agent_name": "Neural Turing Machine (NTM)",
            "agent_description": "RNN-based controller with external trainable memory resources; learns to interact with memory via differentiable read/write heads trained by gradient descent.",
            "model_size": "unspecified",
            "memory_used": true,
            "memory_type": "differentiable neural memory (trainable memory matrix)",
            "memory_representation": "continuous key/value-like memory matrices (vectors)",
            "memory_access_mechanism": "learned attention-like read/write heads (differentiable addressing), trained end-to-end",
            "task_name": null,
            "task_category": "algorithmic tasks / sequence processing / memory-augmented learning",
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_comparative_results": false,
            "performance_metric": null,
            "tradeoffs_reported": "Mentioned as a neural memory approach that can manipulate memory but is non-symbolic and may be approximate; interpretability and precise symbolic operations limited compared to DB approach.",
            "limitations_or_failure_cases": "Described generally as having non-symbolic, approximate operations that can accumulate errors for complex symbolic reasoning tasks.",
            "citation": "Graves, A., Wayne, G., and Danihelka, I. (2014). Neural turing machines.",
            "uuid": "e6620.4",
            "source_info": {
                "paper_title": "ChatDB: Augmenting LLMs with Databases as Their Symbolic Memory",
                "publication_date_yy_mm": "2023-06"
            }
        },
        {
            "name_short": "Auto-GPT",
            "name_full": "Auto-GPT (tool-using agent / autonomous agent)",
            "brief_description": "An autonomous tool-using agent that chains LLM prompts and external tools (e.g., search) and keeps a memory module storing text prompts directly to track history.",
            "citation_title": "",
            "mention_or_use": "mention",
            "agent_name": "Auto-GPT (tool-using LLM agent)",
            "agent_description": "Agent framework that uses LLMs to call external tools and stores past and current prompts in a memory module (text-based), which can be re-inserted into prompts; memory is prompt-based and stored as text.",
            "model_size": "unspecified",
            "memory_used": true,
            "memory_type": "prompt-based textual memory (semi-structured text store)",
            "memory_representation": "raw text prompts and possibly vector embeddings derived from those prompts",
            "memory_access_mechanism": "stores past prompts and re-inserts or retrieves them when needed (retrieval may be via heuristic or similarity), non-symbolic execution",
            "task_name": null,
            "task_category": "tool-use / autonomous multi-step tasks",
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_comparative_results": false,
            "performance_metric": null,
            "tradeoffs_reported": "Described as prompt-based memory lacking explicit state-tracking and structured update/delete semantics of DBs; prone to poor scaling as prompts grow.",
            "limitations_or_failure_cases": "Paper notes prompt-based memory does not clearly track current state (only records history) and may not support precise updates/deletes like symbolic DBs.",
            "citation": "",
            "uuid": "e6620.5",
            "source_info": {
                "paper_title": "ChatDB: Augmenting LLMs with Databases as Their Symbolic Memory",
                "publication_date_yy_mm": "2023-06"
            }
        },
        {
            "name_short": "Generative Agents",
            "name_full": "Generative Agents: Interactive simulacra of human behavior",
            "brief_description": "A system of generative agents that uses memory to store and retrieve past interactions to simulate persistent agent behavior over time.",
            "citation_title": "Generative agents: Interactive simulacra of human behavior",
            "mention_or_use": "mention",
            "agent_name": "Generative Agents (Park et al.)",
            "agent_description": "Agents use a memory module to store textual memories of past events and retrieve relevant memories to guide future actions; a retrieval mechanism selects memories to include in prompts.",
            "model_size": "unspecified",
            "memory_used": true,
            "memory_type": "prompt-based memory / text memory with retrieval",
            "memory_representation": "textual event memories and embeddings derived for retrieval",
            "memory_access_mechanism": "retrieval based on relevance; retrieved memories provided as context to the LLM when generating behavior/actions",
            "task_name": null,
            "task_category": "long-term agent simulation / dialogue and behavior simulation",
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_comparative_results": false,
            "performance_metric": null,
            "tradeoffs_reported": "Mentioned as storing text prompts directly; lacks structured symbolic update semantics; used for persistent agent behavior rather than precise numeric multi-hop reasoning.",
            "limitations_or_failure_cases": "Paper implies shortcomings for tasks requiring exact numeric/state updates and complex multi-table manipulations compared to symbolic DB memory.",
            "citation": "Park, J. S., O’Brien, J. C., Cai, C. J., Morris, M. R., Liang, P., and Bernstein, M. S. (2023). Generative agents: Interactive simulacra of human behavior.",
            "uuid": "e6620.6",
            "source_info": {
                "paper_title": "ChatDB: Augmenting LLMs with Databases as Their Symbolic Memory",
                "publication_date_yy_mm": "2023-06"
            }
        },
        {
            "name_short": "Toolformer",
            "name_full": "Toolformer: Language models can teach themselves to use tools",
            "brief_description": "A method to teach LMs to call external APIs/tools by demonstrating tool use in prompts so that models learn when and how to invoke tools.",
            "citation_title": "Toolformer: Language models can teach themselves to use tools",
            "mention_or_use": "mention",
            "agent_name": "Toolformer (tool-using LLM)",
            "agent_description": "Approach trains or demonstrates to the LLM that it can invoke external tools/APIs (e.g., calculators, search) to solve tasks; memory aspects are via external tools rather than dedicated structured DB memory.",
            "model_size": "unspecified",
            "memory_used": false,
            "memory_type": "external tool invocation (not a dedicated memory store)",
            "memory_representation": "tool outputs (could be text or structured) returned to the model",
            "memory_access_mechanism": "model-initiated API/tool calls guided by prompt demonstrations; tool outputs inserted into prompt context",
            "task_name": null,
            "task_category": "tool-augmented generation / API use",
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_comparative_results": false,
            "performance_metric": null,
            "tradeoffs_reported": "Paper referenced as tool-using approach; ChatDB positioned as a tool-using instance where DB acts as a tool enabling symbolic operations.",
            "limitations_or_failure_cases": "Tool invocation correctness depends on the model's decision to call tools and the tool responses; not directly targeted at structured stateful memory management like DBs.",
            "citation": "Schick, T., Dwivedi-Yu, J., Dessì, R., Raileanu, R., Lomeli, M., Zettlemoyer, L., Cancedda, N., and Scialom, T. (2023). Toolformer: Language models can teach themselves to use tools.",
            "uuid": "e6620.7",
            "source_info": {
                "paper_title": "ChatDB: Augmenting LLMs with Databases as Their Symbolic Memory",
                "publication_date_yy_mm": "2023-06"
            }
        },
        {
            "name_short": "SQL-PaLM",
            "name_full": "SQL-PaLM (Text-to-SQL with LLMs)",
            "brief_description": "An LLM-based Text-to-SQL approach that uses execution-based self-consistent prompting to generate SQL and improve accuracy on Text-to-SQL tasks.",
            "citation_title": "Sql-palm: Improved large language modeladaptation for text-to-sql",
            "mention_or_use": "mention",
            "agent_name": "SQL-PaLM (Text-to-SQL approach)",
            "agent_description": "Uses LLMs to translate natural language to SQL, leveraging execution feedback and prompting techniques to improve SQL generation quality; related to ChatDB's use of LLM-generated SQL for DB manipulation.",
            "model_size": "unspecified",
            "memory_used": true,
            "memory_type": "symbolic SQL execution (external DB used as target of generated SQL)",
            "memory_representation": "structured relational database targeted by generated SQL",
            "memory_access_mechanism": "LLM generates SQL which is executed; execution feedback can be used to refine SQL (execution-based prompting)",
            "task_name": null,
            "task_category": "Text-to-SQL / semantic parsing / SQL execution",
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_comparative_results": false,
            "performance_metric": null,
            "tradeoffs_reported": "Cited as evidence LLMs can generate executable SQL; ChatDB builds on this capability to treat DB as memory.",
            "limitations_or_failure_cases": "Not evaluated in this paper; referenced as prior art enabling LLM-&gt;SQL generation.",
            "citation": "Sun, R., Arik, S. O., Nakhost, H., Dai, H., Sinha, R., Yin, P., and Pfister, T. (2023). Sql-palm: Improved large language modeladaptation for text-to-sql.",
            "uuid": "e6620.8",
            "source_info": {
                "paper_title": "ChatDB: Augmenting LLMs with Databases as Their Symbolic Memory",
                "publication_date_yy_mm": "2023-06"
            }
        },
        {
            "name_short": "BINDER",
            "name_full": "BINDER: Binding language models in symbolic languages",
            "brief_description": "Framework that maps task inputs to executable programs in a programming language bound with an API to call LLMs for various functionalities.",
            "citation_title": "Binding language models in symbolic languages",
            "mention_or_use": "mention",
            "agent_name": "BINDER",
            "agent_description": "Maps inputs to executable programs (e.g., Python) and binds them to APIs; demonstrates LLMs can be orchestrated to produce symbolic programmatic interactions with stateful systems (related to using DBs as tools/memory).",
            "model_size": "unspecified",
            "memory_used": true,
            "memory_type": "symbolic program execution / external toolbinding (not necessarily a DB)",
            "memory_representation": "program state or external storage manipulated by generated programs",
            "memory_access_mechanism": "LLM-generated program execution to interact with external APIs or storage",
            "task_name": null,
            "task_category": "program synthesis / tool-augmented execution",
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_comparative_results": false,
            "performance_metric": null,
            "tradeoffs_reported": "Highlighted as a precedent for treating symbolic execution as a tool for LLMs; ChatDB differs by treating DB specifically as symbolic memory.",
            "limitations_or_failure_cases": "Not evaluated here; mentioned as related work enabling symbolic execution by LLMs.",
            "citation": "Cheng, Z., Xie, T., Shi, P., Li, C., Nadkarni, R., Hu, Y., Xiong, C., Radev, D., Ostendorf, M., Zettlemoyer, L., et al. (2022). Binding language models in symbolic languages.",
            "uuid": "e6620.9",
            "source_info": {
                "paper_title": "ChatDB: Augmenting LLMs with Databases as Their Symbolic Memory",
                "publication_date_yy_mm": "2023-06"
            }
        },
        {
            "name_short": "ChatExcel",
            "name_full": "ChatExcel (LLM-generated spreadsheet commands)",
            "brief_description": "A system where LLMs generate Excel execution commands to manipulate spreadsheet data as a form of external stateful tool use.",
            "citation_title": "",
            "mention_or_use": "mention",
            "agent_name": "ChatExcel",
            "agent_description": "Uses LLMs to produce spreadsheet/Excel commands to perform data operations; conceptually similar to using DBs as symbolic memory but targeted at spreadsheets.",
            "model_size": "unspecified",
            "memory_used": true,
            "memory_type": "symbolic spreadsheet (Excel) as external memory/tool",
            "memory_representation": "structured cells/tables in a spreadsheet",
            "memory_access_mechanism": "LLM emits spreadsheet commands which are executed in the spreadsheet environment; outputs returned to model/user",
            "task_name": null,
            "task_category": "spreadsheet manipulation / tool-augmented interaction",
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_comparative_results": false,
            "performance_metric": null,
            "tradeoffs_reported": "Mentioned as a prior example of LLM -&gt; executable structured operations (Excel) similar to ChatDB's LLM -&gt; SQL approach.",
            "limitations_or_failure_cases": "",
            "citation": "",
            "uuid": "e6620.10",
            "source_info": {
                "paper_title": "ChatDB: Augmenting LLMs with Databases as Their Symbolic Memory",
                "publication_date_yy_mm": "2023-06"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Recurrent memory transformer",
            "rating": 2
        },
        {
            "paper_title": "Neural turing machines",
            "rating": 2
        },
        {
            "paper_title": "Generative agents: Interactive simulacra of human behavior",
            "rating": 2
        },
        {
            "paper_title": "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp",
            "rating": 2
        },
        {
            "paper_title": "Toolformer: Language models can teach themselves to use tools",
            "rating": 2
        },
        {
            "paper_title": "Binding language models in symbolic languages",
            "rating": 2
        },
        {
            "paper_title": "Sql-palm: Improved large language modeladaptation for text-to-sql",
            "rating": 2
        }
    ],
    "cost": 0.018140499999999997,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>ChatDB: Augmenting LLMs with Databases as Their SYMBOLIC MEMORY</h1>
<p>Chenxu Hu ${ }^{1 *}$ Jie Fu ${ }^{2 * \dagger}$ Chenzhuang Du ${ }^{1}$ Simian Luo ${ }^{1}$ Junbo Zhao ${ }^{3}$ Hang Zhao ${ }^{1 \dagger}$<br>${ }^{1}$ Tsinghua University ${ }^{2}$ Beijing Academy of Artificial Intelligence ${ }^{3}$ Zhejiang University<br>fujie@baai.ac.cn hangzhao@mail.tsinghua.edu.cn</p>
<h4>Abstract</h4>
<p>Large language models (LLMs) with memory are computationally universal (Schuurmans, 2023). However, mainstream LLMs are not taking full advantage of memory, and the designs are heavily influenced by biological brains. Due to their approximate nature and proneness to the accumulation of errors, conventional neural memory mechanisms cannot support LLMs to simulate complex reasoning. In this paper, we seek inspiration from modern computer architectures to augment LLMs with symbolic memory for complex multi-hop reasoning. Such a symbolic memory framework is instantiated as an LLM and a set of SQL databases, where the LLM generates SQL instructions to manipulate the SQL databases. We validate the effectiveness of the proposed memory framework on a synthetic dataset requiring complex reasoning. The project website is available at https: //chatdatabase.github.io/.</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: Overall workflow of ChatDB. The LLM controller controls the read and write operations to the memory. The memory stores historical information and provides relevant historical information to assist in responding to user input. In ChatDB, we focus on augmenting LLMs with databases as their symbolic memory.</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>1 Introduction</p>
<p>Large language models (LLMs), such as GPT-4 <em>(OpenAI, 2023)</em> and PaLM 2 <em>(Anil et al., 2023)</em>, have increasingly become an essential component of modern artificial intelligence (AI) systems, revolutionizing our understanding of natural language processing (NLP) and transforming various industries <em>(Hao et al., 2023; Wang et al., 2023)</em>. While LLMs have made significant strides in understanding and generating contextually relevant responses, they have limitations <em>(Chen et al., 2023)</em>. One of the main challenges is that multi-turn interactions with language models generate a large number of tokens, which can easily exceed the input token limit of LLMs. For example, GPT-4 (32K) can only handle 32,000 tokens. As the interaction progresses, the LLMs must maintain contextual information (e.g., user inputs, and previous responses) and generate responses based on the accumulated data. Simply concatenating all contextual information and cramming it into LLMs, however, can easily exceed the processing capabilities of LLMs and accumulate errors, causing the model to lose track of the conversation and produce less accurate responses.</p>
<p>Some neural memory mechanisms have been explored <em>(Wu et al., 2022a; Khattab et al., 2022; Zhong et al., 2022)</em> to overcome the limited token input issue of LLMs. The memory components serve as a storage and retrieval system for relevant information from previous interactions. However, augmenting LLMs with conventional neural memory usually leads to difficulties in storing, retrieving, and manipulating historical information in memory, especially for tasks requiring complex multi-hop reasoning. Two main causes are (a) They do not store historical information in a structured form; (b) Their manipulation of the information stored in memory is not symbolic, as they all rely on some vector similarity calculations, which can be inaccurate, thus leading to the accumulation of errors.</p>
<p>To address the aforementioned issues, we propose using databases as novel symbolic memory for LLMs. The whole framework is named ChatDB. As shown in Figure 1, ChatDB consists of two components: an LLM controller and its memory. The LLM controller can be any commonly used LLM <em>(OpenAI, 2023; Touvron et al., 2023; Du et al., 2022; Zeng et al., 2022)</em> and is responsible for controlling the read and write operations to the memory. The memory of LLMs, which can be symbolic or non-symbolic, or a combination of both, is responsible for storing historical information and providing information when needed to assist the LLM in responding to user input. In ChatDB, we focus on using databases as symbolic memory, which allows for the structured storage of historical information through the execution of a symbolic language, namely SQL statements. These SQL statements are generated by an LLM. Incorporating a database as symbolic memory is particularly useful in scenarios requiring precise recording, modification, querying, deletion, and analysis of historical data. For example, a store manager needs to maintain daily sales records, where using plain text or matrices as memory is unsuitable <em>(Chen et al., 2023)</em>. However, using a database as external symbolic memory is highly suitable. The database enables accurate operations, including data insertion, deletion, update, and selection, using SQL statements. Thus, employing databases as external symbolic memory ensures precision and efficiency in managing and manipulating historical data, significantly enhancing the performance of LLMs in scenarios that require high accuracy and long-term data recording and processing.</p>
<p>In the ChatDB framework, we propose the chain-of-memory (CoM) approach to manipulate the external symbolic memory more effectively, thereby further enhancing the reasoning capabilities of LLMs. The chain-of-memory approach transforms user input into a series of intermediate memory operation steps that lead to final results. Through the chain-of-memory approach, a complex problem is decomposed into multiple steps of memory operations, significantly reducing the complexity of problem-solving. In ChatDB, each intermediate step involves one or more SQL statements.</p>
<p>Our ChatDB makes several contributions to the field of LLMs. Firstly, we propose augmenting LLMs with databases as their external symbolic memory, allowing for structured storage of historical data and enabling symbolic and complex data operations using SQL statements. Secondly, our chain-of-memory approach enables effective memory manipulation by converting user input into multi-step intermediate memory operations, which enhance the performance of ChatDB, enabling it to handle complex, multi-table database interactions with improved accuracy and stability. Finally, our experiments demonstrate that augmenting LLMs with symbolic memory improves multi-hop reasoning capabilities and prevents error accumulation, thereby enabling ChatDB to significantly outperform ChatGPT on a synthetic dataset.</p>
<h2>2 Related Work</h2>
<p>Memory-Augmented Large Language Models (LLMs). LLMs, such as GPT-4 <em>(OpenAI, 2023)</em> and PaLM 2 <em>(Anil et al., 2023)</em>, have demonstrated powerful reasoning and decision-making abilities. However, LLMs are often hindered by their limited context window sizes (e.g., GPT-4 can only handle 32K tokens). Memory-augmented LLMs <em>(Wu et al., 2022a, b; Zhong et al., 2022; Lewis et al., 2020; Guu et al., 2020; Park et al., 2023; Khattab et al., 2022; Izacard et al., 2022)</em> incorporate a memory module that prevents the model from forgetting crucial information and allows it to handle long text inputs that exceed the context window size. Retrieval-augmented in-context learning <em>(Khattab et al., 2022)</em></p>
<p>uses retrieval models (RM) to retrieve relevant information that can be inserted into the LLM as a prompt. For example, Auto-GPT ${ }^{3}$ and Generative Agents (Park et al., 2023) utilize a memory module to store the text prompt directly, allowing the agent to keep track of its history. The past and current prompts are then input into the LLM for processing. Neural Turing Machines (NMT) (Graves et al., 2014), which incorporate the recurrent neural network (RNN) with external trainable memory resources and learn to interact with the memory module with gradient descent. Gated Graph Sequence Neural Network (GGS-NN) (Johnson, 2017) constructs and modifies graphs and utilizes the graphs to produce reasonable outputs. Recurrent Memory Transformer (RMT) (Bulatov et al., 2022) introduces additional memory tokens to the input and output sequences to store, process and exchange local and global information between segments of long sequences, and then train the model to control both memory operation and sequence representations processing.
Reasoning with LLMs. LLMs are known to struggle in complex reasoning tasks. Previous methods focus on incorporating specially designed supervisory signals or fine-tuning to enhance the reasoning ability of language models (Piękos et al., 2021; Ran et al., 2019; Andor et al., 2019; Cobbe et al., 2021; Chen et al., 2022). Recent methods mainly improve the reasoning ability of language models through In-Context Learning (Brown et al., 2020; Lester et al., 2021; Wei et al., 2021, 2022; Wang et al., 2022). The most representative of these is Chain-of-Thought (CoT) (Wei et al., 2022), which presents the intermediate reasoning process of solving sample problems to the language model, greatly enhancing its reasoning capabilities.
LLMs with DBs. LLMs have demonstrated an impressive capability in generating code, including Python code, execution commands for Excel, and Structured Query Language (SQL) for databases (OpenAI, 2023). ChatExcel ${ }^{4}$ uses LLMs to generate the Excel execution command, simplifying the user interaction process. BINDER (Cheng et al., 2022) proposes a framework that maps task inputs to executable programs in a programming language (e.g., Python code) bound with an API to call LLMs to perform a wide range of functionalities. SQL-PALM (Sun et al., 2023) proposes an LLM-based Text-to-SQL model, using the execution-based self-consistent prompting approach, and outperforms previous Text-2-SQL methods by a large margin. While previous works involve databases to some extent, our proposed ChatDB system differs significantly from these methods. In specific, ChatDB views the databases as the external symbolic memory module for the LLM, and then leverages the database for reading and writing essential data information to enhance the reasoning process via chain-of-memory, leading to more accurate reasoning results.
Tool-using LLMs. From the tool-using perspective, ChatDB can also be seen as an LLM utilizing DBs as a tool (Schick et al., 2023; Shen et al., 2023; Surís et al., 2023; Paranjape et al., 2023). Toolformer (Schick et al., 2023), through a series of demonstrations, instructs the language model that it can invoke some APIs to utilize external tools to solve the current problem. Another representative work is Auto-GPT ${ }^{5}$, which enables the language models to complete a series of impressive tasks using a search engine. The advantage of ChatDB, which uses a database as an external tool, is that it allows the language model to maintain more accurate records and use historical data, thereby addressing more complex problems, especially those that require accurate historical data for reasoning.</p>
<h1>3 ChatDB</h1>
<p>In this section, we first briefly introduce the task definition and setting. We then describe the overall framework of our proposed ChatDB. Finally, we delve into the details of the chain-of-memory approach, which is the main component of ChatDB.</p>
<h3>3.1 Task Definition</h3>
<p>Given a user input in natural language and details of existing tables in the database (not required if there are no existing tables), the goal is to manipulate the symbolic memory, i.e., the external database, to fulfill the user's request. For instance, if the user (e.g., a store manager) command is to record, modify, query, and delete specific data, the corresponding SQL operation should be to insert, update, select, and delete the relevant data in the appropriate tables, respectively. These operations often involve multiple tables in the database.</p>
<h3>3.2 Framework Overview</h3>
<p>ChatDB framework consists of three main stages: input processing, chain-of-memory, and response summary, as illustrated in Figure 2. Algorithm 1 provides a detailed illustration of the entire algorithmic procedure of ChatDB to respond to the user input.</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: ChatDB framework. The red arrow lines represent the process flow of chain-of-memory, indicating the connection between multiple memory operations. The red arrow lines between database tables represent the reference relationships between primary keys and foreign keys, which start from primary keys to foreign keys. Only the first four columns of each table are shown for brevity. This example showcases the process of returning goods purchased on 2023-01-02 by a customer with the phone number 823451.</p>
<p>Input Processing. ChatDB generates a series of intermediate steps to manipulate the symbolic memory by utilizing LLMs if responding to the user input requires the use of memory. Otherwise, we use LLMs directly to generate a reply.
Chain-of-Memory. ChatDB executes a series of intermediate memory operation steps to interact with symbolic memory. ChatDB manipulates the symbolic memory in sequence according to a series of previously generated SQL statements, including operations such as insert, update, select, delete, etc. The external database executes the corresponding SQL statements, updates the database, and returns the results. It is worth noting that ChatDB decides whether to update the memory operation step based on the results of previous SQL statements before executing this operation. ChatDB executes the next step following the same procedure until all operations on the memory are completed.
Response Summary. ChatDB summarizes the final response to the user based on the results of a series of chain-ofmemory steps.</p>
<h1>3.3 Chain-of-Memory</h1>
<p>Chain-of-thought (Wei et al., 2022) emphasizes decomposing complex reasoning into a series of intermediate steps. Chain-of-memory (CoM) can be seen as a way to augment chain-of-thought by providing a symbolic memory mechanism to support the storage associated with those intermediate steps.
The purpose of chain-of-memory is to enhance the reasoning capabilities and robustness of LLMs when manipulating symbolic memory. The approach involves converting the user input into a sequence of intermediate memory operations, enabling LLMs to more accurately and effectively manipulate the memory in a symbolic way. The ability to manipulate symbolic memory is particularly valuable for real-world applications that involve complex and accurate interactions with historical data, such as record-keeping and data analysis in a management setting.
To enhance the performance and stability of our approach, we employ in-context learning (Brown et al., 2020), providing prompt exemplars of several sequences of chain-of-memory steps, and chain-of-thought prompting. A robust and accurate chain-of-memory process enables LLMs to better reason over symbolic memory and handle more complex scenarios.</p>
<p>The advantages of chain-of-memory are twofold. Firstly, it enables LLMs to perform complex database manipulations with greater accuracy, enhancing their multi-hop reasoning ability over symbolic memory. Secondly, by decomposing complex operations into a sequence of intermediate memory operations, the chain-of-memory approach enhances the capability of LLMs when handling complex, multi-table interactions. This approach enables LLMs to handle edge cases and unexpected scenarios better, making it a promising method for real-world applications.</p>
<div class="codehilite"><pre><span></span><code><span class="nv">Algorithm</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="nv">The</span><span class="w"> </span><span class="nv">algorithm</span><span class="w"> </span><span class="nv">of</span><span class="w"> </span><span class="nv">ChatDB</span>
<span class="nv">Input</span>:<span class="w"> </span><span class="nv">userInput</span>,<span class="w"> </span><span class="nv">dataBase</span>
<span class="nv">Output</span>:<span class="w"> </span><span class="nv">reply</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="nv">need</span><span class="w"> </span><span class="nv">manipulate</span><span class="w"> </span><span class="nv">memory</span><span class="w"> </span><span class="nv">to</span><span class="w"> </span><span class="nv">respond</span><span class="w"> </span><span class="nv">to</span><span class="w"> </span><span class="nv">user</span><span class="w"> </span><span class="nv">Input</span><span class="w"> </span><span class="k">then</span>
<span class="w">    </span><span class="nv">memOps</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">LLM</span><span class="w"> </span><span class="nv">getSteps</span><span class="ss">(</span><span class="nv">userInput</span><span class="ss">)</span>
<span class="w">    </span><span class="k">else</span>
<span class="w">        </span><span class="nv">reply</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">LLM</span><span class="ss">(</span><span class="nv">userInput</span><span class="ss">)</span>
<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="nv">reply</span>
<span class="w">    </span><span class="k">end</span><span class="w"> </span><span class="k">if</span>
<span class="w">    </span><span class="nv">sqlResults</span><span class="w"> </span><span class="o">=</span><span class="w"> </span>[]
<span class="w">    </span><span class="nv">newMemOps</span><span class="w"> </span><span class="o">=</span><span class="w"> </span>[]
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="nv">each</span><span class="w"> </span><span class="nv">memOp</span><span class="w"> </span><span class="nv">in</span><span class="w"> </span><span class="nv">memOps</span><span class="w"> </span><span class="k">do</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="nv">need</span><span class="w"> </span><span class="nv">update</span><span class="w"> </span><span class="nv">memOp</span><span class="w"> </span><span class="nv">based</span><span class="w"> </span><span class="nv">on</span><span class="w"> </span><span class="nv">sqlResults</span><span class="w"> </span><span class="k">then</span>
<span class="w">            </span><span class="nv">newMemOp</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">LLM</span><span class="w"> </span><span class="nv">updateOperation</span><span class="ss">(</span><span class="nv">memOp</span>,<span class="w"> </span><span class="nv">sqlResults</span><span class="ss">)</span>
<span class="w">        </span><span class="k">else</span>
<span class="w">            </span><span class="nv">newMemOp</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">memOp</span>
<span class="w">        </span><span class="k">end</span><span class="w"> </span><span class="k">if</span>
<span class="w">        </span><span class="nv">sqlResult</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">executeOperation</span><span class="ss">(</span><span class="nv">newMemOp</span>,<span class="w"> </span><span class="nv">dataBase</span><span class="ss">)</span>
<span class="w">        </span><span class="nv">sqlResults</span>.<span class="nv">append</span><span class="ss">(</span><span class="nv">sqlResult</span><span class="ss">)</span>
<span class="w">        </span><span class="nv">newMemOps</span>.<span class="nv">append</span><span class="ss">(</span><span class="nv">newMemOp</span><span class="ss">)</span>
<span class="w">    </span><span class="k">end</span><span class="w"> </span><span class="k">for</span>
<span class="w">        </span><span class="nv">reply</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">LLM</span><span class="w"> </span><span class="nv">summary</span><span class="ss">(</span><span class="nv">userInput</span>,<span class="w"> </span><span class="nv">newMemOps</span>,<span class="w"> </span><span class="nv">sqlResults</span><span class="ss">)</span>
<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="nv">reply</span>
</code></pre></div>

<p>$\triangleright$ Begin of Input Processing
$\triangleright$ Generate intermediate steps using LLMs
$\triangleright$ Generate reply using LLMs directly
$\triangleright$ Begin of Chain-of-Memory</p>
<h1>3.4 Comparison with previous memory-augmented LLMs</h1>
<p>Table 1: Comparison with prompt-based memory and matrix-based memory.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Type</th>
<th style="text-align: center;">Model</th>
<th style="text-align: center;">Memory format</th>
<th style="text-align: center;">Supported operations</th>
<th style="text-align: center;">Memory storage</th>
<th style="text-align: center;">Memory execution</th>
<th style="text-align: center;">Interpretability</th>
<th style="text-align: center;">State tracking</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Symbolic</td>
<td style="text-align: center;">ChatDB</td>
<td style="text-align: center;">Symbolic storage <br> (e.g., database)</td>
<td style="text-align: center;">Insert, Delete Update, Select</td>
<td style="text-align: center;">Structured</td>
<td style="text-align: center;">Symbolic</td>
<td style="text-align: center;">High</td>
<td style="text-align: center;">Yes</td>
</tr>
<tr>
<td style="text-align: center;">Prompt-based</td>
<td style="text-align: center;">Auto-GPT</td>
<td style="text-align: center;">Content and its vector embeddings</td>
<td style="text-align: center;">Insert, Select</td>
<td style="text-align: center;">Semi-Structured</td>
<td style="text-align: center;">Non-Symbolic</td>
<td style="text-align: center;">Normal</td>
<td style="text-align: center;">No</td>
</tr>
<tr>
<td style="text-align: center;">Matrix-based</td>
<td style="text-align: center;">RMT</td>
<td style="text-align: center;">Memory tokens/ memory matrices</td>
<td style="text-align: center;">Read, Write</td>
<td style="text-align: center;">Semi-Structured</td>
<td style="text-align: center;">Non-Symbolic</td>
<td style="text-align: center;">Low</td>
<td style="text-align: center;">Yes</td>
</tr>
</tbody>
</table>
<p>In this subsection, we provide a comprehensive comparison between ChatDB and recent approaches that augment Transformer-based language models with memory module. The memory modules of language models proposed in previous work can be broadly categorized into two types. The first type of memory stores context and uses a retrieval model to find content from past interactions that's most relevant to the current conversation, and then uses it as a prompt for the language model (Khattab et al., 2022). We refer to this type of memory as prompt-based memory. The second type of approach utilizes additional memory tokens or memory matrices as memory (Bulatov et al., 2022), which we refer to as matrix-based memory. We compare ChatDB with these approaches based on the following aspects:</p>
<ol>
<li>Memory Format. This aspect relates to the format used for storing memory. ChatDB utilizes databases as its memory. Prompt-based memory (Park et al., 2023) stores relevant interaction content and/or their corresponding vector embeddings. Matrix-based memory employs additional trainable memory tokens (Bulatov et al., 2022, 2023) or trainable memory matrices (Graves et al., 2014).</li>
<li>Supported Operations. This aspect refers to the operations supported for manipulating memory. ChatDB supports operations such as insertion, deletion, update, and selection of data in the database memory. The prompt-based memory primarily supports insertion and selection operations but lacks complete support for updates and deletions. Matrix-based memory supports reading (selection) and writing (insertion, updating, deletion) operations. However, the exact operations performed by the neural network are not explicitly known.</li>
<li>Memory Storage. This aspect refers to the format in which data is stored in memory, specifically whether it is structured or not. ChatDB stores memory in a structured format using databases, while both the prompt-based memory</li>
</ol>
<p>and matrix-based memory are viewed as semi-structured. The reason is that vector embeddings and memory matrices have specific dimensions and sizes, but each individual dimension does not carry a specific and explicit meaning.
4. Memory Execution. This aspect focuses on how memory operations are executed, specifically whether they are symbolic or not. ChatDB executes operations on its database memory using SQL, which is a symbolic language, thus making it inherently symbolic. Prompt-based memory performs selections based on a similarity metric using vector embeddings and employs a language encoder to obtain vector embeddings for insertions. Both of these are considered non-symbolic executions. In matrix-based memory augmentated LLMs, memory operations are entirely controlled by the neural network, resulting in non-symbolic executions as well.
5. Interpretability. This aspect refers to the degree of interpretability of memory. In ChatDB, memory is stored in a structured and explicit format, and its operations are symbolic, leading to a high level of interpretability. In the prompt-based memory, interpretability is generally limited due to inherent challenges in interpreting vector embeddings. For matrix-based memory approach, the degree of interpretability is low since memory is completely controlled by the neural network implicitly.
6. State Tracking. This aspect refers to whether the memory effectively tracks the current state of the LLMs. In the case of ChatDB, its memory accurately tracks the current state of the LLMs. The fruit shop experiment serves as a demonstration, where after processing each record, ChatDB's database memory is updated to reflect the latest state of the fruit shop. This showcases how ChatDB's memory effectively tracks its current state. Thanks to the symbolic memory execution, ChatDB's memory allows for easy rollback to any desired timestamp, providing greater flexibility and controllability. In matrix-based memory approach, memory is continuously updated and altered by the model itself, enabling it to track the current state of the LLMs. However, the prompt-based memory approach simply stores the historical context and only knows what has happened in the past without a clear understanding of the current state.
By examining these aspects, we observe the distinctive features and capabilities of ChatDB in comparison to existing approaches. The superiority of ChatDB highlights the advantages of using symbolic memory to augment LLMs.</p>
<h1>4 Evaluation</h1>
<p>In this section, we conduct experiments to evaluate the effectiveness of augmenting LLMs with databases as their symbolic memory. Our experiment results demonstrate that ChatDB significantly outperforms the baseline model ChatGPT, highlighting the advantages of symbolic memory integration.</p>
<h3>4.1 Experimental Setup</h3>
<p>As previously mentioned, using a database as symbolic memory is particularly suitable for scenarios that require precise recording and processing of historical information, such as various data management scenarios. To adapt to the use case of ChatDB and enable quantitative comparisons with other models, we constructed a synthetic dataset simulating the management of a fruit shop.
Furthermore, in order to evaluate the performance of the models, we collected a set of 50 questions with annotated standard answers. These questions varied in difficulty, ranging from hard ones that required multi-hop reasoning to easy ones that only required retrieving information from historical data. There are 15 easy questions and 35 hard questions. Each question is independently answered by the models.</p>
<h3>4.1.1 Model Configuration</h3>
<p>ChatDB. The LLM used in ChatDB is ChatGPT (GPT-3.5 Turbo), and the hyperparameter temperature is set to 0 . We used the MySQL database as the external symbolic memory.
Baseline. We use ChatGPT (GPT-3.5 Turbo) as the baseline model with a maximum token length of 4096. Similar to ChatDB, we set the temperature to 0 .</p>
<h3>4.1.2 Dataset</h3>
<p>We synthesize a dataset of fruit shop management records, referred to as the "Fruit Shop Dataset". This dataset simulates four common operations in a shop: purchasing, selling, changing prices, and goods returns. We ensure that all historical records are valid and do not encounter issues such as negative inventory. We generate 70 records arranged in chronological order, totaling approximately 3.3 k tokens, which is within the maximum token length limit of ChatGPT (4096 tokens).</p>
<p>(a) Purchasing goods: the shop purchases goods from suppliers.</p>
<p>Record: We restocked our store on 2023-01-01 with a new supply of fruits from "ABC" (abc_sup@example.com, 10080). The purchased quantities include 24 kg cherry, at unit prices of 0.8 . Our intended selling price of cherry is 1.3 dollars per unit.
ChatDB:
Begin to interact with the external database (symbolic memory).
Step1: Insert supplier 'ABC' if not exists
INSERT INTO suppliers (supplier_name, contact_number, email)
SELECT 'ABC', "10080", 'abc_sup@example.com'
WHERE NOT EXISTS (SELECT 1 FROM suppliers WHERE supplier_name $\sim$ - "ABC");
Step2: Insert fruit (set the selling price to NULL and stock quantity to 0 ) if not exists</p>
<p>INSERT INTO fruits (fruit_name, selling_price, stock_quantity, $\sim$ fruit_type, shelf_life)
SELECT 'cherry', NULL, 0, NULL, NULL
WHERE NOT EXISTS (SELECT 1 FROM fruits WHERE fruit_name $\sim$ 'cherry');
Step3: Insert purchase
INSERT INTO purchases (supplier_id, purchase_date, $\sim$ total_cost)
VALUES (SELECT supplier_id FROM suppliers WHERE
$\sim$ supplier_name - "ABC"), "2023-01-01", 24 - 0.8);
Step4: Insert purchase item
INSERT INTO purchase_items (purchase_id, fruit_id,
$\sim$ quantity_purchased, cost_per_item, item_total_cost)
VALUES (SELECT MAX(purchase_id) FROM purchases), (SELECT
$\sim$ fruit_id FROM fruits WHERE fruit_name - "cherry"), 24,
$\sim 0.8,24$ - 0.8);
Step5: Update the stock quantity of cherry
UPDATE fruits
SET stock_quantity = stock_quantity + 24
WHERE fruit_name = "cherry";
Step6: Update the selling price of cherry if given new selling price
UPDATE fruits
SET selling_price $=1.3$
WHERE fruit_name = "cherry";
(c) Return of goods: customers bring back purchased items to the shop.</p>
<p>Record: Because the customer returned their purchase, we are required to undo the sales transaction made by customer 'John Doe' (phone: 123-4567890, email: john.doe@example.com) on 2023-01-05.
ChatDB:
Begin to interact with the external database (symbolic memory).
Step1: Find the sale_id for this customer on this date
SELECT sale_id FROM sales
WHERE customer_id = (SELECT customer_id FROM customers WHERE
$\sim$ phone_number = "123-456-7890" AND email =
"john.doe@example.com") AND sale_date = "2023-01-05";
Database response:
$\qquad$
| sale_id |
$+$............
1 9
$+$............
Step2: Get all the fruit_id and quantity_sold for this sale, replace <sale_id> with the results from the previous queries
SELECT fruit_id, quantity_sold FROM sale_items
WHERE sale_id = 9 [<sale_id>];
Database response:
$+$.............
| fruit_id | quantity_sold |
$+$.............
| 7 | 10
1 0
$+$............
$\square$</p>
<h2>(b) Selling goods: customers buy goods from the shop</h2>
<p>Record: A sale was made on 2023-01-02 to 'Bob Smith' (contact details: 123-456-7893, bob.smith@example.com). The items purchased were 9 kg apple, 4 kg cherry.
ChatDB:
Begin to interact with the external database (symbolic memory).
Step1: Insert customer 'Bob Smith' if not exists
INSERT INTO customers (first_name, last_name, phone_number, $\sim$ email)
SELECT 'Bob', 'Smith', "123-456-7893",
$\sim$ 'bob.smith@example.com'
WHERE NOT EXISTS (SELECT 1 FROM customers WHERE phone_number $\sim$ = "123-456-7893");
Step2: Insert sale
INSERT INTO sales (customer_id, sale_date, total_price)
VALUES (SELECT customer_id FROM customers WHERE phone_number
$\sim$ = "123-456-7893"), "2023-01-02", (SELECT selling_price
$\sim$ FROM fruits WHERE fruit_name = "apple") + 9 + (SELECT
$\sim$ selling_price FROM fruits WHERE fruit_name = "cherry") + $\sim$ 4);</p>
<p>Step3: Insert sale item
INSERT INTO sale_items (sale_id, fruit_id, quantity_sold,
$\sim$ price_per_item, item_total_price)
VALUES (SELECT MAX(sale_id) FROM sales), (SELECT fruit_id
$\sim$ FROM fruits WHERE fruit_name = "apple"), 9, (SELECT
$\sim$ selling_price FROM fruits WHERE fruit_name = "apple"),
$\sim$ (SELECT selling_price FROM fruits WHERE fruit_name =
$\sim$ "apple") + 9),
((SELECT MAX(sale_id) FROM sales), (SELECT fruit_id FROM
$\sim$ fruits WHERE fruit_name = "cherry"), 4, (SELECT
$\sim$ selling_price FROM fruits WHERE fruit_name = "cherry"),
$\sim$ (SELECT selling_price FROM fruits WHERE fruit_name =
$\sim$ "cherry") + 4);
Step4: Update the stock quantity of apple and cherry
UPDATE fruits
SET stock_quantity = CASE
WHERE fruit_name = "apple" THEN stock_quantity = 9
WHERE fruit_name = "cherry" THEN stock_quantity = 4
ELSE stock_quantity
END
WHERE fruit_name IN ("apple", "cherry");</p>
<p>Step3: Increase the stock_quantity for each fruit sold in this sale, replace <quantity_sold> <fruit_id> with the results from the previous queries
UPDATE fruits
SET stock_quantity = stock_quantity + 10 [<quantity_sold>]
WHERE fruit_id = 7 [<fruit_id>];
UPDATE fruits
SET stock_quantity = stock_quantity + 9 [<quantity_sold>]
WHERE fruit_id = 6 [<fruit_id>];
Step4: Delete the sale items for this sale, replace <sale_id> with the results from the previous queries
DELETE FROM sale_items WHERE sale_id = 9 [<sale_id>];
Step5: Delete the sale record, replace <sale_id> with the results from the previous queries
DELETE FROM sales WHERE sale_id = 9 [<sale_id>];
(d) Changing prices: modify the price of the goods.</p>
<p>Record: On 2023-01-05, the sale price of pear in the store was changed to 1.6 dollar per unit.
ChatDB:
Begin to interact with the external database (symbolic memory).
Step1: Update the selling price of pear
UPDATE fruits
SET selling_price $=1.6$
WHERE fruit_name = "pear";</p>
<p>Figure 3: Examples showcasing ChatDB's response to the four common operations in the records of the Fruit Shop Dataset. " 9 [<sale_id>]" represents that <sale_id> is replaced with 9 in the updated SQL statement. Due to page size limitations, some unnecessary details and ChatDB's summary are omitted.</p>
<p>Suppose you are a fruit shop manager and good at analyzing history records.
The fruit shop newly opened on January 1, 2023. Given the history records for the fruit shop in January 2023, which include customer names, transaction dates, fruit prices, quantities purchased, and whether the items were returned, you need to answer some questions.
By default, exclude the sales transactions that have been returned when performing calculations.
Here are the historical records of the fruit shop, which are arranged in chronological order based on the occurrence time, surrounded by triple backticks:
$\cdots$
${$ records $}$
$\cdots$
Based on the history records, answer the question about the fruit shop:
${$ question $}$
Figure 4: Prompt for ChatGPT to answer questions in the Fruit Shop Dataset. The placeholders "records" and "question" will be replaced by specific details when it is actually used.</p>
<p>Why do we limit the token length of the dataset? If the token length of the dataset exceeds the maximum token length of ChatGPT, memory becomes necessary. However, the mainstream memory retrieval methods based on vector embedding are prone to errors. This inevitably leads to a decline in the performance of ChatGPT, which is not desired. Therefore, we deliberately design the token length of the dataset to be within the maximum token length of ChatGPT to avoid using memory and maximize the model's performance. Note that ChatDB's performance is generally unaffected by the token length of the dataset. Thus, if ChatDB outperforms ChatGPT when the dataset is small, it indicates that ChatDB is also superior to memory-augmented ChatGPT when the dataset is large.</p>
<h1>4.1.3 Processing records</h1>
<p>For ChatDB, the first step is to initialize the database. We need to generate a reasonable database schema for the specific task scenario and create tables in the database. The generation of the database schema can be done manually or using LLMs. Next, for each record in the dataset, ChatDB processes them one by one. Using the LLM controller, ChatDB manipulates the external database (i.e., symbolic memory) following Algorithm 1. We provide examples of ChatDB's response to the four common operations in the Fruit Shop Dataset, namely purchasing, selling, changing prices, and goods returns, as shown in Figure 3. It is worth emphasizing that ChatDB processes record one by one, so it is not sensitive to the total number of records. Furthermore, each step of the database operation in ChatDB is symbolic and free from errors. Therefore, in theory, ChatDB can handle an infinite number of historical records without sacrificing performance. However, for ChatGPT or existing memory-augmented LLMs, excessively long historical records can significantly degrade performance. In this experiment, as for the ChatGPT baseline, since the records are not long, we simply treat them as part of the prompt.</p>
<h3>4.1.4 Answering questions</h3>
<p>When answering questions, ChatDB no longer requires records to be part of the prompt. After processing the records, the information is stored in symbolic memory. Following Algorithm 1, ChatDB utilizes SQL statements to perform a series of database queries (including calculations) in order to answer the question. On the other hand, ChatGPT includes records as part of the prompt and directly asks the question. The prompt template is shown in Figure 4.</p>
<h3>4.2 Results</h3>
<p>The experimental results are presented in Table 2, which clearly demonstrate that ChatDB outperforms ChatGPT with significantly higher accuracy. While ChatGPT is capable of answering easy questions, it falls short in handling hard questions that necessitate multi-hop reasoning and precise calculations. Consequently, ChatGPT exhibits a low accuracy rate for these hard questions. In contrast, ChatDB exhibits a notably high accuracy rate, underscoring the advantages of utilizing a database as symbolic memory. This approach not only prevents error accumulation but also enhances the multi-hop reasoning and precise calculation capabilities of LLMs.
We present several examples of the two models answering questions in Figure 5 for comparison. In all these examples, ChatDB correctly answers the questions while ChatGPT fails. ChatGPT often exhibits errors in calculating the total price of each sale transaction, as observed in Figure 5(a). Sometimes, the formulas are correct but the calculations are wrong, while other times, even the formulas are incorrect. In addition, ChatGPT struggles to find all valid sale</p>
<p>(a) Question: What was the total revenue for January 2023?</p>
<h2>ChatGPT:</h2>
<p>To calculate the total revenue for January 2023, we need to sum up the revenue generated from each sales transaction. We can use the following formula to calculate the revenue for each transaction: revenue $=$ quantity $*$ selling price We also need to exclude the sales transactions that have been returned. Based on the history records, the following sales transactions have been returned:</p>
<ul>
<li>Alice Smith on 2023-01-17 - Bob Smith on 2023-01-05 [...]</li>
</ul>
<p>Therefore, we need to exclude these transactions when calculating the total revenue. Here is the calculation for each sales transaction:</p>
<ul>
<li>Bob Smith on 2023-01-02: $(9 \mathrm{~kg} * 3.8 \mathrm{USD} / \mathrm{kg})+(4 \mathrm{~kg} * 1.3 \mathrm{USD} / \mathrm{kg})=39.1$ USD [WRONG]: calculation error, should be 39.4</li>
<li>Sue Davis on 2023-01-02: $1 \mathrm{~kg} * 3.8$ USD/kg $=3.8$ USD</li>
<li>Bob Smith on 2023-01-05: $(5 \mathrm{~kg} * 1.8 \mathrm{USD} / \mathrm{kg})+(2 \mathrm{~kg} * 3.0 \mathrm{USD} / \mathrm{kg})+(6 \mathrm{~kg}$ * 2.8 USD/kg) $=47.6$ USD [WRONG]: calculation error and this transaction has been returned.
[...] [WRONG]: most of the sale transactions are calculated incorrectly.
[STOP]: Because it exceeds the maximum token length.
(b) Question: Which day in January 2023 had the highest revenue?</li>
</ul>
<h2>ChatGPT:</h2>
<p>To calculate the revenue for each day, we need to sum up the total sales for that day (excluding any returned items) and multiply by the selling price. We can then compare the revenue for each day to determine which day had the highest revenue.
Here is the breakdown of sales for each day:</p>
<ul>
<li>January 2: 9 kg apple at $3.8=34.2,4 \mathrm{~kg}$ cherry at $1.3=5.2,3 \mathrm{~kg}$ cherry at $1.3=$ $3.9,5 \mathrm{~kg}$ orange at $2.1=6.3$, total sales $=49.6$ [WRONG]: should be 43.2</li>
<li>January 4: 2 kg apple at $1.5=3,4 \mathrm{~kg}$ pear at $1.6=6.4,7 \mathrm{~kg}$ cherry at $1.3=9.1$, total sales $=18.5$ [WRONG]: should be 27.9</li>
<li>January 5: 5 kg cherry at $1.9=9.5,10 \mathrm{~kg}$ orange at $1.8=18,1 \mathrm{~kg}$ cherry at 1.9 $=1.9,1 \mathrm{~kg}$ grape at $3.2=3.2$, total sales $=32.6$ [WRONG]: should be 83</li>
<li>January 6: 3 kg apple at $1.5=4.5,10 \mathrm{~kg}$ grape at $3.2=32$, total sales $=36.5$ [WRONG]: should be 29.4</li>
<li>January 7: 4 kg pear at $1.6=6.4$, total sales $=6.4$ [WRONG]: should be 37.2</li>
<li>January 8: 6 kg peach at $3=18$, total sales $=18$ [WRONG]: should be 21.6
[...] [WRONG]: most of the daily revenues are calculated incorrectly.
[STOP]: Because it exceeds the maximum token length.</li>
</ul>
<h2>ChatDB:</h2>
<p>Begin to interact with the external database (symbolic memory).
Step1: Calculate the total revenue for January 2023
SELECT SUM (total_price) AS total_revenue
FROM sales
WHERE sale_date &gt;= <em>2023-01-01</em> AND sale_date &lt; <em>2023-02-01</em>;
Database response:
{
\total_revenue
$\mid$
707.8
}</p>
<h2>ChatDB:</h2>
<p>Begin to interact with the external database (symbolic memory).
Step1: Calculate the total revenue for each day in January 2023
SELECT sale_date, SUM (total_price) AS revenue
FROM sales
WHERE sale_date BETWEEN <em>2023-01-01</em> AND <em>2023-01-31</em> GROUP BY sale_data;</p>
<p>Database response:
{
\sale_date | revenue
}
2023-01-02 43.2
2023-01-04 27.9
Step2: Find the day with the highest revenue
SELECT sale_date, SUM (total_price) AS revenue
FROM sales
WHERE sale_date BETWEEN <em>2023-01-01</em> AND <em>2023-01-31</em> GROUP BY sale_date ORDER BY revenue DESC LIMIT 1;</p>
<p>Database response:
}
\sale_date | revenue
}
2023-01-30 119.7
}
(c) Question: What was the average weight of fruit per sales transaction in January 2023?</p>
<p>ChatGPT: To calculate the average weight of fruit per sales transaction, we need to first identify all the sales transactions in January 2023 and calculate the total weight of fruit sold in those transactions. Then, we can divide the total weight by the number of sales transactions to get the average weight per transaction. Here are the sales transactions in January 2023:</p>
<ul>
<li>Bob Smith on 2023-01-02: 9 kg apple, 4 kg cherry</li>
<li>Sue Davis on 2023-01-02: 1 kg apple</li>
<li>Bob Smith on 2023-01-05: 5 kg orange, 2 kg peach, 6 kg pear [WRONG]: this transaction has been returned.</li>
<li>Sue Davis on 2023-01-05: 5 kg pear, 10 kg orange, 1 kg cherry</li>
<li>Alice Smith on 2023-01-05: 5 kg cherry
[...] [WRONG]: not find out all valid sale transactions.
To calculate the total weight of fruit sold, we can add up the quantities of each fruit sold in the above transactions:</li>
<li>Apples: 16 kg - Cherries: 12 kg - Oranges: 10 kg - Pears: 18 kg - Kiwis: 12 kg Grapes: 18 kg - Bananas: 27 kg - Strawberries: 7 kg - Peaches: 9 kg - Plums: 8 kg
The total weight of fruit sold in January 2023 is 127 kg . [WRONG]: It should be 278. Even according to the calculation above, the total should be 137, not 127. To calculate the average weight per sales transaction, we need to divide the total weight by the number of sales transactions. There are 18 sales transactions in January 2023, [WRONG]: It should be 28 valid sale transactions in total. so the average weight [STOP]: Because it exceeds the maximum token length.</li>
</ul>
<table>
<thead>
<tr>
<th style="text-align: left;">ChatDB:</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Begin to interact with the external database (symbolic memory).</td>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;">Step1: Calculate the total weight of fruit sold in January 2023</td>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;">SELECT SUM(si.quantity_sold) as</td>
<td style="text-align: left;">Database response:</td>
</tr>
<tr>
<td style="text-align: left;">$\rightarrow$ total_weight</td>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;">FROM sale_items si</td>
<td style="text-align: left;">total_weight</td>
</tr>
<tr>
<td style="text-align: left;">JOIN sales $x$ ON si.sale_id = s.sale_id</td>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;">WHERE s.sale_date BETWEEN <em>2023-01-01</em></td>
<td style="text-align: left;">278</td>
</tr>
<tr>
<td style="text-align: left;">$\rightarrow$ AND <em>2023-01-31</em></td>
<td style="text-align: left;"></td>
</tr>
</tbody>
</table>
<p>Step2: Count the number of sales transactions in January 2023
SELECT COUNT (DISTINCT s.sale_id) as
$\rightarrow$ num_sales
FROM sales $x$
WHERE s.sale_date BETWEEN <em>2023-01-01</em> $\rightarrow$ AND <em>2023-01-31</em></p>
<div class="codehilite"><pre><span></span><code>\s avg_weight_per_sale
</code></pre></div>

<p>Step3: Calculate the average weight of fruit per sales transaction in January 2023, replace <total_weight> and <num_sales> with the results from the previous queries</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">SELECT 278</td>
<td style="text-align: left;"><total_weight></td>
</tr>
<tr>
<td style="text-align: left;">$\rightarrow$</td>
<td style="text-align: left;">$&lt;$ <num_sales></td>
</tr>
<tr>
<td style="text-align: left;">as avg_weight_per_sale</td>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">9.93</td>
</tr>
</tbody>
</table>
<p>Figure 5: Examples of ChatDB and ChatGPT answering questions. While ChatGPT fails to answer any of the questions correctly, ChatDB successfully answers all of them. The issues with ChatGPT are highlighted in red. Some irrelevant details and ChatDB's summary are omitted for brevity. The gray ellipsis [...] indicates that the response is trimmed.</p>
<p>Table 2: The experimental results of answering questions in the Fruit Shop Dataset. There are 50 questions in total, with 15 being easy questions and 35 being hard questions.</p>
<table>
<thead>
<tr>
<th>Model</th>
<th>Easy</th>
<th>Hard</th>
<th>All</th>
<th>Accuracy</th>
</tr>
</thead>
<tbody>
<tr>
<td>ChatGPT</td>
<td>$10 / 15$</td>
<td>$1 / 35$</td>
<td>$11 / 50$</td>
<td>$22 \%$</td>
</tr>
<tr>
<td>ChatDB (ours)</td>
<td>$13 / 15$</td>
<td>$28 / 35$</td>
<td>$41 / 50$</td>
<td>$82 \%$</td>
</tr>
</tbody>
</table>
<p>transactions, leading to errors in its answering process. This issue is commonly encountered and evident in all these examples. Furthermore, ChatGPT tends to make sequential errors, resulting in significant error accumulation.</p>
<p>In contrast, ChatDB performs quite well in these examples. During the initial processing of records, symbolic operations (i.e., SQL operations) are applied to manipulate the database (i.e., symbolic memory), ensuring that all information is stored in a structured form within the database. When answering questions, ChatDB generates SQL statements to query the database. The three examples demonstrate the effectiveness of ChatDB in solving problems requiring one, two, and three chain-of-memory steps, respectively. We can observe that ChatDB accurately answers the questions, and the execution logic of the chain-of-memory is clear, with each step tightly connected and approaching the ultimate answer. From these examples, the advantages of ChatDB are evident in two aspects:</p>
<ol>
<li>Through the chain-of-memory approach, complex problems are decomposed into multiple steps of memory operations, simplifying the problem's complexity. Each step's result is accurately stored as an intermediate outcome and used in subsequent steps, which greatly assists in complex reasoning.</li>
<li>Symbolic memory enables precise operations and calculations. ChatDB delegates many calculational tasks to the external database by executing SQL statements, ensuring the accuracy of each step and preventing error accumulation.</li>
</ol>
<p>In summary, by leveraging external databases as symbolic memory, ChatDB significantly outperforms ChatGPT in this experiment.</p>
<h1>5 Conclusion</h1>
<p>In this paper, we introduce ChatDB, a framework that augments LLMs with symbolic memory in the form of databases. We demonstrate the advantages and capabilities of symbolic memory and chain-of-memory approach in enhancing complex reasoning and preventing error accumulation. By providing a precise storage mechanism for intermediate results, symbolic memory enables accurate and reliable operations. Moreover, the use of symbolic languages, such as SQL, allows symbolic computation and manipulation of stored information. Through experimental evaluation, we observe a significant improvement in performance with ChatDB compared to ChatGPT. The integration of symbolic memory in ChatDB substantially enhances the model's ability to handle various queries and reasoning tasks in management settings. This improvement highlights the benefits and effectiveness of leveraging symbolic memory in LLMs.</p>
<h2>References</h2>
<p>Andor, D., He, L., Lee, K., and Pitler, E. (2019). Giving bert a calculator: Finding operations and arguments with reading comprehension. arXiv preprint arXiv:1909.00109.</p>
<p>Anil, R., Dai, A. M., Firat, O., Johnson, M., Lepikhin, D., Passos, A., Shakeri, S., Taropa, E., Bailey, P., Chen, Z., et al. (2023). Palm 2 technical report. arXiv preprint arXiv:2305.10403.</p>
<p>Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et al. (2020). Language models are few-shot learners. Advances in neural information processing systems, 33:1877-1901.</p>
<p>Bulatov, A., Kuratov, Y., and Burtsev, M. (2022). Recurrent memory transformer. Advances in Neural Information Processing Systems, 35:11079-11091.</p>
<p>Bulatov, A., Kuratov, Y., and Burtsev, M. S. (2023). Scaling transformer to 1m tokens and beyond with rmt. arXiv preprint arXiv:2304.11062.</p>
<p>Chen, A., Phang, J., Parrish, A., Padmakumar, V., Zhao, C., Bowman, S. R., and Cho, K. (2023). Two failures of self-consistency in the multi-step reasoning of llms. arXiv preprint arXiv:2305.14279.</p>
<p>Chen, W., Ma, X., Wang, X., and Cohen, W. W. (2022). Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks. arXiv preprint arXiv:2211.12588.</p>
<p>Cheng, Z., Xie, T., Shi, P., Li, C., Nadkarni, R., Hu, Y., Xiong, C., Radev, D., Ostendorf, M., Zettlemoyer, L., et al. (2022). Binding language models in symbolic languages. arXiv preprint arXiv:2210.02875.</p>
<p>Cobbe, K., Kosaraju, V., Bavarian, M., Chen, M., Jun, H., Kaiser, L., Plappert, M., Tworek, J., Hilton, J., Nakano, R., et al. (2021). Training verifiers to solve math word problems. arXiv preprint arXiv:2110.14168.</p>
<p>Du, Z., Qian, Y., Liu, X., Ding, M., Qiu, J., Yang, Z., and Tang, J. (2022). Glm: General language model pretraining with autoregressive blank infilling. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 320-335.</p>
<p>Graves, A., Wayne, G., and Danihelka, I. (2014). Neural turing machines. arXiv preprint arXiv:1410.5401.
Guu, K., Lee, K., Tung, Z., Pasupat, P., and Chang, M. (2020). Retrieval augmented language model pre-training. In International conference on machine learning, pages 3929-3938. PMLR.</p>
<p>Hao, S., Gu, Y., Ma, H., Hong, J. J., Wang, Z., Wang, D. Z., and Hu, Z. (2023). Reasoning with language model is planning with world model. arXiv preprint arXiv:2305.14992.</p>
<p>Izacard, G., Lewis, P., Lomeli, M., Hosseini, L., Petroni, F., Schick, T., Dwivedi-Yu, J., Joulin, A., Riedel, S., and Grave, E. (2022). Few-shot learning with retrieval augmented language models. arXiv preprint arXiv:2208.03299.</p>
<p>Johnson, D. D. (2017). Learning graphical state transitions. In International conference on learning representations.
Khattab, O., Santhanam, K., Li, X. L., Hall, D., Liang, P., Potts, C., and Zaharia, M. (2022). Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp. arXiv preprint arXiv:2212.14024.</p>
<p>Lester, B., Al-Rfou, R., and Constant, N. (2021). The power of scale for parameter-efficient prompt tuning. arXiv preprint arXiv:2104.08691.</p>
<p>Lewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin, V., Goyal, N., Küttler, H., Lewis, M., Yih, W.-t., Rocktäschel, T., et al. (2020). Retrieval-augmented generation for knowledge-intensive nlp tasks. Advances in Neural Information Processing Systems, 33:9459-9474.</p>
<p>OpenAI (2023). Gpt-4 technical report.
Paranjape, B., Lundberg, S., Singh, S., Hajishirzi, H., Zettlemoyer, L., and Ribeiro, M. T. (2023). Art: Automatic multi-step reasoning and tool-use for large language models. arXiv preprint arXiv:2303.09014.</p>
<p>Park, J. S., O’Brien, J. C., Cai, C. J., Morris, M. R., Liang, P., and Bernstein, M. S. (2023). Generative agents: Interactive simulacra of human behavior. arXiv preprint arXiv:2304.03442.</p>
<p>Piękos, P., Michalewski, H., and Malinowski, M. (2021). Measuring and improving bert's mathematical abilities by predicting the order of reasoning. arXiv preprint arXiv:2106.03921.</p>
<p>Ran, Q., Lin, Y., Li, P., Zhou, J., and Liu, Z. (2019). Numnet: Machine reading comprehension with numerical reasoning. arXiv preprint arXiv:1910.06701.</p>
<p>Schick, T., Dwivedi-Yu, J., Dessì, R., Raileanu, R., Lomeli, M., Zettlemoyer, L., Cancedda, N., and Scialom, T. (2023). Toolformer: Language models can teach themselves to use tools. arXiv preprint arXiv:2302.04761.</p>
<p>Schuurmans, D. (2023). Memory augmented large language models are computationally universal. arXiv preprint arXiv:2301.04589.</p>
<p>Shen, Y., Song, K., Tan, X., Li, D., Lu, W., and Zhuang, Y. (2023). Hugginggpt: Solving ai tasks with chatgpt and its friends in huggingface. arXiv preprint arXiv:2303.17580.</p>
<p>Sun, R., Arik, S. O., Nakhost, H., Dai, H., Sinha, R., Yin, P., and Pfister, T. (2023). Sql-palm: Improved large language modeladaptation for text-to-sql.</p>
<p>Surís, D., Menon, S., and Vondrick, C. (2023). Vipergpt: Visual inference via python execution for reasoning. arXiv preprint arXiv:2303.08128.</p>
<p>Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.-A., Lacroix, T., Rozière, B., Goyal, N., Hambro, E., Azhar, F., et al. (2023). Llama: Open and efficient foundation language models. arXiv preprint arXiv:2302.13971.</p>
<p>Wang, W., Chen, Z., Chen, X., Wu, J., Zhu, X., Zeng, G., Luo, P., Lu, T., Zhou, J., Qiao, Y., et al. (2023). Visionllm: Large language model is also an open-ended decoder for vision-centric tasks. arXiv preprint arXiv:2305.11175.</p>
<p>Wang, X., Wei, J., Schuurmans, D., Le, Q., Chi, E., and Zhou, D. (2022). Self-consistency improves chain of thought reasoning in language models. arXiv preprint arXiv:2203.11171.</p>
<p>Wei, J., Bosma, M., Zhao, V. Y., Guu, K., Yu, A. W., Lester, B., Du, N., Dai, A. M., and Le, Q. V. (2021). Finetuned language models are zero-shot learners. arXiv preprint arXiv:2109.01652.</p>
<p>Wei, J., Wang, X., Schuurmans, D., Bosma, M., Chi, E., Le, Q., and Zhou, D. (2022). Chain of thought prompting elicits reasoning in large language models. arXiv preprint arXiv:2201.11903.</p>
<p>Wu, Y., Rabe, M. N., Hutchins, D., and Szegedy, C. (2022a). Memorizing transformers. arXiv preprint arXiv:2203.08913.</p>
<p>Wu, Y., Zhao, Y., Hu, B., Minervini, P., Stenetorp, P., and Riedel, S. (2022b). An efficient memory-augmented transformer for knowledge-intensive nlp tasks. arXiv preprint arXiv:2210.16773.</p>
<p>Zeng, A., Liu, X., Du, Z., Wang, Z., Lai, H., Ding, M., Yang, Z., Xu, Y., Zheng, W., Xia, X., et al. (2022). Glm-130b: An open bilingual pre-trained model. arXiv preprint arXiv:2210.02414.</p>
<p>Zhong, Z., Lei, T., and Chen, D. (2022). Training language models with memory augmentation. arXiv preprint arXiv:2205.12674.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{3}$ https://github.com/Significant-Gravitas/Auto-GPT
${ }^{4}$ https://chatexcel.com/
${ }^{5}$ https://github.com/Significant-Gravitas/Auto-GPT&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>