<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-3181 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-3181</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-3181</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-74.html">extraction-schema-74</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the agent, the memory mechanism, the tasks, and performance comparisons.</div>
                <p><strong>Paper ID:</strong> paper-47baad35896702c96ffcdd879bdaf387f5c59853</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/47baad35896702c96ffcdd879bdaf387f5c59853" target="_blank">A Machine With Human-Like Memory Systems</a></p>
                <p><strong>Paper Venue:</strong> arXiv.org</p>
                <p><strong>Paper TL;DR:</strong> This work explicitly model an agent with both semantic and episodic memory systems, and shows that it is better than having just one of the two memory systems.</p>
                <p><strong>Paper Abstract:</strong> Inspired by the cognitive science theory, we explicitly model an agent with both semantic and episodic memory systems, and show that it is better than having just one of the two memory systems. In order to show this, we have designed and released our own challenging environment,"the Room", compatible with OpenAI Gym, where an agent has to properly learn how to encode, store, and retrieve memories to maximize its rewards. The Room environment allows for a hybrid intelligence setup where machines and humans can collaborate. We show that two agents collaborating with each other results in better performance than one agent acting alone.</p>
                <p><strong>Cost:</strong> 0.009</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e3181.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e3181.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the agent, the memory mechanism, the tasks, and performance comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>HC1</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Handcrafted 1: Only Episodic (forget oldest, answer latest)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A rule-based agent with only an episodic memory store of bounded capacity that forgets the oldest episodic memory when full and answers questions using the most recent relevant episodic memory.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Handcrafted 1 (Only Episodic)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>A handcrafted rule-based agent that maintains an episodic memory M_E composed of RDF-like quadruples (head, relation, tail, timestamp). When memory is full it drops the oldest episodic memory; when multiple relevant episodic memories exist it returns the most recent one.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>episodic memory</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism_description</strong></td>
                            <td>Episodic memories are stored as quadruples (h, r, t, timestamp). The store has bounded capacity; insertion appends new episodic observations; eviction policy: drop the oldest episodic memory when capacity is exceeded. Retrieval: find relevant episodic quadruples matching the question (h,r) and select the latest (largest timestamp).</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>the Room environment</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Partially-observable environment where the agent observes one human placing an object at a time (RDF-like quadruples) and must answer location questions (e.g., <Karen's cat, AtLocation>) to earn +1 for correct answers; challenges include partial observability, nonstationary object locations, and limited memory capacity.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>question answering (interactive / partially-observable environment)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>With limited memory capacity, the episodic-only agent performs best among handcrafted variants because recent episodic traces are most informative when capacity is low; overall handcrafted memory policies outperform random baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Bounded memory capacity can limit generalization; episodic-only strategy fails to generalize commonsense regularities when capacity increases; agent uses simple handcrafted eviction heuristic (oldest) which may be suboptimal.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Machine With Human-Like Memory Systems', 'publication_date_yy_mm': '2022-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3181.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e3181.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the agent, the memory mechanism, the tasks, and performance comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>HC2</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Handcrafted 2: Only Semantic (forget weakest, answer strongest)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A rule-based agent with only a semantic memory store that tracks aggregated commonsense strengths and evicts weakest entries, answering using the strongest relevant semantic memory.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Handcrafted 2 (Only Semantic)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>A handcrafted agent that maintains a semantic memory M_S of aggregated, person-agnostic RDF-like triples (object, relation, location, strength). When full, it evicts the weakest semantic memory; retrieval returns the strongest matching semantic triple.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>semantic memory (aggregated counts / strengths)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism_description</strong></td>
                            <td>Semantic memories are quadruples (object, relation, location, strength) where strength is incremented when observations support the triple; bounded capacity with eviction of weakest-strength entries. Retrieval: find semantically relevant triples matching the query and pick highest-strength entry.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>the Room environment</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Same as above: answer AtLocation questions in a partially observable, dynamic room; main challenge is learning and using generalized commonsense location knowledge from observations.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>question answering</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Semantic-only agents perform better as memory capacity increases because they can generalize commonsense regularities; semantic knowledge helps when many observations are available to form strong semantic entries.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Semantic memories are person-agnostic and cannot answer person-specific episodic queries; maintaining accurate strengths depends on sufficient observations; handcrafted eviction of weakest may discard useful but rare facts.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Machine With Human-Like Memory Systems', 'publication_date_yy_mm': '2022-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3181.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e3181.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the agent, the memory mechanism, the tasks, and performance comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>HC3</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Handcrafted 3: Both Episodic and Semantic (learn compressions)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A hybrid handcrafted agent with both episodic and semantic stores that compresses similar episodic memories into semantic entries and uses episodic retrieval first, falling back to semantic.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Handcrafted 3 (Both Episodic and Semantic)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>A handcrafted hybrid agent that maintains both M_E (episodic quadruples with timestamps) and M_S (semantic quadruples with strengths), compresses groups of similar episodic memories into semantic entries when appropriate, and retrieves episodic memories preferentially, falling back to semantic memories.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>episodic memory + semantic memory (hybrid)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism_description</strong></td>
                            <td>Episodic memories stored as (h,r,t,timestamp) and semantic as (object,relation,location,strength). When episodic memory is full, it forgets similar episodic memories that can be compressed into a semantic memory (i.e., summarization); semantic eviction: drop weakest strength entries. Retrieval: attempt latest relevant episodic memory first; if none, use strongest relevant semantic memory.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>the Room environment</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Same Room QA task; challenge: decide what to store/forget in bounded episodic/semantic stores and when to compress episodic patterns into semantic knowledge to improve QA over time.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>question answering</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Hybrid (episodic+semantic) agents outperform single-memory agents as capacity increases because they can both recall recent events and generalize regularities; summarization (compressing episodic to semantic) helps manage bounded memory.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Requires heuristics for recognizing compressible episodic patterns; fixed equal split of capacity between M_E and M_S (in experiments) might be suboptimal; no learned policy for compression (handcrafted).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Machine With Human-Like Memory Systems', 'publication_date_yy_mm': '2022-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3181.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e3181.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the agent, the memory mechanism, the tasks, and performance comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>HC4</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Handcrafted 4: Episodic + Pretrained Semantic (ConceptNet)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A hybrid agent with an episodic store and a semantic store prepopulated with external commonsense knowledge (ConceptNet), using episodic retrieval first and semantic fallback.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Handcrafted 4 (Episodic + Pretrained Semantic)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>A handcrafted agent that begins episodes with the semantic memory prepopulated from ConceptNet commonsense triples and maintains an episodic memory for recent person-specific events, using latest episodic memory first and strongest semantic memory as fallback.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>episodic memory + pretrained semantic memory (external knowledge graph)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism_description</strong></td>
                            <td>Semantic memory M_S is initialized at episode start with ConceptNet-derived commonsense triples (object,AtLocation,location,strength). Episodic memories are collected during the episode and evicted by oldest-first when full (unless semantic space leaves room). Retrieval: prefer latest episodic match; otherwise return strongest semantic match from prepopulated M_S.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>the Room environment</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Same Room QA task; main challenge: combine preexisting commonsense knowledge with online episodic observations to answer person-specific and general location questions under partial observability.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>question answering</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Pretraining the semantic memory with ConceptNet leads to better performance because the agent can rely on commonsense knowledge and focus episodic capacity on recent person-specific events; Handcrafted 4 achieved the best performance among handcrafted policies when semantic pretraining was available.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Quality of pretrained semantic knowledge determines fallback accuracy; prepopulated semantic memory reduces space for episodic memories (handled by allocating remaining capacity), requiring trade-offs; approach is handcrafted rather than learned.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Machine With Human-Like Memory Systems', 'publication_date_yy_mm': '2022-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3181.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e3181.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the agent, the memory mechanism, the tasks, and performance comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RandomBaseline</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Random forgetting and answering baseline</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Baseline policies that either forget memories and/or answer questions uniformly at random to evaluate the benefit of structured memory policies.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Random forgetting/answering baseline</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Baseline agents that perform forgetting and/or answering uniformly at random rather than using structured heuristics; used to demonstrate the value of handcrafted memory policies.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>episodic and/or semantic (randomized policies)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism_description</strong></td>
                            <td>Baseline still holds bounded memory but applies random eviction (forget uniformly-randomly) and random answer selection (answer uniformly-randomly) rather than heuristic-based retrieval.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>the Room environment</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Same Room QA task serving as a low-performing baseline to compare against structured memory policies.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>question answering</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Handcrafted forgetting and answering policies significantly outperform the random baseline; random forgetting-and-answering performed worst in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Random policies are not meaningful baseline agents beyond serving as a lower bound; does not provide insight into how to improve memory strategies.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Machine With Human-Like Memory Systems', 'publication_date_yy_mm': '2022-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3181.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e3181.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the agent, the memory mechanism, the tasks, and performance comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MultiAgent</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Multiple agents collaborating (machine-machine or human-machine)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Setup where two or more agents (or humans+agents) combine their separate memories to answer questions, yielding better coverage and improved QA performance.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Multi-agent collaboration (two-agent setup)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Multiple agents each maintain their own bounded episodic/semantic storages and can use the union (or consult each other's stores) to answer questions; agents explore different parts of the room leading to complementary memories.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>distributed episodic and/or semantic memories across agents</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism_description</strong></td>
                            <td>Each agent stores observations in its own M_E and/or M_S. For answering, agents can query combined memory holdings (e.g., use the most recent relevant episodic memory among agents or strongest semantic memory across agents). Capacity is kept equal across setups for fair comparison (e.g., single agent 32 vs two agents with 16 each).</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>the Room environment (multi-agent variant)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Same QA task but with multiple agents present who observe different humans placing objects; challenge is leveraging distributed partial observations to improve QA accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>question answering / multi-agent coordination</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Two agents collaborating (with combined memory capacity split across them) answer more questions than a single agent with the same total capacity because they explore different areas and thus have more diverse episodic coverage.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Comparison kept total capacity constant but divided across agents; benefits depend on exploration diversity; coordination/trust/conflict resolution among agents/humans not implemented and noted as future work.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Machine With Human-Like Memory Systems', 'publication_date_yy_mm': '2022-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Episodic Memory Reader: Learning What to Remember for Question Answering from Streaming Data <em>(Rating: 2)</em></li>
                <li>Integrating Episodic and Semantic Information in Memory for Natural Scenes <em>(Rating: 2)</em></li>
                <li>Elements of Episodic Memory <em>(Rating: 1)</em></li>
                <li>ConceptNet 5.5: An Open Multilingual Graph of General Knowledge <em>(Rating: 1)</em></li>
                <li>The Soar Cognitive Architecture <em>(Rating: 2)</em></li>
                <li>Discovering skill <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-3181",
    "paper_id": "paper-47baad35896702c96ffcdd879bdaf387f5c59853",
    "extraction_schema_id": "extraction-schema-74",
    "extracted_data": [
        {
            "name_short": "HC1",
            "name_full": "Handcrafted 1: Only Episodic (forget oldest, answer latest)",
            "brief_description": "A rule-based agent with only an episodic memory store of bounded capacity that forgets the oldest episodic memory when full and answers questions using the most recent relevant episodic memory.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "Handcrafted 1 (Only Episodic)",
            "agent_description": "A handcrafted rule-based agent that maintains an episodic memory M_E composed of RDF-like quadruples (head, relation, tail, timestamp). When memory is full it drops the oldest episodic memory; when multiple relevant episodic memories exist it returns the most recent one.",
            "memory_used": true,
            "memory_type": "episodic memory",
            "memory_mechanism_description": "Episodic memories are stored as quadruples (h, r, t, timestamp). The store has bounded capacity; insertion appends new episodic observations; eviction policy: drop the oldest episodic memory when capacity is exceeded. Retrieval: find relevant episodic quadruples matching the question (h,r) and select the latest (largest timestamp).",
            "task_name": "the Room environment",
            "task_description": "Partially-observable environment where the agent observes one human placing an object at a time (RDF-like quadruples) and must answer location questions (e.g., &lt;Karen's cat, AtLocation&gt;) to earn +1 for correct answers; challenges include partial observability, nonstationary object locations, and limited memory capacity.",
            "task_type": "question answering (interactive / partially-observable environment)",
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_performance_comparison": true,
            "key_findings": "With limited memory capacity, the episodic-only agent performs best among handcrafted variants because recent episodic traces are most informative when capacity is low; overall handcrafted memory policies outperform random baselines.",
            "limitations_or_challenges": "Bounded memory capacity can limit generalization; episodic-only strategy fails to generalize commonsense regularities when capacity increases; agent uses simple handcrafted eviction heuristic (oldest) which may be suboptimal.",
            "uuid": "e3181.0",
            "source_info": {
                "paper_title": "A Machine With Human-Like Memory Systems",
                "publication_date_yy_mm": "2022-04"
            }
        },
        {
            "name_short": "HC2",
            "name_full": "Handcrafted 2: Only Semantic (forget weakest, answer strongest)",
            "brief_description": "A rule-based agent with only a semantic memory store that tracks aggregated commonsense strengths and evicts weakest entries, answering using the strongest relevant semantic memory.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "Handcrafted 2 (Only Semantic)",
            "agent_description": "A handcrafted agent that maintains a semantic memory M_S of aggregated, person-agnostic RDF-like triples (object, relation, location, strength). When full, it evicts the weakest semantic memory; retrieval returns the strongest matching semantic triple.",
            "memory_used": true,
            "memory_type": "semantic memory (aggregated counts / strengths)",
            "memory_mechanism_description": "Semantic memories are quadruples (object, relation, location, strength) where strength is incremented when observations support the triple; bounded capacity with eviction of weakest-strength entries. Retrieval: find semantically relevant triples matching the query and pick highest-strength entry.",
            "task_name": "the Room environment",
            "task_description": "Same as above: answer AtLocation questions in a partially observable, dynamic room; main challenge is learning and using generalized commonsense location knowledge from observations.",
            "task_type": "question answering",
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_performance_comparison": true,
            "key_findings": "Semantic-only agents perform better as memory capacity increases because they can generalize commonsense regularities; semantic knowledge helps when many observations are available to form strong semantic entries.",
            "limitations_or_challenges": "Semantic memories are person-agnostic and cannot answer person-specific episodic queries; maintaining accurate strengths depends on sufficient observations; handcrafted eviction of weakest may discard useful but rare facts.",
            "uuid": "e3181.1",
            "source_info": {
                "paper_title": "A Machine With Human-Like Memory Systems",
                "publication_date_yy_mm": "2022-04"
            }
        },
        {
            "name_short": "HC3",
            "name_full": "Handcrafted 3: Both Episodic and Semantic (learn compressions)",
            "brief_description": "A hybrid handcrafted agent with both episodic and semantic stores that compresses similar episodic memories into semantic entries and uses episodic retrieval first, falling back to semantic.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "Handcrafted 3 (Both Episodic and Semantic)",
            "agent_description": "A handcrafted hybrid agent that maintains both M_E (episodic quadruples with timestamps) and M_S (semantic quadruples with strengths), compresses groups of similar episodic memories into semantic entries when appropriate, and retrieves episodic memories preferentially, falling back to semantic memories.",
            "memory_used": true,
            "memory_type": "episodic memory + semantic memory (hybrid)",
            "memory_mechanism_description": "Episodic memories stored as (h,r,t,timestamp) and semantic as (object,relation,location,strength). When episodic memory is full, it forgets similar episodic memories that can be compressed into a semantic memory (i.e., summarization); semantic eviction: drop weakest strength entries. Retrieval: attempt latest relevant episodic memory first; if none, use strongest relevant semantic memory.",
            "task_name": "the Room environment",
            "task_description": "Same Room QA task; challenge: decide what to store/forget in bounded episodic/semantic stores and when to compress episodic patterns into semantic knowledge to improve QA over time.",
            "task_type": "question answering",
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_performance_comparison": true,
            "key_findings": "Hybrid (episodic+semantic) agents outperform single-memory agents as capacity increases because they can both recall recent events and generalize regularities; summarization (compressing episodic to semantic) helps manage bounded memory.",
            "limitations_or_challenges": "Requires heuristics for recognizing compressible episodic patterns; fixed equal split of capacity between M_E and M_S (in experiments) might be suboptimal; no learned policy for compression (handcrafted).",
            "uuid": "e3181.2",
            "source_info": {
                "paper_title": "A Machine With Human-Like Memory Systems",
                "publication_date_yy_mm": "2022-04"
            }
        },
        {
            "name_short": "HC4",
            "name_full": "Handcrafted 4: Episodic + Pretrained Semantic (ConceptNet)",
            "brief_description": "A hybrid agent with an episodic store and a semantic store prepopulated with external commonsense knowledge (ConceptNet), using episodic retrieval first and semantic fallback.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "Handcrafted 4 (Episodic + Pretrained Semantic)",
            "agent_description": "A handcrafted agent that begins episodes with the semantic memory prepopulated from ConceptNet commonsense triples and maintains an episodic memory for recent person-specific events, using latest episodic memory first and strongest semantic memory as fallback.",
            "memory_used": true,
            "memory_type": "episodic memory + pretrained semantic memory (external knowledge graph)",
            "memory_mechanism_description": "Semantic memory M_S is initialized at episode start with ConceptNet-derived commonsense triples (object,AtLocation,location,strength). Episodic memories are collected during the episode and evicted by oldest-first when full (unless semantic space leaves room). Retrieval: prefer latest episodic match; otherwise return strongest semantic match from prepopulated M_S.",
            "task_name": "the Room environment",
            "task_description": "Same Room QA task; main challenge: combine preexisting commonsense knowledge with online episodic observations to answer person-specific and general location questions under partial observability.",
            "task_type": "question answering",
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_performance_comparison": true,
            "key_findings": "Pretraining the semantic memory with ConceptNet leads to better performance because the agent can rely on commonsense knowledge and focus episodic capacity on recent person-specific events; Handcrafted 4 achieved the best performance among handcrafted policies when semantic pretraining was available.",
            "limitations_or_challenges": "Quality of pretrained semantic knowledge determines fallback accuracy; prepopulated semantic memory reduces space for episodic memories (handled by allocating remaining capacity), requiring trade-offs; approach is handcrafted rather than learned.",
            "uuid": "e3181.3",
            "source_info": {
                "paper_title": "A Machine With Human-Like Memory Systems",
                "publication_date_yy_mm": "2022-04"
            }
        },
        {
            "name_short": "RandomBaseline",
            "name_full": "Random forgetting and answering baseline",
            "brief_description": "Baseline policies that either forget memories and/or answer questions uniformly at random to evaluate the benefit of structured memory policies.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "Random forgetting/answering baseline",
            "agent_description": "Baseline agents that perform forgetting and/or answering uniformly at random rather than using structured heuristics; used to demonstrate the value of handcrafted memory policies.",
            "memory_used": true,
            "memory_type": "episodic and/or semantic (randomized policies)",
            "memory_mechanism_description": "Baseline still holds bounded memory but applies random eviction (forget uniformly-randomly) and random answer selection (answer uniformly-randomly) rather than heuristic-based retrieval.",
            "task_name": "the Room environment",
            "task_description": "Same Room QA task serving as a low-performing baseline to compare against structured memory policies.",
            "task_type": "question answering",
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_performance_comparison": true,
            "key_findings": "Handcrafted forgetting and answering policies significantly outperform the random baseline; random forgetting-and-answering performed worst in experiments.",
            "limitations_or_challenges": "Random policies are not meaningful baseline agents beyond serving as a lower bound; does not provide insight into how to improve memory strategies.",
            "uuid": "e3181.4",
            "source_info": {
                "paper_title": "A Machine With Human-Like Memory Systems",
                "publication_date_yy_mm": "2022-04"
            }
        },
        {
            "name_short": "MultiAgent",
            "name_full": "Multiple agents collaborating (machine-machine or human-machine)",
            "brief_description": "Setup where two or more agents (or humans+agents) combine their separate memories to answer questions, yielding better coverage and improved QA performance.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "Multi-agent collaboration (two-agent setup)",
            "agent_description": "Multiple agents each maintain their own bounded episodic/semantic storages and can use the union (or consult each other's stores) to answer questions; agents explore different parts of the room leading to complementary memories.",
            "memory_used": true,
            "memory_type": "distributed episodic and/or semantic memories across agents",
            "memory_mechanism_description": "Each agent stores observations in its own M_E and/or M_S. For answering, agents can query combined memory holdings (e.g., use the most recent relevant episodic memory among agents or strongest semantic memory across agents). Capacity is kept equal across setups for fair comparison (e.g., single agent 32 vs two agents with 16 each).",
            "task_name": "the Room environment (multi-agent variant)",
            "task_description": "Same QA task but with multiple agents present who observe different humans placing objects; challenge is leveraging distributed partial observations to improve QA accuracy.",
            "task_type": "question answering / multi-agent coordination",
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_performance_comparison": true,
            "key_findings": "Two agents collaborating (with combined memory capacity split across them) answer more questions than a single agent with the same total capacity because they explore different areas and thus have more diverse episodic coverage.",
            "limitations_or_challenges": "Comparison kept total capacity constant but divided across agents; benefits depend on exploration diversity; coordination/trust/conflict resolution among agents/humans not implemented and noted as future work.",
            "uuid": "e3181.5",
            "source_info": {
                "paper_title": "A Machine With Human-Like Memory Systems",
                "publication_date_yy_mm": "2022-04"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Episodic Memory Reader: Learning What to Remember for Question Answering from Streaming Data",
            "rating": 2
        },
        {
            "paper_title": "Integrating Episodic and Semantic Information in Memory for Natural Scenes",
            "rating": 2
        },
        {
            "paper_title": "Elements of Episodic Memory",
            "rating": 1
        },
        {
            "paper_title": "ConceptNet 5.5: An Open Multilingual Graph of General Knowledge",
            "rating": 1
        },
        {
            "paper_title": "The Soar Cognitive Architecture",
            "rating": 2
        },
        {
            "paper_title": "Discovering skill",
            "rating": 2
        }
    ],
    "cost": 0.00882925,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>A Machine With Human-Like Memory Systems</h1>
<p>Taewoon KIM ${ }^{\mathrm{a}}$, Michael COCHEZ ${ }^{\mathrm{a}}$, Vincent FRANOIS-LAVET ${ }^{\mathrm{a}}$, Mark NEERINCX ${ }^{\text {b }}$, and Piek VOSSEN ${ }^{\text {a }}$<br>${ }^{a}$ Vrije Universiteit Amsterdam<br>${ }^{\mathrm{b}}$ Technische Universiteit Delft<br>{t.kim, m.cochez, vincent.francoislavet, p.t.j.m.vossen}@vu.nl<br>m.a.neerincx@tudelft.nl</p>
<h4>Abstract</h4>
<p>Inspired by the cognitive science theory, we explicitly model an agent with both semantic and episodic memory systems, and show that it is better than having just one of the two memory systems. In order to show this, we have designed and released our own challenging environment, "the Room", compatible with OpenAI Gym, where an agent has to properly learn how to encode, store, and retrieve memories to maximize its rewards. The Room environment allows for a hybrid intelligence setup where machines and humans can collaborate. We show that two agents collaborating with each other results in better performance than one agent acting alone. The code is open-sourced at https://github.com/humemai/agent-room-env-v0.</p>
<p>Keywords. explicit memory, episodic memory, semantic memory, hybrid intelligence</p>
<h2>1. Introduction</h2>
<p>In cognitive science, it is thought that humans have an explicit memory system, which is composed of semantic and episodic memory systems. Semantic memory has to do with general world knowledge, while episodic has to do with one's personal memory. For example, when one asks you a question, "In general, where are laptops located?" you might be able to answer it, if you have successfully encoded and stored a relevant memory in your brain. Let's assume that you have, and your answer is "On the desks". However, it is likely that you do not know when and where you have encoded and stored the memory. Nonetheless, you were able to retrieve it. This is because this type of memory is semantic. When your brain deals with such factual (general) knowledge memories, it does not store the information regarding when and where. Let's ask you another question, "Where is Karen's laptop?" Let's again assume that you have observed where Karen's laptop was. To answer this question, one revisits when and where this memory was encoded and stored. Retrieval of such a memory is a reconstruction process of it. This type of memory is called episodic. It is more personal to you than semantic [1-3].</p>
<p>Motivated by this, we have explicitly modeled an agent that has both semantic and episodic memory systems. An agent interacts with the environment and has to answer questions to maximize the rewards. Our hypothesis is that if it can successfully encode</p>
<p>and store relevant observations in its brain as either semantic or episodic memories, then it can also answer the questions more successfully than using only one of the two memory systems.</p>
<p>The contributions of this paper are as follows. (1) Inspired by the cognitive science theory, we explicitly model an agent with both semantic and episodic memory systems, and show that it is better than having just one memory system in our experiments. (2) We designed and released our own challenging environment, compatible with OpenAI Gym [4], where an agent has to properly learn how to encode, store, and retrieve memories to maximize rewards. (3) We demonstrate that when an agent collaborates with another agent or human, it leads to better performance.</p>
<h1>2. Methodology</h1>
<h3>2.1. The Room Environment</h3>
<p>The OpenAI-Gym-compatible Room environment is one big room with $N_{\text {people }}$ number of people who can freely move around. Each of them selects one object, among $N_{\text {objects }}$, and places it in one of the $N_{\text {locations }}$ locations. $N_{\text {agents }}$ number of agent(s) are also in this room. They can only observe one human placing an object, one at a time; $\boldsymbol{x}^{(t)}$. At the same time, they are given one question about the location of an object; $\boldsymbol{q}^{(t)} \cdot \boldsymbol{x}^{(t)}$ is given as a quadruple, $\left(\boldsymbol{h}^{(t)}, \boldsymbol{r}^{(t)}, \boldsymbol{t}^{(t)}, t\right)$, For example, <James's laptop, AtLocation, James's desk, 42> accounts for an observation where an agent sees James placing his laptop on his desk at $t=42 . \boldsymbol{q}^{(t)}$ is given as a double, $(\boldsymbol{h}, \boldsymbol{r})$. For example, <Karen's cat, AtLocation> is asking where Karen's cat is located. If the agent answers the question correctly, it gets a reward of +1 , and if not, it gets 0 .</p>
<p>The reason why the observations and questions are given as RDF-triple-like format is two folds. One is that this structured format is easily readable / writable by both humans and machines. Second is that we can use existing knowledge graphs, such as ConceptNet [5].</p>
<p>To simplify the environment, the agents themselves are not actually moving, but the room is continuously changing. There are several random factors in this environment to be considered:</p>
<ol>
<li>With the chance of $p_{\text {commonsense }}$, a human places an object in a commonsense location (e.g., a laptop on a desk). The commonsense knowledge we use is from ConceptNet. With the chance of $1-p_{\text {commonsense }}$, an object is placed at a noncommonsense random location (e.g., a laptop on the tree).</li>
<li>With the chance of $p_{\text {new_location }}$, a human changes object location.</li>
<li>With the chance of $p_{\text {new_object }}$, a human changes his/her object to another one.</li>
<li>With the chance of $p_{\text {switch_person }}$, two people switch their locations. This is done to mimic an agent moving around the room.</li>
</ol>
<p>All of the four probabilities account for the Bernoulli distributions.</p>
<h1>2.2. Episodic and Semantic Memory Systems</h1>
<p>Each agent partially observes the environment (i.e., they cannot see the entire room at once, but one human at a time). This means that it should keep the history of its observations. This can be done by having memory systems. In our work, we model our agent to have a human-like explicit memory system. This means that it has both episodic and semantic memory systems. For example, at current time $t=23$, a question given by the environment is <Karen's cat, AtLocation>. If the agent has an episodic memory <Karen's cat, AtLocation, Karen's office, 21>, which it has seen two time steps ago, this episodic memory will likely be a "correct" memory to be retrieved to answer the question.</p>
<p>Not every observation has to be saved in the episodic memory system. Using our commonsense, we know that laptops are mostly placed on the desk. So for example, at current time $t=23$, let's say that a question <James's laptop, AtLocation> is given. If the agent has an episodic memory of this event, then it can use it. But if not, then it can use a commonsense knowledge <laptop, AtLocation, desk, 10>. This commonsense knowledge forms the semantic memory of the agent, since semantic memory has to do with the general knowledge of the world. Similar to episodic memories, semantic memories are also quadruples. However, the last element of a semantic memory is not a timestamp, but the strength of the semantic memory. For example, <laptop, AtLocation, desk, 10> is a stronger semantic memory than <laptop, AtLocation, garage, 5>, since the agent has seen laptops being placed on desk 10 times, while it has only seen them in a garage five times. Notice that semantic memories do not include the names of people, since this type of memory is not person-specific.</p>
<p>Both episodic and semantic memory systems, $\boldsymbol{M}<em S="S">{E}$ and $\boldsymbol{M}</em>$, respectively, are bounded in size. Since an agent can not store all of its observations, it should learn what to store and what to forget. It should also learn that some of its episodic memories can be summarized into one semantic memory. For example, if it always sees humans placing their laptops on their desks, then perhaps one semantic memory <laptop, AtLocation, desk> is enough to answer the related questions.</p>
<h3>2.3. Hybrid Intelligence</h3>
<p>The Room environment does not restrict the number of agents. It allows for humanmachine or machine-machine collaboration. For example, at current time $t=23$, a question given by the environment is <Karen's cat, AtLocation>. If agent ${ }<em 2="2">{1}$ has an episodic memory <Karen's cat, AtLocation, Karen's office, 21> and agent ${ }</em>$ has an episodic memory <Karen's cat, AtLocation, Karen's desk, 22>, then it is more likely that the memory of agent $<em 1="1">{2}$ can answer the question more accurately since its memory is more recent than that of agent $</em>$. Or, it is also possible for them to use commonsense knowledge that "Cats are often found on the lap of their owners.", if the agents have encoded such a thing in their semantic memory system.</p>
<h1>3. Experimental Setup</h1>
<h3>3.1. Data Collection and the Environment Hyperparameters</h3>
<p>In order to simplify the experiment setup, we decided to use a subset of the ConceptNet. To be more specific, we restricted the number of objects to 10 , where the commonsense locations of every object is also restricted to be one. 10 random human names were used to mimic humans in the room. The relation $\boldsymbol{r}^{[t]}$ is always AtLocation. The four probabilities $p_{\text {commonsense }}, p_{\text {new_location }}, p_{\text {new_object }}$, and $p_{\text {switch_person }}$ were set to $0.7,0.1$, 0.1 , and 0.5 , respectively. We have tuned these values to mimic a realistic environment. We have also set the maximum steps of the environment to 1,000 . This means that the environment terminates after an agent has taken 1,000 steps.</p>
<h3>3.2. Single Agent Policies</h3>
<p>Inspired by the theories on the explicit human memory, we have designed the following four handcrafted policies (models).</p>
<p>Handcrafted 1: Only episodic, forget the oldest and answer the latest. This agent only has an episodic memory system. When the episodic memory system is full, it will forget the oldest episodic memory. When a question is asked and there are more than one relevant episodic memories found, it will use the latest relevant episodic memory to answer the question.</p>
<p>Handcrafted 2: Only semantic, forget the weakest and answer the strongest. This agent only has a semantic memory system. When the semantic memory system is full, it will forget the weakest semantic memory. When a question is asked and there are more than one relevant semantic memories found, it will use the strongest relevant semantic memory to answer the question.</p>
<p>Handcrafted 3: Both episodic and semantic. This agent has both episodic and semantic memory systems. When the episodic memory system is full, it will forget similar episodic memories that can be compressed into one semantic memory. When the semantic memory system is full, it will forget the weakest semantic memory. When a question is asked, it will first try to use the latest episodic memory to answer it, if it can not, it will use the strongest relevant semantic memory to answer the question.</p>
<p>Handcrafted 4: Both episodic and pretrained semantic. From the beginning of an episode, the semantic memory system is populated with the ConceptNet commonsense knowledge. When the episodic memory system is full, it will forget the oldest episodic memory. When a question is asked, it will first try to use the latest episodic memory to answer it, if it can not, it will use the strongest relevant semantic memory to answer the question.</p>
<p>For a fair comparison, every agent has the same total memory capacity. As for the Handcrafted 3 agent, the episodic and semantic memory systems have the same capacity, since this agent does not know which one is more important a priori. As for the Handcrafted 4 agent, if there is space left in the semantic memory system after filling it up, it will give the rest of the space to the episodic memory system. In order to show the validity of our handcrafted agents, we compare them with the agents that forget and answer uniform-randomly.</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1. Handcrafted vs. random policies</p>
<h1>3.3. Multiple Agent Policies</h1>
<p>The multiple agent policies work in the same manner as the single agent policies, except that they can use their combined memory systems to answer questions.</p>
<h2>4. Results</h2>
<p>Figure 1 shows that our handcrafted forgetting and answering policies outperform random policies. Obviously, when both forgetting memories and answering questions are done randomly, it performs the worst.</p>
<p>Figure 2 shows the results after one episode, with their best handcrafted policies. It shows that when the memory capacity is low, having only episodic memory system is better than the others. This is because when there are not enough memories in the system, it is not enough to learn the general world knowledge. As the memory capacity increases, however, it shows that having a semantic memory system helps, as it learns to generalize the world. It is especially interesting to see the Handcrafted 4 agent, which has an episodic system and a pretrained semantic system. Since it already knows the general world knowledge, it could focus more on the episodic part, leading to better performance.</p>
<p>Figure 3 compares the performance between single-agent and double-agent setups. For a fair comparison, memory capacity was kept the same (i.e., as for the two agent setup, each agent can store 16 memories, while the agent in the single-agent setup can store 32). It shows that two agents working together were able to answer more questions than one agent working alone. This is due to the fact that the two agents were exploring the room in different directions. This led them to cover more area than one agent acting alone.</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2. Total rewards with respect to different handcrafted policies and memory capacities.</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3. Total rewards with respect to the number of agents. The lighter and narrower bars account for the single agent.</p>
<h1>5. Related work</h1>
<p>After studying related literature, we observed that papers that are theoretically similar to ours are mostly cognitive science papers. ACT-R [6] and Soar [7] put a big emphasis on theories, but they lack of computational experiments, which makes it hard to compare. There was a work [8] that studied how episodic and semantic memory systems play a role in recall of objects, but their experiments were human-based empirical results, which does not scale as well as our computational method.</p>
<p>Second is that although some computer science based papers do computational experiments that are a bit similar to ours, they often do not study episodic and semantic memory systems together. For example, Episodic Memory Reader [9] also learns what to forget in their memory system, and they also use question-answering to evaluate their</p>
<p>method. However, this work only focuses on episodic memory. Also, their memory system is not composed of RDF-like data, but rather numeric embeddings, which are hard to interpret what they have captured.</p>
<h1>6. Conclusions</h1>
<p>We have created our own OpenAI-Gym-compatible environment, where agents with both episodic and semantic memory systems can be tested. We showed that when a machine is explicitly given both semantic and episodic memory systems, it outperforms the ones that only have one of the two memory systems. We also showed that when an agent is pretrained with commonsense knowledge, it outperforms the one that is not pretrained. Multiple agents collaborating with each other were better at question answering, since they can complement each other's memories.</p>
<p>In the future, we want to see if reinforcement learning agents can perform as good as the handcrafted ones, to see if such data-driven agents can lead to better generalization. We also hope to make the Room environment even closer to the real human environment (e.g., adding images, voices, more entities and relations, etc.). As for the collaboration, the current setup is limited to only agents working together. We would like to extend this to different collaboration setups (e.g., multiple humans and multiple agents). It would be especially interesting to encourage agents to ask humans questions, when it is not sure how to answer them. Collaboration will not always be straightforward, especially if there are conflicts and different degrees of trust among humans and agents. Dealing them elegantly will be another future challenge.</p>
<h2>Acknowledgements</h2>
<p>This research was (partially) funded by the Hybrid Intelligence Center, a 10-year program funded by the Dutch Ministry of Education, Culture and Science through the Netherlands Organization for Scientific Research, https://www.hybrid-intelligencecentre.nl/.</p>
<h2>References</h2>
<p>[1] Tulving E. Elements of Episodic Memory. Oxford University Press; 1983.
[2] Tulving E. Memory and consciousness. Canadian Psychology/Psychologie canadienne. 1985;26(1):1.
[3] Tulving E, Thomson DM. Encoding specificity and retrieval processes in episodic memory. Psychological Review. 1973;80:352-73.
[4] Brockman G, Cheung V, Pettersson L, Schneider J, Schulman J, Tang J, et al.. OpenAI Gym; 2016. Cite arxiv:1606.01540. Available from: http://arxiv.org/abs/1606.01540.
[5] Speer R, Chin J, Havasi C. ConceptNet 5.5: An Open Multilingual Graph of General Knowledge. Proceedings of the AAAI Conference on Artificial Intelligence. 2017 Feb;31(1). Available from: https://ojs.aaai.org/index.php/AAAI/article/view/11164.
[6] Anderson JR, Betts S, Bothell D, Lebiere C. Discovering skill. Cognitive Psychology. 2021;129:101410. Available from: https://www.sciencedirect.com/science/article/pii/ S0010028521000335.
[7] Laird JE. The Soar Cognitive Architecture. The MIT Press; 2012.</p>
<p>[8] Hemmer P, Steyvers M. Integrating Episodic and Semantic Information in Memory for Natural Scenes; 2009. .
[9] Han M, Kang M, Jung H, Hwang SJ. Episodic Memory Reader: Learning What to Remember for Question Answering from Streaming Data. In: Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. Florence, Italy: Association for Computational Linguistics; 2019. p. 4407-17. Available from: https://aclanthology.org/P19-1434.</p>            </div>
        </div>

    </div>
</body>
</html>