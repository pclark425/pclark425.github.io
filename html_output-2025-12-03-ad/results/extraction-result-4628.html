<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-4628 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-4628</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-4628</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-102.html">extraction-schema-102</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including mechanisms, representations, performance, and failure modes.</div>
                <p><strong>Paper ID:</strong> paper-ab0e3d3e4d42369de5933a3b4c237780b41c0d77</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/ab0e3d3e4d42369de5933a3b4c237780b41c0d77" target="_blank">Solving Quantitative Reasoning Problems with Language Models</a></p>
                <p><strong>Paper Venue:</strong> Neural Information Processing Systems</p>
                <p><strong>Paper Abstract:</strong> Language models have achieved remarkable performance on a wide range of tasks that require natural language understanding. Nevertheless, state-of-the-art models have generally struggled with tasks that require quantitative reasoning, such as solving mathematics, science, and engineering problems at the college level. To help close this gap, we introduce Minerva, a large language model pretrained on general natural language data and further trained on technical content. The model achieves state-of-the-art performance on technical benchmarks without the use of external tools. We also evaluate our model on over two hundred undergraduate-level problems in physics, biology, chemistry, economics, and other sciences that require quantitative reasoning, and find that the model can correctly answer nearly a third of them.</p>
                <p><strong>Cost:</strong> 0.015</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e4628.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e4628.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including mechanisms, representations, performance, and failure modes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Minerva</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Minerva (math-finetuned PaLM family models)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A family of autoregressive transformer language models (based on PaLM) finetuned on a large technical dataset containing LaTeX/math webpages and arXiv papers to improve quantitative reasoning and arithmetic/symbolic manipulation without external tools.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Minerva (PaLM-based: 8B, 62B, 540B)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Decoder-only transformer models continued from PaLM pretrained checkpoints. Sizes: ~8.63B, 62.50B, 540.35B parameters. Continued unsupervised finetuning on ~38.5B technical tokens (math webpages + arXiv + small amount of general NL); context length 2048; autoregressive objective; no external calculator/tools at inference.</td>
                        </tr>
                        <tr>
                            <td><strong>arithmetic_task_type</strong></td>
                            <td>multi-digit integer addition (10- and 18-digit), school/math word problems (addition/subtraction/multiplication/division), multi-step algebraic calculation, symbolic manipulation</td>
                        </tr>
                        <tr>
                            <td><strong>mechanism_hypothesis</strong></td>
                            <td>Arithmetic ability arises from a combination of: (1) statistical pattern learning over mathematical notation and sequences preserved by training on LaTeX/math content (enabling token-level symbolic manipulations), (2) memorization/recall of intermediate numeric facts and identities, and (3) learned chain-of-thought style generation (autoregressive stepwise reasoning) rather than explicit external algorithmic computation.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_for_mechanism</strong></td>
                            <td>Finetuning on math-focused data (LaTeX preserved) correlates with strong gains; models produce step-by-step solutions in LaTeX; manual analyses show frequent recall of intermediate facts (square roots, moments of inertia, trig identities) used in solutions; majority-voting on sampled chain-of-thought outputs substantially improves final-answer accuracy, implying distributional concentration on correct reasoning trajectories.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_against_mechanism</strong></td>
                            <td>Memorization analyses (BLEU search across training corpus and modified-problem robustness) find little evidence of direct memorization of exact test problems/solutions; removing outputs with high BLEU to ground truth barely degrades majority-vote accuracy, arguing performance is not simply rote memorization of full solutions.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Table 3 & text: On quantitative benchmarks (few-shot): Minerva 62B maj1@k (k large) MATH 43.4%, Minerva 62B maj1@k GSM8k 68.5% (maj1@k = majority vote with many samples); Minerva 540B maj1@k MATH 50.3%, GSM8k 78.5%. Appendix H (basic arithmetic): Minerva 540B achieves >80% accuracy on 10-digit addition and >20% accuracy on 18-digit addition. Failure/false-positive stats: estimated average false positive rate for 62B on MATH ~8% (difficulty-dependent up to 30% at highest difficulty).</td>
                        </tr>
                        <tr>
                            <td><strong>probing_or_intervention_results</strong></td>
                            <td>Memorization probes: BLEU search of top-correct samples against training corpus (no exact matches found among inspected top hits); robustness tests: 20 manually-modified problems (wording/numbers) showed correlated accuracies with originals (no strong reliance on exact memorization). Removing high-BLEU outputs had limited effect on majority-vote accuracy. Manual inspection of 100 MATH answers used to estimate false positive rates per difficulty level. No neuron-level probes or causal interventions reported.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_and_failure_modes</strong></td>
                            <td>Reported dominant failure modes: incorrect reasoning (most common), incorrect calculation (many are benign arithmetic mistakes), misunderstanding the question, using incorrect facts, solution too short, hallucinated math objects. Quantitatively (Table 4 on 201 samples): incorrect reasoning 82, incorrect calculation 70, misunderstand question 22, incorrect fact 16, hallucinated math objects 4. Long-digit arithmetic degrades (18-digit addition accuracy low ~20%); model lacks access to external calculators so struggles with complicated numerical computation; false positives increase with problem difficulty (up to ~30% at hardest).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Compared to PaLM baselines (same architectures before math finetuning) and OpenAI davinci-002: Minerva substantially outperforms pretrained PaLM and davinci-002 on MATH/GSM8k/MMLU-STEM when using chain-of-thought prompting + majority voting. Example: PaLM 62B few-shot MATH 4.4% vs Minerva 62B 27.6% (single sample), and Minerva 62B maj1@k 43.4%. Published SOTA numbers listed for reference (some external baselines), and Minerva 540B maj1@k reaches reported SOTA on several tasks in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title_in_paper</strong></td>
                            <td>Solving Quantitative Reasoning Problems with Language Models</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Solving Quantitative Reasoning Problems with Language Models', 'publication_date_yy_mm': '2022-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4628.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e4628.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including mechanisms, representations, performance, and failure modes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Memorization (as mechanism)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Memorization / recall of intermediate facts and solutions</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The paper examines memorization as a contributor to arithmetic performance, distinguishing memorization of intermediate facts (numbers, identities) from memorizing entire problem–solution pairs; concludes memorization of facts plays a role but full-problem memorization is unlikely to explain performance.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Minerva / general LLMs (discussion)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Discussion-level claim about LLMs trained on large corpora containing mathematical content; not a separate trained model.</td>
                        </tr>
                        <tr>
                            <td><strong>arithmetic_task_type</strong></td>
                            <td>intermediate-fact recall (square roots, trig identities), arithmetic/subexpression recall</td>
                        </tr>
                        <tr>
                            <td><strong>mechanism_hypothesis</strong></td>
                            <td>Models may rely on memorized numeric constants and identities to carry out multi-step solutions; stronger performance could be attributable to recall of intermediate steps or facts combined with generative composition.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_for_mechanism</strong></td>
                            <td>Authors observe many solutions that rely on recalled intermediate facts (e.g., moments of inertia, numerical square roots, trigonometric identities) and that these facts are crucial elements of produced solutions. Model trained on LaTeX math preserves such facts in tokens.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_against_mechanism</strong></td>
                            <td>BLEU-based corpus search across training data for top-correct samples found no exact matches for the evaluated problems; modifying problems (wording/numbers) maintained correlated accuracy, suggesting not simply memorized full solutions. Removing outputs with high BLEU had limited effect on majority-vote accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Not a model per se; relevant quantitative findings: 160/5000 test questions had a sample with BLEU >=80; false positive rates and modification experiments indicate memorization alone cannot explain majority-vote performance.</td>
                        </tr>
                        <tr>
                            <td><strong>probing_or_intervention_results</strong></td>
                            <td>BLEU search of 100 highest-confidence correct problem-solution pairs over math webpages dataset and manual inspection of top 250 matches; robustness to problem modifications; BLEU-threshold ablations where removing high-BLEU samples did not strongly reduce majority-vote accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_and_failure_modes</strong></td>
                            <td>Authors note that memorization of intermediate facts is real and important, but models still fail when arithmetic manipulation or multi-step composition is required; memorization of entire problems/solutions not supported by their searches but partial memorization can produce plausible-sounding yet incorrect chains (false positives).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Discussion relative to prior memorization literature (Trinh & Le 2018, Radford et al. 2019, Carlini et al. 2022) but no direct cross-model memorization ablation beyond Minerva's analyses.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Solving Quantitative Reasoning Problems with Language Models', 'publication_date_yy_mm': '2022-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4628.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e4628.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including mechanisms, representations, performance, and failure modes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Chain-of-Thought + Majority Voting</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Chain-of-thought prompting, scratchpad-style reasoning, and majority-vote sampling</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Inference-time techniques used to elicit and amplify step-by-step reasoning in LLM outputs (chain-of-thought or scratchpad), and to improve final-answer reliability by sampling multiple solutions and selecting the most common final answer (majority voting).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Minerva (evaluated with chain-of-thought prompts and majority voting)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>The paper uses chain-of-thought prompting during sampling (few-shot examples that include step-by-step solutions) and samples k outputs (nucleus sampling T=0.6) then applies majority voting (maj1@k) to pick final answers.</td>
                        </tr>
                        <tr>
                            <td><strong>arithmetic_task_type</strong></td>
                            <td>multi-step arithmetic and symbolic problem solving (MATH/GSM8k/MMLU-STEM), basic arithmetic as part of multi-step solutions</td>
                        </tr>
                        <tr>
                            <td><strong>mechanism_hypothesis</strong></td>
                            <td>Chain-of-thought elicits intermediate reasoning tokens that the autoregressive model can follow to synthesize arithmetic steps; majority voting reduces error by selecting the most common final answer across stochastic samples, capitalizing on the fact that correct answers occupy a concentrated mode in the model's output distribution.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_for_mechanism</strong></td>
                            <td>Large empirical gains when using chain-of-thought + majority voting: e.g., Minerva 62B maj1@k MATH 43.4% vs single-sample 27.6%; Minerva 540B maj1@k MATH 50.3% vs single-sample 33.6%. Figure 6 and Table 7 show majority voting saturates quickly while pass@k continues improving, consistent with selecting a dominant correct mode.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_against_mechanism</strong></td>
                            <td>Majority-vote outputs can include false positives (correct final answer with incorrect chain); manual checking shows non-negligible false positive rates, especially at high difficulty and for pass@k tails. Log-likelihood reranking was less effective than majority voting, suggesting confidence scores alone are not sufficient.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>See Table 3 and Table 7: majority-vote results: Minerva 8B maj1@256 MATH 25.4% (vs 14.1% single); Minerva 62B maj1@256 MATH 43.4% (vs 27.6% single); Minerva 62B maj5@k MATH 64.9% for k=256; pass@256 can be much higher (reported pass@256 accuracy ~84.5% for 62B before false-positive removal).</td>
                        </tr>
                        <tr>
                            <td><strong>probing_or_intervention_results</strong></td>
                            <td>Empirical sweep over number of samples k (Figure 6) showing majority voting saturates (most accuracy achieved by k~64 for MATH) and pass@k continues to improve; comparison vs log-likelihood reranking (Table 8) shows majority voting substantially better than likelihood-based reranking.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_and_failure_modes</strong></td>
                            <td>Majority voting can hide incorrect chains (false positives); pass@k improvements may reflect rare correct samples rather than consistent reasoning; majority voting saturates and cannot fix systematic biases or arithmetic blunders that dominate the model distribution.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Technique compared (empirically) across Minerva sizes and to davinci-002 where used; majority voting beneficial across models but magnitude of gain depends on model/data (larger Minerva models benefit more).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Solving Quantitative Reasoning Problems with Language Models', 'publication_date_yy_mm': '2022-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4628.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e4628.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including mechanisms, representations, performance, and failure modes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Math-aware Pretraining (LaTeX/web + arXiv)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Finetuning on LaTeX-preserving math webpages and arXiv papers</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The paper emphasizes that preserving LaTeX/math notation in the finetuning data exposes the model to explicit symbolic mathematical language, which enables better token-level calculation and symbolic manipulation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Minerva (training data / representation change)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Continued unsupervised finetuning on 38.5B tokens composed of ~17.5B math webpages (MathJax/LaTeX extracted), ~21B arXiv LaTeX papers, plus small general NL subset; cleaning preserves mathematical notation and formatting.</td>
                        </tr>
                        <tr>
                            <td><strong>arithmetic_task_type</strong></td>
                            <td>symbolic manipulation, algebraic derivations, numeric computations embedded in LaTeX tokens</td>
                        </tr>
                        <tr>
                            <td><strong>mechanism_hypothesis</strong></td>
                            <td>Exposure to raw LaTeX/math tokens allows the model to learn representations that respect syntactic structure of formulas and to statistically model sequences of mathematical tokens, improving its ability to generate correct formulas and perform token-level arithmetic reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_for_mechanism</strong></td>
                            <td>Models finetuned on this technical dataset (Minerva) substantially outperform PaLM baselines on mathematical reasoning tasks; authors attribute improvements to preserving mathematical notation in training data which makes formulae like e^{ai}+1=0 presented in full to the model during training.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_against_mechanism</strong></td>
                            <td>No direct representational probes (e.g., embeddings/attention analyses) are provided; absence of explicit evidence tying learned token representations to algorithmic arithmetic computation beyond performance gains.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Training-data attribution: Minerva models (finetuned) achieve large gains vs PaLM: e.g., PaLM 62B few-shot MATH 4.4% vs Minerva 62B 27.6% (single-sample). This empirical improvement is presented as evidence that the math-aware dataset helps arithmetic/symbolic tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>probing_or_intervention_results</strong></td>
                            <td>No neuron-level or attention probing reported; evidence limited to ablations comparing models before/after finetuning and dataset description.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_and_failure_modes</strong></td>
                            <td>While preserving LaTeX helps, models still make arithmetic mistakes and cannot reliably perform long-digit numeric computation; dataset curation gives little control over specific capabilities acquired; no guarantee of algorithmic correctness from token-level exposure alone.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Compared against original PaLM checkpoints (same architectures) demonstrating clear finetuning gains; also compared to external models (davinci-002) in downstream tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Solving Quantitative Reasoning Problems with Language Models', 'publication_date_yy_mm': '2022-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4628.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e4628.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including mechanisms, representations, performance, and failure modes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Basic arithmetic results (Appendix H)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Appendix H: evaluation of simple arithmetic (multi-digit addition)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Empirical evaluation of Minerva 540B's performance on straightforward long-integer addition tasks, showing degradation as digit length grows.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Minerva 540B</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Largest Minerva variant (540B) evaluated on synthetic long-digit addition benchmarks as reported in Appendix H.</td>
                        </tr>
                        <tr>
                            <td><strong>arithmetic_task_type</strong></td>
                            <td>multi-digit integer addition (10-digit, 18-digit)</td>
                        </tr>
                        <tr>
                            <td><strong>mechanism_hypothesis</strong></td>
                            <td>No explicit algorithmic addition mechanism; model manifests partial ability via learned token sequences/patterns but accuracy falls off with increased digit length, suggesting lack of robust algorithmic generalization for long numerical arithmetic.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_for_mechanism</strong></td>
                            <td>Empirical accuracies: >80% accuracy on 10-digit addition and >20% accuracy on 18-digit addition for Minerva 540B (Appendix H). This shows capability at moderate digit lengths but rapid degradation as length increases.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_against_mechanism</strong></td>
                            <td>No evidence of an internal systematic algorithm (e.g., digit-wise carry circuits); steep drop in accuracy with digit length argues against learned perfect algorithmic addition.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Minerva 540B: >80% on 10-digit addition, >20% on 18-digit addition (as reported in Appendix H).</td>
                        </tr>
                        <tr>
                            <td><strong>probing_or_intervention_results</strong></td>
                            <td>No targeted probes or interventions for digit-wise mechanisms; only aggregate accuracy numbers reported.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_and_failure_modes</strong></td>
                            <td>Performance quickly degrades with longer numbers; model makes arithmetic/carry errors; absence of external calculators limits exact numeric computation; no guaranteed correctness even when chain-of-thought looks plausible.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>No direct head-to-head long-digit-addition comparison to other models provided in Appendix H; comparison is implicit via overall benchmark performance vs other models in main tables.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Solving Quantitative Reasoning Problems with Language Models', 'publication_date_yy_mm': '2022-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Chain of thought prompting elicits reasoning in large language models <em>(Rating: 2)</em></li>
                <li>Self-consistency improves chain of thought reasoning in language models <em>(Rating: 2)</em></li>
                <li>Training verifiers to solve math word problems <em>(Rating: 2)</em></li>
                <li>PaLM: Scaling language modeling with pathways <em>(Rating: 2)</em></li>
                <li>A neural network solves, explains, and generates university math problems by program synthesis and few-shot learning at human level <em>(Rating: 1)</em></li>
                <li>Evaluating large language models trained on code <em>(Rating: 1)</em></li>
                <li>Quantifying memorization across neural language models <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-4628",
    "paper_id": "paper-ab0e3d3e4d42369de5933a3b4c237780b41c0d77",
    "extraction_schema_id": "extraction-schema-102",
    "extracted_data": [
        {
            "name_short": "Minerva",
            "name_full": "Minerva (math-finetuned PaLM family models)",
            "brief_description": "A family of autoregressive transformer language models (based on PaLM) finetuned on a large technical dataset containing LaTeX/math webpages and arXiv papers to improve quantitative reasoning and arithmetic/symbolic manipulation without external tools.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Minerva (PaLM-based: 8B, 62B, 540B)",
            "model_description": "Decoder-only transformer models continued from PaLM pretrained checkpoints. Sizes: ~8.63B, 62.50B, 540.35B parameters. Continued unsupervised finetuning on ~38.5B technical tokens (math webpages + arXiv + small amount of general NL); context length 2048; autoregressive objective; no external calculator/tools at inference.",
            "arithmetic_task_type": "multi-digit integer addition (10- and 18-digit), school/math word problems (addition/subtraction/multiplication/division), multi-step algebraic calculation, symbolic manipulation",
            "mechanism_hypothesis": "Arithmetic ability arises from a combination of: (1) statistical pattern learning over mathematical notation and sequences preserved by training on LaTeX/math content (enabling token-level symbolic manipulations), (2) memorization/recall of intermediate numeric facts and identities, and (3) learned chain-of-thought style generation (autoregressive stepwise reasoning) rather than explicit external algorithmic computation.",
            "evidence_for_mechanism": "Finetuning on math-focused data (LaTeX preserved) correlates with strong gains; models produce step-by-step solutions in LaTeX; manual analyses show frequent recall of intermediate facts (square roots, moments of inertia, trig identities) used in solutions; majority-voting on sampled chain-of-thought outputs substantially improves final-answer accuracy, implying distributional concentration on correct reasoning trajectories.",
            "evidence_against_mechanism": "Memorization analyses (BLEU search across training corpus and modified-problem robustness) find little evidence of direct memorization of exact test problems/solutions; removing outputs with high BLEU to ground truth barely degrades majority-vote accuracy, arguing performance is not simply rote memorization of full solutions.",
            "performance_metrics": "Table 3 & text: On quantitative benchmarks (few-shot): Minerva 62B maj1@k (k large) MATH 43.4%, Minerva 62B maj1@k GSM8k 68.5% (maj1@k = majority vote with many samples); Minerva 540B maj1@k MATH 50.3%, GSM8k 78.5%. Appendix H (basic arithmetic): Minerva 540B achieves &gt;80% accuracy on 10-digit addition and &gt;20% accuracy on 18-digit addition. Failure/false-positive stats: estimated average false positive rate for 62B on MATH ~8% (difficulty-dependent up to 30% at highest difficulty).",
            "probing_or_intervention_results": "Memorization probes: BLEU search of top-correct samples against training corpus (no exact matches found among inspected top hits); robustness tests: 20 manually-modified problems (wording/numbers) showed correlated accuracies with originals (no strong reliance on exact memorization). Removing high-BLEU outputs had limited effect on majority-vote accuracy. Manual inspection of 100 MATH answers used to estimate false positive rates per difficulty level. No neuron-level probes or causal interventions reported.",
            "limitations_and_failure_modes": "Reported dominant failure modes: incorrect reasoning (most common), incorrect calculation (many are benign arithmetic mistakes), misunderstanding the question, using incorrect facts, solution too short, hallucinated math objects. Quantitatively (Table 4 on 201 samples): incorrect reasoning 82, incorrect calculation 70, misunderstand question 22, incorrect fact 16, hallucinated math objects 4. Long-digit arithmetic degrades (18-digit addition accuracy low ~20%); model lacks access to external calculators so struggles with complicated numerical computation; false positives increase with problem difficulty (up to ~30% at hardest).",
            "comparison_to_other_models": "Compared to PaLM baselines (same architectures before math finetuning) and OpenAI davinci-002: Minerva substantially outperforms pretrained PaLM and davinci-002 on MATH/GSM8k/MMLU-STEM when using chain-of-thought prompting + majority voting. Example: PaLM 62B few-shot MATH 4.4% vs Minerva 62B 27.6% (single sample), and Minerva 62B maj1@k 43.4%. Published SOTA numbers listed for reference (some external baselines), and Minerva 540B maj1@k reaches reported SOTA on several tasks in this paper.",
            "citation_title_in_paper": "Solving Quantitative Reasoning Problems with Language Models",
            "uuid": "e4628.0",
            "source_info": {
                "paper_title": "Solving Quantitative Reasoning Problems with Language Models",
                "publication_date_yy_mm": "2022-06"
            }
        },
        {
            "name_short": "Memorization (as mechanism)",
            "name_full": "Memorization / recall of intermediate facts and solutions",
            "brief_description": "The paper examines memorization as a contributor to arithmetic performance, distinguishing memorization of intermediate facts (numbers, identities) from memorizing entire problem–solution pairs; concludes memorization of facts plays a role but full-problem memorization is unlikely to explain performance.",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": "Minerva / general LLMs (discussion)",
            "model_description": "Discussion-level claim about LLMs trained on large corpora containing mathematical content; not a separate trained model.",
            "arithmetic_task_type": "intermediate-fact recall (square roots, trig identities), arithmetic/subexpression recall",
            "mechanism_hypothesis": "Models may rely on memorized numeric constants and identities to carry out multi-step solutions; stronger performance could be attributable to recall of intermediate steps or facts combined with generative composition.",
            "evidence_for_mechanism": "Authors observe many solutions that rely on recalled intermediate facts (e.g., moments of inertia, numerical square roots, trigonometric identities) and that these facts are crucial elements of produced solutions. Model trained on LaTeX math preserves such facts in tokens.",
            "evidence_against_mechanism": "BLEU-based corpus search across training data for top-correct samples found no exact matches for the evaluated problems; modifying problems (wording/numbers) maintained correlated accuracy, suggesting not simply memorized full solutions. Removing outputs with high BLEU had limited effect on majority-vote accuracy.",
            "performance_metrics": "Not a model per se; relevant quantitative findings: 160/5000 test questions had a sample with BLEU &gt;=80; false positive rates and modification experiments indicate memorization alone cannot explain majority-vote performance.",
            "probing_or_intervention_results": "BLEU search of 100 highest-confidence correct problem-solution pairs over math webpages dataset and manual inspection of top 250 matches; robustness to problem modifications; BLEU-threshold ablations where removing high-BLEU samples did not strongly reduce majority-vote accuracy.",
            "limitations_and_failure_modes": "Authors note that memorization of intermediate facts is real and important, but models still fail when arithmetic manipulation or multi-step composition is required; memorization of entire problems/solutions not supported by their searches but partial memorization can produce plausible-sounding yet incorrect chains (false positives).",
            "comparison_to_other_models": "Discussion relative to prior memorization literature (Trinh & Le 2018, Radford et al. 2019, Carlini et al. 2022) but no direct cross-model memorization ablation beyond Minerva's analyses.",
            "uuid": "e4628.1",
            "source_info": {
                "paper_title": "Solving Quantitative Reasoning Problems with Language Models",
                "publication_date_yy_mm": "2022-06"
            }
        },
        {
            "name_short": "Chain-of-Thought + Majority Voting",
            "name_full": "Chain-of-thought prompting, scratchpad-style reasoning, and majority-vote sampling",
            "brief_description": "Inference-time techniques used to elicit and amplify step-by-step reasoning in LLM outputs (chain-of-thought or scratchpad), and to improve final-answer reliability by sampling multiple solutions and selecting the most common final answer (majority voting).",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "Minerva (evaluated with chain-of-thought prompts and majority voting)",
            "model_description": "The paper uses chain-of-thought prompting during sampling (few-shot examples that include step-by-step solutions) and samples k outputs (nucleus sampling T=0.6) then applies majority voting (maj1@k) to pick final answers.",
            "arithmetic_task_type": "multi-step arithmetic and symbolic problem solving (MATH/GSM8k/MMLU-STEM), basic arithmetic as part of multi-step solutions",
            "mechanism_hypothesis": "Chain-of-thought elicits intermediate reasoning tokens that the autoregressive model can follow to synthesize arithmetic steps; majority voting reduces error by selecting the most common final answer across stochastic samples, capitalizing on the fact that correct answers occupy a concentrated mode in the model's output distribution.",
            "evidence_for_mechanism": "Large empirical gains when using chain-of-thought + majority voting: e.g., Minerva 62B maj1@k MATH 43.4% vs single-sample 27.6%; Minerva 540B maj1@k MATH 50.3% vs single-sample 33.6%. Figure 6 and Table 7 show majority voting saturates quickly while pass@k continues improving, consistent with selecting a dominant correct mode.",
            "evidence_against_mechanism": "Majority-vote outputs can include false positives (correct final answer with incorrect chain); manual checking shows non-negligible false positive rates, especially at high difficulty and for pass@k tails. Log-likelihood reranking was less effective than majority voting, suggesting confidence scores alone are not sufficient.",
            "performance_metrics": "See Table 3 and Table 7: majority-vote results: Minerva 8B maj1@256 MATH 25.4% (vs 14.1% single); Minerva 62B maj1@256 MATH 43.4% (vs 27.6% single); Minerva 62B maj5@k MATH 64.9% for k=256; pass@256 can be much higher (reported pass@256 accuracy ~84.5% for 62B before false-positive removal).",
            "probing_or_intervention_results": "Empirical sweep over number of samples k (Figure 6) showing majority voting saturates (most accuracy achieved by k~64 for MATH) and pass@k continues to improve; comparison vs log-likelihood reranking (Table 8) shows majority voting substantially better than likelihood-based reranking.",
            "limitations_and_failure_modes": "Majority voting can hide incorrect chains (false positives); pass@k improvements may reflect rare correct samples rather than consistent reasoning; majority voting saturates and cannot fix systematic biases or arithmetic blunders that dominate the model distribution.",
            "comparison_to_other_models": "Technique compared (empirically) across Minerva sizes and to davinci-002 where used; majority voting beneficial across models but magnitude of gain depends on model/data (larger Minerva models benefit more).",
            "uuid": "e4628.2",
            "source_info": {
                "paper_title": "Solving Quantitative Reasoning Problems with Language Models",
                "publication_date_yy_mm": "2022-06"
            }
        },
        {
            "name_short": "Math-aware Pretraining (LaTeX/web + arXiv)",
            "name_full": "Finetuning on LaTeX-preserving math webpages and arXiv papers",
            "brief_description": "The paper emphasizes that preserving LaTeX/math notation in the finetuning data exposes the model to explicit symbolic mathematical language, which enables better token-level calculation and symbolic manipulation.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "Minerva (training data / representation change)",
            "model_description": "Continued unsupervised finetuning on 38.5B tokens composed of ~17.5B math webpages (MathJax/LaTeX extracted), ~21B arXiv LaTeX papers, plus small general NL subset; cleaning preserves mathematical notation and formatting.",
            "arithmetic_task_type": "symbolic manipulation, algebraic derivations, numeric computations embedded in LaTeX tokens",
            "mechanism_hypothesis": "Exposure to raw LaTeX/math tokens allows the model to learn representations that respect syntactic structure of formulas and to statistically model sequences of mathematical tokens, improving its ability to generate correct formulas and perform token-level arithmetic reasoning.",
            "evidence_for_mechanism": "Models finetuned on this technical dataset (Minerva) substantially outperform PaLM baselines on mathematical reasoning tasks; authors attribute improvements to preserving mathematical notation in training data which makes formulae like e^{ai}+1=0 presented in full to the model during training.",
            "evidence_against_mechanism": "No direct representational probes (e.g., embeddings/attention analyses) are provided; absence of explicit evidence tying learned token representations to algorithmic arithmetic computation beyond performance gains.",
            "performance_metrics": "Training-data attribution: Minerva models (finetuned) achieve large gains vs PaLM: e.g., PaLM 62B few-shot MATH 4.4% vs Minerva 62B 27.6% (single-sample). This empirical improvement is presented as evidence that the math-aware dataset helps arithmetic/symbolic tasks.",
            "probing_or_intervention_results": "No neuron-level or attention probing reported; evidence limited to ablations comparing models before/after finetuning and dataset description.",
            "limitations_and_failure_modes": "While preserving LaTeX helps, models still make arithmetic mistakes and cannot reliably perform long-digit numeric computation; dataset curation gives little control over specific capabilities acquired; no guarantee of algorithmic correctness from token-level exposure alone.",
            "comparison_to_other_models": "Compared against original PaLM checkpoints (same architectures) demonstrating clear finetuning gains; also compared to external models (davinci-002) in downstream tasks.",
            "uuid": "e4628.3",
            "source_info": {
                "paper_title": "Solving Quantitative Reasoning Problems with Language Models",
                "publication_date_yy_mm": "2022-06"
            }
        },
        {
            "name_short": "Basic arithmetic results (Appendix H)",
            "name_full": "Appendix H: evaluation of simple arithmetic (multi-digit addition)",
            "brief_description": "Empirical evaluation of Minerva 540B's performance on straightforward long-integer addition tasks, showing degradation as digit length grows.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "Minerva 540B",
            "model_description": "Largest Minerva variant (540B) evaluated on synthetic long-digit addition benchmarks as reported in Appendix H.",
            "arithmetic_task_type": "multi-digit integer addition (10-digit, 18-digit)",
            "mechanism_hypothesis": "No explicit algorithmic addition mechanism; model manifests partial ability via learned token sequences/patterns but accuracy falls off with increased digit length, suggesting lack of robust algorithmic generalization for long numerical arithmetic.",
            "evidence_for_mechanism": "Empirical accuracies: &gt;80% accuracy on 10-digit addition and &gt;20% accuracy on 18-digit addition for Minerva 540B (Appendix H). This shows capability at moderate digit lengths but rapid degradation as length increases.",
            "evidence_against_mechanism": "No evidence of an internal systematic algorithm (e.g., digit-wise carry circuits); steep drop in accuracy with digit length argues against learned perfect algorithmic addition.",
            "performance_metrics": "Minerva 540B: &gt;80% on 10-digit addition, &gt;20% on 18-digit addition (as reported in Appendix H).",
            "probing_or_intervention_results": "No targeted probes or interventions for digit-wise mechanisms; only aggregate accuracy numbers reported.",
            "limitations_and_failure_modes": "Performance quickly degrades with longer numbers; model makes arithmetic/carry errors; absence of external calculators limits exact numeric computation; no guaranteed correctness even when chain-of-thought looks plausible.",
            "comparison_to_other_models": "No direct head-to-head long-digit-addition comparison to other models provided in Appendix H; comparison is implicit via overall benchmark performance vs other models in main tables.",
            "uuid": "e4628.4",
            "source_info": {
                "paper_title": "Solving Quantitative Reasoning Problems with Language Models",
                "publication_date_yy_mm": "2022-06"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Chain of thought prompting elicits reasoning in large language models",
            "rating": 2,
            "sanitized_title": "chain_of_thought_prompting_elicits_reasoning_in_large_language_models"
        },
        {
            "paper_title": "Self-consistency improves chain of thought reasoning in language models",
            "rating": 2,
            "sanitized_title": "selfconsistency_improves_chain_of_thought_reasoning_in_language_models"
        },
        {
            "paper_title": "Training verifiers to solve math word problems",
            "rating": 2,
            "sanitized_title": "training_verifiers_to_solve_math_word_problems"
        },
        {
            "paper_title": "PaLM: Scaling language modeling with pathways",
            "rating": 2,
            "sanitized_title": "palm_scaling_language_modeling_with_pathways"
        },
        {
            "paper_title": "A neural network solves, explains, and generates university math problems by program synthesis and few-shot learning at human level",
            "rating": 1,
            "sanitized_title": "a_neural_network_solves_explains_and_generates_university_math_problems_by_program_synthesis_and_fewshot_learning_at_human_level"
        },
        {
            "paper_title": "Evaluating large language models trained on code",
            "rating": 1,
            "sanitized_title": "evaluating_large_language_models_trained_on_code"
        },
        {
            "paper_title": "Quantifying memorization across neural language models",
            "rating": 1,
            "sanitized_title": "quantifying_memorization_across_neural_language_models"
        }
    ],
    "cost": 0.01526775,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Solving Quantitative Reasoning Problems with Language Models</h1>
<p>Aitor Lewkowycz<em>, Anders Andreassen ${ }^{\dagger}$, David Dohan ${ }^{\dagger}$, Ethan Dyer ${ }^{\dagger}$, Henryk Michalewski ${ }^{\dagger}$, Vinay Ramasesh ${ }^{\dagger}$, Ambrose Slone, Cem Anil, Imanol Schlag, Theo Gutman-Solo,<br>Yuhuai Wu, Behnam Neyshabur</em>, Guy Gur-Ari<em>, and Vedant Misra</em><br>Google Research</p>
<h4>Abstract</h4>
<p>Language models have achieved remarkable performance on a wide range of tasks that require natural language understanding. Nevertheless, state-of-the-art models have generally struggled with tasks that require quantitative reasoning, such as solving mathematics, science, and engineering problems at the college level. To help close this gap, we introduce Minerva, a large language model pretrained on general natural language data and further trained on technical content. The model achieves state-of-the-art performance on technical benchmarks without the use of external tools. We also evaluate our model on over two hundred undergraduate-level problems in physics, biology, chemistry, economics, and other sciences that require quantitative reasoning, and find that the model can correctly answer nearly a third of them.</p>
<h2>1 Introduction</h2>
<p>Artificial neural networks have seen remarkable success in a variety of domains including computer vision, speech recognition, audio and image generation, translation, game playing, and robotics. In particular, large language models have achieved excellent performance across a variety of natural language tasks including common-sense reasoning, question answering, and summarization (Raffel et al., 2019; Brown et al., 2020; Rae et al., 2021; Smith et al., 2022; Chowdhery et al., 2022). However, these models have struggled with tasks that require quantitative reasoning, such as solving mathematics, science, and engineering problems (Hendrycks et al., 2021; Cobbe et al., 2021).
Quantitative reasoning problems are an interesting domain of application for language models because they test the capability of models on several fronts. They require the solver to correctly parse a natural language input, potentially recall world knowledge that pertains to the problem, and apply an algorithm or series of computations to the information provided in order to arrive at a correct solution. They also require that the solver is able to correctly parse and generate precise sequences of mathematical tokens, as well as apply a computational procedure to tokens via symbolic and numerical manipulation. Finally, such problems are a proving ground for research toward robust quantitative reasoning solvers that are useful in supporting the work of humans in scientific and technical fields.</p>
<p>Previous research has shown that large language models achieve impressive performance on math and programming questions after training on domain specific datasets (Chen et al., 2021; Austin et al., 2021;</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>Question: A line parallel to $y=4 x+6$ passes through $(5,10)$. What is the $y$-coordinate of the point where this line crosses the $y$-axis?</p>
<p>Target: Since the line is parallel to $y=4 x+6$, we know that its slope is 4 . Thus the equation of the line is $y=4 x+b$ where $b$ is the $y$-intercept. Plugging $(5,10)$ into this gives $10=4 \cdot 5+b \Rightarrow b=\boxed{-10}$ which is what we wanted.</p>
<p>Model output: The line is parallel to $y=4 x+6$, which means that it has the same slope as $y=4 x+6$. Since the line passes through $(5,10)$, we can use the point-slope form of a line to find the equation of the line:</p>
<p>$$
\begin{aligned}
y-10 &amp; =4(x-5) \
y-10 &amp; =4 x-20 \
y &amp; =4 x-10
\end{aligned}
$$</p>
<p>Now that we have the equation of the line, we can find the $y$-coordinate of the point where the line crosses the $y$-axis by substituting $x=0$ into the equation:</p>
<p>$$
y=4 \cdot 0-10=\boxed{-10}
$$</p>
<p>Figure 1: Question from the MATH dataset (Algebra 4) with a solution generated by Minerva 62B. The solution was selected by majority vote over 256 samples. This and other MATH questions were prompted with the same 4 -shot prompt. The model derives the solution by writing down a line equation, simplifying it, substituting $x$, and solving for $y$. The model outputs valid $\mathrm{LAT}_{\mathrm{E}} \mathrm{X}$ along with natural language explanations. The approach taken by the model is different from the one used in the ground truth target.</p>
<p>Drori et al., 2021). In this work, we apply this approach to quantitative reasoning problems, in which the model is required to provide a complete and self-contained solution, without relying on external tools. Such tasks include mathematics word problems, competition mathematics evaluations, and many problems in science and engineering.</p>
<h1>1.1 Our Contribution</h1>
<p>We present Minerva, a language model that achieves strong performance on many quantitative reasoning tasks. Our model is able to process scientific and mathematical questions formulated in natural language, and generate step-by-step solutions using correct $\mathrm{LAT}_{\mathrm{E}} \mathrm{X}$ notation. Figures 1, 2 and 3 show example responses from Minerva to mathematics and physics questions.
Minerva is based on the PaLM general language models Chowdhery et al. (2022) that are further trained on a high-quality dataset containing scientific and mathematical data. In particular, we start with 8B, 62B, and 540 B parameter pretrained models, and continue training them on our technical content dataset. We achieve state-of-the-art performance on MATH Hendrycks et al. (2021), GSM8k Cobbe et al. (2021), and a STEM subset of the MMLU Hendrycks et al. (2020) dataset, all of which include math and science questions formulated in natural language. Notably, our models achieve robust performance in a few-shot setting without being explicitly trained on these evaluation datasets.
The main novelty of this paper is a large training dataset that juxtaposes natural language with the correct use of formal mathematical language, such as equations and diagrams. The data is collected from the arXiv preprint server and from web pages that we carefully process to minimise the loss of mathematical content. In addition to establishing new state-of-the-art results, this work establishes a new baseline for the performance achievable on quantitative reasoning benchmarks by increasing data quality and model size.
To further increase the coverage of quantitative reasoning benchmarks, we build a dataset of over 200</p>
<p>Question: Assume that the variance of the first $n$ natural numbers is 10 , and the variance of the first $m$ even natural numbers is 16 . Compute $m+n$.</p>
<p>Model output: Let $\sigma^{2}$ be the variance of the first $m$ even natural numbers, and $\tau^{2}$ be the variance of the first $n$ natural numbers. Then, we have $\tau^{2}=\frac{n^{2}-1}{12}$ and $\sigma^{2}=\frac{m^{2}-1}{3}$. We solve the system of equations:</p>
<p>$$
\begin{aligned}
&amp; \frac{n^{2}-1}{12}=10 \
&amp; \frac{m^{2}-1}{3}=16
\end{aligned}
$$</p>
<p>This translates into the system</p>
<p>$$
\begin{gathered}
n^{2}=121 \
m^{2}=48+1=49
\end{gathered}
$$</p>
<p>Therefore, $n=\underline{11}$ and $m=\underline{7}$, so $n+m=$ 18 .</p>
<p>Question: For every $a, b, b \neq a$ prove that</p>
<p>$$
\frac{a^{2}+b^{2}}{2}&gt;\left(\frac{a+b}{2}\right)^{2}
$$</p>
<h2>Model output:</h2>
<p>$$
\begin{gathered}
\frac{a^{2}+b^{2}}{2}&gt;\left(\frac{a+b}{2}\right)^{2} \
\Longleftrightarrow \frac{a^{2}+b^{2}}{2}&gt;\frac{a^{2}+b^{2}+2 a b}{4} \
\Longleftrightarrow a^{2}+b^{2}&gt;\frac{a^{2}+b^{2}+2 a b}{2} \
\Longleftrightarrow 2 a^{2}+2 b^{2}&gt;a^{2}+b^{2}+2 a b \
\Longleftrightarrow a^{2}+b^{2}&gt;2 a b \
\Longleftrightarrow a^{2}+b^{2}-2 a b&gt;0 \
\Longleftrightarrow(a-b)^{2}&gt;0
\end{gathered}
$$</p>
<p>which is true, because the square of a real number is positive.</p>
<p>Figure 2: Example questions with solutions from Minerva 540B. Left: Question from the Joint Entrance Examination Main Math 2020 exam taken each year by almost 2 M Indian high-school students intending to study engineering and similar fields. Right: Question from the National Math Exam in Poland (May 2022). The exam is taken by approximately 270 K high-school students every year.
undergraduate-level questions in science and mathematics from MIT's OpenCourseWare (OCW). This provides a measure of our model's quantitative reasoning abilities in a chain-of-thought context beyond a pure mathematical setting.</p>
<h1>1.2 Related Works</h1>
<p>Solving quantitative reasoning problems expressed in natural language has been an active area of study (Koncel-Kedziorski et al., 2015; Hosseini et al., 2014). Prompting language models using scratchpad Nye et al. (2021) or chain-of-thought Wei et al. (2022) solutions can lead them to output step-by-step solutions to unseen problems. The GSM8k work Cobbe et al. (2021) showed that training verifiers to rerank model outputs can lead to improved performance. The original version of GSM8k included special syntax for algebraic calculations, which were processed by a calculator. In this work we focus on self-contained models without access to external tools.
The standard method for evaluating language models on generative tasks is to greedily sample one solution per problem. Recent works (Chen et al., 2021; Li et al., 2022; Thoppilan et al., 2022; Wang et al., 2022) have shown that it is advantageous to sample multiple solutions per problem, and then filter those down to a final answer. We find that majority voting (Wang et al., 2022) significantly improves performance over greedy decoding.
The work Drori et al. (2021) includes an evaluation of davinci-002, OpenAI's latest publicly available language</p>
<p>Question: A uniform solid disk starts from rest and rolls down an inclined plane without slipping. After some time, what fraction of the disk's total kinetic energy is rotational kinetic energy? What of the following is the right choice? Explain you answer.
(A) $1 / 4$ (B) $1 / 3$ (C) $1 / 2$ (D) $2 / 3$</p>
<p>Model output: The disk has both translational and rotational kinetic energy. Let $v$ be the speed of the center of mass of the disk, $I$ be the moment of inertia of the disk, $M$ be the mass of the disk, and $R$ be the radius of the disk. The translational kinetic energy of the disk is given by</p>
<p>$$
K_{t}=\frac{1}{2} M v^{2}
$$</p>
<p>The rotational kinetic energy of the disk is given by</p>
<p>$$
K_{r}=\frac{1}{2} I \omega^{2}=\frac{1}{2}\left(\frac{1}{2} M R^{2}\right)\left(\frac{v}{R}\right)^{2}=\frac{1}{4} M v^{2}
$$</p>
<p>Therefore, the ratio of the rotational kinetic energy to the total kinetic energy is</p>
<p>$$
\frac{K_{r}}{K_{t}+K_{r}}=\frac{\frac{1}{4} M v^{2}}{\frac{1}{2} M v^{2}+\frac{1}{4} M v^{2}}=\frac{\frac{1}{4} M v^{2}}{\frac{1}{4} M v^{2}}=\frac{1}{3}
$$</p>
<p>Final Answer: The final answer is (B).</p>
<p>Question: A particle moves so that it is at $\left(3 \sin \frac{t}{4}, 3 \cos \frac{t}{4}\right)$ at time $t$. Find the speed of the particle, measured in unit of distance per unit of time.</p>
<p>Target: The parametric curve $(x, y)=\left(3 \sin \frac{t}{4}, 3 \cos \frac{t}{4}\right)$ describes a circle with radius 3 . Furthermore, it makes a full revolution at time $t=8 \pi$. (figure) Therefore, the speed of the particle is $\frac{6 \pi}{8 \pi}=\left[\frac{3}{4}\right]$.</p>
<p>Model output: The speed is the magnitude of the velocity vector. Therefore, we must first find the velocity vector, which is the derivative of the position vector. We have</p>
<p>$$
\mathbf{v}=\frac{d}{d t}\left(3 \sin \frac{t}{4}, 3 \cos \frac{t}{4}\right)=3\left(\cos \frac{t}{4},-\sin \frac{t}{4}\right) \frac{1}{4}=\left(\frac{3}{4} \cos \frac{t}{4},-\frac{3}{4} \sin \frac{t}{4}\right)
$$</p>
<p>Therefore, the magnitude of the velocity vector is</p>
<p>$$
\begin{aligned}
|\mathbf{v}| &amp; =\sqrt{\left(\frac{3}{4} \cos \frac{t}{4}\right)^{2}+\left(-\frac{3}{4} \sin \frac{t}{4}\right)^{2}}=\sqrt{\frac{9}{16} \cos ^{2} \frac{t}{4}+\frac{9}{16} \sin ^{2} \frac{t}{4}} \
&amp; =\frac{3}{4} \sqrt{\cos ^{2} \frac{t}{4}+\sin ^{2} \frac{t}{4}}=\frac{3}{4}
\end{aligned}
$$</p>
<p>Therefore, the speed of the particle is $\left[\frac{3}{4}\right]$.</p>
<p>Figure 3: Physics questions with their Minerva solutions. Top: Example question from MMLU (College Physics) and the solution generated by Minerva 540B. The model introduces notation to describe the moving object's physical properties, writes down the relevant physical relationships, recalls the moment of inertia of a solid disk, and then correctly computes the desired energy ratio. Bottom: Question from the MATH dataset (Precalculus 4). The model correctly takes the derivative of a position vector to compute the velocity. It then computes the norm of the resulting vector, and uses a trigonometric identity to obtain a final numerical answer. Minerva takes a completely different approach from the ground truth solution.</p>
<p>model, on a subset of 90 problems from the MATH dataset. Due to the focus on a subset of questions, as well as changes made to the way questions are formatted, it is difficult to directly compare our results with those of Drori et al. (2021). In Section 3, we compare OpenAI davinci-002 with our models under the same experimental conditions.</p>
<p>Code generation. Applying code generating models to mathematical problems has been an active area of exploration. PaLM Chowdhery et al. (2022) showed that a large language model with code in its training dataset can achieve good performance on a code version of GSM8k. Furthermore, the Codex model (Chen et al., 2021) can generate code solutions to MATH problems Drori et al. (2021). These solutions often rely on external libraries to perform mathematical operations such as solving equations or taking limits. This is a complementary approach to ours, in which we directly probe the model's ability to arrive at an answer by relying only on its own reasoning capability.</p>
<p>Formal mathematics. Mathematics developed as a discipline based in natural language, but its axiomatic fundamentals make it possible to simulate mathematical thinking. This can be achieved using specialized programming languages that facilitate the simulation of logical and mathematical thinking using a computer, such as Coq (development team, 2022), Isabelle (Wenzel et al., 2008), HOL4 (Harrison, 1996), Lean (de Moura et al., 2015), Metamath (Megill and Wheeler, 2019) and Mizar (Grabowski et al., 2010). Work on automation of proof assistants and automated theorem provers such as E (Schulz, 2013), leanCoP (Otten, 2008), and Vampire (Kovács and Voronkov, 2013) has substantially benefited from integration with machine learning methods (Alemi et al., 2016; Goertzel et al., 2021; Li et al., 2021; Polu and Sutskever, 2020; Kaliszyk et al., 2018).</p>
<p>Language models applied to formal and synthetic mathematical problems. Previous work trained language models to predict mathematical expressions Rabe et al. (2021); Li et al. (2021); Polu and Sutskever (2020); Wu et al. (2021); Han et al. (2022); Polu et al. (2022); Jiang et al. (2022); Wu et al. (2022). In turn, such a predictive model can be used to guide a proof search, as done by Polu and Sutskever (2020). Large language models excel in modelling natural language, though in the case of formal languages, models that facilitate retaining information about the graph structure of a given mathematical formula, such as GNNs, are still very competitive.</p>
<p>Modelling mathematics as a discipline of natural language. New benchmark datasets (Hendrycks et al., 2021; Welleck et al., 2021) cover more advanced mathematical topics. In this domain language models are facing limited competition from other classes of models.</p>
<h1>2 Training and Evaluation</h1>
<h3>2.1 Mathematical Training Dataset</h3>
<p>Our models were trained on a dataset of 38.5 B tokens from webpages filtered for mathematical content and from papers submitted to the arXiv preprint server. In addition, the dataset includes general natural language data, which is the same dataset that was used for pretraining PaLM. Our mathematical webpage dataset was constructed by collecting pages that contain mathematical expressions in MathJax format. The pages underwent a cleaning process that removes most HTML tags but preserves mathematical notation, including $\mathrm{LAT}_{\mathrm{E}} \mathrm{X}$ symbols and formatting. The result is that mathematical formulae like $e^{a i}+1=0$ or $E=m c^{2}$ are presented in full to the model during training. This procedure makes it possible for the model to perform well on tasks that require calculation and symbolic manipulation. Table 1 provides a breakdown of the training dataset. See Appendix B for more details.</p>
<p>Table 1: Proportion of data, and number of tokens, from each source in the technical training dataset. The General Natural Language dataset is a subset of the dataset used to pretrain the model.</p>
<table>
<thead>
<tr>
<th>Data source</th>
<th>Proportion of data</th>
<th>Tokens</th>
<th>Present during pretraining</th>
</tr>
</thead>
<tbody>
<tr>
<td>Math Web Pages</td>
<td>47.5%</td>
<td>17.5B</td>
<td>No</td>
</tr>
<tr>
<td>arXiv</td>
<td>47.5%</td>
<td>21.0B</td>
<td>No</td>
</tr>
<tr>
<td>General Natural Language Data</td>
<td>5%</td>
<td>&gt;100B</td>
<td>Yes</td>
</tr>
</tbody>
</table>
<h3>2.2 Models and Training Procedure</h3>
<p>Our approach is to start with the PaLM pretrained decoder-only transformer language models <em>Chowdhery et al. (2022)</em>, and further train (finetune) them on our mathematical dataset using an autoregressive objective. Table 2 contains the main model and training hyperparameters. The largest model, with 540B parameters, was finetuned on 26B tokens. While this model is highly undertrained compared to the 8B and 62B models, it still achieves superior performance. Additional details can be found in Appendix C.</p>
<p>Table 2: Model architecture and continued training hyperparameters. Model training was resumed from the pretrained PaLM models, and the number of steps quoted refers only to continued training on our technical dataset.</p>
<table>
<thead>
<tr>
<th>Model</th>
<th>Layers</th>
<th>Heads</th>
<th>$d_{\text{model}}$</th>
<th>Parameters</th>
<th>Steps</th>
<th>Tokens</th>
</tr>
</thead>
<tbody>
<tr>
<td>Minerva 8B</td>
<td>32</td>
<td>16</td>
<td>4096</td>
<td>8.63B</td>
<td>624k</td>
<td>164B</td>
</tr>
<tr>
<td>Minerva 62B</td>
<td>64</td>
<td>32</td>
<td>8192</td>
<td>62.50B</td>
<td>416k</td>
<td>109B</td>
</tr>
<tr>
<td>Minerva 540B</td>
<td>118</td>
<td>48</td>
<td>18432</td>
<td>540.35B</td>
<td>399k</td>
<td>26B</td>
</tr>
</tbody>
</table>
<h3>2.3 Evaluation Datasets</h3>
<p>We mainly focus on few shot evaluation, though see Appendix E.3 for a discussion of finetuned evaluation. For evaluation, we truncate the inputs from the left to 1024 tokens and we use the model to generate up to 512 tokens. When sampling once per problem, we sample greedily. When sampling multiple times per problem we use nucleus sampling <em>(Holtzman et al., 2019)</em> with temperature $T=0.6$, $p=0.95$. For generative tasks, the model produces a chain-of-thought answer and demarcates a final answer. We evaluate a solution as correct if the final answer matches the ground truth solution, independent of the quality of the chain-of-thought preceding it. To evaluate correctness, we parse the final answers and compare them using the SymPy library <em>(Meurer et al., 2017)</em>. This is done in order to correctly identify answers that are mathematically equivalent such as $1/\sqrt{3}$ and $\sqrt{3}/3$. See Appendix D.1 for further details.</p>
<p>The existing datasets on which we focus are:</p>
<ul>
<li>MATH: a dataset of 12K middle school and high school mathematics problems <em>Hendrycks et al. (2021)</em>. Problem statements are written in LaTeX. We prompt the model with a fixed 4-shot prompt (listed in Appendix D.2). This prompt includes four random examples from the training dataset whose ground truth targets are not too long.</li>
<li>GSM8k: middle school math word problems <em>Cobbe et al. (2021)</em>. Models are evaluated using the chain-of-thought prompt from Wei et al. <em>Wei et al. (2022)</em>. Previous models evaluated on GSM8k made use of an external calculator. In this work, our model does not have access to any external tools.</li>
</ul>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 4: Performance on MATH and MMLU-STEM by subtopic. Minerva achieves state-of-the-art results on both datasets. maj1@k denotes evaluations where $k$ samples were generated for each problem and only the most common answer was selected (Wang et al., 2022). For MATH, $k=256$ for Minerva 8B and 62B, and $k=64$ for 540B. For MMLU-STEM, $k=16$. davinci-002 is the latest publicly available language model from OpenAI.</p>
<ul>
<li>MMLU-STEM: subset of the MMLU dataset (Hendrycks et al., 2020) focused on science, technology, engineering, and mathematics (STEM). For the original version, we use the 5 -shot prompt from the development set for each task. We also consider chain-of-thought prompting for this task, where we prompt the model with examples that include step-by-step solutions. We use a multiple-choice version of the MATH prompt for topics that involve mathematical reasoning, and add step-by-step solutions to the standard 5-shot prompts for the rest of the topics. See Appendix G for more details.</li>
</ul>
<h1>2.4 Undergraduate-Level STEM Problems</h1>
<p>To evaluate the scientific reasoning capabilities of Minerva, we harvested a set of STEM problems at the undergraduate level, most of which involve multi-step reasoning, which we refer to in this paper as OCWCourses. Using publicly-available course materials offered by MIT (OpenCourseWare), we collected problems with automatically-verifiable solutions (either numeric or symbolically verifiable via SymPy) from courses including "solid-state chemistry", "information and entropy", "differential equations", and "special relativity." These problems were processed by contractors to be self-contained and to have a clearly-delineated final answer. Problems asking for a proof or open-ended short answer were not included. In total we curated 272 problems, 191 of which have numeric solutions and 81 have symbolic solutions. In Appendix F, we detail the contributions from each course, and the process of converting these course materials into a format suitable for processing by language models. We also provide the text of all problems. We plan to release these as part of an open-source dataset which will be detailed in an upcoming manuscript.</p>
<h3>2.5 Inference-Time Techniques</h3>
<p>We find that we can considerably outperform greedy decoding by sampling $k&gt;1$ solutions (with a non-zero temperature) and selecting one using majority voting Wang et al. (2022). This consists of grouping predictions with respect to their final answer and selecting the most common answer. We denote this as maj1@k, following Li et al. (2022). A variation of this algorithm, denoted majn@k, involves selecting the $n$ most</p>
<p>Table 3: Model performance on several quantitative reasoning datasets. For majority voting we use $k=256$ (64 for 540B) samples for MATH, $k=64$ for OCWCourses, $k=100$ (40 for 540B) for GSM8k and $k=16$ for MMLU-STEM. The PaLM GSM8k results do not use a calculator and were reported in Chowdhery et al., 2022. We evaluated datasets that did not have published results on recent models on OpenAI davinci-002. Despite MMLU-STEM being a multiple choice task, we can apply majority vote by prompting the model to generate a rationale prior to the final answer, sampling multiple times, and then using majority vote on the final answers. Superscripts denote results that are quoted from previous work: ${ }^{a}$ GPT-2 Hendrycks et al. (2021), ${ }^{b}$ PaLM 540B maj1@40 Wang et al. (2022), and ${ }^{c}$ Chinchilla Hoffmann et al. (2022).</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: right;">MATH</th>
<th style="text-align: right;">OCWCourses</th>
<th style="text-align: right;">GSM8k</th>
<th style="text-align: right;">MMLU-STEM</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">PaLM 8B</td>
<td style="text-align: right;">$1.5 \%$</td>
<td style="text-align: right;">$1.5 \%$</td>
<td style="text-align: right;">$4.1 \%$</td>
<td style="text-align: right;">$22.0 \%$</td>
</tr>
<tr>
<td style="text-align: left;">Minerva 8B</td>
<td style="text-align: right;">$14.1 \%$</td>
<td style="text-align: right;">$7.7 \%$</td>
<td style="text-align: right;">$16.2 \%$</td>
<td style="text-align: right;">$35.6 \%$</td>
</tr>
<tr>
<td style="text-align: left;">Minerva 8B, maj1@k</td>
<td style="text-align: right;">$25.4 \%$</td>
<td style="text-align: right;">$12.5 \%$</td>
<td style="text-align: right;">$28.4 \%$</td>
<td style="text-align: right;">$43.4 \%$</td>
</tr>
<tr>
<td style="text-align: left;">PaLM 62B</td>
<td style="text-align: right;">$4.4 \%$</td>
<td style="text-align: right;">$5.9 \%$</td>
<td style="text-align: right;">$33.0 \%$</td>
<td style="text-align: right;">$39.1 \%$</td>
</tr>
<tr>
<td style="text-align: left;">Minerva 62B</td>
<td style="text-align: right;">$27.6 \%$</td>
<td style="text-align: right;">$12.9 \%$</td>
<td style="text-align: right;">$52.4 \%$</td>
<td style="text-align: right;">$53.9 \%$</td>
</tr>
<tr>
<td style="text-align: left;">Minerva 62B, maj1@k</td>
<td style="text-align: right;">$43.4 \%$</td>
<td style="text-align: right;">$23.5 \%$</td>
<td style="text-align: right;">$68.5 \%$</td>
<td style="text-align: right;">$63.5 \%$</td>
</tr>
<tr>
<td style="text-align: left;">PaLM 540B</td>
<td style="text-align: right;">$8.8 \%$</td>
<td style="text-align: right;">$7.1 \%$</td>
<td style="text-align: right;">$56.5 \%$</td>
<td style="text-align: right;">$58.7 \%$</td>
</tr>
<tr>
<td style="text-align: left;">Minerva 540B</td>
<td style="text-align: right;">$33.6 \%$</td>
<td style="text-align: right;">$17.6 \%$</td>
<td style="text-align: right;">$58.8 \%$</td>
<td style="text-align: right;">$63.9 \%$</td>
</tr>
<tr>
<td style="text-align: left;">Minerva 540B, maj1@k</td>
<td style="text-align: right;">$\mathbf{5 0 . 3 \%}$</td>
<td style="text-align: right;">$\mathbf{3 0 . 8 \%}$</td>
<td style="text-align: right;">$\mathbf{7 8 . 5 \%}$</td>
<td style="text-align: right;">$\mathbf{7 5 . 0 \%}$</td>
</tr>
<tr>
<td style="text-align: left;">OpenAI davinci-002</td>
<td style="text-align: right;">$19.1 \%$</td>
<td style="text-align: right;">$14.8 \%$</td>
<td style="text-align: right;">-</td>
<td style="text-align: right;">-</td>
</tr>
<tr>
<td style="text-align: left;">Published SOTA</td>
<td style="text-align: right;">$6.9 \%^{a}$</td>
<td style="text-align: right;">-</td>
<td style="text-align: right;">$74.4 \%^{b}$</td>
<td style="text-align: right;">$54.9 \%^{c}$</td>
</tr>
</tbody>
</table>
<p>common answers. Intuitively, the reason majority voting improves performance is that while there are many ways to answer a question incorrectly, there are typically very few ways to answer correctly.
Contrast majority voting with pass@k, where a task is considered solved if any single sample solves it out of $k$ samples. See Section 4.2 for more details on pass@k performance. In Appendix E.1, we report on how performance depends on $k$ for different metrics. We find that while pass@k continues to improve as $k$ is increased, majority voting performance saturates faster: $97 \%$ of the large $k$ accuracy is achieved at $k=64$ for MATH and $k=16$ for GSM8k. This is likely because majority voting selects the most common answer in the modeled distribution, and the error of this estimate decreases with increasing $k$. This is in contrast to pass@k where the performance improvement comes from the tail of the distribution, which can keep improving as $k$ is increased.
Log-likelihood is another metric that can be used to rerank samples. We found that majority voting performs significantly better than log-likelihood reranking (see Appendix E.2).</p>
<h1>3 Results</h1>
<p>Table 3 summarizes the results for Minerva models and other models, on the evaluation datasets described in Section 2.3. Figure 4 presents a breakdown of the MATH dataset results by subtopic. For MMLU evaluations, unless otherwise noted, performance is measured by using the standard 5 -shot prompt per topic and picking the answer with the highest score. When evaluating MMLU with majority voting, we sample $k=16$ model answers using a chain-of-thought prompt.
We present model output samples in Figures 1, 2 and 3, and additional output samples are listed in the Appendix. In addition, we evaluated Minerva 62B on the National Math Exam in Poland and found that it achieves a score of $57 \%$, which happened to be the national average in 2021 (CKE, 2021, p. 23). The 540B</p>
<p>model achieves $65 \%$.
We include results on the latest publicly available language model from OpenAI, davinci-002, evaluated using the OpenAI API with temperature set to the official recommendation $(T=0.2)$. The combination of training data, scale and inference techniques yields state of the art results on all the technical tasks that we considered. For all tasks (with the exception of GSM8k), the improvement with respect to previous results is considerable.
While our main focus is on few shot evaluation, we also tried to finetune Minerva on MATH. While we did not observe any improvement, we found that finetuning PaLM on MATH did give a significant improvement, which suggests that the marginal utility of standard finetuning decreases as the quality and diversity of the unsupervised training dataset improves. Further details can be found in Appendix E.3.</p>
<h1>3.1 Basic arithmetic</h1>
<p>In Appendix H, we study the performance of Minerva 540B on simple arithmetic tasks. The model achieves over $80 \%$ accuracy on 10-digit addition and over $20 \%$ accuracy on 18-digit addition.</p>
<h2>4 Performance Analysis</h2>
<h3>4.1 Model Mistakes</h3>
<p>To better understand the types of mistakes our models make, we compare the performance of Minerva 8B and Minerva 62B on 216 problems with high confidence majority decisions of both models. Specifically, we selected examples where the top answer received at least $15 \%$ of votes, and that either Minerva 8B was correct and Minerva 62B was incorrect ( 15 samples), or vice versa (201 samples). The categories and examples for each category are described in Appendix I.2.
As shown in Table 4, the prevailing errors of the 8B model were related to incorrect reasoning or calculations. Many of the calculation errors were relatively benign arithmetic mistakes. Solutions that were too short were relatively rare (in these cases, the model immediately produces an incorrect answer without any intermediate reasoning steps). Finally, in a few cases, the model hallucinates an equation or mathematical fact that is not real.
In the samples where the 62 B model was incorrect, the dominating failure modes were again incorrect reasoning and incorrect calculations. In summary, we find that the 62B Minerva model retains most of the skills of the 8 B model and improves upon both reasoning and calculation robustness.</p>
<p>Table 4: Failure modes of the 8B Minerva model, out of 201 samples which the 62B model solved correctly and the 8 B model did not.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Type of mistakes</th>
<th style="text-align: center;">Occurrences</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Incorrect reasoning</td>
<td style="text-align: center;">82</td>
</tr>
<tr>
<td style="text-align: left;">Incorrect calculation</td>
<td style="text-align: center;">70</td>
</tr>
<tr>
<td style="text-align: left;">Misunderstands question</td>
<td style="text-align: center;">22</td>
</tr>
<tr>
<td style="text-align: left;">Uses incorrect fact</td>
<td style="text-align: center;">16</td>
</tr>
<tr>
<td style="text-align: left;">Solution too short</td>
<td style="text-align: center;">4</td>
</tr>
<tr>
<td style="text-align: left;">Hallucinated math objects</td>
<td style="text-align: center;">4</td>
</tr>
<tr>
<td style="text-align: left;">Other mistakes</td>
<td style="text-align: center;">3</td>
</tr>
</tbody>
</table>
<h1>4.2 False Positives</h1>
<p>In our approach to solving quantitative reasoning problems, we are able to automatically verify whether the final answer to a problem is correct, but we do not have an automatic way to verify the model's chain of reasoning. This leaves open the possibility of false positives: samples which have the correct final answer, but for which the reasoning is incomplete or incorrect.
We selected 100 random questions from MATH ( 20 per difficulty level), along with answers sampled at zero temperature from the 62 B model. We then manually inspected the answers to determine the false positive rate, which is the ratio between number of false positive examples and number of examples for which the final answer is correct; see Table 5. We found that the overall false positive rate is low, though it does increase with difficulty level.
Our focus on pass@1 and majority voting as the primary evaluation metrics is due in part to the fact that they are less susceptible to false positives than pass@k (Li et al., 2022). While the pass@256 accuracy is $84.5 \%$ for the 62 B model, false positives account for part of it. We inspected the samples that failed in majority voting but passed on pass@k due to a single correct answer, and estimate the false positive rate for pass@256 to be $30 \%$ among samples selected in this way. After removing false positives, we estimate that the pass@256 accuracy to be bigger than $68 \%$; see Appendix I. 3 for details.</p>
<p>Table 5: Estimated false positive rates of the 62B model on the MATH dataset, by difficulty level. The average is the estimated false positive rate on the MATH dataset, given by the average of per-level false positive rates weighted by positive rates.</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: center;">Difficulty level</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">Average</td>
</tr>
<tr>
<td style="text-align: left;">False positive rate</td>
<td style="text-align: center;">$&lt;5 \%$</td>
<td style="text-align: center;">$10 \%$</td>
<td style="text-align: center;">$&lt;5 \%$</td>
<td style="text-align: center;">$15 \%$</td>
<td style="text-align: center;">$30 \%$</td>
<td style="text-align: center;">$8 \%$</td>
</tr>
</tbody>
</table>
<h2>5 Memorization</h2>
<p>A central question in interpreting Minerva's solutions is whether performance reflects genuine analytic capability or instead rote memorization. This is especially relevant as there has been much prior work indicating that language models often memorize some fraction of their training data (Trinh and Le, 2018; Radford et al., 2019; Carlini et al., 2022). When examining model solutions, we find that memorization of intermediate facts, such as numerical values of square roots or trigonometric identities, are crucial elements of model solutions. Truly strong performance would combine recall of intermediate facts with genuine solution synthesis. We would like to investigate a strong form of memorization, where model performance is a result of memorizing the explicit problems and solutions in our evaluation set, but also a weaker form, where the model has memorized alternate answers to the same questions.
In order to evaluate the degree to which our models solve problems by recalling information memorized from training data, we conduct three analyses on the MATH dataset. First we directly search for problems and solutions in our training corpus. Next, we generate modified versions of problems and evaluate our models' robustness to these changes. Finally, we measure the degree of overlap between the ground truth solutions and solutions generated by our model and measure the effect of this similarity on model performance. Overall, we find little evidence that the model's performance can be attributed to memorization.</p>
<h1>5.1 Training and Evaluation Dataset Overlap</h1>
<p>We selected the problems for which our 62B parameter model produced a correct answer, and filtered them to the 100 problems with the highest majority vote score, expecting that problems with a high majority vote score are more likely to have been memorized. For each of these question-answer pairs, we compute the BLEU score across chunks of 500 characters in our Math Web Pages dataset (a histogram of the BLEU scores is shown in Appendix Figure 10). We then manually inspect the 250 documents with the highest BLEU scores. While many of the top matches were from homework help sites with math questions and solutions, none of the questions matched the questions in the subset of MATH under consideration. We have included these 250 segments in Appendix J.1. We note that some problems from MATH can be found on the web. Nevertheless, this analysis concludes that these problems did not make it through our data collection process.</p>
<h3>5.2 Performance on Modified MATH Problems</h3>
<p>To further investigate memorization, we randomly selected twenty problems which the 62B model answered correctly under majority voting. We manually modified each problem either by introducing minor changes to problem wording (framing) or by changing the numbers which appeared in the problem and modifying the solution accordingly. We then compared the accuracy over sampled solutions before and after the modification. Results are shown in Figure 5. In both cases the accuracy before and after modifications are correlated, with no clear bias in favor of the original formulation. This is suggestive of minimal memorization. The modified problems are listed in Appendix J.2.
<img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 5: Results indicating lack of memorization on MATH. Left, Center: Accuracy of original questions from the MATH dataset and their modified versions. Each point represents a question. The $x$ axis is accuracy on the original question, and the $y$ axis is accuracy on the modified one. Right: Majority vote accuracy, computed only on samples with BLEU score to the ground truth solution less than or equal to the $x$-axis value.</p>
<h3>5.3 BLEU Score Between Ground Truth and Generated Solutions</h3>
<p>We seek to detect memorization of solutions by computing BLEU score between ground truth answers and model generated answers. We use the 62B model and analyze 256 samples per problem in the MATH dataset. First, we compute overlap statistics for all correct samples. We find that 160 out of 5,000 test questions have a sample with a BLEU score greater than or equal to 80 (see Appendix J.3). We note that they tend to be short solutions. To understand the effect of answer similarity on performance, we remove model samples above a certain BLEU score threshold, and recompute the majority vote accuracy. We find that majority vote performance is robust even down to relatively low similarities (see Figure 5), indicating that performance cannot be attributed to model outputs that are very similar to ground truth answers.</p>
<h1>6 Conclusions and Discussion</h1>
<p>In this work, we take an approach to quantitative reasoning that relies on solving problems using mathematical reasoning expressed in natural language. We show that by training a large language model on a high quality mathematical dataset, we are able to achieve strong performance on tasks that require logical reasoning, numerical calculation, and symbolic manipulation. Our model does not make use of external tools, and at inference time relies exclusively on autoregressive sampling to achieve this performance. Complementary approaches to quantitative reasoning include code-generating models and formal methods. These are all different routes toward a common goal: an agent that can reason about and solve quantitative problems. We believe that such an agent should combine useful elements from all of these approaches.</p>
<h3>6.1 Limitations of Our Approach</h3>
<p>Our approach to quantitative reasoning has several limitations. First, we have no automatic way of verifying the correctness of the model's answers. This is in contrast to formal approaches, for which automatic verification is intrinsic. Second, our model has no access to external tools such as a calculator or a Python interpreter. It is therefore limited in its ability to perform quantitative reasoning tasks that require complicated numerical calculations. Third, because our model was trained on a large amount of data, we have little direct control over the specific capabilities that the model acquired.</p>
<h3>6.2 Societal Impact</h3>
<p>Artificial neural networks capable of solving quantitative reasoning problems in a general setting have the potential of substantial societal impact. Minerva, while a step in this direction, is still far from achieving this goal, and its potential societal impact is therefore limited. The model's performance is still well below human performance, and furthermore, we do not have an automatic way of verifying the correctness of its outputs. If these issues could be solved, we expect the impacts of this model to be broadly positive. A direct application could be an accessible and affordable math tutor which could help improve educational inequalities.</p>
<h2>7 Acknowledgments</h2>
<p>We thank David Andre, Jacob Austin, Maarten Bosma, Aakanksha Chowdhery, Sergey Ioffe, Colin Raffel, Charles Sutton, and Christian Szegedy for helpful discussions.</p>
<h2>References</h2>
<p>Alemi, A. A., Chollet, F., Een, N., Irving, G., Szegedy, C., and Urban, J. (2016). Deepmath - Deep Sequence Models for Premise Selection. In Proceedings of the 30th International Conference on Neural Information Processing Systems, NIPS'16, pages 2243-2251, USA. Curran Associates Inc.</p>
<p>Austin, J., Odena, A., Nye, M., Bosma, M., Michalewski, H., Dohan, D., Jiang, E., Cai, C., Terry, M., Le, Q., et al. (2021). Program synthesis with large language models. arXiv preprint arXiv:2108.07732.</p>
<p>Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et al. (2020). Language models are few-shot learners. Advances in neural information processing systems, 33:1877-1901.</p>
<p>Carlini, N., Ippolito, D., Jagielski, M., Lee, K., Tramer, F., and Zhang, C. (2022). Quantifying memorization across neural language models.</p>
<p>Chen, M., Tworek, J., Jun, H., Yuan, Q., Pinto, H. P. d. O., Kaplan, J., Edwards, H., Burda, Y., Joseph, N., Brockman, G., Ray, A., Puri, R., Krueger, G., Petrov, M., Khlaaf, H., Sastry, G., Mishkin, P., Chan, B., Gray, S., Ryder, N., Pavlov, M., Power, A., Kaiser, L., Bavarian, M., Winter, C., Tillet, P., Such, F. P., Cummings, D., Plappert, M., Chantzis, F., Barnes, E., Herbert-Voss, A., Guss, W. H., Nichol, A., Paino, A., Tezak, N., Tang, J., Babuschkin, I., Balaji, S., Jain, S., Saunders, W., Hesse, C., Carr, A. N., Leike, J., Achiam, J., Misra, V., Morikawa, E., Radford, A., Knight, M., Brundage, M., Murati, M., Mayer, K., Welinder, P., McGrew, B., Amodei, D., McCandlish, S., Sutskever, I., and Zaremba, W. (2021). Evaluating large language models trained on code.</p>
<p>Chowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra, G., Roberts, A., Barham, P., Chung, H. W., Sutton, C., Gehrmann, S., Schuh, P., Shi, K., Tsvyashchenko, S., Maynez, J., Rao, A., Barnes, P., Tay, Y., Shazeer, N., Prabhakaran, V., Reif, E., Du, N., Hutchinson, B., Pope, R., Bradbury, J., Austin, J., Isard, M., Gur-Ari, G., Yin, P., Duke, T., Levskaya, A., Ghemawat, S., Dev, S., Michalewski, H., Garcia, X., Misra, V., Robinson, K., Fedus, L., Zhou, D., Ippolito, D., Luan, D., Lim, H., Zoph, B., Spiridonov, A., Sepassi, R., Dohan, D., Agrawal, S., Omernick, M., Dai, A. M., Pillai, T. S., Pellat, M., Lewkowycz, A., Moreira, E., Child, R., Polozov, O., Lee, K., Zhou, Z., Wang, X., Saeta, B., Diaz, M., Firat, O., Catasta, M., Wei, J., Meier-Hellstern, K., Eck, D., Dean, J., Petrov, S., and Fiedel, N. (2022). Palm: Scaling language modeling with pathways.</p>
<p>CKE (2021). Skale centylowe wyników - matura 2021.
Cobbe, K., Kosaraju, V., Bavarian, M., Chen, M., Jun, H., Kaiser, L., Plappert, M., Tworek, J., Hilton, J., Nakano, R., Hesse, C., and Schulman, J. (2021). Training verifiers to solve math word problems.
de Moura, L. M., Kong, S., Avigad, J., van Doorn, F., and von Raumer, J. (2015). The lean theorem prover (system description). In Felty, A. P. and Middeldorp, A., editors, CADE, volume 9195 of Lecture Notes in Computer Science, pages 378-388. Springer.
development team, T. C. (2022). The Coq reference manual. Version 8.15.
Drori, I., Zhang, S., Shuttleworth, R., Tang, L., Lu, A., Ke, E., Liu, K., Chen, L., Tran, S., Cheng, N., Wang, R., Singh, N., Patti, T. L., Lynch, J., Shporer, A., Verma, N., Wu, E., and Strang, G. (2021). A neural network solves, explains, and generates university math problems by program synthesis and few-shot learning at human level.</p>
<p>Goertzel, Z. A., Chvalovský, K., Jakubuv, J., Olsák, M., and Urban, J. (2021). Fast and slow enigmas and parental guidance. CoRR, abs/2107.06750.</p>
<p>Grabowski, A., Kornilowicz, A., and Naumowicz, A. (2010). Mizar in a nutshell. J. Formalized Reasoning, $3(2): 153-245$.</p>
<p>Han, J. M., Rute, J., Wu, Y., Ayers, E., and Polu, S. (2022). Proof artifact co-training for theorem proving with language models. In International Conference on Learning Representations.</p>
<p>Harrison, J. (1996). Hol light: A tutorial introduction. In Srivas, M. and Camilleri, A., editors, Formal Methods in Computer-Aided Design, pages 265-269, Berlin, Heidelberg. Springer Berlin Heidelberg.</p>
<p>Hendrycks, D., Burns, C., Basart, S., Zou, A., Mazeika, M., Song, D., and Steinhardt, J. (2020). Measuring massive multitask language understanding. CoRR, abs/2009.03300.</p>
<p>Hendrycks, D., Burns, C., Kadavath, S., Arora, A., Basart, S., Tang, E., Song, D., and Steinhardt, J. (2021). Measuring mathematical problem solving with the math dataset.</p>
<p>Hoffmann, J., Borgeaud, S., Mensch, A., Buchatskaya, E., Cai, T., Rutherford, E., Casas, D. d. L., Hendricks, L. A., Welbl, J., Clark, A., Hennigan, T., Noland, E., Millican, K., Driessche, G. v. d., Damoc, B., Guy, A., Osindero, S., Simonyan, K., Elsen, E., Rae, J. W., Vinyals, O., and Sifre, L. (2022). Training compute-optimal large language models.</p>
<p>Holtzman, A., Buys, J., Du, L., Forbes, M., and Choi, Y. (2019). The curious case of neural text degeneration.
Hosseini, M. J., Hajishirzi, H., Etzioni, O., and Kushman, N. (2014). Learning to solve arithmetic word problems with verb categorization. EMNLP, 523533.</p>
<p>Jiang, A. Q., Li, W., Tworkowski, S., Czechowski, K., Odrzygózdz, T., Milos, P., Wu, Y., and Jamnik, M. (2022). Thor: Wielding hammers to integrate language models and automated theorem provers. CoRR, abs/2205.10893.</p>
<p>Kaliszyk, C., Urban, J., Michalewski, H., and Olšák, M. (2018). Reinforcement learning of theorem proving. In Bengio, S., Wallach, H., Larochelle, H., Grauman, K., Cesa-Bianchi, N., and Garnett, R., editors, Advances in Neural Information Processing Systems, volume 31. Curran Associates, Inc.</p>
<p>Koncel-Kedziorski, R., Hajishirzi, H., Sabharwal, A., Etzioni, O., and Ang, S. D. (2015). Parsing algebraic word problems into equations. Transactions of the Association for Computational Linguistics, 3.</p>
<p>Kovács, L. and Voronkov, A. (2013). First-order theorem proving and Vampire. In $C A V$.
Li, W., Yu, L., Wu, Y., and Paulson, L. C. (2021). Isarstep: a benchmark for high-level mathematical reasoning. In $I C L R$.</p>
<p>Li, Y., Choi, D., Chung, J., Kushman, N., Schrittwieser, J., Leblond, R., Eccles, T., Keeling, J., Gimeno, F., Lago, A. D., Hubert, T., Choy, P., d’Autume, C. d. M., Babuschkin, I., Chen, X., Huang, P.-S., Welbl, J., Gowal, S., Cherepanov, A., Molloy, J., Mankowitz, D. J., Robson, E. S., Kohli, P., de Freitas, N., Kavukcuoglu, K., and Vinyals, O. (2022). Competition-level code generation with alphacode.</p>
<p>Megill, N. D. and Wheeler, D. A. (2019). Metamath: A Computer Language for Pure Mathematics. Lulu Press, Morrisville, North Carolina. http://us.metamath.org/downloads/metamath.pdf.</p>
<p>Meurer, A., Smith, C. P., Paprocki, M., Čertík, O., Kirpichev, S. B., Rocklin, M., Kumar, A., Ivanov, S., Moore, J. K., Singh, S., Rathnayake, T., Vig, S., Granger, B. E., Muller, R. P., Bonazzi, F., Gupta, H., Vats, S., Johansson, F., Pedregosa, F., Curry, M. J., Terrel, A. R., Roučka, v., Saboo, A., Fernando, I., Kulal, S., Cimrman, R., and Scopatz, A. (2017). Sympy: symbolic computing in python. PeerJ Computer Science, 3:e103.</p>
<p>Nye, M., Andreassen, A. J., Gur-Ari, G., Michalewski, H., Austin, J., Bieber, D., Dohan, D., Lewkowycz, A., Bosma, M., Luan, D., Sutton, C., and Odena, A. (2021). Show Your Work: Scratchpads for Intermediate Computation with Language Models. arXiv e-prints, page arXiv:2112.00114.</p>
<p>Otten, J. (2008). leancop 2.0 and ileancop 1.2: High performance lean theorem proving in classical and intuitionistic logic (system descriptions). In Armando, A., Baumgartner, P., and Dowek, G., editors, Automated Reasoning, pages 283-291, Berlin, Heidelberg. Springer Berlin Heidelberg.</p>
<p>Polu, S., Han, J. M., Zheng, K., Baksys, M., Babuschkin, I., and Sutskever, I. (2022). Formal mathematics statement curriculum learning. CoRR, abs/2202.01344.</p>
<p>Polu, S. and Sutskever, I. (2020). Generative language modeling for automated theorem proving. arXiv preprint arXiv:2009.03393.</p>
<p>Rabe, M. N., Lee, D., Bansal, K., and Szegedy, C. (2021). Mathematical reasoning via self-supervised skip-tree training.</p>
<p>Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., Sutskever, I., et al. (2019). Language models are unsupervised multitask learners. OpenAI blog, 1(8):9.</p>
<p>Rae, J. W., Borgeaud, S., Cai, T., Millican, K., Hoffmann, J., Song, F., Aslanides, J., Henderson, S., Ring, R., Young, S., et al. (2021). Scaling language models: Methods, analysis \&amp; insights from training gopher. arXiv preprint arXiv:2112.11446.</p>
<p>Raffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou, Y., Li, W., and Liu, P. J. (2019). Exploring the limits of transfer learning with a unified text-to-text transformer. arXiv preprint arXiv:1910.10683.</p>
<p>Roberts, A., Chung, H. W., Levskaya, A., Mishra, G., Bradbury, J., Andor, D., Narang, S., Lester, B., Gaffney, C., Mohiuddin, A., Hawthorne, C., Lewkowycz, A., Salcianu, A., van Zee, M., Austin, J., Goodman, S., Soares, L. B., Hu, H., Tsvyashchenko, S., Chowdhery, A., Bastings, J., Bulian, J., Garcia, X., Ni, J., Chen, A., Kenealy, K., Clark, J. H., Lee, S., Garrette, D., Lee-Thorp, J., Raffel, C., Shazeer, N., Ritter, M., Bosma, M., Passos, A., Maitin-Shepard, J., Fiedel, N., Omernick, M., Saeta, B., Sepassi, R., Spiridonov, A., Newlan, J., and Gesmundo, A. (2022). Scaling up models and data with t5x and seqio.</p>
<p>Schulz, S. (2013). System Description: E 1.8. In McMillan, K., Middeldorp, A., and Voronkov, A., editors, Proc. of the 19th LPAR, volume 8312 of LNCS. Springer.</p>
<p>Smith, S., Patwary, M., Norick, B., LeGresley, P., Rajbhandari, S., Casper, J., Liu, Z., Prabhumoye, S., Zerveas, G., Korthikanti, V., et al. (2022). Using deepspeed and megatron to train megatron-turing nlg 530b, a large-scale generative language model. arXiv preprint arXiv:2201.11990.</p>
<p>Thoppilan, R., De Freitas, D., Hall, J., Shazeer, N., Kulshreshtha, A., Cheng, H.-T., Jin, A., Bos, T., Baker, L., Du, Y., Li, Y., Lee, H., Zheng, H. S., Ghafouri, A., Menegali, M., Huang, Y., Krikun, M., Lepikhin, D., Qin, J., Chen, D., Xu, Y., Chen, Z., Roberts, A., Bosma, M., Zhao, V., Zhou, Y., Chang, C.-C., Krivokon, I., Rusch, W., Pickett, M., Srinivasan, P., Man, L., Meier-Hellstern, K., Morris, M. R., Doshi, T., Santos, R. D., Duke, T., Soraker, J., Zevenbergen, B., Prabhakaran, V., Diaz, M., Hutchinson, B., Olson, K., Molina, A., Hoffman-John, E., Lee, J., Aroyo, L., Rajakumar, R., Butryna, A., Lamm, M., Kuzmina, V., Fenton, J., Cohen, A., Bernstein, R., Kurzweil, R., Aguera-Arcas, B., Cui, C., Croak, M., Chi, E., and Le, Q. (2022). Lamda: Language models for dialog applications.</p>
<p>Trinh, T. H. and Le, Q. V. (2018). A simple method for commonsense reasoning. arXiv preprint arXiv:1806.02847.</p>
<p>Wang, X., Wei, J., Schuurmans, D., Le, Q., Chi, E., Narang, S., Chowdhery, A., and Zhou, D. (2022). Self-consistency improves chain of thought reasoning in language models.</p>
<p>Wei, J., Wang, X., Schuurmans, D., Bosma, M., Chi, E., Le, Q., and Zhou, D. (2022). Chain of thought prompting elicits reasoning in large language models.</p>
<p>Welleck, S., Liu, J., Bras, R. L., Hajishirzi, H., Choi, Y., and Cho, K. (2021). Naturalproofs: Mathematical theorem proving in natural language. CoRR, abs/2104.01112.</p>
<p>Wenzel, M., Paulson, L. C., and Nipkow, T. (2008). The isabelle framework. In Mohamed, O. A., Muñoz, C., and Tahar, S., editors, Theorem Proving in Higher Order Logics, pages 33-38, Berlin, Heidelberg. Springer Berlin Heidelberg.</p>
<p>Wu, Y., Jiang, A. Q., Li, W., Rabe, M. N., Staats, C., Jamnik, M., and Szegedy, C. (2022). Autoformalization with large language models. CoRR, abs/2205.12615.</p>
<p>Wu, Y., Rabe, M. N., Li, W., Ba, J., Grosse, R. B., and Szegedy, C. (2021). LIME: learning inductive bias for primitives of mathematical reasoning. In Meila, M. and Zhang, T., editors, Proceedings of the 38th International Conference on Machine Learning, ICML 2021, 18-24 July 2021, Virtual Event, volume 139 of Proceedings of Machine Learning Research, pages 11251-11262. PMLR.</p>
<h1>Appendix</h1>
<h2>A Detailed Contributions</h2>
<p>Aitor prepared the Mathematical web pages dataset and Aitor and David prepared the arXiv dataset used to train Minerva.
Aitor trained the Minerva models presented in the paper, and he, along with David and Vedant, conducted ablation studies.
Aitor, Ambrose, and David built the experimental infrastructure for training and evaluating Minerva. They, along with Anders, Ethan, Henryk, Vinay, and Vedant collected the evaluation datasets and conducted model evaluations.
Aitor, Anders, Behnam, Ethan, Guy, and Vedant conducted experiments and ablation studies on inference-time techniques.
Vedant and Vinay collected the OCWCourses dataset and supervised the contractors' work.
Aitor, Ambrose, Anders, David, Ethan, Guy, Henryk, Theo, Vedant, Vinay, and Yuhuai analyzed the models' results, including sample explorations to categorize model mistakes and identify false positives.
Aitor, Anders, and Cem conducted fine-tuning evaluation experiments.
Ethan, Vedant, and Vinay designed and conducted the memorization experiments.
Aitor, Anders, Ethan, Guy, Henryk, Imanol, Vedant, and Yuhuai wrote the paper.
Aitor, Behnam, Guy, and Vedant advised and led the project throughout its life cycle.</p>
<h2>B Training Dataset Details</h2>
<p>The two main data sources for our training dataset are arXiv papers and web pages that contain mathematics. Here we present additional details on how the data from each source was collected and processed.</p>
<h2>B. 1 arXiv</h2>
<p>The arXiv dataset contains 2 M arXiv papers up to February 2021, in $\mathrm{IAT}<em _mathrm_E="\mathrm{E">{\mathrm{E}} \mathrm{X}$ format. If multiple $\mathrm{IT}</em>$ files were present, they were concatenated. Comments were removed, and anything before the first section header or after an appendix/bibliography header was removed. The title and abstract of each paper were added to the document from the arXiv metadata. In order to retain high quality documents and maximize the information per token, papers were filtered out if they were longer than 75 k tokens, had on average more than 0.6 tokens per character, had no \section headers, or ended up being empty after processing. The final arXiv dataset after processing includes 1.2 M papers totalling 58 GB of data.}} \mathrm{X</p>
<h2>B. 2 Mathematical web pages</h2>
<p>We started with a collection of web pages that included the string "&lt;math" or "MathJax-Element-" in the raw HTML, which we used as our filter for pages that that include mathematical content. We considered pages as of January 2022. We then used several heuristics to process the pages. We found empirically that these are sufficient to extract most of the available mathematical content in either $\mathrm{IT}_{\mathrm{E}} \mathrm{X}$ format or ASCII-math format. The majority of the documents (about $80 \%$ of documents) have one of these two formats:</p>
<ol>
<li>A majority of these HTML documents contain math in TeX or AsciiMath format inside tags of the form <script type="math/latex"> or <script type="math/asciimath">.</li>
<li>Another common appearance of $\mathrm{LAT}_{\mathrm{E}} \mathrm{X}$ happens with <annotation encoding="application/x-tex"> tags inside <math> MathML blocks. We extract the content of these <annotation> blocks but do not include other content from inside the <math> blocks.</li>
</ol>
<p>The remaining documents (about 20\%) generally have math in MathML format, which we discarded. After extracting the content in any of the previous two forms, we removed all other content that was inside <math> or <span id=MathJax-Element-*> blocks, because these blocks often encode the MathML version of TeX or AsciiMath content. After filtering, processing, and selecting only English documents, the final dataset size is 60 GB .</p>
<h1>C Model and Training Procedure Details</h1>
<p>We start with pretrained PaLM models, and perform unsupervised finetuning on our technical dataset to obtain Minerva. The models have context length 2048. They are trained with batch size 128 (except for the 540 B model which was trained with batch size 32) and without dropout.
The learning rate schedule was reciprocal square-root decay, which continued the schedule of the pretrained models. The 8 B model was pretrained for 1 M steps and further trained for 600 k additional unsupervised finetuning steps. The 62 B model was pretrained for 520 k steps and further trained for 400 k additional unsupervised finetuning steps. The 540 B model was pretrained for 257 k steps and was further trained for 383 k additional steps during unsupervised finetuning.
Finally, the learning rate was dropped 10x and all models were then trained for $4 \%$ additional steps. We note that these models had a significantly larger batch size during pretraining.
We used the t5x framework (Roberts et al., 2022) and trained our models with v4 TPU on Google Cloud. The 8 B model was trained for 14 days on a v4-128, the 62 B model was trained for 17 days on a v4-512, and the 540 B model was trained for 29 days on a v4-1024.</p>
<h2>D MATH Evaluation Details</h2>
<h2>D. 1 MATH Answer Normalization</h2>
<p>Extracting and evaluating the correctness of answers to math questions is non-trivial because answers can often be presented in many different ways, both in terms of formatting (e.g. answers can be underlined, or surrounded by a box) and in terms of mathematical content (a large number can be equivalently represented as 1,000 or 1000, answers about currency potentially have the currency symbol attached to them, etc.). Here we describe how final answers are extracted and normalized. After normalization, answers are compared using SymPy (see below). Failing to normalize answers properly will typically lead to falsely identifying correct answers as incorrect ("false negatives"), and therefore to underestimate the model's accuracy.
We first extract the final answer from the full model response, which potentially includes chain-of-thought reasoning. In the few-shot prompt, we used the format "Final Answer: The final answer is ANSWER. I hope it is correct." for every final answer. We look for this pattern in the model output and extract ANSWER.
We then apply a normalization function to this answer, shown in Listing 1. In order to develop it we manually inspected ground truth targets, samples from Minerva, and samples from OpenAI davinci-002. We were especially careful to avoid changes in the format of the ground truth target that might produce false positives.</p>
<div class="codehilite"><pre><span></span><code>SUBSTITUTIONS = [
    {&#39;an &#39;, &#39;&#39;}, {&#39;a &#39;, &#39;&#39;}, (&#39;.\$&#39;, &#39;\$&#39;), (&#39;\\$&#39;, &#39;&#39;), {r&#39;\ &#39;, &#39;&#39;},
    {&#39; &#39;, &#39;&#39;}, {&#39;mbox&#39;, &#39;text&#39;}, {&#39;,\\text{and}&#39;,&#39;,&#39;},
    {&#39;\\text{and}&#39;,&#39;,&#39;}, {&#39;\\text{m}&#39;,&#39;\\text{}&#39;}
]
REMOVED_EXPRESSIONS = [
    &#39;square&#39;, &#39;ways&#39;, &#39;integers&#39;, &#39;dollars&#39;, &#39;mph&#39;, &#39;inches&#39;, &#39;ft&#39;,
    &#39;hours&#39;, &#39;km&#39;, &#39;units&#39;, &#39;\\ldots&#39;, &#39;sue&#39;, &#39;points&#39;, &#39;feet&#39;,
    &#39;minutes&#39;, &#39;digits&#39;, &#39;cents&#39;, &#39;degrees&#39;, &#39;cm&#39;, &#39;gm&#39;, &#39;pounds&#39;,
    &#39;meters&#39;, &#39;meals&#39;, &#39;edges&#39;, &#39;students&#39;, &#39;childrentickets&#39;, &#39;multiples&#39;,
    &#39;\\text{s}&#39;, &#39;\\text{.}&#39;, &#39;\\text{\ns}&#39;, &#39;\\text{}^2&#39;,
    &#39;\\text{}^3&#39;, &#39;\\text{\n}&#39;, &#39;\\text{}&#39;, r&#39;\mathrm{th}&#39;,
    r&#39;^\circ&#39;, r&#39;^{\circ}&#39;, r&#39;\,&#39;, r&#39;,\!&#39;, &#39;\,}&#39;, &#39;&quot;&#39;, &#39;\\dots&#39;
]
def normalize_final_answer(final_answer: str) -&gt; str:
    &quot;&quot;&quot;Normalize a final answer to a quantitative reasoning question.&quot;&quot;&quot;
    final_answer = final_answer.split(&#39;-&#39;) [-1]
    for before, after in SUBSTITUTIONS:
        final_answer = final_answer.replace(before, after)
    for expr in REMOVED_EXPRESSIONS:
        final_answer = final_answer.replace(expr, &#39;&#39;)
    # Extract answer that is in LaTeX math, is bold,
    # is surrounded by a box, etc.
    final_answer = re.sub{r&#39;(.*?)\$\$)(.*?)\$\$)(.*)&#39;, &#39;\$\\3\$&#39;, final_answer)
    final_answer = re.sub{r&#39;(\\text\{\}(.*?)\\})&#39;, &#39;\\2&#39;, final_answer)
    final_answer = re.sub{r&#39;(\\textbf\\}(.*?)\\})&#39;, &#39;\\2&#39;, final_answer)
    final_answer = re.sub{r&#39;(\\overline\{\}(.*?)\\})&#39;, &#39;\\2&#39;, final_answer)
    final_answer = re.sub{r&#39;(\\boxed\\}(.*)\\})&#39;, &#39;\\2&#39;, final_answer)
    # Normalize shorthand TeX:
    # \fracab -&gt; \frac{a}{b}
    # \frac{abc}{bef} -&gt; \frac{abc}{bef}
    # \fracabc -&gt; \frac{a}{b}
    # \sqrt -&gt; \sqrt{a}
    # \sqrtab -&gt; sqrt{a}
    final_answer = re.sub{
        r&#39;{frac}([&#39;[]){.}&#39;, &#39;frac[\\2){\\3}&#39;, final_answer)
    final_answer = re.sub{
        r&#39;{sqrt}([&#39;[])&#39;, &#39;sqrt[\\2]&#39;, final_answer)
    final_answer = final_answer.replace(&#39;\$&#39;, &#39;&#39;)
    # Normalize 100,000 -&gt; 100000
    if final_answer.replace(&#39;,&#39;, &#39;&#39;).isdigit():
        final_answer = final_answer.replace(&#39;,&#39;, &#39;&#39;)
    return final_answer
</code></pre></div>

<p>Listing 1: Python code used to normalize final answers.
After applying this normalization function, we checked whether the formatted target and prediction strings are SymPy-equivalent. SymPy equivalence is determined by parsing the answers via
sympy.parsing.latex.parse_latex and then checking whether substracting the two resulting SymPy objects and applying sympy. simplify gives zero. We set a timeout of 5 s when calling sympy. simplify, and labeled strings as nonequivalent if this timeout was exceeded.
For MATH problems, SymPy equivalence improved overall accuracy by around $1 \%$. See Table 6 for the accuracies in MATH with only exact string match vs. SymPy equivalence.</p>
<p>Table 6: Comparing MATH accuracy when evaluating results with and without SymPy processing.</p>
<table>
<thead>
<tr>
<th></th>
<th>MATH Accuracy</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>without SymPy</td>
<td>with SymPy</td>
</tr>
<tr>
<td>Minerva 8B</td>
<td>13.3</td>
<td>14.1</td>
</tr>
<tr>
<td>Minerva 8B Majority</td>
<td>24.6</td>
<td>25.4</td>
</tr>
<tr>
<td>Minerva 62B</td>
<td>26.5</td>
<td>27.6</td>
</tr>
<tr>
<td>Minerva 62B Majority</td>
<td>42.2</td>
<td>43.4</td>
</tr>
<tr>
<td>OpenAI davinci-002</td>
<td>18.7</td>
<td>19.1</td>
</tr>
</tbody>
</table>
<h1>D. 2 MATH Prompt</h1>
<p>Listing 2 shows the 4 -shot prompt used when sampling answers to MATH questions. We picked it by choosing 8 random examples from MATH and selecting examples which did not include Asymptote plotting commands. We chose four examples so that most problems fit within a context length of 1024, to enable comparisons with a wide range of models.</p>
<div class="codehilite"><pre><span></span><code><span class="n">Problem</span><span class="o">:</span>
<span class="n">Find</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">domain</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">expression</span><span class="w"> </span><span class="n">$</span><span class="w"> </span><span class="o">\</span><span class="n">frac</span><span class="o">{\</span><span class="n">sqrt</span><span class="o">{</span><span class="n">x</span><span class="o">-</span><span class="mi">2</span><span class="o">}}{\</span><span class="n">sqrt</span><span class="o">{</span><span class="mi">5</span><span class="o">-</span><span class="n">x</span><span class="o">}}}.</span><span class="n">$</span><span class="o">.</span>
<span class="n">Solution</span><span class="o">:</span>
<span class="n">The</span><span class="w"> </span><span class="n">expressions</span><span class="w"> </span><span class="n">inside</span><span class="w"> </span><span class="k">each</span><span class="w"> </span><span class="n">square</span><span class="w"> </span><span class="n">root</span><span class="w"> </span><span class="n">must</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">non</span><span class="o">-</span><span class="n">negative</span><span class="o">.</span><span class="w"> </span><span class="n">Therefore</span><span class="o">,</span>
<span class="n">$x</span><span class="o">-</span><span class="mi">2</span><span class="w"> </span><span class="o">\</span><span class="n">ge</span><span class="w"> </span><span class="mi">0</span><span class="n">$</span><span class="o">,</span><span class="w"> </span><span class="n">so</span><span class="w"> </span><span class="n">$x</span><span class="o">\</span><span class="n">ge2$</span><span class="o">,</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">$5</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">\</span><span class="n">ge</span><span class="w"> </span><span class="mi">0</span><span class="n">$</span><span class="o">,</span><span class="w"> </span><span class="n">so</span><span class="w"> </span><span class="n">$x</span><span class="w"> </span><span class="o">\</span><span class="n">le</span><span class="w"> </span><span class="mi">5</span><span class="n">$</span><span class="o">.</span><span class="w"> </span><span class="n">Also</span><span class="o">,</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">denominator</span>
<span class="n">cannot</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">equal</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">zero</span><span class="o">,</span><span class="w"> </span><span class="n">so</span><span class="w"> </span><span class="n">$5</span><span class="o">-</span><span class="n">x</span><span class="o">&gt;</span><span class="mi">0</span><span class="n">$</span><span class="o">,</span><span class="w"> </span><span class="n">which</span><span class="w"> </span><span class="n">gives</span><span class="w"> </span><span class="n">$x</span><span class="o">&lt;</span><span class="mi">5</span><span class="n">$</span><span class="o">.</span><span class="w"> </span><span class="n">Therefore</span><span class="o">,</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">domain</span><span class="w"> </span><span class="n">of</span>
<span class="n">the</span><span class="w"> </span><span class="n">expression</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">$</span><span class="w"> </span><span class="n">boxed</span><span class="w"> </span><span class="o">{</span><span class="mi">2</span><span class="o">,</span><span class="mi">5</span><span class="o">}.</span><span class="n">$</span><span class="o">.</span>
<span class="n">Final</span><span class="w"> </span><span class="n">Answer</span><span class="o">:</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="kd">final</span><span class="w"> </span><span class="n">answer</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">$2</span><span class="o">,</span><span class="mi">5</span><span class="n">$</span><span class="o">.</span><span class="w"> </span><span class="n">I</span><span class="w"> </span><span class="n">hope</span><span class="w"> </span><span class="n">it</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">correct</span><span class="o">.</span>
<span class="n">Problem</span><span class="o">:</span>
<span class="n">If</span><span class="w"> </span><span class="n">$</span><span class="w"> </span><span class="o">\</span><span class="n">det</span><span class="w"> </span><span class="o">\</span><span class="n">mathbf</span><span class="o">{</span><span class="n">A</span><span class="o">}</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">2</span><span class="n">$</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">$</span><span class="w"> </span><span class="o">\</span><span class="n">det</span><span class="w"> </span><span class="o">\</span><span class="n">mathbf</span><span class="o">{</span><span class="n">B</span><span class="o">}</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">12</span><span class="o">,</span><span class="n">$</span><span class="w"> </span><span class="n">then</span><span class="w"> </span><span class="n">find</span>
<span class="n">$</span><span class="w"> </span><span class="o">\</span><span class="n">det</span><span class="w"> </span><span class="o">(\</span><span class="n">mathbf</span><span class="o">{</span><span class="n">A</span><span class="o">})</span><span class="w"> </span><span class="o">\</span><span class="n">mathbf</span><span class="o">{</span><span class="n">B</span><span class="o">}}.</span><span class="n">$</span>
<span class="n">Solution</span><span class="o">:</span>
<span class="n">We</span><span class="w"> </span><span class="n">have</span><span class="w"> </span><span class="n">that</span><span class="w"> </span><span class="n">$</span><span class="w"> </span><span class="o">\</span><span class="n">det</span><span class="w"> </span><span class="o">(\</span><span class="n">mathbf</span><span class="o">{</span><span class="n">A</span><span class="o">})</span><span class="w"> </span><span class="o">\</span><span class="n">mathbf</span><span class="o">{</span><span class="n">B</span><span class="o">})</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">(\</span><span class="n">det</span><span class="w"> </span><span class="o">\</span><span class="n">mathbf</span><span class="o">{</span><span class="n">A</span><span class="o">})(\</span><span class="n">det</span><span class="w"> </span><span class="o">\</span><span class="n">mathbf</span><span class="o">{</span><span class="n">B</span><span class="o">})</span>
<span class="o">=</span><span class="w"> </span><span class="o">(</span><span class="mi">2</span><span class="o">)(</span><span class="mi">12</span><span class="o">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">\</span><span class="n">boxed</span><span class="o">{</span><span class="mi">24</span><span class="o">}.</span><span class="n">$</span>
<span class="n">Final</span><span class="w"> </span><span class="n">Answer</span><span class="o">:</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="kd">final</span><span class="w"> </span><span class="n">answer</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">$24$</span><span class="o">.</span><span class="w"> </span><span class="n">I</span><span class="w"> </span><span class="n">hope</span><span class="w"> </span><span class="n">it</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">correct</span><span class="o">.</span>
<span class="n">Problem</span><span class="o">:</span>
<span class="n">Terrell</span><span class="w"> </span><span class="n">usually</span><span class="w"> </span><span class="n">lifts</span><span class="w"> </span><span class="n">two</span><span class="w"> </span><span class="mi">20</span><span class="o">-</span><span class="n">pound</span><span class="w"> </span><span class="n">weights</span><span class="w"> </span><span class="mi">12</span><span class="w"> </span><span class="n">times</span><span class="o">.</span><span class="w"> </span><span class="n">If</span><span class="w"> </span><span class="n">he</span><span class="w"> </span><span class="n">uses</span><span class="w"> </span><span class="n">two</span><span class="w"> </span><span class="mi">15</span><span class="o">-</span><span class="n">pound</span>
<span class="n">weights</span><span class="w"> </span><span class="n">instead</span><span class="o">,</span><span class="w"> </span><span class="n">how</span><span class="w"> </span><span class="n">many</span><span class="w"> </span><span class="n">times</span><span class="w"> </span><span class="n">must</span><span class="w"> </span><span class="n">Terrell</span><span class="w"> </span><span class="n">lift</span><span class="w"> </span><span class="n">them</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">order</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">lift</span><span class="w"> </span><span class="n">the</span>
<span class="n">same</span><span class="w"> </span><span class="n">total</span><span class="w"> </span><span class="n">weight</span><span class="o">?</span>
<span class="n">Solution</span><span class="o">:</span>
<span class="n">If</span><span class="w"> </span><span class="n">Terrell</span><span class="w"> </span><span class="n">lifts</span><span class="w"> </span><span class="n">two</span><span class="w"> </span><span class="mi">20</span><span class="o">-</span><span class="n">pound</span><span class="w"> </span><span class="n">weights</span><span class="w"> </span><span class="mi">12</span><span class="w"> </span><span class="n">times</span><span class="o">,</span><span class="w"> </span><span class="n">he</span><span class="w"> </span><span class="n">lifts</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">total</span><span class="w"> </span><span class="n">of</span>
<span class="n">$2</span><span class="o">\</span><span class="n">cdot</span><span class="w"> </span><span class="mi">12</span><span class="o">\</span><span class="n">cdot20</span><span class="o">=</span><span class="mi">480</span><span class="n">$</span><span class="w"> </span><span class="n">pounds</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">weight</span><span class="o">.</span><span class="w"> </span><span class="n">If</span><span class="w"> </span><span class="n">he</span><span class="w"> </span><span class="n">lifts</span><span class="w"> </span><span class="n">two</span><span class="w"> </span><span class="mi">15</span><span class="o">-</span><span class="n">pound</span>
<span class="n">weights</span><span class="w"> </span><span class="n">instead</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">$n$</span><span class="w"> </span><span class="n">times</span><span class="o">,</span><span class="w"> </span><span class="n">he</span><span class="w"> </span><span class="n">will</span><span class="w"> </span><span class="n">lift</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">total</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">$2</span><span class="o">\</span><span class="n">cdot15</span><span class="o">\</span><span class="n">cdot</span><span class="w"> </span><span class="n">n</span><span class="o">=</span><span class="mi">30</span><span class="n">n$</span>
<span class="n">pounds</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">weight</span><span class="o">.</span><span class="w"> </span><span class="n">Equating</span><span class="w"> </span><span class="k">this</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="mi">480</span><span class="w"> </span><span class="n">pounds</span><span class="o">,</span><span class="w"> </span><span class="n">we</span><span class="w"> </span><span class="n">can</span><span class="w"> </span><span class="n">solve</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">$n$</span><span class="o">:</span>
<span class="o">\</span><span class="n">begin</span><span class="o">{</span><span class="n">align</span><span class="o">*}</span>
<span class="mi">30</span><span class="n">na</span><span class="o">=</span><span class="mi">480</span><span class="o">\\</span>
<span class="o">\</span><span class="n">Rightarrow</span>
<span class="o">\</span><span class="n">boldsymbol</span><span class="o">{</span><span class="n">qquad</span><span class="w"> </span><span class="n">n4</span><span class="o">=</span><span class="mi">480</span><span class="o">/</span><span class="mi">30</span><span class="o">=\</span><span class="n">boxed</span><span class="o">{</span><span class="mi">16</span><span class="o">}</span>
<span class="o">\</span><span class="n">end</span><span class="o">{</span><span class="n">align</span><span class="o">*}</span>
<span class="n">Final</span><span class="w"> </span><span class="n">Answer</span><span class="o">:</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="kd">final</span><span class="w"> </span><span class="n">answer</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">$16$</span><span class="o">.</span><span class="w"> </span><span class="n">I</span><span class="w"> </span><span class="n">hope</span><span class="w"> </span><span class="n">it</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">correct</span><span class="o">.</span>
<span class="n">Problem</span><span class="o">:</span>
<span class="n">If</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">system</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">equations</span>
<span class="o">\</span><span class="n">begin</span><span class="o">{</span><span class="n">align</span><span class="o">*}</span>
<span class="mi">6</span><span class="n">x</span><span class="o">-</span><span class="mi">4</span><span class="n">y4</span><span class="o">=</span><span class="n">a</span><span class="o">,\\</span>
<span class="mi">6</span><span class="n">y</span><span class="o">-</span><span class="mi">9</span><span class="n">x</span><span class="w"> </span><span class="o">&amp;-</span><span class="n">b</span><span class="o">.</span>
<span class="o">\</span><span class="n">end</span><span class="o">{</span><span class="n">align</span><span class="o">*}</span><span class="n">has</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">solution</span><span class="w"> </span><span class="n">$</span><span class="o">(</span><span class="n">x</span><span class="o">,</span><span class="w"> </span><span class="n">y</span><span class="o">)</span><span class="n">$</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="n">$x$</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">$y$</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">both</span><span class="w"> </span><span class="n">nonzero</span><span class="o">,</span>
<span class="n">find</span><span class="w"> </span><span class="n">$</span><span class="w"> </span><span class="o">\</span><span class="n">frac</span><span class="o">{</span><span class="n">a</span><span class="o">}{</span><span class="n">b</span><span class="o">},</span><span class="n">$</span><span class="w"> </span><span class="n">assuming</span><span class="w"> </span><span class="n">$b$</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">nonzero</span><span class="o">.</span>
<span class="n">Solution</span><span class="o">:</span>
<span class="n">If</span><span class="w"> </span><span class="n">we</span><span class="w"> </span><span class="n">multiply</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">first</span><span class="w"> </span><span class="n">equation</span><span class="w"> </span><span class="n">by</span><span class="w"> </span><span class="n">$</span><span class="o">-\</span><span class="n">frac</span><span class="o">{</span><span class="mi">3</span><span class="o">}{</span><span class="mi">2</span><span class="o">}</span><span class="n">$</span><span class="o">,</span><span class="w"> </span><span class="n">we</span><span class="w"> </span><span class="n">obtain</span>
</code></pre></div>

<h1>E Additional Evaluation Experiments</h1>
<h2>E. 1 Dependence of performance on number of generated samples</h2>
<p>We study the dependence of performance on the number of generated samples per question on MATH and GSM8k. Table 7 shows results for maj1@k and maj5@k, and Figure 6 shows the dependence on $k$ for pass@k and majority voting. We observe that while pass@k continues to improve, majority voting saturates quickly.</p>
<p>Table 7: Performance on MATH $(k=256)$ and GSM8k $(k=100)$ when generating $k$ samples per task.</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: center;">MATH</th>
<th style="text-align: center;">GSM8k</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Minerva 8B, maj1@k</td>
<td style="text-align: center;">$25.4 \%$</td>
<td style="text-align: center;">$28.4 \%$</td>
</tr>
<tr>
<td style="text-align: left;">Minerva 8B, maj5@k</td>
<td style="text-align: center;">$47.6 \%$</td>
<td style="text-align: center;">$56.8 \%$</td>
</tr>
<tr>
<td style="text-align: left;">Minerva 62B, maj1@k</td>
<td style="text-align: center;">$43.4 \%$</td>
<td style="text-align: center;">$67.5 \%$</td>
</tr>
<tr>
<td style="text-align: left;">Minerva 62B, maj5@k</td>
<td style="text-align: center;">$64.9 \%$</td>
<td style="text-align: center;">$89.0 \%$</td>
</tr>
<tr>
<td style="text-align: left;">Published SOTA</td>
<td style="text-align: center;">$6.9 \%$</td>
<td style="text-align: center;">$74.5 \%$</td>
</tr>
</tbody>
</table>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 6: Accuracy as a function of $k$, the number of samples per task. Majority voting performance saturates quickly while pass@k seems to continue improving slowly. Accuracies were computed using exact string match (without SymPy processing).</p>
<h2>E. 2 Log-Likelihood Reranking</h2>
<p>Table 8 compares majority voting with reranking based on the log-likelihood that the model assigns to each response. We observe that majority voting is significantly better.</p>
<p>Table 8: A comparison of the majority voting results presented in the main text with log-likelihood reranking. We do not use SymPy processing here.</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: center;">MATH</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Minerva 62B, pass1 $T=0.0$</td>
<td style="text-align: center;">$26.5 \%$</td>
</tr>
<tr>
<td style="text-align: left;">Minerva 62B, Majority Voting 1@k</td>
<td style="text-align: center;">$42.0 \%$</td>
</tr>
<tr>
<td style="text-align: left;">Minerva 62B, pass1 $T=0.6$</td>
<td style="text-align: center;">$21.8 \%$</td>
</tr>
<tr>
<td style="text-align: left;">Minerva 62B, Log-likelihood 1@k</td>
<td style="text-align: center;">$23.8 \%$</td>
</tr>
</tbody>
</table>
<h1>E. 3 Finetuning on MATH</h1>
<p>Most of our results involve few-shot prompting Minerva on MATH and other datasets on which the model was not explicitly trained. In this section we discuss finetuning our models on the training split of the MATH dataset, and then evaluating on the test split as before. We finetune both the PaLM and Minerva 8B for 3000 steps with 2048 tokens per batch with batch size 128 and dropout of 0.1 . Similar to Li et al. (2022), we found that the accuracy for PaLM kept improving despite the test loss increasing. We picked the model with the best test accuracy after 50 training steps.
We finetuned using a few different prompts: A 0 -shot prompt, our custom 4 -shot prompt, and a prompt containing 4 random examples. Each model was evaluated using the same prompt as was used during finetuning, except for the random prompt model, with was evaluated using the fixed 4 -shot prompt that we used for the non-finetuned models.
The results can be found in Table 9. Standard finetuning does not seem to improve the performance of Minerva. On the other hand, it does lead to measurable improvements in PaLM, though this performance still lagged behind Minerva. These results suggest that the marginal utility of supervised finetuning decreases as one improves the quality and diversity of the unsupervised pretraining or unsupervised finetuning dataset.</p>
<p>Table 9: We finetune PaLM and Minerva using different finetuning methods. We find that while finetuning helps considerably for the PaLM, it does not help for Minerva.</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: center;">MATH Accuracy</th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: center;">PaLM 8B</td>
<td style="text-align: center;">Minerva 8B</td>
</tr>
<tr>
<td style="text-align: left;">Few Shot</td>
<td style="text-align: center;">$1.5 \%$</td>
<td style="text-align: center;">$14.1 \%$</td>
</tr>
<tr>
<td style="text-align: left;">Custom prompt finetuning</td>
<td style="text-align: center;">$5.6 \%$</td>
<td style="text-align: center;">$13.4 \%$</td>
</tr>
<tr>
<td style="text-align: left;">Random prompt finetuning</td>
<td style="text-align: center;">$4.4 \%$</td>
<td style="text-align: center;">$12.9 \%$</td>
</tr>
<tr>
<td style="text-align: left;">No prompt finetuning</td>
<td style="text-align: center;">$5.6 \%$</td>
<td style="text-align: center;">$13.0 \%$</td>
</tr>
</tbody>
</table>
<h2>E. 4 Majority Voting Thresholds</h2>
<p>From Figure 6, we see how majority voting saturates rather quickly at some $k$, while pass@k keeps improving. Here we analyze the asymptotic behavior of majority voting at large $k$.
Let $c_{i}$ denote the sorted number of counts for answer $i$ when we sample $N$ times and let there be a total for $A_{N}$ answers. In other words, $\sum_{i=1}^{A_{N}} c_{i}=N, c_{i}&gt;c_{i+1}$. We expect that when sampling $k \ll N$ samples, we can model the sampling distribution as a multinomial distribution with probabilities $p_{i}=\frac{c_{i}}{N}$. This approximation will have the error of attributing $p_{i}=0$ to any answer which doesn't appear in $N$ draws, so we can't really</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>*Equal leadership and advising contribution
${ }^{\dagger}$ Equal contribution&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>