<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-8557 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-8557</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-8557</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-153.html">extraction-schema-153</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models (LLMs) being evaluated on puzzle games that require spatial knowledge (such as Sudoku, Rubik's Cube, Minesweeper, etc.), including details of the models, the puzzles, the evaluation setup, the mechanisms or strategies used by the models, performance metrics, evidence of spatial reasoning, comparisons to other models or humans, and any reported limitations or failure cases.</div>
                <p><strong>Paper ID:</strong> paper-9152697c8835946200f2f1119b3e80feeba937f8</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/9152697c8835946200f2f1119b3e80feeba937f8" target="_blank">GeoSense: Evaluating Identification and Application of Geometric Principles in Multimodal Reasoning</a></p>
                <p><strong>Paper Venue:</strong> arXiv.org</p>
                <p><strong>Paper TL;DR:</strong> The in-depth analysis reveals that the identification and application of geometric principles remain a bottleneck for leading MLLMs, jointly hindering their reasoning abilities, and underscores GeoSense's potential to guide future advancements in MLLMs' geometric reasoning capabilities, paving the way for more robust and human-like reasoning in artificial intelligence.</p>
                <p><strong>Paper Abstract:</strong> Geometry problem-solving (GPS), a challenging task requiring both visual comprehension and symbolic reasoning, effectively measures the reasoning capabilities of multimodal large language models (MLLMs). Humans exhibit strong reasoning ability in this task through accurate identification and adaptive application of geometric principles within visual contexts. However, existing benchmarks fail to jointly assess both dimensions of the human-like geometric reasoning mechanism in MLLMs, remaining a critical gap in assessing their ability to tackle GPS. To this end, we introduce GeoSense, the first comprehensive bilingual benchmark designed to systematically evaluate the geometric reasoning abilities of MLLMs through the lens of geometric principles. GeoSense features a five-level hierarchical framework of geometric principles spanning plane and solid geometry, an intricately annotated dataset of 1,789 problems, and an innovative evaluation strategy. Through extensive experiments on GeoSense with various open-source and closed-source MLLMs, we observe that Gemini-2.0-pro-flash performs best, achieving an overall score of $65.3$. Our in-depth analysis reveals that the identification and application of geometric principles remain a bottleneck for leading MLLMs, jointly hindering their reasoning abilities. These findings underscore GeoSense's potential to guide future advancements in MLLMs' geometric reasoning capabilities, paving the way for more robust and human-like reasoning in artificial intelligence.</p>
                <p><strong>Cost:</strong> 0.019</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e8557.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e8557.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models (LLMs) being evaluated on puzzle games that require spatial knowledge (such as Sudoku, Rubik's Cube, Minesweeper, etc.), including details of the models, the puzzles, the evaluation setup, the mechanisms or strategies used by the models, performance metrics, evidence of spatial reasoning, comparisons to other models or humans, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Gemini-2.0-pro-flash</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Gemini 2.0 Pro Flash</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A closed-source multimodal large language model (MLLM) from the Gemini family evaluated on GeoSense geometry problems; reported as the top-performing model on this benchmark in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Gemini-2.0-pro-flash</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Closed-source multimodal LLM from the Gemini family used for visual + textual geometry problem solving; evaluated in a zero-shot setting with Chain-of-Thought prompting and required to explicitly identify and apply geometric principles.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_name</strong></td>
                            <td>GeoSense geometry problems (plane and solid geometry)</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_type</strong></td>
                            <td>Visual geometric problem-solving: multi-step spatial reasoning with diagrams covering plane and solid geometry (e.g., triangle/circle properties, surface area/volume, transformations).</td>
                        </tr>
                        <tr>
                            <td><strong>task_setup</strong></td>
                            <td>Zero-shot evaluation with CoT prompting; models are given a multimodal input (problem text + geometry diagram) and asked to produce step-by-step reasoning that explicitly identifies and applies geometric principles. Responses are judged for principle identification (GPI), principle application alignment to diagram elements (GPA), and final-answer accuracy (ACC) using GPT-4o-0513 as judge.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanisms_or_strategies</strong></td>
                            <td>Chain-of-Thought prompting; models must explicitly name geometric principles and map them to diagram elements; no specialized symbolic solver was attached â€” pure MLLM reasoning over text+image. Evaluations required models to produce steps that include geometric principles and their application.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>On GeoSense (ALL aggregated): GPI = 72.1, GPA = 49.7, ACC = 74.1, AVG = 65.3 (percent scores reported in paper's Table 3 / Table 7). On subject breakdown (Table 4) shows strong CSF/CPF performance (e.g., ACC very high on computation of solid figures and calculation of plane figures).</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_of_spatial_reasoning</strong></td>
                            <td>Measured indirectly via GPI/GPA: high GPI indicates good retrieval of relevant geometric principles; GPA (49.7) indicates only moderate success aligning principles to visual elements. Paper reports Gemini-2.0-pro-flash performs better on solid geometry than on plane-figure understanding, indicating partial spatial reasoning capability but failures in mapping/understanding complex planar relations.</td>
                        </tr>
                        <tr>
                            <td><strong>comparisons</strong></td>
                            <td>Reported as best overall AVG (65.3) among closed- and open-source models in the paper. Compared to GPT-4o and other closed-source models, Gemini-2.0-Pro-Flash has higher ACC and better GPI. Paper also notes open-source models generally underperform closed-source ones, and that larger model variants (when available) show improvements.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Primary failure mode is limited GPA: incorrect application/alignment of principles to diagram elements; difficulties in plane geometry (many confusable principles) and in complex problems requiring many principles. Error analysis lists GPA as primary error source; GPI still contributes (paper reports 23.5% of Gemini-2.0-Pro-Flash's errors due to GPI). Also, overthinking (in some models) can hurt ACC despite good GPI/GPA.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'GeoSense: Evaluating Identification and Application of Geometric Principles in Multimodal Reasoning', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8557.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e8557.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models (LLMs) being evaluated on puzzle games that require spatial knowledge (such as Sudoku, Rubik's Cube, Minesweeper, etc.), including details of the models, the puzzles, the evaluation setup, the mechanisms or strategies used by the models, performance metrics, evidence of spatial reasoning, comparisons to other models or humans, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-4o</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-4o (multimodal variant)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>OpenAI's GPT-4o multimodal model evaluated on GeoSense; used as one of the closed-source baselines for geometry problem solving.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4o</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Closed-source multimodal model from OpenAI used with CoT prompting in zero-shot; asked to explicitly identify and apply geometric principles in visual geometry problems.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_name</strong></td>
                            <td>GeoSense geometry problems (plane and solid geometry)</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_type</strong></td>
                            <td>Visual geometric problem-solving requiring extraction of spatial relations from diagrams and symbolic reasoning (angles, similarity/congruence, areas/volumes).</td>
                        </tr>
                        <tr>
                            <td><strong>task_setup</strong></td>
                            <td>Zero-shot Chain-of-Thought prompting; required explicit principle identification and application in reasoning steps. Judging performed automatically via GPT-4o-0513.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanisms_or_strategies</strong></td>
                            <td>Chain-of-Thought prompting; explicit naming and application of geometric principles; visual understanding component via model's multimodal capabilities.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>On GeoSense (ALL aggregated): GPI = 64.4, GPA = 45.3, ACC = 51.7, AVG = 53.8 (percent scores from Table 3). On subject breakdown GPT-4o shows high CSF GPI (91.3) and moderate ACC in computation-heavy tasks but lower performance on plane-figure understanding.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_of_spatial_reasoning</strong></td>
                            <td>Has strong ability to retrieve computational/formula-based principles (high GPI for formulas) but lower GPA indicates challenges mapping principles to visual elements; qualitative and aggregated metrics show limited adaptive application of geometric principles.</td>
                        </tr>
                        <tr>
                            <td><strong>comparisons</strong></td>
                            <td>Underperforms Gemini-2.0-pro-flash in AVG and ACC; compared to closed-source peers shows particular strengths on some computational solid-figure tasks but weaker GPA than some SOTA models. Paper compares across many models showing GPT-4o mid-to-high ranking but not top.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Failings largely in GPA (applying principles to diagrams) and in plane geometry understanding; some errors also from hallucinations and calculations per error breakdown. The paper notes lower GPA and ACC on UPF (understanding plane figures).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'GeoSense: Evaluating Identification and Application of Geometric Principles in Multimodal Reasoning', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8557.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e8557.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models (LLMs) being evaluated on puzzle games that require spatial knowledge (such as Sudoku, Rubik's Cube, Minesweeper, etc.), including details of the models, the puzzles, the evaluation setup, the mechanisms or strategies used by the models, performance metrics, evidence of spatial reasoning, comparisons to other models or humans, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Qwen2.5-VL-72B</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Qwen2.5-VL 72B</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A large open-source vision-language model (72B) in the Qwen family evaluated on GeoSense; demonstrates strong overall performance among open-source models.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Qwen2.5-VL-72B</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Open-source multimodal model (72B parameters as indicated by name) designed for vision-language tasks; evaluated with CoT prompting in zero-shot and required to identify/apply geometric principles.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>72B</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_name</strong></td>
                            <td>GeoSense geometry problems</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_type</strong></td>
                            <td>Multimodal geometric reasoning tasks requiring spatial understanding and algebraic computation grounded in visual diagrams.</td>
                        </tr>
                        <tr>
                            <td><strong>task_setup</strong></td>
                            <td>Zero-shot Chain-of-Thought prompting; models instructed to produce reasoning with explicit mention of geometric principles and their application. Responses are judged for GPI, GPA, and ACC by an automated judge.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanisms_or_strategies</strong></td>
                            <td>Chain-of-Thought prompting and explicit principle annotation in outputs; internal spatial-aware modules are referenced in background (Qwen-VL family) but evaluation used plain prompting.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>On GeoSense (ALL aggregated): GPI = 68.5, GPA = 48.1, ACC = 63.8, AVG = 60.1 (Table 3). Subject breakdowns show higher ACC on calculation/formula tasks and weaker on plane-figure understanding.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_of_spatial_reasoning</strong></td>
                            <td>Shows relatively high GPI for formulas and theorems, indicating good retrieval of geometric knowledge; GPA below GPI indicates partial but imperfect alignment to spatial diagram elements. Performance trends (better in solid than plane geometry) indicate some spatial reasoning capacity but difficulty in complex/ambiguous planar relations.</td>
                        </tr>
                        <tr>
                            <td><strong>comparisons</strong></td>
                            <td>Among open-source models, Qwen2.5-VL-72B is one of the stronger performers (higher AVG) and benefits from scale (72B). Paper reports model-size-driven improvements in the Qwen2.5-VL series.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>GPA remains a bottleneck; errors arise when mapping principles to visual elements and when many principles are required. The paper notes ACC declines as number of required principles increases, indicating brittleness on complex spatial tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'GeoSense: Evaluating Identification and Application of Geometric Principles in Multimodal Reasoning', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8557.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e8557.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models (LLMs) being evaluated on puzzle games that require spatial knowledge (such as Sudoku, Rubik's Cube, Minesweeper, etc.), including details of the models, the puzzles, the evaluation setup, the mechanisms or strategies used by the models, performance metrics, evidence of spatial reasoning, comparisons to other models or humans, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>QVQ-72B-Preview</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>QVQ 72B Preview</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A reasoning-optimized large multimodal model (72B preview) evaluated on GeoSense, showing high GPI and GPA but lower final-answer accuracy due to overthinking.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>QVQ-72B-Preview</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>A large MLLM fine-tuned/optimized for reasoning tasks (72B preview model); evaluated zero-shot with CoT prompting and asked to explicitly identify and apply geometric principles.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>72B</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_name</strong></td>
                            <td>GeoSense geometry problems</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_type</strong></td>
                            <td>Visual mathematical reasoning requiring spatial alignment of principles to diagrams and symbolic computations.</td>
                        </tr>
                        <tr>
                            <td><strong>task_setup</strong></td>
                            <td>Zero-shot evaluation with Chain-of-Thought prompting; model required to output steps enumerating principles and their application, judged by GPI/GPA/ACC.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanisms_or_strategies</strong></td>
                            <td>Optimized for reasoning (mixed-preference/multi-objective training referenced in paper), uses CoT prompting; tends to produce detailed reasoning steps which the authors note can lead to overthinking.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>On GeoSense (ALL aggregated): GPI = 72.3, GPA = 53.5, ACC = 54.3, AVG = 60.0 (Table 3). High GPI/GPA relative to many other models but ACC lower due to tendency to overthink and produce incorrect final answers.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_of_spatial_reasoning</strong></td>
                            <td>High GPI and GPA indicate strong retrieval and better alignment of principles to diagrams than many models; however qualitative behavior (overthinking) can reduce final correctness, demonstrating partial but imperfect spatial reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>comparisons</strong></td>
                            <td>Per paper, QVQ-72B-Preview achieves strong GPI/GPA scores among open-source models but ACC is lower than Gemini-2.0-Pro-Flash. Compared to other reasoning-optimized models it shows expected strengths in principle identification/application.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Overthinking (producing extra or incorrect steps) reduces ACC despite good GPI/GPA; GPA errors still present and perception-to-principle mapping failures remain. Paper highlights GPA as a common error source even for strong models like QVQ.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'GeoSense: Evaluating Identification and Application of Geometric Principles in Multimodal Reasoning', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8557.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e8557.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models (LLMs) being evaluated on puzzle games that require spatial knowledge (such as Sudoku, Rubik's Cube, Minesweeper, etc.), including details of the models, the puzzles, the evaluation setup, the mechanisms or strategies used by the models, performance metrics, evidence of spatial reasoning, comparisons to other models or humans, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>InternVL2.5-38B-MPO</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>InternVL2.5-38B-MPO (Mixed Preference Optimization)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A reasoning-enhanced variant of the InternVL2.5 open-source MLLM (38B) that shows improved reasoning on GeoSense relative to base InternVL2.5-38B.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>InternVL2.5-38B-MPO</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Open-source InternVL2.5 series model (38B) further trained/optimized with mixed-preference optimization (MPO) to enhance reasoning; evaluated zero-shot with CoT prompting on GeoSense.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>38B</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_name</strong></td>
                            <td>GeoSense geometry problems</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_type</strong></td>
                            <td>Multimodal geometry tasks requiring spatial comprehension and symbolic geometric reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>task_setup</strong></td>
                            <td>Zero-shot Chain-of-Thought prompting; models required to explicitly identify and apply geometric principles. Evaluated on GPI, GPA, and ACC metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanisms_or_strategies</strong></td>
                            <td>MPO training for reasoning improvements; use of CoT prompting during evaluation; forced explicit principle identification and application in outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>On GeoSense (ALL aggregated): GPI = 53.9, GPA = 33.6, ACC = 27.7, AVG = 38.4 (Table 3). Shows a +9.1% AVG improvement over the base InternVL2.5-38B per authors (reported in text).</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_of_spatial_reasoning</strong></td>
                            <td>Improved GPI relative to base model suggests better retrieval of necessary geometric principles; GPA and ACC remain low, indicating limited ability to align principles to diagram elements and produce correct final answers.</td>
                        </tr>
                        <tr>
                            <td><strong>comparisons</strong></td>
                            <td>Paper explicitly compares InternVL2.5-38B-MPO to InternVL2.5-38B, noting a ~9.1% AVG improvement. Still trails top closed-source models; scale and reasoning-specific training improve some capabilities but GPA remains limiting.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Low GPA and ACC indicate failures in applying principles to the diagram and in multi-step reasoning leading to final answer; errors include misperception of diagram elements and incorrect mapping between principle and diagram.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'GeoSense: Evaluating Identification and Application of Geometric Principles in Multimodal Reasoning', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8557.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e8557.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models (LLMs) being evaluated on puzzle games that require spatial knowledge (such as Sudoku, Rubik's Cube, Minesweeper, etc.), including details of the models, the puzzles, the evaluation setup, the mechanisms or strategies used by the models, performance metrics, evidence of spatial reasoning, comparisons to other models or humans, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Qwen2-VL-72B</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Qwen2-VL 72B</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A large vision-language model (72B) from the Qwen-VL family evaluated on GeoSense; demonstrates solid performance across GPI/GPA/ACC metrics among open-source baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Qwen2-VL-72B</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Open-source Qwen-VL family vision-language model (72B) designed for detailed perception and spatial understanding; evaluated with CoT prompting zero-shot on geometry problems.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>72B</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_name</strong></td>
                            <td>GeoSense geometry problems</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_type</strong></td>
                            <td>Visual geometric problems requiring spatial reasoning (circle/triangle properties, areas, solid geometry).</td>
                        </tr>
                        <tr>
                            <td><strong>task_setup</strong></td>
                            <td>Zero-shot Chain-of-Thought prompting; models produce reasoning steps naming and applying geometric principles; judged by GPI/GPA/ACC automatically.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanisms_or_strategies</strong></td>
                            <td>CoT prompting and visual-linguistic perception modules (Qwen-VL family emphasises spatial-aware modules). Explicit principle-identification requirement during reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>On GeoSense (ALL aggregated): GPI = 64.0, GPA = 43.4, ACC = 49.2, AVG = 52.2 (Table 3). Performance improves with larger model sizes in Qwen family according to paper.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_of_spatial_reasoning</strong></td>
                            <td>Moderate GPI and GPA suggest the model retrieves relevant geometric knowledge but has moderate success mapping to diagram elements; paper reports better performance on computational/formula tasks than on conceptual/theorem-based plane geometry.</td>
                        </tr>
                        <tr>
                            <td><strong>comparisons</strong></td>
                            <td>Per paper, Qwen2-VL-72B outperforms smaller Qwen variants and many open-source baselines but is below the top closed-source models like Gemini-2.0-pro-flash.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>GPA limitations: misalignment of principles to diagram elements; struggles in plane geometry understanding and in complex problems requiring many principles as ACC declines with problem complexity.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'GeoSense: Evaluating Identification and Application of Geometric Principles in Multimodal Reasoning', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8557.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e8557.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models (LLMs) being evaluated on puzzle games that require spatial knowledge (such as Sudoku, Rubik's Cube, Minesweeper, etc.), including details of the models, the puzzles, the evaluation setup, the mechanisms or strategies used by the models, performance metrics, evidence of spatial reasoning, comparisons to other models or humans, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Claude37_Sonnet</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Claude 3.7 Sonnet</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Anthropic's Claude 3.7 Sonnet evaluated as a closed-source MLLM on GeoSense; shows strong theorem/formula identification and decent overall performance.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Claude37_Sonnet</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Closed-source multimodal model (Anthropic) evaluated zero-shot with CoT prompting on GeoSense tasks; required to explicitly identify and apply geometric principles.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_name</strong></td>
                            <td>GeoSense geometry problems</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_type</strong></td>
                            <td>Visual geometric problem solving requiring both diagram perception and symbolic reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>task_setup</strong></td>
                            <td>Zero-shot Chain-of-Thought prompting; outputs judged for GPI, GPA, and ACC using the paper's automated evaluation pipeline.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanisms_or_strategies</strong></td>
                            <td>CoT prompting and explicit principle enumeration in answers; multimodal perception for diagrams.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>On GeoSense (ALL aggregated): GPI = 68.7, GPA = 45.2, ACC = 57.6, AVG = 57.2 (Table 3). Shows high GPI for formulas/theorems and moderate GPA.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_of_spatial_reasoning</strong></td>
                            <td>High GPI values for computational principles but moderate GPA reflect partial spatial reasoning: capable of retrieving principles but less reliable in aligning them to diagram elements.</td>
                        </tr>
                        <tr>
                            <td><strong>comparisons</strong></td>
                            <td>Per paper, Claude37_Sonnet is competitive with other closed-source models but below Gemini-2.0-pro-flash in AVG and ACC. Closed-source group overall outperforms many open-source models.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>GPA remains a major limitation; struggles more on plane-figure understanding than on solid-figure calculation; errors due to mapping principles to diagram elements and occasional hallucination/calculation errors.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'GeoSense: Evaluating Identification and Application of Geometric Principles in Multimodal Reasoning', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8557.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e8557.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models (LLMs) being evaluated on puzzle games that require spatial knowledge (such as Sudoku, Rubik's Cube, Minesweeper, etc.), including details of the models, the puzzles, the evaluation setup, the mechanisms or strategies used by the models, performance metrics, evidence of spatial reasoning, comparisons to other models or humans, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Gemini-1.5-pro-flash</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Gemini 1.5 Pro Flash</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An earlier Gemini-family closed-source MLLM evaluated on GeoSense and included as a baseline; shows competitive performance but below Gemini-2.0-pro-flash.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Gemini-1.5-pro-flash</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Closed-source multimodal LLM (Gemini 1.5 variant) evaluated in zero-shot with Chain-of-Thought prompting on GeoSense; required explicit geometric-principle reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_name</strong></td>
                            <td>GeoSense geometry problems</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_type</strong></td>
                            <td>Visual mathematical puzzles requiring spatial diagram interpretation and symbolic reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>task_setup</strong></td>
                            <td>Zero-shot CoT prompting; models instructed to list and apply geometric principles; judged via automated pipeline for GPI/GPA/ACC.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanisms_or_strategies</strong></td>
                            <td>Chain-of-Thought prompting with explicit principle identification; multimodal perception for diagrams.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>On GeoSense (ALL aggregated): GPI = 67.9, GPA = 44.9, ACC = 55.7, AVG = 56.2 (Table 3).</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_of_spatial_reasoning</strong></td>
                            <td>Similar pattern to other top closed-source models: relatively high GPI but lower GPA, indicating some ability to retrieve geometric knowledge but imperfect visual alignment/application.</td>
                        </tr>
                        <tr>
                            <td><strong>comparisons</strong></td>
                            <td>Per paper, Gemini-1.5-pro-flash is outperformed by Gemini-2.0-pro-flash; closed-source group overall ranks above most open-source models.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>GPA errors (incorrect application/alignment) and difficulties with plane geometry; complex multi-principle tasks reduce GPI and ACC.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'GeoSense: Evaluating Identification and Application of Geometric Principles in Multimodal Reasoning', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>GeoQA: A Geometric Question Answering Benchmark Towards Multimodal Numerical Reasoning <em>(Rating: 2)</em></li>
                <li>GeonVerse: A Systematic Evaluation of Large Models for Geometric Reasoning <em>(Rating: 2)</em></li>
                <li>MathVerse: Does Your Multi-modal LLM Truly See the Diagrams in Visual Math Problems? <em>(Rating: 2)</em></li>
                <li>MathVista: Evaluating Mathematical Reasoning of Foundation Models in Visual Contexts <em>(Rating: 2)</em></li>
                <li>GeoEval: Benchmark for Evaluating LLMs and Multi-Modal Models on Geometry Problem-Solving <em>(Rating: 2)</em></li>
                <li>Wei-Math: Does Your Large Multimodal Model Achieve Human-like Mathematical Reasoning? <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-8557",
    "paper_id": "paper-9152697c8835946200f2f1119b3e80feeba937f8",
    "extraction_schema_id": "extraction-schema-153",
    "extracted_data": [
        {
            "name_short": "Gemini-2.0-pro-flash",
            "name_full": "Gemini 2.0 Pro Flash",
            "brief_description": "A closed-source multimodal large language model (MLLM) from the Gemini family evaluated on GeoSense geometry problems; reported as the top-performing model on this benchmark in the paper.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "Gemini-2.0-pro-flash",
            "model_description": "Closed-source multimodal LLM from the Gemini family used for visual + textual geometry problem solving; evaluated in a zero-shot setting with Chain-of-Thought prompting and required to explicitly identify and apply geometric principles.",
            "model_size": null,
            "puzzle_name": "GeoSense geometry problems (plane and solid geometry)",
            "puzzle_type": "Visual geometric problem-solving: multi-step spatial reasoning with diagrams covering plane and solid geometry (e.g., triangle/circle properties, surface area/volume, transformations).",
            "task_setup": "Zero-shot evaluation with CoT prompting; models are given a multimodal input (problem text + geometry diagram) and asked to produce step-by-step reasoning that explicitly identifies and applies geometric principles. Responses are judged for principle identification (GPI), principle application alignment to diagram elements (GPA), and final-answer accuracy (ACC) using GPT-4o-0513 as judge.",
            "mechanisms_or_strategies": "Chain-of-Thought prompting; models must explicitly name geometric principles and map them to diagram elements; no specialized symbolic solver was attached â€” pure MLLM reasoning over text+image. Evaluations required models to produce steps that include geometric principles and their application.",
            "performance_metrics": "On GeoSense (ALL aggregated): GPI = 72.1, GPA = 49.7, ACC = 74.1, AVG = 65.3 (percent scores reported in paper's Table 3 / Table 7). On subject breakdown (Table 4) shows strong CSF/CPF performance (e.g., ACC very high on computation of solid figures and calculation of plane figures).",
            "evidence_of_spatial_reasoning": "Measured indirectly via GPI/GPA: high GPI indicates good retrieval of relevant geometric principles; GPA (49.7) indicates only moderate success aligning principles to visual elements. Paper reports Gemini-2.0-pro-flash performs better on solid geometry than on plane-figure understanding, indicating partial spatial reasoning capability but failures in mapping/understanding complex planar relations.",
            "comparisons": "Reported as best overall AVG (65.3) among closed- and open-source models in the paper. Compared to GPT-4o and other closed-source models, Gemini-2.0-Pro-Flash has higher ACC and better GPI. Paper also notes open-source models generally underperform closed-source ones, and that larger model variants (when available) show improvements.",
            "limitations_or_failure_cases": "Primary failure mode is limited GPA: incorrect application/alignment of principles to diagram elements; difficulties in plane geometry (many confusable principles) and in complex problems requiring many principles. Error analysis lists GPA as primary error source; GPI still contributes (paper reports 23.5% of Gemini-2.0-Pro-Flash's errors due to GPI). Also, overthinking (in some models) can hurt ACC despite good GPI/GPA.",
            "uuid": "e8557.0",
            "source_info": {
                "paper_title": "GeoSense: Evaluating Identification and Application of Geometric Principles in Multimodal Reasoning",
                "publication_date_yy_mm": "2025-04"
            }
        },
        {
            "name_short": "GPT-4o",
            "name_full": "GPT-4o (multimodal variant)",
            "brief_description": "OpenAI's GPT-4o multimodal model evaluated on GeoSense; used as one of the closed-source baselines for geometry problem solving.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "GPT-4o",
            "model_description": "Closed-source multimodal model from OpenAI used with CoT prompting in zero-shot; asked to explicitly identify and apply geometric principles in visual geometry problems.",
            "model_size": null,
            "puzzle_name": "GeoSense geometry problems (plane and solid geometry)",
            "puzzle_type": "Visual geometric problem-solving requiring extraction of spatial relations from diagrams and symbolic reasoning (angles, similarity/congruence, areas/volumes).",
            "task_setup": "Zero-shot Chain-of-Thought prompting; required explicit principle identification and application in reasoning steps. Judging performed automatically via GPT-4o-0513.",
            "mechanisms_or_strategies": "Chain-of-Thought prompting; explicit naming and application of geometric principles; visual understanding component via model's multimodal capabilities.",
            "performance_metrics": "On GeoSense (ALL aggregated): GPI = 64.4, GPA = 45.3, ACC = 51.7, AVG = 53.8 (percent scores from Table 3). On subject breakdown GPT-4o shows high CSF GPI (91.3) and moderate ACC in computation-heavy tasks but lower performance on plane-figure understanding.",
            "evidence_of_spatial_reasoning": "Has strong ability to retrieve computational/formula-based principles (high GPI for formulas) but lower GPA indicates challenges mapping principles to visual elements; qualitative and aggregated metrics show limited adaptive application of geometric principles.",
            "comparisons": "Underperforms Gemini-2.0-pro-flash in AVG and ACC; compared to closed-source peers shows particular strengths on some computational solid-figure tasks but weaker GPA than some SOTA models. Paper compares across many models showing GPT-4o mid-to-high ranking but not top.",
            "limitations_or_failure_cases": "Failings largely in GPA (applying principles to diagrams) and in plane geometry understanding; some errors also from hallucinations and calculations per error breakdown. The paper notes lower GPA and ACC on UPF (understanding plane figures).",
            "uuid": "e8557.1",
            "source_info": {
                "paper_title": "GeoSense: Evaluating Identification and Application of Geometric Principles in Multimodal Reasoning",
                "publication_date_yy_mm": "2025-04"
            }
        },
        {
            "name_short": "Qwen2.5-VL-72B",
            "name_full": "Qwen2.5-VL 72B",
            "brief_description": "A large open-source vision-language model (72B) in the Qwen family evaluated on GeoSense; demonstrates strong overall performance among open-source models.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "Qwen2.5-VL-72B",
            "model_description": "Open-source multimodal model (72B parameters as indicated by name) designed for vision-language tasks; evaluated with CoT prompting in zero-shot and required to identify/apply geometric principles.",
            "model_size": "72B",
            "puzzle_name": "GeoSense geometry problems",
            "puzzle_type": "Multimodal geometric reasoning tasks requiring spatial understanding and algebraic computation grounded in visual diagrams.",
            "task_setup": "Zero-shot Chain-of-Thought prompting; models instructed to produce reasoning with explicit mention of geometric principles and their application. Responses are judged for GPI, GPA, and ACC by an automated judge.",
            "mechanisms_or_strategies": "Chain-of-Thought prompting and explicit principle annotation in outputs; internal spatial-aware modules are referenced in background (Qwen-VL family) but evaluation used plain prompting.",
            "performance_metrics": "On GeoSense (ALL aggregated): GPI = 68.5, GPA = 48.1, ACC = 63.8, AVG = 60.1 (Table 3). Subject breakdowns show higher ACC on calculation/formula tasks and weaker on plane-figure understanding.",
            "evidence_of_spatial_reasoning": "Shows relatively high GPI for formulas and theorems, indicating good retrieval of geometric knowledge; GPA below GPI indicates partial but imperfect alignment to spatial diagram elements. Performance trends (better in solid than plane geometry) indicate some spatial reasoning capacity but difficulty in complex/ambiguous planar relations.",
            "comparisons": "Among open-source models, Qwen2.5-VL-72B is one of the stronger performers (higher AVG) and benefits from scale (72B). Paper reports model-size-driven improvements in the Qwen2.5-VL series.",
            "limitations_or_failure_cases": "GPA remains a bottleneck; errors arise when mapping principles to visual elements and when many principles are required. The paper notes ACC declines as number of required principles increases, indicating brittleness on complex spatial tasks.",
            "uuid": "e8557.2",
            "source_info": {
                "paper_title": "GeoSense: Evaluating Identification and Application of Geometric Principles in Multimodal Reasoning",
                "publication_date_yy_mm": "2025-04"
            }
        },
        {
            "name_short": "QVQ-72B-Preview",
            "name_full": "QVQ 72B Preview",
            "brief_description": "A reasoning-optimized large multimodal model (72B preview) evaluated on GeoSense, showing high GPI and GPA but lower final-answer accuracy due to overthinking.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "QVQ-72B-Preview",
            "model_description": "A large MLLM fine-tuned/optimized for reasoning tasks (72B preview model); evaluated zero-shot with CoT prompting and asked to explicitly identify and apply geometric principles.",
            "model_size": "72B",
            "puzzle_name": "GeoSense geometry problems",
            "puzzle_type": "Visual mathematical reasoning requiring spatial alignment of principles to diagrams and symbolic computations.",
            "task_setup": "Zero-shot evaluation with Chain-of-Thought prompting; model required to output steps enumerating principles and their application, judged by GPI/GPA/ACC.",
            "mechanisms_or_strategies": "Optimized for reasoning (mixed-preference/multi-objective training referenced in paper), uses CoT prompting; tends to produce detailed reasoning steps which the authors note can lead to overthinking.",
            "performance_metrics": "On GeoSense (ALL aggregated): GPI = 72.3, GPA = 53.5, ACC = 54.3, AVG = 60.0 (Table 3). High GPI/GPA relative to many other models but ACC lower due to tendency to overthink and produce incorrect final answers.",
            "evidence_of_spatial_reasoning": "High GPI and GPA indicate strong retrieval and better alignment of principles to diagrams than many models; however qualitative behavior (overthinking) can reduce final correctness, demonstrating partial but imperfect spatial reasoning.",
            "comparisons": "Per paper, QVQ-72B-Preview achieves strong GPI/GPA scores among open-source models but ACC is lower than Gemini-2.0-Pro-Flash. Compared to other reasoning-optimized models it shows expected strengths in principle identification/application.",
            "limitations_or_failure_cases": "Overthinking (producing extra or incorrect steps) reduces ACC despite good GPI/GPA; GPA errors still present and perception-to-principle mapping failures remain. Paper highlights GPA as a common error source even for strong models like QVQ.",
            "uuid": "e8557.3",
            "source_info": {
                "paper_title": "GeoSense: Evaluating Identification and Application of Geometric Principles in Multimodal Reasoning",
                "publication_date_yy_mm": "2025-04"
            }
        },
        {
            "name_short": "InternVL2.5-38B-MPO",
            "name_full": "InternVL2.5-38B-MPO (Mixed Preference Optimization)",
            "brief_description": "A reasoning-enhanced variant of the InternVL2.5 open-source MLLM (38B) that shows improved reasoning on GeoSense relative to base InternVL2.5-38B.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "InternVL2.5-38B-MPO",
            "model_description": "Open-source InternVL2.5 series model (38B) further trained/optimized with mixed-preference optimization (MPO) to enhance reasoning; evaluated zero-shot with CoT prompting on GeoSense.",
            "model_size": "38B",
            "puzzle_name": "GeoSense geometry problems",
            "puzzle_type": "Multimodal geometry tasks requiring spatial comprehension and symbolic geometric reasoning.",
            "task_setup": "Zero-shot Chain-of-Thought prompting; models required to explicitly identify and apply geometric principles. Evaluated on GPI, GPA, and ACC metrics.",
            "mechanisms_or_strategies": "MPO training for reasoning improvements; use of CoT prompting during evaluation; forced explicit principle identification and application in outputs.",
            "performance_metrics": "On GeoSense (ALL aggregated): GPI = 53.9, GPA = 33.6, ACC = 27.7, AVG = 38.4 (Table 3). Shows a +9.1% AVG improvement over the base InternVL2.5-38B per authors (reported in text).",
            "evidence_of_spatial_reasoning": "Improved GPI relative to base model suggests better retrieval of necessary geometric principles; GPA and ACC remain low, indicating limited ability to align principles to diagram elements and produce correct final answers.",
            "comparisons": "Paper explicitly compares InternVL2.5-38B-MPO to InternVL2.5-38B, noting a ~9.1% AVG improvement. Still trails top closed-source models; scale and reasoning-specific training improve some capabilities but GPA remains limiting.",
            "limitations_or_failure_cases": "Low GPA and ACC indicate failures in applying principles to the diagram and in multi-step reasoning leading to final answer; errors include misperception of diagram elements and incorrect mapping between principle and diagram.",
            "uuid": "e8557.4",
            "source_info": {
                "paper_title": "GeoSense: Evaluating Identification and Application of Geometric Principles in Multimodal Reasoning",
                "publication_date_yy_mm": "2025-04"
            }
        },
        {
            "name_short": "Qwen2-VL-72B",
            "name_full": "Qwen2-VL 72B",
            "brief_description": "A large vision-language model (72B) from the Qwen-VL family evaluated on GeoSense; demonstrates solid performance across GPI/GPA/ACC metrics among open-source baselines.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "Qwen2-VL-72B",
            "model_description": "Open-source Qwen-VL family vision-language model (72B) designed for detailed perception and spatial understanding; evaluated with CoT prompting zero-shot on geometry problems.",
            "model_size": "72B",
            "puzzle_name": "GeoSense geometry problems",
            "puzzle_type": "Visual geometric problems requiring spatial reasoning (circle/triangle properties, areas, solid geometry).",
            "task_setup": "Zero-shot Chain-of-Thought prompting; models produce reasoning steps naming and applying geometric principles; judged by GPI/GPA/ACC automatically.",
            "mechanisms_or_strategies": "CoT prompting and visual-linguistic perception modules (Qwen-VL family emphasises spatial-aware modules). Explicit principle-identification requirement during reasoning.",
            "performance_metrics": "On GeoSense (ALL aggregated): GPI = 64.0, GPA = 43.4, ACC = 49.2, AVG = 52.2 (Table 3). Performance improves with larger model sizes in Qwen family according to paper.",
            "evidence_of_spatial_reasoning": "Moderate GPI and GPA suggest the model retrieves relevant geometric knowledge but has moderate success mapping to diagram elements; paper reports better performance on computational/formula tasks than on conceptual/theorem-based plane geometry.",
            "comparisons": "Per paper, Qwen2-VL-72B outperforms smaller Qwen variants and many open-source baselines but is below the top closed-source models like Gemini-2.0-pro-flash.",
            "limitations_or_failure_cases": "GPA limitations: misalignment of principles to diagram elements; struggles in plane geometry understanding and in complex problems requiring many principles as ACC declines with problem complexity.",
            "uuid": "e8557.5",
            "source_info": {
                "paper_title": "GeoSense: Evaluating Identification and Application of Geometric Principles in Multimodal Reasoning",
                "publication_date_yy_mm": "2025-04"
            }
        },
        {
            "name_short": "Claude37_Sonnet",
            "name_full": "Claude 3.7 Sonnet",
            "brief_description": "Anthropic's Claude 3.7 Sonnet evaluated as a closed-source MLLM on GeoSense; shows strong theorem/formula identification and decent overall performance.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "Claude37_Sonnet",
            "model_description": "Closed-source multimodal model (Anthropic) evaluated zero-shot with CoT prompting on GeoSense tasks; required to explicitly identify and apply geometric principles.",
            "model_size": null,
            "puzzle_name": "GeoSense geometry problems",
            "puzzle_type": "Visual geometric problem solving requiring both diagram perception and symbolic reasoning.",
            "task_setup": "Zero-shot Chain-of-Thought prompting; outputs judged for GPI, GPA, and ACC using the paper's automated evaluation pipeline.",
            "mechanisms_or_strategies": "CoT prompting and explicit principle enumeration in answers; multimodal perception for diagrams.",
            "performance_metrics": "On GeoSense (ALL aggregated): GPI = 68.7, GPA = 45.2, ACC = 57.6, AVG = 57.2 (Table 3). Shows high GPI for formulas/theorems and moderate GPA.",
            "evidence_of_spatial_reasoning": "High GPI values for computational principles but moderate GPA reflect partial spatial reasoning: capable of retrieving principles but less reliable in aligning them to diagram elements.",
            "comparisons": "Per paper, Claude37_Sonnet is competitive with other closed-source models but below Gemini-2.0-pro-flash in AVG and ACC. Closed-source group overall outperforms many open-source models.",
            "limitations_or_failure_cases": "GPA remains a major limitation; struggles more on plane-figure understanding than on solid-figure calculation; errors due to mapping principles to diagram elements and occasional hallucination/calculation errors.",
            "uuid": "e8557.6",
            "source_info": {
                "paper_title": "GeoSense: Evaluating Identification and Application of Geometric Principles in Multimodal Reasoning",
                "publication_date_yy_mm": "2025-04"
            }
        },
        {
            "name_short": "Gemini-1.5-pro-flash",
            "name_full": "Gemini 1.5 Pro Flash",
            "brief_description": "An earlier Gemini-family closed-source MLLM evaluated on GeoSense and included as a baseline; shows competitive performance but below Gemini-2.0-pro-flash.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "Gemini-1.5-pro-flash",
            "model_description": "Closed-source multimodal LLM (Gemini 1.5 variant) evaluated in zero-shot with Chain-of-Thought prompting on GeoSense; required explicit geometric-principle reasoning.",
            "model_size": null,
            "puzzle_name": "GeoSense geometry problems",
            "puzzle_type": "Visual mathematical puzzles requiring spatial diagram interpretation and symbolic reasoning.",
            "task_setup": "Zero-shot CoT prompting; models instructed to list and apply geometric principles; judged via automated pipeline for GPI/GPA/ACC.",
            "mechanisms_or_strategies": "Chain-of-Thought prompting with explicit principle identification; multimodal perception for diagrams.",
            "performance_metrics": "On GeoSense (ALL aggregated): GPI = 67.9, GPA = 44.9, ACC = 55.7, AVG = 56.2 (Table 3).",
            "evidence_of_spatial_reasoning": "Similar pattern to other top closed-source models: relatively high GPI but lower GPA, indicating some ability to retrieve geometric knowledge but imperfect visual alignment/application.",
            "comparisons": "Per paper, Gemini-1.5-pro-flash is outperformed by Gemini-2.0-pro-flash; closed-source group overall ranks above most open-source models.",
            "limitations_or_failure_cases": "GPA errors (incorrect application/alignment) and difficulties with plane geometry; complex multi-principle tasks reduce GPI and ACC.",
            "uuid": "e8557.7",
            "source_info": {
                "paper_title": "GeoSense: Evaluating Identification and Application of Geometric Principles in Multimodal Reasoning",
                "publication_date_yy_mm": "2025-04"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "GeoQA: A Geometric Question Answering Benchmark Towards Multimodal Numerical Reasoning",
            "rating": 2
        },
        {
            "paper_title": "GeonVerse: A Systematic Evaluation of Large Models for Geometric Reasoning",
            "rating": 2
        },
        {
            "paper_title": "MathVerse: Does Your Multi-modal LLM Truly See the Diagrams in Visual Math Problems?",
            "rating": 2
        },
        {
            "paper_title": "MathVista: Evaluating Mathematical Reasoning of Foundation Models in Visual Contexts",
            "rating": 2
        },
        {
            "paper_title": "GeoEval: Benchmark for Evaluating LLMs and Multi-Modal Models on Geometry Problem-Solving",
            "rating": 2
        },
        {
            "paper_title": "Wei-Math: Does Your Large Multimodal Model Achieve Human-like Mathematical Reasoning?",
            "rating": 2
        }
    ],
    "cost": 0.019488,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>GeoSense: Evaluating Identification and Application of Geometric Principles in Multimodal Reasoning</h1>
<p>Liangyu Xu<em>, Yingxiu Zhao</em>, Jingyun Wang, Yingyao Wang<br>Pi Bu, Chen Wang, Mingliang Zhang, Jihao Gu<br>Xiang Li, Xiaoyong Zhu, Jun Song ${ }^{\dagger}$, Bo Zheng<br>Taobao \&amp; Tmall Group of Alibaba<br>Beijing, China</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: The performance of MLLMs in different subjects across (a) GPI, (b) GPA, and (c) ACC.</p>
<h2>ABSTRACT</h2>
<p>Geometry problem-solving (GPS), a challenging task requiring both visual comprehension and symbolic reasoning, effectively measures the reasoning capabilities of multimodal large language models (MLLMs). Humans exhibit strong reasoning ability in this task through accurate identification and adaptive application of geometric principles within visual contexts. However, existing benchmarks fail to jointly assess both dimensions of the human-like geometric reasoning mechanism in MLLMs, remaining a critical gap in assessing their ability to tackle GPS. To this end, we introduce GeoSense, the first comprehensive bilingual benchmark designed to systematically evaluate the geometric reasoning abilities of MLLMs through the lens of geometric principles. GeoSense features a five-level hierarchical framework of geometric principles spanning plane and solid geometry, an intricately annotated dataset of 1,789 problems, and an innovative evaluation strategy. Through extensive experiments on GeoSense with various open-source and closedsource MLLMs, we observe that Gemini-2.0-pro-flash performs best, achieving an overall score of 65.3. Our in-depth analysis reveals that the identification and application of geometric principles remain a bottleneck for leading MLLMs, jointly hindering their reasoning abilities. These findings underscore GeoSense's potential to guide future advancements in MLLMs' geometric reasoning capabilities,</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup>paving the way for more robust and human-like reasoning in artificial intelligence. We will open-source the code and dataset within a month.</p>
<h2>CCS CONCEPTS</h2>
<ul>
<li>Theory of computation $\rightarrow$ Computational geometry.</li>
</ul>
<h2>KEYWORDS</h2>
<p>Geometry problem-solving, Multimodal reasoning, Geometric principles, Benchmark</p>
<h2>1 INTRODUCTION</h2>
<p>Geometry Problem-Solving (GPS) involves understanding spatial relationships and employing symbolic reasoning to arrive at logical solutions within complex visual contexts [6, 17, 26, 31, 51]. When faced with geometry problems, humans exhibit exceptional skills by correctly identifying geometric principles ${ }^{\dagger}$ and then adaptively applying them to derive solutions, as illustrated in Fig. 2.</p>
<p>With the rise of multimodal large language models (MLLMs) [1, 24, 29, 36, 40], GPS emerges as a crucial testbed for evaluating the reasoning capabilities of MLLMs. Numerous benchmarks are developed to assess MLLMs' performance on GPS, with most prior studies [6, 25, 26, 34] primarily focusing on the correctness of final</p>
<p><sup id="fnref:1"><a class="footnote-ref" href="#fn:1">2</a></sup></p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: Humans solve geometric problems by first identifying the relevant geometric principles and then applying them to derive solutions.
answers. Recent researches shift attention to the reasoning process of MLLMs in GPS [4, 31, 51]. Despite progress, challenges persist. For instance, studies like MathVerse [51] and MathFlow [4] point out that MLLMs' imprecise perception and interpretation of geometric diagrams can impede subsequent reasoning. Nonetheless, through extensive experiments and analysis, we further reveal that even when MLLMs demonstrate accurate visual perception and logical reasoning steps, their lack of essential geometric principles often leads to failure, as shown in Fig. 3 (a). Moreover, while WeMath [31] acknowledges the importance of underlying principles, it falls short of evaluating whether MLLMs correctly apply them within the visual context. For example, even with correct retrieval of geometric principles, incorrect application can still result in reasoning failures, as shown in Fig. 3 (b). These underscore a critical gap in current research: There is a lack of comprehensive evaluation framework to assess simultaneously both the accurate identification of geometric principles and their proper contextual application within complicated visual scenarios.</p>
<p>In light of these limitations, we propose two key questions for evaluating MLLMs in GPS tasks:
Q1: Could MLLMs accurately identify the required geometric principles when solving geometric problems?
Q2: Are MLLMs capable of adaptively applying geometric principles to visual geometric diagrams?</p>
<p>To address these questions, we propose GeoSense, the first comprehensive bilingual benchmark designed to systematically assess the reasoning abilities of MLLMs through the perspective of geometric principles. GeoSense features a hierarchical system of geometric principles, an intricately structured and finely annotated dataset, and an innovative evaluation strategy. It supports both English and Chinese, bridging human intuition and MLLMs' reasoning. Specifically, we first organize geometric principles into a multilevel framework consisting of 148 unique principles, spanning from plane geometry to solid geometry. This framework encompasses graphical computation, conceptual understanding, and detailed definitions, theorems, and formulas. Next, we curate a dataset of 1,789 geometric math problems sourced from existing benchmarks and
<img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3: MLLMs encounter failures in GPS: Qwen2-VL-7B fails to identify the correct principle and GPT-4o struggles to apply principles to solve questions.
the IXL website ${ }^{2}$. To ensure precise annotation, we employ 23 expert annotators and develop a semi-automated annotation pipeline, ultimately generating 5,556 geometric principles and their aligned application within geometric diagrams. Furthermore, we propose a novel evaluation strategy with two key evaluation metrics: Geometry Principle Identification (GPI), which assesses MLLMs' ability to identify the most relevant geometric principles for a given problem; and Geometry Principle Application (GPA), which evaluates their skills in aligning and applying these principles to specific elements in geometric diagrams. Additionally, we use answer accuracy (ACC) as a holistic measure of a model's overall performance. Table 1 compares GeoSense with other GPS-related reasoning benchmarks.</p>
<p>Extensive experiments on GeoSense are performed with various popular open-source and closed-source MLLMs, yielding several key insights. As shown in Fig. 1, while MLLMs excel in computation tasks, they struggle with understanding tasks, which can be proven by lower GPI scores in plane geometry. Notably, though Gemini-2.0-Pro-Flash outperforms others by final answer accuracy, its GPA scores, representing the capability of adaptively applying geometric principles within visual contexts, are still limited. Such a result further verifies that our proposed GeoSense points out new pathways for MLLMs' future advancements in GPS.</p>
<p>In summary, our contributions are outlined as follows:</p>
<ul>
<li>We develop GeoSense, the first comprehensive bilingual benchmark that systematically evaluates the reasoning abilities of MLLMs rooted in geometric principles.</li>
<li>We establish a holistic framework for geometric principles, providing a structured hierarchy for geometric reasoning.</li>
<li>We design an innovative evaluation strategy to thoroughly assess the MLLMs' ability to identify and effectively apply them within visual diagrams.</li>
<li>Our extensive experiments and analysis yield valuable insights for enhancing MLLMs reasoning abilities for solving geometry problems.</li>
</ul>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<table>
<thead>
<tr>
<th style="text-align: left;">BenchMark</th>
<th style="text-align: center;">Size</th>
<th style="text-align: center;">Language</th>
<th style="text-align: center;">Category</th>
<th style="text-align: center;">Level</th>
<th style="text-align: center;">CoT-E.</th>
<th style="text-align: center;">P.I.</th>
<th style="text-align: center;">P.A.</th>
<th style="text-align: center;">Metric</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">GeoS [34]</td>
<td style="text-align: center;">186</td>
<td style="text-align: center;">EN</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">SAT</td>
<td style="text-align: center;">$\times$</td>
<td style="text-align: center;">$\times$</td>
<td style="text-align: center;">$\times$</td>
<td style="text-align: center;">Rule-based</td>
</tr>
<tr>
<td style="text-align: left;">Geometry3K [26]</td>
<td style="text-align: center;">601</td>
<td style="text-align: center;">EN</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">Middle School</td>
<td style="text-align: center;">$\times$</td>
<td style="text-align: center;">$\times$</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">Rule-based</td>
</tr>
<tr>
<td style="text-align: left;">GeoQA [6]</td>
<td style="text-align: center;">754</td>
<td style="text-align: center;">EN\&amp;CH</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">Middle School</td>
<td style="text-align: center;">$\times$</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">$\times$</td>
<td style="text-align: center;">Rule-based</td>
</tr>
<tr>
<td style="text-align: left;">GeoQA+ [3]</td>
<td style="text-align: center;">755</td>
<td style="text-align: center;">EN\&amp;CH</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">Middle School</td>
<td style="text-align: center;">$\times$</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">$\times$</td>
<td style="text-align: center;">Rule-based</td>
</tr>
<tr>
<td style="text-align: left;">PGPS9K [49]</td>
<td style="text-align: center;">1,000</td>
<td style="text-align: center;">EN</td>
<td style="text-align: center;">30</td>
<td style="text-align: center;">Middle School</td>
<td style="text-align: center;">$\times$</td>
<td style="text-align: center;">$\times$</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">Rule-based</td>
</tr>
<tr>
<td style="text-align: left;">GeoEval [48]</td>
<td style="text-align: center;">2,000</td>
<td style="text-align: center;">EN\&amp;CH</td>
<td style="text-align: center;">7</td>
<td style="text-align: center;">Middle\&amp;High School</td>
<td style="text-align: center;">$\times$</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">$\times$</td>
<td style="text-align: center;">Rule-based</td>
</tr>
<tr>
<td style="text-align: left;">GeomVerse [17]</td>
<td style="text-align: center;">2,000</td>
<td style="text-align: center;">EN</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">Synthetic</td>
<td style="text-align: center;">$\times$</td>
<td style="text-align: center;">$\times$</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">Rule-based</td>
</tr>
<tr>
<td style="text-align: left;">MathVision [51]</td>
<td style="text-align: center;">2,612</td>
<td style="text-align: center;">EN</td>
<td style="text-align: center;">12</td>
<td style="text-align: center;">Competitions</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">$\times$</td>
<td style="text-align: center;">$\times$</td>
<td style="text-align: center;">LLM-as-a-judge</td>
</tr>
<tr>
<td style="text-align: left;">MathVista [25]</td>
<td style="text-align: center;">5,487</td>
<td style="text-align: center;">EN</td>
<td style="text-align: center;">19</td>
<td style="text-align: center;">SAT\&amp;Middle School</td>
<td style="text-align: center;">$\times$</td>
<td style="text-align: center;">$\times$</td>
<td style="text-align: center;">$\times$</td>
<td style="text-align: center;">LLM-as-a-judge</td>
</tr>
<tr>
<td style="text-align: left;">MathVerse [51]</td>
<td style="text-align: center;">2,612</td>
<td style="text-align: center;">EN</td>
<td style="text-align: center;">12</td>
<td style="text-align: center;">High School</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">$\times$</td>
<td style="text-align: center;">$\times$</td>
<td style="text-align: center;">LLM-as-a-judge</td>
</tr>
<tr>
<td style="text-align: left;">WeMath [31]</td>
<td style="text-align: center;">1,674</td>
<td style="text-align: center;">EN</td>
<td style="text-align: center;">67</td>
<td style="text-align: center;">Middle\&amp;High School</td>
<td style="text-align: center;">$\times$</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">$\times$</td>
<td style="text-align: center;">Rule-based</td>
</tr>
<tr>
<td style="text-align: left;">GeoSense</td>
<td style="text-align: center;">1,789</td>
<td style="text-align: center;">EN\&amp;CH</td>
<td style="text-align: center;">148</td>
<td style="text-align: center;">Middle\&amp;High School</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">LLM-as-a-judge</td>
</tr>
</tbody>
</table>
<p>Table 1: Comparisons between our GeoSense and other GPS-related benchmarks. CoT-E., P.I. and P.A. are short for CoT evaluation, principle identification, and principle application, respectively.</p>
<h2>2 THE GEOSENSE DATASET</h2>
<p>We first give a clear definition of geometric principles in Section 2.1. Then, in Section 2.2, we provide an overview of the dataset, including its composition, categorization, and detailed statistical information. We also construct a fine-grained hierarchical framework of geometric principles. Furthermore, in Section 2.3, we introduce a pipeline for the annotation of essential geometric principles and their application in visual contexts for our collected data.</p>
<h3>2.1 Definition of Geometric Principles</h3>
<p>"Euclid's elements ${ }^{3 "}$ " provides a foundational classification of geometric propositions, including definitions, theorems, postulates, and axioms. Drawing inspiration from Euclid's systematic approach, we focus on the most commonly utilized categories and define geometric principles as fundamental concepts in geometry. These principles encapsulate definitions, theorems, and formulas, with the latter specifically representing mathematical expressions for calculations, such as the calculation of length, area, and volume.</p>
<h3>2.2 Data Collection and Statistics</h3>
<p>We present the statistical information of our proposed GeoSense dataset in Table 2. GeoSense consists of 1,789 geometric math problems: 1,116 problems from existing benchmarks [6, 26, 34, 51] and 666 problems from the IXL website ${ }^{4}$. With these geometric math problems, we annotate 5,556 necessary geometric principles ( 3,235 definitions, 1,714 theorems, and 607 formulas), and their contextual applications. Furthermore, all geometric principles are categorized into five hierarchical levels, forming a comprehensive framework for geometric knowledge (see Fig. 4 and details in Appendix 4.1). We initially categorize these principles into plane and solid geometry, and then progressively refine the classification from various perspectives, such as graphical computation and understanding. This process ultimately leads to detailed definitions, theorems, and formulas. With this framework, we could evaluate the MLLMs' mastery of geometric knowledge across different dimensions and granularities for GPS tasks.</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup>Table 2: Key Statistics of our GeoSense.</p>
<h3>2.3 Data Annotation and Review</h3>
<p>We develop a rigorous and meticulous semi-automated annotation pipeline to label the necessary geometric principles and their contextual applications within visual geometric images for each problem. Initially, we prompt GPT-4o to generate a detailed geometric problem-solving process for each question, which explicitly specifies the names of the geometric principles and their application. Human annotation experts then review and correct any errors in the responses provided by GPT-4o. After obtaining a standardized reasoning process, we prompt GPT-4o again to extract the geometric principles and their specific application ${ }^{5}$. Human annotation experts then standardize the names of the extracted geometric principles and their applications within the problems, ensuring accuracy and consistency. Finally, human annotation experts use</p>
<p><sup id="fnref2:1"><a class="footnote-ref" href="#fn:1">2</a></sup></p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 4: Diagram of the top-3 levels of geometric principles ( 5 levels in total). See details in Appendix 4.1.
<note></note> tags to mark the key points in the application process of geometric principles, providing references for subsequent evaluations. Notably, our annotation team consists of 23 expert annotators, each holding at least a bachelor's degree. To ensure data quality, the annotation results are cross-validated a minimum of two times. The complete annotation training and the entire annotation process together spanned a period of 4 weeks.</p>
<h2>3 EVALUATION STRATEGY</h2>
<p>Geometry problem-solving (GPS) serves as an effective measurement of MLLMs' reasoning capability, requiring both appropriate identification of geometric principles and correct application within complex visual context. However, existing benchmarks fail to evaluate both aspects, limiting a systematic evaluation of MLLMs on GPS. In this section, we propose a new evaluation system, consisting of Geometric Principles Identification (GPI) score (Section 3.1) and Geometric Principles Application (GPA) score (Section 3.2), to fully evaluate human-like reasoning mechanism of MLLMs in GPS. Fig. 5 illustrates the overall evaluation framework of GeoSense.</p>
<h3>3.1 Geometric Principles Identification</h3>
<p>In this section, we propose a Geometric Principles Identification (GPI) score to assess a MLLM's geometric principle identification ability, i.e., whether the MLLM can accurately identify necessary geometric principles to solve the problem. As shown in Figure 5, given a geometric problem $q_{i}$, its corresponding annotation in our dataset explicitly presents the set of necessary geometric principles $P_{i}=\left{p_{i}^{1}, p_{i}^{2}, \ldots, p_{i}^{n}\right}$. For each principle $p_{i}^{j}$, we prompt GPT-4o to determine whether it appears in the MLLM's response. The GPI score $S_{i}^{j}$ is defined by:</p>
<p>$$
S_{i}^{j}=\frac{\sum_{j=1}^{n} F\left(p_{i}^{j}\right)}{n}
$$</p>
<p>where $F\left(p_{i}^{j}\right) \in{0,1}$ indicates whether the principle $p_{i}^{j}$ is applied in the MLLM's response. The score $S_{i}^{R}$ reflects whether the MLLM can correctly retrieve the appropriate geometric principles when resolving geometric problems. However, the GPI score alone can not reveal whether the model applies these principles appropriately within the visual context. Such a challenge mirrors the limitations in human geometric reasoning, wherein we may grasp accurate principles such as similar triangles yet still struggle to correctly apply it within the geometric diagram.</p>
<h3>3.2 Geometric Principles Application</h3>
<p>To evaluate and understand more granularly whether MLLMs can proficiently apply geometric principles to solve problems in geometric reasoning, we further analyze the model's accuracy in applying these principles within a visual context. In our benchmark, we annotate not only the set of geometric principles required for each problem $P_{i}=\left{p_{i}^{1}, p_{i}^{2}, \ldots, p_{i}^{n}\right}$, but also their corresponding representations in the geometric diagrams $C_{i}=\left{c_{i}^{1}, c_{i}^{2}, \ldots, c_{i}^{n}\right}$.</p>
<p>We use <note> tags to mark the key elements essential for correct problem-solving, as shown in Figure 1. The key elements within each geometric principle $c_{i}^{j}$ are denoted as $m_{i}^{j}$. When $F\left(p_{i}^{j}\right)=1$, we use GPT-4o to extract content related to this principle from the model's response $\hat{y}<em i="i">{i}$, denoted as $\hat{c}</em>}^{j}$, with its key elements represented as $\hat{m<em i="i">{i}^{j}$. Next, we compare the key elements in $m</em>}^{j}$ and $\hat{m<em i="i">{i}^{j}$ to calculate precision and recall for each geometric principle and subsequently compute the F1 score. Based on this, we aggregate the results to obtain the overall knowledge application evaluation measure $S</em>$ :}^{A</p>
<p>$$
S_{i}^{A}=\frac{\sum_{j=1}^{n} F\left(p_{i}^{j}\right) \cdot \frac{2 \times\left|\hat{m}<em i="i">{i}^{j} / \mid m</em>}^{j}\right|}{\left|\hat{m<em i="i">{i}^{j}\right|+\left|m</em>
$$}^{j}\right|}}{\sum_{j=1}^{n} F\left(p_{i}^{j}\right)</p>
<p>This measure allows us to effectively evaluate the model's ability to apply geometric principles appropriately within a visual context.</p>
<h3>3.3 Final Answer Evaluation</h3>
<p>We also evaluate the correctness of the final answers. Specifically, given a problem $q_{i}$ and its corresponding geometric image $x_{i}$, the final answer generated by the model is denoted as $\hat{y}<em i="i">{i}$. We compare $\hat{y}</em>$ as follows:}$ with the ground truth $y_{i}$ and define the final answer score $S_{i}^{F</p>
<p>$$
S_{i}^{F}= \begin{cases}1, &amp; \hat{y}<em i="i">{i}=y</em>
$$} \ 0, &amp; \text { otherwise }\end{cases</p>
<p>This metric quantifies the overall performance of MLLMs on GPS.</p>
<h2>4 EXPERIMENTS</h2>
<p>In this section, we systematically evaluate existing MLLMs on GeoSense. First, we introduce the experimental setup in Section 4.1. Then, we detail the experimental results and analysis in Section 4.2, and present the error analysis in Section 4.4.</p>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Figure 5: Illustration of GenSense evaluation strategy. MLLMs are assessed through three aspects: identification (i.e., GPI), applications (i.e., GPA) of geometric principles, and final answer accuracy.</p>
<h3>4.1 Experimental Setup</h3>
<p>Evaluation Models. We evaluate the geometric reasoning capabilities of three categories of MLLMs on GeoSense: 1) closedsource MLLMs, including Claude35_Sonnet ${ }^{6}$, Claude37_Sonnet ${ }^{7}$, Gemini-2.0-pro-flash ${ }^{8}$, and GPT-4o ${ }^{9}$; 2) open-source MLLMs, including the InternVL2.5 series [9], Deepseek-VL2 [43] series, Qwen2VL series [40], Qwen2.5-VL ${ }^{10}$ series, Llama-vision-11B/90B ${ }^{11}$, and LLaVA-onevision-0.6B/72B [19]; and 3) reasoning MLLMs, including InternVL2.5-38B-MPO [41], QVQ-72B-Preview ${ }^{12}$.</p>
<p>Implementation Details. All our evaluations adopt CoT prompting technique[42]. Additionally, the models are further required to explicitly identify and apply the necessary geometric principles during the reasoning steps. All experiments are conducted in a zero-shot setting to reveal the models' general reasoning abilities. Open-source model reasoning is performed on NVIDIA A100 GPUs, while closed-source model reasoning is conducted via their official API calls. The temperature and sampling parameters are set to the official default settings for each model. For evaluation, we use "GPT-4o-0513" as the judge.</p>
<p><sup id="fnref4:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<h3>4.2 Experimental results</h3>
<p>To systematically examine the multimodal reasoning capabilities grounded in geometric principles, we report the evaluation results of various models on GeoSense for three attributes (i.e., definitions, theorems, and formulas) as depicted in Table 3. Additionally, we measure five detailed topics namely, calculation of solid figures (CSF), understanding of solid figures (USF), transformation and motion of plane figures (TMPF), calculation of plane figures (CPF), and understanding of plane figures (UPF) as illustrated in Table 4.</p>
<p>From the results, we notice that closed-sourced models generally outperform open-source models. Among them, Gemini-2.0-ProFlash performs the best, with an average score of 65.3. MLLMs trained specifically for reasoning tasks show significant improvements in reasoning abilities; for example, InternVL2.5-38B-MPO exhibits a $9.1 \%$ average performance improvement (AVG) compared to InternVL2.5-38B. QVQ-72B-Preview performs well in GPI and GPA but has a lower ACC than Gemini-2.0-Pro-Flash, primarily due to overthinking leading to incorrect answers. Additionally, larger model sizes contribute to performance enhancements, as seen in the Qwen2.5-VL series, where overall performance improves with increasing model size.</p>
<p>From the results across different subjects in Table 4 and Fig. 1, we observe that models perform better in solid geometry than in plane geometry, and understanding plane geometric figures is a common weakness among all MLLMs. This is due to the large number of geometric principles involved in plane geometry, which includes many easily confused concepts (such as determining the similarity and congruence of triangles). These factors pose greater challenges</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Model</th>
<th style="text-align: center;">Definitions</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Theorems</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Formulas</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">ALL</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">GPI</td>
<td style="text-align: center;">GPA</td>
<td style="text-align: center;">ACC.</td>
<td style="text-align: center;">GPI</td>
<td style="text-align: center;">GPA</td>
<td style="text-align: center;">ACC</td>
<td style="text-align: center;">GPI</td>
<td style="text-align: center;">GPA</td>
<td style="text-align: center;">ACC</td>
<td style="text-align: center;">GPI</td>
<td style="text-align: center;">GPA</td>
<td style="text-align: center;">ACC</td>
<td style="text-align: center;">AVG.</td>
</tr>
<tr>
<td style="text-align: center;">Closed-Sourced MLLMs</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Claude35_Sonnet</td>
<td style="text-align: center;">56.5</td>
<td style="text-align: center;">41.2</td>
<td style="text-align: center;">41.9</td>
<td style="text-align: center;">54.9</td>
<td style="text-align: center;">46.8</td>
<td style="text-align: center;">33.8</td>
<td style="text-align: center;">82.8</td>
<td style="text-align: center;">52.5</td>
<td style="text-align: center;">52.9</td>
<td style="text-align: center;">63.2</td>
<td style="text-align: center;">40.8</td>
<td style="text-align: center;">46.1</td>
<td style="text-align: center;">50.0</td>
</tr>
<tr>
<td style="text-align: center;">Claude37_Sonnet</td>
<td style="text-align: center;">62.0</td>
<td style="text-align: center;">46.7</td>
<td style="text-align: center;">54.3</td>
<td style="text-align: center;">60.2</td>
<td style="text-align: center;">50.0</td>
<td style="text-align: center;">46.5</td>
<td style="text-align: center;">92.4</td>
<td style="text-align: center;">56.1</td>
<td style="text-align: center;">67.9</td>
<td style="text-align: center;">68.7</td>
<td style="text-align: center;">45.2</td>
<td style="text-align: center;">57.6</td>
<td style="text-align: center;">57.2</td>
</tr>
<tr>
<td style="text-align: center;">Gemini-1.5-pro-flash</td>
<td style="text-align: center;">60.2</td>
<td style="text-align: center;">43.8</td>
<td style="text-align: center;">53.0</td>
<td style="text-align: center;">58.7</td>
<td style="text-align: center;">51.5</td>
<td style="text-align: center;">45.6</td>
<td style="text-align: center;">85.9</td>
<td style="text-align: center;">55.3</td>
<td style="text-align: center;">56.1</td>
<td style="text-align: center;">67.9</td>
<td style="text-align: center;">44.9</td>
<td style="text-align: center;">55.7</td>
<td style="text-align: center;">56.2</td>
</tr>
<tr>
<td style="text-align: center;">Gemini-2.0-pro-flash</td>
<td style="text-align: center;">64.2</td>
<td style="text-align: center;">47.0</td>
<td style="text-align: center;">73.3</td>
<td style="text-align: center;">72.7</td>
<td style="text-align: center;">59.0</td>
<td style="text-align: center;">72.4</td>
<td style="text-align: center;">87.4</td>
<td style="text-align: center;">60.0</td>
<td style="text-align: center;">77.9</td>
<td style="text-align: center;">72.1</td>
<td style="text-align: center;">49.7</td>
<td style="text-align: center;">74.1</td>
<td style="text-align: center;">65.3</td>
</tr>
<tr>
<td style="text-align: center;">GPT-40</td>
<td style="text-align: center;">56.3</td>
<td style="text-align: center;">46.3</td>
<td style="text-align: center;">48.0</td>
<td style="text-align: center;">54.1</td>
<td style="text-align: center;">49.3</td>
<td style="text-align: center;">37.4</td>
<td style="text-align: center;">90.8</td>
<td style="text-align: center;">58.3</td>
<td style="text-align: center;">61.1</td>
<td style="text-align: center;">64.4</td>
<td style="text-align: center;">45.3</td>
<td style="text-align: center;">51.7</td>
<td style="text-align: center;">53.8</td>
</tr>
<tr>
<td style="text-align: center;">Open-Soured MLLMs</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">InternVL2.5-8B</td>
<td style="text-align: center;">43.7</td>
<td style="text-align: center;">40.7</td>
<td style="text-align: center;">21.2</td>
<td style="text-align: center;">38.2</td>
<td style="text-align: center;">39.3</td>
<td style="text-align: center;">20.0</td>
<td style="text-align: center;">67.6</td>
<td style="text-align: center;">24.7</td>
<td style="text-align: center;">13.7</td>
<td style="text-align: center;">46.7</td>
<td style="text-align: center;">27.3</td>
<td style="text-align: center;">21.1</td>
<td style="text-align: center;">31.7</td>
</tr>
<tr>
<td style="text-align: center;">InternVL2.5-38B</td>
<td style="text-align: center;">48.7</td>
<td style="text-align: center;">40.6</td>
<td style="text-align: center;">28.9</td>
<td style="text-align: center;">44.5</td>
<td style="text-align: center;">43.9</td>
<td style="text-align: center;">29.8</td>
<td style="text-align: center;">74.8</td>
<td style="text-align: center;">26.4</td>
<td style="text-align: center;">16.0</td>
<td style="text-align: center;">52.7</td>
<td style="text-align: center;">31.1</td>
<td style="text-align: center;">27.3</td>
<td style="text-align: center;">37.0</td>
</tr>
<tr>
<td style="text-align: center;">InternVL2.5-38B-MPO ${ }^{\dagger}$</td>
<td style="text-align: center;">50.7</td>
<td style="text-align: center;">44.6</td>
<td style="text-align: center;">29.7</td>
<td style="text-align: center;">48.2</td>
<td style="text-align: center;">46.4</td>
<td style="text-align: center;">30.0</td>
<td style="text-align: center;">75.6</td>
<td style="text-align: center;">29.3</td>
<td style="text-align: center;">16.0</td>
<td style="text-align: center;">53.9</td>
<td style="text-align: center;">33.6</td>
<td style="text-align: center;">27.7</td>
<td style="text-align: center;">38.4</td>
</tr>
<tr>
<td style="text-align: center;">InternVL2.5-78B</td>
<td style="text-align: center;">49.0</td>
<td style="text-align: center;">45.2</td>
<td style="text-align: center;">29.8</td>
<td style="text-align: center;">48.6</td>
<td style="text-align: center;">46.8</td>
<td style="text-align: center;">32.0</td>
<td style="text-align: center;">80.2</td>
<td style="text-align: center;">30.5</td>
<td style="text-align: center;">18.3</td>
<td style="text-align: center;">53.7</td>
<td style="text-align: center;">32.9</td>
<td style="text-align: center;">28.7</td>
<td style="text-align: center;">38.4</td>
</tr>
<tr>
<td style="text-align: center;">Deepseek-VL2-small</td>
<td style="text-align: center;">25.6</td>
<td style="text-align: center;">35.7</td>
<td style="text-align: center;">23.3</td>
<td style="text-align: center;">26.7</td>
<td style="text-align: center;">36.1</td>
<td style="text-align: center;">19.5</td>
<td style="text-align: center;">67.9</td>
<td style="text-align: center;">48.1</td>
<td style="text-align: center;">30.2</td>
<td style="text-align: center;">34.2</td>
<td style="text-align: center;">23.8</td>
<td style="text-align: center;">26.3</td>
<td style="text-align: center;">28.1</td>
</tr>
<tr>
<td style="text-align: center;">Deepseek-VL2</td>
<td style="text-align: center;">40.1</td>
<td style="text-align: center;">37.8</td>
<td style="text-align: center;">33.1</td>
<td style="text-align: center;">40.6</td>
<td style="text-align: center;">39.6</td>
<td style="text-align: center;">26.0</td>
<td style="text-align: center;">76.3</td>
<td style="text-align: center;">52.8</td>
<td style="text-align: center;">42.4</td>
<td style="text-align: center;">48.4</td>
<td style="text-align: center;">33.4</td>
<td style="text-align: center;">35.7</td>
<td style="text-align: center;">39.2</td>
</tr>
<tr>
<td style="text-align: center;">Llama-vision-11B</td>
<td style="text-align: center;">43.2</td>
<td style="text-align: center;">36.1</td>
<td style="text-align: center;">22.6</td>
<td style="text-align: center;">37.9</td>
<td style="text-align: center;">35.6</td>
<td style="text-align: center;">18.7</td>
<td style="text-align: center;">74.8</td>
<td style="text-align: center;">37.5</td>
<td style="text-align: center;">29.8</td>
<td style="text-align: center;">47.9</td>
<td style="text-align: center;">29.2</td>
<td style="text-align: center;">24.8</td>
<td style="text-align: center;">34.0</td>
</tr>
<tr>
<td style="text-align: center;">Llama-vision-90B</td>
<td style="text-align: center;">49.1</td>
<td style="text-align: center;">39.2</td>
<td style="text-align: center;">27.3</td>
<td style="text-align: center;">42.0</td>
<td style="text-align: center;">36.0</td>
<td style="text-align: center;">21.2</td>
<td style="text-align: center;">78.2</td>
<td style="text-align: center;">43.6</td>
<td style="text-align: center;">37.0</td>
<td style="text-align: center;">52.9</td>
<td style="text-align: center;">31.4</td>
<td style="text-align: center;">29.8</td>
<td style="text-align: center;">38.0</td>
</tr>
<tr>
<td style="text-align: center;">LLaVA-onevison-7B</td>
<td style="text-align: center;">36.3</td>
<td style="text-align: center;">38.0</td>
<td style="text-align: center;">22.7</td>
<td style="text-align: center;">39.2</td>
<td style="text-align: center;">39.2</td>
<td style="text-align: center;">22.7</td>
<td style="text-align: center;">72.9</td>
<td style="text-align: center;">40.6</td>
<td style="text-align: center;">42.6</td>
<td style="text-align: center;">41.4</td>
<td style="text-align: center;">26.0</td>
<td style="text-align: center;">22.8</td>
<td style="text-align: center;">30.1</td>
</tr>
<tr>
<td style="text-align: center;">LLaVA-onevison-72B</td>
<td style="text-align: center;">47.9</td>
<td style="text-align: center;">39.0</td>
<td style="text-align: center;">33.7</td>
<td style="text-align: center;">49.6</td>
<td style="text-align: center;">44.8</td>
<td style="text-align: center;">36.4</td>
<td style="text-align: center;">68.3</td>
<td style="text-align: center;">55.9</td>
<td style="text-align: center;">43.1</td>
<td style="text-align: center;">52.5</td>
<td style="text-align: center;">33.2</td>
<td style="text-align: center;">37.2</td>
<td style="text-align: center;">41.0</td>
</tr>
<tr>
<td style="text-align: center;">Qwen2-VL-72B</td>
<td style="text-align: center;">57.2</td>
<td style="text-align: center;">44.2</td>
<td style="text-align: center;">46.6</td>
<td style="text-align: center;">57.7</td>
<td style="text-align: center;">44.2</td>
<td style="text-align: center;">46.6</td>
<td style="text-align: center;">85.5</td>
<td style="text-align: center;">52.0</td>
<td style="text-align: center;">50.4</td>
<td style="text-align: center;">64.0</td>
<td style="text-align: center;">43.4</td>
<td style="text-align: center;">49.2</td>
<td style="text-align: center;">52.2</td>
</tr>
<tr>
<td style="text-align: center;">Qwen2.5-VL-3B</td>
<td style="text-align: center;">50.5</td>
<td style="text-align: center;">39.9</td>
<td style="text-align: center;">33.5</td>
<td style="text-align: center;">48.8</td>
<td style="text-align: center;">47.0</td>
<td style="text-align: center;">27.7</td>
<td style="text-align: center;">74.8</td>
<td style="text-align: center;">45.0</td>
<td style="text-align: center;">41.2</td>
<td style="text-align: center;">55.2</td>
<td style="text-align: center;">36.5</td>
<td style="text-align: center;">34.9</td>
<td style="text-align: center;">42.2</td>
</tr>
<tr>
<td style="text-align: center;">Qwen2.5-VL-7B</td>
<td style="text-align: center;">57.7</td>
<td style="text-align: center;">45.6</td>
<td style="text-align: center;">43.6</td>
<td style="text-align: center;">57.4</td>
<td style="text-align: center;">51.2</td>
<td style="text-align: center;">37.5</td>
<td style="text-align: center;">85.9</td>
<td style="text-align: center;">60.4</td>
<td style="text-align: center;">53.1</td>
<td style="text-align: center;">63.1</td>
<td style="text-align: center;">44.6</td>
<td style="text-align: center;">46.3</td>
<td style="text-align: center;">51.3</td>
</tr>
<tr>
<td style="text-align: center;">Qwen2.5-VL-72B</td>
<td style="text-align: center;">61.5</td>
<td style="text-align: center;">47.5</td>
<td style="text-align: center;">61.5</td>
<td style="text-align: center;">65.1</td>
<td style="text-align: center;">54.8</td>
<td style="text-align: center;">57.5</td>
<td style="text-align: center;">89.7</td>
<td style="text-align: center;">61.5</td>
<td style="text-align: center;">63.8</td>
<td style="text-align: center;">68.5</td>
<td style="text-align: center;">48.1</td>
<td style="text-align: center;">63.8</td>
<td style="text-align: center;">60.1</td>
</tr>
<tr>
<td style="text-align: center;">QVQ-72B-Preview ${ }^{\dagger}$</td>
<td style="text-align: center;">68.2</td>
<td style="text-align: center;">56.0</td>
<td style="text-align: center;">53.1</td>
<td style="text-align: center;">63.6</td>
<td style="text-align: center;">58.3</td>
<td style="text-align: center;">49.6</td>
<td style="text-align: center;">85.1</td>
<td style="text-align: center;">58.4</td>
<td style="text-align: center;">54.2</td>
<td style="text-align: center;">72.3</td>
<td style="text-align: center;">53.5</td>
<td style="text-align: center;">54.3</td>
<td style="text-align: center;">60.0</td>
</tr>
</tbody>
</table>
<p>Table 3: Mathematical Evaluation on Different Types of Geometric Principles in GeoSense. GPI refers to Geometric Principles Identification, GPA means Geometric Principles Application. MLLMs with $\dagger$ are particularly adept at reasoning tasks.
<img alt="img-5.jpeg" src="img-5.jpeg" />
(a) Closed-sourced MLLMs.
(b) Open-sourced MLLMs.</p>
<p>Figure 6: The performance of (a) Closed-sourced and (b) Opensourced MLLMs on problems with different number of geometric principles.
to MLLMs in processing visual information and reasoning about spatial relationships.</p>
<h3>4.3 Experimental Analysis</h3>
<p>We primarily analyze performance of MLLMs on GeoSense, and have the following observations:</p>
<p>GPI and GPA jointly affect MLLMs' reasoning abilities. MLLMs' ACC scores on GeoSense are concurrently determined by both GPI and GPA scores. In Table 3, InternVL-2.5-8B and InternVL-2.5-38B achieve similar GPA scores for retrieving geometric principles. However, InternVL-2.5-38B achieves ACC 7.7\% higher than InternVL-2.5-8B because of its 5\% higher GPI score. Additionally, more examples, such as Claude37_Sonnet and Qwen2.5-VL-72B,
further demonstrate that a decrease in GPA also impedes model performance under full-scale evaluation. Across different subjects in Table 4, most MLLMs show minimal variation in GPI scores between CPF and TMPF tasks. However, the ACC scores of MLLMs tend to decrease in TMPF due to lower GPA scores. Moreover, most existing MLLMs show relatively limited GPI and GPA scores on GeoSense, indicating that the identification accuracy and application correctness of geometric principles jointly limit the reasoning ability of MLLMs on GPS.</p>
<p>Why MLLMs perform worse on complex problems. Intuitively, more complex geometric problems require more geometric principles. In Figure 6, we exhibit how our proposed metrics vary with the complexity of geometric problems. We utilize the average scores of open-sourced and closed-sourced models to represent MLLMs' performance and the numbers of geometric principles to represent the complexity. We observe that both GPI and ACC scores decrease as the complexity increases, while GPA scores show a negligible impact. Such a trend is even more evident in closed-source MLLMs. These observations suggest that MLLMs' worse performances on complex problems are mainly caused by the failure to accurately identify essential geometric principles. This experiment</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Model</th>
<th style="text-align: center;">CSF</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">USF</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">TMPF</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">CPF</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">UPF</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">GPI</td>
<td style="text-align: center;">GPA</td>
<td style="text-align: center;">ACC</td>
<td style="text-align: center;">GPI</td>
<td style="text-align: center;">GPA</td>
<td style="text-align: center;">ACC</td>
<td style="text-align: center;">GPI</td>
<td style="text-align: center;">GPA</td>
<td style="text-align: center;">ACC</td>
<td style="text-align: center;">GPI</td>
<td style="text-align: center;">GPA</td>
<td style="text-align: center;">ACC</td>
<td style="text-align: center;">GPI</td>
<td style="text-align: center;">GPA</td>
<td style="text-align: center;">ACC</td>
</tr>
<tr>
<td style="text-align: center;">Closed-Sourced MLLMs</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Claude35_Sonnet</td>
<td style="text-align: center;">85.0</td>
<td style="text-align: center;">53.5</td>
<td style="text-align: center;">53.8</td>
<td style="text-align: center;">80.9</td>
<td style="text-align: center;">34.7</td>
<td style="text-align: center;">54.6</td>
<td style="text-align: center;">65.9</td>
<td style="text-align: center;">32.5</td>
<td style="text-align: center;">27.2</td>
<td style="text-align: center;">68.4</td>
<td style="text-align: center;">60.5</td>
<td style="text-align: center;">56.1</td>
<td style="text-align: center;">45.1</td>
<td style="text-align: center;">38.7</td>
<td style="text-align: center;">40.7</td>
</tr>
<tr>
<td style="text-align: center;">Claude37_Sonnet</td>
<td style="text-align: center;">91.1</td>
<td style="text-align: center;">62.5</td>
<td style="text-align: center;">76.8</td>
<td style="text-align: center;">80.8</td>
<td style="text-align: center;">36.5</td>
<td style="text-align: center;">73.5</td>
<td style="text-align: center;">82.7</td>
<td style="text-align: center;">39.4</td>
<td style="text-align: center;">47.3</td>
<td style="text-align: center;">70.5</td>
<td style="text-align: center;">63.5</td>
<td style="text-align: center;">68.5</td>
<td style="text-align: center;">54.1</td>
<td style="text-align: center;">44.8</td>
<td style="text-align: center;">52.0</td>
</tr>
<tr>
<td style="text-align: center;">Gemini-1.5-pro-flash</td>
<td style="text-align: center;">87.3</td>
<td style="text-align: center;">62.6</td>
<td style="text-align: center;">62.1</td>
<td style="text-align: center;">86.0</td>
<td style="text-align: center;">33.5</td>
<td style="text-align: center;">64.2</td>
<td style="text-align: center;">83.9</td>
<td style="text-align: center;">44.1</td>
<td style="text-align: center;">48.4</td>
<td style="text-align: center;">73.1</td>
<td style="text-align: center;">65.4</td>
<td style="text-align: center;">64.8</td>
<td style="text-align: center;">50.7</td>
<td style="text-align: center;">43.5</td>
<td style="text-align: center;">49.3</td>
</tr>
<tr>
<td style="text-align: center;">Gemini-2.0-pro-flash</td>
<td style="text-align: center;">88.1</td>
<td style="text-align: center;">58.8</td>
<td style="text-align: center;">89.9</td>
<td style="text-align: center;">72.4</td>
<td style="text-align: center;">35.1</td>
<td style="text-align: center;">89.9</td>
<td style="text-align: center;">84.6</td>
<td style="text-align: center;">47.2</td>
<td style="text-align: center;">62.1</td>
<td style="text-align: center;">77.7</td>
<td style="text-align: center;">69.5</td>
<td style="text-align: center;">77.0</td>
<td style="text-align: center;">60.3</td>
<td style="text-align: center;">51.2</td>
<td style="text-align: center;">70.9</td>
</tr>
<tr>
<td style="text-align: center;">GPT-4o</td>
<td style="text-align: center;">91.3</td>
<td style="text-align: center;">66.8</td>
<td style="text-align: center;">72.3</td>
<td style="text-align: center;">73.7</td>
<td style="text-align: center;">37.0</td>
<td style="text-align: center;">75.1</td>
<td style="text-align: center;">83.5</td>
<td style="text-align: center;">37.0</td>
<td style="text-align: center;">34.7</td>
<td style="text-align: center;">72.7</td>
<td style="text-align: center;">73.1</td>
<td style="text-align: center;">66.1</td>
<td style="text-align: center;">49.4</td>
<td style="text-align: center;">44.8</td>
<td style="text-align: center;">44.2</td>
</tr>
<tr>
<td style="text-align: center;">Open-Soured MLLMs</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">InterVL2.5-8B</td>
<td style="text-align: center;">74.3</td>
<td style="text-align: center;">28.7</td>
<td style="text-align: center;">14.2</td>
<td style="text-align: center;">55.0</td>
<td style="text-align: center;">28.5</td>
<td style="text-align: center;">21.2</td>
<td style="text-align: center;">73.6</td>
<td style="text-align: center;">31.9</td>
<td style="text-align: center;">17.0</td>
<td style="text-align: center;">55.9</td>
<td style="text-align: center;">36.3</td>
<td style="text-align: center;">29.1</td>
<td style="text-align: center;">35.0</td>
<td style="text-align: center;">35.3</td>
<td style="text-align: center;">21.5</td>
</tr>
<tr>
<td style="text-align: center;">InterVL2.5-38B</td>
<td style="text-align: center;">82.4</td>
<td style="text-align: center;">35.3</td>
<td style="text-align: center;">17.1</td>
<td style="text-align: center;">67.0</td>
<td style="text-align: center;">32.9</td>
<td style="text-align: center;">24.1</td>
<td style="text-align: center;">82.7</td>
<td style="text-align: center;">28.0</td>
<td style="text-align: center;">23.2</td>
<td style="text-align: center;">57.5</td>
<td style="text-align: center;">43.3</td>
<td style="text-align: center;">37.4</td>
<td style="text-align: center;">39.8</td>
<td style="text-align: center;">36.7</td>
<td style="text-align: center;">28.6</td>
</tr>
<tr>
<td style="text-align: center;">InterVL2.5-38B-MPO ${ }^{\dagger}$</td>
<td style="text-align: center;">84.0</td>
<td style="text-align: center;">34.8</td>
<td style="text-align: center;">16.4</td>
<td style="text-align: center;">62.1</td>
<td style="text-align: center;">33.5</td>
<td style="text-align: center;">23.3</td>
<td style="text-align: center;">87.9</td>
<td style="text-align: center;">35.7</td>
<td style="text-align: center;">26.1</td>
<td style="text-align: center;">56.3</td>
<td style="text-align: center;">42.8</td>
<td style="text-align: center;">35.6</td>
<td style="text-align: center;">41.9</td>
<td style="text-align: center;">39.7</td>
<td style="text-align: center;">30.1</td>
</tr>
<tr>
<td style="text-align: center;">InterVL2.5-78B</td>
<td style="text-align: center;">90.1</td>
<td style="text-align: center;">34.5</td>
<td style="text-align: center;">17.4</td>
<td style="text-align: center;">65.0</td>
<td style="text-align: center;">35.4</td>
<td style="text-align: center;">22.5</td>
<td style="text-align: center;">86.0</td>
<td style="text-align: center;">34.8</td>
<td style="text-align: center;">27.6</td>
<td style="text-align: center;">61.5</td>
<td style="text-align: center;">46.0</td>
<td style="text-align: center;">36.2</td>
<td style="text-align: center;">40.2</td>
<td style="text-align: center;">41.7</td>
<td style="text-align: center;">30.8</td>
</tr>
<tr>
<td style="text-align: center;">Deepseek-VL2-small</td>
<td style="text-align: center;">66.3</td>
<td style="text-align: center;">51.8</td>
<td style="text-align: center;">34.1</td>
<td style="text-align: center;">52.0</td>
<td style="text-align: center;">25.3</td>
<td style="text-align: center;">38.9</td>
<td style="text-align: center;">53.7</td>
<td style="text-align: center;">22.3</td>
<td style="text-align: center;">16.3</td>
<td style="text-align: center;">47.0</td>
<td style="text-align: center;">59.7</td>
<td style="text-align: center;">40.1</td>
<td style="text-align: center;">21.9</td>
<td style="text-align: center;">28.8</td>
<td style="text-align: center;">20.0</td>
</tr>
<tr>
<td style="text-align: center;">Deepseek-VL2</td>
<td style="text-align: center;">79.4</td>
<td style="text-align: center;">55.0</td>
<td style="text-align: center;">49.2</td>
<td style="text-align: center;">53.7</td>
<td style="text-align: center;">40.3</td>
<td style="text-align: center;">51.7</td>
<td style="text-align: center;">49.0</td>
<td style="text-align: center;">33.6</td>
<td style="text-align: center;">30.4</td>
<td style="text-align: center;">58.6</td>
<td style="text-align: center;">56.0</td>
<td style="text-align: center;">48.3</td>
<td style="text-align: center;">33.6</td>
<td style="text-align: center;">35.6</td>
<td style="text-align: center;">28.6</td>
</tr>
<tr>
<td style="text-align: center;">Llama-vision-11B</td>
<td style="text-align: center;">77.9</td>
<td style="text-align: center;">41.0</td>
<td style="text-align: center;">33.9</td>
<td style="text-align: center;">55.0</td>
<td style="text-align: center;">33.4</td>
<td style="text-align: center;">37.3</td>
<td style="text-align: center;">58.9</td>
<td style="text-align: center;">19.1</td>
<td style="text-align: center;">14.8</td>
<td style="text-align: center;">52.6</td>
<td style="text-align: center;">46.4</td>
<td style="text-align: center;">42.7</td>
<td style="text-align: center;">32.2</td>
<td style="text-align: center;">33.7</td>
<td style="text-align: center;">20.7</td>
</tr>
<tr>
<td style="text-align: center;">Llama-vision-90B</td>
<td style="text-align: center;">83.4</td>
<td style="text-align: center;">52.3</td>
<td style="text-align: center;">45.8</td>
<td style="text-align: center;">70.5</td>
<td style="text-align: center;">32.7</td>
<td style="text-align: center;">45.1</td>
<td style="text-align: center;">68.2</td>
<td style="text-align: center;">21.5</td>
<td style="text-align: center;">19.7</td>
<td style="text-align: center;">58.8</td>
<td style="text-align: center;">52.3</td>
<td style="text-align: center;">44.3</td>
<td style="text-align: center;">37.5</td>
<td style="text-align: center;">34.8</td>
<td style="text-align: center;">24.1</td>
</tr>
<tr>
<td style="text-align: center;">LLaVA-onevison-7B</td>
<td style="text-align: center;">79.3</td>
<td style="text-align: center;">42.6</td>
<td style="text-align: center;">32.8</td>
<td style="text-align: center;">57.3</td>
<td style="text-align: center;">26.2</td>
<td style="text-align: center;">35.3</td>
<td style="text-align: center;">52.3</td>
<td style="text-align: center;">22.4</td>
<td style="text-align: center;">16.0</td>
<td style="text-align: center;">51.6</td>
<td style="text-align: center;">43.8</td>
<td style="text-align: center;">32.2</td>
<td style="text-align: center;">28.6</td>
<td style="text-align: center;">33.6</td>
<td style="text-align: center;">21.7</td>
</tr>
<tr>
<td style="text-align: center;">LLaVA-onevison-72B</td>
<td style="text-align: center;">65.7</td>
<td style="text-align: center;">65.5</td>
<td style="text-align: center;">50.0</td>
<td style="text-align: center;">48.1</td>
<td style="text-align: center;">35.3</td>
<td style="text-align: center;">56.3</td>
<td style="text-align: center;">71.4</td>
<td style="text-align: center;">19.3</td>
<td style="text-align: center;">24.8</td>
<td style="text-align: center;">65.5</td>
<td style="text-align: center;">54.2</td>
<td style="text-align: center;">43.3</td>
<td style="text-align: center;">39.1</td>
<td style="text-align: center;">37.7</td>
<td style="text-align: center;">35.0</td>
</tr>
<tr>
<td style="text-align: center;">Qwen2-VL-72B</td>
<td style="text-align: center;">82.5</td>
<td style="text-align: center;">57.8</td>
<td style="text-align: center;">57.4</td>
<td style="text-align: center;">70.7</td>
<td style="text-align: center;">41.2</td>
<td style="text-align: center;">67.1</td>
<td style="text-align: center;">78.6</td>
<td style="text-align: center;">29.8</td>
<td style="text-align: center;">22.2</td>
<td style="text-align: center;">72.1</td>
<td style="text-align: center;">61.0</td>
<td style="text-align: center;">67.1</td>
<td style="text-align: center;">49.1</td>
<td style="text-align: center;">43.2</td>
<td style="text-align: center;">43.7</td>
</tr>
<tr>
<td style="text-align: center;">Qwen2.5-VL-3B</td>
<td style="text-align: center;">77.6</td>
<td style="text-align: center;">48.9</td>
<td style="text-align: center;">48.7</td>
<td style="text-align: center;">68.4</td>
<td style="text-align: center;">34.3</td>
<td style="text-align: center;">60.0</td>
<td style="text-align: center;">73.4</td>
<td style="text-align: center;">26.8</td>
<td style="text-align: center;">17.4</td>
<td style="text-align: center;">66.1</td>
<td style="text-align: center;">57.1</td>
<td style="text-align: center;">53.1</td>
<td style="text-align: center;">40.6</td>
<td style="text-align: center;">39.5</td>
<td style="text-align: center;">29.5</td>
</tr>
<tr>
<td style="text-align: center;">Qwen2.5-VL-7B</td>
<td style="text-align: center;">85.9</td>
<td style="text-align: center;">63.9</td>
<td style="text-align: center;">59.6</td>
<td style="text-align: center;">72.9</td>
<td style="text-align: center;">43.1</td>
<td style="text-align: center;">67.9</td>
<td style="text-align: center;">82.3</td>
<td style="text-align: center;">36.0</td>
<td style="text-align: center;">26.3</td>
<td style="text-align: center;">67.2</td>
<td style="text-align: center;">71.1</td>
<td style="text-align: center;">60.3</td>
<td style="text-align: center;">48.9</td>
<td style="text-align: center;">44.5</td>
<td style="text-align: center;">40.6</td>
</tr>
<tr>
<td style="text-align: center;">Qwen2.5-VL-72B</td>
<td style="text-align: center;">88.2</td>
<td style="text-align: center;">64.4</td>
<td style="text-align: center;">74.1</td>
<td style="text-align: center;">73.9</td>
<td style="text-align: center;">36.6</td>
<td style="text-align: center;">78.7</td>
<td style="text-align: center;">89.7</td>
<td style="text-align: center;">37.6</td>
<td style="text-align: center;">42.0</td>
<td style="text-align: center;">76.1</td>
<td style="text-align: center;">69.7</td>
<td style="text-align: center;">77.6</td>
<td style="text-align: center;">55.2</td>
<td style="text-align: center;">47.3</td>
<td style="text-align: center;">56.7</td>
</tr>
<tr>
<td style="text-align: center;">QVQ-72B-Preview ${ }^{\dagger}$</td>
<td style="text-align: center;">87.3</td>
<td style="text-align: center;">71.1</td>
<td style="text-align: center;">66.2</td>
<td style="text-align: center;">76.7</td>
<td style="text-align: center;">45.8</td>
<td style="text-align: center;">67.9</td>
<td style="text-align: center;">82.5</td>
<td style="text-align: center;">42.1</td>
<td style="text-align: center;">47.4</td>
<td style="text-align: center;">74.0</td>
<td style="text-align: center;">71.2</td>
<td style="text-align: center;">65.3</td>
<td style="text-align: center;">58.5</td>
<td style="text-align: center;">52.9</td>
<td style="text-align: center;">48.2</td>
</tr>
</tbody>
</table>
<p>Table 4: Mathematical Evaluation on Different Subjects in GeoSense. GPI = Geometric Principles Identification, GPA= Geometric Principles Application, Calculation of Solid Figures = CSF, Understanding of Solid Figures = USF, Transformation and Motion of Plane Figures = TMPF, Calculation of Plane Figures = CPF and Understanding of Plane Figures = UPF. MLLMs with $\dagger$ are typically trained for reasoning tasks.
highlights the importance of improving the MLLMs' ability to identify geometric principles more accurately to further enhance their reasoning capabilities.</p>
<p>MLLMs excel in computation but fail in understanding. From the results in Table 3, the performance of the three metrics for MLLMs under Formulas is significantly higher than under Definitions and Theorems, especially for GPI metric. This indicates that MLLMs can more clearly identify the required geometric principles when faced with computational problems. In contrast, definitions and theorems often contain abstract properties and relationships of geometric elements, which MLLMs struggle to understand.</p>
<p>GPI limits MLLMs' performance in plane geometry. Fig. 7 illustrates the differences in various metrics for several models on USF and UPF. In terms of the GPI metric, we find that most models perform better on the USF subject compared to UPF. However, for the GPA metric, the performance difference between the two subjects is not significant, with models, except for Deepseek-VL, even being stronger in the UPF domain. Nonetheless, regarding the ACC metric, most models still perform better on USF. These observations suggest that the key factor limiting the models' ability to solve plane geometry problems is GPI, i.e., the difficulty models face in accurately identifying the necessary geometric principles. This is due to the numerous and easily confusable principles in plane geometry, such as determining similar and congruent triangles. This
highlights the need for models to accurately identify necessary principles to enhance their understanding of plane geometry.</p>
<h3>4.4 Error Analysis</h3>
<p>To gain a deeper insight into the performance bottlenecks of state-of-the-art MLLMs on GPS tasks, we analyze the error distribution of the leading closed-source and open-source models: Gemini-2.0-Pro-Flash and Qwen2.5-VL-72B. For each problem, we identify the critical errors in their reasoning process and categorize these errors into four types: geometric principles identification errors, geometric principles application errors, calculation errors, and hallucinations.</p>
<p>As illustrated in Fig. 8, the primary source of errors for the SOTA models is GPA, which involves incorrectly applying geometric principles within visual geometric contexts. Errors in perception and the inability to align geometric principles with visual elements lead to GPA errors. Secondly, GPI represents the second major source of errors, with Gemini-2.0-Pro-Flash and Qwen2.5-VL-72B exhibiting $23.5 \%$ and $38.2 \%$ of errors due to GPI, respectively. This indicates that enhancing the models' ability to recognize geometric principles could further improve their reasoning capabilities. Additionally, a small number of errors are attributed to calculation errors and model hallucinations, and addressing these issues is crucial for optimizing overall model performance.</p>
<p><img alt="img-6.jpeg" src="img-6.jpeg" /></p>
<p>Figure 7: The (a) GPI, (b) GPA, (c) ACC performance of MLLMs on USF and UPF.
<img alt="img-7.jpeg" src="img-7.jpeg" /></p>
<p>Figure 8: Error Analysis of Leading Closed-Source and OpenSource MLLMs.</p>
<h2>5 RELATED WORK</h2>
<h3>5.1 Multi-modal Large Language Models</h3>
<p>The synergistic evolution of Large Language Models (LLMs) [2, 16, $28,37,38$ ] and vision foundation models[18, 32, 50, 52, 53] has formed the core driving force behind the development of MLLMs. Building upon breakthroughs in text-based models [2, 37] and vision frameworks [18, 32], researchers have progressively established fundamental cross-modal interaction capabilities. MLLMs have achieved performance breakthroughs through massive-scale data training, where closed-source models like OpenAI's GPT$4 \mathrm{~V}[29]$ and Google's Gemini[36] have set benchmarks in complex visual reasoning tasks. Concurrently, open-source community initiatives such as LLaVA[22-24] and MiniGPT-4[7, 55] employ frozen CLIP[32] models for image encoding while injecting visual prompts into LLaMA[37] for multimodal instruction tuning. As technology iterates, multimodal architectures continue to evolve: mPLUGOwl[44, 45] proposes cross-modal collaborative training mechanisms, Qwen-VL[1] enhances fine-grained understanding through spatial-aware modules, and InternLM-XComposer[12] along with SPHINX[20, 21] adopt mixture-of-experts architectures to boost multi-task performance. Recent advancements in large reasoning LLMs like OpenAI o1[30] and DeepSeekR1[11], which demonstrate remarkable progress in complex problem-solving, have spurred numerous explorations to enhance MLLMs' reasoning capabilities[8, 35]. Specialized algorithms have also been developed to strengthen MLLMs' mathematical and geometric reasoning capacities. In this paper, we introduce the GeoSense benchmark to comprehensively
evaluate MLLMs' ability to solve geometric problems by leveraging geometric principles.</p>
<h3>5.2 Geometry Benchmarks</h3>
<p>Mathematical reasoning has become a pivotal area within contemporary AI research, posing significant challenges for LLMs and MLLMs. Initially, datasets in this domain targeted elementary algebra[15] and arithmetic word problems[33], which were relatively limited in scope and number. Subsequent efforts expanded to more complex and diversified mathematical problem sets, exemplified by datasets like MATH[15], GSM8K[10], and MMLU[14]. These datasets notably enhanced the difficulty and breadth of mathematical questions, thereby establishing robust benchmarks for evaluating general-purpose and math-specific language models[13, 27, 39, 47, 54]. Moreover, the rapid advancement of MLLMs has spurred the need for high-quality multimodal benchmarks to assess the models' capabilities in solving mathematical problems within visually enriched contexts. For instance, datasets such as GeoQA[6], UniGeo[5], and Geometry3K[26] focus specifically on geometryrelated queries. In addition, initiatives like MathVista[25] have broadened the scope to incorporate a range of multimodal tasks involving mathematical reasoning, while MMMU[46] addresses college-level problems requiring intricate domain-specific knowledge. These multimodal benchmarks significantly advance the evaluation of models in complex mathematical reasoning and their application across modalities. Nonetheless, current benchmarks in the geometry problem-solving domain still exhibit notable shortcomings, particularly in systematically evaluating the cross-modal application of geometric principles. Thus, developing comprehensive and systematic benchmarks that fully assess cross-modal capabilities in geometric reasoning remains an imperative research direction.</p>
<h2>6 CONCLUSION</h2>
<p>In this paper, we introduce GeoSense, the first comprehensive bilingual benchmark to systematically evaluate the reasoning abilities of MLLMs with a focus on identifying and applying geometric principles. We first establish a comprehensive framework that includes 148 unique geometric principles. Additionally, we curate a dataset that comprises 1,789 geometric math problems, annotate 5,556 geometric principles and their application within geometric images. Moreover, we introduce two novel evaluation metrics GPI and GPA to assess MLLMs' ability to identify correct geometric principles and apply them to specific elements within geometric</p>
<p>diagrams, respectively. Extensive experiments reveal insights into the performance of different MLLMs, highlighting their limitations in applying geometric principles within visual contexts.</p>
<h2>REFERENCES</h2>
<p>[1] Jinze Bai, Shuai Bai, Shusheng Yang, Shijie Wang, Sinan Tan, Peng Wang, Junyang Lin, Chang Zhou, and Jingren Zhou. 2023. Qwen-VL: A Versatile VisionLanguage Model for Understanding, Localization, Text Reading, and Beyond. arXiv:2308.12966 [cs.CV] https://arxiv.org/abs/2308.12966
[2] Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, et al. 2020. Language Models are FewShot Learners. arXiv:2005.14165 [cs.CL] https://arxiv.org/abs/2005.14165
[3] Jie Cao and Jing Xiao. 2022. An Augmented Benchmark Dataset for Geometric Question Answering through Dual Parallel Text Encoding. In Proceedings of the 29th International Conference on Computational Linguistics, Nicoletta Calzolari, Chu-Ren Huang, Hansaem Kim, James Pustejovsky, Leo Wanner, Key-Sun Choi, Pum-Mo Ryu, Hsin-Hsi Chen, Lucia Donatelli, Heng Ji, Sadao Kurohashi, Patrizia Paggio, Nianwen Xue, Seokhwan Kim, Younggyun Hahm, Zhong He, Tony Kyungil Lee, Enrico Santus, Francis Bond, and Seung-Hoon Nu (Eds.). International Committee on Computational Linguistics, Gyeongju, Republic of Korea, 1511-1520. https://aclanthology.org/2022.coling-1.150/
[4] Felix Chen, Hungjie Yuan, Yumqu Xu, Tao Feng, Jun Cen, Pengwei Liu, Zeying Huang, and Yi Yang. 2025. MathFlow: Enhancing the Perceptual Flow of MLLMs for Visual Mathematical Problems. arXiv:2503.16549 [cs.CV] https://arxiv.org/ abs/2503.16549
[5] Jiaqi Chen, Tong Li, Jinghui Qin, Pan Lu, Liang Lin, Chongyu Chen, and Xiaodan Liang. 2022. UniGeo: Unifying Geometry Logical Reasoning via Reformulating Mathematical Expression. arXiv:2212.02746 [cs.AI] https://arxiv.org/abs/2212. 02746
[6] Jiaqi Chen, Jianheng Tang, Jinghui Qin, Xiaodan Liang, Lingbo Liu, Eric P. Xing, and Liang Lin. 2022. GeoQA: A Geometric Question Answering Benchmark Towards Multimodal Numerical Reasoning. arXiv:2105.14517 [cs.AI] https: //arxiv.org/abs/2105.14517
[7] Jun Chen, Deyao Zhu, Xiaoqian Shen, Xiang Li, Zechun Liu, Pengchuan Zhang, Raghuraman Krishnamoorthi, Vikas Chandra, Yunyang Xiong, and Mohamed Elhoseiny. 2023. MiniGPT-v2: large language model as a unified interface for vision-language multi-task learning. arXiv:2310.09478 [cs.CV] https://arxiv.org/ abs/2310.09478
[8] Liang Chen, Lei Li, Haozhe Zhao, Yifan Song, and Vinci. 2025. R1-V: Reinforcing Super Generalization Ability in Vision-Language Models with Less Than \$3. https://github.com/Deep-Agent/R1-V. Accessed: 2025-02-02.
[9] Zhe Chen, Jiannan Wu, Wenhui Wang, Weijie Su, Guo Chen, Sen Xing, Muyan Zhong, Qinglong Zhang, Xizhou Zhu, Lewei Lu, Bin Li, Ping Luo, Tong Lu, Yu Qiao, and Jifeng Dai. 2024. InternVL: Scaling up Vision Foundation Models and Aligning for Generic Visual-Linguistic Tasks. arXiv:2312.14238 [cs.CV] https://arxiv.org/abs/2312.14238
[10] Karl Cobbe, Vineet Kouaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reilchiro Nakano, Christopher Hesse, and John Schulman. 2021. Training Verifiers to Solve Math Word Problems. arXiv:2110.14168 [cs.LG] https://arxiv.org/abs/2110.14168
[11] DeepSeek-AL 2025. DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning. arXiv:2501.12948 [cs.CL] https://arxiv.org/abs/2501. 12948
[12] Xiaoyi Dong, Pan Zhang, Yuhang Zang, Yuhang Cao, Bin Wang, Linke Ouyang, Xilin Wei, Songyang Zhang, Haodong Duan, Maosong Cao, Wenwei Zhang, Yining Li, Hang Yan, Yang Gao, Xinyue Zhang, Wei Li, Jingwen Li, Kai Chen, Conghui He, Xingcheng Zhang, Yu Qiao, Dahua Lin, and Jiaqi Wang. 2024. InternLM-XComposer2: Mastering Free-form Text-Image Composition and Comprehension in Vision-Language Large Model. arXiv:2401.16420 [cs.CV] https: //arxiv.org/abs/2401.16420
[13] Jiabui Gao, Renjie Pi, Jipeng Zhang, Jiacheng Ye, Wanjun Zhong, Yufei Wang, Lanqing Hong, Jianhua Han, Hang Xu, Zhenguo Li, and Lingpeng Kong. 2023. G-LLaVA: Solving Geometric Problem with Multi-Modal Large Language Model. arXiv:2312.11370 [cs.CL] https://arxiv.org/abs/2312.11370
[14] Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt. 2021. Measuring Massive Multitask Language Understanding. arXiv:2009.03300 [cs.CY] https://arxiv.org/abs/2009.03300
[15] Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song, and Jacob Steinhardt. 2021. Measuring Mathematical Problem Solving With the NATH Dataset. arXiv:2103.05874 [cs.LG] https: //arxiv.org/abs/2103.05874
[16] Albert Q. Jiang, Alexandre Sablayrolles, Antoine Roux, Arthur Mensch, Blanche Savary, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Emma Bou Hanna, et al. 2024. Mixtral of Experts. arXiv:2401.04088 [cs.LG] https://arxiv. org/abs/2401.04088
[17] Mehran Kazemi, Hamideeza Alvari, Ankit Anand, Jialin Wu, Xi Chen, and Radu Soricut. 2023. GeonVerse: A Systematic Evaluation of Large Models for Geometric Reasoning. arXiv:2312.12241 [cs.CV] https://arxiv.org/abs/2312.12241
[18] Alexander Kirillov, Eric Mintun, Nikhila Ravi, Hanzi Mao, Chloe Rolland, Laura Gustafson, Tete Xiao, Spencer Whitehead, Alexander C. Berg, Wan-Ten Lo, Piotr DollÃ¡r, and Ross Girshick. 2023. Segment Anything. arXiv:2304.02643 [cs.CV] https://arxiv.org/abs/2304.02643
[19] Bo Li, Yuanhan Zhang, Dong Guo, Renrui Zhang, Feng Li, Hao Zhang, Kaichen Zhang, Peiyuan Zhang, Yanwei Li, Ziwei Liu, and Chunyuan Li. 2024. LLaVAOneVision: Easy Visual Task Transfer. arXiv:2408.03326 [cs.CV] https://arxiv. org/abs/2408.03326
[20] Ziyi Lin, Chris Liu, Renrui Zhang, Peng Gao, Longtian Qiu, Han Xiao, Han Qiu, Chen Lin, Wenqi Shao, Keqin Chen, Jiaming Han, Siyuan Huang, Yichi Zhang, Xuming He, Hongsheng Li, and Yu Qiao. 2023. SPHINX: The Joint Mixing of Weights, Tasks, and Visual Embeddings for Multi-modal Large Language Models. arXiv:2311.07573 [cs.CV] https://arxiv.org/abs/2311.07573
[21] Dongyang Liu, Renrui Zhang, Longtian Qiu, Siyuan Huang, Weifeng Lin, Shitian Zhao, Shijie Geng, Ziyi Lin, Peng Jin, Kaipeng Zhang, Wenqi Shao, Chao Xu, Conghui He, Junjun He, Hao Shao, Pan Lu, Hongsheng Li, Yu Qiao, and Peng Gao. 2024. SPHINX-X: Scaling Data and Parameters for a Family of Multi-modal Large Language Models. arXiv:2402.05935 [cs.CV] https://arxiv.org/abs/2402.05935
[22] Haotian Liu, Chunyuan Li, Yuheng Li, and Yong Jae Lee. 2024. Improved Baselines with Visual Instruction Tuning. arXiv:2310.03744 [cs.CV] https://arxiv.org/abs/ 2310.03744
[23] Haotian Liu, Chunyuan Li, Yuheng Li, Bo Li, Yuanhan Zhang, Sheng Shen, and Yong Jae Lee. 2024. LLaVA-NoXT: Improved reasoning, OCR, and world knowledge. https://llava-vl.github.io/blog/2024-01-30-llava-noxt/
[24] Haotian Liu, Chunyuan Li, Qingyang Wu, and Yong Jae Lee. 2023. Visual Instruction Tuning.
[25] Pan Lu, Hritik Bansal, Tony Xia, Jiacheng Liu, Chunyuan Li, Hannaneb Hajishirzi, Hao Cheng, Kai-Wei Chang, Michel Galley, and Jianfeng Gao. 2024. MathVista: Evaluating Mathematical Reasoning of Foundation Models in Visual Contexts. arXiv:2310.02255 [cs.CV] https://arxiv.org/abs/2310.02255
[26] Pan Lu, Ran Gong, Shibiao Jiang, Liang Qiu, Siyuan Huang, Xiaodan Liang, and Song-Chun Zhu. 2021. Inter-GP5: Interpretable Geometry Problem Solving with Formal Language and Symbolic Reasoning. arXiv:2105.04165 [cs.CL] https://arxiv.org/abs/2105.04165
[27] Haipeng Luo, Qingfeng Sun, Can Xu, Pu Zhao, Jianguang Lou, Chongyang Tao, Xiubo Geng, Qingwei Lin, Shifeng Chen, Yansong Tang, and Dongmei Zhang. 2025. WizardMath: Empowering Mathematical Reasoning for Large Language Models via Reinforced Evol-Instruct. arXiv:2308.09583 [cs.CL] https: //arxiv.org/abs/2308.09583
[28] OpenAL 2023. Chatgpt. https://chat.openai.com
[29] OpenAL 2023. GPT-4V(ision) system card. https://openai.com/research/gpt-4v-system-card
[30] OpenAL 2024. Learning to reason with LLMs. https://openai.com/index/learning-to-reason-with-llms/
[31] Runqi Qiao, Quina Tan, Guanting Dong, Minhui Wu, Chong Sun, Xiaoshuai Song, Zhuoma GongQue, Shanglin Lei, Zhe Wei, Miaoxuan Zhang, Runfeng Qiao, Yifan Zhang, Xiao Zong, Yida Xu, Muxi Diao, Zhimin Bao, Chen Li, and Honggang Zhang. 2024. Wei-Math: Does Your Large Multimodal Model Achieve Human-like Mathematical Reasoning? arXiv:2407.01284 [cs.AI] https://arxiv.org/abs/2407. 01284
[32] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, and Ilya Sutskever. 2021. Learning Transferable Visual Models From Natural Language Supervision. arXiv:2103.00020 [cs.CV] https://arxiv.org/ abs/2103.00020
[33] Subhro Roy and Dan Roth. 2016. Solving General Arithmetic Word Problems. arXiv:1608.01413 [cs.CL] https://arxiv.org/abs/1608.01413
[34] Minjoon Seo, Hannaneb Hajishirzi, Ali Farhadi, Oren Etzioni, and Clint Malcolm. 2015. Solving Geometry Problems: Combining Text and Diagram Interpretation. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, LluÃ­s MÃ¡rquez, Chris Callison-Burch, and Jian Su (Eds.). Association for Computational Linguistics, Lisbon, Portugal, 1466-1476. https://doi.org/10. 18653/v1/D15-1171
[35] Haodian Shen, Zihai Zhang, Qianqian Zhang, Ruochen Xu, and Tiancheng Zhao. 2025. VLM-R1: A stable and generalizable R1-style Large Vision-Language Model. https://github.com/om-ai-lab/VLM-R1. Accessed: 2025-02-15.
[36] Gemini Team. 2024. Gemini: A Family of Highly Capable Multimodal Models. arXiv:2312.11805 [cs.CL] https://arxiv.org/abs/2312.11805
[37] Hugo Touveon, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, TimothÃ©e Lacroix, Baptiste RoziÃ¨re, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, and Guillaume Lample. 2023. LLaMA: Open and Efficient Foundation Language Models. arXiv:2302.13971 [cs.CL] https://arxiv.org/abs/2302.13971</p>
<p>[38] Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babari, Nikolay Bushlykov, et al. 2023. Llama 2: Open Foundation and FineTuned Chat Models. arXiv:2307.09288 [cs.CL] https://arxiv.org/abs/2307.09288
[39] Ke Wang, Houxing Ren, Aojun Zhou, Zimu Lu, Sichun Luo, Weikang Shi, Renrui Zhang, Linqi Song, Mingjie Zhan, and Hongsheng Li. 2023. MathCoder: Seamless Code Integration in LLMs for Enhanced Mathematical Reasoning. arXiv:2310.03731 [cs.CL] https://arxiv.org/abs/2310.03731
[40] Peng Wang, Shuai Bai, Susan Tan, Shijie Wang, Zhihao Fan, Jinze Bai, Keqin Chen, Xuejing Liu, Jialin Wang, Wenbin Ge, Yang Fan, Kai Dang, Mengfei Du, Xuancheng Ren, Rui Men, Dayiheng Liu, Chang Zhou, Jingren Zhou, and Junyang Lin. 2024. Qwen2-VL: Enhancing Vision-Language Model's Perception of the World at Any Resolution. arXiv:2409.12191 [cs.CV] https://arxiv.org/abs/2409. 12191
[41] Weiyun Wang, Zhe Chen, Wenhai Wang, Yue Cao, Yangzhou Liu, Zhangwei Gao, Jinguo Zhu, Xizhou Zhu, Lewei Lu, Yu Qiao, and Jifeng Dai. 2024. Enhancing the Reasoning Ability of Multimodal Large Language Models via Mixed Preference Optimization. arXiv:2411.10442 [cs.CL] https://arxiv.org/abs/2411.10442
[42] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian lchter, Fei Xia, Ed Chi, Quoc Le, and Denny Zhou. 2023. Chain-of-Thought Prompting Elicits Reasoning in Large Language Models. arXiv:2201.11903 [cs.CL] https: //arxiv.org/abs/2201.11903
[43] Zhiyu Wu, Xiaokang Chen, Zizheng Pan, Xingchao Liu, Wen Liu, Damai Dai, Huazuo Gao, Yiyang Ma, Chengyue Wu, Bingxuan Wang, Zhenda Xie, Yu Wu, Kai Hu, Jiawei Wang, Yaofeng Sun, Yukun Li, Yishi Piao, Kang Guan, Aixin Liu, Xin Xie, Yuxiang You, Kai Dong, Xingkai Yu, Haowei Zhang, Liang Zhao, Yisong Wang, and Chong Ruan. 2024. DeepSeek-VL2: Mixture-of-Experts Vision-Language Models for Advanced Multimodal Understanding. arXiv:2412.10302 [cs.CV] https://arxiv.org/abs/2412.10302
[44] Qinghao Ye, Haiyang Xu, Guohai Xu, Jiabo Ye, Ming Yan, Yiyang Zhou, Junyang Wang, Anwen Hu, Pengcheng Shi, Yaya Shi, Chenliang Li, Yuanhong Xu, Hehong Chen, Junfeng Tian, Qi Qian, Ji Zhang, Fei Huang, and Jingren Zhou. 2024. mPLUG-Owl: Modularization Empowers Large Language Models with Multimodality. arXiv:2304.14178 [cs.CL] https://arxiv.org/abs/2304.14178
[45] Qinghao Ye, Haiyang Xu, Jiabo Ye, Ming Yan, Anwen Hu, Haowei Liu, Qi Qian, Ji Zhang, Fei Huang, and Jingren Zhou. 2023. mPLUG-Owl2: Revolutionizing Multi-modal Large Language Model with Modality Collaboration. arXiv:2311.04257 [cs.CL] https://arxiv.org/abs/2311.04257
[46] Xiang Yue, Yuansheng Ni, Kai Zhang, Tianyu Zheng, Baoqi Liu, Ge Zhang, Samuel Stevens, Dongfu Jiang, Weiming Ren, Yuxuan Sun, Cong Wei, Betsao Yu, Ruibin Yuan, Renliang Sun, Ming Yin, Boyuan Zheng, Zhenzhu Yang, Yibo Liu, Wenhao Huang, Huan Sun, Yu Su, and Wenhu Chen. 2024. MMMU: A Massive Multidiscipline Multimodal Understanding and Reasoning Benchmark for Expert AGI. arXiv:2311.16502 [cs.CL] https://arxiv.org/abs/2311.16502
[47] Xiang Yue, Xingwei Qu, Ge Zhang, Yao Fu, Wenhao Huang, Huan Sun, Yu Su, and Wenhu Chen. 2023. MAmmoTH: Building Math Generalist Models through Hybrid Instruction Tuning. arXiv:2309.05653 [cs.CL] https://arxiv.org/abs/2309. 05653
[48] Jiaxin Zhang, Zhongzhi Li, Mingliang Zhang, Fei Yin, Chenglin Liu, and Yashar Moshfeghi. 2024. GeoEval: Benchmark for Evaluating LLMs and Multi-Modal Models on Geometry Problem-Solving. arXiv:2402.10104 [cs.AI] https://arxiv. org/abs/2402.10104
[49] Ming-Liang Zhang, Fei Yin, and Cheng-Lin Liu. 2023. A Multi-Modal Neural Geometric Solver with Textual Clauses Parsed from Diagram. arXiv:2302.11097 [cs.AI] https://arxiv.org/abs/2302.11097
[50] Renrui Zhang, Xiangfei Hu, Bohao Li, Siyuan Huang, Hanqiu Deng, Hongsheng Li, Yu Qiao, and Peng Gao. 2023. Prompt, Generate, then Cache: Cascade of Foundation Models makes Strong Few-shot Learners. arXiv:2303.02151 [cs.CV] https://arxiv.org/abs/2303.02151
[51] Renrui Zhang, Dongzhi Jiang, Yichi Zhang, Haokun Lin, Ziyu Guo, Pengshuo Qiu, Aojun Zhou, Pan Lu, Kai-Wei Chang, Peng Gao, and Hongsheng Li. 2024. MathVerse: Does Your Multi-modal LLM Truly See the Diagrams in Visual Math Problems? arXiv:2403.14624 [cs.CV] https://arxiv.org/abs/2403.14624
[52] Renrui Zhang, Zhengkai Jiang, Ziyu Guo, Shilin Yan, Junting Pan, Xianzheng Ma, Hao Dong, Peng Gao, and Hongsheng Li. 2023. Personalize Segment Anything Model with One Shot. arXiv:2305.03048 [cs.CV] https://arxiv.org/abs/2305.03048
[53] Renrui Zhang, Lishui Wang, Yu Qiao, Peng Gao, and Hongsheng Li. 2022. Learning 3D Representations from 2D Pre-trained Models via Image-to-Point Masked Autoencoders. arXiv:2212.06785 [cs.CV] https://arxiv.org/abs/2212.06785
[54] Aojun Zhou, Ke Wang, Zimu Lu, Weikang Shi, Sichun Luo, Zipeng Qin, Shaoqing Lu, Anya Jia, Linqi Song, Mingjie Zhan, and Hongsheng Li. 2023. Solving Challenging Math Word Problems Using GPT-4 Code Interpreter with Code-based Self-Verification. arXiv:2308.07921 [cs.CL] https://arxiv.org/abs/2308.07921
[55] Deyao Zhu, Jun Chen, Xiaosjian Shen, Xiang Li, and Mohamed Elhoseiny. 2023. MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large Language Models. arXiv:2304.10592 [cs.CV] https://arxiv.org/abs/2304.10592</p>
<h2>A OVERVIEW</h2>
<ul>
<li>Ethical Concerns (Â§B)</li>
<li>Limitation and future work (Â§C)</li>
<li>More Dataset Details (Â§D)</li>
<li>Geometric Principles Structure (Â§D.1)</li>
<li>Examples with Geometric Principles Annotated in GeoSense (Â§D.2)</li>
<li>Additional experimental details (Â§E)</li>
<li>Evaluation Results of More MMLMs on GeoSense-English (Â§E.1)</li>
<li>Response of Differenet MLLMs (Â§E.2)</li>
<li>Prompts for Evaluation Strategy (Â§E.3)</li>
</ul>
<h2>B ETHICAL CONCERNS</h2>
<p>We guarantee that GeoSense fully complies with legal and ethical standards throughout its data collection and annotation processes, ensuring no violations occur. All annotation experts involved receive fair compensation. The data for GeoSense is derived from publicly accessible test questions and professional websites. Given the standardized nature of answers in mathematical problems, cultural differences do not affect them. Moreover, we confirm that GeoSense is intended exclusively for academic research, with a firm prohibition on any commercial use. In addition, we declare that we will take full responsibility for any infringement of rights and acknowledge the data license accordingly.</p>
<h2>C LIMITATION AND FUTURE WORK</h2>
<p>Although GeoSense represents a significant step forward in evaluating MLLMs on GPS tasks, there are several limitations that can be addressed for improvement.</p>
<p>We have established a knowledge framework that includes 148 geometric principles covering most content from plane and solid geometry at the middle and high school levels. This framework allows us to measure MLLMs' ability to identify and apply basic geometric principles from multiple dimensions. However, future MLLMs are expected to master more complex knowledge across broader domains. Thus, extending GeoSense to include more challenging problems (such as those at the university level) is necessary for a more comprehensive and robust evaluation of MLLMs' multimodal reasoning abilities.</p>
<p>Additionally, we introduced two novel metrics, GPI and GPA, to assess models' mastery of geometric principles. However, the errors MLLMs make in GPA generally fall into two categories: insufficient perceptual ability with regard to chart elements, and incorrect mapping of geometric principles to geometric elements. Distinguishing between these two types of errors allows for a more granular understanding of MLLMs' reasoning capabilities from different perspectives.</p>
<h2>D MORE DATASET DETAILS</h2>
<h2>D. 1 Geometric Principles Structure</h2>
<p>Table 5 illustrates the detailed framework of geometric principles within GeoSense, comprising 148 principles. Utilizing this framework and our annotations during problem-solving, we aim to evaluate the ability of MLLMs to accurately identify and apply geometric</p>
<p>principles when tackling problems. Inspired by the human paradigm of problem-solving based on geometric principles, we construct our dataset using these principles as fundamental units, ensuring scientific rigor and valuable insights in the evaluation results.</p>
<h2>D. 2 Examples with Geometric Principles Annotated in GeoSense</h2>
<p>Please refer to Figure 9 and Figure 10. We have annotated each geometry problem with the geometric principles needed for solving them, detailing the correspondence between these principles and elements within the diagram, along with their specific applications in the solution process. Notably, we support both Chinese and English versions.</p>
<h2>E ADDITIONAL EXPERIMENTAL DETAILS</h2>
<h2>E. 1 Evaluation Results of More MMLMs on GeoSense-English</h2>
<p>Tables 7 and 8 respectively show the performance of more MLLMs on GeoSenese-English under different geometric principle attributes and subjects. Additionally, we present the GPI, GPA, and ACC metrics of each MLLM across different subjects in Figures 11, 12, and 13 .</p>
<h2>E. 2 Response of Differenet MLLMs</h2>
<p>Figure 14 shows the responses of different open-source and closedsource models to the same problem, along with their GPI, GPA, and ACC scores.</p>
<h2>E. 3 Prompts for Evaluation Strategy</h2>
<p>Table 6 presents the prompts used in our evaluation process. These prompts guide the assessment of the model's ability to apply geometric principles accurately and comprehensively. The evaluation phases include verifying final answers, assessing geometric principle identification, extracting relevant content, and evaluating geometric principle alignment. This structured approach ensures precise and consistent evaluation of the model's proficiency in GPS.</p>
<h2>Evaluation Phases</h2>
<p>Prompt for Evaluating Final Answers. It involves verifying the correctness of the model's prediction against the provided correct answer.
Prompt for Evaluating GPI. It requires evaluators to rigorously assess whether the model has correctly utilized specific geometric principles within its predictive response. Prompt for Extracting Relevant Content. In this phase, evaluators focus on extracting all facets related to the geometric principles from the model's response. Ensuring that even dispersed but relevant content is captured, this prompt aids in discerning the comprehensiveness of the model's engagement with the principle.
Prompt for Evaluating GPA. It delves into a deeper comparison between the model-generated description and the standard answer concerning specific geometric principles. The use of <note> </note> tags signifies key elements, helping evaluators measure the alignment in terms of presence and correctness. This prompt extends assessment to symbolic representations, which are critical in geometric evaluations.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Level 1</th>
<th style="text-align: center;">Level 2</th>
<th style="text-align: center;">Level 3</th>
<th style="text-align: center;">Level 4-5</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Solid Geometry</td>
<td style="text-align: center;">Calculaiton of Solid Figures</td>
<td style="text-align: center;">Calculaiton of <br> Surface Area of Solid <br> Figures</td>
<td style="text-align: center;">- Surface Area Formula for a Cube <br> - Formula for the Surface Area of a Cone <br> - Lateral Surface Area Formula of a Prism <br> - Formula for Lateral Area of a Cylinder <br> - Lateral Surface Area of a Cone <br> - Surface Area Formula of a Prism <br> - Surface Area Formula for Rectangular Prism <br> - Surface Area Formula for a Cylinder <br> - Sphere Surface Area Formula <br> - Surface Area Formula for a Triangular Prism</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Calculaiton of <br> Volume of Solid <br> Figures</td>
<td style="text-align: center;">- Volume Formula of Rectangular Prism <br> - Volume Formula of a Cube <br> - Volume Formula of Prism <br> - Volume Formula of Pyramid <br> - Volume Formula of Cylinder <br> - Volume Formula of a Cone <br> - Formula for the Volume of a Sphere</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Understanding of <br> Solid Figures</td>
<td style="text-align: center;">Cylinder and Cone</td>
<td style="text-align: center;">- Definition of Cone <br> - Generatrix <br> - Cylinder <br> - Development of a Cone</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Rectangular Prism and Cube</td>
<td style="text-align: center;">- Definition of Rectangular Prism <br> - Definition of Cube</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Prism</td>
<td style="text-align: center;">- Definition of Prism <br> - Definition of Triangular Prism</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Sphere</td>
<td style="text-align: center;">- Definition of Sphere <br> - Radius of a Sphere</td>
</tr>
<tr>
<td style="text-align: center;">Plane Geometry</td>
<td style="text-align: center;">Transformation and Motion of Plane Figures</td>
<td style="text-align: center;">Symmetry</td>
<td style="text-align: center;">- Symmetric Point <br> - Law of Reflection <br> - Definition of Rotation <br> - Properties of Rotation <br> - Definition of Scale Factor in Rectangular Coordinate Systems <br> - Rotation Invariance Theorem <br> - Definition of Rotational Symmetry <br> - Rotation Transformation <br> - 2D Plane Rotation Formula <br> - Reflection Transformation <br> - Definition of Translation <br> - Translation Invariance Theorem <br> - Scaling Theorem in a Rectangular Coordinate System</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align: center;">Level 1</th>
<th style="text-align: center;">Level 2</th>
<th style="text-align: center;">Level 3</th>
<th style="text-align: center;">Level 4-5</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Calculation of Plane Figures</td>
<td style="text-align: center;">Interior and Exterior <br> Angles of Polygon</td>
<td style="text-align: center;">- Triangle Angle Sum Theorem <br> - Exterior Angle Sum Theorem of Polygon <br> - Formulas for the Central Angle and Interior Angle of a Regular Polygon <br> - Sum of Interior Angles of a Quadrilateral Theorem <br> - Polygon Interior Angle Sum Theorem</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Calculation of Areas</td>
<td style="text-align: center;">- Formula for the Area of a Rectangle <br> - Triangle Area Formula (Using Sine Function) <br> - Area Formula of a Circle <br> - Area Formula of a Triangle <br> - Theorem on the Area Ratio of Similar Triangles <br> - Area Formula of a Parallelogram <br> - Trapezoid Area Formula <br> - Rhombus Area Formula <br> - Heron's Formula <br> - Area Formula for Square</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Calculation of <br> Perimeters</td>
<td style="text-align: center;">- Formula for the Perimeter of a Rectangle <br> - Circumference Formula of Circle <br> - Formula for the Length of an Arc of a Sector <br> - Formula for the Area of a Sector <br> - Perimeter of a Parallelogram <br> - Arc Length Formula of a Circle</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Understanding of Plane Figures</td>
<td style="text-align: center;">Polygons</td>
<td style="text-align: center;">- Definition of Regular Polygon</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Properties and Understanding of Parallelogram</td>
<td style="text-align: center;">- Definition of Parallelogram <br> - Properties of Parallelogram Theorem <br> - Adjacent Angles Supplementary Theorem of Parallelogram</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Properties and Understanding of Rhombus</td>
<td style="text-align: center;">- Definition of Rhombus <br> - Properties of the Diagonals of a Rhombus</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align: center;">Level 1</th>
<th style="text-align: center;">Level 2</th>
<th style="text-align: center;">Level 3</th>
<th style="text-align: center;">Level 4-5</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Properties and Understanding of Triangle</td>
<td style="text-align: center;">- General Properties of Triangle <br> - Definition of Triangle <br> - Definition of Equilateral Triangle <br> - Definition of Median of a Triangle <br> - Triangle Midline Theorem <br> - Pythagorean Theorem <br> - Exterior Angle Theorem of Triangle <br> - Definition of Right Triangle <br> - Trigonometric Functions <br> - Sine Theorem <br> - Definition of Sine Function <br> - Definition of Tangent Function <br> - Cosine Function <br> - Properties of $30^{\circ}-60^{\circ}-90^{\circ}$ Triangle <br> - Complementary Acute Angles in a Right Triangle <br> - Properties and Understanding of Isosceles Triangle <br> - Definition of Isosceles Triangle <br> - Properties of Isosceles Triangle <br> - Coincidence Theorem of Altitude, Median, and Angle Bisector in Isosceles Triangle <br> - Definition of Isosceles Right Triangle <br> - Properties and Understanding of Similar Triangles <br> - Definition of Similar Triangles <br> - Similarity Theorem for Triangles (AA) <br> - SAS Criterion for Similar Triangles <br> - Similarity Theorem for Triangles (SSS) <br> - Properties and Understanding of Congruent Triangles <br> - Definition of Congruent Triangles <br> - Triangle Congruence Theorem (SSS) <br> - Triangular Congruence Theorem (SAS) <br> - Congruence Theorem for Triangles (AAS) <br> - Angle-Side-Angle (ASA) Criterion for Congruence of Triangle <br> - Right Triangle Congruence (Hypotenuse, One Leg)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Properties and Understanding of Trapezoid</td>
<td style="text-align: center;">- Definition of Trapezoid <br> - Median Line Theorem of Trapezoid <br> - Definition of Isosceles Trapezoid <br> - Properties of an Isosceles Trapezoid</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Properties and Understanding of Rectangle</td>
<td style="text-align: center;">- Definition of Rectangle <br> - Property of Diagonals in a Rectangle <br> - Definition of Square</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Representation and Understanding of Angles</td>
<td style="text-align: center;">Representation and Understanding of Angles</td>
<td style="text-align: center;">- Definition of Vertical Angles <br> - Definition of Straight Angle <br> - Definition of Linear Pair of Angles <br> - Definition of Exterior Angle of a Polygon <br> - Definition of Angle Bisector <br> - Naming of Angles <br> - Measurement of Angle</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align: center;">Level 1</th>
<th style="text-align: center;">Level 2</th>
<th style="text-align: center;">Level 3</th>
<th style="text-align: center;">Level 4-5</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Properties and Understanding of Line Segments</td>
<td style="text-align: center;">Midpoint of a Line Segment</td>
<td style="text-align: center;">- Definition of Line Segment <br> - Definition of Ray <br> - Distance Formula Between Two Points</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Positional Relationships between Lines</td>
<td style="text-align: center;">Perpendicularity</td>
<td style="text-align: center;">- Definition of Perpendicular Lines <br> - Definition of Altitude <br> - Definition of Perpendicular Bisector <br> - Properties of the Perpendicular Bisector <br> - Definition of Foot of a Perpendicular</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Parallel</td>
<td style="text-align: center;">- Definition of Parallel Lines <br> - Parallel Postulate 2 of Parallel Lines <br> - Definition of Corresponding Angles <br> - Definition of Alternate Interior Angles <br> - Proportional Segments Theorem <br> - Definition of Consecutive Interior Angles <br> - Transitivity of Parallel Lines</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Circles and Sectors</td>
<td style="text-align: center;">Properties and Understanding of Circles and Sectors</td>
<td style="text-align: center;">- Definition of Circle <br> - Definition of Radius <br> - Definition of Diameter <br> - Corollary to the Inscribed Angle Theorem 2: The Angle Subtended by the Diameter <br> - Definition of Semicircle <br> - Definition of Central Angle <br> - Definition of Inscribed Angle <br> - Inscribed Angle Theorem <br> - Definition of Tangent to a Circle <br> - Tangent-Segment Theorem <br> - Cyclic Quadrilateral <br> - Corollary 3 of the Inscribed Angle Theorem: Diagonal Supplementary Theorem for Cyclic Quadrilateral <br> - Property of the Tangent Line to a Circle <br> - Perpendicular Diameter Theorem <br> - Corollary 1 of the Inscribed Angle Theorem <br> - Definition of Chord <br> - Definition of Arc <br> - Central Angle Theorem <br> - Properties of Central Angles <br> - Secant Line Theorem <br> - Formula for Conversion between Degrees and Radians</td>
</tr>
</tbody>
</table>
<p>Table 5: Hierarchical Structure of Geometric Principles</p>
<p><img alt="img-8.jpeg" src="img-8.jpeg" /></p>
<h2>Question:</h2>
<p>In $\triangle A B C, \angle B=20^{\circ}$, if $C D$ is tangent to $\bigcirc \mathrm{O}$, find $m \angle D C B$.</p>
<h2>Answer: $70^{\circ}$</h2>
<p><img alt="img-9.jpeg" src="img-9.jpeg" /></p>
<h2>Question:</h2>
<p>Find the length of AF in terms of $A B, B D$ and $D F$.
Answer: $A B^{2}+B D^{2}+D F^{2}$
<img alt="img-10.jpeg" src="img-10.jpeg" /></p>
<h2>Question:</h2>
<p>$\overline{A B}$ is tangent to circle $O$. If $m A B=24$ and $m O B=$ 25, find $m D B$.</p>
<p>Answer: 18</p>
<p>Principle 1: Property of the Tangent Line to a Circle
$&lt;$ note $&gt;$ in circle O , point D is the point of tangency where line CD touches the circle, and segment OD is the radius of the circle $&lt;$ /note $&gt;$. According to the property of the tangent line to a circle, $&lt;$ note $&gt;$ the tangent line $C D$ is perpendicular to the radius OD at the point of tangency D, i.e., $\angle \mathrm{OBC}=90^{\circ}&lt;$ /note $&gt;$.</p>
<h2>Principle 1: Pythagorean Theorem</h2>
<p>$&lt;$ note $&gt;$ In the right triangle ADF, angle ADF is a right angle ( 90 degrees) $&lt;$ /note $&gt;,&lt;$ note $&gt;$ sides $A D$ and $D F$ are the legs, and side AF is the hypotenuse $&lt;$ /note $&gt;$, so according to the Pythagorean Theorem, $&lt;$ note $&gt;\mathrm{AF}^{2}=\mathrm{AD}^{2}+\mathrm{DF}^{2}&lt;$ /note $&gt;$. Represent $A D$ and DF respectively using $A B, B D$, and $D F$, that is $A F^{2}=A B^{2}+B D^{2}$ $+\mathrm{DF}^{2}$.</p>
<h2>Principle 1: Definition of Radius</h2>
<p>Points A and D are on circle O , so $&lt;$ note $&gt;\mathrm{OA}&lt;$ /note $&gt;$ and $&lt;$ note $&gt;$ $\mathrm{OD}&lt;$ /note $&gt;$ are radii of the circle. $&lt;$ note $&gt;\mathrm{OA}=\mathrm{OD}&lt;$ /note $&gt;$.</p>
<h2>Principle 3: Pythagorean Theorem</h2>
<p>Triangle OAB is a right triangle with $\angle O A B$ being the right angle. According to the Pythagorean theorem, <note $>\mathrm{OB}^{2}&gt;\mathrm{OA}^{2}+\mathrm{AB}^{2}&lt;$ /note $&gt;$.</p>
<p>Principle 2: Triangle Angle Sum Theorem
$&lt;$ note $&gt;$ Angle DCB,Angle DBC, and Angle $\mathrm{BDC}&lt;$ /note $&gt;$ are the three interior angles of triangle BCD. According to the Triangle Angle Sum Theorem, <note $>$ Angle DCB + Angle $\mathrm{BBC}+$ Angle $\mathrm{BDC}=180^{\circ}&lt;$ /note $&gt;$</p>
<h2>Principle 2: Definition of Prism</h2>
<p>According to the definition of a triangular prism, the $&lt;$ note $&gt;$ edge $A B$ is perpendicular to the base BDF, so angle $A B D$ is $90^{\circ}&lt;$ /note $&gt;$.</p>
<p>Principle 2: Tangent Line Properties Theorem $A B$ is a tangent to circle $O&lt;$ note $&gt;$ at point $A$ $&lt;$ /note&gt;. Since OA is the radius , <note $>$ OA $\perp$ $A B$, with $\angle O A B=90^{\circ}&lt;$ /note $&gt;$.</p>
<p>Principle 4: Calculation of Segments
Point D is on the segment OB, and <note> $\mathrm{DB}=\mathrm{OB}-\mathrm{OD}&lt;$ /note $&gt;$.</p>
<p>Figure 9: Example of GeoSense-English.</p>
<p><img alt="img-11.jpeg" src="img-11.jpeg" /></p>
<h2>Question:</h2>
<p>In $\triangle A B C, \angle B=20^{\circ}$, if $C D$ is tangent to $\bigcirc \mathrm{O}$, find $m \angle D C B$.</p>
<h2>Answer: $70^{\circ}$</h2>
<p><img alt="img-12.jpeg" src="img-12.jpeg" /></p>
<h2>Question:</h2>
<p>Find the length of AF in terms of $A B, B D$ and $D F$.
Answer: $A B^{2}+B D^{2}+D F^{2}$
<img alt="img-13.jpeg" src="img-13.jpeg" /></p>
<h2>Question:</h2>
<p>$\overline{A B}$ is tangent to circle $O$. If $m A B=24$ and $m O B=$ 25, find $m D B$.</p>
<p>Answer: 18</p>
<h2>Principle 1: åœ†çš„åˆ‡çº¿æ€§è´¨</h2>
<p><note>åœ¨åœ† O ä¸­, ç‚¹ D æ˜¯åˆ‡ç‚¹, çº¿æ®µ CD åœ¨æ­¤å¤„ä¸Žåœ†ç›¸åˆ‡, è€Œçº¿æ®µ OD æ˜¯åœ†çš„åŠå¾„</note>ã€‚æ ¹æ®åœ†çš„åˆ‡çº¿æ€§è´¨, <note>åˆ‡çº¿ CD åœ¨åˆ‡ç‚¹ D å¤„ä¸ŽåŠå¾„ OD åž‚ç›´, å³ $\angle \mathrm{ODC}$ $=90^{\circ}&lt;$ /note $&gt;$.</p>
<h2>Principle 1: å‹¾è‚¡å®šç†</h2>
<p><note>åœ¨ç›´è§’ä¸‰è§’å½¢ ADF ä¸­, è§’ ADF æ˜¯ç›´è§’ï¼ˆ90åº¦ï¼‰ </note>, <note>è¾¹ AD å’Œ DF æ˜¯ä¸¤æ¡ç›´è§’è¾¹, è¾¹ AF æ˜¯æ–œè¾¹</note>, å› æ­¤æ ¹æ®å‹¾è‚¡å®šç†, <note>AF ${ }^{2}=A D^{2}+$ $\mathrm{DF}^{2}&lt;$ /note $&gt;$, åˆ†åˆ«ç”¨ $A B ã€ B D$ å’Œ $D F$ è¡¨ç¤º $A D$ å’Œ $D F$ ï¼Œå³ $A F^{2}=A B^{2}+B D^{2}+D F^{2}$ ã€‚</p>
<h2>Principle 1: åŠå¾„çš„å®šä¹‰</h2>
<p>ç‚¹ A å’Œ D åœ¨åœ† O ä¸Š, å› æ­¤<note>OA</note>å’Œ <note>OD</note>æ˜¯åœ†çš„åŠå¾„, <note>OA = OD</note>ã€‚</p>
<h2>Principle 3:å‹¾è‚¡å®šç†</h2>
<p>ä¸‰è§’å½¢ OAB æ˜¯ä¸€ä¸ªç›´è§’ä¸‰è§’å½¢, å…¶ä¸­ $\angle \mathrm{OAB}$ä¸ºç›´è§’ã€‚æ ¹æ®å‹¾è‚¡å®šç†, <note>OB ${ }^{2}=\mathrm{OA}^{2}$ $+A B^{2}&lt;$ /note $&gt;$</p>
<h2>Principle 2: ä¸‰è§’å½¢å†…è§’å’Œå®šç†</h2>
<p><note>è§’ DCBã€è§’ DBC å’Œè§’ BDC</note>æ˜¯ä¸‰è§’å½¢ BCD çš„ä¸‰ä¸ªå†…è§’ã€‚æ ¹æ®ä¸‰è§’å½¢å†…è§’å’Œå®šç†, <note>è§’ DCB + è§’ DBC + è§’ BDC = $180^{\circ}&lt;$ /note&gt;ã€‚</p>
<h2>Principle 2: æ£±æŸ±çš„å®šä¹‰</h2>
<p>æ ¹æ®ä¸‰è§’æŸ±çš„å®šä¹‰, <note>æ£± AB åž‚ç›´äºŽåº•é¢ BDF, å› æ­¤è§’ ABD ä¸º $90^{\circ}&lt;$ /note $&gt;$.</p>
<h2>Principle 2: åˆ‡çº¿çš„æ€§è´¨å®šç†</h2>
<p>AB æ˜¯åœ† O çš„åˆ‡çº¿<note>åœ¨ç‚¹ A å¤„</note>ã€‚ç”±äºŽ OA æ˜¯åŠå¾„, <note>OA $\perp A B$, ä¸” $\angle O A B=90^{\circ}&lt;$ /note $&gt;$.</p>
<h2>Principle 4: çº¿æ®µçš„è®¡ç®—</h2>
<p>ç‚¹ D ä½äºŽçº¿æ®µ OB ä¸Š, ä¸”<note>DB = OB -$\mathrm{OD}&lt;$ /note&gt;ã€‚</p>
<p>Figure 10: Example of GeoSense-Chinese.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Phase</th>
<th style="text-align: center;">Prompt</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Evaluate Final Answers</td>
<td style="text-align: center;">You are a geometry assessment expert. Given the model's prediction and the correct answer, determine whether the model's predicted answer is correct. <br> Model Response: {predict} Answer: {answer} <br> Please provide a clear response with 'yes' or 'no'.</td>
</tr>
<tr>
<td style="text-align: center;">Evaluate GPI</td>
<td style="text-align: center;">Please rigorously assess whether the model's predicted response utilizes the specified geometric principle: <br> Principle Name: {name} Principle Content: {content} Model Response: {predict} <br> Please respond clearly with 'yes' or 'no'.</td>
</tr>
<tr>
<td style="text-align: center;">Extract relevant content</td>
<td style="text-align: center;">Based on the following geometric principle, extract all related content from the model's response (extract any related content even if it is not contiguous): <br> Principle Name: {name} Principle Content: {content} Model Response: {predict} <br> Please directly output all content from the model's response that is related to this principle.</td>
</tr>
<tr>
<td style="text-align: center;">Evaluate GPA</td>
<td style="text-align: center;">You are a geometry assessment expert. Your task is to evaluate the model-generated description against the standard answer for a specific geometric principle. Specifically, in the standard answer, the content wrapped in <note> </note> represents key elements. You need to assess whether the model's response includes these key elements and, if so, whether they correspond correctly-paying particular attention to symbolic representation (e.g., angles ABC and CBA refer to the same angle, which should not be marked incorrect due to order). <br> Finally, please output [ans]num_exist, num_acc, ground_total[/ans], where num_exist is the number of instances of these key elements (as indicated by the tags) present in the model response (regardless of correctness), num_acc is the count of instances that are present and correctly correspond, and ground_total is the total number of key elements wrapped in <note> </note> tags in the standard answer. <br> Standard Description: {ground_truth} <br> Relevant Steps in Model Response: {response}</td>
</tr>
</tbody>
</table>
<p>Table 6: Prompts for Evaluation Strategy.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Model</th>
<th style="text-align: center;">Definitions</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Theorems</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Formula</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">ALL</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">GPI</td>
<td style="text-align: center;">GPA</td>
<td style="text-align: center;">ACC</td>
<td style="text-align: center;">GPI</td>
<td style="text-align: center;">GPA</td>
<td style="text-align: center;">ACC</td>
<td style="text-align: center;">GPI</td>
<td style="text-align: center;">GPA</td>
<td style="text-align: center;">ACC</td>
<td style="text-align: center;">GPI</td>
<td style="text-align: center;">GPA</td>
<td style="text-align: center;">ACC</td>
<td style="text-align: center;">AVG</td>
</tr>
<tr>
<td style="text-align: center;">Closed-Sourced MLLMs</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Claude35_Sonnet</td>
<td style="text-align: center;">56.5</td>
<td style="text-align: center;">41.2</td>
<td style="text-align: center;">41.9</td>
<td style="text-align: center;">54.9</td>
<td style="text-align: center;">46.8</td>
<td style="text-align: center;">33.8</td>
<td style="text-align: center;">82.8</td>
<td style="text-align: center;">52,5</td>
<td style="text-align: center;">52.9</td>
<td style="text-align: center;">63.2</td>
<td style="text-align: center;">40.8</td>
<td style="text-align: center;">46.1</td>
<td style="text-align: center;">50.0</td>
</tr>
<tr>
<td style="text-align: center;">Claude35_Sonnet2</td>
<td style="text-align: center;">58.8</td>
<td style="text-align: center;">44.0</td>
<td style="text-align: center;">49.6</td>
<td style="text-align: center;">59.0</td>
<td style="text-align: center;">46.0</td>
<td style="text-align: center;">42.5</td>
<td style="text-align: center;">84.7</td>
<td style="text-align: center;">52.7</td>
<td style="text-align: center;">59.2</td>
<td style="text-align: center;">66.3</td>
<td style="text-align: center;">43.1</td>
<td style="text-align: center;">53.7</td>
<td style="text-align: center;">54.4</td>
</tr>
<tr>
<td style="text-align: center;">Claude37_Sonnet</td>
<td style="text-align: center;">62.0</td>
<td style="text-align: center;">46.7</td>
<td style="text-align: center;">54.3</td>
<td style="text-align: center;">60.2</td>
<td style="text-align: center;">50.0</td>
<td style="text-align: center;">46.5</td>
<td style="text-align: center;">92.4</td>
<td style="text-align: center;">56.1</td>
<td style="text-align: center;">67.9</td>
<td style="text-align: center;">68.7</td>
<td style="text-align: center;">45.2</td>
<td style="text-align: center;">57.6</td>
<td style="text-align: center;">57.2</td>
</tr>
<tr>
<td style="text-align: center;">Gemini-1.5-pro-flash</td>
<td style="text-align: center;">60.2</td>
<td style="text-align: center;">43.8</td>
<td style="text-align: center;">53.0</td>
<td style="text-align: center;">58.7</td>
<td style="text-align: center;">51.5</td>
<td style="text-align: center;">45.6</td>
<td style="text-align: center;">85.9</td>
<td style="text-align: center;">55.3</td>
<td style="text-align: center;">56.1</td>
<td style="text-align: center;">67.9</td>
<td style="text-align: center;">44.9</td>
<td style="text-align: center;">55.7</td>
<td style="text-align: center;">56.2</td>
</tr>
<tr>
<td style="text-align: center;">Gemini-2.0-pro-flash</td>
<td style="text-align: center;">64.2</td>
<td style="text-align: center;">47.0</td>
<td style="text-align: center;">73.3</td>
<td style="text-align: center;">72.7</td>
<td style="text-align: center;">59.0</td>
<td style="text-align: center;">72.4</td>
<td style="text-align: center;">87.4</td>
<td style="text-align: center;">60.0</td>
<td style="text-align: center;">77.9</td>
<td style="text-align: center;">72.1</td>
<td style="text-align: center;">49.7</td>
<td style="text-align: center;">74.1</td>
<td style="text-align: center;">65.3</td>
</tr>
<tr>
<td style="text-align: center;">GPT-40</td>
<td style="text-align: center;">56.3</td>
<td style="text-align: center;">46.3</td>
<td style="text-align: center;">48.0</td>
<td style="text-align: center;">54.1</td>
<td style="text-align: center;">49.3</td>
<td style="text-align: center;">37.4</td>
<td style="text-align: center;">90.8</td>
<td style="text-align: center;">58.3</td>
<td style="text-align: center;">61.1</td>
<td style="text-align: center;">64.4</td>
<td style="text-align: center;">45.3</td>
<td style="text-align: center;">51.7</td>
<td style="text-align: center;">53.8</td>
</tr>
<tr>
<td style="text-align: center;">GPT-40-mimi</td>
<td style="text-align: center;">54.1</td>
<td style="text-align: center;">44.1</td>
<td style="text-align: center;">40.9</td>
<td style="text-align: center;">48.6</td>
<td style="text-align: center;">49.9</td>
<td style="text-align: center;">34.0</td>
<td style="text-align: center;">86.6</td>
<td style="text-align: center;">50.1</td>
<td style="text-align: center;">49.6</td>
<td style="text-align: center;">61.3</td>
<td style="text-align: center;">41.7</td>
<td style="text-align: center;">43.7</td>
<td style="text-align: center;">48.9</td>
</tr>
<tr>
<td style="text-align: center;">Open-Soured MLLMs</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">InterVL2.5-1B</td>
<td style="text-align: center;">31.3</td>
<td style="text-align: center;">37.1</td>
<td style="text-align: center;">11.1</td>
<td style="text-align: center;">28.0</td>
<td style="text-align: center;">36.4</td>
<td style="text-align: center;">9.6</td>
<td style="text-align: center;">58.8</td>
<td style="text-align: center;">24.3</td>
<td style="text-align: center;">6.9</td>
<td style="text-align: center;">34.5</td>
<td style="text-align: center;">21.5</td>
<td style="text-align: center;">11.1</td>
<td style="text-align: center;">22.4</td>
</tr>
<tr>
<td style="text-align: center;">InterVL2.5-2B</td>
<td style="text-align: center;">39.2</td>
<td style="text-align: center;">42.7</td>
<td style="text-align: center;">15.5</td>
<td style="text-align: center;">32.4</td>
<td style="text-align: center;">42.5</td>
<td style="text-align: center;">14.3</td>
<td style="text-align: center;">67.9</td>
<td style="text-align: center;">30.1</td>
<td style="text-align: center;">11.4</td>
<td style="text-align: center;">42.2</td>
<td style="text-align: center;">27.5</td>
<td style="text-align: center;">15.9</td>
<td style="text-align: center;">28.5</td>
</tr>
<tr>
<td style="text-align: center;">InterVL2.5-8B</td>
<td style="text-align: center;">43.7</td>
<td style="text-align: center;">40.7</td>
<td style="text-align: center;">21.2</td>
<td style="text-align: center;">38.2</td>
<td style="text-align: center;">39.3</td>
<td style="text-align: center;">20.0</td>
<td style="text-align: center;">67.6</td>
<td style="text-align: center;">24.7</td>
<td style="text-align: center;">13.7</td>
<td style="text-align: center;">46.7</td>
<td style="text-align: center;">27.3</td>
<td style="text-align: center;">21.1</td>
<td style="text-align: center;">31.7</td>
</tr>
<tr>
<td style="text-align: center;">InterVL2.5-26B</td>
<td style="text-align: center;">44.1</td>
<td style="text-align: center;">40.1</td>
<td style="text-align: center;">23.8</td>
<td style="text-align: center;">39.2</td>
<td style="text-align: center;">39.9</td>
<td style="text-align: center;">25.1</td>
<td style="text-align: center;">74.8</td>
<td style="text-align: center;">25.1</td>
<td style="text-align: center;">11.1</td>
<td style="text-align: center;">47.2</td>
<td style="text-align: center;">28.1</td>
<td style="text-align: center;">22.6</td>
<td style="text-align: center;">32.6</td>
</tr>
<tr>
<td style="text-align: center;">InterVL2.5-38B</td>
<td style="text-align: center;">48.7</td>
<td style="text-align: center;">40.6</td>
<td style="text-align: center;">28.9</td>
<td style="text-align: center;">44.5</td>
<td style="text-align: center;">43.9</td>
<td style="text-align: center;">29.8</td>
<td style="text-align: center;">74.8</td>
<td style="text-align: center;">26.4</td>
<td style="text-align: center;">16.0</td>
<td style="text-align: center;">52.7</td>
<td style="text-align: center;">31.1</td>
<td style="text-align: center;">27.3</td>
<td style="text-align: center;">37.0</td>
</tr>
<tr>
<td style="text-align: center;">InterVL2.5-38B-MPO $\dagger$</td>
<td style="text-align: center;">50.7</td>
<td style="text-align: center;">44.6</td>
<td style="text-align: center;">29.7</td>
<td style="text-align: center;">48.2</td>
<td style="text-align: center;">46.4</td>
<td style="text-align: center;">30.0</td>
<td style="text-align: center;">75.6</td>
<td style="text-align: center;">29.3</td>
<td style="text-align: center;">16.0</td>
<td style="text-align: center;">53.9</td>
<td style="text-align: center;">33.6</td>
<td style="text-align: center;">27.7</td>
<td style="text-align: center;">38.4</td>
</tr>
<tr>
<td style="text-align: center;">InterVL2.5-78B</td>
<td style="text-align: center;">49.0</td>
<td style="text-align: center;">45.2</td>
<td style="text-align: center;">29.8</td>
<td style="text-align: center;">48.6</td>
<td style="text-align: center;">46.8</td>
<td style="text-align: center;">32.0</td>
<td style="text-align: center;">80.2</td>
<td style="text-align: center;">30.5</td>
<td style="text-align: center;">18.3</td>
<td style="text-align: center;">53.7</td>
<td style="text-align: center;">32.9</td>
<td style="text-align: center;">28.7</td>
<td style="text-align: center;">38.4</td>
</tr>
<tr>
<td style="text-align: center;">Deepseek-VL2-tiny</td>
<td style="text-align: center;">20.1</td>
<td style="text-align: center;">27.4</td>
<td style="text-align: center;">15.8</td>
<td style="text-align: center;">20.1</td>
<td style="text-align: center;">27.4</td>
<td style="text-align: center;">15.8</td>
<td style="text-align: center;">53.4</td>
<td style="text-align: center;">35.9</td>
<td style="text-align: center;">18.7</td>
<td style="text-align: center;">17.6</td>
<td style="text-align: center;">26.5</td>
<td style="text-align: center;">15.2</td>
<td style="text-align: center;">19.8</td>
</tr>
<tr>
<td style="text-align: center;">Deepseek-VL2-small</td>
<td style="text-align: center;">25.6</td>
<td style="text-align: center;">35.7</td>
<td style="text-align: center;">23.3</td>
<td style="text-align: center;">26.7</td>
<td style="text-align: center;">36.1</td>
<td style="text-align: center;">19.5</td>
<td style="text-align: center;">67.9</td>
<td style="text-align: center;">48.1</td>
<td style="text-align: center;">30.2</td>
<td style="text-align: center;">34.2</td>
<td style="text-align: center;">23.8</td>
<td style="text-align: center;">26.3</td>
<td style="text-align: center;">28.1</td>
</tr>
<tr>
<td style="text-align: center;">Deepseek-VL2</td>
<td style="text-align: center;">40.1</td>
<td style="text-align: center;">37.8</td>
<td style="text-align: center;">33.1</td>
<td style="text-align: center;">40.6</td>
<td style="text-align: center;">39.6</td>
<td style="text-align: center;">26.0</td>
<td style="text-align: center;">76.3</td>
<td style="text-align: center;">52.8</td>
<td style="text-align: center;">42.4</td>
<td style="text-align: center;">48.4</td>
<td style="text-align: center;">33.4</td>
<td style="text-align: center;">35.7</td>
<td style="text-align: center;">39.2</td>
</tr>
<tr>
<td style="text-align: center;">Llama-vision-11B</td>
<td style="text-align: center;">43.2</td>
<td style="text-align: center;">36.1</td>
<td style="text-align: center;">22.6</td>
<td style="text-align: center;">37.9</td>
<td style="text-align: center;">35.6</td>
<td style="text-align: center;">18.7</td>
<td style="text-align: center;">74.8</td>
<td style="text-align: center;">37.5</td>
<td style="text-align: center;">29.8</td>
<td style="text-align: center;">47.9</td>
<td style="text-align: center;">29.2</td>
<td style="text-align: center;">24.8</td>
<td style="text-align: center;">34.0</td>
</tr>
<tr>
<td style="text-align: center;">Llama-vision-90B</td>
<td style="text-align: center;">49.1</td>
<td style="text-align: center;">39.2</td>
<td style="text-align: center;">27.3</td>
<td style="text-align: center;">42.0</td>
<td style="text-align: center;">36.0</td>
<td style="text-align: center;">21.2</td>
<td style="text-align: center;">78.2</td>
<td style="text-align: center;">43.6</td>
<td style="text-align: center;">37.0</td>
<td style="text-align: center;">52.9</td>
<td style="text-align: center;">31.4</td>
<td style="text-align: center;">29.8</td>
<td style="text-align: center;">38.0</td>
</tr>
<tr>
<td style="text-align: center;">LLaVA-onevison-0.6B</td>
<td style="text-align: center;">11.8</td>
<td style="text-align: center;">32.6</td>
<td style="text-align: center;">37.8</td>
<td style="text-align: center;">10.5</td>
<td style="text-align: center;">26.6</td>
<td style="text-align: center;">5.0</td>
<td style="text-align: center;">43.1</td>
<td style="text-align: center;">30.9</td>
<td style="text-align: center;">7.6</td>
<td style="text-align: center;">17.1</td>
<td style="text-align: center;">10.1</td>
<td style="text-align: center;">6.3</td>
<td style="text-align: center;">11.2</td>
</tr>
<tr>
<td style="text-align: center;">LLaVA-onevison-7B</td>
<td style="text-align: center;">36.3</td>
<td style="text-align: center;">38.0</td>
<td style="text-align: center;">22.7</td>
<td style="text-align: center;">39.2</td>
<td style="text-align: center;">39.2</td>
<td style="text-align: center;">22.7</td>
<td style="text-align: center;">72.9</td>
<td style="text-align: center;">40.6</td>
<td style="text-align: center;">42.6</td>
<td style="text-align: center;">41.4</td>
<td style="text-align: center;">26.0</td>
<td style="text-align: center;">22.8</td>
<td style="text-align: center;">30.1</td>
</tr>
<tr>
<td style="text-align: center;">LLaVA-onevison-72B</td>
<td style="text-align: center;">47.9</td>
<td style="text-align: center;">39.0</td>
<td style="text-align: center;">33.7</td>
<td style="text-align: center;">49.6</td>
<td style="text-align: center;">44.8</td>
<td style="text-align: center;">36.4</td>
<td style="text-align: center;">68.3</td>
<td style="text-align: center;">55.9</td>
<td style="text-align: center;">43.1</td>
<td style="text-align: center;">52.5</td>
<td style="text-align: center;">33.2</td>
<td style="text-align: center;">37.2</td>
<td style="text-align: center;">41.0</td>
</tr>
<tr>
<td style="text-align: center;">Qwen2-VL-2B</td>
<td style="text-align: center;">28.1</td>
<td style="text-align: center;">36.3</td>
<td style="text-align: center;">10.9</td>
<td style="text-align: center;">25.1</td>
<td style="text-align: center;">39.0</td>
<td style="text-align: center;">8.4</td>
<td style="text-align: center;">60.3</td>
<td style="text-align: center;">44.6</td>
<td style="text-align: center;">16.0</td>
<td style="text-align: center;">32.5</td>
<td style="text-align: center;">22.6</td>
<td style="text-align: center;">12.5</td>
<td style="text-align: center;">22.5</td>
</tr>
<tr>
<td style="text-align: center;">Qwen2-VL-7B</td>
<td style="text-align: center;">48.2</td>
<td style="text-align: center;">41.7</td>
<td style="text-align: center;">31.9</td>
<td style="text-align: center;">48.0</td>
<td style="text-align: center;">43.2</td>
<td style="text-align: center;">27.5</td>
<td style="text-align: center;">81.3</td>
<td style="text-align: center;">55.2</td>
<td style="text-align: center;">38.2</td>
<td style="text-align: center;">54.6</td>
<td style="text-align: center;">36.8</td>
<td style="text-align: center;">33.6</td>
<td style="text-align: center;">41.7</td>
</tr>
<tr>
<td style="text-align: center;">Qwen2-VL-72B</td>
<td style="text-align: center;">57.2</td>
<td style="text-align: center;">44.2</td>
<td style="text-align: center;">46.6</td>
<td style="text-align: center;">57.7</td>
<td style="text-align: center;">44.2</td>
<td style="text-align: center;">46.6</td>
<td style="text-align: center;">85.5</td>
<td style="text-align: center;">52.0</td>
<td style="text-align: center;">50.4</td>
<td style="text-align: center;">64.0</td>
<td style="text-align: center;">43.4</td>
<td style="text-align: center;">49.2</td>
<td style="text-align: center;">52.2</td>
</tr>
<tr>
<td style="text-align: center;">Qwen2.5-VL-3B</td>
<td style="text-align: center;">50.5</td>
<td style="text-align: center;">39.9</td>
<td style="text-align: center;">33.5</td>
<td style="text-align: center;">48.8</td>
<td style="text-align: center;">47.0</td>
<td style="text-align: center;">27.7</td>
<td style="text-align: center;">74.8</td>
<td style="text-align: center;">45.0</td>
<td style="text-align: center;">41.2</td>
<td style="text-align: center;">55.2</td>
<td style="text-align: center;">36.5</td>
<td style="text-align: center;">34.9</td>
<td style="text-align: center;">42.2</td>
</tr>
<tr>
<td style="text-align: center;">Qwen2.5-VL-7B</td>
<td style="text-align: center;">57.7</td>
<td style="text-align: center;">45.6</td>
<td style="text-align: center;">43.6</td>
<td style="text-align: center;">57.4</td>
<td style="text-align: center;">51.2</td>
<td style="text-align: center;">37.5</td>
<td style="text-align: center;">85.9</td>
<td style="text-align: center;">60.4</td>
<td style="text-align: center;">53.1</td>
<td style="text-align: center;">63.1</td>
<td style="text-align: center;">44.6</td>
<td style="text-align: center;">46.3</td>
<td style="text-align: center;">51.3</td>
</tr>
<tr>
<td style="text-align: center;">Qwen2.5-VL-72B</td>
<td style="text-align: center;">61.5</td>
<td style="text-align: center;">47.5</td>
<td style="text-align: center;">61.5</td>
<td style="text-align: center;">65.1</td>
<td style="text-align: center;">54.8</td>
<td style="text-align: center;">57.5</td>
<td style="text-align: center;">89.7</td>
<td style="text-align: center;">61.5</td>
<td style="text-align: center;">63.8</td>
<td style="text-align: center;">68.5</td>
<td style="text-align: center;">48.1</td>
<td style="text-align: center;">63.8</td>
<td style="text-align: center;">60.1</td>
</tr>
<tr>
<td style="text-align: center;">QVQ-72B-Preview $\dagger$</td>
<td style="text-align: center;">68.2</td>
<td style="text-align: center;">56.0</td>
<td style="text-align: center;">53.1</td>
<td style="text-align: center;">63.6</td>
<td style="text-align: center;">58.3</td>
<td style="text-align: center;">49.6</td>
<td style="text-align: center;">85.1</td>
<td style="text-align: center;">58.4</td>
<td style="text-align: center;">54.2</td>
<td style="text-align: center;">72.3</td>
<td style="text-align: center;">53.5</td>
<td style="text-align: center;">54.3</td>
<td style="text-align: center;">60.0</td>
</tr>
</tbody>
</table>
<p>Table 7: Evaluation Results on Different Types of Geometric Principles of More MMLMs on GeoSense-English. GPI = Geometric Principles Identification, GPA= Geometric Principles Application. MLLMs with $\dagger$ are typically trained for reasoning tasks.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Model</th>
<th style="text-align: center;">CSF</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">USF</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">TMPF</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">CPF</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">UPF</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">K.I.</td>
<td style="text-align: center;">K.A.</td>
<td style="text-align: center;">ACC.</td>
<td style="text-align: center;">K.I.</td>
<td style="text-align: center;">K.A.</td>
<td style="text-align: center;">ACC.</td>
<td style="text-align: center;">K.I.</td>
<td style="text-align: center;">K.A.</td>
<td style="text-align: center;">ACC.</td>
<td style="text-align: center;">K.I.</td>
<td style="text-align: center;">K.A.</td>
<td style="text-align: center;">ACC</td>
<td style="text-align: center;">K.I.</td>
<td style="text-align: center;">K.A.</td>
<td style="text-align: center;">ACC</td>
</tr>
<tr>
<td style="text-align: center;">Closed-Sourced MLLMs</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Claude35_Sonnet</td>
<td style="text-align: center;">85.0</td>
<td style="text-align: center;">53.5</td>
<td style="text-align: center;">53.8</td>
<td style="text-align: center;">80.9</td>
<td style="text-align: center;">34.7</td>
<td style="text-align: center;">54.6</td>
<td style="text-align: center;">65.9</td>
<td style="text-align: center;">32.5</td>
<td style="text-align: center;">27.2</td>
<td style="text-align: center;">68.4</td>
<td style="text-align: center;">60.5</td>
<td style="text-align: center;">56.1</td>
<td style="text-align: center;">45.1</td>
<td style="text-align: center;">38.7</td>
<td style="text-align: center;">40.7</td>
</tr>
<tr>
<td style="text-align: center;">Claude35_Sonnet2</td>
<td style="text-align: center;">89.1</td>
<td style="text-align: center;">60.7</td>
<td style="text-align: center;">65.2</td>
<td style="text-align: center;">76.0</td>
<td style="text-align: center;">37.6</td>
<td style="text-align: center;">66.9</td>
<td style="text-align: center;">82.2</td>
<td style="text-align: center;">37.9</td>
<td style="text-align: center;">37.1</td>
<td style="text-align: center;">70.0</td>
<td style="text-align: center;">57.0</td>
<td style="text-align: center;">62.8</td>
<td style="text-align: center;">50.3</td>
<td style="text-align: center;">43.4</td>
<td style="text-align: center;">46.7</td>
</tr>
<tr>
<td style="text-align: center;">Claude37_Sonnet</td>
<td style="text-align: center;">91.1</td>
<td style="text-align: center;">62.5</td>
<td style="text-align: center;">76.8</td>
<td style="text-align: center;">80.8</td>
<td style="text-align: center;">36.5</td>
<td style="text-align: center;">73.5</td>
<td style="text-align: center;">82.7</td>
<td style="text-align: center;">39.4</td>
<td style="text-align: center;">47.3</td>
<td style="text-align: center;">70.5</td>
<td style="text-align: center;">63.5</td>
<td style="text-align: center;">68.5</td>
<td style="text-align: center;">54.1</td>
<td style="text-align: center;">44.8</td>
<td style="text-align: center;">52.0</td>
</tr>
<tr>
<td style="text-align: center;">Gemini-1.5-pro-flash</td>
<td style="text-align: center;">87.3</td>
<td style="text-align: center;">62.6</td>
<td style="text-align: center;">62.1</td>
<td style="text-align: center;">86.0</td>
<td style="text-align: center;">33.5</td>
<td style="text-align: center;">64.2</td>
<td style="text-align: center;">83.9</td>
<td style="text-align: center;">44.1</td>
<td style="text-align: center;">48.4</td>
<td style="text-align: center;">73.1</td>
<td style="text-align: center;">65.4</td>
<td style="text-align: center;">64.8</td>
<td style="text-align: center;">50.7</td>
<td style="text-align: center;">43.5</td>
<td style="text-align: center;">49.3</td>
</tr>
<tr>
<td style="text-align: center;">Gemini-2.0-pro-flash</td>
<td style="text-align: center;">88.1</td>
<td style="text-align: center;">58.8</td>
<td style="text-align: center;">89.9</td>
<td style="text-align: center;">72.4</td>
<td style="text-align: center;">35.1</td>
<td style="text-align: center;">89.9</td>
<td style="text-align: center;">84.6</td>
<td style="text-align: center;">47.2</td>
<td style="text-align: center;">62.1</td>
<td style="text-align: center;">77.7</td>
<td style="text-align: center;">69.5</td>
<td style="text-align: center;">77.0</td>
<td style="text-align: center;">60.3</td>
<td style="text-align: center;">51.2</td>
<td style="text-align: center;">70.9</td>
</tr>
<tr>
<td style="text-align: center;">GPT-4o</td>
<td style="text-align: center;">91.3</td>
<td style="text-align: center;">66.8</td>
<td style="text-align: center;">72.3</td>
<td style="text-align: center;">73.7</td>
<td style="text-align: center;">37.0</td>
<td style="text-align: center;">75.1</td>
<td style="text-align: center;">83.5</td>
<td style="text-align: center;">37.0</td>
<td style="text-align: center;">34.7</td>
<td style="text-align: center;">72.7</td>
<td style="text-align: center;">73.1</td>
<td style="text-align: center;">66.1</td>
<td style="text-align: center;">49.4</td>
<td style="text-align: center;">44.8</td>
<td style="text-align: center;">44.2</td>
</tr>
<tr>
<td style="text-align: center;">GPT-4o-mimi</td>
<td style="text-align: center;">87.3</td>
<td style="text-align: center;">56.9</td>
<td style="text-align: center;">58.8</td>
<td style="text-align: center;">72.3</td>
<td style="text-align: center;">35.0</td>
<td style="text-align: center;">60.3</td>
<td style="text-align: center;">81.7</td>
<td style="text-align: center;">29.2</td>
<td style="text-align: center;">25.6</td>
<td style="text-align: center;">67.9</td>
<td style="text-align: center;">74.4</td>
<td style="text-align: center;">58.5</td>
<td style="text-align: center;">46.6</td>
<td style="text-align: center;">41.6</td>
<td style="text-align: center;">36.9</td>
</tr>
<tr>
<td style="text-align: center;">Open-Soured MLLMs</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">InterVL2.5-1B</td>
<td style="text-align: center;">58.1</td>
<td style="text-align: center;">26.0</td>
<td style="text-align: center;">7.7</td>
<td style="text-align: center;">42.1</td>
<td style="text-align: center;">35.5</td>
<td style="text-align: center;">9.4</td>
<td style="text-align: center;">51.5</td>
<td style="text-align: center;">21.3</td>
<td style="text-align: center;">11.0</td>
<td style="text-align: center;">44.8</td>
<td style="text-align: center;">33.9</td>
<td style="text-align: center;">21.2</td>
<td style="text-align: center;">25.6</td>
<td style="text-align: center;">32.9</td>
<td style="text-align: center;">11.6</td>
</tr>
<tr>
<td style="text-align: center;">InterVL2.5-2B</td>
<td style="text-align: center;">77.0</td>
<td style="text-align: center;">29.7</td>
<td style="text-align: center;">11.9</td>
<td style="text-align: center;">48.7</td>
<td style="text-align: center;">24.6</td>
<td style="text-align: center;">17.5</td>
<td style="text-align: center;">72.9</td>
<td style="text-align: center;">33.4</td>
<td style="text-align: center;">8.3</td>
<td style="text-align: center;">50.5</td>
<td style="text-align: center;">38.2</td>
<td style="text-align: center;">24.1</td>
<td style="text-align: center;">30.4</td>
<td style="text-align: center;">36.1</td>
<td style="text-align: center;">16.6</td>
</tr>
<tr>
<td style="text-align: center;">InterVL2.5-8B</td>
<td style="text-align: center;">74.3</td>
<td style="text-align: center;">28.7</td>
<td style="text-align: center;">14.2</td>
<td style="text-align: center;">55.0</td>
<td style="text-align: center;">28.5</td>
<td style="text-align: center;">21.2</td>
<td style="text-align: center;">73.6</td>
<td style="text-align: center;">31.9</td>
<td style="text-align: center;">17.0</td>
<td style="text-align: center;">55.9</td>
<td style="text-align: center;">36.3</td>
<td style="text-align: center;">29.1</td>
<td style="text-align: center;">35.0</td>
<td style="text-align: center;">35.3</td>
<td style="text-align: center;">21.5</td>
</tr>
<tr>
<td style="text-align: center;">InterVL2.5-26B</td>
<td style="text-align: center;">81.2</td>
<td style="text-align: center;">31.7</td>
<td style="text-align: center;">13.0</td>
<td style="text-align: center;">62.8</td>
<td style="text-align: center;">29.1</td>
<td style="text-align: center;">16.0</td>
<td style="text-align: center;">80.9</td>
<td style="text-align: center;">32.8</td>
<td style="text-align: center;">15.4</td>
<td style="text-align: center;">52.2</td>
<td style="text-align: center;">47.3</td>
<td style="text-align: center;">35.4</td>
<td style="text-align: center;">35.1</td>
<td style="text-align: center;">34.2</td>
<td style="text-align: center;">23.5</td>
</tr>
<tr>
<td style="text-align: center;">InterVL2.5-38B</td>
<td style="text-align: center;">82.4</td>
<td style="text-align: center;">35.3</td>
<td style="text-align: center;">17.1</td>
<td style="text-align: center;">67.0</td>
<td style="text-align: center;">32.9</td>
<td style="text-align: center;">24.1</td>
<td style="text-align: center;">82.7</td>
<td style="text-align: center;">28.0</td>
<td style="text-align: center;">23.2</td>
<td style="text-align: center;">57.5</td>
<td style="text-align: center;">43.3</td>
<td style="text-align: center;">37.4</td>
<td style="text-align: center;">39.8</td>
<td style="text-align: center;">36.7</td>
<td style="text-align: center;">28.6</td>
</tr>
<tr>
<td style="text-align: center;">InterVL2.5-38B-MPO $\dagger$</td>
<td style="text-align: center;">84.0</td>
<td style="text-align: center;">34.8</td>
<td style="text-align: center;">16.4</td>
<td style="text-align: center;">62.1</td>
<td style="text-align: center;">33.5</td>
<td style="text-align: center;">23.3</td>
<td style="text-align: center;">87.9</td>
<td style="text-align: center;">35.7</td>
<td style="text-align: center;">26.1</td>
<td style="text-align: center;">56.3</td>
<td style="text-align: center;">42.8</td>
<td style="text-align: center;">35.6</td>
<td style="text-align: center;">41.9</td>
<td style="text-align: center;">39.7</td>
<td style="text-align: center;">30.1</td>
</tr>
<tr>
<td style="text-align: center;">InterVL2.5-78B</td>
<td style="text-align: center;">90.1</td>
<td style="text-align: center;">34.5</td>
<td style="text-align: center;">17.4</td>
<td style="text-align: center;">65.0</td>
<td style="text-align: center;">35.4</td>
<td style="text-align: center;">22.5</td>
<td style="text-align: center;">86.0</td>
<td style="text-align: center;">34.8</td>
<td style="text-align: center;">27.6</td>
<td style="text-align: center;">61.5</td>
<td style="text-align: center;">46.0</td>
<td style="text-align: center;">36.2</td>
<td style="text-align: center;">40.2</td>
<td style="text-align: center;">41.7</td>
<td style="text-align: center;">30.8</td>
</tr>
<tr>
<td style="text-align: center;">Deepseek-VL2-tiny</td>
<td style="text-align: center;">55.3</td>
<td style="text-align: center;">40.7</td>
<td style="text-align: center;">21.2</td>
<td style="text-align: center;">36.4</td>
<td style="text-align: center;">21.5</td>
<td style="text-align: center;">18.0</td>
<td style="text-align: center;">29.1</td>
<td style="text-align: center;">11.3</td>
<td style="text-align: center;">11.4</td>
<td style="text-align: center;">32.9</td>
<td style="text-align: center;">48.3</td>
<td style="text-align: center;">21.5</td>
<td style="text-align: center;">15.4</td>
<td style="text-align: center;">20.8</td>
<td style="text-align: center;">14.5</td>
</tr>
<tr>
<td style="text-align: center;">Deepseek-VL2-small</td>
<td style="text-align: center;">66.3</td>
<td style="text-align: center;">51.8</td>
<td style="text-align: center;">34.1</td>
<td style="text-align: center;">52.0</td>
<td style="text-align: center;">25.3</td>
<td style="text-align: center;">38.9</td>
<td style="text-align: center;">53.7</td>
<td style="text-align: center;">22.3</td>
<td style="text-align: center;">16.3</td>
<td style="text-align: center;">47.0</td>
<td style="text-align: center;">59.7</td>
<td style="text-align: center;">40.1</td>
<td style="text-align: center;">21.9</td>
<td style="text-align: center;">28.8</td>
<td style="text-align: center;">20.0</td>
</tr>
<tr>
<td style="text-align: center;">Deepseek-VL2</td>
<td style="text-align: center;">79.4</td>
<td style="text-align: center;">55.0</td>
<td style="text-align: center;">49.2</td>
<td style="text-align: center;">53.7</td>
<td style="text-align: center;">40.3</td>
<td style="text-align: center;">51.7</td>
<td style="text-align: center;">49.0</td>
<td style="text-align: center;">33.6</td>
<td style="text-align: center;">30.4</td>
<td style="text-align: center;">58.6</td>
<td style="text-align: center;">56.0</td>
<td style="text-align: center;">48.3</td>
<td style="text-align: center;">33.6</td>
<td style="text-align: center;">35.6</td>
<td style="text-align: center;">28.6</td>
</tr>
<tr>
<td style="text-align: center;">Llama-vision-11B</td>
<td style="text-align: center;">77.9</td>
<td style="text-align: center;">41.0</td>
<td style="text-align: center;">33.9</td>
<td style="text-align: center;">55.0</td>
<td style="text-align: center;">33.4</td>
<td style="text-align: center;">37.3</td>
<td style="text-align: center;">58.9</td>
<td style="text-align: center;">19.1</td>
<td style="text-align: center;">14.8</td>
<td style="text-align: center;">52.6</td>
<td style="text-align: center;">46.4</td>
<td style="text-align: center;">42.7</td>
<td style="text-align: center;">32.2</td>
<td style="text-align: center;">33.7</td>
<td style="text-align: center;">20.7</td>
</tr>
<tr>
<td style="text-align: center;">Llama-vision-90B</td>
<td style="text-align: center;">83.4</td>
<td style="text-align: center;">52.3</td>
<td style="text-align: center;">45.8</td>
<td style="text-align: center;">70.5</td>
<td style="text-align: center;">32.7</td>
<td style="text-align: center;">45.1</td>
<td style="text-align: center;">68.2</td>
<td style="text-align: center;">21.5</td>
<td style="text-align: center;">19.7</td>
<td style="text-align: center;">58.8</td>
<td style="text-align: center;">52.3</td>
<td style="text-align: center;">44.3</td>
<td style="text-align: center;">37.5</td>
<td style="text-align: center;">34.8</td>
<td style="text-align: center;">24.1</td>
</tr>
<tr>
<td style="text-align: center;">LLaVA-onevison-0.6B</td>
<td style="text-align: center;">42.8</td>
<td style="text-align: center;">32.3</td>
<td style="text-align: center;">7.3</td>
<td style="text-align: center;">27.1</td>
<td style="text-align: center;">23.0</td>
<td style="text-align: center;">9.1</td>
<td style="text-align: center;">31.0</td>
<td style="text-align: center;">8.3</td>
<td style="text-align: center;">13.9</td>
<td style="text-align: center;">22.6</td>
<td style="text-align: center;">25.0</td>
<td style="text-align: center;">7.1</td>
<td style="text-align: center;">9.3</td>
<td style="text-align: center;">22.4</td>
<td style="text-align: center;">5.6</td>
</tr>
<tr>
<td style="text-align: center;">LLaVA-onevison-7B</td>
<td style="text-align: center;">79.3</td>
<td style="text-align: center;">42.6</td>
<td style="text-align: center;">32.8</td>
<td style="text-align: center;">57.3</td>
<td style="text-align: center;">26.2</td>
<td style="text-align: center;">35.3</td>
<td style="text-align: center;">52.3</td>
<td style="text-align: center;">22.4</td>
<td style="text-align: center;">16.0</td>
<td style="text-align: center;">51.6</td>
<td style="text-align: center;">43.8</td>
<td style="text-align: center;">32.2</td>
<td style="text-align: center;">28.6</td>
<td style="text-align: center;">33.6</td>
<td style="text-align: center;">21.7</td>
</tr>
<tr>
<td style="text-align: center;">LLaVA-onevison-72B</td>
<td style="text-align: center;">65.7</td>
<td style="text-align: center;">65.5</td>
<td style="text-align: center;">50.0</td>
<td style="text-align: center;">48.1</td>
<td style="text-align: center;">35.3</td>
<td style="text-align: center;">56.3</td>
<td style="text-align: center;">71.4</td>
<td style="text-align: center;">19.3</td>
<td style="text-align: center;">24.8</td>
<td style="text-align: center;">65.5</td>
<td style="text-align: center;">54.2</td>
<td style="text-align: center;">43.3</td>
<td style="text-align: center;">39.1</td>
<td style="text-align: center;">37.7</td>
<td style="text-align: center;">35.0</td>
</tr>
<tr>
<td style="text-align: center;">Qwen2-VL-2B</td>
<td style="text-align: center;">62.5</td>
<td style="text-align: center;">44.6</td>
<td style="text-align: center;">20.0</td>
<td style="text-align: center;">43.1</td>
<td style="text-align: center;">40.3</td>
<td style="text-align: center;">23.5</td>
<td style="text-align: center;">39.4</td>
<td style="text-align: center;">18.7</td>
<td style="text-align: center;">8.5</td>
<td style="text-align: center;">36.3</td>
<td style="text-align: center;">43.1</td>
<td style="text-align: center;">17.3</td>
<td style="text-align: center;">20.1</td>
<td style="text-align: center;">32.9</td>
<td style="text-align: center;">9.9</td>
</tr>
<tr>
<td style="text-align: center;">Qwen2-VL-7B</td>
<td style="text-align: center;">80.5</td>
<td style="text-align: center;">60.0</td>
<td style="text-align: center;">43.2</td>
<td style="text-align: center;">65.7</td>
<td style="text-align: center;">39.2</td>
<td style="text-align: center;">56.7</td>
<td style="text-align: center;">66.2</td>
<td style="text-align: center;">28.7</td>
<td style="text-align: center;">18.3</td>
<td style="text-align: center;">63.7</td>
<td style="text-align: center;">55.9</td>
<td style="text-align: center;">42.6</td>
<td style="text-align: center;">38.6</td>
<td style="text-align: center;">38.7</td>
<td style="text-align: center;">31.0</td>
</tr>
<tr>
<td style="text-align: center;">Qwen2-VL-72B</td>
<td style="text-align: center;">82.5</td>
<td style="text-align: center;">57.8</td>
<td style="text-align: center;">57.4</td>
<td style="text-align: center;">70.7</td>
<td style="text-align: center;">41.2</td>
<td style="text-align: center;">67.1</td>
<td style="text-align: center;">78.6</td>
<td style="text-align: center;">29.8</td>
<td style="text-align: center;">22.2</td>
<td style="text-align: center;">72.1</td>
<td style="text-align: center;">61.0</td>
<td style="text-align: center;">67.1</td>
<td style="text-align: center;">49.1</td>
<td style="text-align: center;">43.2</td>
<td style="text-align: center;">43.7</td>
</tr>
<tr>
<td style="text-align: center;">Qwen2.5-VL-3B</td>
<td style="text-align: center;">77.6</td>
<td style="text-align: center;">48.9</td>
<td style="text-align: center;">48.7</td>
<td style="text-align: center;">68.4</td>
<td style="text-align: center;">34.3</td>
<td style="text-align: center;">60.0</td>
<td style="text-align: center;">73.4</td>
<td style="text-align: center;">26.8</td>
<td style="text-align: center;">17.4</td>
<td style="text-align: center;">66.1</td>
<td style="text-align: center;">57.1</td>
<td style="text-align: center;">53.1</td>
<td style="text-align: center;">40.6</td>
<td style="text-align: center;">39.5</td>
<td style="text-align: center;">29.5</td>
</tr>
<tr>
<td style="text-align: center;">Qwen2.5-VL-7B</td>
<td style="text-align: center;">85.9</td>
<td style="text-align: center;">63.9</td>
<td style="text-align: center;">59.6</td>
<td style="text-align: center;">72.9</td>
<td style="text-align: center;">43.1</td>
<td style="text-align: center;">67.9</td>
<td style="text-align: center;">82.3</td>
<td style="text-align: center;">36.0</td>
<td style="text-align: center;">26.3</td>
<td style="text-align: center;">67.2</td>
<td style="text-align: center;">71.1</td>
<td style="text-align: center;">60.3</td>
<td style="text-align: center;">48.9</td>
<td style="text-align: center;">44.5</td>
<td style="text-align: center;">40.6</td>
</tr>
<tr>
<td style="text-align: center;">Qwen2.5-VL-72B</td>
<td style="text-align: center;">88.2</td>
<td style="text-align: center;">64.4</td>
<td style="text-align: center;">74.1</td>
<td style="text-align: center;">73.9</td>
<td style="text-align: center;">36.6</td>
<td style="text-align: center;">78.7</td>
<td style="text-align: center;">89.7</td>
<td style="text-align: center;">37.6</td>
<td style="text-align: center;">42.0</td>
<td style="text-align: center;">76.1</td>
<td style="text-align: center;">69.7</td>
<td style="text-align: center;">77.6</td>
<td style="text-align: center;">55.2</td>
<td style="text-align: center;">47.3</td>
<td style="text-align: center;">56.7</td>
</tr>
<tr>
<td style="text-align: center;">QVQ-72B-Preview $\dagger$</td>
<td style="text-align: center;">87.3</td>
<td style="text-align: center;">71.1</td>
<td style="text-align: center;">66.2</td>
<td style="text-align: center;">76.7</td>
<td style="text-align: center;">45.8</td>
<td style="text-align: center;">67.9</td>
<td style="text-align: center;">82.5</td>
<td style="text-align: center;">42.1</td>
<td style="text-align: center;">47.4</td>
<td style="text-align: center;">74.0</td>
<td style="text-align: center;">71.2</td>
<td style="text-align: center;">65.3</td>
<td style="text-align: center;">58.5</td>
<td style="text-align: center;">52.9</td>
<td style="text-align: center;">48.2</td>
</tr>
</tbody>
</table>
<p>Table 8: Mathematical Evaluation of more MLLMs on Different Subjects in GeoSense-English. GPI = Geometric Principles Identification, GPA= Geometric Principles Application, Calculation of Solid Figures = CSF, Understanding of Solid Figures = USF, Transformation and Motion of Plane Figures = TMPF, Calculation of Plane Figures = CPF and Understanding of Plane Figures = UPF. MLLMs with $\dagger$ are typically trained for reasoning tasks.</p>
<p><img alt="img-14.jpeg" src="img-14.jpeg" /></p>
<p>Figure 11: The performance of MLLMs in different subjects on GPI.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>https://www.anthropic.com/news/claude-3-5-sonnet
https://www.anthropic.com/news/claude-3-7-sonnet
https://deepmind.google/technologies/gemini/flash/
https://openai.com/index/
https://help.aliyun.com/zh/model-studio/developer-reference/use-qwen-by-calling-
api
https://ollama.com/library/llama3.2-vision
https://qwenlm.github.io/zh/blog/qvq-72b-preview/&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref4:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
<li id="fn:1">
<p>All prompts used during the annotation process are listed in the Supplementary Material.&#160;<a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 2 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:1" title="Jump back to footnote 2 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>