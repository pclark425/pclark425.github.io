<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1313 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1313</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1313</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-29.html">extraction-schema-29</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <p><strong>Paper ID:</strong> paper-237855678</p>
                <p><strong>Paper Title:</strong> <a href="https://web.archive.org/web/20210715080419/https:/res.mdpi.com/d_attachment/electronics/electronics-10-01491/article_deploy/electronics-10-01491-v2.pdf" target="_blank">Virtual to Real-World Transfer Learning: A Systematic Review</a></p>
                <p><strong>Paper Abstract:</strong> : Machine learning has become an important research area in many domains and real-world applications. The prevailing assumption in traditional machine learning techniques, that training and testing data should be of the same domain, is a challenge. In the real world, gathering enough training data to create high-performance learning models is not easy. Sometimes data are not available, very expensive, or dangerous to collect. In this scenario, the concept of machine learning does not hold up to its potential. Transfer learning has recently gained much acclaim in the ﬁeld of research as it has the capability to create high performance learners through virtual environments or by using data gathered from other domains. This systematic review deﬁnes (a) transfer learning; (b) discusses the recent research conducted; (c) the current status of transfer learning and ﬁnally, (d) discusses how transfer learning can bridge the gap between the virtual and real-world. conducted on transferring a model trained on a simulation and transferring it to a physical robot or vehicle, respectively. There are few papers that suggest novel solutions to improve the performance of this application; discuss how training data are gathered; how simulation environments are setup; and how training data are generated for optimum learning. There are 23 (34%) papers related to research conducted on transfer learning methods, algorithms and techniques used to transfer learning. Classiﬁcations on simulation to physical robot and simulation to vehicle yield 24 (35%) and 6 (8.8%) papers, respectively. These papers include the application of transfer learning where authors of the paper conducted transfer learning.</p>
                <p><strong>Cost:</strong> 0.016</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1313.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1313.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MuJoCo</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>MuJoCo physics engine</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A commercial physics simulator used for multibody dynamics and contact-rich robotic simulation; mentioned as the simulator used for simulated training of industrial pick-and-place robot arms in reviewed studies.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_name</strong></td>
                            <td>MuJoCo</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_description</strong></td>
                            <td>A physics engine for simulating articulated bodies, contacts, and dynamics; referenced as the engine used to simulate industrial robot arms for high-precision tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>mechanics / robotics / robotic manipulation</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_level</strong></td>
                            <td>described in the review as high-precision for robotics tasks (used where high demand and precision are required in manufacturing)</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_characteristics</strong></td>
                            <td>supports multibody dynamics and contact-rich interactions appropriate for manipulation and robot-arm simulation; review notes simulators including MuJoCo are used to approximate dynamics but may not capture full real-world chaotic dynamics or quasi-static nonlinearities</td>
                        </tr>
                        <tr>
                            <td><strong>model_or_agent_name</strong></td>
                            <td>industrial pick-and-place robot policies (robotic arm controllers)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>reinforcement learning agents / neural-network control policies trained in simulation</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task</strong></td>
                            <td>robot manipulation and pick-and-place control (policy learning for industrial robot arms)</td>
                        </tr>
                        <tr>
                            <td><strong>training_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_target</strong></td>
                            <td>physical robot arms / real-world manufacturing setups</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>compares_fidelity_levels</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>minimal_fidelity_discussion</strong></td>
                            <td>The review argues that perfect fidelity is unnecessary in many cases; a crude simulator that captures salient features and introduces noise can suffice, but creating high-fidelity simulators remains difficult and useful for precision tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>Review cites general failure modes when simulators do not capture full dynamics (e.g., real-world chaotic dynamics, quasi-static kinematics not matched) leading to reduced performance after transfer; specific papers (e.g., Tobin et al.) found tightening joints and other small physical differences drastically reduced performance compared to simulation.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1313.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e1313.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>NVIDIA Flex</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>NVIDIA Flex (GPU-based physics simulator)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A GPU-accelerated physics simulation library mentioned as an example of a high-fidelity, GPU-based simulator used to reduce the reality gap in sim-to-real work.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_name</strong></td>
                            <td>NVIDIA Flex</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_description</strong></td>
                            <td>A GPU-based physics simulation framework intended for high-performance, high-fidelity simulation of physical phenomena (cited by the review as an example of GPU-based high-fidelity simulators).</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>mechanics / robotics / general physical simulation</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_level</strong></td>
                            <td>described as high-fidelity (GPU-based) in the review</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_characteristics</strong></td>
                            <td>review states it is GPU-accelerated and considered higher-fidelity than crude simulators; specifics of modeled phenomena are not detailed in the review</td>
                        </tr>
                        <tr>
                            <td><strong>model_or_agent_name</strong></td>
                            <td>various robotic control policies referenced in the reviewed literature</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>reinforcement learning agents or control policies trained in simulation</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task</strong></td>
                            <td>robot control and manipulation tasks where higher-fidelity physics may help bridge the reality gap</td>
                        </tr>
                        <tr>
                            <td><strong>training_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_target</strong></td>
                            <td>real-world robotic systems / physical experiments</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>compares_fidelity_levels</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>minimal_fidelity_discussion</strong></td>
                            <td>The review notes GPU-based high-fidelity simulators (like NVIDIA Flex) are being developed to bridge the reality gap, but also suggests that domain randomization or crude simulators capturing salient features can sometimes suffice.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>No simulator-specific empirical failures reported in the review; general failure cases include mismatches in dynamics and hardware differences that high-fidelity simulators attempt to reduce.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1313.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e1313.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RAWSim-O</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>RAWSim-O (robotic mobile fulfillment systems simulator)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A simulator used for Mobile Fulfillment Systems (RMFS) research, cited in the review as an example of domain-specific simulation used to move from simulation to real-world RMFS deployment.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>From Simulation to Real-World Robotic Mobile Fulfillment Systems</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_name</strong></td>
                            <td>RAWSim-O</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_description</strong></td>
                            <td>A domain-specific simulator for simulating Robotic Mobile Fulfillment Systems (RMFS), used to study and train systems in warehouse/logistics contexts.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>logistics / robotics / automation (warehouse systems)</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_level</strong></td>
                            <td>not explicitly quantified in the review; presented as a simulator developed for realistic RMFS experimentation</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_characteristics</strong></td>
                            <td>models RMFS tasks and environment specifics for mobile fulfillment systems; review does not detail exact physics fidelity</td>
                        </tr>
                        <tr>
                            <td><strong>model_or_agent_name</strong></td>
                            <td>mobile fulfilment system controllers / multi-robot coordination policies</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>control algorithms and transfer-learning approaches for multi-robot logistics systems</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task</strong></td>
                            <td>simulation and transfer of policies for robotic mobile fulfillment (warehouse automation) to real-world systems</td>
                        </tr>
                        <tr>
                            <td><strong>training_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_target</strong></td>
                            <td>real-world Robotic Mobile Fulfillment Systems</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>compares_fidelity_levels</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>minimal_fidelity_discussion</strong></td>
                            <td>Review mentions domain-specific simulators like RAWSim-O are used to decrease the reality difference for particular applications and implies capturing salient system features matters more than complete physical fidelity.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>No RAWSim-O-specific failures discussed; review generally warns that simulators can fail to reproduce chaotic real-world dynamics and dynamic friction effects leading to transfer degradation.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1313.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e1313.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Alphabet Soup</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Alphabet Soup (named simulator in review)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Referenced in the review alongside other GPU-based and high-fidelity simulators as an example of simulators being developed to close the reality gap; specific details are not provided in the review.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_name</strong></td>
                            <td>Alphabet Soup</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_description</strong></td>
                            <td>Mentioned as an example of simulators (grouped with MuJoCo, NVIDIA Flex) that are being developed to improve sim-to-real transfer; the review does not provide a technical description.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>mechanics / robotics (implied)</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_level</strong></td>
                            <td>implicitly described as part of 'GPU based high-fidelity simulators' but the review gives no explicit fidelity metrics</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_characteristics</strong></td>
                            <td>not specified in the review beyond being listed among high-fidelity simulator examples</td>
                        </tr>
                        <tr>
                            <td><strong>model_or_agent_name</strong></td>
                            <td>general robotic control policies discussed in the literature</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>reinforcement learning agents / controllers trained using simulation</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task</strong></td>
                            <td>robot control and policy transfer to the real world</td>
                        </tr>
                        <tr>
                            <td><strong>training_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_target</strong></td>
                            <td>real-world robotic systems</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>compares_fidelity_levels</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>minimal_fidelity_discussion</strong></td>
                            <td>No specific discussion tied to Alphabet Soup; review-level recommendation is that simulators should capture salient features and noise, and domain randomization can compensate for lacking fidelity.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>No simulator-specific failure data provided in the review.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1313.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e1313.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Meta-Sim</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Meta-Sim: Learning to Generate Synthetic Datasets</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A method/paper cited in the review about learning to generate synthetic datasets (meta-simulation) to improve sim-to-real training data generation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Meta-Sim: Learning to Generate Synthetic Datasets</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_name</strong></td>
                            <td>Meta-Sim (dataset/synthetic data generator)</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_description</strong></td>
                            <td>A learning approach to generate synthetic datasets (meta-simulation) for training models; presented as a tool to create realistic synthetic training data for vision and related tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>computer vision / synthetic data generation (general ML)</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_level</strong></td>
                            <td>aims to produce synthetic datasets with higher realism for training; fidelity is data-driven rather than physics-driven and tailored to the target task</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_characteristics</strong></td>
                            <td>focus on generating task-relevant visual realism and diversity in synthetic data; review does not provide implementation specifics</td>
                        </tr>
                        <tr>
                            <td><strong>model_or_agent_name</strong></td>
                            <td>vision models and policies trained on synthetic datasets</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>deep learning vision models and policies trained using synthetic images/data generated by Meta-Sim</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task</strong></td>
                            <td>training perception modules (e.g., object detection, driving behaviour recognition) in simulation using synthetic datasets</td>
                        </tr>
                        <tr>
                            <td><strong>training_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_target</strong></td>
                            <td>real-world perception tasks / downstream models</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>compares_fidelity_levels</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>minimal_fidelity_discussion</strong></td>
                            <td>Review highlights synthetic-data approaches like Meta-Sim as an option to improve realism of training sets, implicitly reducing the need for perfect physics fidelity when perception is the main task.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>Not specified in the review; general caveat that synthetic datasets and simulators can still leave a reality gap if salient target-domain features are not captured.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1313.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e1313.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Game engine (generic)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Generic game engine physics simulator</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The review refers to using game engines to simulate real-world physics and generate parallel simulations for training, especially for tasks where real data are expensive or dangerous to collect.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_name</strong></td>
                            <td>game engine (generic)</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_description</strong></td>
                            <td>Generic game-engine-based simulation environments (e.g., engines that model physics, rendering, and interactions) used as low-to-medium-fidelity virtual training environments.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>mechanics / robotics / autonomous systems (general)</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_level</strong></td>
                            <td>varies from low- to medium-fidelity depending on the engine and configuration; review notes game engines cannot fully capture real-world dynamics but are useful for large-scale parallelized training</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_characteristics</strong></td>
                            <td>typically model visual aspects (lighting, textures) and simplified physics; review notes visual randomization can be applied (camera position, lighting, textures) but full physical fidelity may be lacking</td>
                        </tr>
                        <tr>
                            <td><strong>model_or_agent_name</strong></td>
                            <td>self-driving car and robotics models (perception and control policies)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>deep reinforcement learning agents, perception models, and control policies trained in simulated game-engine environments</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task</strong></td>
                            <td>perception, planning, and control tasks such as autonomous driving scenarios and robotics behaviours where synthetic scenarios are generated</td>
                        </tr>
                        <tr>
                            <td><strong>training_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_target</strong></td>
                            <td>real-world vehicles and robots / physical deployments</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>compares_fidelity_levels</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>minimal_fidelity_discussion</strong></td>
                            <td>Review suggests that instead of modeling all real-world parameters, heavy domain randomization in game-engine simulations can enable robust transfer; a crude simulator capturing salient features plus randomized variation may be sufficient.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>Review states game engines often cannot fully capture real-world physics leading to a reality gap; specific failure examples include significant performance drops when simulators omit critical dynamics (e.g., friction, joint compliance).</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Domain Randomization for Transferring Deep Neural Networks from Simulation to the Real World <em>(Rating: 2)</em></li>
                <li>Sim-to-Real Transfer of Robotic Control with Dynamics Randomization <em>(Rating: 2)</em></li>
                <li>Using Simulation and Domain Adaptation to Improve Efficiency of Deep Robotic Grasping <em>(Rating: 2)</em></li>
                <li>Sim-to-Real Transfer Learning Using Robustified Controllers in Robotic Tasks Involving Complex Dynamics <em>(Rating: 2)</em></li>
                <li>Closing the Sim-to-Real Loop: Adapting Simulation Randomization with Real World Experience <em>(Rating: 2)</em></li>
                <li>Meta-Sim: Learning to Generate Synthetic Datasets <em>(Rating: 2)</em></li>
                <li>CAD2RL: Real Single-Image Flight without a Single Real Image <em>(Rating: 1)</em></li>
                <li>Sim-to-Real Transfer in Deep Reinforcement Learning for Robotics: A Survey <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1313",
    "paper_id": "paper-237855678",
    "extraction_schema_id": "extraction-schema-29",
    "extracted_data": [
        {
            "name_short": "MuJoCo",
            "name_full": "MuJoCo physics engine",
            "brief_description": "A commercial physics simulator used for multibody dynamics and contact-rich robotic simulation; mentioned as the simulator used for simulated training of industrial pick-and-place robot arms in reviewed studies.",
            "citation_title": "",
            "mention_or_use": "mention",
            "simulator_name": "MuJoCo",
            "simulator_description": "A physics engine for simulating articulated bodies, contacts, and dynamics; referenced as the engine used to simulate industrial robot arms for high-precision tasks.",
            "scientific_domain": "mechanics / robotics / robotic manipulation",
            "fidelity_level": "described in the review as high-precision for robotics tasks (used where high demand and precision are required in manufacturing)",
            "fidelity_characteristics": "supports multibody dynamics and contact-rich interactions appropriate for manipulation and robot-arm simulation; review notes simulators including MuJoCo are used to approximate dynamics but may not capture full real-world chaotic dynamics or quasi-static nonlinearities",
            "model_or_agent_name": "industrial pick-and-place robot policies (robotic arm controllers)",
            "model_description": "reinforcement learning agents / neural-network control policies trained in simulation",
            "reasoning_task": "robot manipulation and pick-and-place control (policy learning for industrial robot arms)",
            "training_performance": null,
            "transfer_target": "physical robot arms / real-world manufacturing setups",
            "transfer_performance": null,
            "compares_fidelity_levels": false,
            "fidelity_comparison_results": "",
            "minimal_fidelity_discussion": "The review argues that perfect fidelity is unnecessary in many cases; a crude simulator that captures salient features and introduces noise can suffice, but creating high-fidelity simulators remains difficult and useful for precision tasks.",
            "failure_cases": "Review cites general failure modes when simulators do not capture full dynamics (e.g., real-world chaotic dynamics, quasi-static kinematics not matched) leading to reduced performance after transfer; specific papers (e.g., Tobin et al.) found tightening joints and other small physical differences drastically reduced performance compared to simulation.",
            "uuid": "e1313.0"
        },
        {
            "name_short": "NVIDIA Flex",
            "name_full": "NVIDIA Flex (GPU-based physics simulator)",
            "brief_description": "A GPU-accelerated physics simulation library mentioned as an example of a high-fidelity, GPU-based simulator used to reduce the reality gap in sim-to-real work.",
            "citation_title": "",
            "mention_or_use": "mention",
            "simulator_name": "NVIDIA Flex",
            "simulator_description": "A GPU-based physics simulation framework intended for high-performance, high-fidelity simulation of physical phenomena (cited by the review as an example of GPU-based high-fidelity simulators).",
            "scientific_domain": "mechanics / robotics / general physical simulation",
            "fidelity_level": "described as high-fidelity (GPU-based) in the review",
            "fidelity_characteristics": "review states it is GPU-accelerated and considered higher-fidelity than crude simulators; specifics of modeled phenomena are not detailed in the review",
            "model_or_agent_name": "various robotic control policies referenced in the reviewed literature",
            "model_description": "reinforcement learning agents or control policies trained in simulation",
            "reasoning_task": "robot control and manipulation tasks where higher-fidelity physics may help bridge the reality gap",
            "training_performance": null,
            "transfer_target": "real-world robotic systems / physical experiments",
            "transfer_performance": null,
            "compares_fidelity_levels": false,
            "fidelity_comparison_results": "",
            "minimal_fidelity_discussion": "The review notes GPU-based high-fidelity simulators (like NVIDIA Flex) are being developed to bridge the reality gap, but also suggests that domain randomization or crude simulators capturing salient features can sometimes suffice.",
            "failure_cases": "No simulator-specific empirical failures reported in the review; general failure cases include mismatches in dynamics and hardware differences that high-fidelity simulators attempt to reduce.",
            "uuid": "e1313.1"
        },
        {
            "name_short": "RAWSim-O",
            "name_full": "RAWSim-O (robotic mobile fulfillment systems simulator)",
            "brief_description": "A simulator used for Mobile Fulfillment Systems (RMFS) research, cited in the review as an example of domain-specific simulation used to move from simulation to real-world RMFS deployment.",
            "citation_title": "From Simulation to Real-World Robotic Mobile Fulfillment Systems",
            "mention_or_use": "mention",
            "simulator_name": "RAWSim-O",
            "simulator_description": "A domain-specific simulator for simulating Robotic Mobile Fulfillment Systems (RMFS), used to study and train systems in warehouse/logistics contexts.",
            "scientific_domain": "logistics / robotics / automation (warehouse systems)",
            "fidelity_level": "not explicitly quantified in the review; presented as a simulator developed for realistic RMFS experimentation",
            "fidelity_characteristics": "models RMFS tasks and environment specifics for mobile fulfillment systems; review does not detail exact physics fidelity",
            "model_or_agent_name": "mobile fulfilment system controllers / multi-robot coordination policies",
            "model_description": "control algorithms and transfer-learning approaches for multi-robot logistics systems",
            "reasoning_task": "simulation and transfer of policies for robotic mobile fulfillment (warehouse automation) to real-world systems",
            "training_performance": null,
            "transfer_target": "real-world Robotic Mobile Fulfillment Systems",
            "transfer_performance": null,
            "compares_fidelity_levels": false,
            "fidelity_comparison_results": "",
            "minimal_fidelity_discussion": "Review mentions domain-specific simulators like RAWSim-O are used to decrease the reality difference for particular applications and implies capturing salient system features matters more than complete physical fidelity.",
            "failure_cases": "No RAWSim-O-specific failures discussed; review generally warns that simulators can fail to reproduce chaotic real-world dynamics and dynamic friction effects leading to transfer degradation.",
            "uuid": "e1313.2"
        },
        {
            "name_short": "Alphabet Soup",
            "name_full": "Alphabet Soup (named simulator in review)",
            "brief_description": "Referenced in the review alongside other GPU-based and high-fidelity simulators as an example of simulators being developed to close the reality gap; specific details are not provided in the review.",
            "citation_title": "",
            "mention_or_use": "mention",
            "simulator_name": "Alphabet Soup",
            "simulator_description": "Mentioned as an example of simulators (grouped with MuJoCo, NVIDIA Flex) that are being developed to improve sim-to-real transfer; the review does not provide a technical description.",
            "scientific_domain": "mechanics / robotics (implied)",
            "fidelity_level": "implicitly described as part of 'GPU based high-fidelity simulators' but the review gives no explicit fidelity metrics",
            "fidelity_characteristics": "not specified in the review beyond being listed among high-fidelity simulator examples",
            "model_or_agent_name": "general robotic control policies discussed in the literature",
            "model_description": "reinforcement learning agents / controllers trained using simulation",
            "reasoning_task": "robot control and policy transfer to the real world",
            "training_performance": null,
            "transfer_target": "real-world robotic systems",
            "transfer_performance": null,
            "compares_fidelity_levels": false,
            "fidelity_comparison_results": "",
            "minimal_fidelity_discussion": "No specific discussion tied to Alphabet Soup; review-level recommendation is that simulators should capture salient features and noise, and domain randomization can compensate for lacking fidelity.",
            "failure_cases": "No simulator-specific failure data provided in the review.",
            "uuid": "e1313.3"
        },
        {
            "name_short": "Meta-Sim",
            "name_full": "Meta-Sim: Learning to Generate Synthetic Datasets",
            "brief_description": "A method/paper cited in the review about learning to generate synthetic datasets (meta-simulation) to improve sim-to-real training data generation.",
            "citation_title": "Meta-Sim: Learning to Generate Synthetic Datasets",
            "mention_or_use": "mention",
            "simulator_name": "Meta-Sim (dataset/synthetic data generator)",
            "simulator_description": "A learning approach to generate synthetic datasets (meta-simulation) for training models; presented as a tool to create realistic synthetic training data for vision and related tasks.",
            "scientific_domain": "computer vision / synthetic data generation (general ML)",
            "fidelity_level": "aims to produce synthetic datasets with higher realism for training; fidelity is data-driven rather than physics-driven and tailored to the target task",
            "fidelity_characteristics": "focus on generating task-relevant visual realism and diversity in synthetic data; review does not provide implementation specifics",
            "model_or_agent_name": "vision models and policies trained on synthetic datasets",
            "model_description": "deep learning vision models and policies trained using synthetic images/data generated by Meta-Sim",
            "reasoning_task": "training perception modules (e.g., object detection, driving behaviour recognition) in simulation using synthetic datasets",
            "training_performance": null,
            "transfer_target": "real-world perception tasks / downstream models",
            "transfer_performance": null,
            "compares_fidelity_levels": false,
            "fidelity_comparison_results": "",
            "minimal_fidelity_discussion": "Review highlights synthetic-data approaches like Meta-Sim as an option to improve realism of training sets, implicitly reducing the need for perfect physics fidelity when perception is the main task.",
            "failure_cases": "Not specified in the review; general caveat that synthetic datasets and simulators can still leave a reality gap if salient target-domain features are not captured.",
            "uuid": "e1313.4"
        },
        {
            "name_short": "Game engine (generic)",
            "name_full": "Generic game engine physics simulator",
            "brief_description": "The review refers to using game engines to simulate real-world physics and generate parallel simulations for training, especially for tasks where real data are expensive or dangerous to collect.",
            "citation_title": "",
            "mention_or_use": "mention",
            "simulator_name": "game engine (generic)",
            "simulator_description": "Generic game-engine-based simulation environments (e.g., engines that model physics, rendering, and interactions) used as low-to-medium-fidelity virtual training environments.",
            "scientific_domain": "mechanics / robotics / autonomous systems (general)",
            "fidelity_level": "varies from low- to medium-fidelity depending on the engine and configuration; review notes game engines cannot fully capture real-world dynamics but are useful for large-scale parallelized training",
            "fidelity_characteristics": "typically model visual aspects (lighting, textures) and simplified physics; review notes visual randomization can be applied (camera position, lighting, textures) but full physical fidelity may be lacking",
            "model_or_agent_name": "self-driving car and robotics models (perception and control policies)",
            "model_description": "deep reinforcement learning agents, perception models, and control policies trained in simulated game-engine environments",
            "reasoning_task": "perception, planning, and control tasks such as autonomous driving scenarios and robotics behaviours where synthetic scenarios are generated",
            "training_performance": null,
            "transfer_target": "real-world vehicles and robots / physical deployments",
            "transfer_performance": null,
            "compares_fidelity_levels": false,
            "fidelity_comparison_results": "",
            "minimal_fidelity_discussion": "Review suggests that instead of modeling all real-world parameters, heavy domain randomization in game-engine simulations can enable robust transfer; a crude simulator capturing salient features plus randomized variation may be sufficient.",
            "failure_cases": "Review states game engines often cannot fully capture real-world physics leading to a reality gap; specific failure examples include significant performance drops when simulators omit critical dynamics (e.g., friction, joint compliance).",
            "uuid": "e1313.5"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Domain Randomization for Transferring Deep Neural Networks from Simulation to the Real World",
            "rating": 2,
            "sanitized_title": "domain_randomization_for_transferring_deep_neural_networks_from_simulation_to_the_real_world"
        },
        {
            "paper_title": "Sim-to-Real Transfer of Robotic Control with Dynamics Randomization",
            "rating": 2,
            "sanitized_title": "simtoreal_transfer_of_robotic_control_with_dynamics_randomization"
        },
        {
            "paper_title": "Using Simulation and Domain Adaptation to Improve Efficiency of Deep Robotic Grasping",
            "rating": 2,
            "sanitized_title": "using_simulation_and_domain_adaptation_to_improve_efficiency_of_deep_robotic_grasping"
        },
        {
            "paper_title": "Sim-to-Real Transfer Learning Using Robustified Controllers in Robotic Tasks Involving Complex Dynamics",
            "rating": 2,
            "sanitized_title": "simtoreal_transfer_learning_using_robustified_controllers_in_robotic_tasks_involving_complex_dynamics"
        },
        {
            "paper_title": "Closing the Sim-to-Real Loop: Adapting Simulation Randomization with Real World Experience",
            "rating": 2,
            "sanitized_title": "closing_the_simtoreal_loop_adapting_simulation_randomization_with_real_world_experience"
        },
        {
            "paper_title": "Meta-Sim: Learning to Generate Synthetic Datasets",
            "rating": 2,
            "sanitized_title": "metasim_learning_to_generate_synthetic_datasets"
        },
        {
            "paper_title": "CAD2RL: Real Single-Image Flight without a Single Real Image",
            "rating": 1,
            "sanitized_title": "cad2rl_real_singleimage_flight_without_a_single_real_image"
        },
        {
            "paper_title": "Sim-to-Real Transfer in Deep Reinforcement Learning for Robotics: A Survey",
            "rating": 2,
            "sanitized_title": "simtoreal_transfer_in_deep_reinforcement_learning_for_robotics_a_survey"
        }
    ],
    "cost": 0.0158995,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>electronics Virtual to Real-World Transfer Learning: A Systematic Review
Published: 21 June 2021</p>
<p>Mahesh Ranaweera 
Department of Electrical
Computer and Software Engineering
Ontario Tech University
L1G 0C5OshawaONCanada</p>
<p>Qusay H Mahmoud qusay.mahmoud@ontariotechu.ca*correspondence:mahesh.ranaweerakaluarachchige@ontariotechu.net 
Department of Electrical
Computer and Software Engineering
Ontario Tech University
L1G 0C5OshawaONCanada</p>
<p>electronics Virtual to Real-World Transfer Learning: A Systematic Review
Published: 21 June 202110.3390/electronics10121491Received: 18 May 2021 Accepted: 18 June 2021Review Citation: Ranaweera, M.; Mahmoud, Q.H. Virtual to Real-World Transfer Learning: A Systematic Review. Electronics 2021, 10, 1491. https:// Academic Editor: Amir Mosavi Publisher's Note: MDPI stays neutral with regard to jurisdictional claims in published maps and institutional affil-iations. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https:// creativecommons.org/licenses/by/ 4.0/).machine learningtransfer learningroboticssystematic review
Machine learning has become an important research area in many domains and real-world applications. The prevailing assumption in traditional machine learning techniques, that training and testing data should be of the same domain, is a challenge. In the real world, gathering enough training data to create high-performance learning models is not easy. Sometimes data are not available, very expensive, or dangerous to collect. In this scenario, the concept of machine learning does not hold up to its potential. Transfer learning has recently gained much acclaim in the field of research as it has the capability to create high performance learners through virtual environments or by using data gathered from other domains. This systematic review defines (a) transfer learning; (b) discusses the recent research conducted; (c) the current status of transfer learning and finally, (d) discusses how transfer learning can bridge the gap between the virtual and real-world.</p>
<p>Introduction</p>
<p>Developing robots that have the capabilities and the dexterity of humans is very challenging. It is also a daunting task to preprogram robots by hand to perform specific tasks. Moreover, these preprogrammed tasks cannot be transferred over to another domain or environment; therefore, robots become domain specific and very expensive to operate and manufacture. Recently, there has been much demand in adopting machine learning as a potential solution to teach robots to perform challenging tasks. Machine learning has the potential to allow robots to learn about their environment through sensors and make expert decisions just like a human. However, training robotic platforms require more training data and gathering the required amount of data from a physical machine is expensive. Machine learning algorithms often struggle to perform unseen tasks (online learning) and in transferring/applying learned experiences (continual learning) [1]. Gathering quality data is difficult because the collection of accurate data is expensive, has to consider different domains, needs to consider sample data efficiency, and it has to overcome safety concerns and unexpected behaviors that can emerge while operating robots/machinery. Since deep learning models are data dependent, recognizing patterns requires adequate training data from different domains; however, gathering training data from physical robots is considered to be inefficient and expensive.</p>
<p>Recent advancements in machine learning, specifically in the areas of deep reinforcement learning (DRL) and transfer learning have been adapted into developing advanced robotic platforms. Humans gain capability, dexterity, and knowledge throughout their lifetimes by learning at a very young age, by observing, mimicking, and adapting to their environment by trial and error [2]. Similarly, RL assumes that a machine can be trained by acquiring knowledge through rewards when the machine behaves/acts in a certain way. Adequate training data can be gathered using simulation-based training at a significantly lower cost, and a trained model can be transferred to the physical robot. There is an inherent mismatch when transferring knowledge from the virtual to the real world, which can be minimized through realistic virtual training environments [3]. There has been significant advancement using transfer learning in DRL to enhance the quality of training and transferring models, trained on a virtual environment to a physical mechanical entity.</p>
<p>The Neural Information Processing Systems (NIPS) workshop held on "Learning to Learn: Knowledge Consolidation and Transfer in Inductive Systems" in 1995 was the first inference for coining the term transfer learning [4,5]. There are many researchers who have conducted transferring of learned knowledge from one domain to another. However, in all these cases, the term transfer learning was not explicitly used as a valid technique. There are many questions that need to be answered in terms of benefits, limitations, challenges, and open research areas that need to be explored and improved.</p>
<p>The purpose of this paper, therefore, is to present a systematic review on transfer learning and to provide in-depth answers to the above-mentioned questions. Multiple surveys have been conducted on the topic of transfer learning [6][7][8]. This research study is different from previous studies in terms of the area of the study, its focus, and the methodology. While other review papers focus on the general status of transfer learning in a wide area of applications, this paper focuses specific attention on the status of transfer learning in the virtual to real-world context. Additionally, this paper followed a systematic structure when gathering research papers and extracting the information. This systematic review is structured as follows. Section 2 provides an overview of transfer learning. Section 3 defines the research methodology. Section 4 presents the research results, which are further discussed in Section 5. Finally, Section 6 concludes the paper and offers ideas for future work.</p>
<p>Overview of Transfer Learning</p>
<p>In classical supervised learning, a model is trained on a certain domain with labeled data that corresponds to the given domain. The data consist of training and testing sets that belong to the same domain or feature space. For example, for a machine learning model to detect different types of cars, it requires datasets that contain labeled images of cars of different types. The supervised learning paradigm breaks down when sufficient training data are not available. The reliability of the model depends on the labeled data's quantity, quality, and accuracy. For instance, a classification model trained on images taken in the daytime cannot be used to classify objects taken in the nighttime. The accuracy and the performance of the model drastically decreases as the model has not seen the new domain. In certain scenarios, such as when data collection is expensive and dangerous, or the available data are not sufficient [9], the accuracy and the performance of the model degrades. Other machine learning methods perform accurately when the domain and feature space are the same. However, when the domain changes, the learner models need to be retrained to adapt to the new domain. This retraining process is often expensive in terms of computational time and testing, and it seldom requires retraining from the beginning or it expects to gather new training data. In such scenarios, the transfer of knowledge from one domain to another is possible with the training that transfer learning provides.</p>
<p>There are several benefits of using transfer learning in contrast to traditional machine learning techniques.</p>
<p>1.</p>
<p>Traditional techniques are data dependent; however, transfer learning requires less training data to train the model as it can utilize pretrained models as a starting point.</p>
<p>2.</p>
<p>Models trained using transfer learning have the ability to easily generalize for other unseen domains. This is because transfer learning models are trained to identify features that can be applied to an unseen context/domain.</p>
<p>3.</p>
<p>Transfer learning has the potential to make machine learning and deep learning more accessible.</p>
<p>4.</p>
<p>Unlike other learning methods, transfer learning provides an optimized initial starting point, higher learning accuracy, and faster training for new domains.</p>
<p>As mentioned, transfer learning seems to provide a better, accurate model for new unseen tasks of learning and allows the reuse of already existing pretrained models as a starting point. Developers and researchers can circumvent pitfalls during their initial Electronics 2021, 10, 1491 3 of 18 approach to develop new ground-breaking machine learning and deep learning solutions. Transfer learning eliminates the need for expensive and time-consuming data gathering, cleaning, annotation and training procedures. Martina et al. in their research combined multiple pretrained models to create a subject-specific model for extracting emotional content from facial datasets [10]. The above mentioned benefits can be seen as a motivation to use transfer learning. Figure 1 shows how traditional machine learning systems learn individual tasks from the beginning whereas the transfer learning technique attempts to transfer the knowledge obtained from one learning system to another. There are three major types of transfer learning methods: inductive, unsupervised and transductive.</p>
<p>Electronics 2021, 10, x FOR PEER REVIEW 3 of 18</p>
<p>As mentioned, transfer learning seems to provide a better, accurate model for new unseen tasks of learning and allows the reuse of already existing pretrained models as a starting point. Developers and researchers can circumvent pitfalls during their initial approach to develop new ground-breaking machine learning and deep learning solutions. Transfer learning eliminates the need for expensive and time-consuming data gathering, cleaning, annotation and training procedures. Martina et al. in their research combined multiple pretrained models to create a subject-specific model for extracting emotional content from facial datasets [10]. The above mentioned benefits can be seen as a motivation to use transfer learning. Figure 1 shows how traditional machine learning systems learn individual tasks from the beginning whereas the transfer learning technique attempts to transfer the knowledge obtained from one learning system to another. There are three major types of transfer learning methods: inductive, unsupervised and transductive. 1. Inductive transfer learning: It is where few labeled data are available to be used as training data for the target domain. In this case, some labeled data are required to create an objective model. The aim of this transfer learning method is to improve the target function. 2. Unsupervised transfer learning: It is when no labeled training data are available from the source and target domains; however, the source and target tasks are both related and different. 3. Transductive transfer learning: It is a case where no labeled data are available from the target domain whereas more data are available from the source domain. As described in Table 1, the source and target domains are related but different, while the source and target tasks remain the same.  </p>
<p>1.</p>
<p>Inductive transfer learning: It is where few labeled data are available to be used as training data for the target domain. In this case, some labeled data are required to create an objective model. The aim of this transfer learning method is to improve the target function.</p>
<p>2.</p>
<p>Unsupervised transfer learning: It is when no labeled training data are available from the source and target domains; however, the source and target tasks are both related and different.</p>
<p>3.</p>
<p>Transductive transfer learning: It is a case where no labeled data are available from the target domain whereas more data are available from the source domain. As described in Table 1, the source and target domains are related but different, while the source and target tasks remain the same. In contrast, transfer learning techniques tend to transfer knowledge from a previous task to a target task as shown in Table 1, adapted from [6]. As shown in the Figure 1, traditional machine learning techniques attempt to learn new tasks from the beginning, while transfer learning transfers the gained knowledge over to a target domain, which does not have quality training data available. As mentioned earlier, the need for transfer learning occurs when there is a limited supply of training data available for the target domain. This could be either due to the danger posed to humans when accessing such data, or gathering such data is very expensive and time consuming, or data are not available or accessible.</p>
<p>One particular area where the transfer learning method shines is learning from simulations. Many machine learning tasks are very expensive, time consuming or dangerous and can benefit from transfer learning, where the data are gathered through virtual simulations. For example, by using a game engine to simulate real-world physics and to perform expensive simulations to gather the necessary training data. Although a game engine cannot accurately simulate the real world, intended tasks can benefit from running multiple parallel simulations to reduce the margin of error. Self-driving cars and robotics can gain benefits using simulations to improve their accuracy and performance. Google, Waymo and Metamoto have developed their own vehicle simulation environments to simulate advanced road conditions and scenarios that involve pedestrians and other vehicles to train their models. Simulated transfer learning is applied in training robots where it is very expensive to manipulate them and often time consuming. Random scenarios are generated and trained in parallel to different environments.</p>
<p>There are different methods that aim to perform transfer learning in simulations of real-world learning. These methods are: Knowledge Distillation, Imitation Learning, Domain Randomization, Zero-shot Transfer, Meta-reinforcement Learning and Domain Adaptation. Each method will be discussed in the following section.</p>
<p>Knowledge Distillation</p>
<p>Knowledge distillation is a process where large high dimensionality networks are distilled into smaller networks that are smaller but efficient. In this case, the larger network (the teacher) generates training data for the training of the smaller network (the student) [11]. For example, complex visuals that contain high dimensional input are further merged into simpler forms when training the new model.</p>
<p>Imitation Learning</p>
<p>In imitation transfer learning, an expert model demonstrates near optimum behavior to a learning agent. This learning agent attempts to replicate the learned knowledge [12]. There are two methods of imitation learning. They are behavior cloning (agent learns mapping from demonstration) and inverse reinforcement learning where the agent estimates the reward function that best estimates the demonstration [3]. This method can be utilized with Reinforcement Learning to create robust virtual to real-world transfer models.</p>
<p>Domain Randomization</p>
<p>Domain randomization is a method in which instead of modelling all parameters for the real world, the simulated training is highly randomized. This randomization process during the simulated training can eliminate any bias created when transferred to the real world. Visual randomization is a method used to randomize camera position, lighting, textures and environmental details. This method is very useful in transfer learning situations where the robot depends on vision to perform pose-estimation, object localization, object detection and semantic segmentation.</p>
<p>Zero Shot Transfer Method</p>
<p>In this method, the training environment must be realistic to perform the straightforward transferring of the trained model. The difficulty with this method is to build realistic and precise models of the real world. If the simulation is identical to the real world, this method can be used to transfer the trained model without additional optimization [13]. This method is often carried out with a domain randomization method to make sure bias is eliminated.</p>
<p>Meta-Reinforcement Learning</p>
<p>In Meta-reinforcement learning, the model is expected to generalize to an unseen new environment. This method is often known as "learning to learn" because the aim of the trained model is to adapt to the unseen task or environment from multiple training tasks. An optimized meta learning model should be trained on multiple learning tasks and should also be introduced to unseen tasks [14]. With this method, the trained model can use past experience (observed as unseen tasks) in the real world.</p>
<p>Domain Adaptation</p>
<p>Domain adaptation is a subset of the transfer learning method. Traditionally, the aim of transfer learning is to improve the performance of a target domain (Ds) by transferring the learned knowledge that is contained in different but related source domains (Ds) [3]. There are cases where sufficient source domain training data are available, but target domain data are not available or not sufficient. There are two types of domain adaptation methods. They is one-step domain adaptation and multi-step domain adaptation. Each method uses different strategies to transfer knowledge from the source domain to the target domain [15]. In this case, the domain adaptation method can be utilized with simulated data to transfer the model's knowledge.</p>
<p>Research Methodology</p>
<p>For this systematic review and meta-analyses, we adapted the guidelines described in the PRISMA statement [16]. The goal of this systematic review was to get an overview of the research area and find state-of-the-art research conducted on the research topic. A systematic mapping study was conducted to identify the state-of-the-art research, developments, advantages and disadvantages and identify the efficacy of virtual-to-real knowledge transferring methods. This also helped to identify any available research gaps of using virtual to real-world transfer learning.</p>
<p>In this research we followed the systematic mapping methodology ( Figure 2) proposed by Petersen et al. [17]. and precise models of the real world. If the simulation is identical to the real world, this method can be used to transfer the trained model without additional optimization [13]. This method is often carried out with a domain randomization method to make sure bias is eliminated.</p>
<p>Meta-Reinforcement Learning</p>
<p>In Meta-reinforcement learning, the model is expected to generalize to an unseen new environment. This method is often known as "learning to learn" because the aim of the trained model is to adapt to the unseen task or environment from multiple training tasks.</p>
<p>An optimized meta learning model should be trained on multiple learning tasks and should also be introduced to unseen tasks [14]. With this method, the trained model can use past experience (observed as unseen tasks) in the real world.</p>
<p>Domain Adaptation</p>
<p>Domain adaptation is a subset of the transfer learning method. Traditionally, the aim of transfer learning is to improve the performance of a target domain (Ds) by transferring the learned knowledge that is contained in different but related source domains (Ds) [3]. There are cases where sufficient source domain training data are available, but target domain data are not available or not sufficient. There are two types of domain adaptation methods. They is one-step domain adaptation and multi-step domain adaptation. Each method uses different strategies to transfer knowledge from the source domain to the target domain [15]. In this case, the domain adaptation method can be utilized with simulated data to transfer the model's knowledge.</p>
<p>Research Methodology</p>
<p>For this systematic review and meta-analyses, we adapted the guidelines described in the PRISMA statement [16]. The goal of this systematic review was to get an overview of the research area and find state-of-the-art research conducted on the research topic. A systematic mapping study was conducted to identify the state-of-the-art research, developments, advantages and disadvantages and identify the efficacy of virtual-to-real knowledge transferring methods. This also helped to identify any available research gaps of using virtual to real-world transfer learning.</p>
<p>In this research we followed the systematic mapping methodology ( Figure 2) proposed by Petersen et al. [17]. </p>
<p>Definition of Research Questions</p>
<p>As the initial process of systematic study, the following questions were answered to evaluate the state of the art in virtual to real-world transfer learning. These questions were designed to be in line with the research area and to fulfil the objectives of the research.</p>
<p>What Are the Benefits of Using Transfer Learning?</p>
<p>The intention of this question is to primarily understand the application of transfer learning as a solution to overcome downfalls experienced from other machine learning and deep learning techniques. By reviewing articles that utilized transfer learning meth- </p>
<p>Definition of Research Questions</p>
<p>As the initial process of systematic study, the following questions were answered to evaluate the state of the art in virtual to real-world transfer learning. These questions were designed to be in line with the research area and to fulfil the objectives of the research.</p>
<p>What Are the Benefits of Using Transfer Learning?</p>
<p>The intention of this question is to primarily understand the application of transfer learning as a solution to overcome downfalls experienced from other machine learning and deep learning techniques. By reviewing articles that utilized transfer learning methods to overcome pitfalls from other much hyped techniques, future researchers and developers can make better judgments over other techniques. This question also helps to identify the challenges and limitations of using other machine and deep learning methods.</p>
<p>What Are the Use Cases of Transfer Learning in the Virtual to Real-World Context?</p>
<p>There are many use cases, novel applications and implementations of transfer learning. However, the main goal of this research question is to identify use cases of transfer learning in the context of virtual to real-world knowledge transfer. This helps to identify any research gaps available in this context and/or identify areas that can be improved upon. There are many challenges and limitations to using transfer learning in the virtual to real-world context. Based on the applications and prototypes developed, this question seeks to find limitations of using transfer learning.</p>
<p>How Are These Challenges and Limitations Currently Addressed?</p>
<p>This question seeks to identify current approaches taken to overcome the challenges and limitations of using transfer learning. This question looks at current methods or techniques used to overcome challenges and provide guidance for future research development.</p>
<p>What Are the Open Research Issues and Potential Areas for Further Research or Improvements?</p>
<p>The purpose of this question is to identify research gaps in this area of study. Find research gaps and challenges and provide information on such gaps for future researchers to identify and address.</p>
<p>Conducting the Research</p>
<p>For conducting the research, preliminary articles were gathered by searching on multiple scientific publishing research databases and well renowned university publishing. The data were gathered from ScienceDirect, Springer, IEEE Xplore, AAAI Press, arXiv, Sage Journals, and university databases such as Stanford, Vermont and MIT. Some of these publishing sources were not peer reviewed; however, a significant effort was made to ensure that the sources collected were peer reviewed. The articles were collected by performing searches using keywords and phrases such as "transfer learning", "virtualto-real-world", "simulation to real-world", and "sim-to-real". These articles ranged from journals, conferences, books, and symposiums. The articles yielded through the search were downloaded into the local computer and were sorted into multiple folders based on the research database. Each download was tracked with a title and direct download link for future reference or for meta collection. These articles were collected without any time restrictions and if they were considered relevant to the study.</p>
<p>Screening for Relevant Papers</p>
<p>Before the initial sorting, papers yielded from the search results were downloaded to ensure that full text was available for sorting and screening. Also, this eliminated the need for downloading these papers later, for reviewing. Metadata information such as revision number, title of the article, authors, publisher, publishing country, publication type (book, journal, symposium, workshop, conference), published date, doi, year of publication and direct access links were stored in an excel sheet for easy management. Each paper was given an index for quick reference.</p>
<p>Papers retrieved through the search protocol were screened based on the following criteria:</p>
<p>1.</p>
<p>Relevance of the title.</p>
<p>2.</p>
<p>Keyword section contains transfer learning.</p>
<p>3.</p>
<p>Relevance of transfer learning in the context of machine/deep learning.</p>
<p>During the initial screening process, the above search criteria were used to exclude articles that were not relevant to the research topic. The Article's keyword section was used to further determine the relevance of the paper, as in most cases the title did not reflect any relevance. Later, papers that were not relevant to the research area, papers without full text availability, duplicate papers, or revisions of the same paper, were discarded. In the case where the relevance of the paper could not be determined they were passed to the next stage for further reading. Papers that were reviewed and selected in this order were considered as papers on applications of transfer learning.</p>
<p>Keywording on Abstracts</p>
<p>For categorizing papers, the method described in [17] was followed which is shown in Figure 3. It is a process of classifying articles based on keywording which ensures that existing studies are taken into account. The aim of this process was to categorize papers into multiple categories based on keywords found in the articles' abstract section. Based on the keywords found, articles were categorized into multiple categories and those articles were read in detail to make sure that the content was relevant to each identified category. If the content was not relevant, categories were updated. The final result of this process was that all articles collected were mapped into multiple categories. Books on the other hand were reviewed by looking at the content and if any relevant section was found, it was skimmed, and related selections of pages were noted down for further review. Papers retrieved through the search protocol were screened based on the following criteria:</p>
<ol>
<li>Relevance of the title. 2. Keyword section contains transfer learning. 3. Relevance of transfer learning in the context of machine/deep learning.</li>
</ol>
<p>During the initial screening process, the above search criteria were used to exclude articles that were not relevant to the research topic. The Article's keyword section was used to further determine the relevance of the paper, as in most cases the title did not reflect any relevance. Later, papers that were not relevant to the research area, papers without full text availability, duplicate papers, or revisions of the same paper, were discarded. In the case where the relevance of the paper could not be determined they were passed to the next stage for further reading. Papers that were reviewed and selected in this order were considered as papers on applications of transfer learning.</p>
<p>Keywording on Abstracts</p>
<p>For categorizing papers, the method described in [17] was followed which is shown in Figure 3. It is a process of classifying articles based on keywording which ensures that existing studies are taken into account. The aim of this process was to categorize papers into multiple categories based on keywords found in the articles' abstract section. Based on the keywords found, articles were categorized into multiple categories and those articles were read in detail to make sure that the content was relevant to each identified category. If the content was not relevant, categories were updated. The final result of this process was that all articles collected were mapped into multiple categories. Books on the other hand were reviewed by looking at the content and if any relevant section was found, it was skimmed, and related selections of pages were noted down for further review. </p>
<p>Meta Extraction and Mapping</p>
<p>For the final stage of the systematic mapping process, metadata collected during the screening process were filtered down to the following meta items listed in Table 2. Summary fields were added after the papers were read in full detail. The published country was not considered, as it was difficult to identify when there were multiple co-authors from multiple countries, and it did not yield interesting results to add to this paper. Additionally, each paper was assigned with an index for future reference. The Results section discusses the extracted data in more detail.  </p>
<p>Meta Extraction and Mapping</p>
<p>For the final stage of the systematic mapping process, metadata collected during the screening process were filtered down to the following meta items listed in Table 2. Summary fields were added after the papers were read in full detail. The published country was not considered, as it was difficult to identify when there were multiple co-authors from multiple countries, and it did not yield interesting results to add to this paper. Additionally, each paper was assigned with an index for future reference. The Results section discusses the extracted data in more detail. </p>
<p>Results</p>
<p>Through the systematic review and following the research protocol, it was possible to gather a total of 150 papers from scientific and academic databases. These papers were evaluated by following the systematic review. After the initial review of the selection by title, keywords, and duplicate results, 50 papers were discarded, of which 42 papers were not within the research area and the rest were duplicates and irrelevant papers. After reading the abstract of the papers, the selection was further narrowed down to 75 papers. After reading those papers fully, 68 papers were selected for the study. Final selected papers provide novel applications and experimental methods about transfer learning. Table 3 lists all the selected papers, sorted based on the year starting from 2006 to the current research year 2021. The table also shows referenced authors, publication types and the application area of the research paper based on the context. There was no time limitation for the selection of research papers; however, it was important to find the latest research conducted on the applications and state of the art of transfer learning. The gathered research papers ranged from 2006 to mid-March 2021. According to Figure 4, the majority of the papers were published from 2016 till 2021, which means that there was a huge surge in using transfer learning during this period.</p>
<p>List of Selected Papers</p>
<p>7</p>
<p>Contributions Contribution of the paper 8 Summary Summary or the abstract of the paper</p>
<p>Results</p>
<p>Through the systematic review and following the research protocol, it was possible to gather a total of 150 papers from scientific and academic databases. These papers were evaluated by following the systematic review. After the initial review of the selection by title, keywords, and duplicate results, 50 papers were discarded, of which 42 papers were not within the research area and the rest were duplicates and irrelevant papers. After reading the abstract of the papers, the selection was further narrowed down to 75 papers. After reading those papers fully, 68 papers were selected for the study. Final selected papers provide novel applications and experimental methods about transfer learning. Table 3 lists all the selected papers, sorted based on the year starting from 2006 to the current research year 2021. The table also shows referenced authors, publication types and the application area of the research paper based on the context. </p>
<p>List of Selected Papers</p>
<p>Basic Information about the Papers</p>
<p>Publication Year</p>
<p>There was no time limitation for the selection of research papers; however, it was important to find the latest research conducted on the applications and state of the art of transfer learning. The gathered research papers ranged from 2006 to mid-March 2021. According to Figure 4, the majority of the papers were published from 2016 till 2021, which means that there was a huge surge in using transfer learning during this period. </p>
<p>Publication Type and Channel</p>
<p>The publication type can be defined as the medium in which the paper is published such as journal, conference, book, symposium or any other type. The publication channel can be defined as a journal or publisher that is peer-reviewed and approved in the academic publication system. According to Figure 5, the distribution of papers based on the Electronics 2021, 10, 1491 9 of 18 publication type shows that 64% (43 papers) of the selection are journals. Papers published through conferences and symposiums yield 30% (21 papers) and 4% (3 papers) respectively. In addition, only one book chapter was selected after sorting. Table 4 shows the publication channels in which the selected papers have been published. According to this table, many research papers were published on ArXiv, which is an open-access repository to publish scholarly articles. </p>
<p>Publication Type and Channel</p>
<p>The publication type can be defined as the medium in which the paper is published such as journal, conference, book, symposium or any other type. The publication channel can be defined as a journal or publisher that is peer-reviewed and approved in the academic publication system. According to Figure 5, the distribution of papers based on the publication type shows that 64% (43 papers) of the selection are journals. Papers published through conferences and symposiums yield 30% (21 papers) and 4% (3 papers) respectively. In addition, only one book chapter was selected after sorting. Table 4 shows the publication channels in which the selected papers have been published. According to this table, many research papers were published on ArXiv, which is an open-access repository to publish scholarly articles.    Journal of Big Data volume [9] Conference on Intelligent Autonomous Systems [18] Ninth International Conference on Autonomous Agents and Multiagent Systems-Adaptive Learning Agents Workshop [19] The 2013 International Joint Conference on Neural Networks (IJCNN) [20] IEEE International Conference on Robotics and Automation (ICRA) [21][22][23]26,27,30,32,53] IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) [24,34,63] Robotics: Science and Systems [25] International Conference on Advanced Robotics and Intelligent Systems (ARIS) [28] American Control Conference (ACC) [29] NIPS Workshop on Acting and Interacting in the Real World: Challenges in Robot Learning [31] International Journal of Advanced Robotic Systems [36] IEEE Access [37,40] </p>
<p>Publication Channel Papers</p>
<p>Logistics Research [38] Science Robotics [39] International Symposium on Experimental Robotics (ISER) [41] IEEE/CVF International Conferene on Computer Vision (ICCV) [43] IEEE Transactions on Vehicular Technology [44] IEEE Robotics and Automation Letters [45] IEEE Intelligent Vehicles Symposium [46] International Conference on Informatics in Control, Automation and Robotics [47] European Conference on Machine Learning [48] International Joint Conference on Artificial Intelligence [49] International Conference on Unsupervised and Transfer Learning workshop [50] International Conference on Neural Information Processing Systems [51] International Conference on Learning Representations (ICLR) Conference [52,54,55] International Conference on Machine Learning [56,57] Journal of Machine Learning Research [58,72] Springer [59] Nature [60] Stanford University AI Lab [62] ACM Transactions on Intelligent Systems and Technology [66] IEEE Transactions on Pattern Analysis and Machine Intelligence [67] AAAI Publications, 2016 AAAI Spring Symposium Series [70] IEEE International Conference on Data Mining Workshops (ICDMW) [71] Robotics and Autonomous Systems [73] Artificial Intelligence [74] Sensors [78] Synthesis lectures on Artificial Intelligence and Machine Learning [79] </p>
<p>Classification of Selected Papers</p>
<p>This section will focus on the results of the paper classification based on Table 2, and the metadata criteria seven and eight. All the gathered papers were read in full, and the author and summary of the paper were collected. The summary was used to identify the type of the paper as a review or technical paper, and to further categorize them based on the application and context. Table 3 shows that the information was sorted based on the context and application. These papers were further classified into publication types. Reviews are papers that were written by experts in the field. These papers include well known research and technical developments conducted for the specific research area. These papers can be considered as secondary publications and can be used to identify state-of-the-art research areas and get an informed idea about future developments. These secondary papers can be used to understand the research area in a broad view and use it as a guide to find open research areas and find relevant research papers. Technical papers are papers that provide technical information about a specific area of research. In this case, these papers provide research conducted on transfer learning in highly technical detail. It could be new learning and training methods, architectures, new frameworks, data collection methods, retaining methods, and improvements to learning accuracy. Furthermore, these papers allow the identification of pitfalls during transfer learning and provide technical detail on how to overcome them. The papers also introduce state-of-the-art implementation and applications of transfer learning from simulation to the real world. Papers that are classified as simulation to physical robot, simulation to vehicle, and knowledge transfer are considered as technical papers. These identified papers discuss how transfer learning was used to transfer a model's knowledge learned in a simulation to a physical robot or vehicle, and propose and discuss new techniques and frameworks to optimize the learning process. Figure 6 shows the distribution of papers according to the classifications. could be new learning and training methods, architectures, new frameworks, data collection methods, retaining methods, and improvements to learning accuracy. Furthermore, these papers allow the identification of pitfalls during transfer learning and provide technical detail on how to overcome them. The papers also introduce state-of-the-art implementation and applications of transfer learning from simulation to the real world. Papers that are classified as simulation to physical robot, simulation to vehicle, and knowledge transfer are considered as technical papers. These identified papers discuss how transfer learning was used to transfer a model's knowledge learned in a simulation to a physical robot or vehicle, and propose and discuss new techniques and frameworks to optimize the learning process. Figure 6 shows the distribution of papers according to the classifications. Out of the 68 selected papers, 15 (22%) papers were categorized as reviews and the remaining 53 (78%) were identified as technical papers. Technical papers often address multiple use cases/applications of transfer learning. Papers classified as 'Knowledge Transfer' are papers that discuss different transfer learning techniques, solutions to overcome overheads during transfer learning, and proposed novel solutions to overcome these problems. These papers propose new frameworks, algorithms and data collection methods that allow the optimization of the performance of the transferred model. Twenty-one papers were identified for this category.</p>
<p>Papers that were classified as 'Simulation to Robot' or 'Simulation to Vehicle' are papers of research conducted on transferring a model trained on a simulation and transferring it to a physical robot or vehicle, respectively. There are few papers that suggest novel solutions to improve the performance of this application; discuss how training data are gathered; how simulation environments are setup; and how training data are generated for optimum learning. There are 23 (34%) papers related to research conducted on transfer learning methods, algorithms and techniques used to transfer learning. Classifications on simulation to physical robot and simulation to vehicle yield 24 (35%) and 6 (8.8%) papers, respectively. These papers include the application of transfer learning where authors of the paper conducted transfer learning.</p>
<p>Discussion</p>
<p>In this section, research questions defined in the research methodology will be discussed and answered by referring to selected research papers. This section will also identify the limitations and shortcomings of transfer learning in the context of virtual-to-real transfer learning. In addition, it will also enable researchers to find potential open research Out of the 68 selected papers, 15 (22%) papers were categorized as reviews and the remaining 53 (78%) were identified as technical papers. Technical papers often address multiple use cases/applications of transfer learning. Papers classified as 'Knowledge Transfer' are papers that discuss different transfer learning techniques, solutions to overcome overheads during transfer learning, and proposed novel solutions to overcome these problems. These papers propose new frameworks, algorithms and data collection methods that allow the optimization of the performance of the transferred model. Twenty-one papers were identified for this category.</p>
<p>Papers that were classified as 'Simulation to Robot' or 'Simulation to Vehicle' are papers of research conducted on transferring a model trained on a simulation and transferring it to a physical robot or vehicle, respectively. There are few papers that suggest novel solutions to improve the performance of this application; discuss how training data are gathered; how simulation environments are setup; and how training data are generated for optimum learning. There are 23 (34%) papers related to research conducted on transfer learning methods, algorithms and techniques used to transfer learning. Classifications on simulation to physical robot and simulation to vehicle yield 24 (35%) and 6 (8.8%) papers, respectively. These papers include the application of transfer learning where authors of the paper conducted transfer learning.</p>
<p>Discussion</p>
<p>In this section, research questions defined in the research methodology will be discussed and answered by referring to selected research papers. This section will also identify the limitations and shortcomings of transfer learning in the context of virtual-to-real transfer learning. In addition, it will also enable researchers to find potential open research areas, solutions for existing limitations, and opportunities for further improvement in the field of transfer learning.</p>
<p>What Are the Benefits of Using Transfer Learning?</p>
<p>After the systematic review and the mapping study, different applications and use cases of transfer learning were identified. Taylor et al. [72] on their review on transfer learning suggest several metrics to measure the benefits of transfer learning. The first metric that they proposed is Jumpstart, in which the performance of the learning model can be increased by transferring knowledge from an existing source task. Next, the Asymptotic Performer metric, states that the final learned performance of a given model can be improved by using transfer learning. The Total Reward metric states that if an agent uses transfer learning, the reward accumulated by the agent is improved when compared with that of an agent without transfer learning. Transfer ratio metric measures the ratio between the total reward gained by the transfer learner and a non-transfer learner. And the final metric they proposed was time to threshold, which measures the training time that a learning model needs to reach its expected level of performance, which can be reduced through knowledge transfer.</p>
<p>The main goal of using transfer learning is to enable an agent to learn when sufficient training data from the target domain is not available. Barret et al. [19] demonstrated that transfer learning for reinforcement learning on a physical robot can speed up the learning though the simulator even if it does not capture the full dynamics of the robot. According to Wang et al. [51], transfer learning is important when a statistical model that was trained using the source domain does not directly associate with the target domain. Use of transfer learning minimizes the need for labeling data in the target domain.</p>
<p>In reinforcement learning, to solve complex problems, the learning algorithms often need to train the algorithm for a long period of time (high complexity, CPU and GPU intensive). This time cost is currently being reduced using transfer learning. However, this method does not work with multiagent reinforcement domains (it only works with single-agent domains). Boutsioukis et al. [59] in their paper, proposed a novel approach to use transfer learning with reinforcement learning in multiagent domains. Additionally, transfer learning also allows the creation of portable models. Reinforcement learning with rewards can increase the performance of the learning algorithm and further accelerate the learning. Konidaris et al. [56] in their paper, proposed a novel method for training which allows a model to reach an optimal performance even after a brief training session.</p>
<p>One of the major fallbacks of deep learning is that training data collected in one timeframe will not have the same distribution as on another. In this case, transfer learning can be used to adapt localization models trained on one timeframe with another [6]. Andrew et al. in their paper [57], proposed a novel framework called "self-taught learning" for using unlabeled data in transfer learning tasks. Since preparing unlabeled data is much easier and cost effective, the proposed framework utilizes a sparse coding method to reconstruct higher-level features. Wolf et al. [64], proposed TransferTransfo, a transfer learning approach for Neural Network based conversational agents. According to this research, transfer learning has shown significant improvements in discriminative language understanding tasks when compared to other traditional learning methods.</p>
<p>What</p>
<p>Are the Use Cases of Transfer Learning in the Virtual to Real-World Context?</p>
<p>As mentioned above, there are many use cases of transfer learning in contrast to traditional machine learning methods. In traditional methods, the learning is limited to a specific domain, whereas in transfer-learning datasets, models can be trained virtually and transferred into a physical robot. Generally, this field is still in its infancy, but more and more research is conducted in the field. The papers that were reviewed for this review included research methodologies, novel algorithms, frameworks and multiple real-world applications and proof of concepts.</p>
<p>One of the major motivations for using transfer learning is its ability to solve problems when there are insufficient training data. For traditional machine learning, quality training data are the foundation for creating robust machine learning applications. According to Tan et al. [36] on their research on a brain-computer interface for rehabilitation robots, one of the major issues they faced was insufficient training data in bioinformatics. Training using real robots is unrealistic, dangerous and the behavior is always random. Even if such training was completed, the trained model is domain specific. Traditional methods use learned policies; however, such policies learned through simulations will fail in real-world conditions. Therefore, transfer learning is a solution and a technique to create advanced learning-based models that are not domain specific and are capable of learning through experience in the real world. A domain randomization strategy allows us to randomize the environment and dynamics to create advanced simulated environments [47].</p>
<p>For the virtual-to-robotics use case, the primary example is creating an evolutionary robotic platform that can learn and adapt from its environment as proposed and developed by Lipton et al. [18]. The other example is [19] a robot adapting its behavior to environmental changes. Current robotic platforms are designed for ideal service environments such as industrial factories. However, in order to advance robots to their next level, they should be able to act autonomously in more complex and unpredictable environments. Robots should be able to sense when their environment changes, anticipate failures and damage to hardware and create contingency plans without relying on preprogramming. Cully et al. [60] in their paper, proposed a novel algorithm called Intelligent Trial and Error to create a behavior-performance map to allow robots to rapidly adapt to their complex environments and recover from damages/injuries similarly to an animal.</p>
<p>The second use case is creating and training models using virtual environments and transferring it into a real-world system. The benefit of using transfer learning in this situation is that it allows the reuse of a pretrained model, and allows the discovery and extraction of features. In this context, obtaining training data for training drones and robotics platforms are difficult and expensive. In traditional machine learning, necessary features are often hand-crafted by the researchers, but using a representational learning algorithm, features can be discovered in a short period of time. Additionally, it allows a reduction in the size of the datasets which in turn reduces the computational requirements. Examples are Autonomous MAV flight [41], motion planning [29], domain adaptation for improved robot grasping [30,31,35,45], multirobot transfer learning [24,32,53,65,66], mobile fulfilment systems [38] and autonomous driving [42][43][44][45][46][47]. The above mentioned papers use virtual training environments to generate synthetic training data to train a model in the virtual environment and use transfer learning techniques to transfer the knowledge to real-world platforms. These examples use domain adaptation, a method that allows a reduction of the domain bias, which allows the real-world application to adapt to changes in the environment, such as weather and lighting conditions which can drastically change the domain [41].</p>
<p>The interesting factor is that most of the papers that conducted virtual to real-world research used industrial robot arms, specifically pick and place robots, for their development. Simulated training was performed on a MuJoCo Physics engine [32] because of the high demand and precision required in manufacturing. Deploying these robots is an ideal platform to decrease manufacturing costs.</p>
<p>What Are the Challenges and Limitations of Using Transfer Learning in This Context?</p>
<p>Since transfer learning is still in a research state, there are many challenges and limitations that the researchers have faced. Some of the identified challenges and limitations are simulating the real world, performing one-shot transfer learning, unknown target environments, negative transfer and identifying the transferability between the source domain and the target domain. One of the major challenges in current transfer learning research is to determine how much information is required by the learner about the source and target domain relationship [72]. It is critical for a learner to understand the relationship between source and target domains to allow an agent to use past knowledge to be used in the target domain. Current transfer learning uses humans in the loop to direct the learner; however, in an autonomous context, the learner must understand the domain relationships.</p>
<p>Creating a simulator that can simulate the real world with high fidelity to perform one-shot transfer learning is difficult. Current transfer learning requires pre-processing or pre-calibration on the target domain. This is due to Quasi-static kinematics, and the physical forces cannot accurately be simulated [18]. Rusu et al. [76], (Figure 4) in their research, provide detailed information of robot manipulations and the physical world results. Real-world dynamics of the machinery is chaotic and sensitive to environmental variables. Tobin et al., [23] in their research, found that by performing a randomized change on the target tasks, such as tightening the joints on the robot, drastically reduced the performance compared to their simulated results. Additionally, if the target environment is unknown, then creating an accurate virtual environment is difficult, even if the target domain is known. This is because the simulator cannot match all the target attributes.</p>
<p>The purpose of transfer learning in this context is to improve the target learner using simulated learning. However, most of the proposed learning algorithms assume that the source domain and target domain are the same. In a case where the source domain (Ds) and target domain (Dt) are different, even brute-force transfer maybe unsuccessful. In this situation, the target learner is negatively impacted by the imbalanced domain relationship [6,9,31], which is known as negative transfer.</p>
<p>How Are These Challenges and Limitations Currently Addressed?</p>
<p>The studied papers proposed methods, algorithms, simulations, learning and training techniques that can be used to overcome the above-mentioned challenges and limitations in transfer learning. One of the proposed solutions to handle the uncertainties during transfer learning is to create a crude simulator that can capture the salient features of the search space and introduce noise. Domain randomization is a technique that is widely used in transfer learning to provide simulated variability during the training; therefore, during testing the model can generalize the real world [35,63]. Another proposed method is to create a coevolving simulator that becomes increasingly predictive. This method uses evolutionally techniques to design a simulator that can capture important properties of the target environment [18].</p>
<p>Mihalkova et al., in their paper [49], proposes a novel algorithm by studying the gap that exists when there exists a minimum number of target data and where in an extreme case, single-entry information is known. The proposed algorithm is SR2RL and can find effective mapping of knowledge from a source model to the target domain when the target data are extremely limited. To bridge the reality gap, GPU based high-fidelity simulators, such as NVIDIA Flex [43], MuJoCo physics simulator [23], Alphabet Soup and RAWSim-O (used for simulating Mobile Fulfilment Systems (RMFS)) [38] are being developed. Additionally, sensors such as LiDAR are being developed to be used in software-based simulators as well as in the real world to limit the reality difference.</p>
<p>Currently, to adapt a base learner to a new domain when few labeled datasets (fewshot learning) are available is handled using shallow neural networks. However, this method does not yield higher effectiveness and performance. Sun et al. [67] proposed, meta-transfer learning (MTL) which enables transfer of the weights of a deep neural network to handle few-shot learning. Additionally, they also introduced a hard task (HT) meta-batch technique to further improve the efficiency of MTL. Another novel method is to perform multiagent reinforcement transfer learning. Transfer learning methods are primarily applied to single-agent reinforcement learning but have not been performed on multiagent reinforcement learning. Boutsioukis et al. [59] suggest a novel method called BIas TransfER (BITER) to perform multiagent reinforcement learning. When sufficient training data and computation power is not available, Shafahi et al. proposed robust transfer learning, in which it transfers not only performance but also the robustness from the source domain to the target domain [55].</p>
<p>A negative transfer occurs when the information learned from the source domain has a negative effect on the target learning model [9]. For effective transfer learning, there needs to be relevance between the source domain and the target domain. The performance of the target domain significantly improves if both the source and target are relevant. The paper suggests a weighted multimodal knowledge transfer method to weight each source and target domain to determine the relevance of each source domain. The most related source domain will be assigned with the maximum weight. The applied weights on the source domains will lessen the adverse effects of the negative transfer. If the source and target are not related or do not have a close relationship, this can lead to a decrease in performance leading to a negative transfer [53]. From the many papers that have been selected, only two papers provide suggestions and techniques [9,53] to overcome negative transfer.</p>
<p>What Are the Open Research Issues and Potential Areas for Further Research or Improvements?</p>
<p>Since transfer leaning is still an emerging research area, there are still areas to be improved, techniques to be discovered, and proof of concepts to be made to avoid some of the major downfalls of this technique. Literature reviews suggests that fine-tuning compatibility of the source domain and target domain is a necessary factor for some applications of transfer learning. Powerful GPU's and CPUs allowed the researchers to gather high quality simulated datasets and perform real-world simulation, but for consumer applications this high computational demand can be a constraint. Training needs to be fine-tuned to make the model's virtual learning policies robust in the physical world to achieve higher success in transferring [26].</p>
<p>One of the primary areas that needs to be improved is minimizing the reality gap between the virtual and real world. The accuracy of the transfer depends on how close the simulation is to the real-world dynamics. Due to dynamic and static friction, acceleration and collision between actuators can cause nonlinearities. New fine-tuning methods need to be researched to improve the learning policies and minimize the difference between the real world and the simulation.</p>
<p>Finally, one of the major issues that was mentioned in the selected papers was negative transfer. The primary goal of using transfer learning is to improve the learning of the target model using training data from a related source (simulator). As mentioned, negative transfer occurs when the source domain is not related to the target domain. Therefore, the target learner is impacted by the weak relationship. This is called negative transfer, where the target learner's performance does not improve. This is a major open area that needs to be further explored.</p>
<p>Conclusions</p>
<p>The goal of this systematic review was to identify the state of transfer learning in a simulation to real-world context. Through the systematic mapping process [17], 68 papers were identified for the review. The goal during the paper selection was to focus on simto-real and to discuss the improvements through time. For the review, we focused on the state of the art, applications, research state and open research areas to be investigated. Five research questions were created to further identify the objectives of the state of transfer learning in a simulation to real-world context. The first task was to systematically identify the limitations and challenges of researching transfer learning to better identify the gaps and state. According to the systematic review, transfer learning is still in a research state as there were only a few papers of real-world applications and prototypes.</p>
<p>Multiple research gaps were identified during the systematic review. Some of them are negative transfer and closing the reality gap between the simulation and the physical world.</p>
<p>Further research is required to address these gaps, challenges and to improve the overall accuracy of transfer. Improving transfer learning and bridging the gap between the virtual and the real can benefit many applications in domains such as industrial, autonomous vehicles and robotics.</p>
<p>Figure 1 .
1Learning process of traditional vs. transfer learning method.</p>
<p>Figure 1 .
1Learning process of traditional vs. transfer learning method.</p>
<p>Figure 2 .
2Systematic mapping methodology.</p>
<p>Figure 2 .
2Systematic mapping methodology.</p>
<p>Figure 3 .
3Paper classification scheme.</p>
<p>Figure 3 .
3Paper classification scheme.</p>
<p>Figure 4 .
4Distribution of papers by publication year.</p>
<p>Figure 4 .
4Distribution of papers by publication year.</p>
<p>Figure 5 .
5Distribution of papers based on publication type.</p>
<p>Figure 5 .
5Distribution of papers based on publication type.</p>
<p>Figure 6 .
6Distribution of selected papers according to application.</p>
<p>Figure 6 .
6Distribution of selected papers according to application.</p>
<p>Table 1 .
1Relationship between Transfer learning and traditional machine learning.Learning Settings 
Source and Target 
Domain 
Source and Target Task </p>
<p>Traditional Machine Learning 
are the same 
are the same </p>
<p>Transfer Learning </p>
<p>Inductive 
are the same 
are different but related 
Unsupervised are different but related 
are different but related 
Transductive are different but related 
are the same </p>
<p>Table 1 .
1Relationship between Transfer learning and traditional machine learning.Learning Settings 
Source and Target Domain 
Source and Target Task </p>
<p>Traditional Machine Learning 
are the same 
are the same </p>
<p>Transfer Learning </p>
<p>Inductive 
are the same 
are different but related </p>
<p>Unsupervised 
are different but related 
are different but related </p>
<p>Transductive 
are different but related 
are the same </p>
<p>Table 2 .
2Extracted metadata from the mapping process.# 
Meta Field 
Description 
1 
Article Title 
Title of the article 
2 
Published Year 
Year in which the article was published 
3 
Authors 
Authors of the article 
4 
Publication Channel 
Channel used to publish the paper </p>
<p>5 
Publication Type 
Publication Type used, (Journal, Conference, Workshop, 
etc.) </p>
<p>Table 2 .
2Extracted metadata from the mapping process.# 
Meta Field 
Description </p>
<p>1 
Article Title 
Title of the article 
2 
Published Year 
Year in which the article was published 
3 
Authors 
Authors of the article 
4 
Publication Channel 
Channel used to publish the paper 
5 
Publication Type 
Publication Type used, (Journal, Conference, Workshop, etc.) 
6 
Paper Type 
Type based on the classification 
7 
Contributions 
Contribution of the paper 
8 
Summary 
Summary or the abstract of the paper </p>
<p>Table 3 .
3List of papers selected after the mapping process.Application. 
Paper Type </p>
<p>Conference 
Journal 
Symposium Book Chapter </p>
<p>Simulation to Physical robot 
[18-29] 
[30-40] 
[41] 
-</p>
<h2>Simulation to Vehicle</h2>
<h2>[42-47]</h2>
<p>-</p>
<p>Knowledge Transfer 
[48-55] 
[56-69] 
[70] 
-</p>
<p>Review 
[71] 
[1,2,6,8,9,72-78] 
[3] 
[79] </p>
<p>4.2. Basic Information about the Papers 
4.2.1. Publication Year </p>
<p>Table 3 .
3List of papers selected after the mapping process.Application. 
Paper Type 
Conference 
Journal 
Symposium Book Chapter 
Simulation to 
Physical robot 
[18-29] 
[30-40] 
[41] 
-</p>
<p>Simulation to 
Vehicle 
-
[42-47] 
-
-</p>
<p>Knowledge 
Transfer 
[48-55] 
[56-69] 
[70] 
-</p>
<p>Review 
[71] 
[1,2,6,8,9,72-78] 
[3] 
[79] </p>
<p>Table 4 .
4Distribution of papers based on publication channels.Publication Channel 
Papers </p>
<p>ArXiv 
[1,8,33,35,42,61,64,65,68,69, 
75-77] 
IEEE Signal Processing Magazine 
[2] 
IEEE Symposium Series on Computational Intelligence 
(SSCI) 
[3] </p>
<p>IEEE Transactions on Knowledge and Data Engineering 
[6] 
Journal of Big Data volume 
[9] 
Conference on Intelligent Autonomous Systems 
[18] 
Ninth International Conference on Autonomous Agents and 
Multiagent Systems-Adaptive Learning Agents Workshop 
[19] </p>
<p>The 2013 International Joint Conference on Neural Networks 
(IJCNN) 
[20] </p>
<p>IEEE International Conference on Robotics and Automation 
(ICRA) 
[21-23,26,27,30,32,53] </p>
<p>IEEE/RSJ International Conference on Intelligent Robots and 
Systems (IROS) 
[24,34,63] </p>
<p>Robotics: Science and Systems 
[25] 
International Conference on Advanced Robotics and 
Intelligent Systems (ARIS) 
[28] </p>
<p>American Control Conference (ACC) 
[29] 
NIPS Workshop on Acting and Interacting in the Real 
World: Challenges in Robot Learning 
[31] </p>
<p>Table 4 .
4Distribution of papers based on publication channels.Publication Channel 
Papers </p>
<p>ArXiv 
[1,8,33,35,42,61,64,65,68,69,75-77] </p>
<p>IEEE Signal Processing Magazine 
[2] </p>
<p>IEEE Symposium Series on Computational Intelligence 
(SSCI) 
[3] </p>
<p>IEEE Transactions on Knowledge and Data Engineering 
[6] </p>
<p>Table 4 .
4Cont.
Conflicts of Interest:The authors declare no conflict of interest.
. J Wang, E Sezener, D Budden, M Hutter, J Veness, arXiv:2010.12268A Combinatorial Perspective on Transfer Learning. 2020Wang, J.; Sezener, E.; Budden, D.; Hutter, M.; Veness, J. A Combinatorial Perspective on Transfer Learning. arXiv 2020, arXiv:2010.12268.</p>
<p>Deep Reinforcement Learning: A Brief Survey. K Arulkumaran, M P Deisenroth, M Brundage, A A Bharath, 10.1109/MSP.2017.2743240IEEE Signal Process. Mag. 34Arulkumaran, K.; Deisenroth, M.P.; Brundage, M.; Bharath, A.A. Deep Reinforcement Learning: A Brief Survey. IEEE Signal Process. Mag. 2017, 34, 26-38. [CrossRef]</p>
<p>Sim-to-Real Transfer in Deep Reinforcement Learning for Robotics: A Survey. W Zhao, J P Queralta, T Westerlund, Proceedings of the 2020 IEEE Symposium Series on Computational Intelligence (SSCI). the 2020 IEEE Symposium Series on Computational Intelligence (SSCI)Canberra, ACT, AustraliaZhao, W.; Queralta, J.P.; Westerlund, T. Sim-to-Real Transfer in Deep Reinforcement Learning for Robotics: A Survey. In Proceedings of the 2020 IEEE Symposium Series on Computational Intelligence (SSCI), Canberra, ACT, Australia, 1-4 December 2020.</p>
<p>A Comprehensive Hands-On Guide to Transfer Learning with Real-World Applications in Deep Learning. D Sarkar, Sarkar, D. A Comprehensive Hands-On Guide to Transfer Learning with Real-World Applications in Deep Learning. Available online: https://towardsdatascience.com/a-comprehensive-hands-on-guide-to-transfer-learning-with-real-world-applications- in-deep-learning-212bf3b2f27a (accessed on 9 May 2021).</p>
<p>NIPS<em>95 Post-Conference Workshop. Post-NIPS</em>95 Workshop on Transfer in Inductive Systems. NIPS<em>95 Post-Conference Workshop. Post-NIPS</em>95 Workshop on Transfer in Inductive Systems. Available online: https: //plato.acadiau.ca/courses/comp/dsilver/NIPS95_LTL/transfer.workshop.1995.html (accessed on 9 May 2021).</p>
<p>A Survey on Transfer Learning. S J Pan, Q Yang, 10.1109/TKDE.2009.191IEEE Trans. Knowl. Data Eng. 22Pan, S.J.; Yang, Q. A Survey on Transfer Learning. IEEE Trans. Knowl. Data Eng. 2010, 22, 1345-1359. [CrossRef]</p>
<p>Transfer Learning for Object Detection Using State-of-the-Art Deep Neural Networks. J Talukdar, S Gupta, P S Rajpura, R S Hegde, Proceedings of the 2018 5th International Conference on Signal Processing and Integrated Networks (SPIN). the 2018 5th International Conference on Signal Processing and Integrated Networks (SPIN)Noida, IndiaTalukdar, J.; Gupta, S.; Rajpura, P.S.; Hegde, R.S. Transfer Learning for Object Detection Using State-of-the-Art Deep Neural Networks. In Proceedings of the 2018 5th International Conference on Signal Processing and Integrated Networks (SPIN), Noida, India, 22-23 February 2018.</p>
<p>Z Zhu, K Lin, J Zhou, arXiv:2009.07888Transfer Learning in Deep Reinforcement Learning: A Survey. arXiv 2021. Zhu, Z.; Lin, K.; Zhou, J. Transfer Learning in Deep Reinforcement Learning: A Survey. arXiv 2021, arXiv:2009.07888.</p>
<p>. K Weiss, T M Khoshgoftaar, D Wang, 10.1186/s40537-016-0043-6A Survey of Transfer Learning. J. Big Data. 39Weiss, K.; Khoshgoftaar, T.M.; Wang, D. A Survey of Transfer Learning. J. Big Data 2016, 3, 9. [CrossRef]</p>
<p>Personalized Models for Facial Emotion Recognition through Transfer Learning. M Rescigno, M Spezialetti, S Rossi, 10.1007/s11042-020-09405-4Multimed. Tools Appl. 79Rescigno, M.; Spezialetti, M.; Rossi, S. Personalized Models for Facial Emotion Recognition through Transfer Learning. Multimed. Tools Appl. 2020, 79, 35811-35828. [CrossRef]</p>
<p>Knowledge Distillation: A Survey. J Gou, B Yu, S J Maybank, D Tao, 10.1007/s11263-021-01453-zInt. J. Comput. Vis. 129Gou, J.; Yu, B.; Maybank, S.J.; Tao, D. Knowledge Distillation: A Survey. Int. J. Comput. Vis. 2021, 129, 1789-1819. [CrossRef]</p>
<p>S Reddy, A D Dragan, S Levine, Sqil, arXiv:1905.11108Imitation Learning via Reinforcement Learning with Sparse Rewards. arXiv 2019. Reddy, S.; Dragan, A.D.; Levine, S. SQIL: Imitation Learning via Reinforcement Learning with Sparse Rewards. arXiv 2019, arXiv:1905.11108.</p>
<p>Zero-Shot Transfer Learning of a Throwing Task via Domain Randomization. S Park, J Kim, H J Kim, Proceedings of the 2020 20th International Conference on Control, Automation and Systems (ICCAS). the 2020 20th International Conference on Control, Automation and Systems (ICCAS)Busan, KoreaPark, S.; Kim, J.; Kim, H.J. Zero-Shot Transfer Learning of a Throwing Task via Domain Randomization. In Proceedings of the 2020 20th International Conference on Control, Automation and Systems (ICCAS), Busan, Korea, 13-16 October 2020.</p>
<p>Fast Adaptation with Meta-Reinforcement Learning for Trust Modelling in Human-Robot Interaction. Y Gao, E Sibirtseva, G Castellano, D Kragic, Proceedings of the 2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). the 2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)Macau, ChinaGao, Y.; Sibirtseva, E.; Castellano, G.; Kragic, D. Fast Adaptation with Meta-Reinforcement Learning for Trust Modelling in Human-Robot Interaction. In Proceedings of the 2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Macau, China, 3-8 November 2019.</p>
<p>Deep Visual Domain Adaptation: A Survey. M Wang, W Deng, 10.1016/j.neucom.2018.05.083Neurocomputing. 312Wang, M.; Deng, W. Deep Visual Domain Adaptation: A Survey. Neurocomputing 2018, 312, 135-153. [CrossRef]</p>
<p>Preferred Reporting Items for Systematic Reviews and Meta-Analyses: The PRISMA Statement. D Moher, A Liberati, J Tetzlaff, D G Altman, T P Group, 10.1371/journal.pmed.1000097PLoS Med. Moher, D.; Liberati, A.; Tetzlaff, J.; Altman, D.G.; Group, T.P. Preferred Reporting Items for Systematic Reviews and Meta-Analyses: The PRISMA Statement. PLoS Med. 2009, 6, e1000097. [CrossRef]</p>
<p>Systematic Mapping Studies in Software Engineering. K Petersen, R Feldt, S Mujtaba, M Mattsson, Proceedings of the 12th international conference on Evaluation and Assessment in Software Engineering. the 12th international conference on Evaluation and Assessment in Software EngineeringBari, ItalyPetersen, K.; Feldt, R.; Mujtaba, S.; Mattsson, M. Systematic Mapping Studies in Software Engineering. In Proceedings of the 12th international conference on Evaluation and Assessment in Software Engineering, Bari, Italy, 26-27 June 2008.</p>
<p>Evolutionary Robotics for Legged Machines: From Simulation to Physical Reality. H Lipson, J Bongard, V Zykov, E Malone, Proceedings of the 9th International Conference on Intelligent Autonomous Systems. the 9th International Conference on Intelligent Autonomous SystemsTokyo, Japan, 7-9 MarchLipson, H.; Bongard, J.; Zykov, V.; Malone, E. Evolutionary Robotics for Legged Machines: From Simulation to Physical Reality. In Proceedings of the 9th International Conference on Intelligent Autonomous Systems, Tokyo, Japan, 7-9 March 2006; pp. 11-18.</p>
<p>Transfer Learning for Reinforcement Learning on a Physical Robot. S Barrett, M E Taylor, P Stone, Proceedings of the Ninth International Conference on 29 Agents and Multiagent Systems-Adaptive Learning Agents Workshop (AAMAS-ALA). the Ninth International Conference on 29 Agents and Multiagent Systems-Adaptive Learning Agents Workshop (AAMAS-ALA)Toronto, ON, CanadaBarrett, S.; Taylor, M.E.; Stone, P. Transfer Learning for Reinforcement Learning on a Physical Robot. In Proceedings of the Ninth International Conference on 29 Agents and Multiagent Systems-Adaptive Learning Agents Workshop (AAMAS-ALA), Toronto, ON, Canada, 10-14 May 2010.</p>
<p>Alignment-Based Transfer Learning for Robot Models. B Bócsi, L Csató, J Peters, Proceedings of the 2013 International Joint Conference on Neural Networks (IJCNN). the 2013 International Joint Conference on Neural Networks (IJCNN)Dallas, TX, USABócsi, B.; Csató, L.; Peters, J. Alignment-Based Transfer Learning for Robot Models. In Proceedings of the 2013 International Joint Conference on Neural Networks (IJCNN), Dallas, TX, USA, 4-9 August 2013.</p>
<p>Independent Joint Learning: A Novel Task-to-Task Transfer Learning Scheme for Robot Models. T T Um, M S Park, J.-M Park, Proceedings of the 2014 IEEE International Conference on Robotics and Automation (ICRA). the 2014 IEEE International Conference on Robotics and Automation (ICRA)Hong Kong, ChinaUm, T.T.; Park, M.S.; Park, J.-M. Independent Joint Learning: A Novel Task-to-Task Transfer Learning Scheme for Robot Models. In Proceedings of the 2014 IEEE International Conference on Robotics and Automation (ICRA), Hong Kong, China, 31 May-7 June 2014.</p>
<p>Learning Modular Neural Network Policies for Multi-Task and Multi-Robot Transfer. C Devin, A Gupta, T Darrell, P Abbeel, S Levine, Proceedings of the 2017 IEEE International Conference on Robotics and Automation (ICRA). the 2017 IEEE International Conference on Robotics and Automation (ICRA)SingaporeDevin, C.; Gupta, A.; Darrell, T.; Abbeel, P.; Levine, S. Learning Modular Neural Network Policies for Multi-Task and Multi-Robot Transfer. In Proceedings of the 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 29 May-3 June 2017.</p>
<p>Deep Reinforcement Learning for Robotic Manipulation with Asynchronous Off-Policy Updates. S Gu, E Holly, T Lillicrap, S Levine, Proceedings of the 2017 IEEE International Conference on Robotics and Automation (ICRA). the 2017 IEEE International Conference on Robotics and Automation (ICRA)SingaporeGu, S.; Holly, E.; Lillicrap, T.; Levine, S. Deep Reinforcement Learning for Robotic Manipulation with Asynchronous Off-Policy Updates. In Proceedings of the 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 29 May-3 June 2017.</p>
<p>Multi-Robot Transfer Learning: A Dynamical System Perspective. M K Helwa, A P Schoellig, Proceedings of the 2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). the 2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)Vancouver, BC, CanadaHelwa, M.K.; Schoellig, A.P. Multi-Robot Transfer Learning: A Dynamical System Perspective. In Proceedings of the 2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Vancouver, BC, Canada, 24-28 September2017.</p>
<p>F Sadeghi, S Levine, Cad2rl, arXiv:1611.04201Real Single-Image Flight without a Single Real Image. arXiv 2016. Sadeghi, F.; Levine, S. CAD2RL: Real Single-Image Flight without a Single Real Image. arXiv 2016, arXiv:1611.04201.</p>
<p>Sim-to-Real Transfer Learning Using Robustified Controllers in Robotic Tasks Involving Complex Dynamics. J Van Baar, A Sullivan, R Cordorel, D Jha, D Romeres, D Nikovski, Proceedings of the 2019 International Conference on Robotics and Automation (ICRA). the 2019 International Conference on Robotics and Automation (ICRA)Montreal, QC, Canadavan Baar, J.; Sullivan, A.; Cordorel, R.; Jha, D.; Romeres, D.; Nikovski, D. Sim-to-Real Transfer Learning Using Robustified Controllers in Robotic Tasks Involving Complex Dynamics. In Proceedings of the 2019 International Conference on Robotics and Automation (ICRA), Montreal, QC, Canada, 20-24 May 2019.</p>
<p>Closing the Sim-to-Real Loop: Adapting Simulation Randomization with Real World Experience. Y Chebotar, A Handa, V Makoviychuk, M Macklin, J Issac, N Ratliff, D Fox, Proceedings of the 2019 International Conference on Robotics and Automation (ICRA). the 2019 International Conference on Robotics and Automation (ICRA)Montreal, QC, CanadaChebotar, Y.; Handa, A.; Makoviychuk, V.; Macklin, M.; Issac, J.; Ratliff, N.; Fox, D. Closing the Sim-to-Real Loop: Adapting Simulation Randomization with Real World Experience. In Proceedings of the 2019 International Conference on Robotics and Automation (ICRA), Montreal, QC, Canada, 20-24 May 2019.</p>
<p>Object Detection Using Transfer Learning for Underwater Robot. C.-C Wang, H Samani, Proceedings of the 2020 International Conference on Advanced Robotics and Intelligent Systems (ARIS). the 2020 International Conference on Advanced Robotics and Intelligent Systems (ARIS)Taipei, TaiwanWang, C.-C.; Samani, H. Object Detection Using Transfer Learning for Underwater Robot. In Proceedings of the 2020 International Conference on Advanced Robotics and Intelligent Systems (ARIS), Taipei, Taiwan, 19-21 August 2020.</p>
<p>Optimal Control of Wheeled Mobile Robots: From Simulation to Real World. A Arab, Y Mousavi, Proceedings of the 2020 American Control Conference (ACC). the 2020 American Control Conference (ACC)Denver, CO, USAArab, A.; Mousavi, Y. Optimal Control of Wheeled Mobile Robots: From Simulation to Real World. In Proceedings of the 2020 American Control Conference (ACC), Denver, CO, USA, 1-3 July 2020.</p>
<p>Using Simulation and Domain Adaptation to Improve Efficiency of Deep Robotic Grasping. K Bousmalis, A Irpan, P Wohlhart, Y Bai, M Kelcey, M Kalakrishnan, L Downs, J Ibarz, P Pastor, K Konolige, Proceedings of the 2018 IEEE International Conference on Robotics and Automation (ICRA). the 2018 IEEE International Conference on Robotics and Automation (ICRA)Brisbane, QLD, AustraliaBousmalis, K.; Irpan, A.; Wohlhart, P.; Bai, Y.; Kelcey, M.; Kalakrishnan, M.; Downs, L.; Ibarz, J.; Pastor, P.; Konolige, K.; et al. Using Simulation and Domain Adaptation to Improve Efficiency of Deep Robotic Grasping. In Proceedings of the 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 21-25 May 2018.</p>
<p>Sim-to-Real Transfer of Accurate Grasping with Eye-In-Hand Observations and Continuous Control. M Yan, I Frosio, S Tyree, J Kautz, Proceedings of the NIPS Workshop on Acting and Interacting in the Real World: Challenges in Robot Learning. the NIPS Workshop on Acting and Interacting in the Real World: Challenges in Robot LearningLong Beach, CA, USAYan, M.; Frosio, I.; Tyree, S.; Kautz, J. Sim-to-Real Transfer of Accurate Grasping with Eye-In-Hand Observations and Continuous Control. In Proceedings of the NIPS Workshop on Acting and Interacting in the Real World: Challenges in Robot Learning, Long Beach, CA, USA, 4-9 December 2017.</p>
<p>Sim-to-Real Transfer of Robotic Control with Dynamics Randomization. X B Peng, M Andrychowicz, W Zaremba, P Abbeel, Proceedings of the 2018 IEEE International Conference on Robotics and Automation (ICRA). the 2018 IEEE International Conference on Robotics and Automation (ICRA)Brisbane, QLD, AustraliaPeng, X.B.; Andrychowicz, M.; Zaremba, W.; Abbeel, P. Sim-to-Real Transfer of Robotic Control with Dynamics Randomization. In Proceedings of the 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 21-25 May 2018.</p>
<p>A A Rusu, M Vecerik, T Rothörl, N Heess, R Pascanu, R Hadsell, arXiv:1610.04286Real Robot Learning from Pixels with Progressive Nets. arXiv 2018. Rusu, A.A.; Vecerik, M.; Rothörl, T.; Heess, N.; Pascanu, R.; Hadsell, R. Sim-to-Real Robot Learning from Pixels with Progressive Nets. arXiv 2018, arXiv:1610.04286.</p>
<p>Virtual-to-Real-World Transfer Learning for Robots on Wilderness Trails. M L Iuzzolino, M E Walker, D Szafir, Proceedings of the 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). the 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)Madrid, SpainIuzzolino, M.L.; Walker, M.E.; Szafir, D. Virtual-to-Real-World Transfer Learning for Robots on Wilderness Trails. In Proceedings of the 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Madrid, Spain, 1-5 October 2018.</p>
<p>Solving Rubik's Cube with a Robot Hand. A I Open, I Akkaya, M Andrychowicz, M Chociej, M Litwin, B Mcgrew, A Petron, A Paino, M Plappert, G Powell, arXiv:1910.07113Open, A.I.; Akkaya, I.; Andrychowicz, M.; Chociej, M.; Litwin, M.; McGrew, B.; Petron, A.; Paino, A.; Plappert, M.; Powell, G.; et al. Solving Rubik's Cube with a Robot Hand. arXiv 2019, arXiv:1910.07113.</p>
<p>Autoencoder-Based Transfer Learning in Brain-Computer Interface for Rehabilitation Robot. C Tan, F Sun, B Fang, T Kong, W Zhang, 10.1177/1729881419840860Int. J. Adv. Robot. Syst. 16Tan, C.; Sun, F.; Fang, B.; Kong, T.; Zhang, W. Autoencoder-Based Transfer Learning in Brain-Computer Interface for Rehabilitation Robot. Int. J. Adv. Robot. Syst. 2019, 16, 1729881419840860. [CrossRef]</p>
<p>Transfer of Robot Perception Module with Adversarial Learning. H Sui, W Shang, X Li, 10.1109/ACCESS.2019.2923541IEEE Access. 7Sui, H.; Shang, W.; Li, X. Transfer of Robot Perception Module with Adversarial Learning. IEEE Access 2019, 7, 79726-79736. [CrossRef]</p>
<p>From Simulation to Real-World Robotic Mobile Fulfillment Systems. L Xie, H Li, N Thieme, Logist. Res. 129Xie, L.; Li, H.; Thieme, N. From Simulation to Real-World Robotic Mobile Fulfillment Systems. Logist. Res. 2019, 12, 9.</p>
<p>Learning Quadrupedal Locomotion over Challenging Terrain. Sci. J Lee, J Hwangbo, L Wellhausen, V Koltun, M Hutter, 10.1126/scirobotics.abc5986Robot. 2020, 5, eabc5986. [CrossRefLee, J.; Hwangbo, J.; Wellhausen, L.; Koltun, V.; Hutter, M. Learning Quadrupedal Locomotion over Challenging Terrain. Sci. Robot. 2020, 5, eabc5986. [CrossRef]</p>
<p>Transfer Learning for Humanoid Robot Appearance-Based Localization in a Visual Map. E Ovalle-Magallanes, N G Aldana-Murillo, J G Avina-Cervantes, J Ruiz-Pinales, J Cepeda-Negrete, S Ledesma, 10.1109/ACCESS.2020.3048936IEEE Access. 9Ovalle-Magallanes, E.; Aldana-Murillo, N.G.; Avina-Cervantes, J.G.; Ruiz-Pinales, J.; Cepeda-Negrete, J.; Ledesma, S. Transfer Learning for Humanoid Robot Appearance-Based Localization in a Visual Map. IEEE Access 2021, 9, 6868-6877. [CrossRef]</p>
<p>Learning Transferable Policies for Monocular Reactive MAV Control. S Daftry, J A Bagnell, M Hebert, International Symposium on Experimental Robotics. Cham, SwitzerlandSpringer1Daftry, S.; Bagnell, J.A.; Hebert, M. Learning Transferable Policies for Monocular Reactive MAV Control. In International Symposium on Experimental Robotics; Springer: Cham, Switzerland, 2016; Volume 1, pp. 3-11.</p>
<p>Virtual to Real Reinforcement Learning for Autonomous Driving. X Pan, Y You, Z Wang, C Lu, arXiv:1704.03952Pan, X.; You, Y.; Wang, Z.; Lu, C. Virtual to Real Reinforcement Learning for Autonomous Driving. arXiv 2017, arXiv:1704.03952.</p>
<p>Learning to Generate Synthetic Datasets. A Kar, A Prakash, M.-Y Liu, E Cameracci, J Yuan, M Rusiniak, D Acuna, A Torralba, S Fidler, Meta-Sim, Proceedings of the 2019 IEEE/CVF International Conference on Computer Vision (ICCV). the 2019 IEEE/CVF International Conference on Computer Vision (ICCV)Seoul, KoreaKar, A.; Prakash, A.; Liu, M.-Y.; Cameracci, E.; Yuan, J.; Rusiniak, M.; Acuna, D.; Torralba, A.; Fidler, S. Meta-Sim: Learning to Generate Synthetic Datasets. In Proceedings of the 2019 IEEE/CVF International Conference on Computer Vision (ICCV), Seoul, Korea, 27 October-2 November 2019.</p>
<p>Virtual-to-Real Knowledge Transfer for Driving Behavior Recognition: Framework and a Case Study. C Lu, F Hu, D Cao, J Gong, Y Xing, Z Li, 10.1109/TVT.2019.2917025IEEE Trans. Veh. Technol. 68Lu, C.; Hu, F.; Cao, D.; Gong, J.; Xing, Y.; Li, Z. Virtual-to-Real Knowledge Transfer for Driving Behavior Recognition: Framework and a Case Study. IEEE Trans. Veh. Technol. 2019, 68, 6391-6402. [CrossRef]</p>
<p>Good Robot!": Efficient Reinforcement Learning for Multi-Step Visual Tasks with Sim to Real Transfer. A Hundt, B Killeen, N Greene, H Wu, H Kwon, C Paxton, G Hager, arXiv:1909.11730Hundt, A.; Killeen, B.; Greene, N.; Wu, H.; Kwon, H.; Paxton, C.; Hager, G. "Good Robot!": Efficient Reinforcement Learning for Multi-Step Visual Tasks with Sim to Real Transfer. arXiv 2019, arXiv:1909.11730.</p>
<p>From Simulation to Real World Maneuver Execution Using Deep Reinforcement Learning. A P Capasso, G Bacchiani, A Broggi, Proceedings of the 2020 IEEE Intelligent Vehicles Symposium (IV). the 2020 IEEE Intelligent Vehicles Symposium (IV)Las Vegas, NV, USACapasso, A.P.; Bacchiani, G.; Broggi, A. From Simulation to Real World Maneuver Execution Using Deep Reinforcement Learning. In Proceedings of the 2020 IEEE Intelligent Vehicles Symposium (IV), Las Vegas, NV, USA, 19 October-13 November 2020.</p>
<p>Sim-to-Real Transfer with Incremental Environment Complexity for Reinforcement Learning of Depth-Based Robot Navigation. T Chaffre, J Moras, A Chan-Hon-Tong, J Marzat, Proceedings of the 17th International Conference on Informatics in Control, Automation and Robotics-ICINCO. the 17th International Conference on Informatics in Control, Automation and Robotics-ICINCOParis, FranceChaffre, T.; Moras, J.; Chan-Hon-Tong, A.; Marzat, J. Sim-to-Real Transfer with Incremental Environment Complexity for Reinforcement Learning of Depth-Based Robot Navigation. In Proceedings of the 17th International Conference on Informatics in Control, Automation and Robotics-ICINCO, Paris, France, 5-7 July 2020.</p>
<p>Transfer Learning in Reinforcement Learning Problems through Partial Policy Recycling. J Ramon, K Driessens, T Croonenborghs, Proceedings of the Machine Learning: ECML 2007, 18th European Conference on Machine Learning. the Machine Learning: ECML 2007, 18th European Conference on Machine LearningHeidelberge, Germany; Berlin, GermanySpringer4701Ramon, J.; Driessens, K.; Croonenborghs, T. Transfer Learning in Reinforcement Learning Problems through Partial Policy Recycling. In Proceedings of the Machine Learning: ECML 2007, 18th European Conference on Machine Learning, Heidelberge, Germany, 17-21 September 2007; Springer: Berlin, Germany, 2007; Volume 4701, pp. 699-707.</p>
<p>Transfer Learning from Minimal Target Data by Mapping across Relational Domains. L Mihalkova, R J Mooney, Proceedings of the 21st International Jont Conference on Artifical Intelligence. the 21st International Jont Conference on Artifical IntelligenceIJCAI'09Mihalkova, L.; Mooney, R.J. Transfer Learning from Minimal Target Data by Mapping across Relational Domains. In Proceedings of the 21st International Jont Conference on Artifical Intelligence; IJCAI'09;</p>
<p>Transfer Learning in Sequential Decision Problems: A Hierarchical Bayesian Approach. A Wilson, A Fern, P Tadepalli, Proceedings of the 2011 International Conference on Unsupervised and Transfer Learning Workshop. the 2011 International Conference on Unsupervised and Transfer Learning WorkshopWashington, DC, USA, 2Wilson, A.; Fern, A.; Tadepalli, P. Transfer Learning in Sequential Decision Problems: A Hierarchical Bayesian Approach. In Proceedings of the 2011 International Conference on Unsupervised and Transfer Learning Workshop, Washington, DC, USA, 2 July 2011.</p>
<p>Flexible Transfer Learning under Support and Model Shift. X Wang, J Schneider, Proceedings of the 27th International Conference on Neural Information Processing Systems. the 27th International Conference on Neural Information Processing SystemsMontreal, QC, CanadaWang, X.; Schneider, J. Flexible Transfer Learning under Support and Model Shift. In Proceedings of the 27th International Conference on Neural Information Processing Systems, Montreal, QC, Canada, 8-13 December 2014.</p>
<p>Learning Invariant Feature Spaces to Transfer Skills with Reinforcement Learning. A Gupta, C Devin, Y Liu, P Abbeel, S Levine, Proceedings of the International Conference on Learning Representations. the International Conference on Learning RepresentationsToulon, FranceGupta, A.; Devin, C.; Liu, Y.; Abbeel, P.; Levine, S. Learning Invariant Feature Spaces to Transfer Skills with Reinforcement Learning. In Proceedings of the International Conference on Learning Representations, Toulon, France, 24-26 April 2017.</p>
<p>Cross-Domain Transfer in Reinforcement Learning Using Target Apprentice. G Joshi, G Chowdhary, Proceedings of the 2018 IEEE International Conference on Robotics and Automation (ICRA). the 2018 IEEE International Conference on Robotics and Automation (ICRA)Brisbane, QLD, AustraliaJoshi, G.; Chowdhary, G. Cross-Domain Transfer in Reinforcement Learning Using Target Apprentice. In Proceedings of the 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, Australia, 21-25 May 2018; pp. 7525-7532.</p>
<p>Learning to Adapt in Dynamic, Real-World Environments Through Meta-Reinforcement Learning. A Nagabandi, I Clavera, S Liu, R S Fearing, P Abbeel, S Levine, C Finn, Proceedings of the International Conference on Learning Representations (ICLR) Conference. the International Conference on Learning Representations (ICLR) ConferenceNew Orleans, LA, USANagabandi, A.; Clavera, I.; Liu, S.; Fearing, R.S.; Abbeel, P.; Levine, S.; Finn, C. Learning to Adapt in Dynamic, Real-World Envi- ronments Through Meta-Reinforcement Learning. In Proceedings of the International Conference on Learning Representations (ICLR) Conference, New Orleans, LA, USA, 6-9 May 2019.</p>
<p>Adversarially Robust Transfer Learning. A Shafahi, P Saadatpanah, C Zhu, A Ghiasi, C Studer, D Jacobs, T Goldstein, Proceedings of the International Conference on Learning Representations (ICLR) Conference, Adidas Ababa. the International Conference on Learning Representations (ICLR) Conference, Adidas AbabaEthiopiaShafahi, A.; Saadatpanah, P.; Zhu, C.; Ghiasi, A.; Studer, C.; Jacobs, D.; Goldstein, T. Adversarially Robust Transfer Learning. In Proceedings of the International Conference on Learning Representations (ICLR) Conference, Adidas Ababa, Ethiopia, 26 April-1 May 2020.</p>
<p>Autonomous Shaping: Knowledge Transfer in Reinforcement Learning. G Konidaris, A Barto, Proceedings of the 23rd International Conference on Machine Learning-ICML '06. the 23rd International Conference on Machine Learning-ICML '06Pittsburgh, PA, USAACM PressKonidaris, G.; Barto, A. Autonomous Shaping: Knowledge Transfer in Reinforcement Learning. In Proceedings of the 23rd International Conference on Machine Learning-ICML '06; ACM Press: Pittsburgh, PA, USA, 2006; pp. 489-496.</p>
<p>Self-Taught Learning: Transfer Learning from Unlabeled Data. R Raina, A Battle, H Lee, B Packer, A Y Ng, Proceedings of the 24th International Conference on Machine Learning-ICML '07. the 24th International Conference on Machine Learning-ICML '07Corvalis, OR, USAACM PressRaina, R.; Battle, A.; Lee, H.; Packer, B.; Ng, A.Y. Self-Taught Learning: Transfer Learning from Unlabeled Data. In Proceedings of the 24th International Conference on Machine Learning-ICML '07; ACM Press: Corvalis, OR, USA, 2007; pp. 759-766.</p>
<p>Transfer Learning via Inter-Task Mappings for Temporal Difference Learning. M Taylor, P Stone, Y Liu, J. Mach. Learn. Res. 8Taylor, M.; Stone, P.; Liu, Y. Transfer Learning via Inter-Task Mappings for Temporal Difference Learning. J. Mach. Learn. Res. 2007, 8, 2125-2167.</p>
<p>Transfer Learning in Multi-Agent Reinforcement Learning Domains. G Boutsioukis, I Partalas, I Vlahavas, Recent Advances in Reinforcement Learning. Boutsioukis, G.; Partalas, I.; Vlahavas, I. Transfer Learning in Multi-Agent Reinforcement Learning Domains. In Recent Advances in Reinforcement Learning;</p>
<p>. S Sanner, M Hutter, Lecture Notes in Computer Science. SpringerSanner, S., Hutter, M., Eds.; Lecture Notes in Computer Science; Springer: Berlin/Heidelberg, Germany, 2012; pp. 249-260.</p>
<p>Robots That Can Adapt like Animals. A Cully, J Clune, D Tarapore, J.-B Mouret, 10.1038/nature14422arXiv:1610.03518Transfer from Simulation to Real World through Learning Deep Inverse Dynamics Model. arXiv 2016. 52161Cully, A.; Clune, J.; Tarapore, D.; Mouret, J.-B. Robots That Can Adapt like Animals. Nature 2015, 521, 503-507. [CrossRef] 61. Transfer from Simulation to Real World through Learning Deep Inverse Dynamics Model. arXiv 2016, arXiv:1610.03518.</p>
<p>Deep Learning for Robotics. I Lenz, New York, NY, USACornell UniversityPh.D. ThesisLenz, I. Deep Learning for Robotics. Ph.D. Thesis, Cornell University, New York, NY, USA, 2016.</p>
<p>Domain Randomization for Transferring Deep Neural Networks from Simulation to the Real World. J Tobin, R Fong, A Ray, J Schneider, W Zaremba, P Abbeel, Proceedings of the 2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). the 2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)Vancouver, BC, CanadaTobin, J.; Fong, R.; Ray, A.; Schneider, J.; Zaremba, W.; Abbeel, P. Domain Randomization for Transferring Deep Neural Networks from Simulation to the Real World. In Proceedings of the 2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Vancouver, BC, Canada, 24-28 September 2017; pp. 23-30.</p>
<p>T Wolf, V Sanh, J Chaumond, C Delangue, Transfertransfo, arXiv:1901.08149A Transfer Learning Approach for Neural Network Based Conversational Agents. arXiv 2019. Wolf, T.; Sanh, V.; Chaumond, J.; Delangue, C. TransferTransfo: A Transfer Learning Approach for Neural Network Based Conversational Agents. arXiv 2019, arXiv:1901.08149.</p>
<p>Y Jang, H Lee, S J Hwang, J Shin, arXiv:1905.05901Learning What and Where to Transfer. arXiv 2019. Jang, Y.; Lee, H.; Hwang, S.J.; Shin, J. Learning What and Where to Transfer. arXiv 2019, arXiv:1905.05901.</p>
<p>Transfer Learning with Dynamic Distribution Adaptation. J Wang, Y Chen, W Feng, H Yu, M Huang, Q Yang, 10.1145/3360309ACM Trans. Intell. Syst. Technol. 11Wang, J.; Chen, Y.; Feng, W.; Yu, H.; Huang, M.; Yang, Q. Transfer Learning with Dynamic Distribution Adaptation. ACM Trans. Intell. Syst. Technol. 2020, 11, 1-25. [CrossRef]</p>
<p>Meta-Transfer Learning through Hard Tasks. Q Sun, Y Liu, Z Chen, T.-S Chua, B Schiele, 10.1109/TPAMI.2020.3018506IEEE Trans. Pattern Anal. Mach. Intell. 2020PubMedSun, Q.; Liu, Y.; Chen, Z.; Chua, T.-S.; Schiele, B. Meta-Transfer Learning through Hard Tasks. IEEE Trans. Pattern Anal. Mach. Intell. 2020, 1. [CrossRef] [PubMed]</p>
<p>How to Pick the Domain Randomization Parameters for Sim-to. Q Vuong, S Vikram, H Su, S Gao, H I Christensen, arXiv:1903.11774Real Transfer of Reinforcement Learning Policies? arXiv 2019. Vuong, Q.; Vikram, S.; Su, H.; Gao, S.; Christensen, H.I. How to Pick the Domain Randomization Parameters for Sim-to-Real Transfer of Reinforcement Learning Policies? arXiv 2019, arXiv:1903.11774.</p>
<p>Unsupervised Transfer Learning with Self-Supervised Remedy. J Huang, S Gong, arXiv:2006.047372020Huang, J.; Gong, S. Unsupervised Transfer Learning with Self-Supervised Remedy. arXiv 2020, arXiv:2006.04737.</p>
<p>A Preliminary Study of Transfer Learning between Unicycle Robots. K Raimalwala, B Francis, A Schoellig, AAAI Spring Symposia7Raimalwala, K.; Francis, B.; Schoellig, A. A Preliminary Study of Transfer Learning between Unicycle Robots. AAAI Spring Symposia. 2016, 7, 53-59.</p>
<p>A Comparative Study of Methods for Transductive Transfer Learning. A Arnold, R Nallapati, W W Cohen, Proceedings of the Seventh IEEE International Conference on Data Mining Workshops (ICDMW 2007). the Seventh IEEE International Conference on Data Mining Workshops (ICDMW 2007)Omaha, NE, USAArnold, A.; Nallapati, R.; Cohen, W.W. A Comparative Study of Methods for Transductive Transfer Learning. In Proceedings of the Seventh IEEE International Conference on Data Mining Workshops (ICDMW 2007), Omaha, NE, USA, 28-31 October 2007; pp. 77-82.</p>
<p>Transfer Learning for Reinforcement Learning Domains: A Survey. M E Taylor, P Stone, J. Mach. Learn. Res. 10Taylor, M.E.; Stone, P. Transfer Learning for Reinforcement Learning Domains: A Survey. J. Mach. Learn. Res. 2009, 10, 1633-1685.</p>
<p>A Survey of Robot Learning from Demonstration. B Argall, S Chernova, M Veloso, B Browning, 10.1016/j.robot.2008.10.024Robot. Auton. Syst. 57Argall, B.; Chernova, S.; Veloso, M.; Browning, B. A Survey of Robot Learning from Demonstration. Robot. Auton. Syst. 2009, 57, 469-483. [CrossRef]</p>
<p>Deliberation for Autonomous Robots: A Survey. F Ingrand, M Ghallab, 10.1016/j.artint.2014.11.003Artif. Intell. 247Ingrand, F.; Ghallab, M. Deliberation for Autonomous Robots: A Survey. Artif. Intell. 2017, 247, 10-44. [CrossRef]</p>
<p>. C Tan, F Sun, T Kong, W Zhang, C Yang, C Liu, arXiv:1808.01974A Survey on Deep Transfer Learning. Tan, C.; Sun, F.; Kong, T.; Zhang, W.; Yang, C.; Liu, C. A Survey on Deep Transfer Learning. arXiv 2018, arXiv:1808.01974.</p>
<p>A Fabisch, C Petzoldt, M Otto, F Kirchner, arXiv:1906.01868A Survey of Behavior Learning Applications in Robotics-State of the Art and Perspectives. arXiv 2019. Fabisch, A.; Petzoldt, C.; Otto, M.; Kirchner, F. A Survey of Behavior Learning Applications in Robotics-State of the Art and Perspectives. arXiv 2019, arXiv:1906.01868.</p>
<p>T Hospedales, A Antoniou, P Micaelli, A Storkey, Meta-Learning, arXiv:2004.05439Neural Networks: A Survey. arXiv 2020. Hospedales, T.; Antoniou, A.; Micaelli, P.; Storkey, A. Meta-Learning in Neural Networks: A Survey. arXiv 2020, arXiv:2004.05439.</p>
<p>Learning for a Robot: Deep Reinforcement Learning, Imitation Learning, Transfer Learning. J Hua, L Zeng, G Li, Z Ju, 10.3390/s21041278Sensors. 21Hua, J.; Zeng, L.; Li, G.; Ju, Z. Learning for a Robot: Deep Reinforcement Learning, Imitation Learning, Transfer Learning. Sensors 2021, 21, 1278. [CrossRef]</p>
<p>Lifelong Machine Learning, Second Edition. Z Chen, B Liu, 10.2200/S00832ED1V01Y201802AIM037Synth. Lect. on Artif. Intell. Mach. Learn. 12Chen, Z.; Liu, B. Lifelong Machine Learning, Second Edition. Synth. Lect. on Artif. Intell. Mach. Learn. 2018, 12, 1-207. [CrossRef]</p>            </div>
        </div>

    </div>
</body>
</html>