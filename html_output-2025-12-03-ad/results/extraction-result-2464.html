<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2464 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2464</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2464</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-67.html">extraction-schema-67</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <p><strong>Paper ID:</strong> paper-220424408</p>
                <p><strong>Paper Title:</strong> <a href="https://arxiv.org/pdf/2007.04674v1.pdf" target="_blank">Resource Aware Multifidelity Active Learning for Efficient Optimization</a></p>
                <p><strong>Paper Abstract:</strong> Traditional methods for black box optimization require a considerable number of evaluations which can be time consuming, unpractical, and often unfeasible for many engineering applications that rely on accurate representations and expensive models to evaluate. Bayesian Optimization (BO) methods search for the global optimum by progressively (actively) learning a surrogate model of the objective function along the search path. Bayesian optimization can be accelerated through multifidelity approaches which leverage multiple black-box approximations of the objective functions that can be computationally cheaper to evaluate, but still provide relevant information to the search task. Further computational benefits are offered by the availability of parallel and distributed computing architectures whose optimal usage is an open opportunity within the context of active learning. This paper introduces the Resource Aware Active Learning (RAAL) strategy, a multifidelity Bayesian scheme to accelerate the optimization of black box functions. At each optimization step, the RAAL procedure computes the set of best sample locations and the associated fidelity sources that maximize the information gain to acquire during the parallel/distributed evaluation of the objective function, while accounting for the limited computational budget. The scheme is demonstrated for a variety of benchmark problems and results are discussed for both single fidelity and multifidelity settings. In particular we observe that the RAAL strategy optimally seeds multiple points at each iteration allowing for a major speed up of the optimization task.</p>
                <p><strong>Cost:</strong> 0.025</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2464.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2464.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RAAL</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Resource Aware Active Learning</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A multipoint, multifidelity Bayesian optimization/active learning scheme that jointly selects sample locations and fidelity levels and allocates parallel computational resources via a MILP knapsack to maximize information gain under a limited computational budget.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Resource Aware Active Learning (RAAL)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>RAAL is an active-learning-for-optimization system that couples (i) a multifidelity Gaussian Process (MF-GP) surrogate (autoregressive style) and acquisition functions (EI / MFEI) with (ii) a candidate-evaluation stage that computes acquisition-function values on a pre-filtered feasible candidate set and (iii) a mixed-integer linear programming (MILP) knapsack-style seeding optimizer that selects multiple points, fidelity levels and assigns them to parallel CPUs. Key components: MF-GP predictive mean/variance, Expected Improvement (EI) and Multifidelity EI (MFEI) as utilities, adaptive discretization (uniform or AF-weighted quantile gridding controlled by parameter ξ) to partition the domain into strata, decision variables p_i^{(m),g} and q_i in the MILP, objective that (hierarchically) (a) minimizes unused CPU capacity and (b) maximizes the sum of acquisition values for chosen point–fidelity pairs, and constraints enforcing per-CPU capacity, one-point-per-bin (diversity), single-CPU-per-point, and fidelity interdependence consistent with the autoregressive MF-GP.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>General expensive black-box optimization tasks, demonstrated for engineering/aerospace test problems (analytical benchmarks); applicable to design optimization, model calibration, hyperparameter tuning, and other experimental-design or automated-discovery tasks requiring expensive evaluations.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Formulates selection/allocation as a knapsack-like MILP: decision variables p(m)_{i,g} = 1 if candidate i is chosen at fidelity m and assigned to CPU g, and q_i = 1 if candidate i is chosen. Objective = Υ * (aggregate unused CPU capacity) - sum_i,m,g υ_i^{(m)} p(m)_{i,g}, where υ_i^{(m)} are AF values; Υ is set >> sum of AF values so that maximizing resource usage is prioritized, then AF sum. Constraints enforce per-CPU capacity (sum λ(m) p ≤ β_g), at most one chosen per stratum/bin, single CPU per point, and fidelity coherence for autoregressive MF-GP. Thus selection simultaneously decides which hypotheses (x) and which fidelities (m) to evaluate and assigns them to computational units to maximize information within budget.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Abstract computational-cost units λ(m) per fidelity (user-provided). In experiments the highest fidelity cost is 1 and lower fidelities fractional (example rule used: λ(m)=1 for m=M, λ(m)=1/5^{(M-m)} for m<M). Per-CPU capacity β_g is expressed in same λ-units; total used budget B accumulates λ(m). Practically represents normalized evaluation cost (proxy for wall-clock/CPU-time).</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Acquisition function values υ(x,m): single-fidelity Expected Improvement (EI) at the highest fidelity and Multifidelity Expected Improvement (MFEI) for lower-fidelity queries (EI at top fidelity multiplied by utility factors α_1 (correlation) and α_2 (noise/scaling)). The MILP sums these υ values for chosen assignments as surrogate for expected information gain.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Multiple mechanisms: (1) The underlying EI/MFEI acquisition function provides the classic exploration-exploitation trade-off via predictive mean/variance and a tunable ζ parameter; (2) Adaptive discretization (parameter ξ with schedule ξ_t) transitions the search grid from uniform (exploration) to AF-concentrated (exploitation) as budget is spent; (3) The MILP enforces a well-distributed selection across strata (via at-most-one-per-bin) to maintain exploration while the objective still favors high-AF points for exploitation; (4) The hierarchical MILP objective (Υ weight) prioritizes using resources fully which can increase exploration through parallel sampling.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Explicit: domain is partitioned into E_j bins per dimension (uniform or AF-weighted quantile bins). MILP constraint enforces at most one selected point per bin (constraint (16a)), and q_i together with decoded bin indicators χ_i ensure chosen set is spread across strata. Adaptive gridding allows bins to be concentrated near AF modes or uniform depending on ξ.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Computational-resource budget: per-CPU capacities β_g (parallel resources) and a global total budget B_max expressed in λ(m) cost-units; also iteration-wise budget tracking.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Encoded directly in the MILP: per-CPU capacity constraints (sum of λ(m) p(m)_{i,g} ≤ β_g), global budget tracked and used to update discretization parameter ξ (eq. 14). The MILP objective includes a large weight Υ that prioritizes maximizing usage of available computational capacity before maximizing AF value, ensuring budget is efficiently filled.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Not defined as an explicit novelty/breakthrough score in the paper; practical proxy used is improvement in objective function (expected improvement) and distance to known global optimum. Experiments measure Root Squared Error to known optimum and number of iterations to reach optimum.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Reported metrics are Root Squared Error (RSE) to known global optimum vs iterations and iterations-to-convergence under fixed total computational budget B_max. Example numerical results reported in the paper: SF Test 1 with 5 CPUs: RAAL reaches optimum in ~2.5 iterations on average vs sequential BO in ~5 iterations; SF Test 2: sequential BO ~20 iterations, RAAL ~10 iterations with 2 CPUs and <5 iterations with 5 CPUs (B_max=30); MF Test 2: RAAL often finds global optimum in ~5 iterations with 5 CPUs (B_max=20); high-dimensional Rosenbrock (d=8) MF: RAAL achieved a smaller final error in a fraction of iterations compared to sequential BO (B_max varied 30–80). All experiments report medians over 20 randomized runs and 25–75% percentile bands.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Standard sequential Bayesian Optimization (single-point-per-iteration BO using the same GP surrogate and acquisition function but run on a single CPU), i.e., sequential BO.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>RAAL consistently converged faster and more robustly than sequential BO across benchmarks. Representative comparisons: SF Test1 (5 CPUs): RAAL 2.5 iterations vs sequential 5; SF Test2: sequential 20 iterations vs RAAL 10 (2 CPUs) and <5 (5 CPUs); MF Test2: RAAL found the global optimum where SF sometimes failed. RAAL also reduced inter-run variability.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Described as a 'major speed up' in the paper. Representative numeric gains: ~2× speedup (20→10 iterations) or up to ~4× (20→5) in some cases; ~2× improvement in iterations for SF Test1 example (5→2.5). Gains depend on number of CPUs, grid resolution and use of multifidelity information.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Paper analyzes interaction between grid resolution (E), adaptive-gridding learning rate (η_ξ), number of CPUs, and multifidelity availability: (i) finer grid (larger E) aids multimodal problems and benefits when many CPUs are available; (ii) higher η_ξ (faster shift to exploitation) can hurt performance on highly multimodal single-fidelity problems by reducing exploration; (iii) multifidelity access reduces sensitivity to η_ξ and generally improves ability to explore (lower-fidelity cheap evaluations allow more samples); (iv) MILP objective weighting prioritizes resource usage over AF maximization, which the authors argue leads to better wall-clock performance when parallel resources are limited. Overall, balancing exploration/exploitation and resource usage is controlled via ξ schedule, E, η_ξ, and Υ.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Key recommendations/insights: (1) prioritize filling available parallel resources (maximize CPU utilization) and then maximize summed AF across chosen assignments (implemented via large Υ), (2) select multiple well-distributed candidate points per iteration rather than greedy single-point maximization, (3) exploit cheaper lower-fidelity models to sample more points and improve exploration (multifidelity gives major advantages), (4) adapt discretization from exploration to exploitation as budget is consumed (use ξ schedule), and (5) enforce fidelity coherence consistent with autoregressive MF-GP. These principles produced faster convergence in all demonstrated benchmarks.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Resource Aware Multifidelity Active Learning for Efficient Optimization', 'publication_date_yy_mm': '2020-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2464.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2464.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MFEI</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Multifidelity Expected Improvement (Augmented EI)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An acquisition function for multifidelity Bayesian optimization that multiplies the Expected Improvement (at the highest fidelity) by utility factors that discount lower-fidelity usefulness based on correlation and noise.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Multifidelity Expected Improvement (MFEI / Augmented EI)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>MFEI is defined as MFEI(x,m) = EI(x) * α_1(x,m) * α_2(x,m), where EI(x) is the Expected Improvement at the highest fidelity, α_1(x,m) is a correlation-based discount factor corr(f^{(m)}(x), f^{(M)}(x)) (reducing utility for lower fidelities), and α_2(x,m) accounts for observational noise (equals 1 in deterministic settings). In this paper MFEI values υ_i^{(m)} are used as the utility scores for candidate point–fidelity pairs in the RAAL MILP.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Multifidelity Bayesian Optimization for black-box expensive functions.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Scores candidate (x,m) pairs by their MFEI value; these scores are input to the RAAL MILP which then allocates resources (which points/m fidelities to evaluate) under capacity constraints to maximize aggregate MFEI subject to resource usage priorities.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>MFEI itself does not include cost; in RAAL it is combined with per-fidelity cost λ(m) in the MILP constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Based on Expected Improvement (expected gain in objective value) at the highest fidelity, modulated by α_1 and α_2 to reflect fidelity correlation and noise.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Retains EI's exploration/exploitation trade-off through predictive mean/variance and ζ; lower-fidelity contributions are downweighted by α_1 so selection prefers higher-fidelity EI when correlation is low.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Paper notes α_1 discounts lower fidelity utility and α_2 accounts for noise; deterministic α_2=1. MFEI is compatible with RAAL's resource-aware selection by providing per-(x,m) utility.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>MFEI provides a straightforward, computationally tractable way to include fidelity choice in acquisition scoring; when combined with explicit cost-aware selection (MILP) it supports resource-aware multifidelity sampling.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Resource Aware Multifidelity Active Learning for Efficient Optimization', 'publication_date_yy_mm': '2020-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2464.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2464.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MF-BO</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Multifidelity Bayesian Optimization (general)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The extension of Bayesian optimization to multiple information sources/fidelity levels, combining them in a single surrogate (e.g., autoregressive MF-GP) and using multifidelity acquisition functions to choose both locations and fidelities to query.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Multifidelity Bayesian Optimization</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Combines autoregressive multifidelity Gaussian Processes (f^{(m)} related via f^{(m)}(x)=ρ f^{(m-1)}(x)+δ^{(m)}(x)) to jointly model multiple fidelity levels, and uses multifidelity acquisition functions (MFEI, MFES, etc.) to decide both x and m. In RAAL the MF-BO surrogate provides predictive mean/variance at all fidelities and supplies acquisition values used by the resource allocation MILP.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Black-box optimization with multiple approximation/simulator fidelities (engineering design, simulation-based optimization).</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Chooses both sample location and fidelity, guided by multifidelity acquisition functions; in RAAL these choices are combined with an explicit resource-allocation MILP that accounts for evaluation costs λ(m) and CPU capacities β_g.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Per-fidelity cost λ(m) (normalized); total budget B_max.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Acquisition functions (MFEI, entropy-based methods) that quantify expected utility from querying (x,m).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Acquisition functions encode the trade-off; RAAL augments this with multipoint selection and diversity constraints to foster exploration.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Computational budget, evaluation cost per fidelity.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Handled by RAAL's MILP when used; otherwise typical MF-BO methods may use cost-aware acquisition heuristics.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Typically improvement in objective or reduction in posterior uncertainty; not given a separate novelty metric in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>In experiments multifidelity RAAL often outperforms single-fidelity RAAL and sequential BO, e.g., MF Test2 RAAL reaches global optimum more reliably and faster than SF counterparts.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Sequential single-fidelity BO and RAAL single-fidelity variants.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>MF RAAL benefits from low-fidelity cheap evaluations to sample more candidates per iteration, enabling faster exploration and more robust convergence (examples in paper: MF Test2 shows RAAL achieves global optimum where SF sometimes fails).</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Multifidelity availability allowed RAAL to seed more points per iteration for same budget, leading to faster convergence (examples: MF Test2 often reaches the optimum in ~5 iterations with 5 CPUs).</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Paper discusses that multifidelity reduces sensitivity to adaptive-gridding hyperparameters and allows a different exploration/exploitation balance (more exploration possible because of cheaper low-fidelity samples).</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Using cheaper lower-fidelity models strategically to increase sample counts per iteration is beneficial; resource-aware scheduling of fidelities via cost-aware selection (e.g. MFEI scores combined with λ(m) in MILP) yields better wall-clock/iteration performance.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Resource Aware Multifidelity Active Learning for Efficient Optimization', 'publication_date_yy_mm': '2020-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2464.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2464.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MILP-knapsack seeding</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Mixed-Integer Linear Programming knapsack-based multipoint multifidelity seeding</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A MILP formulation that selects multiple candidate points and their fidelity assignments and assigns them to parallel CPUs to maximize aggregate acquisition-value subject to per-CPU capacities, diversity (one-per-bin) and fidelity-coherence constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>MILP knapsack-based seeding optimizer</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Decision variables: binary p(m)_{i,g} (point i at fidelity m assigned to CPU g) and q_i (point i chosen). Objective: minimize Υ*(unused CPU capacity) - sum υ_i^{(m)} p(m)_{i,g} (Υ >> sum υ ensures resource usage prioritized). Key constraints: (16a) at most one chosen point per bin/stratum, (16b) per-CPU capacity ∑ λ(m) p ≤ β_g, (16c)-(16d) logical link between p and q, (16e) one CPU per (i,m), and (16f) fidelity interdependence for autoregressive GP (ensures consistency among fidelities). Implemented with PuLP and COIN CLP/CBC in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Resource-aware selection/seeding in multipoint Bayesian optimization under parallel/distributed computational resources.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Optimizes a knapsack objective to (a) pack evaluations into available CPU capacities and (b) choose assignments that maximize cumulative acquisition utility. It directly assigns evaluations to computational units respecting per-unit capacity, so it handles both which experiments to run and where to run them in a parallel environment.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Per-fidelity costs λ(m) and per-CPU capacities β_g; objective includes unused-capacity term measured in same λ-units.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Per-(x,m) acquisition values υ_i^{(m)} (EI / MFEI) summed in objective as proxy for information gained by chosen set.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Diversity constraints (one-per-bin) enforce spread/exploration; the MILP objective promotes assigning high-AF points for exploitation but only after capacity usage is prioritized via Υ; adaptive discretization upstream shapes bins to shift between exploration and exploitation.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Explicit at-most-one-per-bin constraint (16a) ensuring chosen points are well-distributed across strata.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Per-CPU capacity constraints and aggregate budget tracked externally.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Hard constraints in the MILP (16b); objective includes term prioritizing full capacity utilization to minimize wasted budget.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Used as the core selection mechanism in RAAL; contributes to the iteration-level performance gains reported for RAAL (see RAAL performance metrics).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Implicit baseline is greedy pointwise maximization of AF (standard BO); experiments compare full RAAL (including MILP) to sequential BO (greedy single point).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>By optimizing multi-point selections and packing them into CPUs, MILP-based seeding enables RAAL to outperform sequential BO in iteration count to optimum and robustness; see RAAL numeric examples.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Contributes to RAAL's 2×–4× reductions in iterations-to-convergence in reported benchmarks by enabling parallel, well-distributed, cost-aware seeding.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Objective weighting (Υ) creates explicit tradeoff: filling CPU time (exploration via more samples) vs maximizing summed AF (exploitation); choice of Υ and discretization parameters (E, ξ, η_ξ) control this tradeoff.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Formulating multipoint multifidelity seeding as an MILP knapsack that (a) enforces diversity and (b) prioritizes CPU utilization leads to better wall-clock efficiency than greedy single-point schemes; fidelity-coherent constraints are necessary for correct MF-GP updates.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Resource Aware Multifidelity Active Learning for Efficient Optimization', 'publication_date_yy_mm': '2020-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2464.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2464.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Adaptive Gridding</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Adaptive AF-weighted discretization (adaptive gridding)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A discretization technique mapping candidate points to per-dimension strata using acquisition-function quantiles (parameter ξ) to concentrate bins around AF modes and thereby tune exploration vs exploitation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Adaptive AF-weighted discretization (Adaptive Gridding)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Two modes: uniform gridding (equal-length bins per dimension) and AF-weighted adaptive gridding where points with AF below a quantile ξ are removed and remaining points per-dimension are binned by AF quantiles Q^e_j. The mapping Ξ(x,ξ) assigns candidate points to strata; ξ is adaptively updated per iteration via ξ_t = ξ_max * (1 - exp(-η_ξ * (B / B_max - B))) (see eq. 14) to move from exploration (ξ≈0 uniform) to exploitation (ξ>0 concentrating bins near AF peaks). The discretized χ_i feed the MILP which enforces at-most-one-per-bin for diversity.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Candidate selection and diversity enforcement in multipoint Bayesian optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Shapes candidate strata so that MILP selection picks points that are both high-utility (AF) and well-distributed according to the chosen gridding; ξ schedule is used to shift allocation behavior as budget is consumed.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Uses AF values to construct quantile-based bins; AF thus directly shapes bin placement and therefore the information gain distribution of chosen points.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Direct: ξ controls how much the discretization favors AF modes (exploitation) vs uniform coverage (exploration). The learning-rate η_ξ and ξ_max tune how quickly the algorithm transitions to exploitation as budget is spent.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Yes — works with MILP's per-bin selection constraints to ensure selections are spread over the adaptive grid.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Adaptive parameter ξ is updated based on fraction of budget used (B/B_max).</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>ξ_t update formula (eq. 14) uses current budget consumed to change discretization; thus budget depletion drives exploitation.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Empirical findings: finer grid (larger E) improves performance for highly multimodal problems when many CPUs are available; high learning rates η_ξ that concentrate quickly on exploitation can hurt performance in single-fidelity multimodal problems; multifidelity reduces sensitivity to η_ξ.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Uniform gridding (ξ=0)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Adaptive gridding with appropriate ξ/η_ξ improved convergence in several benchmarks compared to uniform gridding, but mis-tuned parameters can degrade performance.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Contributes to RAAL's faster convergence by trading early exploration for focused exploitation later, when budget is low and accurate AF peaks are known.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Paper reports the interplay between grid resolution E, learning rate η_ξ, and number of CPUs: coarse grid + many CPUs → exploration bias; fine grid + few CPUs → over-exploitation; tune grid/resolution to CPU count and problem multimodality.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Adaptively concentrate bins near AF modes as budget depletes, but use more uniform bins early to ensure sufficient exploration; increase grid resolution when more parallel evaluations are possible.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Resource Aware Multifidelity Active Learning for Efficient Optimization', 'publication_date_yy_mm': '2020-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2464.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e2464.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>EI</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Expected Improvement</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A standard Bayesian optimization acquisition function that computes the expected positive improvement over the current best; used here as the primary AF and the backbone of MFEI.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Expected Improvement (EI)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>EI(x) = E[max(f(x) - f(x^+)-ζ, 0)], computable from GP predictive mean µ(x) and variance σ^2(x); ζ tunes exploration/exploitation. The paper uses EI as the single-fidelity AF and as the EI component inside the multifidelity MFEI.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Acquisition function in Bayesian optimization for black-box expensive functions.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>EI ranks candidate points by expected improvement; in RAAL EI values for highest fidelity are combined with α-factors for lower fidelities to create utility scores υ used by MILP.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Expected improvement in objective value (in original problem units).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>ζ parameter controls trade-off: larger ζ increases exploration by preferring uncertain regions with high σ(x) over small improvements near current best.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Improvement in objective value.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Used as AF across experiments; RAAL uses EI-derived utilities and shows improved iteration-to-optimum vs sequential BO that also used EI.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Used by baseline sequential BO as well (so comparisons isolate allocation strategy rather than AF choice).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>When the same EI is used, RAAL's resource-aware multipoint selection yields faster convergence than sequential single-point EI maximization.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Contributes to RAAL's gains when combined with parallel multipoint selection and resource-aware allocation.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Resource Aware Multifidelity Active Learning for Efficient Optimization', 'publication_date_yy_mm': '2020-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Predicting the output from a complex computer code when fast approximations are available <em>(Rating: 2)</em></li>
                <li>Multifidelity efficient global optimization: Methodology and application to airfoil shape design <em>(Rating: 2)</em></li>
                <li>Information-based multifidelity bayesian optimization <em>(Rating: 2)</em></li>
                <li>Multi-fidelity bayesian optimization with max-value entropy search <em>(Rating: 2)</em></li>
                <li>Milp models for the selection of a small set of well-distributed points <em>(Rating: 2)</em></li>
                <li>The knowledge-gradient algorithm for sequencing experiments in drug discovery <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2464",
    "paper_id": "paper-220424408",
    "extraction_schema_id": "extraction-schema-67",
    "extracted_data": [
        {
            "name_short": "RAAL",
            "name_full": "Resource Aware Active Learning",
            "brief_description": "A multipoint, multifidelity Bayesian optimization/active learning scheme that jointly selects sample locations and fidelity levels and allocates parallel computational resources via a MILP knapsack to maximize information gain under a limited computational budget.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Resource Aware Active Learning (RAAL)",
            "system_description": "RAAL is an active-learning-for-optimization system that couples (i) a multifidelity Gaussian Process (MF-GP) surrogate (autoregressive style) and acquisition functions (EI / MFEI) with (ii) a candidate-evaluation stage that computes acquisition-function values on a pre-filtered feasible candidate set and (iii) a mixed-integer linear programming (MILP) knapsack-style seeding optimizer that selects multiple points, fidelity levels and assigns them to parallel CPUs. Key components: MF-GP predictive mean/variance, Expected Improvement (EI) and Multifidelity EI (MFEI) as utilities, adaptive discretization (uniform or AF-weighted quantile gridding controlled by parameter ξ) to partition the domain into strata, decision variables p_i^{(m),g} and q_i in the MILP, objective that (hierarchically) (a) minimizes unused CPU capacity and (b) maximizes the sum of acquisition values for chosen point–fidelity pairs, and constraints enforcing per-CPU capacity, one-point-per-bin (diversity), single-CPU-per-point, and fidelity interdependence consistent with the autoregressive MF-GP.",
            "application_domain": "General expensive black-box optimization tasks, demonstrated for engineering/aerospace test problems (analytical benchmarks); applicable to design optimization, model calibration, hyperparameter tuning, and other experimental-design or automated-discovery tasks requiring expensive evaluations.",
            "resource_allocation_strategy": "Formulates selection/allocation as a knapsack-like MILP: decision variables p(m)_{i,g} = 1 if candidate i is chosen at fidelity m and assigned to CPU g, and q_i = 1 if candidate i is chosen. Objective = Υ * (aggregate unused CPU capacity) - sum_i,m,g υ_i^{(m)} p(m)_{i,g}, where υ_i^{(m)} are AF values; Υ is set &gt;&gt; sum of AF values so that maximizing resource usage is prioritized, then AF sum. Constraints enforce per-CPU capacity (sum λ(m) p ≤ β_g), at most one chosen per stratum/bin, single CPU per point, and fidelity coherence for autoregressive MF-GP. Thus selection simultaneously decides which hypotheses (x) and which fidelities (m) to evaluate and assigns them to computational units to maximize information within budget.",
            "computational_cost_metric": "Abstract computational-cost units λ(m) per fidelity (user-provided). In experiments the highest fidelity cost is 1 and lower fidelities fractional (example rule used: λ(m)=1 for m=M, λ(m)=1/5^{(M-m)} for m&lt;M). Per-CPU capacity β_g is expressed in same λ-units; total used budget B accumulates λ(m). Practically represents normalized evaluation cost (proxy for wall-clock/CPU-time).",
            "information_gain_metric": "Acquisition function values υ(x,m): single-fidelity Expected Improvement (EI) at the highest fidelity and Multifidelity Expected Improvement (MFEI) for lower-fidelity queries (EI at top fidelity multiplied by utility factors α_1 (correlation) and α_2 (noise/scaling)). The MILP sums these υ values for chosen assignments as surrogate for expected information gain.",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "Multiple mechanisms: (1) The underlying EI/MFEI acquisition function provides the classic exploration-exploitation trade-off via predictive mean/variance and a tunable ζ parameter; (2) Adaptive discretization (parameter ξ with schedule ξ_t) transitions the search grid from uniform (exploration) to AF-concentrated (exploitation) as budget is spent; (3) The MILP enforces a well-distributed selection across strata (via at-most-one-per-bin) to maintain exploration while the objective still favors high-AF points for exploitation; (4) The hierarchical MILP objective (Υ weight) prioritizes using resources fully which can increase exploration through parallel sampling.",
            "diversity_mechanism": "Explicit: domain is partitioned into E_j bins per dimension (uniform or AF-weighted quantile bins). MILP constraint enforces at most one selected point per bin (constraint (16a)), and q_i together with decoded bin indicators χ_i ensure chosen set is spread across strata. Adaptive gridding allows bins to be concentrated near AF modes or uniform depending on ξ.",
            "uses_diversity_promotion": true,
            "budget_constraint_type": "Computational-resource budget: per-CPU capacities β_g (parallel resources) and a global total budget B_max expressed in λ(m) cost-units; also iteration-wise budget tracking.",
            "budget_constraint_handling": "Encoded directly in the MILP: per-CPU capacity constraints (sum of λ(m) p(m)_{i,g} ≤ β_g), global budget tracked and used to update discretization parameter ξ (eq. 14). The MILP objective includes a large weight Υ that prioritizes maximizing usage of available computational capacity before maximizing AF value, ensuring budget is efficiently filled.",
            "breakthrough_discovery_metric": "Not defined as an explicit novelty/breakthrough score in the paper; practical proxy used is improvement in objective function (expected improvement) and distance to known global optimum. Experiments measure Root Squared Error to known optimum and number of iterations to reach optimum.",
            "performance_metrics": "Reported metrics are Root Squared Error (RSE) to known global optimum vs iterations and iterations-to-convergence under fixed total computational budget B_max. Example numerical results reported in the paper: SF Test 1 with 5 CPUs: RAAL reaches optimum in ~2.5 iterations on average vs sequential BO in ~5 iterations; SF Test 2: sequential BO ~20 iterations, RAAL ~10 iterations with 2 CPUs and &lt;5 iterations with 5 CPUs (B_max=30); MF Test 2: RAAL often finds global optimum in ~5 iterations with 5 CPUs (B_max=20); high-dimensional Rosenbrock (d=8) MF: RAAL achieved a smaller final error in a fraction of iterations compared to sequential BO (B_max varied 30–80). All experiments report medians over 20 randomized runs and 25–75% percentile bands.",
            "comparison_baseline": "Standard sequential Bayesian Optimization (single-point-per-iteration BO using the same GP surrogate and acquisition function but run on a single CPU), i.e., sequential BO.",
            "performance_vs_baseline": "RAAL consistently converged faster and more robustly than sequential BO across benchmarks. Representative comparisons: SF Test1 (5 CPUs): RAAL 2.5 iterations vs sequential 5; SF Test2: sequential 20 iterations vs RAAL 10 (2 CPUs) and &lt;5 (5 CPUs); MF Test2: RAAL found the global optimum where SF sometimes failed. RAAL also reduced inter-run variability.",
            "efficiency_gain": "Described as a 'major speed up' in the paper. Representative numeric gains: ~2× speedup (20→10 iterations) or up to ~4× (20→5) in some cases; ~2× improvement in iterations for SF Test1 example (5→2.5). Gains depend on number of CPUs, grid resolution and use of multifidelity information.",
            "tradeoff_analysis": "Paper analyzes interaction between grid resolution (E), adaptive-gridding learning rate (η_ξ), number of CPUs, and multifidelity availability: (i) finer grid (larger E) aids multimodal problems and benefits when many CPUs are available; (ii) higher η_ξ (faster shift to exploitation) can hurt performance on highly multimodal single-fidelity problems by reducing exploration; (iii) multifidelity access reduces sensitivity to η_ξ and generally improves ability to explore (lower-fidelity cheap evaluations allow more samples); (iv) MILP objective weighting prioritizes resource usage over AF maximization, which the authors argue leads to better wall-clock performance when parallel resources are limited. Overall, balancing exploration/exploitation and resource usage is controlled via ξ schedule, E, η_ξ, and Υ.",
            "optimal_allocation_findings": "Key recommendations/insights: (1) prioritize filling available parallel resources (maximize CPU utilization) and then maximize summed AF across chosen assignments (implemented via large Υ), (2) select multiple well-distributed candidate points per iteration rather than greedy single-point maximization, (3) exploit cheaper lower-fidelity models to sample more points and improve exploration (multifidelity gives major advantages), (4) adapt discretization from exploration to exploitation as budget is consumed (use ξ schedule), and (5) enforce fidelity coherence consistent with autoregressive MF-GP. These principles produced faster convergence in all demonstrated benchmarks.",
            "uuid": "e2464.0",
            "source_info": {
                "paper_title": "Resource Aware Multifidelity Active Learning for Efficient Optimization",
                "publication_date_yy_mm": "2020-07"
            }
        },
        {
            "name_short": "MFEI",
            "name_full": "Multifidelity Expected Improvement (Augmented EI)",
            "brief_description": "An acquisition function for multifidelity Bayesian optimization that multiplies the Expected Improvement (at the highest fidelity) by utility factors that discount lower-fidelity usefulness based on correlation and noise.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "Multifidelity Expected Improvement (MFEI / Augmented EI)",
            "system_description": "MFEI is defined as MFEI(x,m) = EI(x) * α_1(x,m) * α_2(x,m), where EI(x) is the Expected Improvement at the highest fidelity, α_1(x,m) is a correlation-based discount factor corr(f^{(m)}(x), f^{(M)}(x)) (reducing utility for lower fidelities), and α_2(x,m) accounts for observational noise (equals 1 in deterministic settings). In this paper MFEI values υ_i^{(m)} are used as the utility scores for candidate point–fidelity pairs in the RAAL MILP.",
            "application_domain": "Multifidelity Bayesian Optimization for black-box expensive functions.",
            "resource_allocation_strategy": "Scores candidate (x,m) pairs by their MFEI value; these scores are input to the RAAL MILP which then allocates resources (which points/m fidelities to evaluate) under capacity constraints to maximize aggregate MFEI subject to resource usage priorities.",
            "computational_cost_metric": "MFEI itself does not include cost; in RAAL it is combined with per-fidelity cost λ(m) in the MILP constraints.",
            "information_gain_metric": "Based on Expected Improvement (expected gain in objective value) at the highest fidelity, modulated by α_1 and α_2 to reflect fidelity correlation and noise.",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "Retains EI's exploration/exploitation trade-off through predictive mean/variance and ζ; lower-fidelity contributions are downweighted by α_1 so selection prefers higher-fidelity EI when correlation is low.",
            "diversity_mechanism": null,
            "uses_diversity_promotion": null,
            "budget_constraint_type": null,
            "budget_constraint_handling": null,
            "breakthrough_discovery_metric": null,
            "performance_metrics": null,
            "comparison_baseline": null,
            "performance_vs_baseline": null,
            "efficiency_gain": null,
            "tradeoff_analysis": "Paper notes α_1 discounts lower fidelity utility and α_2 accounts for noise; deterministic α_2=1. MFEI is compatible with RAAL's resource-aware selection by providing per-(x,m) utility.",
            "optimal_allocation_findings": "MFEI provides a straightforward, computationally tractable way to include fidelity choice in acquisition scoring; when combined with explicit cost-aware selection (MILP) it supports resource-aware multifidelity sampling.",
            "uuid": "e2464.1",
            "source_info": {
                "paper_title": "Resource Aware Multifidelity Active Learning for Efficient Optimization",
                "publication_date_yy_mm": "2020-07"
            }
        },
        {
            "name_short": "MF-BO",
            "name_full": "Multifidelity Bayesian Optimization (general)",
            "brief_description": "The extension of Bayesian optimization to multiple information sources/fidelity levels, combining them in a single surrogate (e.g., autoregressive MF-GP) and using multifidelity acquisition functions to choose both locations and fidelities to query.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "Multifidelity Bayesian Optimization",
            "system_description": "Combines autoregressive multifidelity Gaussian Processes (f^{(m)} related via f^{(m)}(x)=ρ f^{(m-1)}(x)+δ^{(m)}(x)) to jointly model multiple fidelity levels, and uses multifidelity acquisition functions (MFEI, MFES, etc.) to decide both x and m. In RAAL the MF-BO surrogate provides predictive mean/variance at all fidelities and supplies acquisition values used by the resource allocation MILP.",
            "application_domain": "Black-box optimization with multiple approximation/simulator fidelities (engineering design, simulation-based optimization).",
            "resource_allocation_strategy": "Chooses both sample location and fidelity, guided by multifidelity acquisition functions; in RAAL these choices are combined with an explicit resource-allocation MILP that accounts for evaluation costs λ(m) and CPU capacities β_g.",
            "computational_cost_metric": "Per-fidelity cost λ(m) (normalized); total budget B_max.",
            "information_gain_metric": "Acquisition functions (MFEI, entropy-based methods) that quantify expected utility from querying (x,m).",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "Acquisition functions encode the trade-off; RAAL augments this with multipoint selection and diversity constraints to foster exploration.",
            "diversity_mechanism": null,
            "uses_diversity_promotion": null,
            "budget_constraint_type": "Computational budget, evaluation cost per fidelity.",
            "budget_constraint_handling": "Handled by RAAL's MILP when used; otherwise typical MF-BO methods may use cost-aware acquisition heuristics.",
            "breakthrough_discovery_metric": "Typically improvement in objective or reduction in posterior uncertainty; not given a separate novelty metric in this paper.",
            "performance_metrics": "In experiments multifidelity RAAL often outperforms single-fidelity RAAL and sequential BO, e.g., MF Test2 RAAL reaches global optimum more reliably and faster than SF counterparts.",
            "comparison_baseline": "Sequential single-fidelity BO and RAAL single-fidelity variants.",
            "performance_vs_baseline": "MF RAAL benefits from low-fidelity cheap evaluations to sample more candidates per iteration, enabling faster exploration and more robust convergence (examples in paper: MF Test2 shows RAAL achieves global optimum where SF sometimes fails).",
            "efficiency_gain": "Multifidelity availability allowed RAAL to seed more points per iteration for same budget, leading to faster convergence (examples: MF Test2 often reaches the optimum in ~5 iterations with 5 CPUs).",
            "tradeoff_analysis": "Paper discusses that multifidelity reduces sensitivity to adaptive-gridding hyperparameters and allows a different exploration/exploitation balance (more exploration possible because of cheaper low-fidelity samples).",
            "optimal_allocation_findings": "Using cheaper lower-fidelity models strategically to increase sample counts per iteration is beneficial; resource-aware scheduling of fidelities via cost-aware selection (e.g. MFEI scores combined with λ(m) in MILP) yields better wall-clock/iteration performance.",
            "uuid": "e2464.2",
            "source_info": {
                "paper_title": "Resource Aware Multifidelity Active Learning for Efficient Optimization",
                "publication_date_yy_mm": "2020-07"
            }
        },
        {
            "name_short": "MILP-knapsack seeding",
            "name_full": "Mixed-Integer Linear Programming knapsack-based multipoint multifidelity seeding",
            "brief_description": "A MILP formulation that selects multiple candidate points and their fidelity assignments and assigns them to parallel CPUs to maximize aggregate acquisition-value subject to per-CPU capacities, diversity (one-per-bin) and fidelity-coherence constraints.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "MILP knapsack-based seeding optimizer",
            "system_description": "Decision variables: binary p(m)_{i,g} (point i at fidelity m assigned to CPU g) and q_i (point i chosen). Objective: minimize Υ*(unused CPU capacity) - sum υ_i^{(m)} p(m)_{i,g} (Υ &gt;&gt; sum υ ensures resource usage prioritized). Key constraints: (16a) at most one chosen point per bin/stratum, (16b) per-CPU capacity ∑ λ(m) p ≤ β_g, (16c)-(16d) logical link between p and q, (16e) one CPU per (i,m), and (16f) fidelity interdependence for autoregressive GP (ensures consistency among fidelities). Implemented with PuLP and COIN CLP/CBC in experiments.",
            "application_domain": "Resource-aware selection/seeding in multipoint Bayesian optimization under parallel/distributed computational resources.",
            "resource_allocation_strategy": "Optimizes a knapsack objective to (a) pack evaluations into available CPU capacities and (b) choose assignments that maximize cumulative acquisition utility. It directly assigns evaluations to computational units respecting per-unit capacity, so it handles both which experiments to run and where to run them in a parallel environment.",
            "computational_cost_metric": "Per-fidelity costs λ(m) and per-CPU capacities β_g; objective includes unused-capacity term measured in same λ-units.",
            "information_gain_metric": "Per-(x,m) acquisition values υ_i^{(m)} (EI / MFEI) summed in objective as proxy for information gained by chosen set.",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "Diversity constraints (one-per-bin) enforce spread/exploration; the MILP objective promotes assigning high-AF points for exploitation but only after capacity usage is prioritized via Υ; adaptive discretization upstream shapes bins to shift between exploration and exploitation.",
            "diversity_mechanism": "Explicit at-most-one-per-bin constraint (16a) ensuring chosen points are well-distributed across strata.",
            "uses_diversity_promotion": true,
            "budget_constraint_type": "Per-CPU capacity constraints and aggregate budget tracked externally.",
            "budget_constraint_handling": "Hard constraints in the MILP (16b); objective includes term prioritizing full capacity utilization to minimize wasted budget.",
            "breakthrough_discovery_metric": null,
            "performance_metrics": "Used as the core selection mechanism in RAAL; contributes to the iteration-level performance gains reported for RAAL (see RAAL performance metrics).",
            "comparison_baseline": "Implicit baseline is greedy pointwise maximization of AF (standard BO); experiments compare full RAAL (including MILP) to sequential BO (greedy single point).",
            "performance_vs_baseline": "By optimizing multi-point selections and packing them into CPUs, MILP-based seeding enables RAAL to outperform sequential BO in iteration count to optimum and robustness; see RAAL numeric examples.",
            "efficiency_gain": "Contributes to RAAL's 2×–4× reductions in iterations-to-convergence in reported benchmarks by enabling parallel, well-distributed, cost-aware seeding.",
            "tradeoff_analysis": "Objective weighting (Υ) creates explicit tradeoff: filling CPU time (exploration via more samples) vs maximizing summed AF (exploitation); choice of Υ and discretization parameters (E, ξ, η_ξ) control this tradeoff.",
            "optimal_allocation_findings": "Formulating multipoint multifidelity seeding as an MILP knapsack that (a) enforces diversity and (b) prioritizes CPU utilization leads to better wall-clock efficiency than greedy single-point schemes; fidelity-coherent constraints are necessary for correct MF-GP updates.",
            "uuid": "e2464.3",
            "source_info": {
                "paper_title": "Resource Aware Multifidelity Active Learning for Efficient Optimization",
                "publication_date_yy_mm": "2020-07"
            }
        },
        {
            "name_short": "Adaptive Gridding",
            "name_full": "Adaptive AF-weighted discretization (adaptive gridding)",
            "brief_description": "A discretization technique mapping candidate points to per-dimension strata using acquisition-function quantiles (parameter ξ) to concentrate bins around AF modes and thereby tune exploration vs exploitation.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Adaptive AF-weighted discretization (Adaptive Gridding)",
            "system_description": "Two modes: uniform gridding (equal-length bins per dimension) and AF-weighted adaptive gridding where points with AF below a quantile ξ are removed and remaining points per-dimension are binned by AF quantiles Q^e_j. The mapping Ξ(x,ξ) assigns candidate points to strata; ξ is adaptively updated per iteration via ξ_t = ξ_max * (1 - exp(-η_ξ * (B / B_max - B))) (see eq. 14) to move from exploration (ξ≈0 uniform) to exploitation (ξ&gt;0 concentrating bins near AF peaks). The discretized χ_i feed the MILP which enforces at-most-one-per-bin for diversity.",
            "application_domain": "Candidate selection and diversity enforcement in multipoint Bayesian optimization.",
            "resource_allocation_strategy": "Shapes candidate strata so that MILP selection picks points that are both high-utility (AF) and well-distributed according to the chosen gridding; ξ schedule is used to shift allocation behavior as budget is consumed.",
            "computational_cost_metric": null,
            "information_gain_metric": "Uses AF values to construct quantile-based bins; AF thus directly shapes bin placement and therefore the information gain distribution of chosen points.",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "Direct: ξ controls how much the discretization favors AF modes (exploitation) vs uniform coverage (exploration). The learning-rate η_ξ and ξ_max tune how quickly the algorithm transitions to exploitation as budget is spent.",
            "diversity_mechanism": "Yes — works with MILP's per-bin selection constraints to ensure selections are spread over the adaptive grid.",
            "uses_diversity_promotion": true,
            "budget_constraint_type": "Adaptive parameter ξ is updated based on fraction of budget used (B/B_max).",
            "budget_constraint_handling": "ξ_t update formula (eq. 14) uses current budget consumed to change discretization; thus budget depletion drives exploitation.",
            "breakthrough_discovery_metric": null,
            "performance_metrics": "Empirical findings: finer grid (larger E) improves performance for highly multimodal problems when many CPUs are available; high learning rates η_ξ that concentrate quickly on exploitation can hurt performance in single-fidelity multimodal problems; multifidelity reduces sensitivity to η_ξ.",
            "comparison_baseline": "Uniform gridding (ξ=0)",
            "performance_vs_baseline": "Adaptive gridding with appropriate ξ/η_ξ improved convergence in several benchmarks compared to uniform gridding, but mis-tuned parameters can degrade performance.",
            "efficiency_gain": "Contributes to RAAL's faster convergence by trading early exploration for focused exploitation later, when budget is low and accurate AF peaks are known.",
            "tradeoff_analysis": "Paper reports the interplay between grid resolution E, learning rate η_ξ, and number of CPUs: coarse grid + many CPUs → exploration bias; fine grid + few CPUs → over-exploitation; tune grid/resolution to CPU count and problem multimodality.",
            "optimal_allocation_findings": "Adaptively concentrate bins near AF modes as budget depletes, but use more uniform bins early to ensure sufficient exploration; increase grid resolution when more parallel evaluations are possible.",
            "uuid": "e2464.4",
            "source_info": {
                "paper_title": "Resource Aware Multifidelity Active Learning for Efficient Optimization",
                "publication_date_yy_mm": "2020-07"
            }
        },
        {
            "name_short": "EI",
            "name_full": "Expected Improvement",
            "brief_description": "A standard Bayesian optimization acquisition function that computes the expected positive improvement over the current best; used here as the primary AF and the backbone of MFEI.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "Expected Improvement (EI)",
            "system_description": "EI(x) = E[max(f(x) - f(x^+)-ζ, 0)], computable from GP predictive mean µ(x) and variance σ^2(x); ζ tunes exploration/exploitation. The paper uses EI as the single-fidelity AF and as the EI component inside the multifidelity MFEI.",
            "application_domain": "Acquisition function in Bayesian optimization for black-box expensive functions.",
            "resource_allocation_strategy": "EI ranks candidate points by expected improvement; in RAAL EI values for highest fidelity are combined with α-factors for lower fidelities to create utility scores υ used by MILP.",
            "computational_cost_metric": null,
            "information_gain_metric": "Expected improvement in objective value (in original problem units).",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "ζ parameter controls trade-off: larger ζ increases exploration by preferring uncertain regions with high σ(x) over small improvements near current best.",
            "diversity_mechanism": null,
            "uses_diversity_promotion": false,
            "budget_constraint_type": null,
            "budget_constraint_handling": null,
            "breakthrough_discovery_metric": "Improvement in objective value.",
            "performance_metrics": "Used as AF across experiments; RAAL uses EI-derived utilities and shows improved iteration-to-optimum vs sequential BO that also used EI.",
            "comparison_baseline": "Used by baseline sequential BO as well (so comparisons isolate allocation strategy rather than AF choice).",
            "performance_vs_baseline": "When the same EI is used, RAAL's resource-aware multipoint selection yields faster convergence than sequential single-point EI maximization.",
            "efficiency_gain": "Contributes to RAAL's gains when combined with parallel multipoint selection and resource-aware allocation.",
            "uuid": "e2464.5",
            "source_info": {
                "paper_title": "Resource Aware Multifidelity Active Learning for Efficient Optimization",
                "publication_date_yy_mm": "2020-07"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Predicting the output from a complex computer code when fast approximations are available",
            "rating": 2,
            "sanitized_title": "predicting_the_output_from_a_complex_computer_code_when_fast_approximations_are_available"
        },
        {
            "paper_title": "Multifidelity efficient global optimization: Methodology and application to airfoil shape design",
            "rating": 2,
            "sanitized_title": "multifidelity_efficient_global_optimization_methodology_and_application_to_airfoil_shape_design"
        },
        {
            "paper_title": "Information-based multifidelity bayesian optimization",
            "rating": 2,
            "sanitized_title": "informationbased_multifidelity_bayesian_optimization"
        },
        {
            "paper_title": "Multi-fidelity bayesian optimization with max-value entropy search",
            "rating": 2,
            "sanitized_title": "multifidelity_bayesian_optimization_with_maxvalue_entropy_search"
        },
        {
            "paper_title": "Milp models for the selection of a small set of well-distributed points",
            "rating": 2,
            "sanitized_title": "milp_models_for_the_selection_of_a_small_set_of_welldistributed_points"
        },
        {
            "paper_title": "The knowledge-gradient algorithm for sequencing experiments in drug discovery",
            "rating": 1,
            "sanitized_title": "the_knowledgegradient_algorithm_for_sequencing_experiments_in_drug_discovery"
        }
    ],
    "cost": 0.024857999999999998,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Resource Aware Multifidelity Active Learning for Efficient Optimization</p>
<p>F Grassi 
United Technologies Research Centre Ireland, Ltd, Cork City
Ireland</p>
<p>G Manganini 
United Technologies Research Centre Ireland, Ltd, Cork City
Ireland</p>
<p>Gran Sasso Science Institute, L'Aquila
Italy</p>
<p>M Garraffa 
United Technologies Research Centre Ireland, Ltd, Cork City
Ireland</p>
<p>University College Cork
Cork CityIreland</p>
<p>L Mainini 
United Technologies Research Centre Ireland, Ltd, Cork City
Ireland</p>
<p>Resource Aware Multifidelity Active Learning for Efficient Optimization</p>
<p>Traditional methods for black box optimization require a considerable number of evaluations which can be time consuming, unpractical, and often unfeasible for many engineering applications that rely on accurate representations and expensive models to evaluate. Bayesian Optimization (BO) methods search for the global optimum by progressively (actively) learning a surrogate model of the objective function along the search path. Bayesian optimization can be accelerated through multifidelity approaches which leverage multiple black-box approximations of the objective functions that can be computationally cheaper to evaluate, but still provide relevant information to the search task. Further computational benefits are offered by the availability of parallel and distributed computing architectures whose optimal usage is an open opportunity within the context of active learning. This paper introduces the Resource Aware Active Learning (RAAL) strategy, a multifidelity Bayesian scheme to accelerate the optimization of black box functions. At each optimization step, the RAAL procedure computes the set of best sample locations and the associated fidelity sources that maximize the information gain to acquire during the parallel/distributed evaluation of the objective function, while accounting for the limited computational budget. The scheme is demonstrated for a variety of benchmark problems and results are discussed for both single fidelity and multifidelity settings. In particular we observe that the RAAL strategy optimally seeds multiple points at each iteration allowing for a major speed up of the optimization task.</p>
<p>Introduction</p>
<p>O ptimization problems are common in aerospace science and engineering. Practical examples include the design of vehicles, systems and structures, which require the evaluation of disciplinary models and objective functions that are frequently treated as black-box functions. Typically, an optimization algorithm operates sequentially by evaluating the objective function at a given point based on its previous evaluations till some stopping criteria is met. When the evaluation of the function is expensive, traditional methods for black-box optimization -in which a considerable number of evaluations is required -are poorly suited for such applications. Surrogate Based Optimization (SBO) can significantly improve the efficiency of the optimization procedure: the available information is exhausted and synthetized into a surrogate model to lower the amount of required expensive function evaluations thus saving time, resources and the associated costs [1,2,3,4,5,6]. Efficiency can be further improved in a multifidelity setting, where we have cheaper, but potentially biased approximations to the function that can be used to assist the search of optimal points [7,8,9,10,11,12]. Within this context, we propose a scheme for resource-aware multifidelity active learning to reduce the computational time and cost associated with the optimization of black-box functions. We aim to achieve this goal through the optimal exploitation of computational budgets (time and computing resources) and of the information contained in the surrogate model (continuously updated while searching for the optimum).</p>
<p>Multifidelity active learning for the optimization of black-box functions has been popularly studied in the Bayesian Optimization (BO) setting [13,14,15], which consists of two components: (i) a Bayesian statistical model to approximate the objective function, and (ii) an acquisition function to decide where to sample next [16,17]. The statistical models are almost invariably Gaussian Processes (GP), for their capability to model arbitrary complex functions, analytical tractability and profitability to estimate uncertainty in a probabilistic framework [18,8,7,19,20]. The search for the optimum is guided by an acquisition function -computed on the statistical surrogate model -which defines a metric for evaluating the next point to sample, balancing the trade-off between a global exploration and a local exploitation of the surrogate. The BO framework for the multifidelity settings combines different information sources (the objective function and its approximations at different levels of fidelity) into a single surrogate model and implements active learning strategies by adaptively sampling from different fidelity levels.</p>
<p>Multifidelity Bayesian Optimization is largely explored in the literature [21,22,23,24]. However, many challenges are still open to the research community. The optimization of the multifidelity acquisition function is of critical importance for the implementation of an effective active learning strategy, and it may be computationally demanding: in real-world physics-based problems (e.g. the design of aerospace systems and vehicles), the acquisition function is defined over multidimensional domains and subject to non-trivial/non-convex constraints limiting the space of feasible and acceptable solutions [25,26,27]. Moreover, the rationale behind the construction and optimization of the acquisition function, at each sampling step, is the balance between exploration and exploitation thrusts: exploitation involves greedily improving over an already good point and exploration is the attempt to gain information about the optimum in under-explored regions. This motivates the interest not only for the point-wise maximization of the acquisition function, but also for its overall form and shape assumed over the entire search domain. This aspect is crucial within an active learning process and contributes to the knowledge acquisition and uncertainty reduction towards the optimization of the black-box function. Finally, BO approaches commonly meet difficulties in optimally exploiting a given computational budget and greedy strategies are usually adopted, which simply maximize the acquisition function point-wise.</p>
<p>Stemming from these open challenges, this paper proposes a scheme for resource-aware multifidelity active learning to assist/inform and accelerate optimization. In particular, we present a computational approach to enable: (i) constraints-aware, space filling sampling; (ii) optimal allocation of available resources at each single step, including leveraging parallel computing architectures at best through the optimal distribution of sample evaluations; (iii) optimally informative multipoint and multifidelity sampling at each step.</p>
<p>To achieve these goals, we formulate the sampling task at each step of the BO as a knapsack problem to select multiple points and allocate resources for their evaluation. Specifically, this means identifying the best candidate locations and the associated fidelity sources in order to maximize the information gain that can be acquired during a parallel evaluation of the objective function, while accounting for the limited computational budget. Differently from most of the approaches, rather than explicitly optimizing the acquisition function [28], we evaluate it on a set of feasible points checked beforehand and then consider the problem of selecting an appropriate subset of candidate points with good informative properties, coherently with a knapsack problem approach. By splitting the feasibility check and the points selection tasks, it is possible to fast optimize even complex multifidelity acquisition functions constrained over a non-convex domain. The knapsack problem is implemented as a mixed-integer linear programming (MILP) model over the candidate points within the feasible domain. The domain is partitioned into strata to capture multiple features of the acquisition function by sampling it in wisely distributed locations [29]. During the (active) learning process the choice of the sampling locations is driven and refined at each step through adaptive discretization techniques. The optimized sampling procedure is aware of the computational time budget and of the parallel computing resources available, which are therefore leveraged to balance the trade-off between exploration and exploitation in a principled way. In addition, the optimal use of the available resources for the learning process permits a major contraction of the time required to approach and eventually achieve (or closely approximate) the optimum.</p>
<p>The paper is organized as follows. Section 2 discusses the setup of the Bayesian Optimization problem and its extension to multifidelity formulations. Section 3 introduces the Resource Aware Active Learning scheme (RAAL for short) with formulations for multipoint and multifidelity adaptive sampling. Section 4 demonstrates the RAAL scheme for the multifidelity optimization of a variety of standard analytical test functions and for classical benchmark problems. Finally, Section 5 summarizes the concluding remarks.</p>
<p>2 Optimization framework</p>
<p>Bayesian Optimization</p>
<p>Bayesian Optimization (BO) is a class of machine learning techniques for the efficient optimization of expensive black-box functions [16,17]. Let consider the constrained optimization problem in the form: min
x∈A f (x).(1)
where x ∈ R d is the input, A is a feasible set in which it is easy to assess membership, and f (x) ∈ R is the continuous objective function. In this context, the term black-box denotes functions that lack of any special structure, as concavity or linearity, or for which derivatives are not known. This is the case in a wide range of applications, such as design of engineering and control systems [30,31,32], design of laboratory experiments [33,34], model calibration [35], reinforcement learning [36,16,37], and hyperparameter tuning of machine learning algorithms [38,39]. In the following, we will denote f (x * ) the solution to problem (1), and x * its location. The BO framework consists of two components: a Bayesian surrogate model for modelling the objective function, and an Acquisition Function (AF) for deciding where to sample next. The surrogate models are frequently in the form of Gaussian Processes (GP) that can provide efficient representations of complex functions and characterize model uncertainty in probabilistic frameworks (Section 2.1.1). The search for the optimum is guided by an acquisition function defined on the statistical surrogate and defines a metric for evaluating the next point to sample through a continuous trade-off between a global exploration and a local exploitation of the surrogate (Section 2.1.2).</p>
<p>Gaussian processes</p>
<p>The main building block of our approach is the Gaussian Process regression [18]. Let consider a dataset of n paired input/output observations D n = {(x i , y(x i ))} n i=1 , with x i ∈ R d and y(x i ) ∈ R, generated by the unknown mapping function y(x) = f (x) + , where ∼ N (0, σ ) is the measurement noise. The GP regression defines a supervised problem in which we associate to the function f a GP prior having mean 0 and covariance function κ : R d → R, such that
f ∼ GP (0, κ(x, x )).(2)
Denoting K ∈ R n×n the kernel matrix, such that K(i, j) = κ(x i , x j ), and κ n (x) . =(κ(x, x 1 ), . . . , κ(x, x n )), the predictive distribution of the GP is defined by the mean function µ(x) and the variance function σ 2 (x)
µ(x) = κ n (x) (K + σ I) −1 y (3a) σ 2 (x) = κ(x, x) − κ n (x) (K + σ I) −1 κ n (x),(3b)
where y . = (y(x 1 ), . . . , y(x n )) and I the n-dimensional identity matrix.</p>
<p>Acquisition function</p>
<p>Once we have a statistical model to represent our belief about the unknown function f given D n , we need a sampling strategy or policy for selecting the new query point x n+1 . In Bayesian optimization, the selection strategy utilizes the posterior distribution to guide the search and usually consists in the maximization of a quantity that measures how much information this query will provide, i.e. its expected utility. More formally, the unknown objective function f will be evaluated at x n+1 = arg max x υ(x | D n ) where υ(·) is the Acquisition Function (AF). Common acquisition functions are the Probability of Improvement (PI) [40], Expected Improvement (EI) [1], entropy Search (ES) [41] and Predictive Entropy Search (PES) [42]. The results of this work are obtained using the EI, which, given its analytical tractability and good trade-off between computational cost and accuracy, is the most widely used in the literature [1]. The Expected Improvement is defined as
EI(x) = E[max(f (x) − f (x + ), 0)] = (µ(x) − f (x + ) − ζ)Φ(Z) + σ(x)φ(Z) if σ(x) &gt; 0 0, if σ(x) = 0(4)
where µ(x) and σ(x) are the predictive in equations in (3), f (x + ) is the value of the best sample so far and x + is the location of that sample. Φ and φ are the cumulative distribution function (CDF) and the probability density function (PDF) of the standard normal distribution, respectively, and Z the standardized improvement
Z =    (µ(x) − f (x + ) − ζ) σ(x) if σ(x) &gt; 0 0, if σ(x) = 0.(5)
The parameter ζ allows to tune the trade-off between exploration and exploitation, determining the relative importance of the posterior mean µ(x) with respect to the potential improvement in region with high uncertainty, i.e. large σ(x).</p>
<p>Multifidelity Bayesian Optimization</p>
<p>Multifidelity optimization approaches leverage the availability of analysis models characterized by different levels of fidelity. Typically, high fidelity models consist of ground-truth observations, which are costly to obtain, and/or accurate computer representations of the physics which can be expensive to evaluate. Cheap low-fidelity models may come in various forms: coarser discretizations and resolutions of numerical models, simplified representations which neglect physical effects included in the more expensive high-fidelity models, or approximations through surrogate modeling techniques.</p>
<p>Multifidelity Gaussian processes</p>
<p>The Gaussian process regression can be extended to combine different sources of information in a single probabilistic model. For this purpose, let assume that y (1) (x), . . . , y (M ) (x) observation values are available at M different fidelity levels, where y (1) (x) is the lowest fidelity and y (M ) (x) the highest. The training dataset
D n = {(x i , y (m i ) (x i ), m i )} n i=1
is then composed by the paired input/output observation (x i , y (m i ) (x i )), generated by the m i unknown mapping function y (m) (x) = f (m) (x) + , where the measurement noise ∼ N (0, σ ) is assumed to have the same distribution over the fidelities. In this setting, the multifidelity Gaussian process regression (MF-GP) can be formulated using an autoregressive scheme [7], where the lowest fidelity function is characterized by a GP prior f (1) ∼ GP (0, κ 1 (x, x )) with kernel function κ 1 : R d×d → R, and the higher fidelities are defined recursively as
f (m) (x) = ρf (m−1) (x) + δ (m) (x) m = 2, . . . , M(6)
where ρ is a constant factor that scales the contribution of the preceding fidelity to the following one, and δ (m) (x) ∼ GP (0, κ m (x, x )) models the bias between fidelities. The autoregressive formulation implies the following
cov f (m) (x), f (m−1) (x ) f (m−1) (x) = 0 ∀x = x ,(7)
which can be interpreted as a Markov property: given the point
f (m−1) (x), we can learn nothing more about f (m) (x) from any other model evaluation f (m−1) (x ), for x = x [7, 43]. A kernel function between a pair of samples {(x i , y (m i ) (x i ), m i ), (x j , y (m j ) (x j ), m j )} can be written as κ((x i , m i ), (x j , m j )) = cov f (m i ) (x i ), f (m j ) (x j ) .(8)
Denoting K ∈ R n×n the kernel matrix, such that K(i, j) = κ((x i , m i ), (x j , m j )), the predictive distribution of the MF-GP is defined by the predictive mean and variance
µ (m) (x) = κ (m) n (x) (K + σ I) −1 y (9a) σ 2(m) (x) = κ((x, m), (x, m)) − κ (m) n (x) (K + σ I) −1 κ (m) n (x),(9b)
where κ n (x) . = (κ((x, m), (x 1 , m 1 )), . . . , κ((x, m), (x n , m n ))) and y . = (y (m 1 ) (x 1 ), . . . , y (mn) (x n )) .</p>
<p>Multifidelity acquisition function</p>
<p>The availability of multiple fidelity levels poses a new challenge for the Bayesian Optimization: not only we have to determine the location of the new sample to evaluate, but also the most convenient fidelity level to query. Different approaches can be found in the literature, as Multifidelity Expected Improvement (MFEI) [44], Multifidelity Predictive Entropy Search (MFES) [45] or Multifidelity Max-value Entropy Search [15]. For consistency, our formulation is based on the MFEI, which preserves the good properties of its single fidelity counterpart. The MFEI (or Augmented EI) [44] is defined as
MFEI(x, m) = E[max(f (M ) (x) − f (M ) (x + ), 0)]α 1 (x, m)α 2 (x, m),(10)
where the first term is simply the EI evaluated at the highest fidelity, therefore can be simply derived from (4). The utility functions α 1 (x, l) and α 2 (x, l) are defined as
α 1 (x, m) = corr f (m) (x), f (M ) (x) (11) α 2 (x, m) = 1 − σ σ 2(m) (x) + σ 2 ,(12)
where α 1 (x, m) is designed to discount the utility when a lower fidelity evaluation is considered, whereas α 2 (x, m) takes into account the stochastic nature of the unknown function f due to the presence of noise, therefore for deterministic problems is α 2 (x, l) = 1. The function α 1 (x, m) has been chosen to be straightforward to compute under the assumptions of the GP regression, and it holds α 1 (x, M ) = 1 and, for deterministic problems,
α 1 (x, m) = 0 if (x, y (m) (x), m) ∈ D n .
For a more detailed analysis of the MFEI, please refer to [44].</p>
<p>Algorithm 1: Resource-Aware Active Learning (RAAL) Algorithm
Input: Feasible set P ⊂ R d , multifidelity objective function f (), priors GP (0, κ m (x, x )), parallel CPUs budget {β g } G g=1
Output: (Approximate) Solution x * to (1)
Select initial points S 0 ⊂ P with associated fidelities M 0 t ← 0, B ← 0 repeat // Parallel function evaluation D nt ← Evaluate f () at points x ∈ S t at fidelities m ∈ M t on G parallel CPUs P ← P \ S t // Learn/Update surrogate model Update posteriors µ (m) , σ 2(m) in (9) based on D n 0 :nt . ={D n 0 , . . . , D nt } // Multipoint multifidelity seeding begin ∀x i ∈ P Discretize points: χ i ← Ξ(x i , ξ t ) /<em> Section 3.2 </em>/ Evaluate the AF: υ (m) i ← υ(x i , m), ∀m ∈ [M ] end S t+1 , M t+1 ← Solve (16) based on {χ i } N i=1 , {υ (m) i } N,M i=1,m=1 , {λ (m) } M m=1 , {β g } G g=1 /<em> Section 3.3 </em>/ // Next iteration B ← B + m∈Mt λ (m) Update ξ t by (14) t ← t + 1 until Stop criteria is met on iterations t &lt; t max or used budget B &lt; B max return Point x with minimum y (M ) (x) over the whole dataset D n 0 :nt 3 Resource-Aware Active Learning
The computational improvements introduced by the adoption of multifidelity surrogates can be further enhanced by the optimal use of parallel or distributed computing architectures. This section introduces our Resource-Aware Active Learning algorithm (RAAL, for short) that leverages the availability of multiple sources of information at different levels of fidelity in conjunction with the possibility to distribute the evaluations across multiple computational resources (CPUs) in parallel. Section 3.1 outlines the main steps of the RAAL algorithm. We then discuss the two elements representing the core of the approach: the multipoint exploration/exploitation of the AF, in Section 3.2, and the optimization procedure for the multipoint multifidelity seeding in Section 3.3. In the following, for the sake of compactness, we write [n] for {1, . . . , n}.</p>
<p>Overview</p>
<p>In the conventional BO, one point is selected at each iteration and evaluated at a prescribed fidelity level. This information is then used to learn/update the surrogate model and the associated AF, before the next point selection can be made. In the remaining of this paper, this conventional BO is referred to as sequential BO. Differently, the RAAL scheme samples multiple points across different fidelities at each iteration. In addition, the RAAL scheme optimally allocates the computational resources available to take most advantage of parallel computing and/or distributed computing architectures.</p>
<p>We describe here the main steps of the RAAL strategy (Algorithm 1). We start from an initial set of feasible points P = {x 1 , . . . , x N } ⊂ R d that can be assembled through any Design of Experiment (DOE) procedure, for instance a Latin Hypercube Design (LHD), and then remove the unfeasible points x / ∈ A. At the first iteration t = 0, a subset S 0 of n 0 points is selected together with a set of fidelity levels M 0 and used to run the first evaluations of the function f , and hence obtain the dataset D n 0 employed to learn an initial surrogate model f (M ) and the associated AF, as described in Section 2. At this point, similarly to the sequential BO, the RAAL algorithm optimizes the AF, but with the notable difference of selecting a subset of points S 1 ⊂ P \ S 0 together with the associated fidelity levels M 1 . At the next iteration t = 1, parallel computational resources are used to built simultaneously the dataset D n 1 , where n 1 &gt; 1, and, similarly to the sequential BO, the optimization loop is executed based on the augmented dataset D n 0 :n 1 . ={D n 0 , D n 1 }. As it will be showed in the numerical results of Section 4, the seeding of more than one point at each BO iteration significantly speeds up the overall computational time, mitigating the impact of the main bottleneck in the BO process, i.e. the evaluation of the black-box function f . The process is then iterated till a maximum number of iterations t max or a maximum computational budget B max is reached.</p>
<p>The RAAL multipoint selection comes with a number of favourable properties. As explained in more details in Section 3.2, the optimization of the AF -which may be complex, highdimensional and multifidelity -is accomplished by evaluating it point-wise at points in P and picking those points that cumulatively maximize the function over the search domain. By doing so it is possible to handle even complex constraints on the design space, since their feasibility is checked beforehand and not during the AF optimization. Besides, the selected points can be chosen to achieve a tunable exploration/exploitation trade-off of the AF, combining spacefilling characteristics with selective exploitation of the AF shape. Another important aspect of the multipoint seeding is that the sampled points maximize the usage of the computational resources available in terms of the computational burden required to evaluate the points at the selected fidelity levels. The aim is to make the most out of the parallel resources in order to reduce the impact of the function evaluations on the BO iterations, also by properly allocating the different evaluation tasks to the parallel CPUs.</p>
<p>Summarizing, the n t+1 points in the set S t+1 and their associated fidelities M t+1 , selected at each iteration t of the RAAL algorithm for the maximization of the AF, (i) are feasible with respect to design constraints, (ii) are well-distributed and have tunable space-filling properties, and (iii) maximize the usage of available computational resources. Section 3.2 will describe how the points should be processed in order to take into consideration a trade-off between AF exploration and exploitation; Section 3.3 will describe the multipoint multifidelity optimization routine.</p>
<p>Optimal exploration/exploitation of the Acquisition Function in multipoint scenario</p>
<p>The optimization of the AF in the RAAL multipoint scenario relies on a tunable exploitation and exploration of the AF, which will be actively employed in the optimization procedure of Section 3.3 for the selection of multiple points at each BO iteration. When a feasible set of points P in the AF domain is given, the maximization (i.e. exploitation) of the AF itself can be done by simply evaluating the function in these points for each required level of fidelity, obtaining a set of values υ(x i , m), with x i ∈ P and m ∈ [M ], and then picking the highest value. In a standard BO scheme, this is an optimization-by-evaluation procedure that can be especially suitable when the numerical optimization of the AF is particularly challenging, mainly due to the presence of complex and non-convex feasibility constraints. While still convenient in a parallel-BO scheme, some attention must be paid: indeed, a greedy selection of only the best points would lead to oversampling the AF in a close neighborhood of the optimum, without consequently providing much additional information instead of picking the single optimum and, in fact, wasting computational resources.</p>
<p>A better strategy can be devised if we include aspects not only related to the exploitation, but also to the exploration of the AF. One way to explore the AF (and hence the domain of the original objective function) is to use experimental design techniques. A very common approach in this field is the LHD, which divides each dimension j of a d-dimensional space into E j equispaced levels (also known as strata or bins), where each level contains exactly one point in the design. In the literature (see [29] for a brief survey) there are different criteria to evaluate the goodness of an LHD configuration. A popular criterion is the L p -discrepancy with respect to the uniform distribution, which measures the difference between the empirical distribution of a set of points and the multivariate uniform distribution over the same domain. Such uniform discrepancy is a multidimensional property that is difficult to evaluate, however computing the discrepancy along each one-dimensional projection is a much simpler task. Notice that, for example, the defining property of a LHD is that each one-dimensional projection has low uniform discrepancy along that dimension.</p>
<p>Uniform gridding If we take a purely exploration point of view, our measure of the goodness of a set of points is related to the difference with the ideal one-dimensional distributions of the points along the d axes. First we divide each continuous domain j ∈ [d] into a pre-specified number of bins E j with the mapping Ξ : R → {0, 1} E j , and then project each point onto the d axes:
(Ξ j (x)) e . = 1 if x ∈ L j + (e − 1) U j −L j E j , e U j −L j E j 0 otherwise ,(13)
where e ∈ [E j ] and [L j , U j ] represent the interval of the j-th domain. Then, each vector x i ∈ P is mapped onto an extended vector Ξ(x i ) .
=(Ξ 1 (x i,1 ), . . . , Ξ d (x i,d ))
). If the points in a set S ⊂ P were uniformly distributed, the projection along each axis would look like a univariate uniform distribution. Given equispaced strata of each variable j, each stratum should contain the same number of points, i.e |S|/E j . In Section 3.3 we will see how to implement this in a proper optimization problem. Adaptive gridding The discretization technique of Equation (13) produces a uniform grid without taking into consideration the shape of the AF, since the points in P are discretized into partitions of equal length/width and recall as close as possible the measure of discrepancy from the uniform distribution. In order to balance the pure exploration given by the uniform gridding with the function exploitation of the AF, we propose a AF-weighted discretization technique. In place of transforming the points in P on a purely geometric basis, the AF values υ(x i , m) are used to guide their discretization. First, for each dimension j ∈ [d], the points with an AF value smaller than a predefined quantile level ξ ∈ (0, 1) are removed. Subsequently, quantiles Q e j are computed on the AF values of the remaining points, where Q e j is the e-th E j -quantile of the points along the dimension j, with 0 &lt; e &lt; E j . Figure 1 offers an illustrative example: on the left we see the case with ξ = 0, resulting in a uniform grid, while on the right we see the impact of selecting a ξ &gt; 0, which results in a more refined grid around the modes of the AF.</p>
<p>The parameter ξ can also be automatically updated during the iterations of the RAAL algorithm, so as to favour exploration at the beginning of the algorithm, and foster exploitation as we get close to the depletion of the available computational budget. Formally, said ξ max the maximum allowed value for the parameter ξ, the update rule can be specified as
ξ t = ξ max 1 − exp −η ξ B B max − B(14)
where ξ t is the parameter value at iteration t, B is the current budget over the total B max and η ξ is the learning rate.</p>
<p>Once defined the quantiles for each dimension, each point in P is projected onto the j axis by the mapping
(Ξ j (x, ξ)) e . = 1 if x ∈ Q e j , Q e+1 j 0 otherwise(15)
where e ∈ [E j ], and Q 0
j . = L j , Q E j j . = U j .
In this case we highlighted the dependence on the parameter ξ because, contrary to (13), the width of the bins is adjusted depending on the AF values distribution using the quantile-based method. This leads to a finer grid resolution in those areas where the AF has higher values, and therefore where it is more likely to sample more informative points. Similarly to the previous case, each vector x i ∈ P is finally mapped onto an extended vector Ξ(x i , ξ) . =(Ξ 1 (x i,1 , ξ), . . . , Ξ d (x i,d , ξ)). Section 3.3 will show hot to implement proper constraints such that the projection along each axis looks like a univariate uniform distribution to obtain well distributed points over the defined grid.</p>
<p>Multipoint multifidelity seeding</p>
<p>When multiple computational resources are available at each iteration of the BO loop, we face the problem of how to best utilize these resources to gain as much information as possible from the current surrogate model and its related AF. Section 3.2 already discussed the proposed strategies for the multipoint maximization of the AF, in the direction of balancing exploitation and exploration. This section describes how these strategies can be embedded in an optimization program that takes into consideration three main aspects characterizing our multipoint multifidelity seeding, namely:</p>
<ol>
<li>
<p>the maximization of the usage of the computational resources available and their optimal allocation for the evaluation of the objective function f at different fidelity levels;</p>
</li>
<li>
<p>the optimal exploitation and exploration of the AF;</p>
</li>
<li>
<p>a sampling strategy compatible with the recursive GP model used to build the surrogate (Section 2.2.1).</p>
</li>
</ol>
<p>From an high level perspective, the seeding routine is implemented as a knapsack problem, where the candidate points and the relative fidelity sources are selected so that the information acquired during a parallel evaluation of the objective function is maximized, and the computational load is less than or equal to the available parallel resources. Consequently, the optimization problem takes four groups of input parameters: the points to be selected x i , transformed and 'decoded' into their categorical version χ i . = Ξ(x i ), thanks to the discretization procedures (13) or (15); the υ (m) i values of the AF evaluated at points x i ∈ P and fidelities m ∈ [M ]; the computational cost λ (m) of evaluating the objective function f at fidelity m ∈ [M ]; the computational resources β g of each single computational unit g ∈ [G], where G is the number of available CPUs, to be allocated for the evaluation of f at the fidelity levels that will be selected.</p>
<p>The decision variables that allow for the selection of the next points and their fidelities to be evaluated (i.e. the sets S t+1 and M t+1 in Algorithm 1) are arranged into two groups: variables p (m) i,g equal 1 iff the point x i at fidelity m is chosen and assigned to the computational unit g ∈ [G]; variables q i equal 1 iff the point x i is chosen from P, independently from the fidelity level. The variables q i are used in combination with the discretized data χ i to select a set of points such that each stratum of the discretized grid is represented, in order to measure a (scaled) discrepancy with respect to the uniform distribution. It is worth reminding that, according to the discretization procedure chosen from Section 3.2, such measure enforces the property of weighted well-distributed points, hence balancing the exploration/exploitation of the AF itself over the selected points. On the other hand, variables p The optimization routine is finally formulated as the following Mixed Integer Linear Programming (MILP) problem:
min p (m) i,g ,q i Υ   G g β g − N,M,G i,m,g λ (m) p (m) i,g   − N,M,G i,m,g υ (m) i p (m) i,g s.t N i χ e i q i ≤ 1 ∀e ∈ [E] (16a) N,M i,m λ (m) p (m) i,g ≤ β g ∀g ∈ [G] (16b) M,G m,g p (m) i,g ≤ (M * G)q i ∀i ∈ [N ] (16c) q i ≤ M,G m,p p (m) i,g ∀i ∈ [N ] (16d) G g p (m) i,g ≤ 1 ∀i ∈ [N ], m ∈ [M ] (16e) G g p (m) i,g ≤ G g p p i,l ∀m ≥ l, l, m ∈ [M ] (16f) p (m) i,g , q i ∈ {0, 1} i ∈ [N ], m ∈ [M ], g ∈ [G]
where E = d j=1 E j is the total number of bins used in the processing of data χ i . The MILP objective induces a hierarchical order in the optimization of the two goals of maximizing the usage of resources and maximizing the AF: the former is prioritized over the latter through the weighting factor Υ set such that Υ &gt;&gt; N,M i,m υ (m) i . With constraints (16a) we impose that at most one point can be chosen that belongs to each bin e ∈ [E], hence enforcing the well-distributed property described in Section 3.2. Constraints (16b) guarantee that the capacity of each computational unit is not violated when the evaluations of the objective i,g are is imposed by constraints (16c) and (16d), while (16e) assure that a single point cannot be evaluated on more than one CPU. Finally, the fidelity interdependence for the construction of the coherent auto-regressive GP model (described in Section 2) is implemented by (16f).</p>
<p>Experiments</p>
<p>In this section we present numerical experiments demonstrating the performances of the RAAL algorithm compared to a standard sequential BO scheme (i.e. using a single CPU), for which we use a set of benchmark problems. In the following, we first describe the experimental setup followed in all the experiments, including the benchmarks description and the tests configurations; then we move to discuss the results obtained in both single and multifidelity versions of the benchmark problems.</p>
<p>We implemented the RAAL algorithm, its statistical models and acquisition functions in Python 3.7.3, leveraging functionality from the Emukit toolkit [46], while the MILP Optimization Routine of Section 3.3 was implemented with PuLP [47], a linear programming modeler written in Python, and solved by means of COIN CLP/CBC [48].</p>
<p>Experimental setup</p>
<p>We conducted experiments on a variety of popular benchmark problems to test the efficiency and robustness of the proposed approach against the standard sequential BO, either in single (SF) and multifidelity (MF) settings. The benchmark functions were selected to exemplify different types of correlations among the fidelity levels, described in the following. Consistently with the already used notation, we denote y (m) (x) the objective functions, and sort the fidelities in an increasing order m = 1, . . . , M . Accordingly, M is the representation at the highest-fidelity and is considered the reference ground-truth.</p>
<p>Analytical Test 1 The first benchmark is the popular Forrester function [31], one of the most common analytical benchmark in the literature. It is a 1-dimensional nonlinear function over the domain [0, 1], defined as
y (2) (x) = (6x − 2) 2 sin(12x − 4),(17)
with x * 0.727549 and f (x * ) −6.02074. Its low fidelity level is given by the linear mapping
y (1) (x) = 0.5y (2) (x) + 10(x − 0.5).(18)
Analytical Test 2 The second benchmark is a sinusoidal squared 1-dimensional function [20], with domain in the interval [0, 1]. The high fidelity function is defined as
y (2) (x) = (x − √ 2)(y (1) (x)) 2 ,(19)
which is a non linear function of the low fidelity variant, given by
y (1) (x) = sin(8πx).(20)
Its ground truth solution to problem (1) is f (x * ) −1.35201 at x * 0.0619147.</p>
<p>Analytical Test 3</p>
<p>The third benchmark problem is the d-dimensional Rosenbrock function [49], a non-convex function with domain in the interval [−2, 2] d and defined as
y (2) (x) = d−1 i=1 (1 − x i ) 2 + 100(x i+1 − x i ) 2 where x = [x 1 , . . . , x d ] ∈ R d .(21)
The global minimum f (x * ) = 0 lies in a narrow, parabolic valley and is located at x * = [1, . . . , 1] d . The low fidelity observations are given by a linear mapping defined as [50]: Figure 2 illustrates the three analytical objective functions, together with their low fidelity alternatives. In the remaining of the paper "SF Test " denotes the optimization of theth Analytical Test problem in a single fidelity setting, where just the highest fidelity level is considered. Conversely, "MF Test " indicates the optimization of the -th Analytical Test problem in a multifidelity setting, considering all the available fidelity levels as available sources of information.
y (1) (x) = y (2) (x) − 4.0 − d i=1 0.5x i 3.0 + d i=1 0.25x i .(22)
For all the numerical results, same initial conditions were imposed to each algorithm configuration: an identical initial set S 0 , with cardinality dictated by the specific benchmark application, was selected randomly from the feasible set P, drawn quasi-randomly via LHD over the feasible domain of each benchmark. We also allocated, for each experiment, the same maximum total computational budget B max to both the sequential BO and the RAAL algorithm, i.e. the highest level of fidelity can be evaluated the same number of times Finally, for all the analytical benchmarks, we set a unitary cost to the maximum fidelity level and a fractional cost to all the lower fidelity level, according to the following rule
λ (m) =    1 if m = M, 1 5(M − m) if m &lt; M.(23)
In the RAAL algorithm, each available CPU was assigned with a computational budget capable of running a single evaluation of the objective function at the maximum fidelity level. In the following results we report the Root Squared Error between the optimal solution computed at each step and the known global optimum (minimum) of the high fidelity function of each benchmark. The error is plotted as a function of the iterations used by each algorithm, for which we allocate the same total computational budget to fairly compare the results. This metric is directly related to the execution time taken by the sequential and parallel BO, given that the computational overhead of choosing the next information source and sample is omitted, as it is negligible compared to invoking an information source in real-world applications. All the numerical experiments were randomized over 20 runs, from different initial sets S 0 : all diagrams reports the median values (solid lines) together with all the other observations falling in the interval between the 25-th and 75-th percentiles (shaded areas). The hyperparameters of the kernel and mean functions of the GP surrogate models were optimized via Maximum Likelihood Estimation [8,5]. </p>
<p>Single fidelity results</p>
<p>This section discusses the results observed for the single fidelity version (SF) of the artificial benchmarks; this set of experiments permits to investigate the impact of different parameter values of the RAAL algorithm on its performances, namely the accuracy and the speed of convergence to the known optimum. In particular, we focus our attention on different grid resolutions E and different values of the learning rate parameter η ξ while varying the number of available CPUs (that is the number of points that can be evaluated simultaneously). Figure 3 shows the results on the SF Test 1 benchmark, for which we chose an initial DOE of n 0 = 2 points. We run the tests with B max = 30, and all the different parameters combinations resulting from two discretization levels E = 5 and E = 10 and three learning rates η ξ = 0, 1, 2. First of all we can see how the RAAL algorithm achieves better results than the sequential BO in terms of convergence speed: the RAAL algorithm takes 2.5 iterations on average to reach the optimum in case 5 CPUs are employed, whereas the sequential BO takes on average 5 iterations. Similar results are obtained for all the parameter settings of the grid discretization, that is the number of bins E and the learning rate η ξ . From these experiment, the learning rate seems not to have significant impact onto the convergence speed. This holds for the simple case of SF Test 1, whose AF shape may be fairly simple to be captured and exploited.</p>
<p>We move now to investigate the impact of different numbers of bins E in the discretization grid and of the learning rate η ξ on the SF Test 2. For this test we used n 0 = 2 points as initial DOE and a maximum computational budget of B max = 30. Interestingly, Figure 4 shows similar results to Figure 3: the parallel selection of multiple points leads to a significantly improved convergence speed, without compromising the performances in terms of accuracy. While the sequential BO takes 20 iterations to reach the optimum, the RAAL algorithm takes 10 iterations with 2 CPUs and less than 5 iterations with 5 CPUs. Another important aspect regards the resolution of the grid: increasing the resolution of the grid by doubling the number of bins from E = 5 (top row) to E = 10 (bottom row) helped the RAAL achieve a faster convergence and avoid local optima, represented by those plateau in the algorithm iterations. It may be deduced that, given the high multimodality of SF Test 2, the RAAL algorithm can benefit from a higher number of bins in the search grid, which allows a finer search and the movement from one local optima to another, till reaching the true objective function optimum. Lastly, higher learning rates degrade the performance in presence of local optima, both with a coarse and a finer grid. The main reason is that the adaptation yields denser sampling in the proximity of the peaks of the acquisition function, therefore mitigating the exploration thrusts of the uniform gridding which would be beneficial to skip out of local minima. This is confirmed by the behaviour observed for the uniform gridding, for which we record shorter stagnation at the local minimum. An additional analysis was carried out on the multidimensional domain of the SF Test 3 (Rosenbrok), where we set uniform gridding for the entire optimization procedure (η ξ = 0) and E j = 5 bins for each dimension. Investigations were conducted for different dimensionality of the problem, namely for d = 2 and d = 4. Also in this scenario, the RAAL BO outperforms the sequential BO in terms of convergence speed, even if with d = 4 the sequential BO achieves, on average, a slightly better accuracy. A possible reason for this is that, ideally, the cardinality of the set of points to evaluate at each iteration increases with the dimensionality of the domain to sample.</p>
<p>Multifidelity results</p>
<p>In this section we describe the results for the multifidelity (MF) version of the analytical benchmarks and discuss the impact of the RAAL parameters. In addition, the outcomes are compared to the single fidelity experiments, in order to verify whether similar considerations can be drawn. Similarly to the single fidelity case, we investigate the impact of different parameters of the RAAL algorithm, that is the numbers of bins E in the discretization grid and the learning rate η ξ . In particular we investigate their role for the 2 CPUs and the 5 CPUs architectures. Figure 6: MF Test 1. Comparison between sequential BO and RAAL BO with 2 CPUs and 5 CPUs with B max = 10. RAAL parameters are E = 5 and η ξ = 0. Figure 6 reports the results obtained for the benchmark MF Test 1, with a maximum computational budget B max = 10. Here we use a uniform grid of E = 5 bins and establish an initial set of 5 and 2 points for the low and high fidelity levels, respectively. The multipoint selection of the RAAL BO permits to sensitively accelerate the convergence to the optimum; this already emerges when 2 CPUs only are available. Moreover, the parallel selection of different points reduces the variability of the results across the experiments, that is, the proposed multipoint and multifidelity seeding enhances the robustness of the BO scheme with respect to a sequential approach.</p>
<p>We run the MF Test 2 with B max = 20 for all the settings of the algorithmic parameters resulting from two discretization levels E = 5 and E = 10, and three learning rates η ξ = 0, η ξ = 1, and η ξ = 2. Similarly to the MF Test 1, the initial DOE consists of 5 and 2 points for the low and high fidelity, respectively. Figure 7 shows that, also in this second multifidelity benchmark, the multipoint selection dramatically accelerates the search of the optimum which in many cases can be found in only 5 iterations when exploiting 5 CPUs. Furthermore, it is worth noticing that the RAAL algorithm performs better in this MF Test 2 rather than in its single fidelity version SF Test 2. The comparison of Figures 4 and 7 reveals that the RAAL algorithm always achieves the global optimum of the benchmark function in the MF setting, whereas it does not manage the same in the SF case, when 5 CPUs are used. In fact, the access to a lower fidelity and less costly representation of the objective function allows the RAAL algorithm to sample more points and to better explore the search space, which turns out to be very useful for highly multimodal problems of this kind. For what concerns the effect of different discretization levels, we can observe that a coarse E leads to better optimization performance when we have a smaller number of CPUs, whereas a finer grid allows to achieve faster convergence when the number of CPUs is higher. This is related to trade-off between the exploration and the exploitation thrusts: the combination of a lower number of CPUs with a finer grid is too unbalanced towards the exploitation, whereas a coarse grid paired with a high number of CPUs (and therefore samples per iteration), biases the optimization in favour of the exploration. Lastly, differently from what observed for the single fidelity settings, increments of the learning rate η ξ do not have any significant impact on the convergence history of the multifidelity implementation of benchmark Test 2.</p>
<p>Eventually, experiments are reported for the mutidimensional benchmark Test 3 (Rosenbrock function) in the multifidelity scenario. Investigations have been conducted for d = 2, 4 and 8 dimensional domains with different maximum budget B max = 30, 40, and 80, respectively allocated; a uniform gridding is adopted to discretize each dimension with E j = 5 bins.</p>
<p>Similarly to what observed for the single fiedelity experiment, the results recorded for the multifidelity settings (Figure 8) demonstrate the faster convergence speed of the RAAL BO, which is particularly impressive in the highest dimensional domain of d = 8: the parallel multipoint selection of the RAAL algorithm leads to a smaller final error with respect to the true optimum, which was achieved in a little fraction of the iterations taken by the sequential BO. </p>
<p>Concluding Remarks</p>
<p>In this work we proposed a novel multipoint and multifidelity Bayesian Optimization (BO) scheme, with the objective of accelerating the optimization of expensive-to-evaluate black box functions. Our Resource Aware Active Learning (RAAL) algorithm is able to maximize the information gain to acquire at each step of the underlying BO methodology by seeding multiple points and the associated fidelities while optimally allocate parallel/distributed computational resources available for their evaluation. The core of the algorithm is the seeding procedure, implemented as a mathematical programming problem, which leverages in a principled way the computational time budget and parallel resources available to balance the trade-off between exploration and exploitation of the Acquisition Function (AF), leading a major speed up in the iterative optimization task. Another main characteristic of the RAAL algorithm is its general formulation, which can scale to any finite number of fidelities, handle any statistical model and deal with any AF. This should guarantee a wide applicability of the approach, without limiting its validity to any specific BO-related setting.</p>
<p>The performances of the approach were empirically evaluated on a number of well-known analytical benchmarks available in the literature, with non-linear and multimodal characteristics, tested with two fidelity levels for demonstration purposes. The results obtained for all the numerical experiments reveal a significant speed up of the RAAL algorithm in solving the optimization problem with respect to a standard BO scheme, where the AF is optimized and sampled in only one point. Interestingly enough, the RAAL achieves even better performances in multifidelity scenarios, demonstrating the ability to take full advantage of the lower fidelity and cheaper-to-evaluate approximation of the objective function in seeding more points and hence better explore the search domain at each algorithm iteration.</p>
<p>As potential extension of this work, we are currently investigating different opportunities. First, numerical results should be extended to physics-based applications and problems, for an additional validation of the approach for physics-based multidomain use cases. Another worthwhile investigation may regard the use of opportunely extended Multipoint Acquisition Functions, explicitly formulated so as to maximize the information gain either at the same BO iteration or over a look-ahead on future iterations, recalling a Dynamic Programming approach. Some attempts are already available in the literature, but they only focus on the single fidelity scenario. Lastly, a potential advancement of the algorithm can be its adaptation to the socalled Constrained Bayesian Optimization, where the objective function has to be optimized in presence of expensive-to-evaluate feasibility constraint, which usually involve the formulation of modified Acquisition Functions.</p>
<p>Figure 1 :
1An example of adaptive gridding techniques on a synthetic 2D AF profile with with E j = 8, j =[2]. Left figure represent a uniform grid obtain when ξ = 0, while the right figure shows the impact of ξ = 0.8 in the generation of a finer grid around AF modes.</p>
<p>g determine the fidelity level m and the computational unit g assigned to point x i to minimize the waste of resources, accounting for the specific computational cost λ (m) associated to the fidelity level m ∈ [M ].</p>
<p>Figure 2 :
2Analytical benchmark objective functions and their low fidelity alternatives: Analytical Test 1 (left), Analytical Test 2 (center), and Analytical Test 3 with d = 2 (right). function are assigned. Logical interdependence between the groups of variables q i and p (m)</p>
<p>Figure 3 :
3SF Test 1. Comparison between sequential BO and RAAL BO with 2 CPUs and 5 CPUs: impact of the number of bins E in the search point discretization, and of the learning rate η ξ in the adaptive grid. Tests were run with a maximum budget of B max = 20.</p>
<p>Figure 4 :
4SF Test 2. Comparison between sequential BO and RAAL BO with 2 CPUs and 5 CPUs: impact of the number of bins E in the search point discretization, and of the learning rate η ξ in the adaptive grid. Tests were run with a maximum budget of B max = 30.</p>
<p>Figure 5 :
5SF Test 3, with d = 2 (left) and d = 4 (right). Comparison between sequential BO and RAAL BO with 2 CPUs and 5 CPUs. RAAL parameters are E j = 5, j ∈ [d] and η ξ = 0.</p>
<p>Figure 7 :
7MF Test 2. Comparison between sequential BO and RAAL BO with 2 CPUs and 5 CPUs: impact of the number of bins E in the search point discretization, and of the learning rate η ξ in the adaptive grid. Tests were run with a maximum budget of B max = 20.</p>
<p>Figure 8 :
8MF Test 3, with d = 2 (left), d = 4 (center), and d = 8 (right), with B max = 30, B max = 40, and B max = 80, respectively. Comparison between sequential BO and RAAL BO with 2 CPUs and 5 CPUs. RAAL parameters are E j = 5, j ∈ [d], and η ξ = 0.
AcknowledgmentsThis work was supported by the IDA Center of Excellence in Cyber Physical Systems Grant No. 176474 under the Industrial Development Agency (Ireland) program.
Efficient global optimization of expensive black-box functions. D R Jones, M Schonlau, W J Welch, Journal of Global optimization. 134D. R. Jones, M. Schonlau, and W. J. Welch, "Efficient global optimization of expensive black-box functions," Journal of Global optimization, vol. 13, no. 4, pp. 455-492, 1998.</p>
<p>Surrogate-based analysis and optimization. N V Queipo, R T Haftka, W Shyy, T Goel, R Vaidyanathan, P K Tucker, Progress in aerospace sciences. 411N. V. Queipo, R. T. Haftka, W. Shyy, T. Goel, R. Vaidyanathan, and P. K. Tucker, "Surrogate-based analysis and optimization," Progress in aerospace sciences, vol. 41, no. 1, pp. 1-28, 2005.</p>
<p>Formulations for surrogate-based optimization with data fit, multifidelity, and reduced-order models. M Eldred, D Dunlavy, 11th AIAA/ISSMO Multidisciplinary Analysis and Optimization Conference. 7117M. Eldred and D. Dunlavy, "Formulations for surrogate-based optimization with data fit, multifidelity, and reduced-order models," in 11th AIAA/ISSMO Multidisciplinary Analysis and Optimization Conference, 2006, p. 7117.</p>
<p>Surrogate-based optimization using multifidelity models with variable parameterization and corrected space mapping. T Robinson, M Eldred, K Willcox, R Haimes, AIAA Journal. 4611T. Robinson, M. Eldred, K. Willcox, and R. Haimes, "Surrogate-based optimization using multifidelity models with variable parameterization and corrected space mapping," AIAA Journal, vol. 46, no. 11, pp. 2814-2822, 2008.</p>
<p>Recent advances in surrogate-based optimization. A I Forrester, A J Keane, Progress in aerospace sciences. 45A. I. Forrester and A. J. Keane, "Recent advances in surrogate-based optimization," Progress in aerospace sciences, vol. 45, no. 1-3, pp. 50-79, 2009.</p>
<p>Advances in surrogate based modeling, feasibility analysis, and optimization: A review. A Bhosekar, M Ierapetritou, Computers &amp; Chemical Engineering. 108A. Bhosekar and M. Ierapetritou, "Advances in surrogate based modeling, feasibility anal- ysis, and optimization: A review," Computers &amp; Chemical Engineering, vol. 108, pp. 250 -267, 2018.</p>
<p>Predicting the output from a complex computer code when fast approximations are available. M C Kennedy, A O&apos;hagan, Biometrika. 871M. C. Kennedy and A. O'Hagan, "Predicting the output from a complex computer code when fast approximations are available," Biometrika, vol. 87, no. 1, pp. 1-13, 2000.</p>
<p>Multi-fidelity optimization via surrogate modelling. A I Forrester, A Sóbester, A J Keane, Proceedings of the royal society a: mathematical, physical and engineering sciences. the royal society a: mathematical, physical and engineering sciences463A. I. Forrester, A. Sóbester, and A. J. Keane, "Multi-fidelity optimization via surrogate modelling," Proceedings of the royal society a: mathematical, physical and engineering sciences, vol. 463, no. 2088, pp. 3251-3269, 2007.</p>
<p>Review of multi-fidelity models. M G Fernández-Godino, C Park, N.-H Kim, R T Haftka, arXiv:1609.07196arXiv preprintM. G. Fernández-Godino, C. Park, N.-H. Kim, and R. T. Haftka, "Review of multi-fidelity models," arXiv preprint arXiv:1609.07196, 2016.</p>
<p>Remarks on multi-fidelity surrogates. C Park, R T Haftka, N H Kim, Structural and Multidisciplinary Optimization. 55C. Park, R. T. Haftka, and N. H. Kim, "Remarks on multi-fidelity surrogates," Structural and Multidisciplinary Optimization, vol. 55, no. 3, pp. 1029-1050, 2017.</p>
<p>Survey of multifidelity methods in uncertainty propagation, inference, and optimization. B Peherstorfer, K Willcox, M Gunzburger, Siam Review. 603B. Peherstorfer, K. Willcox, and M. Gunzburger, "Survey of multifidelity methods in uncer- tainty propagation, inference, and optimization," Siam Review, vol. 60, no. 3, pp. 550-591, 2018.</p>
<p>Comparison of multi-fidelity approaches for military vehicle design. P S Beran, D Bryson, A S Thelen, M Diez, A Serani, AIAA AVIATION 2020 FORUM. 3158P. S. Beran, D. Bryson, A. S. Thelen, M. Diez, and A. Serani, "Comparison of multi-fidelity approaches for military vehicle design," in AIAA AVIATION 2020 FORUM, 2020, p. 3158.</p>
<p>Efficient global optimization algorithm assisted by multiple surrogate techniques. F A Viana, R T Haftka, L T Watson, Journal of Global Optimization. 562F. A. Viana, R. T. Haftka, and L. T. Watson, "Efficient global optimization algorithm assisted by multiple surrogate techniques," Journal of Global Optimization, vol. 56, no. 2, pp. 669-689, 2013.</p>
<p>Multifidelity optimization using statistical surrogate modeling for non-hierarchical information sources. R Lam, D L Allaire, K E Willcox, 56th AIAA/ASCE/AHS/ASC Structures, Structural Dynamics, and Materials Conference. 143R. Lam, D. L. Allaire, and K. E. Willcox, "Multifidelity optimization using statistical surro- gate modeling for non-hierarchical information sources," in 56th AIAA/ASCE/AHS/ASC Structures, Structural Dynamics, and Materials Conference, 2015, p. 0143.</p>
<p>Multi-fidelity bayesian optimization with max-value entropy search. S Takeno, H Fukuoka, Y Tsukada, T Koyama, M Shiga, I Takeuchi, M Karasuyama, arXiv:1901.08275arXiv preprintS. Takeno, H. Fukuoka, Y. Tsukada, T. Koyama, M. Shiga, I. Takeuchi, and M. Kara- suyama, "Multi-fidelity bayesian optimization with max-value entropy search," arXiv preprint arXiv:1901.08275, 2019.</p>
<p>A tutorial on bayesian optimization of expensive cost functions, with application to active user modeling and hierarchical reinforcement learning. E Brochu, V M Cora, N De Freitas, E. Brochu, V. M. Cora, and N. de Freitas, "A tutorial on bayesian optimization of expensive cost functions, with application to active user modeling and hierarchical reinforcement learning," 2010.</p>
<p>A tutorial on bayesian optimization. P I Frazier, arXiv:1807.02811arXiv preprintP. I. Frazier, "A tutorial on bayesian optimization," arXiv preprint arXiv:1807.02811, 2018.</p>
<p>Gaussian processes for machine learning. C K Williams, C E Rasmussen, MIT press2Cambridge, MAC. K. Williams and C. E. Rasmussen, Gaussian processes for machine learning. MIT press Cambridge, MA, 2006, vol. 2, no. 3.</p>
<p>Recursive co-kriging model for design of computer experiments with multiple levels of fidelity. L , Le Gratiet, J Garnier, International Journal for Uncertainty Quantification. 45L. Le Gratiet and J. Garnier, "Recursive co-kriging model for design of computer experi- ments with multiple levels of fidelity," International Journal for Uncertainty Quantification, vol. 4, no. 5, 2014.</p>
<p>Deep gaussian processes for multi-fidelity modeling. K Cutajar, M Pullin, A Damianou, N Lawrence, J González, arXiv:1903.07320arXiv preprintK. Cutajar, M. Pullin, A. Damianou, N. Lawrence, and J. González, "Deep gaussian pro- cesses for multi-fidelity modeling," arXiv preprint arXiv:1903.07320, 2019.</p>
<p>Special section on multidisciplinary design optimization: metamodeling in multidisciplinary design optimization: how far have we really come?. F A Viana, T W Simpson, V Balabanov, V Toropov, AIAA journal. 524F. A. Viana, T. W. Simpson, V. Balabanov, and V. Toropov, "Special section on multi- disciplinary design optimization: metamodeling in multidisciplinary design optimization: how far have we really come?" AIAA journal, vol. 52, no. 4, pp. 670-690, 2014.</p>
<p>Analysis of dataset selection for multifidelity surrogates for a turbine problem. Z Guo, L Song, C Park, J Li, R T Haftka, Structural and Multidisciplinary Optimization. 57Z. Guo, L. Song, C. Park, J. Li, and R. T. Haftka, "Analysis of dataset selection for multi- fidelity surrogates for a turbine problem," Structural and Multidisciplinary Optimization, vol. 57, no. 6, pp. 2127-2142, 2018.</p>
<p>Multifidelity efficient global optimization: Methodology and application to airfoil shape design. M Meliani, N Bartoli, T Lefebvre, M.-A Bouhlel, J Martins, J Morlier, AIAA Aviation 2019 Forum. 3236M. Meliani, N. Bartoli, T. Lefebvre, M.-A. Bouhlel, J. Martins, and J. Morlier, "Multi- fidelity efficient global optimization: Methodology and application to airfoil shape design," in AIAA Aviation 2019 Forum, 2019, p. 3236.</p>
<p>A comparison study of two multifidelity methods for aerodynamic optimization. S G Kontogiannis, J Demange, A M Savill, T Kipouros, Aerospace Science and Technology. 97105592S. G. Kontogiannis, J. Demange, A. M. Savill, and T. Kipouros, "A comparison study of two multifidelity methods for aerodynamic optimization," Aerospace Science and Technology, vol. 97, p. 105592, 2020.</p>
<p>Bayesian optimization with inequality constraints. J R Gardner, M J Kusner, Z E Xu, K Q Weinberger, J P Cunningham, ICML. J. R. Gardner, M. J. Kusner, Z. E. Xu, K. Q. Weinberger, and J. P. Cunningham, "Bayesian optimization with inequality constraints." in ICML, 2014, pp. 937-945.</p>
<p>A general framework for constrained bayesian optimization using information-based search. J M Hernández-Lobato, M A Gelbart, R P Adams, M W Hoffman, Z Ghahramani, The Journal of Machine Learning Research. 171J. M. Hernández-Lobato, M. A. Gelbart, R. P. Adams, M. W. Hoffman, and Z. Ghahra- mani, "A general framework for constrained bayesian optimization using information-based search," The Journal of Machine Learning Research, vol. 17, no. 1, pp. 5549-5601, 2016.</p>
<p>Constrained bayesian optimization with max-value entropy search. V Perrone, I Shcherbatyi, R Jenatton, C Archambeau, M Seeger, arXiv:1910.07003arXiv preprintV. Perrone, I. Shcherbatyi, R. Jenatton, C. Archambeau, and M. Seeger, "Constrained bayesian optimization with max-value entropy search," arXiv preprint arXiv:1910.07003, 2019.</p>
<p>Maximizing acquisition functions for bayesian optimization. J Wilson, F Hutter, M Deisenroth, Advances in Neural Information Processing Systems. J. Wilson, F. Hutter, and M. Deisenroth, "Maximizing acquisition functions for bayesian optimization," in Advances in Neural Information Processing Systems, 2018, pp. 9884-9895.</p>
<p>Milp models for the selection of a small set of well-distributed points. C Ambrosio, G Nannicini, G Sartor, Operations Research Letters. 451C. D'Ambrosio, G. Nannicini, and G. Sartor, "Milp models for the selection of a small set of well-distributed points," Operations Research Letters, vol. 45, no. 1, pp. 46-52, 2017.</p>
<p>Bayesian approach to global optimization: theory and applications. J Mockus, Springer Science &amp; Business Media37J. Mockus, Bayesian approach to global optimization: theory and applications. Springer Science &amp; Business Media, 2012, vol. 37.</p>
<p>Engineering Design via Surrogate Modelling: A Practical Guide. A Forrester, A Sobester, A Keane, WileyA. Forrester, A. Sobester, and A. Keane, Engineering Design via Surrogate Modelling: A Practical Guide. Wiley, 2008.</p>
<p>Controller design via experimental exploration with robustness guarantees. T Holicki, C W Scherer, S Trimpe, arXiv:2003.08613arXiv preprintT. Holicki, C. W. Scherer, and S. Trimpe, "Controller design via experimental exploration with robustness guarantees," arXiv preprint arXiv:2003.08613, 2020.</p>
<p>The knowledge-gradient algorithm for sequencing experiments in drug discovery. D M Negoescu, P I Frazier, W B Powell, INFORMS Journal on Computing. 233D. M. Negoescu, P. I. Frazier, and W. B. Powell, "The knowledge-gradient algorithm for sequencing experiments in drug discovery," INFORMS Journal on Computing, vol. 23, no. 3, pp. 346-363, 2011.</p>
<p>Bayesian Optimization for Materials Science. D Packwood, SpringerD. Packwood, Bayesian Optimization for Materials Science. Springer, 2017.</p>
<p>Quantifying uncertainty in climate change science through empirical information theory. A J Majda, B Gershgorin, Proceedings of the National Academy of Sciences. 10734A. J. Majda and B. Gershgorin, "Quantifying uncertainty in climate change science through empirical information theory," Proceedings of the National Academy of Sciences, vol. 107, no. 34, pp. 14 958-14 963, 2010.</p>
<p>Automatic gait optimization with gaussian process regression. D J Lizotte, T Wang, M H Bowling, D Schuurmans, IJCAI. 7D. J. Lizotte, T. Wang, M. H. Bowling, and D. Schuurmans, "Automatic gait optimization with gaussian process regression." in IJCAI, vol. 7, 2007, pp. 944-949.</p>
<p>Reinforcement learning with multi-fidelity simulators. M Cutler, T J Walsh, J P How, 2014 IEEE International Conference on Robotics and Automation (ICRA). M. Cutler, T. J. Walsh, and J. P. How, "Reinforcement learning with multi-fidelity sim- ulators," in 2014 IEEE International Conference on Robotics and Automation (ICRA).</p>
<p>. IEEE. IEEE, 2014, pp. 3888-3895.</p>
<p>Practical bayesian optimization of machine learning algorithms. J Snoek, H Larochelle, R P Adams, Advances in neural information processing systems. J. Snoek, H. Larochelle, and R. P. Adams, "Practical bayesian optimization of machine learning algorithms," in Advances in neural information processing systems, 2012, pp. 2951- 2959.</p>
<p>Transfer learning based multi-fidelity physics informed deep neural network. S Chakraborty, arXiv:2005.10614arXiv preprintS. Chakraborty, "Transfer learning based multi-fidelity physics informed deep neural net- work," arXiv preprint arXiv:2005.10614, 2020.</p>
<p>A New Method of Locating the Maximum Point of an Arbitrary Multipeak Curve in the Presence of Noise. H J Kushner, Journal of Basic Engineering. 861H. J. Kushner, "A New Method of Locating the Maximum Point of an Arbitrary Multipeak Curve in the Presence of Noise," Journal of Basic Engineering, vol. 86, no. 1, pp. 97-106, 03 1964.</p>
<p>Entropy search for information-efficient global optimization. P Hennig, C J Schuler, Journal of Machine Learning Research. 13P. Hennig and C. J. Schuler, "Entropy search for information-efficient global optimization," Journal of Machine Learning Research, vol. 13, no. Jun, pp. 1809-1837, 2012.</p>
<p>Predictive entropy search for efficient global optimization of black-box functions. J M Hernández-Lobato, M W Hoffman, Z Ghahramani, Advances in neural information processing systems. J. M. Hernández-Lobato, M. W. Hoffman, and Z. Ghahramani, "Predictive entropy search for efficient global optimization of black-box functions," in Advances in neural information processing systems, 2014, pp. 918-926.</p>
<p>A markov property for covariance structures. A O&apos;hagan, Statistics Research Report. 9813A. O'Hagan, "A markov property for covariance structures," Statistics Research Report, vol. 98, p. 13, 1998.</p>
<p>Sequential kriging optimization using multiple-fidelity evaluations. D Huang, T T Allen, W I Notz, R A Miller, Structural and Multidisciplinary Optimization. 32D. Huang, T. T. Allen, W. I. Notz, and R. A. Miller, "Sequential kriging optimization using multiple-fidelity evaluations," Structural and Multidisciplinary Optimization, vol. 32, no. 5, pp. 369-382, 2006.</p>
<p>Information-based multifidelity bayesian optimization. Y Zhang, T N Hoang, B K H Low, M Kankanhalli, NIPS Workshop on Bayesian Optimization. Y. Zhang, T. N. Hoang, B. K. H. Low, and M. Kankanhalli, "Information-based multi- fidelity bayesian optimization," in NIPS Workshop on Bayesian Optimization, 2017.</p>
<p>Emulation of physical processes with emukit. A Paleyes, M Pullin, M Mahsereci, N Lawrence, J González, Second Workshop on Machine Learning and the Physical Sciences. NeurIPSA. Paleyes, M. Pullin, M. Mahsereci, N. Lawrence, and J. González, "Emulation of phys- ical processes with emukit," in Second Workshop on Machine Learning and the Physical Sciences, NeurIPS, 2019.</p>
<p>Pulp: a linear programming toolkit for python. S Mitchell, M Osullivan, I Dunning, Auckland, New ZealandThe University of AucklandS. Mitchell, M. OSullivan, and I. Dunning, "Pulp: a linear programming toolkit for python," The University of Auckland, Auckland, New Zealand, 2011.</p>
<p>The common optimization interface for operations research: Promoting open-source software in the operations research community. R Lougee-Heimer, IBM Journal of Research and Development. 471R. Lougee-Heimer, "The common optimization interface for operations research: Promot- ing open-source software in the operations research community," IBM Journal of Research and Development, vol. 47, no. 1, pp. 57-66, 2003.</p>
<p>An automatic method for finding the greatest or least value of a function. H Rosenbrock, The Computer Journal. 33H. Rosenbrock, "An automatic method for finding the greatest or least value of a function," The Computer Journal, vol. 3, no. 3, pp. 175-184, 1960.</p>
<p>A unified, multifidelity quasi-newton optimization method with application to aero-structural design. D E Bryson, University of DaytonPh.D. dissertationD. E. Bryson, "A unified, multifidelity quasi-newton optimization method with application to aero-structural design," Ph.D. dissertation, University of Dayton, 2017.</p>            </div>
        </div>

    </div>
</body>
</html>