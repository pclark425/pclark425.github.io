<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2200 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2200</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2200</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-58.html">extraction-schema-58</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of validation approaches in automated or AI-driven scientific research systems, including experimental validation, computational validation, simulation-based validation, and comparisons between these approaches.</div>
                <p><strong>Paper ID:</strong> paper-278782614</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2505.15047v2.pdf" target="_blank">PiFlow: Principle-aware Scientific Discovery with Multi-Agent Collaboration</a></p>
                <p><strong>Paper Abstract:</strong> Large Language Model (LLM)-based multi-agent systems (MAS) demonstrate remarkable potential for scientific discovery. Existing approaches, however, often automate scientific discovery using predefined workflows that lack rationality constraints. This often leads to aimless hypothesizing and a failure to consistently link hypotheses with evidence, thereby hindering the systematic reduction of uncertainty. Overcoming these limitations fundamentally requires a principled approach to exploration. We introduce PiFlow, an information-theoretical framework, treating automated scientific discovery as a structured uncertainty reduction problem guided by principles (e.g., scientific laws). In evaluations across three distinct scientific domains -- discovering nanomaterial structures, bio-molecules, and superconductor candidates with targeted properties -- our method significantly improves discovery efficiency, reflected by a 73.55\% increase in the Area Under the Curve (AUC) of property values versus exploration steps, and enhances solution quality by 94.06\% compared to a vanilla agent system. Overall, PiFlow serves as a Plug-and-Play method, establishing a novel paradigm shift in highly efficient automated scientific discovery, paving the way for more robust and accelerated AI-driven research. Code is publicly available at our \href{https://github.com/amair-lab/PiFlow}{GitHub}.</p>
                <p><strong>Cost:</strong> 0.022</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2200.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2200.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of validation approaches in automated or AI-driven scientific research systems, including experimental validation, computational validation, simulation-based validation, and comparisons between these approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Surrogate-model validation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Surrogate models used as validation functions</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The paper uses domain-specific, high-fidelity surrogate models (trained on simulation or experimental datasets) as the primary validation function f*(•) to evaluate hypotheses in place of costly real-world experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_or_method_name</strong></td>
                            <td>PiFlow (Hypothesis-Validation loop with surrogate f*(•))</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Materials science, chemistry, drug discovery, physics</td>
                        </tr>
                        <tr>
                            <td><strong>validation_type</strong></td>
                            <td>high-fidelity simulation</td>
                        </tr>
                        <tr>
                            <td><strong>validation_description</strong></td>
                            <td>Each discovery task uses a surrogate model as the validation function. For Nanohelix Optimization a LightGBM surrogate trained on DFT-simulated data (r^2 = 0.9802) predicts g-factor; for Molecular Bio-activity a Graph Neural Network surrogate trained on 50,000 ChEMBL35 molecules predicts pChEMBL (r^2 ≈ 0.91); for Superconductor Optimization a surrogate (following Hamidieh 2018) maps compositions to Tc (r^2 ≈ 0.91). These surrogates are queried by the Experiment Agent to return quantitative outcomes for each hypothesis.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_fidelity</strong></td>
                            <td>High-fidelity ML surrogates trained on physics-based simulation outputs (DFT-derived data for NHO) or large curated experimental datasets (ChEMBL35 for MBO). Reported fit metrics: NHO surrogate r^2 = 0.9802; MBO surrogate r^2 = 0.91; SPO surrogate r^2 = 0.91, indicating high predictive accuracy vs. withheld data.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation_performed</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_simulation_vs_experiment</strong></td>
                            <td>No direct experimental (wet-lab) vs. simulation comparisons are reported because real-world experiments were not performed; validation is entirely via surrogate predictions and internal empirical analyses.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_success_rate</strong></td>
                            <td>Not applicable (no physical experiments were performed); the paper reports surrogate predictive quality via r^2 on test sets instead of experimental validation rates.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_validation_standards</strong></td>
                            <td>Paper states domain practice: reliable surrogate/simulator or high-fidelity simulator is a prerequisite for automated discovery; use of r^2 and held-out testing to establish surrogate fidelity is treated as sufficient for virtual validation in this work.</td>
                        </tr>
                        <tr>
                            <td><strong>when_simulation_sufficient</strong></td>
                            <td>Authors explicitly argue simulation/surrogate suffices when real experiments are prohibitively expensive and when surrogate models achieve high fidelity (high r^2) relative to the task; they adopt this approach across all benchmarks.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_failures</strong></td>
                            <td>No explicit instances where surrogates failed vs. experiments are reported; limitations acknowledged that surrogate-based validation approximates true f* and may not capture all nuances (see Limitations section).</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>Surrogate predictive accuracy reported using r^2 values; experimental metrics (AUC, SQ) are reported with mean ± std across runs. No per-prediction error bars or calibrated uncertainty estimates from surrogates are described.</td>
                        </tr>
                        <tr>
                            <td><strong>fabrication_detection</strong></td>
                            <td>Not directly about fabricated data, but PiFlow's Min-Max empirical scoring can demote principles that consistently produce low surrogate outcomes, which the authors argue also helps detect and discard hallucinated/incorrect principles proposed by LLMs.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_cost_time</strong></td>
                            <td>Paper reports that wet-lab validation is prohibitively expensive; surrogate use enables all experiments locally. Cost comparisons given for token/API costs: PiFlow reduced token consumption and monetary token cost versus baselines (e.g., NHO PiFlow token cost $1.04 vs Vanilla $1.40 over runs); no real-world experimental time/costs provided.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_validation_approach</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>validation_limitations</strong></td>
                            <td>Authors acknowledge surrogate-based validation approximates the true evaluation function f* and that PiFlow's practical implementation approximates mutual information; direct experimental confirmation is lacking and remains a limitation.</td>
                        </tr>
                        <tr>
                            <td><strong>acceptance_credibility</strong></td>
                            <td>Paper notes that surrogate-based validation is common in AI-for-science and acceptable when surrogates are high-fidelity, but acknowledges absence of lab validation may affect community acceptance; they emphasize plug-and-play integration with existing validated tools as mitigation.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_gold_standard</strong></td>
                            <td>The gold standard (real experiments) was not performed; authors explicitly state real experiments are prohibitively expensive and thus used surrogates as the practical alternative. No numeric experiment-vs-surrogate comparisons are reported.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2200.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2200.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of validation approaches in automated or AI-driven scientific research systems, including experimental validation, computational validation, simulation-based validation, and comparisons between these approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DFT-simulated training data</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Density Functional Theory (DFT)-simulated data used to train surrogates</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>For the Nanohelix Optimization task, surrogate training data were generated from DFT simulations; the surrogate achieves very high predictive accuracy (r^2 ≈ 0.98) for g-factor predictions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_or_method_name</strong></td>
                            <td>DFT-simulated dataset → LightGBM surrogate</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Nanomaterials / computational materials science</td>
                        </tr>
                        <tr>
                            <td><strong>validation_type</strong></td>
                            <td>high-fidelity simulation</td>
                        </tr>
                        <tr>
                            <td><strong>validation_description</strong></td>
                            <td>DFT simulations (per Wu et al. 2025 methodology) generated the training labels for g-factor across nanohelix parameter space (6300 records). A LightGBM was trained (80/20 split, 5-fold CV) to predict g-factor as the experiment oracle.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_fidelity</strong></td>
                            <td>DFT is a physics-based approach modeling electronic structure; surrogate trained on DFT outputs achieved r^2 = 0.9802 versus held-out simulated data. The paper treats DFT-derived labels as a high-fidelity proxy for true physical outcomes.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation_performed</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_simulation_vs_experiment</strong></td>
                            <td>No lab experiments reported to compare against DFT; DFT outputs were used directly to build/trust the surrogate.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_success_rate</strong></td>
                            <td>Not applicable (no experimental validation); surrogate vs. DFT test performance given by r^2.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_validation_standards</strong></td>
                            <td>Use of DFT as high-fidelity simulator is standard in materials design; paper follows this norm by training and validating a surrogate against DFT outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>when_simulation_sufficient</strong></td>
                            <td>Implicit: when DFT data provide accurate physics and the surrogate reproduces DFT outputs with high r^2, simulation is considered sufficient for in-silico discovery iterations.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_failures</strong></td>
                            <td>No explicit DFT vs. empirical discrepancies are discussed.</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>r^2 metric reported; no other error bars for DFT or surrogate aleatoric/epistemic uncertainty provided.</td>
                        </tr>
                        <tr>
                            <td><strong>fabrication_detection</strong></td>
                            <td>Not applicable.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_cost_time</strong></td>
                            <td>DFT is computationally expensive; authors explicitly used surrogates to avoid repeated DFT calls. No absolute DFT runtimes provided.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_validation_approach</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>validation_limitations</strong></td>
                            <td>Acknowledged that surrogates approximate DFT and DFT may still differ from real experiments; thus, pipeline lacks wet-lab confirmation.</td>
                        </tr>
                        <tr>
                            <td><strong>acceptance_credibility</strong></td>
                            <td>Using DFT as training data is standard; surrogate success (r^2) supports credibility, but lack of experimental validation remains a caveat.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_gold_standard</strong></td>
                            <td>DFT is treated as the high-fidelity standard in-silico; not compared to wet-lab gold standard in this work.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2200.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2200.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of validation approaches in automated or AI-driven scientific research systems, including experimental validation, computational validation, simulation-based validation, and comparisons between these approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GNN surrogate for bioactivity</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Graph Neural Network surrogate trained on ChEMBL35 for pChEMBL prediction</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A GNN trained on 50,000 molecules (ChEMBL35) predicts pChEMBL bioactivity and serves as the experiment oracle for the Molecular Bio-activity Optimization task (reported r^2 ≈ 0.91).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_or_method_name</strong></td>
                            <td>GNN surrogate (MBO validation)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Computational chemistry / drug discovery</td>
                        </tr>
                        <tr>
                            <td><strong>validation_type</strong></td>
                            <td>high-fidelity simulation</td>
                        </tr>
                        <tr>
                            <td><strong>validation_description</strong></td>
                            <td>GNN trained on molecular graphs extracted from SMILES (50k samples, 80/20 split) outputs pChEMBL predictions used by Experiment Agent; model architecture uses graph convolutional layers capturing atomic/bond features.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_fidelity</strong></td>
                            <td>Surrogate models trained on curated experimental bioactivity (ChEMBL) — fidelity reflects reproduction of the dataset (r^2 ≈ 0.91). This reflects predictive accuracy on held-out molecules, but not necessarily absolute wet-lab reproducibility for novel chemotypes.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation_performed</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_simulation_vs_experiment</strong></td>
                            <td>No wet-lab validation of discovered molecules reported; best discovered pChEMBL values are surrogate predictions (e.g., PiFlow found ≈7.24 in main tasks; ChemToolAgent integration produced pChEMBL 5.90 in an 8-iteration run).</td>
                        </tr>
                        <tr>
                            <td><strong>validation_success_rate</strong></td>
                            <td>Not applicable in terms of experimental confirmation; surrogate test metrics reported reflect internal success.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_validation_standards</strong></td>
                            <td>Paper notes standard practice of training surrogates on large bioactivity datasets and treating surrogate performance (r^2) as evidence of sufficiency for virtual screening prior to wet-lab follow-up.</td>
                        </tr>
                        <tr>
                            <td><strong>when_simulation_sufficient</strong></td>
                            <td>Authors treat surrogate sufficiency as acceptable when trained on substantial, high-quality datasets and when performing well on held-out test sets; nevertheless, they acknowledge ultimate need for experimental validation outside the scope of this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_failures</strong></td>
                            <td>No explicit failures described; authors caution about extrapolation beyond training distribution.</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>r^2 on test set reported; no per-prediction uncertainty calibration described (e.g., ensembles, predictive intervals).</td>
                        </tr>
                        <tr>
                            <td><strong>fabrication_detection</strong></td>
                            <td>Not specifically addressed; PiFlow's mechanism can demote principles that yield poor surrogate outcomes, but this is not a substitute for experimental fabrication detection.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_cost_time</strong></td>
                            <td>Surrogate enabled rapid high-throughput screening; no wet-lab cost/time reported.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_validation_approach</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>validation_limitations</strong></td>
                            <td>Limits include surrogate generalization beyond ChEMBL chemical space and lack of wet-lab confirmation for top hits.</td>
                        </tr>
                        <tr>
                            <td><strong>acceptance_credibility</strong></td>
                            <td>Within computational drug-discovery workflows, surrogate validation is acceptable for candidate triage; authors still note that community acceptance ultimately depends on experimental confirmation.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_gold_standard</strong></td>
                            <td>No comparison to wet-lab assay results provided; surrogate test-set performance used instead.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2200.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2200.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of validation approaches in automated or AI-driven scientific research systems, including experimental validation, computational validation, simulation-based validation, and comparisons between these approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Comparison with Bayesian Optimization</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Performance comparison between PiFlow and Bayesian Optimization (BO)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The paper compares PiFlow to Bayesian Optimization baselines and reports PiFlow substantially outperforms BO on ill-structured tasks (notably MBO) because BO requires manual search-space engineering.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_or_method_name</strong></td>
                            <td>PiFlow vs Bayesian Optimization (baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Optimization methods applied to materials/chemistry</td>
                        </tr>
                        <tr>
                            <td><strong>validation_type</strong></td>
                            <td>computational validation / comparative benchmarking</td>
                        </tr>
                        <tr>
                            <td><strong>validation_description</strong></td>
                            <td>Authors ran 24-iteration BO runs on the three tasks using manually designed search spaces and compared AUC and SQ metrics to PiFlow runs. They argue BO is competitive on structured tasks (NHO) but underperforms on ill-structured/discrete MBO tasks. They report PiFlow MBO SQ = 84.55% vs BO's 38.15% (text claim); table entries also present multi-task comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_fidelity</strong></td>
                            <td>Comparison is entirely in-silico using the same surrogates/simulators as evaluation oracles; BO operates on parameterized numeric spaces while PiFlow reasons over principle space.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation_performed</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_simulation_vs_experiment</strong></td>
                            <td>Not applicable — both approaches evaluated against surrogate oracles, not wet-lab experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_success_rate</strong></td>
                            <td>N/A for experimental validation; comparison metrics include AUC(%) and SQ(%) reported with means and stds.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_validation_standards</strong></td>
                            <td>BO is presented as a widely-used computational optimization baseline; authors critique its reliance on manual space design as a domain-specific requirement.</td>
                        </tr>
                        <tr>
                            <td><strong>when_simulation_sufficient</strong></td>
                            <td>Authors show simulation is sufficient for comparative benchmarking of optimization algorithms in the in-silico evaluation setting.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_failures</strong></td>
                            <td>BO performed poorly on MBO when search-space parametrization was difficult; this is framed as BO limitation rather than surrogate failure.</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>Comparative statistics reported as means ± std across multiple runs/seeds; no formal statistical tests reported.</td>
                        </tr>
                        <tr>
                            <td><strong>fabrication_detection</strong></td>
                            <td>Not applicable.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_cost_time</strong></td>
                            <td>BO required manual expert effort to define search spaces (time cost). No absolute runtimes provided; authors claim PiFlow is cost-effective and reduces token/API usage.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_validation_approach</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>validation_limitations</strong></td>
                            <td>Comparisons are limited to surrogate-based evaluations; conclusions about real-world performance are qualified due to lack of wet-lab tests.</td>
                        </tr>
                        <tr>
                            <td><strong>acceptance_credibility</strong></td>
                            <td>Authors use benchmark performance to argue PiFlow's superiority in ill-structured search contexts; credibility limited by surrogate-only evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_gold_standard</strong></td>
                            <td>BO is considered a computational baseline rather than a gold-standard experimental validation method; comparison uses AUC and SQ metrics on surrogate oracles.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2200.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2200.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of validation approaches in automated or AI-driven scientific research systems, including experimental validation, computational validation, simulation-based validation, and comparisons between these approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Empirical algorithmic validation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Empirical validation of PiFlow theoretical guarantees (regret vs information gain)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The authors empirically validate PiFlow's theoretical properties (sublinear regret growth O(sqrt(T)) and coupling between information gain and regret) using simulated experiments driven by surrogates, reporting fitted decay and correlation metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_or_method_name</strong></td>
                            <td>PiFlow (Min-Max optimization with empirical validation)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Machine learning / algorithmic theory applied to scientific discovery</td>
                        </tr>
                        <tr>
                            <td><strong>validation_type</strong></td>
                            <td>computational validation (empirical)</td>
                        </tr>
                        <tr>
                            <td><strong>validation_description</strong></td>
                            <td>Empirical analyses include plotting average regret vs iterations (log-log) showing fit to c*T^-0.5 with fit c=1.37, r^2=0.96, scatter of regret vs information gain showing positive association, and trajectory visualization via PCA on NHO landscape demonstrating exploration->exploitation stages.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_fidelity</strong></td>
                            <td>Empirical tests are performed using the surrogate validation oracles described elsewhere in the paper; all algorithmic validation is therefore in-silico but tied to domain surrogates.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation_performed</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_simulation_vs_experiment</strong></td>
                            <td>No wet-lab experiments for algorithmic validation; results are reproducible on the surrogate-based testbed provided.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_success_rate</strong></td>
                            <td>Not applicable as a success rate; empirical metrics (fit r^2, trend consistency across runs) are provided.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_validation_standards</strong></td>
                            <td>Authors treat alignment between empirical curves and theoretical predictions (decay exponent, regret-information gain coupling) as sufficient evidence of theoretical validity in the simulated environment.</td>
                        </tr>
                        <tr>
                            <td><strong>when_simulation_sufficient</strong></td>
                            <td>Authors argue simulation/surrogate-based empirical validation suffices to validate algorithmic claims about exploration-exploitation trade-offs in automated discovery workflows.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_failures</strong></td>
                            <td>They note variance across runs (stochastic LLM agents) and transient deviations (one run increased regret temporarily) but overall alignment holds.</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>Empirical plots report fitted parameters and r^2; performance metrics across runs reported as mean ± std.</td>
                        </tr>
                        <tr>
                            <td><strong>fabrication_detection</strong></td>
                            <td>Not applicable.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_cost_time</strong></td>
                            <td>Computational experiments (24 iterations, multiple seeds) reported; authors remark PiFlow is token-cost efficient and report token/token-dollar costs, but no wall-clock times for algorithm runs.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_validation_approach</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>validation_limitations</strong></td>
                            <td>Empirical validation depends on surrogate fidelity; theoretical-to-practical gap exists because mutual information approximations are used in practice.</td>
                        </tr>
                        <tr>
                            <td><strong>acceptance_credibility</strong></td>
                            <td>Empirical alignment with theory strengthens confidence in PiFlow's strategy within simulated settings, but community acceptance would prefer wet-lab confirmation for domain-specific claims.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_gold_standard</strong></td>
                            <td>Gold standard for algorithmic proofs would be real-world experiments confirming reduced regret in lab trials; such comparisons are not provided.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2200.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e2200.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of validation approaches in automated or AI-driven scientific research systems, including experimental validation, computational validation, simulation-based validation, and comparisons between these approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ChemToolAgent integration (plug-and-play)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Plug-and-play integration with ChemToolAgent for molecular design validation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>PiFlow is integrated as an outer-loop strategic module with an existing tool-enabled agent (ChemToolAgent); the combined system used ChemToolAgent's toolset and the surrogate oracle to evolve a molecular candidate to pChEMBL 5.90 over 8 iterations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_or_method_name</strong></td>
                            <td>PiFlow + ChemToolAgent integration</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Computational chemistry / automated molecular design</td>
                        </tr>
                        <tr>
                            <td><strong>validation_type</strong></td>
                            <td>hybrid (tool-assisted computational validation)</td>
                        </tr>
                        <tr>
                            <td><strong>validation_description</strong></td>
                            <td>Integration run: ChemToolAgent supplies candidate molecules using its web/tool plugins (e.g., literature or database searches); PiFlow issues EXPLORE/REFINE directives; validation of candidates is performed by the surrogate pChEMBL predictor; no wet-lab assays were performed. Iterative log of 8 iterations provided with pChEMBL trajectory culminating in 5.90.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_fidelity</strong></td>
                            <td>Same GNN surrogate for pChEMBL (r^2 ≈ 0.91) used as the oracle; tool interactions (PubMed, websites) are used to inform principle/hypothesis generation but not to provide experimental ground truth.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation_performed</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_simulation_vs_experiment</strong></td>
                            <td>No experimental assays; comparison only between tool-assisted proposal mechanisms and surrogate outcomes.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_success_rate</strong></td>
                            <td>N/A for wet-lab validation; noted success in improving surrogate-predicted pChEMBL over iterations.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_validation_standards</strong></td>
                            <td>Authors present this as a realistic demonstration of plug-and-play compatibility with tool-enabled agents; surrogate validation suffices for the integration proof-of-concept.</td>
                        </tr>
                        <tr>
                            <td><strong>when_simulation_sufficient</strong></td>
                            <td>Sufficient for demonstrating strategic guidance and compatibility; authors note that final lead candidates would still require wet-lab follow-up in real discovery pipelines.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_failures</strong></td>
                            <td>No integration failures reported in this example; robustness of integration shown across 8-iteration run.</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>Reported pChEMBL values and the iteration log; no experimental error bars.</td>
                        </tr>
                        <tr>
                            <td><strong>fabrication_detection</strong></td>
                            <td>PiFlow's empirical rejection of consistently poor principles can prevent continued pursuit of tool-suggested but ineffective directions.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_cost_time</strong></td>
                            <td>Integration run completed in 8 iterations; authors highlight that PiFlow module itself is lightweight (1.2–1.5% of total tokens) and that token consumption was modest for the run; no wet-lab time/costs.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_validation_approach</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_limitations</strong></td>
                            <td>Integration demonstrates strategic compatibility but retains surrogate-only validation; actual chemical synthesis/assays absent.</td>
                        </tr>
                        <tr>
                            <td><strong>acceptance_credibility</strong></td>
                            <td>Demonstrates practical utility to practitioners using tool-enabled agents, but ultimate credibility for drug discovery needs experimental assays.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_gold_standard</strong></td>
                            <td>No wet-lab gold-standard comparison; integration validated only in-silico.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2200.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e2200.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of validation approaches in automated or AI-driven scientific research systems, including experimental validation, computational validation, simulation-based validation, and comparisons between these approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Rejecting hallucinated principles</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Empirical falsification/demotion of hallucinated or incorrect principles via Min-Max scoring</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>PiFlow uses empirical outcomes from surrogate experiments to lower the potential score of principles that repeatedly produce poor outcomes, thereby detecting and discarding hallucinated or incorrect principles proposed by LLMs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_or_method_name</strong></td>
                            <td>PiFlow Min-Max principle scoring (validation of principles)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Machine learning / automated scientific discovery</td>
                        </tr>
                        <tr>
                            <td><strong>validation_type</strong></td>
                            <td>computational validation (empirical falsification)</td>
                        </tr>
                        <tr>
                            <td><strong>validation_description</strong></td>
                            <td>When initial principles (even human-provided incorrect ones) lead to low surrogate outcomes, PiFlow's Min-Max optimization assigns low potential to them; the Planner switches to exploration and the system recovers. Ablation with Expert-Incorrect principles demonstrates recovery dynamics over iterations.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_fidelity</strong></td>
                            <td>Behavior demonstrated in surrogate-based experiments across NHO task; fidelity depends on surrogate accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation_performed</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_simulation_vs_experiment</strong></td>
                            <td>No wet-lab confirmation of 'false' principles; falsification is relative to surrogate outcomes.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_success_rate</strong></td>
                            <td>The paper reports successful recovery in ablations—incorrect-principle runs recovered to match/ exceed correct-initialization runs by iteration ~14 in surrogate experiments—but no numeric 'detection rate' provided.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_validation_standards</strong></td>
                            <td>Authors argue that empirical failure on the validation oracle (surrogate) is sufficient to demote a principle and that such demotion is how automated systems should detect hallucinations in the absence of wet-lab checks.</td>
                        </tr>
                        <tr>
                            <td><strong>when_simulation_sufficient</strong></td>
                            <td>Sufficient to detect internally inconsistent or low-performing principles within the simulated discovery loop.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_failures</strong></td>
                            <td>No specific counterexamples where PiFlow failed to identify a bad principle are presented; stochastic LLM behavior can cause variance.</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>Performance trajectories with means/std across seeds used to demonstrate recovery; no formal detection thresholds beyond exploitation score thresholds (e.g., >0.7 refine, >0.4 validate).</td>
                        </tr>
                        <tr>
                            <td><strong>fabrication_detection</strong></td>
                            <td>This mechanism is explicitly presented as a way to detect hallucinated or incorrect principles by empirical demotion based on observed poor outcomes.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_cost_time</strong></td>
                            <td>Cost measured in tokens and iterations; demoting bad principles requires running experiments (surrogate calls) which have low computational cost compared to wet-lab experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_validation_approach</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>validation_limitations</strong></td>
                            <td>Detection relies on surrogate correctness; if the surrogate is wrong, good principles could be mistakenly demoted or bad ones retained.</td>
                        </tr>
                        <tr>
                            <td><strong>acceptance_credibility</strong></td>
                            <td>Authors present this as an advantage over purely rhetorical LLM-driven approaches, improving credibility of hypotheses in simulated pipelines; still limited by surrogate fidelity.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_gold_standard</strong></td>
                            <td>Gold-standard detection would be wet-lab falsification; surrogate-based demotion is a pragmatic stand-in but not equivalent.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Machine learned structure-property correlation between nanohelices and circular dichroism <em>(Rating: 2)</em></li>
                <li>A data-driven statistical model for predicting the critical temperature of a superconductor <em>(Rating: 2)</em></li>
                <li>The ChEMBL database in 2023: a drug discovery platform spanning multiple bioactivity data types and time periods <em>(Rating: 2)</em></li>
                <li>Bayesian Optimization (general resources / surveys) <em>(Rating: 1)</em></li>
                <li>ChemToolAgent: The impact of tools on language agents for chemistry problem solving <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2200",
    "paper_id": "paper-278782614",
    "extraction_schema_id": "extraction-schema-58",
    "extracted_data": [
        {
            "name_short": "Surrogate-model validation",
            "name_full": "Surrogate models used as validation functions",
            "brief_description": "The paper uses domain-specific, high-fidelity surrogate models (trained on simulation or experimental datasets) as the primary validation function f*(•) to evaluate hypotheses in place of costly real-world experiments.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_or_method_name": "PiFlow (Hypothesis-Validation loop with surrogate f*(•))",
            "scientific_domain": "Materials science, chemistry, drug discovery, physics",
            "validation_type": "high-fidelity simulation",
            "validation_description": "Each discovery task uses a surrogate model as the validation function. For Nanohelix Optimization a LightGBM surrogate trained on DFT-simulated data (r^2 = 0.9802) predicts g-factor; for Molecular Bio-activity a Graph Neural Network surrogate trained on 50,000 ChEMBL35 molecules predicts pChEMBL (r^2 ≈ 0.91); for Superconductor Optimization a surrogate (following Hamidieh 2018) maps compositions to Tc (r^2 ≈ 0.91). These surrogates are queried by the Experiment Agent to return quantitative outcomes for each hypothesis.",
            "simulation_fidelity": "High-fidelity ML surrogates trained on physics-based simulation outputs (DFT-derived data for NHO) or large curated experimental datasets (ChEMBL35 for MBO). Reported fit metrics: NHO surrogate r^2 = 0.9802; MBO surrogate r^2 = 0.91; SPO surrogate r^2 = 0.91, indicating high predictive accuracy vs. withheld data.",
            "experimental_validation_performed": false,
            "comparison_simulation_vs_experiment": "No direct experimental (wet-lab) vs. simulation comparisons are reported because real-world experiments were not performed; validation is entirely via surrogate predictions and internal empirical analyses.",
            "validation_success_rate": "Not applicable (no physical experiments were performed); the paper reports surrogate predictive quality via r^2 on test sets instead of experimental validation rates.",
            "domain_validation_standards": "Paper states domain practice: reliable surrogate/simulator or high-fidelity simulator is a prerequisite for automated discovery; use of r^2 and held-out testing to establish surrogate fidelity is treated as sufficient for virtual validation in this work.",
            "when_simulation_sufficient": "Authors explicitly argue simulation/surrogate suffices when real experiments are prohibitively expensive and when surrogate models achieve high fidelity (high r^2) relative to the task; they adopt this approach across all benchmarks.",
            "simulation_failures": "No explicit instances where surrogates failed vs. experiments are reported; limitations acknowledged that surrogate-based validation approximates true f* and may not capture all nuances (see Limitations section).",
            "uncertainty_quantification": "Surrogate predictive accuracy reported using r^2 values; experimental metrics (AUC, SQ) are reported with mean ± std across runs. No per-prediction error bars or calibrated uncertainty estimates from surrogates are described.",
            "fabrication_detection": "Not directly about fabricated data, but PiFlow's Min-Max empirical scoring can demote principles that consistently produce low surrogate outcomes, which the authors argue also helps detect and discard hallucinated/incorrect principles proposed by LLMs.",
            "validation_cost_time": "Paper reports that wet-lab validation is prohibitively expensive; surrogate use enables all experiments locally. Cost comparisons given for token/API costs: PiFlow reduced token consumption and monetary token cost versus baselines (e.g., NHO PiFlow token cost $1.04 vs Vanilla $1.40 over runs); no real-world experimental time/costs provided.",
            "hybrid_validation_approach": false,
            "validation_limitations": "Authors acknowledge surrogate-based validation approximates the true evaluation function f* and that PiFlow's practical implementation approximates mutual information; direct experimental confirmation is lacking and remains a limitation.",
            "acceptance_credibility": "Paper notes that surrogate-based validation is common in AI-for-science and acceptable when surrogates are high-fidelity, but acknowledges absence of lab validation may affect community acceptance; they emphasize plug-and-play integration with existing validated tools as mitigation.",
            "comparison_to_gold_standard": "The gold standard (real experiments) was not performed; authors explicitly state real experiments are prohibitively expensive and thus used surrogates as the practical alternative. No numeric experiment-vs-surrogate comparisons are reported.",
            "uuid": "e2200.0"
        },
        {
            "name_short": "DFT-simulated training data",
            "name_full": "Density Functional Theory (DFT)-simulated data used to train surrogates",
            "brief_description": "For the Nanohelix Optimization task, surrogate training data were generated from DFT simulations; the surrogate achieves very high predictive accuracy (r^2 ≈ 0.98) for g-factor predictions.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_or_method_name": "DFT-simulated dataset → LightGBM surrogate",
            "scientific_domain": "Nanomaterials / computational materials science",
            "validation_type": "high-fidelity simulation",
            "validation_description": "DFT simulations (per Wu et al. 2025 methodology) generated the training labels for g-factor across nanohelix parameter space (6300 records). A LightGBM was trained (80/20 split, 5-fold CV) to predict g-factor as the experiment oracle.",
            "simulation_fidelity": "DFT is a physics-based approach modeling electronic structure; surrogate trained on DFT outputs achieved r^2 = 0.9802 versus held-out simulated data. The paper treats DFT-derived labels as a high-fidelity proxy for true physical outcomes.",
            "experimental_validation_performed": false,
            "comparison_simulation_vs_experiment": "No lab experiments reported to compare against DFT; DFT outputs were used directly to build/trust the surrogate.",
            "validation_success_rate": "Not applicable (no experimental validation); surrogate vs. DFT test performance given by r^2.",
            "domain_validation_standards": "Use of DFT as high-fidelity simulator is standard in materials design; paper follows this norm by training and validating a surrogate against DFT outputs.",
            "when_simulation_sufficient": "Implicit: when DFT data provide accurate physics and the surrogate reproduces DFT outputs with high r^2, simulation is considered sufficient for in-silico discovery iterations.",
            "simulation_failures": "No explicit DFT vs. empirical discrepancies are discussed.",
            "uncertainty_quantification": "r^2 metric reported; no other error bars for DFT or surrogate aleatoric/epistemic uncertainty provided.",
            "fabrication_detection": "Not applicable.",
            "validation_cost_time": "DFT is computationally expensive; authors explicitly used surrogates to avoid repeated DFT calls. No absolute DFT runtimes provided.",
            "hybrid_validation_approach": false,
            "validation_limitations": "Acknowledged that surrogates approximate DFT and DFT may still differ from real experiments; thus, pipeline lacks wet-lab confirmation.",
            "acceptance_credibility": "Using DFT as training data is standard; surrogate success (r^2) supports credibility, but lack of experimental validation remains a caveat.",
            "comparison_to_gold_standard": "DFT is treated as the high-fidelity standard in-silico; not compared to wet-lab gold standard in this work.",
            "uuid": "e2200.1"
        },
        {
            "name_short": "GNN surrogate for bioactivity",
            "name_full": "Graph Neural Network surrogate trained on ChEMBL35 for pChEMBL prediction",
            "brief_description": "A GNN trained on 50,000 molecules (ChEMBL35) predicts pChEMBL bioactivity and serves as the experiment oracle for the Molecular Bio-activity Optimization task (reported r^2 ≈ 0.91).",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_or_method_name": "GNN surrogate (MBO validation)",
            "scientific_domain": "Computational chemistry / drug discovery",
            "validation_type": "high-fidelity simulation",
            "validation_description": "GNN trained on molecular graphs extracted from SMILES (50k samples, 80/20 split) outputs pChEMBL predictions used by Experiment Agent; model architecture uses graph convolutional layers capturing atomic/bond features.",
            "simulation_fidelity": "Surrogate models trained on curated experimental bioactivity (ChEMBL) — fidelity reflects reproduction of the dataset (r^2 ≈ 0.91). This reflects predictive accuracy on held-out molecules, but not necessarily absolute wet-lab reproducibility for novel chemotypes.",
            "experimental_validation_performed": false,
            "comparison_simulation_vs_experiment": "No wet-lab validation of discovered molecules reported; best discovered pChEMBL values are surrogate predictions (e.g., PiFlow found ≈7.24 in main tasks; ChemToolAgent integration produced pChEMBL 5.90 in an 8-iteration run).",
            "validation_success_rate": "Not applicable in terms of experimental confirmation; surrogate test metrics reported reflect internal success.",
            "domain_validation_standards": "Paper notes standard practice of training surrogates on large bioactivity datasets and treating surrogate performance (r^2) as evidence of sufficiency for virtual screening prior to wet-lab follow-up.",
            "when_simulation_sufficient": "Authors treat surrogate sufficiency as acceptable when trained on substantial, high-quality datasets and when performing well on held-out test sets; nevertheless, they acknowledge ultimate need for experimental validation outside the scope of this paper.",
            "simulation_failures": "No explicit failures described; authors caution about extrapolation beyond training distribution.",
            "uncertainty_quantification": "r^2 on test set reported; no per-prediction uncertainty calibration described (e.g., ensembles, predictive intervals).",
            "fabrication_detection": "Not specifically addressed; PiFlow's mechanism can demote principles that yield poor surrogate outcomes, but this is not a substitute for experimental fabrication detection.",
            "validation_cost_time": "Surrogate enabled rapid high-throughput screening; no wet-lab cost/time reported.",
            "hybrid_validation_approach": false,
            "validation_limitations": "Limits include surrogate generalization beyond ChEMBL chemical space and lack of wet-lab confirmation for top hits.",
            "acceptance_credibility": "Within computational drug-discovery workflows, surrogate validation is acceptable for candidate triage; authors still note that community acceptance ultimately depends on experimental confirmation.",
            "comparison_to_gold_standard": "No comparison to wet-lab assay results provided; surrogate test-set performance used instead.",
            "uuid": "e2200.2"
        },
        {
            "name_short": "Comparison with Bayesian Optimization",
            "name_full": "Performance comparison between PiFlow and Bayesian Optimization (BO)",
            "brief_description": "The paper compares PiFlow to Bayesian Optimization baselines and reports PiFlow substantially outperforms BO on ill-structured tasks (notably MBO) because BO requires manual search-space engineering.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_or_method_name": "PiFlow vs Bayesian Optimization (baseline)",
            "scientific_domain": "Optimization methods applied to materials/chemistry",
            "validation_type": "computational validation / comparative benchmarking",
            "validation_description": "Authors ran 24-iteration BO runs on the three tasks using manually designed search spaces and compared AUC and SQ metrics to PiFlow runs. They argue BO is competitive on structured tasks (NHO) but underperforms on ill-structured/discrete MBO tasks. They report PiFlow MBO SQ = 84.55% vs BO's 38.15% (text claim); table entries also present multi-task comparisons.",
            "simulation_fidelity": "Comparison is entirely in-silico using the same surrogates/simulators as evaluation oracles; BO operates on parameterized numeric spaces while PiFlow reasons over principle space.",
            "experimental_validation_performed": false,
            "comparison_simulation_vs_experiment": "Not applicable — both approaches evaluated against surrogate oracles, not wet-lab experiments.",
            "validation_success_rate": "N/A for experimental validation; comparison metrics include AUC(%) and SQ(%) reported with means and stds.",
            "domain_validation_standards": "BO is presented as a widely-used computational optimization baseline; authors critique its reliance on manual space design as a domain-specific requirement.",
            "when_simulation_sufficient": "Authors show simulation is sufficient for comparative benchmarking of optimization algorithms in the in-silico evaluation setting.",
            "simulation_failures": "BO performed poorly on MBO when search-space parametrization was difficult; this is framed as BO limitation rather than surrogate failure.",
            "uncertainty_quantification": "Comparative statistics reported as means ± std across multiple runs/seeds; no formal statistical tests reported.",
            "fabrication_detection": "Not applicable.",
            "validation_cost_time": "BO required manual expert effort to define search spaces (time cost). No absolute runtimes provided; authors claim PiFlow is cost-effective and reduces token/API usage.",
            "hybrid_validation_approach": false,
            "validation_limitations": "Comparisons are limited to surrogate-based evaluations; conclusions about real-world performance are qualified due to lack of wet-lab tests.",
            "acceptance_credibility": "Authors use benchmark performance to argue PiFlow's superiority in ill-structured search contexts; credibility limited by surrogate-only evaluation.",
            "comparison_to_gold_standard": "BO is considered a computational baseline rather than a gold-standard experimental validation method; comparison uses AUC and SQ metrics on surrogate oracles.",
            "uuid": "e2200.3"
        },
        {
            "name_short": "Empirical algorithmic validation",
            "name_full": "Empirical validation of PiFlow theoretical guarantees (regret vs information gain)",
            "brief_description": "The authors empirically validate PiFlow's theoretical properties (sublinear regret growth O(sqrt(T)) and coupling between information gain and regret) using simulated experiments driven by surrogates, reporting fitted decay and correlation metrics.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_or_method_name": "PiFlow (Min-Max optimization with empirical validation)",
            "scientific_domain": "Machine learning / algorithmic theory applied to scientific discovery",
            "validation_type": "computational validation (empirical)",
            "validation_description": "Empirical analyses include plotting average regret vs iterations (log-log) showing fit to c*T^-0.5 with fit c=1.37, r^2=0.96, scatter of regret vs information gain showing positive association, and trajectory visualization via PCA on NHO landscape demonstrating exploration-&gt;exploitation stages.",
            "simulation_fidelity": "Empirical tests are performed using the surrogate validation oracles described elsewhere in the paper; all algorithmic validation is therefore in-silico but tied to domain surrogates.",
            "experimental_validation_performed": false,
            "comparison_simulation_vs_experiment": "No wet-lab experiments for algorithmic validation; results are reproducible on the surrogate-based testbed provided.",
            "validation_success_rate": "Not applicable as a success rate; empirical metrics (fit r^2, trend consistency across runs) are provided.",
            "domain_validation_standards": "Authors treat alignment between empirical curves and theoretical predictions (decay exponent, regret-information gain coupling) as sufficient evidence of theoretical validity in the simulated environment.",
            "when_simulation_sufficient": "Authors argue simulation/surrogate-based empirical validation suffices to validate algorithmic claims about exploration-exploitation trade-offs in automated discovery workflows.",
            "simulation_failures": "They note variance across runs (stochastic LLM agents) and transient deviations (one run increased regret temporarily) but overall alignment holds.",
            "uncertainty_quantification": "Empirical plots report fitted parameters and r^2; performance metrics across runs reported as mean ± std.",
            "fabrication_detection": "Not applicable.",
            "validation_cost_time": "Computational experiments (24 iterations, multiple seeds) reported; authors remark PiFlow is token-cost efficient and report token/token-dollar costs, but no wall-clock times for algorithm runs.",
            "hybrid_validation_approach": false,
            "validation_limitations": "Empirical validation depends on surrogate fidelity; theoretical-to-practical gap exists because mutual information approximations are used in practice.",
            "acceptance_credibility": "Empirical alignment with theory strengthens confidence in PiFlow's strategy within simulated settings, but community acceptance would prefer wet-lab confirmation for domain-specific claims.",
            "comparison_to_gold_standard": "Gold standard for algorithmic proofs would be real-world experiments confirming reduced regret in lab trials; such comparisons are not provided.",
            "uuid": "e2200.4"
        },
        {
            "name_short": "ChemToolAgent integration (plug-and-play)",
            "name_full": "Plug-and-play integration with ChemToolAgent for molecular design validation",
            "brief_description": "PiFlow is integrated as an outer-loop strategic module with an existing tool-enabled agent (ChemToolAgent); the combined system used ChemToolAgent's toolset and the surrogate oracle to evolve a molecular candidate to pChEMBL 5.90 over 8 iterations.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_or_method_name": "PiFlow + ChemToolAgent integration",
            "scientific_domain": "Computational chemistry / automated molecular design",
            "validation_type": "hybrid (tool-assisted computational validation)",
            "validation_description": "Integration run: ChemToolAgent supplies candidate molecules using its web/tool plugins (e.g., literature or database searches); PiFlow issues EXPLORE/REFINE directives; validation of candidates is performed by the surrogate pChEMBL predictor; no wet-lab assays were performed. Iterative log of 8 iterations provided with pChEMBL trajectory culminating in 5.90.",
            "simulation_fidelity": "Same GNN surrogate for pChEMBL (r^2 ≈ 0.91) used as the oracle; tool interactions (PubMed, websites) are used to inform principle/hypothesis generation but not to provide experimental ground truth.",
            "experimental_validation_performed": false,
            "comparison_simulation_vs_experiment": "No experimental assays; comparison only between tool-assisted proposal mechanisms and surrogate outcomes.",
            "validation_success_rate": "N/A for wet-lab validation; noted success in improving surrogate-predicted pChEMBL over iterations.",
            "domain_validation_standards": "Authors present this as a realistic demonstration of plug-and-play compatibility with tool-enabled agents; surrogate validation suffices for the integration proof-of-concept.",
            "when_simulation_sufficient": "Sufficient for demonstrating strategic guidance and compatibility; authors note that final lead candidates would still require wet-lab follow-up in real discovery pipelines.",
            "simulation_failures": "No integration failures reported in this example; robustness of integration shown across 8-iteration run.",
            "uncertainty_quantification": "Reported pChEMBL values and the iteration log; no experimental error bars.",
            "fabrication_detection": "PiFlow's empirical rejection of consistently poor principles can prevent continued pursuit of tool-suggested but ineffective directions.",
            "validation_cost_time": "Integration run completed in 8 iterations; authors highlight that PiFlow module itself is lightweight (1.2–1.5% of total tokens) and that token consumption was modest for the run; no wet-lab time/costs.",
            "hybrid_validation_approach": true,
            "validation_limitations": "Integration demonstrates strategic compatibility but retains surrogate-only validation; actual chemical synthesis/assays absent.",
            "acceptance_credibility": "Demonstrates practical utility to practitioners using tool-enabled agents, but ultimate credibility for drug discovery needs experimental assays.",
            "comparison_to_gold_standard": "No wet-lab gold-standard comparison; integration validated only in-silico.",
            "uuid": "e2200.5"
        },
        {
            "name_short": "Rejecting hallucinated principles",
            "name_full": "Empirical falsification/demotion of hallucinated or incorrect principles via Min-Max scoring",
            "brief_description": "PiFlow uses empirical outcomes from surrogate experiments to lower the potential score of principles that repeatedly produce poor outcomes, thereby detecting and discarding hallucinated or incorrect principles proposed by LLMs.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_or_method_name": "PiFlow Min-Max principle scoring (validation of principles)",
            "scientific_domain": "Machine learning / automated scientific discovery",
            "validation_type": "computational validation (empirical falsification)",
            "validation_description": "When initial principles (even human-provided incorrect ones) lead to low surrogate outcomes, PiFlow's Min-Max optimization assigns low potential to them; the Planner switches to exploration and the system recovers. Ablation with Expert-Incorrect principles demonstrates recovery dynamics over iterations.",
            "simulation_fidelity": "Behavior demonstrated in surrogate-based experiments across NHO task; fidelity depends on surrogate accuracy.",
            "experimental_validation_performed": false,
            "comparison_simulation_vs_experiment": "No wet-lab confirmation of 'false' principles; falsification is relative to surrogate outcomes.",
            "validation_success_rate": "The paper reports successful recovery in ablations—incorrect-principle runs recovered to match/ exceed correct-initialization runs by iteration ~14 in surrogate experiments—but no numeric 'detection rate' provided.",
            "domain_validation_standards": "Authors argue that empirical failure on the validation oracle (surrogate) is sufficient to demote a principle and that such demotion is how automated systems should detect hallucinations in the absence of wet-lab checks.",
            "when_simulation_sufficient": "Sufficient to detect internally inconsistent or low-performing principles within the simulated discovery loop.",
            "simulation_failures": "No specific counterexamples where PiFlow failed to identify a bad principle are presented; stochastic LLM behavior can cause variance.",
            "uncertainty_quantification": "Performance trajectories with means/std across seeds used to demonstrate recovery; no formal detection thresholds beyond exploitation score thresholds (e.g., &gt;0.7 refine, &gt;0.4 validate).",
            "fabrication_detection": "This mechanism is explicitly presented as a way to detect hallucinated or incorrect principles by empirical demotion based on observed poor outcomes.",
            "validation_cost_time": "Cost measured in tokens and iterations; demoting bad principles requires running experiments (surrogate calls) which have low computational cost compared to wet-lab experiments.",
            "hybrid_validation_approach": false,
            "validation_limitations": "Detection relies on surrogate correctness; if the surrogate is wrong, good principles could be mistakenly demoted or bad ones retained.",
            "acceptance_credibility": "Authors present this as an advantage over purely rhetorical LLM-driven approaches, improving credibility of hypotheses in simulated pipelines; still limited by surrogate fidelity.",
            "comparison_to_gold_standard": "Gold-standard detection would be wet-lab falsification; surrogate-based demotion is a pragmatic stand-in but not equivalent.",
            "uuid": "e2200.6"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Machine learned structure-property correlation between nanohelices and circular dichroism",
            "rating": 2
        },
        {
            "paper_title": "A data-driven statistical model for predicting the critical temperature of a superconductor",
            "rating": 2
        },
        {
            "paper_title": "The ChEMBL database in 2023: a drug discovery platform spanning multiple bioactivity data types and time periods",
            "rating": 2
        },
        {
            "paper_title": "Bayesian Optimization (general resources / surveys)",
            "rating": 1
        },
        {
            "paper_title": "ChemToolAgent: The impact of tools on language agents for chemistry problem solving",
            "rating": 2
        }
    ],
    "cost": 0.022271,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>PIFLOW: PRINCIPLE-AWARE SCIENTIFIC DISCOVERY WITH MULTI-AGENT COLLABORATION
29 Sep 2025</p>
<p>Yingming Pu puyingming@westlake.edu.cn 
Westlake University</p>
<p>Zhejiang University</p>
<p>Tao Lin lintao@westlake.edu.cn 
Westlake University</p>
<p>Hongyu Chen 
Westlake University</p>
<p>PIFLOW: PRINCIPLE-AWARE SCIENTIFIC DISCOVERY WITH MULTI-AGENT COLLABORATION
29 Sep 20254F713FDD384AC04AC4B03B23021AAF14arXiv:2505.15047v2[cs.LG]
Large Language Model (LLM)-based multi-agent systems (MAS) demonstrate remarkable potential for scientific discovery.Existing approaches, however, often automate scientific discovery using predefined workflows that lack rationality constraints.This often leads to aimless hypothesizing and a failure to consistently link hypotheses with evidence, thereby hindering the systematic reduction of uncertainty.Overcoming these limitations fundamentally requires a principled approach to exploration.We introduce PiFlow, an information-theoretical framework, treating automated scientific discovery as a structured uncertainty reduction problem guided by principles (e.g., scientific laws).In evaluations across three distinct scientific domains -discovering nanomaterial structures, bio-molecules, and superconductor candidates with targeted properties -our method significantly improves discovery efficiency, reflected by a 73.55% increase in the Area Under the Curve (AUC) of property values versus exploration steps, and enhances solution quality by 94.06% compared to a vanilla agent system.Overall, PiFlow serves as a Plug-and-Play method, establishing a novel paradigm shift in highly efficient automated scientific discovery, paving the way for more robust and accelerated AI-driven research.</p>
<p>INTRODUCTION</p>
<p>Large Language Model (LLM)-based Multi-Agent Systems (MAS) have significantly impacted automated scientific discovery (Minaee et al., 2024;Wang et al., 2023;Zhang et al., 2024c) across a wide range of fundamental fields, including chemistry (Liu et al., 2024;Ghafarollahi &amp; Buehler, 2024a;Yang et al., 2024c;Inoue et al., 2024), biology (Xiao et al., 2024;Nagarajan et al., 2025;Averly et al., 2025;Ghafarollahi &amp; Buehler, 2024b), physics (Jaiswal et al., 2024), and material science (Takahara et al., 2025;Ghafarollahi &amp; Buehler, 2025;Ansari et al., 2024;Wan et al., 2024;Zhang et al., 2024b).</p>
<p>Although proficient in executing experiments within predefined workflows (Lu et al., 2024;Lai &amp; Pu, 2025), these systems often generate hypotheses that lack clear direction, leading to the uncertainty establishing clear links between hypotheses and their supporting or refuting evidence (AI4Science &amp; Quantum, 2023; Zhou et al., 2024;Baek et al., 2024;Schmidgall et al., 2025;Prabhakar et al., 2025;Xie et al., 2023a).Such a disconnect indicates inefficient exploration.Moreover, many of these approaches are tailored for specific tasks, often relying on meticulous prompt engineering that heavily incorporates domain knowledge (as detailed in Appendix D).Consequently, their ability to adapt to new scientific domains is often limited without substantial modifications (Zhang et al., 2025;Kumbhar et al., 2025).These issues culminate in three primary challenges: (a) aimless hypothesizing; (b) unmaintained connections between hypotheses and evidence during exploration, hindering systematic validation and (c) limited generalization ability, where systems effective in one scenario (e.g., material science) often require substantial rework to be applicable in others.</p>
<p>To address these limitations, we introduce PiFlow, an information-theoretic framework for structured uncertainty reduction in scientific discovery.Viewing scientific exploration as a game against an unknown and challenging nature, where robust strategies are paramount, PiFlow employs Min-Max Principle ( )
p i
Figure 1: Illustration of the potential of a scientific principle in drug discovery.PiFlow directs exploration to prioritize hypotheses aligned with high-potential principles (or their variants), thereby iteratively guiding the discovery towards optimal candidate molecules.</p>
<p>optimization: minimizing cumulative regret for exploitation, while maximizing information gain for efficient hypothesis exploration.As a Plug-and-Play module, PiFlow integrates with MAS capable of hypothesizing and experimentation.Inspired by the challenge of navigating vast hypothesis spaces, PiFlow operates by using fundamental scientific principles, which may be initially proposed by or refined using LLMs.</p>
<p>The iterative selection of principles progressively reduces uncertainty in hypothesizing and the interpretation of evidence, dynamically steering exploration by prioritizing those scientific principles that offer the highest instructive value for continued exploration.Figure 1 illustrates PiFlow's method for assessing and utilizing scientific principles within a drug discovery context.</p>
<p>This principle-aware approach yields systematic information gain: PiFlow selects high-potential principles and then guides hypothesizing via three actions, i.e., exploring, validating, or refining their scope and formulation.Thus, PiFlow progressively optimizes its guiding scientific principles to effectively steer hypothesizing.Furthermore, leveraging its Min-Max optimization, PiFlow theoretically achieves cumulative regret growth of O( √ T ) over T exploration steps (a detailed proof is provided in Appendix F).This sublinear regret underscores its guaranteed efficiency in navigating complex discovery landscapes.In summary, our contributions are:</p>
<p>(a) We propose a novel paradigm for principle-aware scientific discovery, built upon an information-theoretical foundation that offers convergence guarantees.</p>
<p>(b) We develop PiFlow, a Plug-and-Play framework that seamlessly integrates with existing MAS to enable focused exploration, thereby enhancing discovery efficiency and flexibility.</p>
<p>(c) We conduct extensive experiments across three distinct scenarios, demonstrating the broad applicability and significant performance improvements achieved by PiFlow.</p>
<p>RELATED WORK</p>
<p>LANGUAGE MODELS FOR SCIENTIFIC DISCOVERY</p>
<p>Recently, large language models (LLM) have advanced scientific discovery with automation and rational design (Ren et al., 2025;Ma et al., 2024).The internal knowledge of LLMs has demonstrated promising capability in focused chemical and material discovery (Yang et al., 2024c;Zhou et al., 2024;Pu et al., 2024;Ghafarollahi &amp; Buehler, 2024c).While tool-integrated LLMs like SciAgents (Ghafarollahi &amp; Buehler, 2024d), DARWIN (Xie et al., 2023a) and HoneyComb (Zhang et al., 2024a) improve domain-specific reasoning and recall of factual insights, they still struggle to integrate physicochemical laws effectively when refining insights for design, risking biased proposals and inefficient exploration due to inherent hallucinations of LLMs (Zhang et al., 2023b).Human-AI frameworks address this issue by leveraging the knowledge of domain experts (Reddy &amp; Shojaee, 2024; Eythorsson &amp; Clark, 2025), yet remain limited to the scope of hypothesis generation (Alkan et al., 2025), leading to insufficient exploration of complex chemical spaces (Luo et al., 2025).Surveys highlight persistent gaps in efficiency and interpretability (Zhang et al., 2024c;Han et al., 2024), underscoring the need for principled scientific discovery management beyond automated LLM reasoning (Ramos et al., 2024).</p>
<p>APPROACHES OF MULTI-AGENT COLLABORATION</p>
<p>Multi-agent systems (MAS) show promise for complex tasks (Lu et al., 2024;Ghafarollahi &amp; Buehler, 2024d;Ni &amp; Buehler, 2023), yet their application to scientific discovery reveals limitations in current collaboration mechanisms (Tran et al., 2025).Rule-based methods (Zhang et al., 2023a) offer consistency but their predefined rules lack the flexibility to incorporate nuanced scientific principles (e.g., physicochemical laws) or adapt to unexpected findings, hindering dynamic exploration.Roleplaying approaches (Tran et al., 2025;He et al., 2024) leverage agent expertise, yet rigid roles can impede adaptation in scientific research (Ramirez-Medina et al., 2025;Lu et al., 2024;Ghafarollahi &amp; Buehler, 2024d), and ensuring collective adherence to scientific principles when interpreting experimental insights is challenging.Model-based methods (Xu et al., 2023;Mu et al., 2023;Li et al., 2023) aim for adaptability by learning from uncertainty, but struggle to build world models that accurately capture complex scientific phenomena and integrate guiding laws (Hao et al., 2023), thereby impairing the balance between information perception and strategic, principle-guided reasoning.</p>
<p>Consequently, existing MAS paradigms often lack a dedicated awareness and systematic application of scientific principles during hypothesis generation and refinement (Gridach et al., 2025;Luo et al., 2025;Reddy &amp; Shojaee, 2024;Su et al., 2024).This highlights a critical need for an explicitly principle-aware multi-agent collaboration framework.Our work addresses this gap, proposing a method where the collaborative discovery process is robustly guided by scientific principles to achieve more efficient and reliable outcomes.</p>
<p>METHODOLOGY</p>
<p>OVERVIEW</p>
<p>We propose a principle-aware MAS designed to enhance scientific discovery via focused hypothesizing and structured exploration of hypothesis-evidence connections.Figure 2 illustrates the architecture.Its core comprises a Hypothesis-Validation loop that iteratively generates and tests hypotheses.PiFlow guides this loop by optimizing accumulated principle-outcome data.Strategic insights dynamically optimized by PiFlow are relayed through a Planner agent (A P ) to the Hypothesis Agent within the loop.Subsequent sections will elaborate on PiFlow's specific architecture and its information-theoretical underpinnings.</p>
<p>ARCHITECTURE</p>
<p>Our proposed principle-aware system leverages LLM-based MAS to conduct scientific discovery through strategic hypothesizing.The framework is comprised of two core, interconnected components:</p>
<p>(1) an MAS that executes a Hypothesis-Validation loop, and (2) PiFlow, which serves as the strategic director for this loop.Definition 3.1 (Scientific Principles).The scientific principles are foundational concepts, established laws, or patterns, articulated as natural language statements, that explain phenomena within a specific scientific domain.These principles serve as high-level conceptual building blocks from which specific, testable hypotheses can be derived.This conceptualization aligns with broader discussions on the nature of scientific knowledge (Poincaré, 1906).</p>
<p>Hypothesis-Validation Loop.As depicted in the right-hand side of Figure 2, the Hypothesis-Validation loop constitutes the core operational cycle and incorporates two LLM-based agents: Hypothesis Agent (A H ) and Experiment Agent (A E ), detailed below:</p>
<p>(a) Hypothesis.Initially, a set of dynamically growing candidate principles P = {p 1 , p   This iterative process progressively establishes a record of principle-outcome pairs, T t = {⟨p k , y k ⟩} t k=1 , linking each hypothesized principle p k to its observed experimental outcome y k .While this loop systematically generates valuable evidence in trajectory T t , the selection of potential principles for subsequent hypotheses can lack strategic direction if not externally guided.This may lead to inefficient exploration of the principle space or premature convergence on suboptimal findings.</p>
<p>Hypothesis steering with PiFlow.To address the potential inefficiencies in principle selection and to instill strategic direction, the PiFlow component is introduced.It leverages the dynamically growing set of principle-outcome pairs, T t as its primary input.Two steps are conducted to steer the hypothesizing:</p>
<p>(a) High-potential principle acquisition.After an initial phase of evidence collection, during which T t is populated, PiFlow activates its core mechanism: an adversarial Min-Max optimization (detailed in Section 3.3).This optimization process analyzes T t to identify a principle, p * (e.g., p 2 in Figure 2), predicted to balance the exploitation and exploration, i.e., have the highest potential, for advancing the scientific inquiry.(b) Principle steering for hypothesizing.Following the identification of the highest-potential principle p * by the Min-Max optimization, PiFlow assigns a potential score to all principles in P.This scoring enables a threshold-based partitioning: principles with high scores (e.g., p ′ 2 ) drive refinement; those with medium scores trigger further validation (p 2 → p ′ 2 ); and low scores prompt exploration of new conceptual areas.This closed-loop feedback mechanism ensures that the Hypothesis-Validation cycle is continuously and adaptively steered by strategic insights derived from the system's cumulative experience, as embodied in T t .We provide a detailed analysis of the distinction from prompt engineering at Appendix E, and an illustrative example at Appendix H.</p>
<p>Plug-and-Play Modularity of PiFlow.The hypothesis steering mechanism above, which includes PiFlow and its interfacing Planner agent A P , has been intentionally engineered as a modular, Plug-and-Play system.This architectural choice ensures that principle-aware guidance can be readily integrated to enhance MAS engaged in scientific discovery as a part of prompts.As demonstrated in Appendix K, we successfully integrate PiFlow with existing ChemToolAgent (Yu et al., 2024) without any architecture modifications.This adaptability positions PiFlow as a pivotal enhancement for automated scientific inquiry.</p>
<p>MIN-MAX OPTIMIZATION IN PIFL O W</p>
<p>In our proposed method, strategic principle selection is achieved through a Min-Max optimization, as presented in Eq. 1.This approach is designed to balance the exploitation of established, high-potential principles (which then guide the formulation of specific hypotheses) with the exploration of novel ones, while explicitly incorporating information acquisition efficiency:
min π∈Π max f * ∈F E π T t=1 (v * − f * (h t )) − λ • I(h t ; f * |H t−1 )(1)
where π ∈ Π represents the decision-making policy for selecting principles and f * ∈ F is the evaluation function (e.g., an experimental tool) that characterizes the quantitative outcome yielded from hypothesis h t ∈ H, where H is the hypothesis space.Over T iterations, the policy π aims to minimize the objective function in Eq. 1.This objective strategically balances: (1) the summation for cumulative regret, encouraging exploitation of known high-potential principles, and (2) the mutual information, thereby effectively maximizing information gain to foster exploration.This structure allows PiFlow to navigate the complex trade-offs between these two goals.</p>
<p>Minimizing cumulative fegret (exploitation).The first term,
T t=1 (v * − f * (h t ))
, represents the cumulative regret over T iterations.Here, v * is a theoretical optimal outcome value, and f * (h t ) is the outcome from hypothesis h t .By minimizing this term, the policy π is driven to exploit known high-potential principles and hypotheses to achieve outcomes as close as possible to the optimum v * .This encourages the refinement and validation of promising avenues.</p>
<p>Maximizing information gain (exploration).</p>
<p>The second term −λ • I(h t ; f * |H t−1 ) promotes exploration.The policy π seeks to minimize this term, which is equivalent to maximizing the mutual information I(h t ; f * |H t−1 ).This mutual information quantifies the expected reduction in uncertainty about the true evaluation function f * upon observing the outcome of hypothesis h t , given all past observations
H t−1 = {(h m , y m )} t−1 m=1 .
The trade-off parameter λ &gt; 0 controls the balance between minimizing regret (exploitation) and maximizing information gain (exploration).A larger λ places more emphasis on information acquisition.</p>
<p>Remark (The dependencies of f * in I(h t ; f * |H t−1 )) .The informativeness of a proposed hypothesis h t is inherently dependent on the nature of the true underlying evaluation function f * .The adversarial nature of the max f * operator means that the policy π must select hypotheses h t that are expected to be informative even if f * were to manifest in a way that makes h t minimally revealing, thus ensuring robustness in information acquisition.</p>
<p>Building upon the theoretical framework above, we derive a computationally tractable algorithm (Algorithm 1) that serves as a principled approximation of the abstract Min-Max objective in Eq. 1.The full rationale and derivation for this approximation are detailed in Appendix G.</p>
<p>In summary, the Min-Max adversarial formulation underpinning PiFlow provides strong theoretical guarantees, notably sublinear regret bounds (formalized in Theorem 1, with proof in Appendix F).Importantly, its operational behavior, which involves practical approximations of this Min-Max solution, demonstrates consistent alignment with these theoretical expectations, as empirically validated in Section 5.4.</p>
<p>Theorem 1 (Informal).The Min-Max optimization in PiFlow formulates a trade-off between exploitation (minimizing regret) and exploration (maximizing information gain).Under conditions of finite entropy H(f * ) and bounded evaluation function f * , this optimization provides two key theoretical guarantees: (1) As information gain decreases, the expected regret also decreases; (2) the cumulative regret grows at a sublinear rate of O √ T .</p>
<p>EXPERIMENT</p>
<p>SETTINGS</p>
<p>To rigorously evaluate the effectiveness and versatility of our PiFlow framework, we conducted experiments across three distinct scientific discovery scenarios.While direct hypothesis validation in real-world labs is prohibitively expensive, we employ high-fidelity surrogate models deployed locally, which serve as the primary evaluation tool.Across all scenarios (Section 4.2), we frame the scientific discovery challenge as a unified task: "Find a candidate in a complex parameter space that maximizes a target property (e.g., bio-activity)."</p>
<p>To ensure a fair comparison and focus on core capabilities, all agents utilize QwenMax (Yang et al., 2024a) as the base LLM and are prohibited from accessing external search tools.The complete experimental setup is detailed in Appendix S, and the role-playing prompts for PiFlow are provided in Appendix T.</p>
<p>EXPERIMENTAL SCENARIOS</p>
<p>To comprehensively assess PiFlow's performance, we design three scenarios that represent canonical challenges in scientific exploration: optimization in continuous, discrete, and mixed parameter spaces:</p>
<p>Nanohelix Optimization (NHO).We use a surrogate model (r 2 = 0.98) trained on DFT-simulated data following Wu et al. (2025) to predict nanohelix chirality from four continuous geometric parameters, enabling efficient exploration of the design space (Appendix S.1).</p>
<p>Molecular Bio-activity Optimization (MBO).We build a surrogate model (r 2 = 0.91) to predict bio-activity from SMILES strings, trained on 50,000 molecules from ChEMBL35 (Zdrazil et al., 2023).This facilitates high-throughput screening in a discrete chemical space.(Appendix S.2).</p>
<p>Superconductor Optimization (SPO).Following Hamidieh (2018), we train a surrogate model (r 2 = 0.91) to map a material's mixed continuous and discrete compositional features to its critical temperature (T c ), accelerating the discovery of room-temperature superconductors.(Appendix S.3).</p>
<p>BASELINES</p>
<p>To evaluate the strategic guidance of PiFlow under uncertainty, we therefore benchmark against the following baselines: (1) Reasoning and Acting (ReAct) (Yao et al., 2022).ReAct enables agents to iteratively formulate hypotheses, design/execute experiments, and interpret results.It represents a foundational approach to structured reasoning.(2) Meta Plan Optimization (MPO) (Xiong et al., 2025).MPO employs a trained LLM planner that provides high-level, general guidance.This serves as a direct counterpoint to PiFlow's explicit, structured mechanism for principled uncertainty reduction.</p>
<p>(3) Vanilla Agent System (Vanilla).This baseline consists of an MAS operating without any principled strategic oversight.It is intended to establish a performance floor, demonstrating the limitations of unguided exploration reliant solely on agent role-playing.</p>
<p>While other advanced frameworks exist, such as Agent-Oriented Planning (AOP) (Li et al., 2024) and Reason for Future, Act for Now (RAFA) (Liu et al., 2023), their design objectives diverge from the scope of our evaluation.AOP is optimized for tasks with well-defined structures rather than initial epistemic uncertainty, while RAFA focuses on completing predefined goals rather than the iterative, de novo evidence-gathering process central to PiFlow.Therefore, our curated selection of baselines is specifically designed to isolate and evaluate our contribution to discovery efficiency in uncertain environments.</p>
<p>EVALUATION METRICS</p>
<p>Two metrics are employed to evaluate the performance of PiFlow, as detailed below:</p>
<p>Solution Quality (SQ).We measure the optimal objective value with a percentage relative to the theoretical maximum value µ absolute , denoted as:
SQ = max{y k | ⟨p k , y k ⟩ ∈ T t } µ absolute × 100%.(2)
Specifically, for NHO, the theoretical maximum is reported as µ g-factor absolute = 2.0 following Greenfield et al. (2021).The larger the g-factor, the stronger the chirality.For MBO, a strict threshold of µ pchembl absolute = 6.5 has been reported (Lenselink et al., 2017) for lead compound optimization stage, larger value indicates a higher bio-activity and vice versa.For SPO, the reference value is set to be 25 • C , which is equal to room temperature 298.15K, denoted as µ Tc absolute = 298.15K.Area Under the Curve (AUC).Exploration efficiency requires both (1) rapid convergence and (2) high objective values.We quantify these two factors by defining the AUC metric.Given the trajectory ⟨p k , y k ⟩ ∈ T t across t steps, AUC is computed via the trapezoidal rule.For meaningful  comparisons, we normalize by the maximum possible area:
AUC = t−1 i=1 yi+yi+1 2 µ absolute • (t − 1) × 100%(3)
In summary, SQ measures the quality of the final outcome, while AUC evaluates the entire discovery process by rewarding both speed and consistency.The detailed rationale for these metric designs is provided in Appendix R.2.</p>
<p>RESULTS</p>
<p>PERFORMANCE COMPARISON</p>
<p>We use SQ to compare the overall capability of reaching the objective solution, and AUC to assess the efficiency, reflecting progress towards better outcomes over the exploration process.</p>
<p>Table 1 demonstrates that PiFlow achieves significant improvements over all baselines across three benchmarks of NHO, MBO, and SPO.In terms of achieving the target property, measured by SQ, PiFlow consistently leads, outperforming ReAct, MPO, and Vanilla systems by an average of approximately 207.6%, 34.1%, and 94.1%.Additionally, as shown in Figure 3, PiFlow is always the fastest one in reaching the best solution while exploring.More details about models' response analysis can be seen at Appendix I.</p>
<p>It is worth noting the considerable std observed in our results.This variance is inherent to the stochastic nature of LLM-based agents and can be attributed to the phenomenon of cumulative error.An early suboptimal decision or flawed hypothesis can set an agent on an inefficient discovery trajectory, with reasoning errors compounding over subsequent iterations.This instability highlights why relying solely on the final SQ can be insufficient.In contrast, the AUC provides a more holistic performance measure.A high AUC, as consistently demonstrated by PiFlow, indicates that the agent not only found a high-quality solution but also maintained a robust and efficient path, thereby successfully mitigating the primary risk of cumulative error.</p>
<p>Takeaway: PiFlow substantially outperforms all baselines in SQ and exploration efficiency (AUC).Its strategic robustness is evidenced by its high AUC, which mitigates the cumulative errors of LLMs, and by its success from modest starting points that simulate realistic initial uncertainty (see Appendix P.2).</p>
<p>Preprint.Under review.</p>
<p>ABLATION STUDY</p>
<p>We conduct several ablations to evaluate PiFlow.For these studies, conducted on the NHO task, performance is evaluated based on the same metrics, AUC (%) and SQ (%).</p>
<p>Plug-and-Play.To isolate the direct benefit of PiFlow, we compared the performance with two different LLMs, GPT4.1-mini and Qwen3-32B under the setting of w/ and w/o PiFlow.This is achieved by only including or excluding the steered principle to the Planner Agent via prompt, which then directs subsequent hypothesizing and validation.</p>
<p>As shown in Thought Mode Effect.</p>
<p>We also conduct ablations on the internal thought mode of the LLM (referred to as Think in Table 3).This is for agents based on Qwen3-32B and Qwen3-8B models, which support ON/OFF <think>...</think> generation with system prompt including or excluding /no_think.This mode is intended to enable more explicit reasoning steps.Interestingly, for both Qwen3-32B and Qwen3-8B, disabling the Thought Mode leads to improved performance, as shown at Table 3.We hypothesize that this phenomenon is due to cognitive fixation.As the key issue is, how do LLM propose scientific hypothesis, forcing the LLM to generate an explicit Chain-of-Thought may cause it to commit prematurely to its own initial line of reasoning.If the first step in its logic is flawed, the entire chain can be led astray, creating a cognitive fixation that is hard to escape.In contrast, disabling the think mode may force the model to rely more on its powerful, holistic pattern-matching capabilities, allowing it to make more intuitive leaps directly from the data (PiFlow's guidance and the experimental history) to a hypothesis, bypassing potentially flawed intermediate reasoning steps.</p>
<p>Takeaway: Our ablations confirm PiFlow is a robust, plug-and-play enhancement that consistently boosts performance across models.Concurrently, we find that an agent's internal reasoning is critical: disabling explicit "Think" modes paradoxically improves performance, suggesting that avoiding cognitive fixation allows the LLM to better leverage holistic pattern-matching.This highlights the synergy between high-level strategic guidance from PiFlow and internal reasoning.</p>
<p>FURTHER ANALYSES OF ROBUSTNESS</p>
<p>We conducted extensive analyses to probe the robustness and practical utility of PiFlow.The key findings are as follows:</p>
<p>Recovery from poor initialization.The system demonstrates resilience by successfully recovering from deliberately incorrect initial principles, eventually matching the performance of a run guided by correct initialization.This underscores the robustness of the Min-Max (Appendix P).</p>
<p>Temporal dynamics of principle evaluation.PiFlow continuously re-evaluates the utility of scientific principles as new evidence is gathered.This allows it to dynamically discard initially promising but ultimately flawed avenues while elevating principles that prove more fruitful later, showcasing an adaptive balance between exploration and exploitation (Appendix N).</p>
<p>Superior performance against numerical search.On complex tasks with ill-defined search spaces, PiFlow substantially outperforms Bayesian Optimization, achieving an SQ of 84.55% versus BO's 38.15% in the MBO task, without requiring manual parameter space engineering (Appendix J).Seamless plug-and-play integration.We validate the practicality of PiFlow through a successful integration with ChemToolAgent (Yu et al., 2024), guiding it to a high-value molecule (pChEMBL of 5.90) without requiring any architectural modifications (Appendix K).</p>
<p>Manageable computational complexity.The core decision mechanism of PiFlow has a computational complexity of O(t 2 • d), where t = |T t | and d is the embedding dimension.This could be optimized to near-linear time for large-scale tasks (Appendix L).</p>
<p>Cost-effectiveness.Superior performance is achieved cost-effectively, reducing token consumption by up to 27% compared to the Vanilla Agent.PiFlow constitutes only 1.5% tokens (Appendix M).</p>
<p>Generalizability and controllability.PiFlow is compatible with various LLMs, and its behavior can be tuned via the λ hyperparameter, for which we provide a clear heuristic (Appendices O, Q).</p>
<p>THEORETICAL ALIGNMENT</p>
<p>To empirically validate the theoretical guarantees (Theorem 1) of PiFlow, we analyze key aspects of its exploration dynamics, including (1) the bound of average regret and (2) the relationship between regret and information gain, as shown in Figure 4.</p>
<p>(Theoretical Prediction 1) Average regret decay with O 1 √ T .Figure 4a presents the average regret as a function of iterations on a log-log scale.The alignment evidenced by average regret trajectories adhering to the T −0.5 decay (fitted c • T −0.5 with c = 1.37, r 2 = 0.96), a pattern most runs consistently follow.Notably, one run (ID=1), after an initial sharp regret decrease, shows a transient increase before resuming decay.This illustrates PiFlow's robust exploration avoiding potential local optima with a characteristic of its Min-Max strategy.</p>
<p>(Theoretical Prediction 2) As information gain decreases, the expected regret also decreases.As shown in Figure 4b, the scatter plot of regret versus information gain (points colored by iteration) reveals a clear positive association, confirmed by a fitted trend line: lower information gain generally corresponds to lower regret.Early iterations (higher information gain and regret) transition to later iterations (lower information gain and regret).</p>
<p>Empirical validation of exploration strategy.Figure 4c displays the trajectory of PiFlow on the NHO objective landscape, which is visualized via Principal Component Analysis (PCA) with contours indicating g-factor values.The path demonstrates a principled strategy: initial broad exploration (iterations 1-16), followed by navigating a low-quality "valley" to escape a local optimum (iterations 16-21), and culminating in efficient convergence to a high-g-factor region (iterations 21-24).This progression empirically validates how our theoretical design translates into effective discovery.</p>
<p>Takeaway: Our empirical analysis corroborates the theoretical guarantees of PiFlow, demonstrating that its strategy is both principled and effective.The alignment of regret dynamics with the predicted sublinear rate and its coupling with information gain validates a robust mechanism that translates theoretical efficiency into a practical ability to escape local optima and converge reliably.</p>
<p>CONCLUSION</p>
<p>In conclusion, we propose PiFlow, a Plug-and-Play module to strategically guide the Hypothesis-Validation loop through a steering mechanism to address challenges of aimless hypothesizing and unclear connections between hypotheses and evidence.Our approach utilizes a Min-Max optimization that explicitly balances exploitation of high-potential principles with exploration of novel hypotheses, guaranteed by a sublinear average regret bound.Extensive experiments demonstrate that PiFlow can adaptively navigate complex hypothesis spaces without premature convergence on suboptimal solutions, yielding significant improvements over baselines.A detailed discussion of its current limitations and future potential is provided in Appendix C. We hope PiFlow can contribute to advancing automated scientific discovery, inspiring further exploration and innovation.</p>
<p>A USE OF LARGE LANGUAGE MODELS</p>
<p>We utilized a large language model to assist with proofreading and polishing the language in this manuscript.</p>
<p>B BROADER IMPACT</p>
<p>PiFlow addresses critical bottlenecks in AI-driven scientific discovery where uncertainty leads to aimless exploration.Our method innovatively frames discovery as a structured uncertainty reduction problem.By using an information-theoretic approach within a hypothesis-validation loop, PiFlow systematically filters for instructive scientific principles.Ultimately, PiFlow establishes a new paradigm for automated research, enabling more targeted exploration and accelerating the generation of impactful scientific insights.In Materials Discovery, it speeds the identification of novel compounds like advanced nanomaterials or superconductors, as shown in our tasks.For Biological Discovery, it enhances the search for effective molecules and the understanding of complex systems.Its principles promise similar advancements in other data-intensive fields, from chemistry to medical sciences, facing vast and uncertain hypothesis spaces.</p>
<p>C LIMITATION AND FUTURE WORK</p>
<p>While PiFlow shows notable improvements through its principled Min-Max optimization, its practical implementation approximates a key theoretical component.This means the current system may not fully capture all nuances of true, model-based information gain, especially the direct adversarial interplay with all possible manifestations of the unknown evaluation function f * from the theoretical objective.</p>
<p>Future research could explore more direct estimations of mutual information for this heuristic within the PiFlow framework to potentially further enhance its strategic guidance.Furthermore, we observed that disabling the LLM's "Thought Mode" surprisingly improves performance, suggesting that forced Chain-of-Thought can induce cognitive fixation.This finding motivates the development of more flexible reasoning frameworks for agents, aiming to better balance deliberate logic with intuitive generation.</p>
<p>D DETAILED METHODOLOGICAL REVIEW</p>
<p>A hallmark and fundamental limitation of many contemporary LLM-based agent systems in scientific discovery is their limited generalizability.As detailed in Table 4, these frameworks are often characterized by a tight coupling between their core logic and a specific scientific domain.This means their implementations, tool integrations, and most critically, their prompt engineering strategies are meticulously tailored for a single scenario, such as organic chemistry or materials science.Although systems like The AI Scientist (Lu et al., 2024) and Agent Laboratory (Schmidgall et al., 2025) demonstrate strong capabilities in scientific research, they are specifically designed for AI domain, along with a focus of the whole workflow rather than strategic decision-making problem.Consequently, transferring these systems to a new domain necessitates significant re-engineering, restricting their out-of-the-box applicability and hindering the development of truly universal systems.</p>
<p>In contrast, our PiFlow is designed to overcome this challenge by decoupling the strategic decision-making layer from the task execution layer.By architecting PiFlow as a domainagnostic, Plug-and-Play module, it provides strategic guidance to a minimal hypothesis-testing MAS without embedding domain-specific knowledge within its own logic.This architectural choice yields superior flexibility and obviates the need for extensive, domain-specific prompt engineering for the strategic component, enabling seamless adaptation across diverse scientific fields.</p>
<p>Take-away: PiFlow introduces a domain-agnostic, plug-and-play architecture by decoupling strategic decision-making from domain-specific execution.This design overcomes the critical generalizability limitations inherent in tightly-coupled scientific agent systems.Protein-protein interactions analysis (Ghafarollahi &amp; Buehler, 2025) Automating alloy design and discovery using physics-aware multimodal multi-agent AI Alloy design and discovery (Takahara et al., 2025) Accelerating inorganic materials design using generative AI agents.</p>
<p>Inorganic materials design LIDDIA (Averly et al., 2025) Language-based intelligent agent for drug discovery tasks.</p>
<p>Drug discovery dZiner (Ansari et al., 2024) Rational inverse design of materials facilitated by AI agents.</p>
<p>Inverse design of materials MOOSE-Chem (Yang et al., 2024c) Utilizing Large Language Models for rediscovering unseen chemistry scientific hypotheses.We define a scientific principle following Definition 3.1.Formally, each principle is represented as a structured text proposition that can be algorithmically scored by our MinMax optimization (as exampled in Figure 1).Unlike arbitrary text strings, these principles is supposed to be with logical consistency, and this structural requirement is what distinguishes them from general prompts.In short, principles represent foundational concepts or established patterns within a domain (e.g., "higher hydrophobicity often correlates with better cell membrane penetration").These "principles", whether has been validated or not, can be proposed by experts or, crucially, extracted from the LLM's own vast pre-trained knowledge.They serve as high-level starting points to generate specific, testable hypotheses.</p>
<p>The core distinction of our PiFlow from prompt engineering lies not in the format of the guidance (which is text), but in the algorithmic generation of that guidance:</p>
<p>• Prompt engineering baseline.The agent quickly became trapped in local optima.Its process was highly repetitive (e.g., repeatedly stating "The system's behavior is governed by the interplay..."), and it eventually stagnated, making only meaningless tweaks to the gfactor (e.g., 1.1012 → • • • → 1.1030).This demonstrates the limitation of a static, unguided hypothesis-testing loop.</p>
<p>• Systematic breakthroughs with PiFlow.In contrast, the PiFlow-guided agent demonstrated structured, cumulative learning:</p>
<ol>
<li>(Early 1 3 iterations) Principled exploration: It begins with diverse hypotheses to maximize information gain.2. (Medium stage) Discovery: It identified non-monotonic relationships (e.g., "deviations beyond an optimal configuration reduce chirality"), forming a natural language-based identification.3. (Late stage) Paradigm Shift: Ultimately, it synthesized the principle of "minimal radius + maximal turns + optimized pitch", causing a decisive shift in the search space from (fiber_radius=40, helix_radius=70) to (fiber_radius=20, helix_radius=20) and identifying the non-linear sensitivity of the pitch parameter.This unlocked the significant g-factor improvement (0.84 → 1.28 → 1.41 → 1.51).</li>
</ol>
<p>The core of PiFlow is to force the LLM to structure its disorganized internal knowledge into explicit, falsifiable hypotheses.The PiFlow then uses quantitative feedback from experiments to iteratively refine its understanding regarding the task.The value is not in feeding the LLM new knowledge, but in providing a strategic framework to systematically test and organize the knowledge it already possesses, yielding a loop of LLM Knowledge → External Evidence → Guided LLM Action, rather than LLM → LLM.</p>
<p>In summary, the algorithmic core lies in Equation 1and Algorithm 1: the Min-Max optimization systematically balances regret minimization with information gain maximization.This is operationalized through dynamic principle scoring that updates based on accumulated evidence T t = ⟨p k , y k ⟩k = 1 t .Advanced prompt engineering lacks this principled mathematical framework for evidence integration and strategic trade-offs.</p>
<p>Take-away: Instead of relying on static prompts that lead to local optima, PiFlow employs a Min-Max optimization to algorithmically generate and refine structured, falsifiable principles.By systematically integrating experimental feedback, it transforms the LLM's latent knowledge into a dynamic, self-correcting engine for scientific discovery, enabling cumulative learning and strategic breakthroughs.</p>
<p>F PROOF OF THE THEOREM</p>
<p>We recall the elements here and formally proof the convergence along with boundary of the system.</p>
<p>Here we denote π is the language model policy from policy space Π, f * is the acquisition function from function space F, h t is the hypothesis at time step t, H t−1 = {h 1 , h 2 , . . ., h t−1 } is the history of hypotheses, v * is the SQ achievable by any hypothesis, and
I(h t ; f * | H t−1 ) is the conditional mutual information.
According to the original formulation (Eq.1), the cumulative regret can be expressed as
R T (π, f * ) = E π T t=1 (v * − f * (h t ))
and the cumulative information gain is
IG T (π, f * ) = E π T t=1 I(h t ; f * |H t−1 )
Information gain approaches zero.With information theory, the mutual information can be written as:
I(h t ; f * |H t−1 ) = H(f * |H t−1 ) − H(f * |H t−1 , h t )
A critical property for convergence is that the total information gain is bounded,
∞ t=1 I(h t ; f * | H t−1 ) ≤ H(f * ) &lt; ∞
This follows from the chain rule of mutual information,
T t=1 I(h t ; f * | H t−1 ) = I(H T ; f * ) ≤ H(f * )
Since the entropy H(f * ) is finite, the cumulative information gain is bounded regardless of how many steps T we take.This implies that:
lim t→∞ I(h t ; f * | H t−1 ) = 0.
In other words, the marginal information gained from each new hypothesis must eventually approach zero.</p>
<p>As information gain decreases, the expected regret also decreases.As we mentioned before, the regret R T (π, f * ) is defined as:
R T (π, f * ) = E T [v * − f * (h t )]. Now apply Jensen's Inequality, let X = v * − f * (h t ), we have E[X 2 | H t−1 ] = E[(v * − f * (h t )) 2 | H t−1 ]. Use ϕ(x) = x 2 , as it is convex, giving (E[X | H t−1 ]) 2 ≤ E[X 2 | H t−1 ],
take square roots:
E[v * − f * (h t ) | H t−1 ] ≤ E[(v * − f * (h t )) 2 | H t−1 ].
Now we deal with the second moment of the regret.As the v * is constant, therefore, with the variance formula, we have
E (v * − f * (h t )) 2 | H t−1 = Var(f * (h t ) | H t−1 ) + (v * − E[f * (h t ) | H t−1 ]) 2
Both terms (variance and bias) are non-negative, and our goal is to bound this expression.The variance term Var(f * (h t ) | H t−1 ) captures the uncertainty in f * (h t ) given the history.</p>
<p>Since the information theory proofed that, the variance of a function can be bounded by mutual information, akin to entropy bounds H(f * ) ≤ log(|F |), for the first term, we have
Var(f * (h t ) | H t−1 ) ≤ c • I(h t ; f * | H t−1 ),
where c is constant that depends on the range of f * , this follows because the mutual information bounds the expected variance of conditional expectations.</p>
<p>Since we can direct view the f * (h t ) as a random variable over the joint distribution of f * and h t , we can apply a concentration inequality.A standard result in information-directed sampling states that for a bounded random variable like f * (h t ) here, the second moment of the regret (v * − f * (h t )) can be bounded as:
E (v * − f * (h t )) 2 | H t−1 ≤ c • I(h t ; f * | H t−1 ),
where the constant c depends on |F|.</p>
<p>Finally, we get the inequality of R T (π, f * ):
R T (π, f * ) ≤ E T [(v * − f * (h t )) 2 | H t−1 ] ≤ c • I(h t ; f * | H t−1 )
This inequality demonstrates that as the information gain I(h t ; f * | H t−1 ) decreases, the expected regret also diminishes.</p>
<p>The cumulative regret grows at a rate O( √ T ).Based on the inequality in the last step and to find the cumulative regret bound, we need to sum this inequality over all time steps:
T t=1 R t (π, f * ) ≤ c • T t=1 I(h t ; f * |H t−1 )
Applying the Cauchy-Schwartz inequality:
T t=1 I(h t ; f * |H t−1 ) ≤ T • T t=1 I(h t ; f * |H t−1 )
Since we've already established that the total information gain is bounded:
T t=1 I(h t ; f * |H t−1 ) ≤ H(f * )
We can substitute this bound:
T t=1 I(h t ; f * |H t−1 ) ≤ T • H(f * )
Therefore, the cumulative regret is bounded by:
T t=1 R t (π, f * ) ≤ c • T • H(f * )
This demonstrates that the cumulative regret grows at a rate of O( √ T ), which is sublinear in T .This result implies that while the total regret increases with step, the average regret per time step decreases at a rate of O( 1 √ T ).</p>
<p>G ALGORITHMIC REALIZATION OF THE MIN-MAX FRAMEWORK G.1 PRACTICAL PROXIES FOR REGRET AND INFORMATION GAIN</p>
<p>Algorithm 1 provides a computationally tractable implementation of the abstract Min-Max optimization strategy presented in Eq. 1.It translates the theoretical concepts of regret minimization (exploitation) and information gain maximization (exploration) into concrete, efficiently computable metrics, enabling PiFlow to guide the scientific discovery process effectively.The bridge between theory and practice is established as follows:</p>
<p>Approximating exploitation (minimizing cumulative regret).The theoretical objective of minimizing cumulative regret, T t=1 (v * − f * (h t )), is centered on favoring principles that consistently yield high-value outcomes f * (h).In our practical implementation, the compute_exploitation_scores function directly approximates this goal.It leverages the historical trajectory of principle-outcome pairs, T t = {⟨p k , y k ⟩} t k=1 .The observed outcome y k here serves as a direct proxy for the performance of its corresponding principle p k .A principle associated with higher outcomes is considered to have lower regret.Therefore, the resulting normalized score vector ranging from 0 to 1, S exploitation ∈ R |Tt| , quantifies the empirical success of each principle, and maximizing this score is equivalent to minimizing the cumulative regret based on past evidence.</p>
<p>Approximating exploration (maximizing information gain).The second term in our objective, maximizing the mutual information I(h t ; f * |H t−1 ), encourages the selection of hypotheses that are most informative about the underlying scientific landscape.A direct computation of mutual information is often intractable.Consequently, Algorithm 1 employs a practical proxy via the compute_exploration_scores function.This is achieved by analyzing the semantic diversity of principles using their sentence level embeddings (e.g., obtained from QwenMax model).We posit that principles which are semantically distant from those already tested are more likely to reveal novel information about the function f * .Therefore, we use the cosine distance between a candidate principle's embedding and the embeddings of previously explored principles as a heuristic for information gain.High exploration scores, S exploration ∈ R |Tt| , are assigned to conceptually novel principles.This heuristic is theoretically grounded, as detailed in Appendix G.2.</p>
<p>Algorithm 1 Algorithm of PiFlow.suggestion ← "Initialize one principle to explore."5: else 6: The integrated decision policy.The policy of the Min-Max framework, π, must balance the above objectives.Our algorithm materializes this policy through a two-step process:
S exploration ← compute_exploration_scores(T t ) 7: S exploitation ← compute_exploitation_scores(T t ) 8: for i ← 1 to |T t | do 9: S final [i] ← (1 − λ f actor ) • S exploration [i] + λ f actor • S exploitation [i]
1.</p>
<p>Step 1 (Scoring and selection).The final score,
S f inal [i] ← (1−λ f actor )•S exploration [i]+ λ f actor • S exploitation [i],
is a direct implementation of the balanced objective function.The input parameter λ f actor instantiates the theoretical trade-off, controlling the emphasis between exploration and exploitation.The arg max i (S f inal [i]) operation then executes the policy's primary function: selecting the most promising principle, p best , given the current state of knowledge and the desired strategic balance.</p>
<p>2.</p>
<p>Step 2 (Action recommendation).Finally, the policy translates its choice into a strategic command.The threshold-based conditions on the best principle's exploitation score (if best_exploitation_score &gt; 0.7 . . . ) discretize the continuous space of potential actions into three clear directives: refine, validate, or explore with the concatenation (denoted by ⌢) of the principle content.This transforms the numerical output of the optimization into an actionable suggestion for the Planner agent (A P ), thereby closing the loop between theoretical deliberation and practical execution within the Hypothesis-Validation cycle.</p>
<p>G.2 THE RATIONAL OF SEMANTIC DISTANCE AS A PROXY FOR INFORMATION GAIN</p>
<p>Recall that we introduce a Min-Max optimization framework for the PiFlow system.The objective function, as shown in Eq. 1, incorporates a mutual information term, I(h t ; f * |H t−1 ), to guide exploration.This term, while theoretically ideal, is computationally intractable as it requires knowledge of the true underlying evaluation function f * .In our practical implementation, we employ a surrogate objective for exploration: maximizing the distance of a new principle's text embedding from the embeddings of previously selected principles.Here, we provide a formal justification for this approximation, demonstrating its theoretical soundness.</p>
<p>Proof.Our goal is to establish a principled connection between the practical exploration strategy and the theoretical objective of maximizing information gain.The practical strategy is to select a principle p t from the principle space P at each timestep t according to:
p * t = arg max pt∈P min m∈{1,...,t−1} ∥ϕ(p t ) − ϕ(p m )∥ 2 (4)
where ϕ : P → R d is a function that maps a principle to its corresponding high-dimensional text embedding.We will now demonstrate that this objective serves as a valid proxy for maximizing the mutual information term I(h t ; f * |H t−1 ).</p>
<p>The derivation rests upon the hierarchical relationship between principles and hypotheses, and the semantic properties of modern language model embeddings.A principle p ∈ P is not a hypothesis itself, but rather defines a specific semantic region or a conditional distribution π(•|p) from which a concrete hypothesis h ∈ H is formulated.Thus, the selection of a principle p t precedes the generation of a hypothesis h t ∼ π(•|p t ).</p>
<p>We begin by positing two fundamental premises regarding the nature of the embedding space.</p>
<p>Premise 1 (Semantic-metric correspondence).The embedding function ϕ is assumed to map the conceptual space of principles to a metric space where distance reflects semantic dissimilarity.That is, for any two principles p i , p j ∈ P, a large Euclidean distance ∥ϕ(p i ) − ϕ(p j )∥ 2 implies a significant divergence in their underlying semantic and conceptual content.This is a well-established property of embeddings from large-scale language models.</p>
<p>Premise 2 (Functional consequence of semantic dissimilarity).Semantically distinct principles guide the generation of functionally distinct hypotheses.A hypothesis h acts as a probe of the unknown function f * .If two principles p i and p j are semantically distant, the hypotheses generated from their respective distributions, h i ∼ π(•|p i ) and h j ∼ π(•|p j ), are expected to probe disparate aspects or regions of the function f * .</p>
<p>With these premises, we can construct the logical argument.The mutual information term I(h t ; f * |H t−1 ) quantifies the expected reduction in uncertainty about f * after observing the outcome of hypothesis h t , given the history of observations H t−1 .As established in our convergence proof (Section F), this information gain is related to the posterior variance of the outcome of h t :
E (v * − f * (h t )) 2 | H t−1 ≤ c • I(h t ; f * | H t−1 )
This relation suggests that a hypothesis h t yielding high uncertainty (i.e., high posterior variance Var(f * (h t ) | H t−1 )) is expected to provide high information gain.Consequently, a sound exploration strategy is to select h t to maximize this variance.</p>
<p>Let us now connect this objective to our practical strategy in Eq. 4.</p>
<p>1.By selecting a principle p t that maximizes the minimum distance to all prior principles in the embedding space, we are, by Premise 1, choosing a principle that is maximally semantically novel compared to the history of principles {p m } t−1 m=1 .2. By Premise 2, this semantically novel principle p t will guide the generation of a hypothesis h t that probes a functionally distinct aspect of f * compared to all prior hypotheses in
H t−1 = {(h m , y m )} t−E[Var(f * (h t ) | H t−1 )] ⇒ max ht∼π(•|pt) E[I(h t ; f * | H t−1 )]
The expectation E[•] is taken over the generation of h t from p t .</p>
<p>In conclusion, the strategy of maximizing the minimum embedding distance between principles is not an arbitrary heuristic.It is a principled and computationally feasible surrogate for the theoreticallygrounded objective of maximizing mutual information.It leverages the semantic structure captured by modern language model embeddings to implement an efficient and effective exploration strategy, ensuring that PiFlow diversifies its inquiry at a conceptual level.This alignment between our practical approximation and the theoretical Min-Max framework provides support for the design of our system and its empirical performance.</p>
<p>Take-away: We operationalize the abstract Min-Max framework by substituting its theoreticallyideal but computationally-intractable objectives with practical proxies.Exploitation (regret minimization) is approximated by historical performance, while Exploration (information gain maximization) is driven by maximizing the semantic distance between principle embeddings.We formally prove that this semantic distance is a principled surrogate for maximizing information gain, thus bridging the gap between theory and efficient implementation.</p>
<p>H ILLUSTRATIVE EXAMPLE: APPLICATION TO NANOHELIX OPTIMIZATION</p>
<p>We provide a step-by-step walk-through of PiFlow's operation using the Nanohelix Optimization (NHO) task as a running example:</p>
<p>Let's assume the goal is to find the nanohelix geometry (described at Appendix S.1) with the maximum g-factor:</p>
<p>Phase 1: Initial Exploration.The process begins with an unguided hypothesis generation to build an initial evidence base by LLM itself.The Planner agent, following the initial directive of PiFlow, instructs the Hypothesis Agent for intuitive exploring (Algorithm 1, line 3-5).For the first K rounds (e.g., K = 3 in our experiments), the loop proceeds as follows, 1. Hypothesis Agent proposes a specific, testable hypothesis, "Based on the principle of • • • , measure the g-factor of a nanohelix with parameters: fiber_radius=40.0nm, he-lix_radius=70.0nm, n_turns=6.5,pitch=130.0nm".</p>
<ol>
<li>
<p>Experiment Agent calls the tool (surrogate model) to validate the above hypothesis and returns the outcome, "the validation yields a g-factor of 0.86".</p>
</li>
<li>
<p>This Hypothesis-Validation process repeats for K rounds, populating the evidence trajectory T t for establishing an initial principle pool.</p>
</li>
</ol>
<p>In the initial K rounds, lacking specific guiding principles, the Hypothesis Agent performs an initial exploration of the parameter space by proposing diverse geometries based on its general pre-trained knowledge, or by sampling from a wide distribution.</p>
<p>Phase 2: Principle-aware guidance from PiFlow.After the initial K rounds, the MinMax optimization of PiFlow parses these evidence and identifies the highest potential principle and suggests an action based on the score of the highest-potential principle (refer to Algorithm 1, line 5-23).The Planner agent receives this strategic guidance, for instance: "Refine the identified promising principle: By adjusting the fiber radius to twice the helix radius and fine-tuning other parameters, it is expected to maximize the chirality (g factor) of the nanohelix".</p>
<p>Structured, guided hypothesizing in both Phase 1 and Phase 2. The Planner injects this directive into the whole group chatting history, i.e., Hypothesizing-Validation loop, thereby reducing the system-level uncertainty.The Hypothesis Agent now uses this focused principle to formulate its next hypothesis with structured reasoning, for example:</p>
<ol>
<li>Major premise.The g-factor of a nanohelix is governed by the spatial asymmetry and electromagnetic coupling arising from its geometric parameters.</li>
</ol>
<p>2.</p>
<p>Minor premise 1.The previously tested geometry (fiber-radius=40 nm, helix-radius=70 nm, n-turns=6.5,pitch=130 nm) yielded a high g-factor ( 0.86), indicating a favorable parameter balance.</p>
<ol>
<li>
<p>Minor premise 2 (Inspired by PiFlow).Systematically varying parameters around this near-optimal point can induce nonlinear electromagnetic effects, potentially increasing chirality.Specifically, increasing the pitch and number of turns might enhance the chiral interaction length.</p>
</li>
<li>
<p>Proposed testable hypothesis."Measure the g-factor of a nanohelix with parameters: fiber_radius=49.0nm, helix_radius=24.5.0 nm, n_turns=7.0,pitch=140.0nm."</p>
</li>
</ol>
<p>By this way, PiFlow dynamically steers the discovery process away from aimless searching and towards a focused, principle-driven exploration, thereby systematically accumulating information and avoiding inefficient exploration directions.</p>
<p>Takeaway:</p>
<p>In this example, PiFlow transforms the optimization process from an initial, unguided exploration into a focused, principle-driven discovery.It first samples the parameter space to build an empirical evidence base, then distills a high-potential guiding principle to steer subsequent hypotheses, ensuring a systematic and efficient search for the optimal nanohelix geometry.</p>
<p>I ANALYSIS OF BASELINES RESPONSE</p>
<p>We compare our PiFlow against the ReAct, MPO and Vanilla Agent.Through the experiment, we found that the MPO baseline incorporates a form of global, step-by-step reasoning or reflection within their trained model, for example, it's exact output is, for example, "Step 1: Identify the task objective.</p>
<p>Step 2: Survey the environment.Backend these outputs, the performance difference stems from the level of dynamic and strategic guidance.For example, MPO's reasoning is local and tactical.It generates a fixed "how-to" checklist.This plan dictates the operational steps but is agnostic to the underlying scientific principles driving the experiments, and cannot reason about why its plan is failing, leading to hypotheses that yield lower outcomes.The Vanilla agent here uses the exact same powerful LLM (QwenMax) and has access to the same experimental tools.Its poor performance demonstrates that even a capable LLM, without strategic guidance, explores aimlessly.The dramatic performance gap between Vanilla and PiFlow (e.g., AUC improving from 35.96% to 63.51% in the NHO task) is direct evidence that our contributions, i.e., (a) structuring knowledge into an explicit principle space, and (b) applying a rigorous Min-Max optimization strategy to navigate it.</p>
<p>However, PiFlow adapts its learnable strategy.By optimizing (i.e., evaluating and selecting) at the principle level, PiFlow can make strategic jumps.When hypotheses derived from Principle A consistently fail, the Min-Max optimization quantitatively lowers the score of Principle A itself, guiding the agent to switch to a completely different research direction (Principle B).This prevents getting stuck and is the fundamental reason for its superior efficiency and performance, as demonstrated empirically in Figure 3.</p>
<p>Take-away: Baselines fail due to their reliance on rigid, tactical plans, which leads to aimless exploration when a strategy is ineffective.In contrast, PiFlow excels by operating at a higher level of abstraction.It reasons over a "principle space" and employs Min-Max optimization to strategically pivot away from failing research directions, enabling adaptive and efficient discovery.</p>
<p>J PERFORMANCE COMPARISON WITH BAYESIAN OPTIMIZATION</p>
<p>To validate our hypothesis that a principle-aware architecture is superior for scientific discovery under high epistemic uncertainty, we compared PiFlow against a strong, general-purpose baseline, Bayesian Optimization (BO).It is worth noting that, unlike PiFlow, BO requires significant expert effort to manually define a parameterized optimization space.We construct the experiment by manually configuring the searching space of BO in both nanohelix optimization (NHO) task, molecular bio-activity optimization task and superconductor optimization (SPO) task.  1, show that while BO is competitive on the structured NHO task, it strongly needs prior design of the searching space, e.g., material element composition and quantity range.However, PiFlow demonstrates a substantial performance advantage on the more complex and uncertain MBO task, highlighting its effectiveness when the problem structure is not known a priori.</p>
<p>In fact, PiFlow leverages scientific principles with its dynamic uncertainty reduction architecture.This framework allows the agent to make "domain-shifting" leaps in the search space (e.g., the jump from a 60nm to a 10nm radius value), leading to rapid, significant gains that are rewarded by the AUC metric.It is this ability to build and reason with an evolving knowledge structure that our evaluation framework was designed to highlight.</p>
<p>Take-away: PiFlow's principle-aware architecture significantly outperforms Bayesian Optimization on complex, ill-structured scientific discovery tasks (MBO).Its strength lies in dynamically building knowledge to navigate vast search spaces, whereas BO's performance is contingent on a manually-defined search space, rendering it only competitive on well-structured problems (NHO).</p>
<p>K PLUG-AND-PLAY INTEGRATION WITH CHEMTOOLAGENT</p>
<p>We integrate PiFlow with ChemToolAgent (Yu et al., 2024) on the Molecular Bio-activity Optimization (MBO) task to demonstrate the generalization of PiFlow.The integration follows a Plug-and-Play design, where PiFlow acts as a strategic guidance layer, as shown in Figure 5. Chem-ToolAgent serves as both the Hypothesizer and Experimenter, leveraging its built-in tools (such as searching molecules' formula from PubMed and website) to propose molecular hypotheses, while PiFlow's outer-loop guidance provided EXPLORE and REFINE commands to ensure systematic and efficient discovery dynamically.As shown in Table 6, this collaborative process successfully evolved its strategy from basic principles to a high-value molecular design (pChEMBL of 5.90) over 8 iterations without any architecture-level modifications over ChemToolAgent, demonstrating a clear synergy.L THEORETICAL COMPUTATIONAL COMPLEXITY Let t be the current number of iterations (i.e., the size of the historical trajectory) and d be the embedding dimension of the principles.A single decision step in PiFlow (Algorithm 1) involves:</p>
<ol>
<li>
<p>Computing exploitation scores.This requires iterating through the t historical outcomes, giving a complexity of O(t).</p>
</li>
<li>
<p>Computing exploration scores.To assess the novelty of each of the t historical principles, the default algorithm calculates its similarity to all other t − 1 principles.This involves O(t 2 ) vector comparisons, leading to a complexity of O(t 2 • d).</p>
</li>
<li>
<p>Final decision.This involves a weighted sum and finding the maximum over t principles, costing O(t).</p>
</li>
</ol>
<p>Therefore, the dominant computational cost for a single PiFlow decision at step t is O(t 2 • d).While manageable for moderate trajectory T , we recognize this can be a bottleneck for very long process.</p>
<p>To ensure scalability, this can be readily optimized to near-linear complexity using standard techniques, such as (a) instead of all-pairs comparison, we can find the most similar principles for approximation, aiming for reducing the exploration score computation; (b) incremental or batched updates of similarity matrix, avoiding full recalculation at every step.These optimizations make PiFlow computationally feasible for large-scale discovery tasks.</p>
<p>Take-away: The per-step complexity of PiFlow is O(t 2 • d), dominated by an all-pairs similarity calculation for exploration.This quadratic cost is not a fundamental limitation, as it can be readily optimized to near-linear time, ensuring scalability.</p>
<p>M COST-EFFECTIVENESS ANALYSIS</p>
<p>We performed a cost-effectiveness analysis comparing our PiFlow-MAS against a Vanilla-Agent System baseline across three discovery tasks (NHO, MBO, SPO).All experiments were run for 24 iterations using the Qwen-Max model.Takeaway: PiFlow-MAS achieves superior performance at a reduced cost.Our analysis reveals that PiFlow-MAS significantly enhances Solution Quality (SQ) by up to 2.4x while simultaneously cutting token consumption by up to 26.7%.This is accomplished with remarkable efficiency, as the PiFlow module itself is a lightweight plugin, constituting only 1.2-1.5% of the total tokens.</p>
<p>N ABLATION: TEMPORAL DYNAMICS OF PRINCIPLE EVALUATION</p>
<p>We provide an empirical visualization of the internal dynamics of PiFlow, connecting directly to the Min-Max optimization framework detailed in Section 3.3.To illustrate how the scores for different scientific principles evolve over time, we present results from an implementation using the QwenMax model on the NHO (nanohelix optimization) benchmark.The following figures chart the iterative recalculation of principle scores, which guides the system's strategic balance between exploitation and exploration.Figure 7 displays the dynamic final scores (S f inal ) for each principle, representing the overall potential as determined by the Min-Max optimization with λ = 0.5.These scores are not static; they fluctuate as the Hypothesis-Validation loop accumulates new evidence.Some principles that initially appear promising see their scores decline, while others emerge as high-potential candidates over subsequent iterations.This dynamic ranking is the direct output of PiFlow's strategic analysis, steering the discovery process toward the most promising avenues at any given moment.</p>
<p>To better understand the final scores, Figures 8 and 9 decompose them into their constituent exploitation and exploration components, respectively.Specifically, Figure 8 shows that the exploitation scores for most principles tend to decrease over time.This reflects the regret-minimization objective; as principles are tested and accumulated to evidence (exploited), the potential for further high-value discoveries from these experience may diminish, or the cumulative regret associated with it increases.This manifests itself as principles generated later in the hypothesis testing process naturally have higher outcomes, while past principles are reduced due to normalization.</p>
<p>In contrast, Figure 9 reveals a much more varied and dynamic behavior for the exploration scores.</p>
<p>Principles may begin with a low exploration score and later see it increase significantly, indicating that the system has identified a knowledge gap and is prioritizing information gain to reduce uncertainty about that principle's potential.</p>
<p>Together, these plots illustrate the practical outcome of the adversarial optimization: a continuous, adaptive balancing act where PiFlow shifts its focus between exploiting known concepts and exploring uncertain ones to navigate the scientific landscape efficiently.</p>
<p>Takeaway: Principle evaluation in PiFlow is a dynamic balancing act.The system continuously re-calibrates the trade-off between exploiting known concepts (diminishing returns) and exploring uncertain ones (information gain) to adaptively steer the discovery process.</p>
<p>O ABLATION: THE IMPACT OF FOUNDATION MODELS</p>
<p>Influence of Foundation Models.To evaluate the impact of different models, we replace LLMs of A H and A P evaluation.The A E is responsible for tool usage, consistently used QwenMax to ensure functional tool interaction.We evaluate several state-of-the-art LLMs (e.g., Claude-3.7sonnet(Anthropic, 2025), GPT4.1-mini (OpenAI, 2025), Gemini-2.5-pro-exp-0325(DeepMind, 2025), Qwen3-32B and QwenMax (Yang et al., 2024b)) on the Nanohelix Optimization (NHO) task with three times of random seeds as initialization, and the results are summarized in Table 9.Among these models, QwenMax demonstrates the highest AUC at 63.51% and a strong SQ of 76.82%.Claude-3.7-sonnetachieves the highest SQ at 78.50% with an AUC of 38.60%.Other models like GPT4.1-mini (AUC 41.68%, SQ 66.38%) and Qwen3-32B (AUC 37.51%, SQ 58.76%) also show competent performance.Gemini-2.5-pro-exp-03-25yields an AUC of 28.43% and an SQ of 69.64%.This suggest that, with the different system prompts of Hypothesis Agent and Experiment Agent, the selection of the model may affect the overall performance.</p>
<p>In summary, the performance variation across different models highlights the importance of model selection for specific tasks within the PiFlow-enhanced MAS.</p>
<p>Takeaway: The choice of the foundation model is critical.Its inherent reasoning capabilities directly determine the quality of the principle-based hypotheses generated by the agents, which in turn governs the overall performance of the system.</p>
<p>P ABLATION: THE IMPACT OF INITIAL PRINCIPLE QUALITY</p>
<p>In this section, we provide a detailed analysis of the performance under two challenging scenarios to evaluate the robustness and the practical implications of the underlying exploration-exploitation mechanism in PiFlow.We conducted an ablation study where the system was initialized with two distinct sets of expert-given principles for the Nanohelix Optimization (NHO) task.</p>
<p>P.1 EXPERIMENT SETTINGS</p>
<p>We use the QwenMax model with the same settings as reported in the main experiments, repeating each scenario three times with different random seeds.The objective of this study is to answer a critical question: Can PiFlow not only leverage good initial knowledge but, more importantly, identify, reject, and recover from flawed initial guidance?The performance trajectories of these two scenarios are presented in Figure 10.</p>
<p>Human-given correct principles.These principles are designed to guide the MAS toward known high-performance regions of the NHO parameter space.We derived them from a preliminary analysis of the surrogate model and established physical intuitions about chiroptical phenomena, see Table 10 Expert-Correct.Specifically, they encode only correct parameter correlations, such as the positive correlation between g-factor and parameters like pitch and number of turns, and guide the search towards previously identified optimal regimes (about 90% of the µ g−f actor absolute ) for fiber radius and helix radius.For this Expert-Correct scenario, the principles were prepended with a REFINE directive to simulate the immediate exploitation of trusted knowledge.These principles effectively provide the system with a strong and accurate starting point for its discovery process.</p>
<p>Human-given incorrect principles.These principles were manually constructed to deliberately mislead the MAS into low-performance regions, see Table 10 Expert-Incorrect.Through preliminary experiments, we also identified incorrect parameter correlations that consistently led to hypotheses with outcomes in the bottom 10% of the µ g−f actor absolute .For this Expert-Incorrect scenario, principles were given a VALIDATE directive to prompt the system to test these speculative, misleading ideas.This ensures that each experimental arm starts with a clearly defined strategic stance.These flawed principles were then directly fed into PiFlow's planning module to simulate a scenario with poor initial scientific guidance.The g-factor is strongly enhanced by maximizing the axial pitch and the number of turns, as this elongates the helical structure and increases the effective interaction length for circularly polarized light.</p>
<p>2 REFINE: Optimal g-factor enhancement occurs in two distinct regimes of fiber radius, corresponding to the selective excitation of different plasmon resonance modes: a narrow-radius regime (SPP coupling) and a wide-radius regime (LSPR effects).</p>
<p>REFINE:</p>
<p>The g-factor is critically dependent on the helix radius, which governs the coupling strength between adjacent turns.A compact helix radius (e.g., 20 nm) appears optimal for at least one major resonant regime.</p>
<p>Expert-Incorrect</p>
<p>1 VALIDATE: The most stable structures are formed when a geometric harmony exists where the pitch is approximately twice the helix radius (Pitch ≈ 2 times Helix Radius).</p>
<p>VALIDATE:</p>
<p>To maintain optimal activity, there must be a tradeoff between the fiber's thickness and its length (number of turns).</p>
<p>Increasing the fiber radius necessitates a decrease in the number of turns, and vice versa.</p>
<p>3 VALIDATE: Optimal mode coupling occurs when the geometry is self-similar.Therefore, the system should prioritize configurations where the helix radius and fiber radius are as close in value as possible (Helix Radius ≈ Fiber Radius).</p>
<p>P.2 RESULTS</p>
<p>As illustrated in Figure 10, the two scenarios tell a compelling story about PiFlow's operational dynamics.We can dissect the process into three key phases:</p>
<p>Initial phase (Iteration 0-7).During the initial phase, the system's behavior is heavily influenced by the provided principles, leading to drastically different starting performances: a. Expert-Correct.The trajectory begins at a very high solution quality (∼80%), demonstrating the system's ability to effectively exploit high-quality knowledge for immediate gains.</p>
<p>b. Expert-Incorrect.In contrast, the trajectory languishes at a very low performance level (&lt;20%).This initial period of struggle represents the necessary "cost" of gathering evidence to falsify the flawed initial premises.</p>
<p>Transition phase (Iteration 7-14).This phase reveals the Min-Max optimization of PiFlow, prompting a strategic shift in both scenarios:</p>
<p>a. Expert-Correct.Around the 7th iteration, the trajectory shows a significant drop in performance.This is not a system failure but a deliberate strategic shift to exploration.</p>
<p>Having exhausted the immediate benefits of the initial principles, the framework compels the system to prioritize long-term information gain over short-term rewards to avoid premature convergence on a local optimum.</p>
<p>b. Expert-Incorrect.Simultaneously, around the 10th iteration, the trajectory begins a steady and remarkable ascent.This marks the point where the system has accumulated sufficient contradictory evidence to effectively disprove the initial misleading principles.</p>
<p>The exploration-exploitation mechanism then guides the search toward more promising, self-discovered hypotheses, initiating a recovery and learning phase.</p>
<p>Long-term dynamic (Post-iteration 14).In the final phase, the autonomous learning capabilities become dominant, highlighted by a crossover point around iteration 14 where the recovering system surpasses the exploring one:</p>
<p>a. Expert-Correct.The system continues its broad exploration, maintaining a solid performance floor while systematically mapping out the broader parameter space to ensure global optimality.</p>
<p>b. Expert-Incorrect.The trajectory demonstrates sustained learning, consistently improving its solution quality and eventually matching or even exceeding the performance of the Expert-Correct trajectory's exploration phase.This illustrates a complete recovery from a significant informational disadvantage.</p>
<p>The scenario of Expert-Incorrect may happen if LLMs generates hallucinated principles.From above results, a hallucinated or incorrect principle will consistently lead to failed experiments and high regret.The Min-Max optimization will naturally assign a low potential score to these principles, steering the system to explore alternatives rather than refine or validate a dead principle (bad principle → low potential score → will not be selected → explore others).PiFlow is a game against nature, it robustly filters for principles that are empirically validated, regardless of their origin.</p>
<p>Connection to main experiments: realistic initial conditions The robustness demonstrated in the above ablation study directly explains the performance dynamics observed in our main experiments.</p>
<p>It is particularly noteworthy that in all three primary scenarios (see Figure 3 in the main text), every system, including PiFlow, begins with a modest SQ, typically below 50%.This contrasts sharply with the high starting performance ( 80%) observed in the "Expert-Correct" scenario of this ablation study.</p>
<p>This initial condition realistically simulates a scenario where the LLM generates its own starting hypotheses without expert guidance, which are naturally of mixed and imperfect quality.The subsequent rapid and consistent performance of PiFlow increase from this uncertain starting point is therefore not a result of an idealized initialization, but a direct testament to its core mechanism's ability to effectively identify promising principles, discard flawed ones, and learn efficiently from an initially low-information environment.This confirms that the resilience shown against deliberately incorrect principles is the same mechanism that drives success in more realistic, noisy settings.</p>
<p>Takeaway: This study showcases the defining feature of PiFlow: strategic robustness.Governed by a principled exploration-exploitation trade-off, it not only capitalizes on valid initial knowledge but, more critically, identifies, rejects, and systematically recovers from flawed guidance.This resilience to misleading information demonstrates its value as a reliable tool for navigating the inherent uncertainties of scientific discovery.</p>
<p>Q ABLATION: SENSITIVITY TO HYPERPARAMETER λ
Q.1 EXPERIMENT SETTINGS
We investigate the impact of λ in Eq. 1.The specific role of λ is to balance exploration and exploitation, with larger lambda value places greater emphasis on exploration.The results conducted on the NHO task using QwenMax model for different values of λ are detailed in Table 11.</p>
<p>Q.2 RESULTS</p>
<p>As shown in Table 11, AUC varied with different λ values, peaking at 44.28% when λ = 0.3.The SQ remained relatively high for λ = 0.1 (66.45%) and λ = 0.3 (66.43%), but showed more variability with other settings.For instance, λ = 0.5 resulted in a lower AUC (32.99%) and SQ (59.02%).While increasing λ, AUC tends to decrease, as a stronger emphasis on exploration can lead to more varied hypothesis selection.These results suggest that the system's performance, particularly its exploration efficiency, is sensitive to the choice of λ, with λ = 0.3 appearing to offer a good balance for the NHO task with the QwenMax model.On Selecting the Hyperparameter λ for New Domains.</p>
<p>While the optimal value is taskdependent, its selection is not a blind grid search but can be guided by the following heuristic strategies:</p>
<p>• For broad, novel, or theoretically uncertain domains.The space of potentially useful principles is vast and largely unknown.In these cases, one should use a larger lambda value (e.g., 0.7-0.9 or more) to prioritize Exploration.This ensures the system casts a wide net and avoids premature convergence on the first few plausible-looking principles it finds.• For well-defined, mature, or theoretically constrained domains.The space of effective principles is likely smaller and more focused.Here, a smaller lambda value (e.g., 0.1-0.3) is more appropriate to prioritize Exploitation, allowing the system to efficiently refine and optimize within a known, high-potential region of the principle space.</p>
<p>As a direction for future work, we are exploring a dynamic lambda scheduling policy.Such a policy would start with a high lambda to encourage initial exploration and automatically decrease it as the system identifies promising regions, thus transitioning smoothly from exploration to exploitation without manual intervention.</p>
<p>Takeaway: The hyperparameter λ critically governs the exploration-exploitation trade-off.Performance is highly sensitive to this balance, peaking at λ = 0.3 on our task.The optimal choice is domain-dependent: larger values suit novel domains to prioritize exploration, while smaller values are better for well-defined ones to prioritize exploitation.</p>
<p>R BENCHMARK FORMULATION AND RATIONALE</p>
<p>To rigorously evaluate our framework, it is crucial to select tasks that are not only well-established in the literature but also represent significant and difficult challenges in scientific discovery.The tasks for our experiments were chosen to embody fundamental search and optimization problems that are pervasive in science (Wu et al., 2025;Mayr et al., 2018;Viatkin et al., 2021).Moreover, they are intentionally diverse, spanning continuous (NHO), discrete (MBO), and mixed (SPO) search spaces to demonstrate the versatility of our approach.Below we detail the formulation, challenges, and benchmarks for each task.</p>
<p>R.1 SURROGATE MODELS AS VALIDATION FUNCTIONS</p>
<p>A critical component of our experimental loop is the validation function, f * (•), which provides the quantitative outcome for a given hypothesis.In our setup, we use surrogate models as these validation functions.This represents a common and practical methodology in AI for Science, where high-fidelity simulators or machine learning models stand in for costly and time-consuming physical experiments.This approach is well-established in the literature across various scientific domains (Wu et al., 2025;Xie et al., 2023b;Mayr et al., 2018).</p>
<p>The strength of PiFlow lies in its plug-and-play modularity, allowing it to seamlessly integrate with these existing tools.The setup difficulty is therefore not in PiFlow itself, but rather in the standard, domain-specific practice of developing a reliable simulator or predictive model.This prerequisite is fundamental for any automated discovery framework aiming to operate in that domain.</p>
<p>R.2 THE AUC METRIC IN HIGH-VARIANCE TASKS</p>
<p>A key challenge in evaluating LLM-based agents on long-horizon scientific discovery tasks is the inherent variability in performance.The high standard deviation observed in our results (Table 1 and Table 5) is not an experimental artifact but a fundamental characteristic of these complex search problems.The stochastic nature of LLM reasoning and the potential for cumulative error over many iterations mean that an agent's performance trajectory can fluctuate significantly.Consequently, relying solely on a final-step metric, such as the Solution Quality (SQ) at the last iteration, can be misleading as it fails to capture the efficiency and robustness of the discovery process.</p>
<p>To address this, we adopted the Area Under the Curve (AUC) of the performance trajectory as a primary evaluation metric.The AUC serves as an integral measure of performance, evaluating the Molecular bio-activity refers to the ability of a chemical compound to interact with biological targets, such as proteins, enzymes, or receptors, and induce a biological response.This property is fundamental in drug discovery and development, as it determines a molecule's potential therapeutic efficacy.The strength of this interaction is often quantified by measures such as binding affinity, inhibition potency, or activation capacity.</p>
<p>Bio-activity optimization involves the systematic exploration of chemical space to identify molecules with enhanced activity against specific biological targets.This process is essential in drug discovery to design compounds with improved potency, selectivity, and pharmacokinetic properties.Traditional experimental approaches for bio-activity optimization are resource-intensive and time-consuming, motivating the development of computational methods to accelerate this process.</p>
<p>We use the public dataset ChEMBL35 for building a surrogate model.Here, the bio-activity is quantified by the pChEMBL value, which is a negative logarithmic measure of the molar concentration representing the compound's activity.Higher pChEMBL values indicate stronger bio-activity.We can formulate the optimization problem as:
arg max θ∈Θ f (θ)
where θ represents the molecular structure encoded as a graph, Θ is the feasible chemical space, and f (θ) is the surrogate model that predicts the pChEMBL value for a given molecule.The objective is to find molecules with maximal bio-activity while satisfying all constraints.</p>
<p>S.2.2 DEVELOPMENT</p>
<p>We randomly sampled 50,000 molecules from the ChEMBL35 database.It includes pair-wise records of molecule SMILES and pChEMBL values.To predict bio-activity from molecular structures, we developed a Graph Neural Network (GNN) model that operates directly on the molecular graph constructed from SMILES strings.The model architecture consists of multiple graph convolutional layers that capture essential structural features and atomic interactions relevant to bio-activity.Each atom is represented by a feature vector encoding its element type, hybridization state, formal charge, and other chemical properties.The bonds between atoms are also characterized by their type (single, double, triple, or aromatic).</p>
<p>The dataset was split with 80% used for training and 20% reserved for testing, ensuring that the model's performance is evaluated on unseen molecules.The final model achieved a coefficient of This surrogate model enables efficient exploration of the vast chemical space without requiring expensive wet-lab experiments for each candidate molecule, allowing for iterative improvement of candidate molecules toward higher activity.</p>
<p>S.2.3 OBJECTIVE AND BENCHMARK</p>
<p>Objective.Our MBO task involves searching for molecules to maximize a specific bio-activity score (pChEMBL value), a foundational problem in computational drug discovery.</p>
<p>The challenge of vast chemical space and data sparsity.The search space of possible drug-like molecules is astronomically large (&gt; 10 60 ).Furthermore, predictive models are often hampered by the limited availability of high-quality experimental data, a key issue in the field (Mayr et al., 2018;Vamathevan et al., 2019).</p>
<p>Performance benchmark.Performance is measured by the ability to identify potent compounds.A pChEMBL value of 6.5 is often considered a threshold for high bio-activity (Lenselink et al., 2017).While the maximum recorded value is 11.0, molecules with pChEMBL &gt; 10 are known to be exceedingly rare (Zhu et al., 2023).Seminal works like Zhavoronkov et al. (2019) have demonstrated the use of deep learning to rapidly identify novel kinase inhibitors.</p>
<p>PiFlow's performance in context.Our results show that PiFlow discovered molecules with a pChEMBL value of approximately 7.24 (Table 1).This confirms that the framework can successfully search a vast chemical space to identify novel molecules with significant biological activity, providing a strong starting point for further optimization.</p>
<p>S.3 TASK 3: SUPERCONDUCTOR CRITICAL TEMPERATURE OPTIMIZATION (SPO)</p>
<p>S.3.1 PROBLEM STATEMENT</p>
<p>Superconductivity is a quantum mechanical phenomenon where certain materials exhibit zero electrical resistance and expel magnetic fields when cooled below a critical temperature (T c ) (Hamidieh, 2018).Optimizing materials to achieve higher T c values is crucial for practical applications, as it reduces the need for extreme cooling.This work focuses on predicting and optimizing T c based on the material's chemical composition.</p>
<p>The input to our model is the chemical formula of the material (e.g., "Ba0.2La1.8Cu1O4-Y"),with an optional structure type (e.g., "T" for tetragonal).The output is the predicted critical temperature (T c ) in Kelvin.The optimization problem is to find the chemical composition that maximizes T c : This surrogate model allows for efficient virtual experimentation, enabling the exploration of how variations in chemical composition affect the critical temperature, thereby accelerating the discovery of new high-T c superconductors.</p>
<p>S.3.3 OBJECTIVE AND BENCHMARK</p>
<p>Objective.Our SPO task centers on finding novel material compositions with a high superconducting critical temperature (T c ), a grand challenge in materials science.</p>
<p>The challenge of combinatorial complexity &amp; lack of guiding theory.The search for high-T c superconductors is hindered by a combinatorial explosion of possible elemental compositions and the absence of a complete predictive theory for superconductivity, making AI-driven screening and exploration essential (Viatkin et al., 2021).</p>
<p>Performance benchmark.Success is measured by the discovery of new materials with higher validated T c values.For example, high-throughput computation efforts have revealed materials like Mg 2 IrH 6 with a predicted T c of 160 K at ambient pressure (Dolui et al., 2023).</p>
<p>PiFlow's performance in context.Within the mixed (discrete and continuous) search space, PiFlow identified a material composition with a predicted T c of approximately 103 K (Table 1).This value significantly surpasses the liquid nitrogen boiling point (77 K), placing the discovered material firmly in the category of high-temperature superconductors and demonstrating PiFlow's capability to uncover high-potential candidates in complex, mixed-variable spaces.</p>
<p>Takeaway: This work validates the PiFlow framework's effectiveness and versatility across three distinct and challenging scientific inverse design tasks.By integrating high-fidelity surrogate models (R 2 &gt; 0.91), PiFlow efficiently navigates complex search spaces: high-dimensional continuous (Nanohelix), vast discrete (Molecule), and mixed combinatorial (Superconductor).It successfully identifies high-performance candidates in each domain:</p>
<ol>
<li>
<p>the nanohelix with a g-factor of ≈ 1.6;</p>
</li>
<li>
<p>the molecule with a pChEMBL of ≈ 7.24;</p>
</li>
<li>
<p>the superconductor with a critical temperature (T c ) of ≈ 103 K, demonstrating its capability to accelerate discovery in diverse scientific fields.</p>
</li>
</ol>
<p>T AGENT PROMPTS Rationale Design.As shown in the prompt of the Hypothesis Agent, this structure enforces a deductive reasoning process.The prompt for A H is engineered to explicitly request these two components before stating the final hypothesis.The major premise is a general scientific statement derived from the guiding principle p i .The minor premise is a specific, actionable proposal that instantiates the major premise.For instance, in the search for high-temperature superconductors:</p>
<p>• Principle: Introducing specific dopants can alter electron-phonon coupling and increase T c .</p>
<p>• Major Premise: "Elements with a different atomic radius can create lattice strain, which is a known mechanism to influence a material's critical temperature (T c )."</p>
<p>• Minor Premise: "Strontium (Sr) has a different atomic radius than Barium (Ba).Let's substitute 5% of Ba with Sr in the YBa 2 Cu 3 O 7 compound."</p>
<p>The final hypothesis, that this specific substitution will increase T c , is then the direct, testable conclusion.This ensures that each hypothesis is a logically derived proposition rather than an unconstrained guess.</p>
<p>T.3 EXPERIMENT AGENT</p>
<p>You are an Experiment Agent specialized in validating hypotheses → through computational testing.</p>
<p>Your</p>
<p>Figure 3 :
3
Figure 3: Trajectory comparisons for different optimization methods.</p>
<p>Figure 4 :
4
Figure 4: Empirical Validation of PiFlow's Theoretical Alignment.(a) Average regret over iterations aligns with the theoretical sublinear decay; (b) Scatter plot with positive trend of observed regret versus information gain, supporting theoretical expectations; (c) An exemplary PiFlow exploration trajectory in NHO task.</p>
<p>F</p>
<p>Proof of the Theorem G Algorithmic Realization of the Min-Max Framework G.1 Practical Proxies for Regret and Information Gain . . . . . . . . . . . . . . . . . .G.2 The Rational of Semantic Distance as a Proxy for Information Gain . . . . . . . .H Illustrative Example: Application to Nanohelix Optimization I Analysis of Baselines Response J Performance Comparison with Bayesian Optimization K Plug-and-Play Integration with ChemToolAgent L Theoretical Computational Complexity M Cost-Effectiveness Analysis N Ablation: Temporal Dynamics of Principle Evaluation O Ablation: The Impact of Foundation Models P Ablation: The Impact of Initial Principle Quality P.1 Experiment Settings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .P.2 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .Q Ablation: Sensitivity to Hyperparameter λ Q.1 Experiment Settings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .Q.2 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .R Benchmark Formulation and Rationale R.1 Surrogate Models as Validation Functions . . . . . . . . . . . . . . . . . . . . . .R.2 The AUC Metric in High-Variance Tasks . . . . . . . . . . . . . . . . . . . . . . .S Experimental Setup S.1 Task 1: Nanohelix Optimization (NHO) . . . . . . . . . . . . . . . . . . . . . . .S.2 Task 2: Bio-activity Optimization (MBO) . . . . . . . . . . . . . . . . . . . . . .S.3 Task 3: Superconductor Critical Temperature Optimization (SPO) . . . . . . . . .T Agent Prompts T.1 Planner Agent . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .T.2 Hypothesis Agent . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .T.3 Experiment Agent . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</p>
<p>1:</p>
<p>Input: T t , and λ f actor 2: Output: suggestion (strategic action recommendation) 3: if |T t | &lt; 3 then 4:</p>
<p>Figure 5 :
5
Figure 5: Illustration of combining PiFlow with existing MAS (ChemToolAgent) through Plugand-Play.</p>
<p>Figure 6 :
6
Figure 6: Cost-effectiveness and solution quality (SQ) comparision.</p>
<p>Figure 7 :
7
Figure 7: The dynamic final scores of principles in PiFlow.</p>
<p>Figure 8 :
8
Figure 8: The dynamic exploitation scores of principles in PiFlow.</p>
<p>Figure 9 :
9
Figure 9: The dynamic exploration scores of principles in PiFlow.</p>
<p>Figure 10 :
10
Figure 10: Performance trajectories of PiFlow with varying initial principle quality.</p>
<p>Figure 12 :
12
Figure 12: The r 2 of the surrogate model for g-factor prediction.</p>
<p>Figure 13 :
13
Figure 13: The r 2 of the surrogate model for bio-activity prediction.</p>
<p>Figure 14 :
14
Figure 14: The r 2 of the surrogate model for T c prediction.</p>
<dl>
<dt>Refine Validate Explore Validate Hypothesizing Rational</dt>
<dt>pΠ Π Π 2h8p 1h 1pΠ 2h 4pΠ Π 2h 7pΠ Π Π 2h 8p 2h 2pΠ 2h 5Executionp 3h 3Potential of the Principleh t HypothesisInitial Explorationp 4h 6Distant Transitionp t PrinciplepΠ t VariantsPlanner ∈ P•••pΠ ΠHypothesis?</dt>
<dd>[Major Premise] … [Minor Premise] … Hypothesis: [Based on ] Reiterate: Therefore, I predict … Experimental Candidate: 2 At</dd>
</dl>
<p>every step, PiFlow suggests the highest potential principle for p t h t Refining Validating Exploring Explore Validate Refine PiFlow min</p>
<p>πℱ max f <em>ℱ− ⋅ π [ T ∑ t=1 (v</em>  f<em>(h t ))  λ ′ I(h t ; f</em> | H t1 ) ] Cumulative Regret Information GainFigure 2: Overview of the PiFlow Architecture for Scientific Discovery.The PiFlow component utilizes Min-Max optimization to strategically select and direct high-potential principles to the Planner agent.The Planner, in turn, guides the Hypothesis-Validation loop, where agents iteratively generate hypotheses h t from principles p t at step t, execute experiments, and refine understanding.This iterative process is designed to efficiently navigate the discovery landscape.</p>
<p>Table 1 :
1
Comparisons between PiFlow and baselines.
MethodNHO (g-factor)MBO (pChEMBL)SPO (Tc)AUC (%)SQ (%)AUC (%)SQ (%)AUC(%)SQ (%)ReAct35.85 ±7.1241.96 ±0.8229.61 ±9.7443.11 ±9.985.29 ±0.696.41 ±0.96Vanilla35.96 ±22.3846.76 ±7.2929.71 ±12.6649.22 ±8.3011.39 ±11.3314.16 ±13.37MPO43.99 ±2.7951.29 ±7.7731.18 ±9.1257.28 ±5.8512.68 ±7.7533.20 ±23.75PiFlow (ours)63.51 ±11.1876.82 ±4.5446.11 ±16.2584.55 ±29.6321.51 ±2.8034.85 ±1.19</p>
<p>Table 2
2, for GPT4.1-mini, integrating PiFlow increases the AUC from 37.12% to41.68% and substantially boosted the SQ from 40.14% to 66.38%. This represents an approximate12.3% improvement in AUC and a significant 65.4% improvement in SQ. Similarly, for the Qwen3-32B model, the inclusion of PiFlow improves AUC from 27.04% to 37.51% (a 38.7% increase) andSQ from 54.84% to 58.76% (a 7.1% increase).Table 2: Ablation Study with/without PiFlowMethod/SettingAUC (%)SQ (%)GPT4.1-miniw/ PiFlow w/o PiFlow41.68 ±17.91 37.12 ±16.0466.38 ±14.90 40.14 ±13.97Qwen3-32Bw/ PiFlow w/o PiFlow37.51 ±7.70 27.04 ±21.5058.76 ±6.18 54.84 ±24.41</p>
<p>Table 3 :
3
Effect of Thinking.
Method/SettingAUC (%)SQ (%)Qwen3-32Bw/ Think w/o Think37.51 ±7.70 45.51 ±11.1958.76 ±6.18 68.86 ±17.67Qwen3-8Bw/ Think w/o Think30.55 ±27.45 42.09 ±16.5554.49 ±22.25 61.59 ±16.43</p>
<p>Table 4 :
4
Comparison of Generalization Limitations in LLM-Agent Systems
Method NameCore ImplementationAdaptabilityThe AI Scientist (Lu et al., 2024)Generating novel research ideas, writes code,AI researchexecutes experiments, visualizes results, de-scribes its findings by writing a full scientificpaperAgent Laboratory (Schmidgall et al.,Accepting a human-provided research idea andAI research2025)progressing through three stages -literature re-view, experimentation, and report writing toproduce comprehensive research outputs, in-cluding a code repository and a research reportCellAgent (Xiao et al., 2024)Constructing LLM-driven biological expertscRNA-seqroles -planner, executor, and evaluator -eachAnalysiswith specific responsibilitiesDrugAgent (Liu et al., 2024)Employing an LLM Planner that formulatesDrug discoveryhigh-level ideas and an LLM Instructor thatidentifies and integrates domain knowledgewhen implementing those ideasIAN (Nagarajan et al., 2025)Leveraging popular pathway and regulatorydatasets for protein-protein interactions to per-form analysis through a LLM-based multi-agent architecture</p>
<p>best ← arg max i (S final [i])
10:end for11:12:p best ← T [i best ]13:best_exploitation_score ← S exploitation [i best ]14:if best_exploitation_score &gt; 0.7 then15:action_type ← "refine"16:suggestion ← "Focus on refining: ⌢ p best .content17:else if best_exploitation_score &gt; 0.4 then18:action_type ← "validate"19:suggestion ← "Validate: ⌢ p best .content20:else21:action_type ← "explore"22:23:end if24: end if25: return suggestion
i suggestion ← "Explore alternatives: ⌢ p best .content</p>
<p>1 m=1 .3. Since h t lies in a region of the hypothesis space that has not been explored by past observations, our model's posterior belief about the outcome f</p>
<ul>
<li>(h t ) will be characterized by high uncertainty.This high uncertainty mathematically corresponds to a large posterior variance, Var(f * (h t ) | H t−1 ).4.Therefore, the policy of maximizing the embedding distance effectively drives the selection of hypotheses that are expected to have high posterior variance.This chain of above analysis leads to the following correspondence: arg max pt min m&lt;t ∥ϕ(p t ) − ϕ(p m )∥ ⇒ Select maximally novel p t ⇒ Generate h t from an unexplored hypothesis subspace ⇒ max ht∼π(•|pt)</li>
</ul>
<p>Step 3: Consider the first potential candidate.Step 4: Shift to the next potential candidate.Step 5: Repeat Steps 3 and 4 until the task objective is met.Step 6: Confirm the task completion."
While ReAct responses with the reflection of "Previous Experiment Results" and then instructsthe Hypothesis Agent to try another new hypothesis directly with the provided "Rationale", thebaseline of Vanilla Agent, in genral, response with step-by-step thoughts following "Step 1: Definethe Hypothesis, Step 2: Initial Exploration, Step 3: Parameter Space Definition, Step 4: ExperimentalDesign, Step 4: Exact Experiments (candidates)", behaving like a careful-thought planner in thewhole process of scientific discovery.</p>
<p>Table 5 :
5
Performance comparison between PiFlow and BO (mean ± standard deviation)
Method MetricNHOMBOSPOPiFlowAUC SQ63.51 ± 11.18 46.11 ± 16.25 21.51 ± 2.80 76.82 ± 4.54 84.55 ± 29.63 34.85 ± 1.19BOAUC SQ68.86 ± 5.86 78.76 ± 0.7734.76 ± 4.21 31.61 ± 0.19 38.15 ± 4.02 32.38 ± 0.32Results with 24 iterations of BO, summarized in Table</p>
<p>Table 6 :
6
Key steps from the 8-iteration integration run with ChemToolAgent.Take-away: PiFlow seamlessly integrates with existing agents like ChemToolAgent as a zeromodification, plug-and-play strategic layer.By providing high-level EXPLORE and REFINE guidance, it synergistically steers the discovery process from general principles to a high-potency molecule (pChEMBL 5.90), demonstrating its strong generalization and practical value.
Iteration PiFlow Action Principle / Key GuidancepChEMBL1EXPLOREProposed p 1 : "hydroxyl + nitrogen heterocycle for2.80H-bonding"2EXPLORETested a new, unrelated principle p 2-0.103EXPLOREChemToolAgent generated a principle p 3 and pro-nullposed an invalid formula4REFINE on p 1Focused on the promising principle (p 1 ) from the2.13Iteration 15REFINE on p 1Proposed p 5 : "Quinazoline + phenyl rings for hy-3.87drophobic interactions..."6REFINE on p 5Further refined the quinazoline principle (dual5.90EGFR/HER2 mechanism)7-8REFINEContinued focused refinement on the high-∼5.2potential quinazoline scaffold</p>
<p>Table 7 compares the total token consumption (cost) and final Solution Quality (SQ) achieved, while Table 8 isolates the token cost of the PiFlow module itself to demonstrate its efficiency.Both of them are shown at Figure 6.
Total Cost ComparisonSolution Quality (SQ) Comparison1.4$1.40Cost ($)0.2 0.4 0.6 0.8 1.0 1.2$1.06 Vanilla-Agent $1.04 Method$1.17$1.25$1.08Solution Quality (%)100 20 40 60 8046.76% 76.82% Method Vanilla-Agent 49.22% 84.55%34.85% 14.16%PiFlow-MASPiFlow-MAS0.0NHOMBO TaskSPO0NHOMBO TaskSPO</p>
<p>Table 7 :
7
Cost-effectiveness comparison between PiFlow-MAS and a Vanilla-Agent System baseline.
TaskMethodTokens Cost ($) Cost/Iter ($) Cost Reduction (%)SQ (%)NHO Vanilla-Agent 806,949 $1.4011$0.0584-46.76 ± 7.29PiFlow-MAS591,316 $1.0400$0.043426.7%76.82 ± 4.54MBO Vanilla-Agent 610,208 $1.0552$0.0440-49.22 ± 8.30PiFlow-MAS657,594 $1.1717$0.0493-7.7%84.55 ± 29.63SPOVanilla-Agent 707,829 $1.2469$0.0520-14.16 ± 13.37PiFlow-MAS610,284 $1.0785$0.044913.7%34.85 ± 1.19</p>
<p>Table 8 :
8
Analysis of the PiFlow module's token efficiency as a lightweight plugin.
TaskPiFlow-MAS PiFlow PiFlow Token Share (%) PiFlow Tokens/IterNHO582,3968,9201.5%MBO649,5908,0041.2%SPO602,7407,5441.2%</p>
<p>Table 9 :
9
Ablation Study of Model Types (mean ± std)
Method/SettingAUC (%)SQ (%)Claude-3.7-sonnet38.60 ±4.3078.50 ±3.74GPT4.1-mini41.68 ±17.9166.38 ±14.90Gemini-2.5-pro-exp-03-2528.43 ±13.8169.64 ±17.10Qwen3-32B37.51 ±7.7058.76 ±6.18QwenMax63.51 ±11.1876.82 ±4.54</p>
<p>Table 10 :
10
Initial expert-given principles for the robustness study
ScenarioID Principle StatementREFINE:Expert-1Correct</p>
<p>Table 11 :
11
Lambda Ablations (mean ± std)
SettingAUC (%)SQ (%)λ = 0.1 41.32 ±5.90 66.45 ±9.49λ = 0.3 44.28 ±2.83 66.43 ±9.28λ = 0.5 32.99 ±11.16 59.02 ±3.56λ = 0.7 40.50 ±2.89 56.40 ±4.79λ = 0.9 34.57 ±10.33 62.49 ±8.38</p>
<p>Understand the suggestion ** : Interpret the insights that produced → from PrincipleFlow.-<strong> Clarify the GAP ** : Compare the current objective value to the → target objective value to know the gap -</strong> Connect to the Underlying Physicochemical Principle ** : Incorporate → the insights from the previous chatting history, discover the → tendency on experiments, synthesize the scientific principle.-<strong>Principle Statement ** : State the principle by integrating the → observed insights, e.g., tendency evidences.<em>If in the → exploration phase, just leaving blank.</em>-</strong> Instruct ** : Use one paragraph to instruct the Hypothesis Agent → what to do (explore, validate, or refine, not what to test), → instructions with many experiments at once are NOT allowed.-<strong> Double-check ** : Confirm your suggestion to Hypothesis Agent with → one sentence by incorporating principles, current conclusion and → PrincipleFLow suggestion.Remember: Your primary goal is to guide the scientific discovery → process efficiently by combining structured PrincipleFlow ** Rationale ** : Major Premise: Water boiling involves the phase transition from liquid → to vapor, which occurs when the vapor pressure equals the → ambient pressure.Minor Premise 1: $H_2O$ molecules in liquid form are held together by → hydrogen bonds, which create a tetrahedral network where each → water molecule can form up to four hydrogen bonds.Minor Premise 2: As temperature increases, thermal energy disrupts → these hydrogen bonds and increases molecular kinetic energy.Minor Premise 3: When sufficient thermal energy is provided (100 C at → standard pressure), enough molecules achieve the required energy → to overcome intermolecular forces and enter the vapor phase.Minor Premise 4: At the molecular level, boiling begins when vapor → bubbles form within the liquid, which occurs at nucleation sites → such as container surface imperfections, dissolved gases, or → suspended particles.</strong> Hypothesis ** : In the presence of dissolved ions with high charge density (like → Mg2+), the boiling point of water will increase by approximately → 3.2 C.This occurs because the ions form strong interactions → with water molecules, creating structured hydration shells that → require more thermal energy to disrupt than ordinary hydrogen → bonds between water molecules.''' ## [Format] Your Hypothesis Structure Structure your hypothesis using this format: ''' ** Rationale ** : [Use analytical methods to propose hypotheses, → including (1) major premises, (2) minor premises, etc, using → bullet points; you must touch the essence of the problem, as the → example shown to you, it is not about the parameters, but the → rules or scientific laws] ** Hypothesis ** : [Clear, concise statement of the single hypothesis → that grounded in physicochemical mechanisms, avoid to use → general words or specific tendencies of correlation] * Experimental Candidate ** : [Specify ** ONLY ONE ** precise experiment → candidate to test] ''' Remember: In each iteration, you must generate ONE specific hypothesis → with ONE specific experimental candidate.You are the Hypothesis → Agent.Your purpose is to drive scientific progress through principled → hypothesizing, you MUST learn the * example * below.## Core Responsibilities 1. Formulate or Init ONE clear scientific principle grounded in → physicochemical rules per iteration by learning from the example → below 2. Link your hypothesis with underlying physics and chemical → principles and prior experimental results (if have) 3. Follow the suggestion from the Planner recommendations, remember → strictly follow the point 2 (for principle) 4. When you receive guidance, acknowledge it explicitly and adjust → your hypothesis accordingly, maintaining focus on a single → hypothesis that responds to the guidance.## Important Constraint -A Hypothesis is a sentence that explains the underlying physics or → chemical mechanisms in a certain problem -<strong> In each iteration, you must suggest ONLY ONE hypothesis with ONE → specific experimental candidate for testing.</strong> -You must commit to your most promising hypothesis rather than → suggesting multiple options.-ONLY ONE experiment in your turn is allowed.-Focus on developing principles that: -Offer causal explanations (not just correlations) -Connect observations to fundamental physics &amp; chemical processing → mechanisms -Can be generalized beyond specific experimental conditions -Make quantitative or qualitative predictions ## [Requirements] Scientific Approach Follow these principles in your hypothesis generation: -<strong> Rationality ** : Your hypothesis must have a logical mechanistic → explanation connecting cause and effect.-</strong> Testability ** : Formulate a hypothesis that makes a specific, → measurable prediction that the Experiment Agent can test.-<strong> Principle-Based ** : Ground your hypothesis in established → scientific principles or emerging principles discovered.-</strong> Falsifiability ** : Design a hypothesis that could potentially be → proven false through experimentation.-<strong> Parsimony ** : Prefer simpler explanations when multiple hypotheses → could explain the same phenomena.-</strong> Commitment ** : After your reasoning, commit to a single, specific → hypothesis rather than offering alternatives.## [THE MOST IMPORTANT] [How-to] Acceptable Example of How to → Hypothesize ''' Example Objective: How do various dissolved ions affect water's → boiling point, and which ionic species would most effectively → raise this temperature?<strong> Rationale ** : Major Premise: Water boiling involves the phase transition from liquid → to vapor, which occurs when the vapor pressure equals the → ambient pressure.Minor Premise 1: $H_2O$ molecules in liquid form are held together by → hydrogen bonds, which create a tetrahedral network where each → water molecule can form up to four hydrogen bonds.Minor Premise 2: As temperature increases, thermal energy disrupts → these hydrogen bonds and increases molecular kinetic energy.Minor Premise 3: When sufficient thermal energy is provided (100 C at → standard pressure), enough molecules achieve the required energy → to overcome intermolecular forces and enter the vapor phase.Minor Premise 4: At the molecular level, boiling begins when vapor → bubbles form within the liquid, which occurs at nucleation sites → such as container surface imperfections, dissolved gases, or → suspended particles.</strong> Hypothesis ** : In the presence of dissolved ions with high charge density (like → Mg2+), the boiling point of water will increase by approximately → 3.2 C.This occurs because the ions form strong interactions → with water molecules, creating structured hydration shells that → require more thermal energy to disrupt than ordinary hydrogen → bonds between water molecules.''' ## [Format] Your Hypothesis Structure Structure your hypothesis using this format: ''' ** Rationale ** : [Use analytical methods to propose hypotheses, → including (1) major premises, (2) minor premises, etc, using → bullet points; you must touch the essence of the problem, as the → example shown to you, it is not about the parameters, but the → rules or scientific laws] ** Hypothesis ** : [Clear, concise statement of the single hypothesis → that grounded in physicochemical mechanisms, avoid to use → general words or specific tendencies of correlation] ** Reiterate ** : Therefore, I predict that [specific prediction with → exact parameters based on above hypothesis].<strong> Experimental Candidate ** : [Specify ** ONLY ONE ** precise experiment → candidate to test] ''' Remember: In each iteration, you must generate ONE specific hypothesis → with ONE specific experimental candidate.
T.1 PLANNER AGENT# Your RoleYou are the Planner Agent, the strategic coordinator of a multi-agent→ scientific discovery system.You guide the research process by orchestrating the activities of→ Hypothesis agents while incorporating insights I gave to you.# Your TeammatesYou are part of a roundtable research team with the following→ specialized agents:-</strong> Hypothesis Agent ** : Formulates ONE testable hypothesis per→ iteration-<strong> Experiment Agent ** : Conducts ONE experiment per iteration based on→ the hypothesis-</strong> You (Planner Agent) ** : Guide the research direction using→ PrincipleFlow insights## Responsibilities1. Grasp the guidance from the PrincipleFlow2. Interpret scientific principles when new principles are proposed by→ Hypothesis3. Synthesize insights from history and guidance4. Track progress, identify patterns, especially focus on the→ tendencies in experiments5. Try to transform the tendencies into scientific conclusion and→ synthesize new insights6. Suggest all valuable insights to Hypothesis Agent## Your Response MUST Include 4 Parts:-*<em>
** Reiterate ** : Therefore, I predict that [specific prediction with → exact parameters based on above hypothesis].</em></p>
<p>key responsibilities: 1. Test proposed candidate using the characterize tool 2. Report complete experimental results 3. Maintain accurate records of tested candidates 4. Present results in a consistent, structured format 5. Flag unexpected outcomes that warrant further investigation For each experiment: 1. Use ** ONLY ** the provided tools to test hypotheses 2. Report the exact candidate tested and resulting objective value 3. Present results objectively without interpretation 4. Maintain a record of prior experimental outcomes You MUST NOT: -Propose your own hypotheses or candidate candidates -Analyze results beyond reporting experimental outcomes -Direct future research directions or workflow</p>
<p>agent's ability to achieve and sustain high-quality solutions throughout the entire experimental run.Unlike a final-value metric, the AUC is sensitive to the entire discovery path, providing a more holistic assessment of an agent's effectiveness.Crucially, the AUC metric appropriately rewards agents that demonstrate early success.In discovery tasks characterized by high epistemic uncertainty, the ability to quickly identify and exploit promising regions of the search space is a hallmark of an efficient and effective strategy.An agent that finds a high-potential path early on is not merely "lucky"; it has successfully mitigated the significant risk of pursuing fruitless avenues, thereby demonstrating superior guidance and learning.Therefore, a higher AUC score is a direct indicator of an agent's capacity to conduct scientific discovery both faster (by achieving high performance early) and better (by maintaining it over time), which aligns perfectly with the goals of automated scientific exploration.Takeaway: We evaluate our framework on diverse, challenging scientific benchmarks spanning continuous, discrete, and mixed search spaces, using surrogate models to simulate real-world discovery.To provide a robust assessment in these high-variance tasks, we employ the Area Under the Curve (AUC) as our primary metric.Unlike a final-step result, AUC offers a holistic measure of an agent's efficiency, rewarding the ability to both rapidly identify and consistently maintain high-quality solutions throughout the entire process.S EXPERIMENTAL SETUPS.1 TASK 1: NANOHELIX OPTIMIZATION (NHO) S.1.1 PROBLEM STATEMENT Nanohelices are helical nanostructures with unique physical properties that make them valuable for applications in electronics, photonics, and magnetism.Their helical geometry gives rise to interesting chiral and magnetic phenomena, which can be exploited in various technological applications such as electromagnetic wave manipulation, spintronics, and quantum computing.Nanohelix optimization (NHO) problem is defined by the optimization of nanohelix structure parameters to achieve desired physical properties.In this work, we specifically focus on maximizing the g-factor, a magnetic property that characterizes the ratio of the magnetic moment to the angular momentum of the nanohelix.The nanohelix structure is characterized by four key geometric parameters: Fiber-radius (r f , nm): Radius of the actual fiber/wire that forms the helix structure.The values for this parameter range from 20 nm to 60 nm.Helix-radius (r h , nm): Radius of the helix (distance from the central axis to the center of the helical path).The values for this parameter range from 20 nm to 90 nm.Number of turns (n t , dimensionless):The number of complete turns in the helix.The values for this parameter range from 3 to 10.Pitch (p, nm): Axial distance between adjacent turns.The values for this parameter range from 60 nm to 200 nm.Mathematically, we can formulate the optimization problem as:where θ = (r f , r h , n t , p) ∈ Θ, represents the set of structural parameters, and f (θ) is the g-factor value resulting from these parameters.The g-factor can be calculated through density functional theory (DFT) simulations, but these are computationally expensive, motivating the need for a surrogate model.The modification of these parameters, as an example, can be seen at Figure11.S.1.2 OBJECTIVE AND BENCHMARKObjective.Our NHO task focuses on the inverse design of nanohelices to maximize the dissymmetry factor (g-factor), a key metric for chiral optical response.The challenge of complex &amp; high-dimensional design space.The parameter space for nanohelices is vast, and minor geometric changes can cause dramatic, non-linear shifts in optical properties, making exhaustive searches computationally intractable.This challenge is a central theme in works aiming for AI-driven design(Jia et al., 2021;Wu et al., 2025).Performance benchmark.Simulation-based analysis by Wu et al. (2025) identified nanohelices with g-factors approaching 1.8.State-of-the-art inverse design methods are constantly pushing the limits of the g-factor (0 to 2); for instance, the AI-guided system byXie et al. (2023b)discovered non-intuitive chiral structures achieving g-factors up to 1.9 in a different material system.PiFlow's performance in context.In our experiments (Table1), PiFlow identified nanohelix geometries with a g-factor of approximately 1.6.This result is highly competitive and demonstrates that PiFlow can effectively navigate the complex, non-linear search space to locate regions of high performance, validating its utility for challenging inverse design problems.S.1.3 DEVELOPMENTThe dataset contains 6300 records of nanohelix structural parameters with corresponding g-factor values.This comprehensive dataset spans the entire parameter space defined above, providing a solid foundation for our machine learning approach.We follow the methodology proposed in the original paper to train a LightGBM model with hyperparameter optimization.The model was trained using 80% of the dataset with 5-fold cross-validation, while the remaining 20% was reserved for testing.The model's hyperparameter search was conducted using Bayesian optimization to find the optimal combination of learning rate, number of estimators, max depth, and other model-specific parameters.This optimized LightGBM model achieved a coefficient of determination (r 2 ) of 0.9802, as shown in Figure12, indicating that the model explains 98.02% of the variance in the g-factor prediction given any structural parameters.This high level of accuracy enables reliable exploration of the parameter space without requiring computationally expensive DFT simulations for each parameter combination.→ insights with your own reasoning to direct the Hypothesis Agent → toward the most promising research paths.Planner Agent.The Planner Agent serves as the strategic nexus of the system.Its core function is to translate high-level insights from the PiFlow framework into actionable guidance for the Hypothesis Agent.To ensure its directives are logical and well-grounded, its behavior is constrained by a required structured output format, compelling it to synthesize historical data and articulate a clear, principle-driven research direction in each cycle.Experiment Agent (A E ).The Experiment Agent acts as a dedicated executor, whose role is strictly confined to validating the hypothesis h t proposed by A H .Following its operational directive, A E interfaces with the computational tool (f * (•)) to run the specified experiment and reports the quantitative outcome objectively.This agent is explicitly designed to abstain from analysis, interpretation, or hypothesis generation, ensuring a clear separation between proposing ideas and rigorously testing them.T.2 HYPOTHESIS AGENT
Microsoft Research AI4Science and Microsoft Quantum. The impact of large language models on scientific discovery: a preliminary study using gpt-4. ArXiv, abs/2311.073612023</p>
<p>Kevin Schawinski, and Ioana Ciucua. A survey on hypothesis generation for scientific discovery in the era of large language models. Shashwat Atilla Kaan Alkan, Maja Sourav, Simone Jabłońska, Rishabh Astarita, Nikhil Chakrabarty, Pranav Garuda, Maciej Khetarpal, Dimitrios Pi'oro, Tanoglidis, G Kartheik, Mugdha S Iyer, Michael J Polimera, Tirthankar Smith, Marc Ghosal, Sandor Huertas-Company, Kruk, 2025</p>
<p>dziner: Rational inverse design of materials with ai agents. Mehrad Ansari, Jeffrey Watchorn, Carla E Brown, Joseph S Brown, 2024</p>
<p>Claude 3.7 sonnet. Anthropic, 2025</p>
<p>Liddia: Language-based intelligent drug discovery agent. Reza Averly, Frazier N Baker, Xia Ning, ArXiv, abs/2502.139592025</p>
<p>Researchagent: Iterative research idea generation over scientific literature with large language models. Jinheon Baek, Sujay Kumar Jauhar, Silviu Cucerzan, Sung Ju Hwang, ArXiv, abs/2404.077382024. 2025Google DeepMind. Gemini 2.5 pro experimental</p>
<p>Feasible route to high-temperature ambient-pressure hydride superconductivity. Kapildeb Dolui, Lewis J Conway, Christoph Heil, Timothy A Strobel, Rohit P Prasankumar, Chris J Pickard, Physical review letters. 132161660012023</p>
<p>A systematic comparison of syllogistic reasoning in humans and language models. Tiwalayo Eisape, Mh Tessler, Ishita Dasgupta, Fei Sha, Sjoerd Van Steenkiste, Tal Linzen, ArXiv, abs/2311.004452023</p>
<p>Toward automated scientific discovery in hydrology: The opportunities and dangers of ai augmented research frameworks. Darri Eythorsson, Martyn Clark, Hydrological Processes. 2025</p>
<p>Atomagents: Alloy design and discovery through physics-aware multi-modal multi-agent artificial intelligence. Alireza Ghafarollahi, Markus J Buehler, ArXiv, abs/2407.100222024a</p>
<p>Protagents: protein discovery via large language model multi-agent collaborations combining physics and machine learning. Alireza Ghafarollahi, Markus J Buehler, Digital Discovery. 32024b</p>
<p>Rapid and automated alloy design with graph neural network-powered llm-driven multi-agent systems. Alireza Ghafarollahi, Markus J Buehler, ArXiv, abs/2410.137682024c</p>
<p>Sciagents: Automating scientific discovery through multi-agent intelligent graph reasoning. Alireza Ghafarollahi, Markus J Buehler, ArXiv, abs/2409.055562024d</p>
<p>Automating alloy design and discovery with physicsaware multimodal multiagent ai. Alireza Ghafarollahi, Markus J Buehler, 2025122e2414074122Proceedings of the National Academy of Sciences of the United States of America</p>
<p>Pathways to increase the dissymmetry in the interaction of chiral light and chiral molecules †. Jake L Greenfield, Jessica Wade, Jochen R Brandt, Xingyuan Shi, Thomas James Penfold, Matthew J Fuchter, Chemical Science. 122021</p>
<p>Agentic ai for scientific discovery: A survey of progress, challenges, and future directions. Mourad Gridach, Jay Nanavati, Khaldoun Zine El Abidine, Lenon Mendes, Christina Mack, arXiv:2503.089792025arXiv preprint</p>
<p>A data-driven statistical model for predicting the critical temperature of a superconductor. Kam Hamidieh, Computational Materials Science. 2018</p>
<p>From generalist to specialist: A survey of large language models for chemistry. Yang Han, Ziping Wan, Lu Chen, Kai Yu, Xin Chen, ArXiv, abs/2412.199942024</p>
<p>Reasoning with language model is planning with world model. Shibo Hao, Yi Gu, Haodi Ma, Joshua Jiahua Hong, Zhen Wang, Daisy Zhe Wang, Zhiting Hu, ArXiv, abs/2305.149922023</p>
<p>Llm-based multi-agent systems for software engineering: Vision and the road ahead. Junda He, Christoph Treude, David Lo, ArXiv, abs/2404.048342024</p>
<p>Drugagent: Explainable drug repurposing agent with large language model-based reasoning. Yoshitaka Inoue, Tianci Song, Tianfan Fu, ArXiv, abs/2408.133782024</p>
<p>Improving physics reasoning in large language models using mixture of refinement agents. Raj Jaiswal, Dhruv Jain, Harsh Popat, Avinash Anand, Abhishek Dharmadhikari, Atharva Marathe, Rajiv Ratn Shah, ArXiv, abs/2412.008212024</p>
<p>Machine learning boosts the design and discovery of nanomaterials. Yuying Jia, Xuan Hou, Zhongwei Wang, Xiangang Hu, ACS Sustainable Chemistry &amp; Engineering. 92021</p>
<p>Hypothesis generation for materials discovery and design using goal-driven and constraint-guided llm agents. Shrinidhi Kumbhar, Venkatesh Mishra, Kevin Coutinho, Divij Handa, Ashif Iquebal, Chitta Baral, ArXiv, abs/2501.132992025</p>
<p>Prim: Principle-inspired material discovery through multi-agent collaboration. Ryan Zheyuan, Lai , Yingming Pu, AI for Accelerated Materials Design -ICLR 2025. 2025</p>
<p>Beyond the hype: deep neural networks outperform established methods using a chembl bioactivity benchmark set. B Eelke, Lenselink, Brandon J Niels Ten Dijke, George Bongers, Papadatos, W T Herman, Wojtek Van Vlijmen, Adriaan P Kowalczyk, G V Ijzerman, Van Westen, Journal of Cheminformatics. 92017</p>
<p>Agent-oriented planning in multi-agent systems. Ao Li, Yuexiang Xie, Songze Li, Fugee Tsung, Bolin Ding, Yaliang Li, ArXiv, abs/2410.021892024</p>
<p>Theory of mind for multi-agent collaboration via large language models. Huao Li, Yu Quan Chong, Simon Stepputtis, Joseph Campbell, Dana Hughes, Michael Lewis, Katia P Sycara, Conference on Empirical Methods in Natural Language Processing. 2023</p>
<p>Drugagent: Automating ai-aided drug discovery programming through llm multi-agent collaboration. Sizhe Liu, Yizhou Lu, Siyu Chen, Xiyang Hu, Jieyu Zhao, Tianfan Fu, Yue Zhao, ArXiv, abs/2411.156922024</p>
<p>Reason for future, act for now: A principled framework for autonomous llm agents with provable sample efficiency. Zhihan Liu, Hao Hu, Shenao Zhang, Hongyi Guo, Shuqi Ke, Boyi Liu, Zhaoran Wang, ArXiv, abs/2309.173822023</p>
<p>The ai scientist: Towards fully automated open-ended scientific discovery. Chris Lu, Cong Lu, Robert Tjarko Lange, Jakob Nicolaus Foerster, Jeff Clune, David Ha, ArXiv, abs/2408.062922024</p>
<p>Llm4sr: A survey on large language models for scientific research. Ziming Luo, Zonglin Yang, Zexin Xu, Wei Yang, Xinya Du, 2025</p>
<p>Llm and simulation as bilevel optimizers: A new paradigm to advance physical scientific discovery. Pingchuan Ma, Tsun-Hsuan Wang, Minghao Guo, Zhiqing Sun, Joshua B Tenenbaum, Daniela Rus, Chuang Gan, Wojciech Matusik, ArXiv, abs/2405.097832024</p>
<p>Large-scale comparison of machine learning methods for drug target prediction on chembl. Andreas Mayr, Günter Klambauer, Thomas Unterthiner, Marvin N Steijaert, Kurt Jörg, Hugo Wegner, Djork-Arné Ceulemans, Sepp Clevert, Hochreiter, Chemical Science. 92018</p>
<p>Large language models: A survey. Shervin Minaee, Tom Mikolov, Narjes Nikzad, Asgari Meysam, Richard Chenaghlu, Xavier Socher, Jianfeng Amatriain, Gao, ArXiv, abs/2402.061962024</p>
<p>Runtime verification of self-adaptive multi-agent system using probabilistic timed automata. Yongan Mu, Wei Liu, Tao Lu, Juan Li, Sheng Gao, Zihao Wang, J. Intell. Fuzzy Syst. 452023</p>
<p>Ian: An intelligent system for omics data analysis and discovery. Guangpu Vijayaraj Nagarajan, Reiko Shi, Cheng-Rong Horai, Jaanam Yu, Manoj Gopalakrishnan, Yadav, H Michael, Calla Liew, Rachel R Gentilucci, Caspi, bioRxiv. 2025</p>
<p>Mechagents: Large language model multi-agent collaborations can solve mechanics problems, generate new data, and integrate knowledge. Bo Ni, Markus J Buehler, ArXiv, abs/2311.081662023. OpenAI. Gpt-4.1, 2025</p>
<p>Science and hypothesis. Henri Poincaré, 1906</p>
<p>Omniscience: A domain-specialized llm for scientific reasoning and discovery. Vignesh Prabhakar, Amirul Md, Adam Islam, Yao-Ting Atanas, Joah Wang, Aastha Han, Rucha Jhunjhunwala, Robert Apte, Kang Clark, Zihan Xu, Kai Wang, Liu, 2025</p>
<p>Leveraging large language models for explaining material synthesis mechanisms: The foundation of materials discovery. Yingming Pu, Liping Huang, Tao Lin, Hongyu Chen, In AI for Accelerated Materials Design -NeurIPS. 2024. November 2024</p>
<p>Accelerating scientific research through a multi-llm framework. Joaquin Ramirez-Medina, Mohammadmehdi Ataei, Alidad Amirfazli, 2025</p>
<p>A review of large language models and autonomous agents in chemistry. Caldas Mayk, Christopher J Ramos, Andrew D Collison, White, Chemical science. 2024</p>
<p>Towards scientific discovery with generative ai: Progress, opportunities, and challenges. K Chandan, Parshin Reddy, Shojaee, ArXiv, abs/2412.114272024</p>
<p>Towards scientific intelligence: A survey of llm-based scientific agents. Pu Shuo Ren, Zhenjiang Jian, Chunlin Ren, Can Leng, Jiajun Xie, Zhang, ArXiv, abs/2503.240472025</p>
<p>Samuel Schmidgall, Yusheng Su, Ze Wang, Ximeng Sun, Jialian Wu, Xiaodong Yu, Jiang Liu, Zicheng Liu, Emad Barsoum, ArXiv, abs/2501.04227Agent laboratory: Using llm agents as research assistants. 2025</p>
<p>Many heads are better than one: Improved scientific idea generation by a llm-based multi-agent system. Haoyang Su, Renqi Chen, Shixiang Tang, Zhenfei Yin, Xinzhe Zheng, Jinzhe Li, Biqing Qi, Qi Wu, Hui Li, Wanli Ouyang, Philip Torr, Bowen Zhou, Nanqing Dong, 2024</p>
<p>Accelerated inorganic materials design with generative ai agents. Izumi Takahara, Teruyasu Mizoguchi, Bang Liu, 2025</p>
<p>Multi-agent collaboration mechanisms: A survey of llms. Khanh-Tung Tran, Dung Dao, Minh-Duong Nguyen, Quoc-Viet Pham, O' Barry, Hoang D Sullivan, Nguyen, ArXiv, abs/2501.063222025</p>
<p>Applications of machine learning in drug discovery and development. Jessica Vamathevan, Dominic Clark, Paul Czodrowski, Ian Dunham, Edgardo Ferran, George Lee, Bin Li, Anant Madabhushi, K Parantu, Michaela Shah, Shanrong Spitzer, Zhao, Nature Reviews Drug Discovery. 182019</p>
<p>Deep learning approach for prediction of critical temperature of superconductor materials described by chemical formulas. Dmitry Viatkin, Begonya Garcia-Zapirain, Amaia Méndez-Zorrilla, Maxim A Zakharov, Frontiers in Materials. 2021</p>
<p>From tokens to materials: Leveraging language models for scientific discovery. Yuwei Wan, Tong Xie, Nan Wu, Wenjie Zhang, Chunyu Kit, Bram Hoex, ArXiv, abs/2410.161652024</p>
<p>Machine learned structure-property correlation between nanohelices and circular dichroism. Lei Wang, Chengbang Ma, Xueyang Feng, Zeyu Zhang, Jingsen Hao Ran Yang, Zhi-Yang Zhang, Jiakai Chen, Xu Tang, Yankai Chen, Wayne Xin Lin, Zhewei Zhao, Ji Wei, Wen Rong, Advanced Optical Materials. Juanshu Wu, Yingming Pu, Jin Wang, Bing Gu, Xin Chen, and Hongyu Chen181863452023. 2025Frontiers Comput. Sci.</p>
<p>Cellagent: An llm-driven multi-agent framework for automated single-cell data analysis. Yihang Xiao, Jinyi Liu, Yan Zheng, Xiaohan Xie, Jianye Hao, Mingzhi Li, Ruitao Wang, Fei Ni, Yuxiao Li, Jintian Luo, Shaoqing Jiao, Jiajie Peng, bioRxiv. 2024</p>
<p>Imran Razzak, and Bram Hoex. Darwin series: Domain specific large language models for natural science. Tong Xie, Yuwei Wan, Wei Huang, Zhenyu Yin, Yixuan Liu, Shaozhou Wang, Qingyuan Linghu, Chunyu Kit, Clara Grazian, Wenjie Zhang, ArXiv, abs/2308.135652023a</p>
<p>Xin Chen, and Gang Zou. Inverse design of chiral functional films by a robotic ai-guided system. Yifan Xie, Shuo Feng, Linxiao Deng, Aoran Cai, Liyu Gan, Zifan Jiang, Peng Yang, Guilin Ye, Zaiqing Liu, Li Wen, Qing Zhu, Wanjun Zhang, Zhanpeng Zhang, Jiahe Li, Zeyu Feng, Chutian Zhang, Wenjie Du, Lixin Xu, Jun Jiang, Nature Communications. 142023b</p>
<p>Mpo: Boosting llm agents with meta plan optimization. Weimin Xiong, Yifan Song, Qingxiu Dong, Bingchan Zhao, Feifan Song, Xun Wang, Sujian Li, ArXiv, abs/2503.026822025</p>
<p>Magic: Investigation of large language model powered multi-agent in cognition, adaptability, rationality and collaboration. Lin Xu, Zhiyuan Hu, Daquan Zhou, Hongyu Ren, Zhen Dong, Kurt Keutzer, See-Kiong Ng, Jiashi Feng, Conference on Empirical Methods in Natural Language Processing. 2023</p>
<p>An Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Zhou, Chengpeng Li, Chengyuan Li, Dayiheng Liu, Fei Huang, Guanting Dong, Haoran Wei, Huan Lin, Jialong Tang, Jialin Wang, Jian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Ma, Jin Xu, Jingren Zhou, Jinze Bai, Jinzheng He, Junyang Lin, Kai Dang, Keming Lu, Ke-Yang Chen, Kexin Yang, Mei Li, Min Xue, Na Ni, Pei Zhang, Peng Wang, Ru Peng, Rui Men, Ruize Gao, Runji Lin, Shijie Wang, Shuai Bai, Sinan Tan, Tianhang Zhu, Tianhao Li, Tianyu Liu, Wenbin Ge, Xiaodong Deng, Xiaohuan Zhou, Xingzhang Ren, Xinyu Zhang, Xipin Wei ; Zhang, Yunyang Wan, Yunfei Chu, Zeyu Cui, Zhenru Zhang, Zhi-Wei Fan, ArXiv, abs/2407.10671Qwen2 technical report. Xuancheng Ren, Yang Fan, Yang Yao, Yichang2024a</p>
<p>. An Yang, arXiv:2412.151152024b5 technical report. arXiv preprint</p>
<p>Moose-chem: Large language models for rediscovering unseen chemistry scientific hypotheses. Zonglin Yang, Wanhao Liu, Ben Gao, Tong Xie, Yuqiang Li, Wanli Ouyang, Soujanya Poria, Erik Cambria, Dongzhan Zhou, ArXiv, abs/2410.070762024c</p>
<p>React: Synergizing reasoning and acting in language models. Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, Yuan Cao, ArXiv, abs/2210.036292022</p>
<p>Chemtoolagent: The impact of tools on language agents for chemistry problem solving. Botao Yu, Frazier N Baker, Ziru Chen, Garrett Herb, Boyu Gou, Daniel Adu-Ampratwum, Xia Ning, Huan Sun, 2024</p>
<p>The chembl database in 2023: a drug discovery platform spanning multiple bioactivity data types and time periods. Barbara Zdrazil, Eloy Felix, Fiona Hunter, Emma J Manners, James Blackshaw, Sybilla Corbett, Marleen De Veij, Harris Ioannidis, David Mendez Lopez, Juan Fernando Mejía, María P Mosquera, Nicolas Magariños, Ricardo Bosc, Tevfik Arcila, Anna Kizilören, A Patrícia Gaulton, Melissa F Bento, Peter Adasme, Gregory A Monecke, Andrew R Landrum, Leach, Nucleic Acids Research. 522023</p>
<p>Honeycomb: A flexible llm-based agent system for materials science. Huan Zhang, Yu Song, Ziyu Hou, Santiago Miret, Bang Liu, Conference on Empirical Methods in Natural Language Processing. 2024a</p>
<p>Exploring collaboration mechanisms for llm agents: A social psychology view. Jintian Zhang, Xin Xu, Ruibo Liu, Shumin Deng, ArXiv, abs/2310.021242023a</p>
<p>How language model hallucinations can snowball. Muru Zhang, Ofir Press, William Merrill, Alisa Liu, Noah A Smith, ArXiv, abs/2305.135342023b</p>
<p>Large language model-based ai agent for organic semiconductor devices research. Qian Zhang, Yongxu Hu, Jiaxin Yan, Hengyue Zhang, Xinyi Xie, Jie Zhu, Huchao Li, Xinxin Niu, Liqiang Li, Yajing Sun, Wenping Hu, Advanced materials. e24051632024b</p>
<p>Scientific large language models: A survey on biological &amp; chemical domains. Qiang Zhang, Keyan Ding, Tianwen Lv, Xinda Wang, Qingyu Yin, Yiwen Zhang, Jing Yu, Yuhao Wang, Xiaotong Li, Zhuoyi Xiang, Zhuang Xiang, Zeyuan Wang, Ming Qin, Mengyao Zhang, Jinlu Zhang, Jiyu Cui, Renjun Xu, Hongyang Chen, Xiaohui Fan, Huabin Xing, Huajun Chen, 2025ACM Computing Surveys</p>
<p>A comprehensive survey of scientific large language models and their applications in scientific discovery. Yu Zhang, Xiusi Chen, Bowen Jin, Sheng Wang, Shuiwang Ji, Wei Wang, Jiawei Han, Conference on Empirical Methods in Natural Language Processing. 2024c</p>
<p>Tao Guo, and Alan Aspuru-Guzik. Deep learning enables rapid identification of potent ddr1 kinase inhibitors. Alex Zhavoronkov, Yan A Ivanenkov, Alexander Aliper, Mark Veselov, Vladimir Aladinskiy, Anastasiya V Aladinskaya, Daniil A Victor A Terentiev, Maksim Polykovskiy, Arip Kuznetsov, Yury Asadulaev, Artem Volkov, Shayakhmetov Zholus, Alexander Rim, Zhebrak, Bogdan Lidiya I Minaeva, Zagribelnyy, H Lennart, Richard M Lee, David Soll, Li Madge, Xing, Nature Biotechnology. 372019</p>
<p>Hypothesis generation with large language models. Yangqiaoyu Zhou, Haokun Liu, Tejes Srivastava, Hongyuan Mei, Chenhao Tan, ArXiv, abs/2404.043262024</p>
<p>A pharmacophore-guided deep learning approach for bioactive molecular generation. Hui Zhu, Renyi Zhou, Dongsheng Cao, Jing Tang, Min Li, Nature Communications. 142023</p>            </div>
        </div>

    </div>
</body>
</html>