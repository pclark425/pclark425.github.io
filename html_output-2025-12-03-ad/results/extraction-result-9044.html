<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-9044 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-9044</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-9044</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-159.html">extraction-schema-159</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being evaluated on cognitive psychology tests, including details of the models, the tests, LLM performance, human baseline performance, and any comparisons or notable findings.</div>
                <p><strong>Paper ID:</strong> paper-264288945</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2310.11616v3.pdf" target="_blank">Evidence of interrelated cognitive-like capabilities in large language models: Indications of artificial general intelligence or achievement?</a></p>
                <p><strong>Paper Abstract:</strong> Large language models (LLMs) are advanced artificial intelligence (AI) systems that can perform a variety of tasks commonly found in human intelligence tests, such as defining words, performing calculations, and engaging in verbal reasoning. There are also substantial individual differences in LLM capacities. Given the consistent observation of a positive manifold and general intelligence factor in human samples, along with group-level factors (e.g., crystallized intelligence), we hypothesized that LLM test scores may also exhibit positive intercorrelations, which could potentially give rise to an artificial general ability (AGA) factor and one or more group-level factors. Based on a sample of 591 LLMs and scores from 12 tests aligned with fluid reasoning (Gf), domain-specific knowledge (Gkn), reading/writing (Grw), and quantitative knowledge (Gq), we found strong empirical evidence for a positive manifold and a general factor of ability. Additionally, we identified a combined Gkn/Grw group-level factor. Finally, the number of LLM parameters correlated positively with both general factor of ability and Gkn/Grw factor scores, although the effects showed diminishing returns. We interpreted our results to suggest that LLMs, like human cognitive abilities, may share a common underlying efficiency in processing information and solving problems, though whether LLMs manifest primarily achievement/expertise rather than intelligence remains to be determined. Finally, while models with greater numbers of parameters exhibit greater general cognitive-like abilities, akin to the connection between greater neuronal density and human general intelligence, other characteristics must also be involved.</p>
                <p><strong>Cost:</strong> 0.021</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e9044.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e9044.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being evaluated on cognitive psychology tests, including details of the models, the tests, LLM performance, human baseline performance, and any comparisons or notable findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Ilić & Gignac LLM 12-test battery (591 models)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Evaluation of 591 LLMs on a 12-test cognitive-like benchmark battery (Ilić & Gignac 2024)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Large-scale empirical evaluation of 591 distinct LLM instances (curated from Hugging Face) on 12 benchmark tests mapped to CHC-like cognitive domains (Gf, Gkn, Grw, Gq); analysis focused on inter-test correlations, latent structure (bifactor), and associations with model parameter counts.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>591 LLMs (Hugging Face sample; diverse families incl. Mistral, LLaMA, GPT, Claude, and many third-party models)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>A heterogeneous corpus of publicly available LLMs downloaded from Hugging Face (snapshot 2024-03-08); models varied in architecture, pretraining/fine-tuning, and parameter counts; the authors curated the sample via DBSCAN clustering and Levenshtein-name deduplication to produce a conservative set of distinct models.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>Varied across models; parameter metadata available for 579 models (after removing two extreme outliers): mean ≈ 14.19 billion parameters (SD = 18.87B), median = 7.24B; two outliers at ~180B and ~238B were excluded from some analyses.</td>
                        </tr>
                        <tr>
                            <td><strong>test_battery_name</strong></td>
                            <td>12-test battery (mixture of Hellaswag, GSM8K subset, MMLU subtests/composites including Elementary Mathematics, High School history tests, Winogrande, and several MMLU domain subtests)</td>
                        </tr>
                        <tr>
                            <td><strong>test_description</strong></td>
                            <td>Tests were selected and mapped to four CHC-aligned domains: fluid reasoning (Gf; e.g., Hellaswag, GSM8K quantitative reasoning items), domain-specific knowledge (Gkn; MMLU domain subtests), reading/writing (Grw; history tests, Winogrande), and quantitative knowledge (Gq; MMLU math/statistics composites). Items were mostly multiple-choice (except GSM8K open-ended) and scored as percent correct.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_performance</strong></td>
                            <td>Across the 12 tests the mean percent-correct (across LLMs) ranged from 18.09% to 74.27% with an overall mean = 48.62% (SD across tests = 20.02). Mean inter-test correlation = 0.73. Latent bifactor analysis produced a dominant general factor (AGA) accounting for ≈ 65.6% of variance; mean general-factor loading = 0.81; omega hierarchical = 0.94.</td>
                        </tr>
                        <tr>
                            <td><strong>human_baseline_performance</strong></td>
                            <td>No direct human normative performance on the exact same battery reported. Authors compare to typical psychometric human benchmarks: mean inter-test correlations in humans ≈ 0.45–0.50 and human g typically accounts for ≈ 40–50% of variance.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>LLMs in this sample exhibited a substantially stronger positive manifold than typically reported in humans (mean inter-test r = 0.73 vs human ≈ 0.45–0.50) and a larger general factor (≈ 66% variance vs human ≈ 40–50%), though absolute accuracy varied by test (mean ≈ 48.6%). Authors caution that stronger LLM g may reflect test/content homogeneity and high test reliability rather than human-like general intelligence.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_details</strong></td>
                            <td>Data downloaded from Hugging Face (2024-03-08); initial 3862 models pruned using DBSCAN (eps=0.33,min_samples=2) and name-similarity/Levenshtein deduplication to final n=591; 12 tests drawn primarily from MMLU, Hellaswag, GSM8K, Winogrande; scores computed as percent correct; factor analyses (EFA, CFA, bifactor) run in lavaan (ML estimation); LOESS and spline models used to characterize parameter-count relationships; 5000 bootstrap resamples for CIs.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_caveats</strong></td>
                            <td>Battery lacked several CHC domains (no visual/spatial Gv, no short-term memory Gsm, no processing speed Gs). Tests are primarily verbal/textual (possible training-data overlap / contamination). Extremely high item counts and very high internal reliabilities (median α ≈ 0.97) can inflate inter-test correlations. Potential non-independence among models (clones, fine-tunes) may remain despite deduplication. No consistent data on training tokens, hyperparameters, or fine-tuning for most models, limiting causal inferences. Authors emphasize possibility that results reflect 'artificial achievement' (expertise/knowledge) rather than true AGI.</td>
                        </tr>
                        <tr>
                            <td><strong>notes</strong></td>
                            <td>Parameter–AGA association: Pearson r ≈ 0.54 (95% CI [0.48,0.59]); Spearman r ≈ 0.62. Relationship nonlinear: steep gains 0.1B–10B params, plateau 10–20B, gradual gains up to ~80B.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Evidence of interrelated cognitive-like capabilities in large language models: Indications of artificial general intelligence or achievement?', 'publication_date_yy_mm': '2023-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9044.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e9044.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being evaluated on cognitive psychology tests, including details of the models, the tests, LLM performance, human baseline performance, and any comparisons or notable findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>HellaSwag</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>HellaSwag benchmark</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A large multiple-choice benchmark (≈10,042 items in this study) testing commonsense reasoning and next-event prediction from natural language contexts; used here as a Gf (fluid reasoning) indicator.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Evidence of interrelated cognitive-like capabilities in large language models: Indications of artificial general intelligence or achievement?</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>591 LLMs (Hugging Face sample)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Evaluated as one indicator/test in the 12-test battery; HellaSwag items require choosing the most plausible continuation from four options.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>Varied across evaluated models</td>
                        </tr>
                        <tr>
                            <td><strong>test_battery_name</strong></td>
                            <td>HellaSwag</td>
                        </tr>
                        <tr>
                            <td><strong>test_description</strong></td>
                            <td>Natural-language commonsense reasoning; multi-choice (4 alternatives); theorized by authors to index fluid reasoning (Gf) in textual form.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_performance</strong></td>
                            <td>Included among the study's per-test results; the paper reports the per-test means range (all 12 tests) as 18.09–74.27% correct and identifies HellaSwag as one of the tests with high mean performance and high negative skew (HellaSwag skewness = −1.04). Exact per-test mean reported in table (within that range) but not re-stated in main text beyond range.</td>
                        </tr>
                        <tr>
                            <td><strong>human_baseline_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>LLMs performed relatively well on HellaSwag (high mean within the battery) and HellaSwag correlated strongly with other verbal benchmarks, contributing to the high positive manifold observed.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_details</strong></td>
                            <td>10,042 items used; multiple-choice four-option format; scored percent-correct; included as a Gf indicator despite being verbal in nature.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_caveats</strong></td>
                            <td>As a large textual benchmark it may be susceptible to training-data leakage; high reliability and large item count may amplify correlations with other tests.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Evidence of interrelated cognitive-like capabilities in large language models: Indications of artificial general intelligence or achievement?', 'publication_date_yy_mm': '2023-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9044.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e9044.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being evaluated on cognitive psychology tests, including details of the models, the tests, LLM performance, human baseline performance, and any comparisons or notable findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GSM8K (subset)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Grade School Math 8K (GSM8K) subset</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A dataset of multi-step grade-school math word problems used here (authors selected 1,319 items) to probe quantitative/quantitative-reasoning aspects of fluid reasoning (Gf).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Evidence of interrelated cognitive-like capabilities in large language models: Indications of artificial general intelligence or achievement?</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>591 LLMs (Hugging Face sample)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>GSM8K subset (1,319 items) presented as open-ended arithmetic/math-reasoning problems; evaluated across the model sample.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>Varied across evaluated models</td>
                        </tr>
                        <tr>
                            <td><strong>test_battery_name</strong></td>
                            <td>GSM8K (selected 1,319 items)</td>
                        </tr>
                        <tr>
                            <td><strong>test_description</strong></td>
                            <td>Multi-step arithmetic and quantitative reasoning in natural language; open-ended answer format requiring numerical output.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_performance</strong></td>
                            <td>Per-test mean not explicitly given in the main text (the full battery per-test means fall in range 18.09–74.27%); authors note LLMs commonly struggle with arithmetic and multi-step reasoning, and GSM8K items were included as quantitative-reasoning indicators.</td>
                        </tr>
                        <tr>
                            <td><strong>human_baseline_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>Authors report that arithmetic/math problems remain a challenge for many LLMs (citing other studies); nevertheless, a math composite (KM) had the largest loading on the general factor in their analysis, suggesting arithmetic-related tasks were strong indicators of AGA.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_details</strong></td>
                            <td>Subset of GSM8K chosen to reflect quantitative reasoning; response format open-ended; scoring converted to percent-correct for analyses.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_caveats</strong></td>
                            <td>LLMs' known difficulties with precise symbolic manipulation, multi-step error propagation, and noisy training signals make direct comparisons to humans problematic; no human performance on the same subset is reported.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Evidence of interrelated cognitive-like capabilities in large language models: Indications of artificial general intelligence or achievement?', 'publication_date_yy_mm': '2023-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9044.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e9044.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being evaluated on cognitive psychology tests, including details of the models, the tests, LLM performance, human baseline performance, and any comparisons or notable findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MMLU composites</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Massive Multitask Language Understanding (MMLU) subtests / composites</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Selected MMLU subtests were combined into composites to index domain-specific knowledge (Gkn), quantitative knowledge (Gq), and reading/writing (Grw); used extensively in the 12-test battery.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Evidence of interrelated cognitive-like capabilities in large language models: Indications of artificial general intelligence or achievement?</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>591 LLMs (Hugging Face sample)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>MMLU-based composites used: e.g., Gkn composites from International Law, Business Ethics, Philosophy, Medical Genetics, Clinical Knowledge, Human Aging, Global Facts, Computer Security, Marketing, Miscellaneous; Gq composites from High School Statistics, Abstract Algebra, Econometrics, Elementary Mathematics items.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>Varied across evaluated models</td>
                        </tr>
                        <tr>
                            <td><strong>test_battery_name</strong></td>
                            <td>MMLU subtests / composites</td>
                        </tr>
                        <tr>
                            <td><strong>test_description</strong></td>
                            <td>Multiple-choice subject-matter tests designed to assess domain knowledge and academic/technical knowledge across many disciplines; mapped by authors to CHC stratum II domains.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_performance</strong></td>
                            <td>Authors report that Gkn composites had very high inter-correlations (r = 0.98–0.99) and high reliabilities (composite αs typically ≈ 0.97). Exact composite means are presented in Table 2 of the paper (within the overall reported range 18.09–74.27%).</td>
                        </tr>
                        <tr>
                            <td><strong>human_baseline_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>Gkn and Grw tests formed a combined group-level factor (Gkn/Grw) separate from AGA; mathematical composite (KM) loaded most strongly on AGA. The Gkn composites' extremely high inter-correlations suggest tight coupling between domain-knowledge items for LLMs.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_details</strong></td>
                            <td>MMLU items accessed from Hugging Face dataset; composites built according to authors' grouping; item-level omissions applied when items failed positive item-total correlations (per supplement).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_caveats</strong></td>
                            <td>High inter-correlation among Gkn subtests may reflect item/content overlap and shared training exposure; lack of human normative data on the same items; possible contamination from training data.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Evidence of interrelated cognitive-like capabilities in large language models: Indications of artificial general intelligence or achievement?', 'publication_date_yy_mm': '2023-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9044.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e9044.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being evaluated on cognitive psychology tests, including details of the models, the tests, LLM performance, human baseline performance, and any comparisons or notable findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Winogrande</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Winogrande benchmark</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A large Winograd Schema-style dataset (binary-choice pronoun resolution) used as a reading/writing (Grw) test; requires contextual language understanding to select the correct referent.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Evidence of interrelated cognitive-like capabilities in large language models: Indications of artificial general intelligence or achievement?</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>591 LLMs (Hugging Face sample)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Evaluated as a Grw indicator; authors report strong association with HellaSwag (r = 0.95) indicating high overlap with other verbal reasoning benchmarks.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>Varied across evaluated models</td>
                        </tr>
                        <tr>
                            <td><strong>test_battery_name</strong></td>
                            <td>Winogrande</td>
                        </tr>
                        <tr>
                            <td><strong>test_description</strong></td>
                            <td>Binary multiple-choice pronoun-disambiguation items requiring contextual reasoning; used to assess language comprehension and pragmatic inference.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_performance</strong></td>
                            <td>Per-test mean not re-stated in main text beyond being within the overall battery range; Winogrande had very high correlation with Hellaswag (r = 0.95), suggesting similar performance profiles across LLMs.</td>
                        </tr>
                        <tr>
                            <td><strong>human_baseline_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>Closely aligned with other verbal benchmarks; contributed to the combined Gkn/Grw group factor.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_details</strong></td>
                            <td>Authors included Winogrande items (paper's Table 1 lists Winogrande with 12,670 items); scored percent-correct.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_caveats</strong></td>
                            <td>Dataset-level overlap with LLM training corpora and overlap with other verbal/conceptual tasks may inflate correlations and not reflect independent capacities.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Evidence of interrelated cognitive-like capabilities in large language models: Indications of artificial general intelligence or achievement?', 'publication_date_yy_mm': '2023-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9044.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e9044.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being evaluated on cognitive psychology tests, including details of the models, the tests, LLM performance, human baseline performance, and any comparisons or notable findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Example model mentions (RoBERTa-large, GPT-2-x1, Mistral 7B, PaLM 2 sizes)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Specific LLM examples cited in background/discussion</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The paper cites several known LLMs and parameter-count examples (as background), but these exemplars were not singled out with per-model results in the reported analyses.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Evidence of interrelated cognitive-like capabilities in large language models: Indications of artificial general intelligence or achievement?</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>RoBERTa-large; GPT-2-x1; Mistral 7B; PaLM 2 (various sizes)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>RoBERTa-large referenced as 355M-parameter model; GPT-2-x1 referenced at 1.56B; Mistral 7B referenced at 7.3B; PaLM 2 mentioned in context of parameter-scaling experiments (Anil et al., 2023) with reported sizes 3.86B, 7.05B, 9.50B, 16.1B in the cited work.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>RoBERTa-large: 355M; GPT-2-x1: 1.56B; Mistral 7B: 7.3B; PaLM 2 experimental sizes cited in literature (3.86B–16.1B).</td>
                        </tr>
                        <tr>
                            <td><strong>test_battery_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>test_description</strong></td>
                            <td>These are background examples to illustrate the variety of model scales and families; the paper did not report per-model test scores for these individual models within the main aggregated results.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>human_baseline_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>experimental_details</strong></td>
                            <td>Mentioned in introduction/discussion as illustrative examples of model scale and families; PaLM 2 parameter variations cited from Anil et al. (2023) as prior evidence that larger parameter counts can improve performance in some tests.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_caveats</strong></td>
                            <td>These are illustrative mentions; the present paper's main analyses aggregate many models and do not provide detailed per-model performance for each of these named models (unless they are among the 591 and identified in supplemental files).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Evidence of interrelated cognitive-like capabilities in large language models: Indications of artificial general intelligence or achievement?', 'publication_date_yy_mm': '2023-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Measuring Massive Multitask Language Understanding <em>(Rating: 2)</em></li>
                <li>HellaSwag: Can a machine really finish your sentence? <em>(Rating: 2)</em></li>
                <li>Training verifiers to solve math word problems (GSM8K) <em>(Rating: 2)</em></li>
                <li>Winogrande: An adversarial Winograd Schema challenge at scale <em>(Rating: 2)</em></li>
                <li>PaLM 2 technical report <em>(Rating: 2)</em></li>
                <li>Training compute-optimal large language models <em>(Rating: 2)</em></li>
                <li>Can large language models put 2 and 2 together? Probing for entailed arithmetical relationships <em>(Rating: 1)</em></li>
                <li>How well do large language models perform in arithmetic tasks? <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-9044",
    "paper_id": "paper-264288945",
    "extraction_schema_id": "extraction-schema-159",
    "extracted_data": [
        {
            "name_short": "Ilić & Gignac LLM 12-test battery (591 models)",
            "name_full": "Evaluation of 591 LLMs on a 12-test cognitive-like benchmark battery (Ilić & Gignac 2024)",
            "brief_description": "Large-scale empirical evaluation of 591 distinct LLM instances (curated from Hugging Face) on 12 benchmark tests mapped to CHC-like cognitive domains (Gf, Gkn, Grw, Gq); analysis focused on inter-test correlations, latent structure (bifactor), and associations with model parameter counts.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "591 LLMs (Hugging Face sample; diverse families incl. Mistral, LLaMA, GPT, Claude, and many third-party models)",
            "model_description": "A heterogeneous corpus of publicly available LLMs downloaded from Hugging Face (snapshot 2024-03-08); models varied in architecture, pretraining/fine-tuning, and parameter counts; the authors curated the sample via DBSCAN clustering and Levenshtein-name deduplication to produce a conservative set of distinct models.",
            "model_size": "Varied across models; parameter metadata available for 579 models (after removing two extreme outliers): mean ≈ 14.19 billion parameters (SD = 18.87B), median = 7.24B; two outliers at ~180B and ~238B were excluded from some analyses.",
            "test_battery_name": "12-test battery (mixture of Hellaswag, GSM8K subset, MMLU subtests/composites including Elementary Mathematics, High School history tests, Winogrande, and several MMLU domain subtests)",
            "test_description": "Tests were selected and mapped to four CHC-aligned domains: fluid reasoning (Gf; e.g., Hellaswag, GSM8K quantitative reasoning items), domain-specific knowledge (Gkn; MMLU domain subtests), reading/writing (Grw; history tests, Winogrande), and quantitative knowledge (Gq; MMLU math/statistics composites). Items were mostly multiple-choice (except GSM8K open-ended) and scored as percent correct.",
            "llm_performance": "Across the 12 tests the mean percent-correct (across LLMs) ranged from 18.09% to 74.27% with an overall mean = 48.62% (SD across tests = 20.02). Mean inter-test correlation = 0.73. Latent bifactor analysis produced a dominant general factor (AGA) accounting for ≈ 65.6% of variance; mean general-factor loading = 0.81; omega hierarchical = 0.94.",
            "human_baseline_performance": "No direct human normative performance on the exact same battery reported. Authors compare to typical psychometric human benchmarks: mean inter-test correlations in humans ≈ 0.45–0.50 and human g typically accounts for ≈ 40–50% of variance.",
            "performance_comparison": "LLMs in this sample exhibited a substantially stronger positive manifold than typically reported in humans (mean inter-test r = 0.73 vs human ≈ 0.45–0.50) and a larger general factor (≈ 66% variance vs human ≈ 40–50%), though absolute accuracy varied by test (mean ≈ 48.6%). Authors caution that stronger LLM g may reflect test/content homogeneity and high test reliability rather than human-like general intelligence.",
            "experimental_details": "Data downloaded from Hugging Face (2024-03-08); initial 3862 models pruned using DBSCAN (eps=0.33,min_samples=2) and name-similarity/Levenshtein deduplication to final n=591; 12 tests drawn primarily from MMLU, Hellaswag, GSM8K, Winogrande; scores computed as percent correct; factor analyses (EFA, CFA, bifactor) run in lavaan (ML estimation); LOESS and spline models used to characterize parameter-count relationships; 5000 bootstrap resamples for CIs.",
            "limitations_or_caveats": "Battery lacked several CHC domains (no visual/spatial Gv, no short-term memory Gsm, no processing speed Gs). Tests are primarily verbal/textual (possible training-data overlap / contamination). Extremely high item counts and very high internal reliabilities (median α ≈ 0.97) can inflate inter-test correlations. Potential non-independence among models (clones, fine-tunes) may remain despite deduplication. No consistent data on training tokens, hyperparameters, or fine-tuning for most models, limiting causal inferences. Authors emphasize possibility that results reflect 'artificial achievement' (expertise/knowledge) rather than true AGI.",
            "notes": "Parameter–AGA association: Pearson r ≈ 0.54 (95% CI [0.48,0.59]); Spearman r ≈ 0.62. Relationship nonlinear: steep gains 0.1B–10B params, plateau 10–20B, gradual gains up to ~80B.",
            "uuid": "e9044.0",
            "source_info": {
                "paper_title": "Evidence of interrelated cognitive-like capabilities in large language models: Indications of artificial general intelligence or achievement?",
                "publication_date_yy_mm": "2023-10"
            }
        },
        {
            "name_short": "HellaSwag",
            "name_full": "HellaSwag benchmark",
            "brief_description": "A large multiple-choice benchmark (≈10,042 items in this study) testing commonsense reasoning and next-event prediction from natural language contexts; used here as a Gf (fluid reasoning) indicator.",
            "citation_title": "Evidence of interrelated cognitive-like capabilities in large language models: Indications of artificial general intelligence or achievement?",
            "mention_or_use": "use",
            "model_name": "591 LLMs (Hugging Face sample)",
            "model_description": "Evaluated as one indicator/test in the 12-test battery; HellaSwag items require choosing the most plausible continuation from four options.",
            "model_size": "Varied across evaluated models",
            "test_battery_name": "HellaSwag",
            "test_description": "Natural-language commonsense reasoning; multi-choice (4 alternatives); theorized by authors to index fluid reasoning (Gf) in textual form.",
            "llm_performance": "Included among the study's per-test results; the paper reports the per-test means range (all 12 tests) as 18.09–74.27% correct and identifies HellaSwag as one of the tests with high mean performance and high negative skew (HellaSwag skewness = −1.04). Exact per-test mean reported in table (within that range) but not re-stated in main text beyond range.",
            "human_baseline_performance": null,
            "performance_comparison": "LLMs performed relatively well on HellaSwag (high mean within the battery) and HellaSwag correlated strongly with other verbal benchmarks, contributing to the high positive manifold observed.",
            "experimental_details": "10,042 items used; multiple-choice four-option format; scored percent-correct; included as a Gf indicator despite being verbal in nature.",
            "limitations_or_caveats": "As a large textual benchmark it may be susceptible to training-data leakage; high reliability and large item count may amplify correlations with other tests.",
            "uuid": "e9044.1",
            "source_info": {
                "paper_title": "Evidence of interrelated cognitive-like capabilities in large language models: Indications of artificial general intelligence or achievement?",
                "publication_date_yy_mm": "2023-10"
            }
        },
        {
            "name_short": "GSM8K (subset)",
            "name_full": "Grade School Math 8K (GSM8K) subset",
            "brief_description": "A dataset of multi-step grade-school math word problems used here (authors selected 1,319 items) to probe quantitative/quantitative-reasoning aspects of fluid reasoning (Gf).",
            "citation_title": "Evidence of interrelated cognitive-like capabilities in large language models: Indications of artificial general intelligence or achievement?",
            "mention_or_use": "use",
            "model_name": "591 LLMs (Hugging Face sample)",
            "model_description": "GSM8K subset (1,319 items) presented as open-ended arithmetic/math-reasoning problems; evaluated across the model sample.",
            "model_size": "Varied across evaluated models",
            "test_battery_name": "GSM8K (selected 1,319 items)",
            "test_description": "Multi-step arithmetic and quantitative reasoning in natural language; open-ended answer format requiring numerical output.",
            "llm_performance": "Per-test mean not explicitly given in the main text (the full battery per-test means fall in range 18.09–74.27%); authors note LLMs commonly struggle with arithmetic and multi-step reasoning, and GSM8K items were included as quantitative-reasoning indicators.",
            "human_baseline_performance": null,
            "performance_comparison": "Authors report that arithmetic/math problems remain a challenge for many LLMs (citing other studies); nevertheless, a math composite (KM) had the largest loading on the general factor in their analysis, suggesting arithmetic-related tasks were strong indicators of AGA.",
            "experimental_details": "Subset of GSM8K chosen to reflect quantitative reasoning; response format open-ended; scoring converted to percent-correct for analyses.",
            "limitations_or_caveats": "LLMs' known difficulties with precise symbolic manipulation, multi-step error propagation, and noisy training signals make direct comparisons to humans problematic; no human performance on the same subset is reported.",
            "uuid": "e9044.2",
            "source_info": {
                "paper_title": "Evidence of interrelated cognitive-like capabilities in large language models: Indications of artificial general intelligence or achievement?",
                "publication_date_yy_mm": "2023-10"
            }
        },
        {
            "name_short": "MMLU composites",
            "name_full": "Massive Multitask Language Understanding (MMLU) subtests / composites",
            "brief_description": "Selected MMLU subtests were combined into composites to index domain-specific knowledge (Gkn), quantitative knowledge (Gq), and reading/writing (Grw); used extensively in the 12-test battery.",
            "citation_title": "Evidence of interrelated cognitive-like capabilities in large language models: Indications of artificial general intelligence or achievement?",
            "mention_or_use": "use",
            "model_name": "591 LLMs (Hugging Face sample)",
            "model_description": "MMLU-based composites used: e.g., Gkn composites from International Law, Business Ethics, Philosophy, Medical Genetics, Clinical Knowledge, Human Aging, Global Facts, Computer Security, Marketing, Miscellaneous; Gq composites from High School Statistics, Abstract Algebra, Econometrics, Elementary Mathematics items.",
            "model_size": "Varied across evaluated models",
            "test_battery_name": "MMLU subtests / composites",
            "test_description": "Multiple-choice subject-matter tests designed to assess domain knowledge and academic/technical knowledge across many disciplines; mapped by authors to CHC stratum II domains.",
            "llm_performance": "Authors report that Gkn composites had very high inter-correlations (r = 0.98–0.99) and high reliabilities (composite αs typically ≈ 0.97). Exact composite means are presented in Table 2 of the paper (within the overall reported range 18.09–74.27%).",
            "human_baseline_performance": null,
            "performance_comparison": "Gkn and Grw tests formed a combined group-level factor (Gkn/Grw) separate from AGA; mathematical composite (KM) loaded most strongly on AGA. The Gkn composites' extremely high inter-correlations suggest tight coupling between domain-knowledge items for LLMs.",
            "experimental_details": "MMLU items accessed from Hugging Face dataset; composites built according to authors' grouping; item-level omissions applied when items failed positive item-total correlations (per supplement).",
            "limitations_or_caveats": "High inter-correlation among Gkn subtests may reflect item/content overlap and shared training exposure; lack of human normative data on the same items; possible contamination from training data.",
            "uuid": "e9044.3",
            "source_info": {
                "paper_title": "Evidence of interrelated cognitive-like capabilities in large language models: Indications of artificial general intelligence or achievement?",
                "publication_date_yy_mm": "2023-10"
            }
        },
        {
            "name_short": "Winogrande",
            "name_full": "Winogrande benchmark",
            "brief_description": "A large Winograd Schema-style dataset (binary-choice pronoun resolution) used as a reading/writing (Grw) test; requires contextual language understanding to select the correct referent.",
            "citation_title": "Evidence of interrelated cognitive-like capabilities in large language models: Indications of artificial general intelligence or achievement?",
            "mention_or_use": "use",
            "model_name": "591 LLMs (Hugging Face sample)",
            "model_description": "Evaluated as a Grw indicator; authors report strong association with HellaSwag (r = 0.95) indicating high overlap with other verbal reasoning benchmarks.",
            "model_size": "Varied across evaluated models",
            "test_battery_name": "Winogrande",
            "test_description": "Binary multiple-choice pronoun-disambiguation items requiring contextual reasoning; used to assess language comprehension and pragmatic inference.",
            "llm_performance": "Per-test mean not re-stated in main text beyond being within the overall battery range; Winogrande had very high correlation with Hellaswag (r = 0.95), suggesting similar performance profiles across LLMs.",
            "human_baseline_performance": null,
            "performance_comparison": "Closely aligned with other verbal benchmarks; contributed to the combined Gkn/Grw group factor.",
            "experimental_details": "Authors included Winogrande items (paper's Table 1 lists Winogrande with 12,670 items); scored percent-correct.",
            "limitations_or_caveats": "Dataset-level overlap with LLM training corpora and overlap with other verbal/conceptual tasks may inflate correlations and not reflect independent capacities.",
            "uuid": "e9044.4",
            "source_info": {
                "paper_title": "Evidence of interrelated cognitive-like capabilities in large language models: Indications of artificial general intelligence or achievement?",
                "publication_date_yy_mm": "2023-10"
            }
        },
        {
            "name_short": "Example model mentions (RoBERTa-large, GPT-2-x1, Mistral 7B, PaLM 2 sizes)",
            "name_full": "Specific LLM examples cited in background/discussion",
            "brief_description": "The paper cites several known LLMs and parameter-count examples (as background), but these exemplars were not singled out with per-model results in the reported analyses.",
            "citation_title": "Evidence of interrelated cognitive-like capabilities in large language models: Indications of artificial general intelligence or achievement?",
            "mention_or_use": "mention",
            "model_name": "RoBERTa-large; GPT-2-x1; Mistral 7B; PaLM 2 (various sizes)",
            "model_description": "RoBERTa-large referenced as 355M-parameter model; GPT-2-x1 referenced at 1.56B; Mistral 7B referenced at 7.3B; PaLM 2 mentioned in context of parameter-scaling experiments (Anil et al., 2023) with reported sizes 3.86B, 7.05B, 9.50B, 16.1B in the cited work.",
            "model_size": "RoBERTa-large: 355M; GPT-2-x1: 1.56B; Mistral 7B: 7.3B; PaLM 2 experimental sizes cited in literature (3.86B–16.1B).",
            "test_battery_name": null,
            "test_description": "These are background examples to illustrate the variety of model scales and families; the paper did not report per-model test scores for these individual models within the main aggregated results.",
            "llm_performance": null,
            "human_baseline_performance": null,
            "performance_comparison": null,
            "experimental_details": "Mentioned in introduction/discussion as illustrative examples of model scale and families; PaLM 2 parameter variations cited from Anil et al. (2023) as prior evidence that larger parameter counts can improve performance in some tests.",
            "limitations_or_caveats": "These are illustrative mentions; the present paper's main analyses aggregate many models and do not provide detailed per-model performance for each of these named models (unless they are among the 591 and identified in supplemental files).",
            "uuid": "e9044.5",
            "source_info": {
                "paper_title": "Evidence of interrelated cognitive-like capabilities in large language models: Indications of artificial general intelligence or achievement?",
                "publication_date_yy_mm": "2023-10"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Measuring Massive Multitask Language Understanding",
            "rating": 2,
            "sanitized_title": "measuring_massive_multitask_language_understanding"
        },
        {
            "paper_title": "HellaSwag: Can a machine really finish your sentence?",
            "rating": 2,
            "sanitized_title": "hellaswag_can_a_machine_really_finish_your_sentence"
        },
        {
            "paper_title": "Training verifiers to solve math word problems (GSM8K)",
            "rating": 2,
            "sanitized_title": "training_verifiers_to_solve_math_word_problems_gsm8k"
        },
        {
            "paper_title": "Winogrande: An adversarial Winograd Schema challenge at scale",
            "rating": 2,
            "sanitized_title": "winogrande_an_adversarial_winograd_schema_challenge_at_scale"
        },
        {
            "paper_title": "PaLM 2 technical report",
            "rating": 2,
            "sanitized_title": "palm_2_technical_report"
        },
        {
            "paper_title": "Training compute-optimal large language models",
            "rating": 2,
            "sanitized_title": "training_computeoptimal_large_language_models"
        },
        {
            "paper_title": "Can large language models put 2 and 2 together? Probing for entailed arithmetical relationships",
            "rating": 1,
            "sanitized_title": "can_large_language_models_put_2_and_2_together_probing_for_entailed_arithmetical_relationships"
        },
        {
            "paper_title": "How well do large language models perform in arithmetic tasks?",
            "rating": 1,
            "sanitized_title": "how_well_do_large_language_models_perform_in_arithmetic_tasks"
        }
    ],
    "cost": 0.0206595,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Evidence of interrelated cognitive-like capabilities in large language models: Indications of artificial general intelligence or achievement?
29 August 2024</p>
<p>David Ilić 
Independent Researcher
BelgradeSerbia</p>
<p>Gilles E Gignac gilles.gignac@uwa.edu.au 
School of Psychological Science
University of Western Australia
Australia</p>
<p>School of Psychological Science
University of Western Australia
35 Stirling Highway6009CrawleyWestern AustraliaAustralia</p>
<p>Evidence of interrelated cognitive-like capabilities in large language models: Indications of artificial general intelligence or achievement?
29 August 2024E24D34C44A300B4792D60494AE99F59C10.1016/j.intell.2024.101858Received 18 June 2024; Received in revised form 9 August 2024; Accepted 21 August 2024 Intelligence 106 (2024) 101858Artificial intelligence Artificial general intelligence Number of parameters
Large language models (LLMs) are advanced artificial intelligence (AI) systems that can perform a variety of tasks commonly found in human intelligence tests, such as defining words, performing calculations, and engaging in verbal reasoning.There are also substantial individual differences in LLM capacities.Given the consistent observation of a positive manifold and general intelligence factor in human samples, along with group-level factors (e.g., crystallised intelligence), we hypothesized that LLM test scores may also exhibit positive intercorrelations, which could potentially give rise to an artificial general ability (AGA) factor and one or more group-level factors.Based on a sample of 591 LLMs and scores from 12 tests aligned with fluid reasoning (Gf), domain-specific knowledge (Gkn), reading/writing (Grw), and quantitative knowledge (Gq), we found strong empirical evidence for a positive manifold and a general factor of ability.Additionally, we identified a combined Gkn/Grw group-level factor.Finally, the number of LLM parameters correlated positively with both general factor of ability and Gkn/Grw factor scores, although the effects showed diminishing returns.We interpreted our results to suggest that LLMs, like human cognitive abilities, may share a common underlying efficiency in processing information and solving problems, though whether LLMs manifest primarily achievement/expertise rather than intelligence remains to be determined.Finally, while models with greater numbers of parameters exhibit greater general cognitive-like abilities, akin to the connection between greater neuronal density and human general intelligence, other characteristics must also be involved.</p>
<p>Introduction
 Gignac and Szodorai (2024, p. 4
) defined artificial intelligence (AI) as "an artificial system's maximal capacity to complete a novel standardized task with veridical scoring using computational algorithms".Currently, much attention has focussed on the development and testing of large language models (LLMs), sophisticated AI systems that leverage extensive datasets and advanced neural network architectures (Zhao et al., 2023).LLMs, such as GPT, Claude, LLaMA, and Gemini, are capable of performing a wide range of tasks, including defining words, retrieving factual information, summarization, performing calculations, verbal reasoning, and creative writing.</p>
<p>A large number of modern LLMs have been developed since the introduction of transformer technology (Zhao et al., 2023).Like humans, LLMs exhibit substantial individual differences in capacities, as evidenced by their varied performance across a diversity of tasks (Owen, 2024).Some LLMs excel in specific domains due to specialized training data or enhanced architectural features, while others perform more robustly across a broader spectrum of tasks (Dong et al., 2023;Lin et al., 2023).This variability in performance suggests that, similar to human intelligence, there might be one or more underlying dimensions that represent LLM performance.Understanding these individual differences may prove useful for advancing our knowledge of AI capabilities and designing more effective and versatile AI systems.Additionally, scientific discoveries into the nature of AI system capabilities and behaviour could provide valuable insights into human intelligence (Gignac &amp; Szodorai, 2024;Neubauer, 2021).Consequently, the primary purpose of this study was to examine whether LLM performance exhibits positive correlations across a range of human-like cognitive abilities.Additionally, we sought to investigate the potential emergence of one or more LLM ability dimensions, including a general ability factor.</p>
<p>General intelligence: human and artificial</p>
<p>Humans who tend to have higher verbal skills also tend to have higher spatial skills, better memories, and faster processing speed (Jensen, 1998).Expressed in statistical terms, the average correlation between a wide array of cognitive ability test performances tends to be approximately 0.45 to 0.50 (Detterman &amp; Daniel, 1989;Walker et al., 2023).In general terms, the observation of consistent, positive correlations between cognitive ability test scores is known as the positive manifold (Jensen, 1998).When cognitive ability inter-correlations are submitted to data reduction procedures such as factor analysis, the largest factor tends to be a general factor that accounts for 40 to 50% of the variance in test performance (Deary et al., 2009).Known as psychometric g (Jensen &amp; Weng, 1994), the phenomenon has been observed across many human cultures (Warne &amp; Burningham, 2019), as well as several species, including orangutans (Damerius et al., 2019), dogs (Arden &amp; Adams, 2016), and deer (Pastrana et al., 2022).</p>
<p>Recently, Gignac and Szodorai (2024) proposed that a general factor of ability could potentially be identified in AI systems, including LLMs, if their performance across various tasks is positively inter-correlated.It should be clarified that many computer scientists, as well the general public, commonly refer to artificial general intelligence (AGI) as a level of intelligence, specifically human-level intelligence (Amazon Web Services, 2024;Demasi et al., 2010;McLean et al., 2023;Obaid, 2023;Rayhan et al., 2023).However, because general intelligence in humans is observed across all levels of ability (Breit et al., 2022;Detterman &amp; Daniel, 1989), Gignac and Szodorai (2024) proposed that AGI should be considered a reflection of the phenomenon of the positive manifold, rather than simply a quantitative level of cognitive ability.From this perspective, one may hypothesize that AGI is observed across all levels of AI system performance.Furthermore, by conceptualising and modeling AGI in a manner consistent with general intelligence in humans, it is possible to quantify levels of AGI across AI systems, as well as investigate predictors and outcomes of AGI.</p>
<p>Before proceeding, we note that Gignac and Szodorai (2024) contended that current LLMs may exhibit what they term as 'artificial achievement' (AA) rather than true AI, as these models may not fulfill all the criteria for genuine intelligence.Acknowledging that this debate is ongoing, we opted to use the broader term 'artificial general ability' (AGA) instead of the more specific term 'artificial general intelligence' (AGI) throughout this paper.We address this issue further in our discussion section.</p>
<p>Group-level factors of intelligence</p>
<p>Beyond the general factor of human intelligence, a reliable amount of the variance in cognitive ability tests scores is accounted for by a variety of smaller, group-level of factors, also known as stratum II dimensions (the general factor is known as a stratum III dimension; Carroll, 2003).According to the most recent Cattell-Horn-Carroll (CHC) model of intelligence, there are approximately 16 stratum II dimensions of cognitive ability (Schneider &amp; McGrew, 2018).Of the 16 strata II dimensions, perhaps seven are relatively more dominant and commonly investigated: fluid reasoning (Gf), comprehension-knowledge (Gc), short-term memory (Gsm), visual processing (Gv), quantitative knowledge (Gq), cognitive processing speed (Gs), and reading and writing (Grw).We briefly review each of these seven dimensions and propose that several commonly used LLM system benchmark tests may align with some of these categories.</p>
<p>Fluid reasoning (Gf) is the ability to use various reasoning methods (e.g., inductive, deductive, analogical, etc.) to solve unfamiliar or novel problems (Kyllonen &amp; Kell, 2017).Tests of Gf can be developed based on spatial, verbal, and numerical content.Raven's progressive matrices is a well-established spatial/figural test of fluid reasoning (Raven, 2000).As LLMs are based exclusively upon textual data, they may not be expected to solve spatial reasoning tasks.However, some are considered capable of solving certain types of verbal reasoning problems (Orrù et al., 2023).</p>
<p>Comprehension-knowledge (Gc) is the ability to understand and communicate culturally significant knowledge (Schneider &amp; McGrew, 2018).A well-established measure of Gc is Vocabulary from the Wechsler scales (Wechsler, 2008a), as well as Similarities which measures the capacity to identify relationships between concepts.Though typically conceived as verbal tests, spatial tests of Gc are conceivable.For example, a geography test where participants are asked to identify nations based on their shapes may be considered a test of spatial comprehension-knowledge (e.g., Hagge, 2023).A less investigated stratum II dimension that is conceptually highly similar to Gc is domainspecific knowledge (Gkn), which represents specialized knowledge and skills in particular areas, such as knowledge of a specific academic subject (e.g., European history) or technical expertise (e.g., computer programming).Many LLM benchmark tests are would likely be classified as measures of Gkn, as we detail further below.</p>
<p>Visual processing intelligence (Gv) represents the cognitive ability to perceive, analyze, synthesize, manipulate, and think with visual patterns, including the capacity to understand spatial relationships.An example Gv test is mental rotation (Vandenberg &amp; Kuse, 1978).As with spatial Gf tasks, LLMs may not be expected to solve Gv problems, as they are based purely on spatial content.</p>
<p>Quantitative knowledge (Gq) represents "declarative and procedural knowledge related to mathematics" (Schneider &amp; McGrew, 2018, p. 123), which includes knowledge of symbols (e.g., ≤, ∞, ∕ =, etc.), operations (e.g., addition, multiplication, etc.) and computational procedures (e.g., long division).An example Gq test is the arithmetic subtest from the Multidimensional Aptitude Test II (Jackson, 2003).Though many LLMs are known to struggle with calculations (Urrutia &amp; Araya, 2024), some can still perform reasonably well in tasks that require the recognition and manipulation of mathematical symbols and operations (Xu et al., 2024).</p>
<p>Short-term memory (Gsm) is the capacity to perceive and temporarily hold a restricted amount of information from one's present circumstances in active conscious awareness (i.e., events that transpired within the last roughly one minute).A commonly used test of short-term memory is digit span, where the participant is asked to immediately recall a sequence of randomly presented numbers in the correct order (Bowden et al., 2013).To date, there are no consistently used tests of memory span for LLMs, though LLM context windows could possibly serve as a rough proxy for short-term memory capacity (Gignac &amp; Szodorai, 2024;Kuratov et al., 2024).</p>
<p>Processing speed (Gs) represents the capacity to execute relatively simple or well-practiced basic cognitive operations swiftly and smoothly, particularly when a high level of focused mental resources and concentration is necessitated.In humans, a well-established method to measuring processing speed is inspection time, which is a psychophysical procedure that determines the minimum exposure duration required for a person to reliably make a simple discrimination between two visual stimuli (Jensen, 2006;Nettelbeck &amp; Lally, 1976).To date, processing speed has not been considered a dimension on which LLMs are compared, though, theoretically, it could be potentially measured (e. g., time taken by an LLM to parse and analyze large volumes of text data).</p>
<p>Similar to the psychometric tests used to measure the intelligence of humans, the capacities of LLMs are measured with benchmark tests, also known as datasets (Welty et al., 2019).At least conceptually, many benchmark tests can be classified with one or more CHC stratum II dimensions.For instance, Hellaswag (Zellers et al., 2019), an LLM benchmark test that involves questions related to commonsense reasoning, requiring the prediction of the most likely scenario continuation, may be regarded as a measure of Gf.Additionally, Winogrande (Sakaguchi et al., 2021) focuses mainly on reading comprehension test items and can be categorized as a measure of Grw.Finally, the HumanEval test is comprised of programming challenges and may be considered to be a measure of Gkn.</p>
<p>Over the years, numerous tests for LLMs have been developed, and many LLMs have been evaluated using benchmark tests, including the three tests noted above.Furthermore, the test results from thousands of LLMs are publicly available on the Hugging Face repository (Hugging Face, 2024).This accessibility allows for the investigation of whether LLM test performances are positively inter-correlated, potentially yielding a positive manifold.Such a positive manifold could indicate the presence of an artificial general ability factor, as well as one or more group-level factors similar to the stratum II abilities recognized within the CHC model of intelligence.</p>
<p>The empirical verification of a general ability factor (AGI or AGA) may be considered important, as it would provide evidence that current LLMs may possess general capabilities that extend beyond narrow task specialization (Lin et al., 2023).Additionally, the identification of a reliable general ability factor would justify the calculation and interpretation of global AI (or AA) performance scores psychometrically, which would facilitate overall performance comparisons between LLMs.Finally, by drawing parallels between the structures of human and artificial intelligence, novel insights into the nature of human intelligence may be eventually achieved (Gignac &amp; Szodorai, 2024;Neubauer, 2021).</p>
<p>Number of parameters and artificial general ability</p>
<p>LLMs are fundamentally based on neural networks (Goldberg, 2016).A neural network is a computational model inspired by the way biological neural networks in the human brain process information (Jeon &amp; Kim, 2023).It consists of layers of interconnected nodes (or neurons), where each connection has an associated weight.These weights are adjusted during the training process to minimize prediction errors and improve the model's performance.In the context of LLMs, the number of parameters refers to the total count of learnable weights and biases in the model, with each weight and bias representing a parameter that can be tuned to optimize the model's predictions (Zhao et al., 2023).For instance, RoBERTa-large is based on 355 million parameters, GPT-2-x1 on 1.56 billion parameters, and Mistral 7B on 7.3 billion parameters (Kazi &amp; Elmahdy, 2023).</p>
<p>In theory, the number of parameters that underpin LLMs may be expected to positively predict the performance of LLMs.This is because a greater number of parameters allows the model to capture more complex patterns and nuances in the data, leading to a higher capacity for learning intricate relationships (Hu et al., 2021).Moreover, the greater capacity should allow the model to generalize better from training data and produce more accurate outputs across diverse tasks, potentially boosting overall performance.As a parallel, in biological organisms, including humans, there is evidence that greater neuronal density and connectivity in specific brain regions are associated with higher cognitive abilities (e.g., Dicke &amp; Roth, 2016;Goriounova et al., 2018).</p>
<p>To date, a small number of studies have examined the association between model parameter size and LLM performance, though within only one model.For example, Anil et al. (2023) examined the performance of Palm 2 on 27 benchmark tests, while varying the number of model parameters experimentally, i.e., 3.86B, 7.05B, 9.50B and 16.1B parameters.The found that performance increased with larger numbers of parameters, though not linearly across all tests.From a differential psychology perspective, it would be useful to estimate the association between number of parameters and performance in a large and diverse sample of LLMs.Based on the above, we predicted a positive correlation between the number of LLM parameters and LLM test performance.</p>
<p>Summary and purpose</p>
<p>Many LLMs have been tested on tasks similar to those found in psychometric intelligence test batteries, and there is evidence that there are substantial individual differences in LLM capabilities.Furthermore, many LLM benchmark tests can be theoretically classified under specific stratum II dimensions within the CHC model of intelligence (Schneider &amp; McGrew, 2018).Consequently, we investigated potential correlations between LLM system performance across diverse benchmark tests, expecting a positive manifold.We also hypothesized the existence of an artificial general factor of ability and explored the possibility of grouplevel factors aligning with stratum II dimensions recognized by the CHC model.Finally, in the event that artificial ability factors were observed, we hypothesized that there would be a positive association between number of LLM parameters and LLM test performance (e.g., general ability factor scores).</p>
<p>Method</p>
<p>Sample</p>
<p>The data for this study were obtained on March 8th, 2024, from the Hugging Face website, a well-known repository for LLM benchmarks.The initial sample consisted of 3862 models.However, many of the models were arguably not sufficiently distinct to be considered unique cases from an individual differences investigation perspective.Defining what constitutes a distinct model in this context is inherently complex, with no universally accepted criteria.We suggest that models may be described on a uniqueness continuum across several categories, from most unique (entirely new architectures and trained on data from scratch), moderately unique (large-scale pre-trained models, merged models with significant training adjustments, and specialized models with unique fine-tuning), less unique (fine-tuned models and merged models with minimal adjustments), and least unique (parameteradjusted models and replicas or clones).While this continuum provides a general framework, it is important to note that the boundaries between categories can be fluid, and factors such as innovative training techniques or specialized applications can influence a model's perceived uniqueness.In our investigation, we employed three strategies to curate a sample to help reduce the impact of less distinct models on our analyses.</p>
<p>First, we employed Density-Based Spatial Clustering of Applications with Noise (DBSCAN; Ester et al., 1996) to remove essentially redundant models.Specifically, we used an epsilon (eps) value of 0.33 and a minimum samples parameter of 2. We arrived at these values through experimentation by collecting groups of models that were slight variations of one another and observing how they responded to changes in the DBSCAN parameters.This process reduced our sample size from 3862 to 2680 models.Next, three months after the initial data were downloaded from the repository, we found that 264 models were no longer on the site, suggesting the models were either deprecated or removed by their creators for various reasons.Finally, two models in our database possessed essentially the same name, differing only in capitalization:
'Vmware/open-llama-7b-v2-open-instruct' versus 'VMware/open- llama-7b-v2-open-instruct.'
We used the most recently uploaded data for our investigation (i.e., Vmware/open-llama-7b-v2-open-instruct), resulting in a final sample size of 2415 models.Well known LLMs included those associated with Mistral, LLaMA, GPT, and Claude, as well models from less well-known sources such as ConvexAI, Lorinma, and CalderaAI, for example.We used model 'submitted time' as an approximate indicator of model age, which yielded a median of 147 days (IQR: 99 days).</p>
<p>For the second subsample of LLMs, we subjectively evaluated the degree of uniqueness among the 2415 models obtained in the first approach based on their names and the number of associated parameters.Information such as model architecture, fine-tuning methods, version numbers, merging or combination indicators, and specialized applications was considered, for example.Based on such an evaluation, we excluded an additional 816 models from 2415, which yielded a subsample size of n = 1599.</p>
<p>For the third and final approach, we quantified the similarity between model names among the 2415 models obtained in the first approach using a Levenshtein distance metric, which measures the number of single-character edits required to transform one name into another (Beernaerts et al., 2019;Levenshtein, 1966).Through initial trials, we determined that a stringent similarity threshold of 20 was necessary to ensure meaningful differentiation between models.Thus, any two models with a name similarity within this distance and have the same number of parameters were considered too similar.The deduplication process was implemented in Python, resulting in a final subsample size of 591 usable models.Because the results derived from all three samples were highly similar, we report only the results derived from the subsample of 591 models in the main manuscript (the results associated with the n = 1599 and n = 2415 subsamples are reported in the supplementary document).</p>
<p>Measures</p>
<p>A total of 12 tests were selected to represent, at least theoretically, four different group-level factors of ability: fluid reasoning (Gf); quantitative knowledge (Gq); reading/writing (Grw) and domain-specific knowledge (Gkn).Several tests were selected from the Massive Multitask Language Understanding (MMLU) test battery (Hendrycks et al., 2020).All items associated with the MMLU subtests can be viewed at htt ps://huggingface.co/datasets/cais/mmlu.</p>
<p>Gf was measured by three tests.First, Hellaswag is a 10,042-item test designed to evaluate an LLM's abilities in natural language understanding and commonsense reasoning (Zellers et al., 2019).Test items consist of various contexts that require the identification of the most plausible continuation out of four provided options.For example, "A woman is outside with a bucket and a dog.The dog is running around trying to avoid a bath.She… a) rinses the bucket off with soap and blow dry the dog's head; b) uses a hose to keep it from getting soapy; c) gets the dog wet, then runs away again (correct); d) gets into a bathtub with the dog.</p>
<p>The two remaining Gf tests were considered measures of quantitative reasoning, a stratum I dimension of Gf (Schneider &amp; McGrew, 2018).The Grade School Math 8 K (GSM8K) aims to test an LLM's ability to perform multi-step arithmetic operations and mathematical reasoning presented in a natural language context (Cobbe et al., 2021).Out of the 8500 items, we selected 1319 that best reflect quantitative reasoning.An example question is: "The ratio of boys to girls in a family is 5:7.The total number of children in the family is 180.If the boys are given $3900 to share, how much money does each boy receive?" (Answer: 52).The response format is open-ended.</p>
<p>The items for the third Gf test, specifically the Elementary Mathematics subtest within the MMLU benchmark battery (Hendrycks et al., 2020), were selected for their ability to represent quantitative reasoning.For instance, one of the items is as follows: "The rate at which a purification process can remove contaminants from a tank of water is proportional to the amount of contaminant remaining.If 20% of the contaminant can be removed during the first minute of the process and 98% must be removed to make the water safe, approximately how long will the decontamination process take?(Response alternatives: a) 2 min, b) 5 min, c) 18 min [correct], and d) 20 min.</p>
<p>Gkn was measured by a combination of three composites scores, which were based on items derived from the (MMLU) test battery (Hendrycks et al., 2020).All items associated with the MMLU subtests can be viewed at https://huggingface.co/datasets/cais/mmlu.Composite score one was based on the International Law, Business Ethics, Philosophy test items.Composite score two was based on the Medical Genetics, Clinical Knowledge, Human Aging, and Human Sexuality test items.Finally, composite score three was based on the Global Facts, Computer Security, Marketing, and Miscellaneous test items.</p>
<p>Gq was also measured by several tests within the MMLU test battery.One composite was based on the High School Statistics, Abstract Algebra, and Econometrics subtests (measuring Mathematical Knowledge; KM).A second composite was based on selected items from the Elementary Mathematics subtest (measuring Mathematical Accomplishment; A3).Finally, the third composite based on a combination of selected Elementary Mathematics items and High School Mathematics subtest items (measuring Mathematical Accomplishment; A3).</p>
<p>Grw was measured by three tests, two of which were from the MMLU: the High School European History test and the High School US History test (Hendrycks et al., 2020).For both tests, the items require carefully reading and comprehending intricate written passages, which often involve nuanced language, contextual references, and philosophical perspectives from different historical eras.Each question is multiplechoice in nature with four response alternatives.The third test, Winogrande, was classified as a measure of Grw, as Winogrande problems require comprehending written sentences/passages and resolving ambiguity through contextual understanding (Sakaguchi et al., 2021).Specifically, for each test item, models must choose between two options to complete a sentence, based on understanding subtle linguistic and contextual cues.For example: 'John moved the couch from the garage to the backyard to create space.The _____ is small.'Choices: a) garage (correct); b) backyard.</p>
<p>All tests were scored such that they represented percentage of questions answered correctly.For a list of the tests, their theorised CHC</p>
<p>Data analysis</p>
<p>All statistical analyses were performed using R (Version 4.2.2) and RStudio (Version 2022.09.1).To evaluate the relationships between key observed variables, Pearson correlation coefficients were calculated.We used the ggplot2 package (Wickham, 2016) to create a scatter matrix, which provided visual insights into the nature and strength of these associations.LOESS regression lines, computed with R's tricubic weighted function (Cleveland &amp; Devlin, 1988), were included in the scatter matrix for a flexible fit, emphasizing data points based on proximity.The default setting window size of 0.75 was specified, implying that 75% of the data points in the neighbourhood of each point were used for local regression.Finally, 95% confidence intervals were included to show estimation uncertainty.</p>
<p>Latent variable modeling was performed using the lavaan package (Rosseel, 2012).Model fit was assessed using RMSEA and SRMR (with values ≤0.08 indicating acceptable fit), as well as CFI and TLI (with values ≥0.950 indicating acceptable fit).Given that the data were continuously scored, maximum likelihood estimation was utilized.Standardized effect 95% confidence intervals were generated through bootstrapping (5000 resamples) using a combination of the manymome (Cheung &amp; Cheung, 2023) and semhelpinghands packages (Cheung &amp; Cheung, 2023).</p>
<p>We evaluated a theoretical model comprising a second-order general factor and four first-order factors (Gf, Gkn, Grw, Gq), aligning with the categorizations and tests outlined in Table 1.To ensure proper identification and scaling, the variance of the general factor was fixed at 1, and one loading for each of the first-order factors was also constrained to 1.The data, scripts, and results are available on the OSF: https://osf.io/792ug/</p>
<p>Results</p>
<p>Descriptive statistics and inter-subtest pearson correlations</p>
<p>As can be seen in Table 2, LLM mean performance (percentage of questions answered correctly) across the 12 tests ranged from 18.09 to 74.27, with a mean of 48.62, suggesting the tests were, on average, moderately difficult.Furthermore, there were substantial individual differences in performance, as the mean test performance standard deviation was 20.02 (range: 10.99 to 31.48).The test performance distributions tended to be negative, though only substantially so for the Hellaswag test (skewness = − 1.04).See Tables S1.1 and S1.2 in the supplementary document for the descriptives based on the other two subsamples.</p>
<p>The inter-correlations between the 12 test performance scores were all positive with a mean correlation of 0.73 (range: 0.35 to 0.99; see Table 2; see Fig. S1.1 for scatter matrix), supporting the hypothesis of a positive manifold.The Gkn inter-correlations were exceptionally large, ranging between 0.98 and 0.99.</p>
<p>Confirmatory factor analysis</p>
<p>The Kaiser-Meyer-Olkin (KMO) index analysis yielded a value of 0.93, suggesting the correlation matrix was appropriate for data reduction (Kaiser &amp; Rice, 1974).Our hypothesized higher-order confirmatory factor analytic model did not produce an interpretable solution, as evidenced by statistically significant negative residual variances for two of the first-order factors.Consequently, we explored the structure of the data by conducting unrestricted factor analyses.First, we conducted a parallel analysis to determine the number of dimensions to extract.The parallel analysis suggested the extraction of one dimension (see Table S2.1).However, a maximum likelihood estimation factor analysis with the extraction of one factor failed to yield good model close-fit (e.g., TLI = 0.814). 2 A subsequent unrestricted factor analysis with the extraction of two factors remained unacceptably well-fitting (e. g., TLI = 0.870).Furthermore, the Hellaswag test was associated with a loading of 1.07 on the first factor, suggesting the factor solution was not stable.Moreover, the correlation between the two factors was quite large at 0.78, suggesting the presence of a substantial general factor.</p>
<p>Based on the above unrestricted factor analytic findings, we tested a supplementary restricted factor analytic bifactor model with a firstorder general factor defined by all 12 tests.Additionally, we specified a nested, first-order Gkn/Grw factor.Due to the very high correlations between the Winogrande and Hellaswag tests (r = 0.95) and the European History and US History tests (r = 0.97), we also specified correlations between these respective test residuals.When we tested the model, the modification indices suggested the addition of one more correlated residual, i.e., between the A3.E and A3.HS tests.The bifactor model with the three correlated residuals yielded acceptable model close-fit, χ 2 (44) = 250.42,p &lt; .001,CFI = 0.984, TLI = 0.977, RMSEA = 0.089, SRMR = 0.025. 3All of the loadings were positive and statistically significant (p &lt; .001;see Fig. 1).The mean general factor loading was large at 0.81 (range: 64 to 0.96; see Table S3.1 for all loadings and 95% CIs).The indicator with the largest general factor loading was associated with the KM mathematics composite (λ = 0.96).The percentage of variance accounted for by the general factor was estimated at 65.6%. 4 Furthermore, the general factor omega hierarchical was 0.94.Thus, there was evidence for a very strong general factor and, thus, highly reliable LLM general ability composite scores.Though the nested Gkn/ Grw nested factor was notably weaker than the general factor, it was nonetheless defined by consistently positive and statistically significant factor loadings (mean λ = 0.50).</p>
<p>Associations with number of parameters</p>
<p>Next, we investigated the associations between the two LLM ability dimensions, artificial general ability (AGA) and Gkn/Grw, and the number of LLM parameters.Number of parameters data were available for 579 models.The LLMs had an average number of parameters equal to 14.86 billion.However, a histogram revealed two outliers with values of 238.09 and 180.00 billion parameters.These outliers were excluded from the correlation analyses.After removing the outliers (n = 577), the number of parameters had a mean of 14.19 billion (SD = 18.87;Median = 7.24 billion).The distribution remained skewed (skewness = 2.53).Therefore, we estimated the associations using both Pearson and Spearman correlations.Additionally, the 95% confidence intervals for the correlations were calculated using 5000 bootstrapped resamples.</p>
<p>The Pearson correlation between number of parameters and general 1 We conducted item-total correlation analyses, prior to the testing of hypotheses.For some tests, we omitted items, as they failed to yield positive itemtotal correlations (see supplementary file 2).Reliabilities were estimated using item-level analyses for all tests, except for the Gkn composite scores, which were derived from three subtests each.For these composite scores, the three respective subtests were used as inputs in the reliability analysis.</p>
<p>2</p>
<p>The parallel analysis procedure fails to identify the correct number of factors to extract in ≈ 2 5% of cases (Crawford et al., 2010).</p>
<p>3 Despite the RMSEA being above 0.080, we considered the model to be acceptably well-fitting because the SRMR was quite low at 0.02 5.This decision is supported by simulation research indicating that RMSEA (but not SRMR) can be overly sensitive to unmodeled correlated residuals (Montoya &amp; Edwards, 2021). 4We calculated the percentage of variance accounted for by summing the squared g loadings and dividing that sum by the total number of indicators in the model (7.87 / 12 = 6 5.6).As can be seen in Fig. 2 (left side), the analysis revealed a positive association, characterized by distinct phases.Initially, there was a sharp increase in AGA factor scores as the number of parameters increased from 100 million to approximately 10 billion parameters.This was followed by a phase of stabilization between 10 and 20 billion parameters.Beyond 30 billion parameters, the AGA factor scores continued to improve gradually and steadily up to 80 billion parameters.Overall, the trend suggests that increasing the number of parameters generally enhances general large language model capacity, with the most significant gains observed at lower parameter counts and a more gradual improvement at higher counts.The Pearson correlation between Gkn/Grw and number of parameters was r = 0.11, 95% [CI: 0.05, 0.18].The corresponding Spearman correlation was r = 0.42, 95% CI: [0.34, 0.49].A nonlinear model (cubic spline) fit the relationship between parameter count and Gkn/Grw scores significantly better than a linear model, F(2, 573) = 87.13,p &lt; .001,Δη 2 = 0.230.As can be seen in Fig. 2 (right side), somewhat similar to the general ability factor, the analysis revealed a positive association, characterized by distinct phases.Initially, there was a sharp increase in Gkn/Grw factor scores as the number of parameters increased from 0 to approximately 10 to 15 billion.This was followed by a phase of fluctuation and slight decline between 10 and 45 billion parameters, indicating variability and a non-linear relationship.Beyond 45 billion parameters, there was essentially no association between the two variables.Overall, the trend suggests that increasing the number of parameters enhances Gkn/Grw ability, though only up to 15 to 20 billion parameters.See Table S2.4 for a summary of the key results across all three subsamples.</p>
<p>Discussion</p>
<p>We found evidence for a LLM test performance positive manifold, as well as an artificial general ability (AGA) factor.Beyond the general factor, instead of four separate group-level factors, we found evidence for only one combined Grw/Gkn group-level factor.A mathematics test composite yielded the largest AGA loading.Finally, number of model parameters was found to associate positively with both AGA and the Grw/Gkn group-level factor.We discuss each of these key results next.</p>
<p>Positive manifold and AGA</p>
<p>The strength of the LLM positive manifold was remarkable, with a Note.N = 591; II = theorised stratum II dimension; Gf = fluid reasoning; Gq = Quantitative Knowledge; Grw = reading/writing; Gkn = domain specific knowledge; all correlations statistically significant, p &lt; .001.mean inter-test correlation of 0.73, significantly higher than that typically observed in humans, i.e., r = 0.45 to 0.50 (Detterman &amp; Daniel, 1989;Walker et al., 2023).Correspondingly, the general factor of artificial ability accounted for 66% of the variance, whereas general factors of intelligence in human samples typically account for 40 to 50% of the variance (Deary et al., 2009).Finally, the LLM general factor yielded a coefficient of omega hierarchical of 0.94, a value higher than typically observed for the general factor of human intelligence (mid to high .80s;Dombrowski et al., 2019;Gignac, 2014a;Gignac &amp; Watkins, 2013).</p>
<p>There are several possible reasons why the LLM general factor was found to be stronger than the general factor of intelligence for humans.First, the LLM test data were mostly associated with exceptional test score reliability.The median internal consistency reliability across the 12 LLM composite test scores was 0.97, whereas, as a point of comparison, the WAIS-IV technical manual (Wechsler, 2008b) reported mean subtest reliabilities of 0.88, which is probably closer to 0.75 to 0.80 in practice (see Oosterwijk et al., 2019).In contrast to LLMs, human performance is influenced by a myriad of factors including emotional and physical states, which vary widely among individuals.LLMs, however, do not experience such variability, likely leading to more reliable test performance.</p>
<p>Relatedly, while LLMs are trained on a vast and diverse corpus of text, the processing of this data by LLMs is uniform.Each piece of text, regardless of its origin or content, is converted into a standardized format and fed into the model through the same training algorithms and procedures (Zhao et al., 2023).This uniformity in processing ensures that the model processes the data in a consistent manner, which is in contrast to the moderate fluctuations that characterize human neurophysiology, thoughts, and behaviours over time (i.e., test-retest reliability far less than 1; Dai et al., 2019;Gnambs, 2014;Noble et al., 2019).</p>
<p>Finally, the median number of items per LLM test we included in the test battery was very large at 300.This is important, as the number of items in a psychometric measure is positively associated with test score reliability (Nunnally &amp; Bernstein, 1994).Correspondingly, the internal consistencies for the LLM tests were typically very high (median 0.97), allowing for maximum possible correlations between LLM test scores (i.e., not attenuated by measurement error).By comparison, humans cannot be expected to complete very large numbers of test items without experiencing fatigue, loss of concentration, or other transient factors that can negatively impact the consistency of performance and, to some extent, the magnitude of an observed score positive manifold.We note that when restricted to the six LLM tests composed of 52 or fewer items, the mean LLM inter-test correlation was 0.63, which is smaller than the 0.73 value associated with all 12 LLM tests, but still larger than the 0.45 to 0.50 typically observed in humans (Detterman &amp; Daniel, 1989;Walker et al., 2023).Thus, the greater breadth of coverage in some of the LLM tests composed of 100 s of items is arguably not the full explanation for why the LLMs yielded a stronger positive manifold than that typically observed in humans.</p>
<p>Admittedly, the range of LLM tests included in our analysis may be considered narrower compared to comprehensive measures of human intelligence.For example, none of the 12 tests assessed spatial abilities, a key dimension of cognitive ability in comprehensive batteries of human intelligence (Johnson &amp; Bouchard Jr, 2005).Therefore, it is plausible that the percentage of variance accounted for by the LLM general factor was somewhat inflated due to the greater homogeneity in the selected LLM benchmark tests.Consequently, we refrained from labelling the LLM general factor identified in our investigation as 'artificial general intelligence,' as true AGI is expected to be demonstrated across verbal and spatial ability tests (Gignac &amp; Szodorai, 2024;Jensen, 1998).We nonetheless note that the mean inter-subtest correlation between the verbal subtests associated with the Wechsler scales is between 0.55 and 0.60 (Wechsler, 1981;Wechsler, 2008b), which is still lower than the 0.73 mean inter-subtest correlation observed in our investigation.In simple terms, our results imply that better LLM performance on one task is substantially associated with better performance on another, much like the patterns observed in human cognitive abilities (Jensen, 1998).Thus, even considering the homogeneity of the LLM tests, the substantial shared variance across moderately distinct LLM tasks suggests the presence of general LLM capability.</p>
<p>Group-level factors</p>
<p>We identified only one group-level factor, not four as hypothesized.This group factor was a combination of Gkn and Grw tests.Tests designed to measure Grw and Gkn share substantial content overlap.Specifically, reading and writing skills often involve the application of Fig. 2. Scatter plots depicting the association between number of parameters (billions) and artificial general ability factor scores (left side),and number of parameters and Grw/Gkn factor scores (right side).Note.N = 577; lines of best fit are LOESS regression lines (tricubic weighting; span = 0.75); the jitter applied to the scatter plots was set to a width and height of 0.3 units along the respective axes; all correlations were significant, p &lt; .001.general knowledge, as comprehension and production of text rely heavily on background information and vocabulary.Schneider and McGrew (2018) contended that it is beneficial to conceptualize a higherorder acquired-knowledge/expertise dimension that unites Gc, Grw, Gkn, and Gq variance.Although we did not find evidence that Gq tests are indicators of any factor beyond AGA, the fact that the Grw and Gkn tests formed a nested group-level factor independent of AGA is at least partially consistent with Schneider and McGrew (2018) theoretical proposition of an overarching acquired knowledge/expertise dimension.</p>
<p>We note that the empirical distinction between Grw and Gkn is far from clear in humans.Based on a sample of 6701 school children who completed a battery of verbal intelligence tests (Gc, Grw, and Gkn), Schipolowski et al. (2014) reported a latent variable correlation of 0.91 between Grw and Gkn.Additionally, based on Bryan and Mayer (2020) meta-analysis on the associations between CHC group-level factors, only one study included a Grw factor and none the Gkn dimension. 5The correlation between Grw and Gc was reported at r = 0.85.Though correlations of 0.85 to 0.91 may not be entirely consistent with the notion of isomorphic constructs, it should be acknowledged that correlations of such a magnitude are so large that the apparent discriminant validity may have arisen due to method artifacts (e.g., question type) rather than substantive (construct) variance.All things considered, the observation of a combined Grw/Gkn dimension in our LLM data may be considered largely consistent with the human intelligence empirical literature, i.e., Grw and Gkn are highly inter-related.</p>
<p>We also failed to observe a Gf factor independent of the general factor.While some have argued that Gf is essentially isomorphic with g in humans (e.g., Gustafsson, 2001), we are more cautious about making such an interpretation with our data.Our selected measures of Gf were, at best, acceptable rather than good or excellent.In particular, two of our Gf tests focused on mathematical reasoning, and none involved figural matrices which are typically well-regarded for measuring fluid reasoning (Gignac, 2015).Consequently, further research with better measures of Gf is required to evaluate the possibility of a distinct Gf group-level factor in LLM data.</p>
<p>Strongest indicator of AGA</p>
<p>Much research has found that Gf dimensions are the strongest indicators of g in humans (e.g., Gignac, 2014b;Hertzog &amp; Schaie, 1988;Kvist &amp; Gustafsson, 2008).However, in our study, a mathematics composite that included algebra and statistics questions yielded the largest AGA loading.As previously noted, among the LLM benchmark tests available for this investigation, none were consistent with the wellregarded figural matrices tests of fluid reasoning.Consequently, it is difficult to compare our results with the broader human intelligence literature, in this context.Nonetheless, it is noteworthy that several investigations have found arithmetic to be the strongest indicator of g in human samples.For example, Gignac (2015) consistently found mathematics/arithmetic subtests to be the strongest indicators of g across bifactor analyses of three comprehensive batteries of human intelligence.Additionally, based on a bifactor analysis of the WAIS-IV normative sample, Gignac and Weiss (2015) found that the Arithmetic subtest yielded the most substantial loading onto g.While arithmetic may or may not be the best indicator of g, the literature on humans suggests that arithmetic is a strong indicator of g, which aligns with the results observed in our investigation with LLMs.</p>
<p>Based on latent variable models, several stratum II cognitive ability dimensions have been found to be unique predictors of human arithmetic ability, suggesting a relatively complex cognitive process (Floyd et al., 2003;Fung &amp; Swanson, 2017).It is noteworthy that LLMs are known to exhibit challenges with completing arithmetic problems (Panas et al., 2024).Possible explanations for this phenomenon include their training on diverse, noisy data which does not emphasize precision, their tendency to propagate errors in multi-step reasoning, and difficulties with symbolic manipulation (Imani et al., 2023;Qian et al., 2022;Yuan et al., 2023).Thus, LLMs capable of greater precision, error correction in multi-step problem solving, and enhanced symbolic manipulation would be expected to perform better at arithmetic, as well as a wide range of other tasks, thereby exhibiting higher levels general ability.In other words, LLMs that excel in solving arithmetic/mathematics problems, which would be expected to require more sophisticated training, model architecture, and computational algorithms, may also be superior at a variety of other verbal tasks, explaining the substantial AGA loading we observed for arithmetic.</p>
<p>Association with number of parameters</p>
<p>We found number of parameters to be a substantial, positive predictor of AGA, as hypothesized.Thus, our results align with the small amount of empirical research on individual LLMs that have indicated that increasing number of parameters improves LLM performance (Anil et al., 2023).We extend the literature by estimating the association based on a large sample of LLMs and a moderately diverse battery of benchmark tests.Thus, our results help support the notion that the more complex patterns captured by larger models not only facilitates better performance on specific tasks (Hu et al., 2021), but on LLM capacity in a general sense.Our finding is also consistent with research with biological organisms that has found greater cognitive abilities to be predicted by greater neuronal density and connectivity (Dicke &amp; Roth, 2016;Goriounova et al., 2018).</p>
<p>While the number of model parameters accounted for approximately 25% of the variance in AGA, the relationship was clearly curvilinear.AGA factor scores generally increased with parameter count, showing the most significant gains at lower ranges (100 M to 10B), followed by somewhat weaker improvements, and essentially no association for Gkn/Grw, at higher parameter counts.These results are supported by Hoffmann et al. (2022), who demonstrated that for compute-optimal training, both the model size and the number of training tokens should be scaled equally.That is, increasing model parameters without also increasing the number of training tokens proportionally should not be expected to improve LLM performance uniformly.Such a perspective is somewhat analogous to neuronal density and cognitive abilities in biological organisms.While the cerebral cortex of humans and other primates has a higher neuronal density compared to other mammals, it is also the intricate patterns of connectivity and the hierarchical organization of these densely packed neurons that enable advanced cognitive functions like language, reasoning, and problem-solving (Herculano-Houzel, 2009;Roth &amp; Dicke, 2005).</p>
<p>Limitations</p>
<p>First, the breadth of the tests in our 12-test battery may be regarded as limited.In particular, our 12-test battery did not include assessments from several important CHC stratum II dimensions, such as Gv (visual processing), Gsm (short-term memory), and Gs (processing speed).Unfortunately, none of the tests within the Hugging Face database fall into these stratum II categories.This limitation reflects the nature of the tests typically used to evaluate LLMs, which are fundamentally verbal in nature.Consequently, it is unreasonable to expect LLMs to be successful at solving visual-spatial problems.Moreover, short-term memory and processing speed have not yet been considered as dimensions for benchmarking LLMs, despite their significant roles in human intelligence (Conway et al., 2013;Jensen, 2006).It is hoped that future benchmarks will address this gap by incorporating tests that evaluate memory span and processing speed.</p>
<p>Additionally, as noted above, none of the included tests can be justifiably regarded as relatively pure indicators of Gf.While good quality Gf tests often involve visual items (e.g., figural matrices), there are high-quality verbal approaches to the measurement of Gf (Beauducel et al., 2001).For example, analogical reasoning (e.g., "Lawyer is to Client as Doctor is to <strong><em>_</em>"), inductive reasoning (e.g., determining the next letter in a sequence like "A, C, E, G, </strong>__"), and logical reasoning (e. g., "All mammals are animals.All dogs are mammals.Therefore, all dogs are ____").All things considered, despite the lack of breadth in our test battery, our results may be considered at least tentatively suggestive of a general factor of artificial ability, which will ideally be re-tested in future when the breadth of tests included in large scale databases is expanded.</p>
<p>Critics might argue that not all models in our analysis were sufficiently distinct to be considered separate cases, potentially inflating the correlations between model test performances.To address this concern, we employed three approaches to exclude insufficiently distinct cases.In our most conservative subsample, we omitted 85% of the models (3271 out of 3862), retaining only 591 for analysis.Beyond architecture (neural network layers, connections, and main components), model size, and even training data, there are many characteristics associated with a language model that can be expected to impact performance, including training duration, input representation (static versus dynamic), hyperparameters (batch sizes), objective (e.g., Masked Language Model; Next Sentence Prediction), data augmentation (artificially increase the size of the training dataset), tokenization (e.g., WordPiece; byte-level BPE), and optimization algorithms (e.g., Adam or Stochastic Gradient Descent).Thus, we believe our most conservative sample essentially represents what can be considered in practice the relatively unique models available in the first half of 2024.</p>
<p>As another limitation, we examined only one predictor of LLM performance.As noted, in addition to the number of model parameters, numerous other factors are expected to impact LLM performance, including the quantity and quality of training data, model architecture, tokenization, hyperparameters, and fine-tuning (Hoffmann et al., 2022).We did not have access to such information for a sufficiently large number of models to examine these factors statistically.Consequently, future research should consider examining these potential predictors as more comprehensive databases of LLM performance become available.</p>
<p>Finally, we acknowledge the possibility that LLMs may not exhibit true intelligence.After IBM's Watson defeated two American Jeopardy!champions in 2011, Detterman (2011) argued that this achievement did not necessarily indicate true intelligence, as that version of Watson was specifically designed to answer Jeopardy!questions and would likely perform poorly on reasoning tasks.Consequently, Detterman (2011) proposed that a more meaningful test of a computer's intelligence would involve a unique battery of IQ tests, developed by human intelligence experts.This challenge would have two levels: the first allowing data and algorithms to be supplied post hoc, similar to Watson's Jeopardy!preparation, and the second requiring only pre-programmed algorithms, forcing the computer to self-organize information as humans do.Only AI systems that answer questions on the second test would be considered to manifest true intelligence.</p>
<p>Although the tests utilized in the current investigation were not crafted by experts in human intelligence, there is awareness in the field that LLMs should not be specifically trained upon the benchmark tests employed to evaluate their performance (Lyu et al., 2021).Consequently, it may be posited that modern LLMs have, to some extent, met the criteria of Detterman (2011) second challenge.However, it is widely acknowledged that even more modern AI systems often struggle to consistently generalize their learned capabilities effectively (Vafa et al., 2024).Moreover, LLMs are prone to making certain types of errors that might be effortlessly avoided by humans, even those with relatively lower cognitive abilities (Tyen et al., 2023).</p>
<p>Considering the importance of generalizability in defining intelligence, some researchers have argued that evidence for true intelligence in AI systems remains limited (van der Maas et al., 2021).More recently, Gignac and Szodorai (2024) contended that, given the nature of LLM development and training, and the essential need for novelty in intelligence testing, there may be more evidence supporting artificial achievement/expertise than artificial intelligence.Finally, beyond the considerations of generalizability and training, some argue that true intelligence includes self-awareness and the capacity for autonomous improvement through self-evaluation (e.g., Bostrom, 2014;Mitchell, 2019;Sternberg, 2011).Correspondingly, a distinction is often made between weak AI, designed for specific tasks without true understanding or consciousness, and strong AI, which can understand, learn, and exhibit consciousness similar to human intelligence (Neubauer, 2021).Awareness and self-improvement are characteristics that were not assessed in our study of LLMs.</p>
<p>Thus, while our findings suggest the presence of a general factor of ability in LLMs, it is unclear whether this factor represents true artificial general intelligence or merely artificial general achievement.Regardless of the validity of Gignac and Szodorai (2024) conclusions, it is noteworthy that current LLMs exhibit a positive manifold -a phenomenon where performance on one task positively correlates with performance on others.This characteristic mirrors a fundamental property observed in human cognitive abilities (Jensen, 1998).</p>
<p>Conclusion</p>
<p>Individual differences in LLM capacities, similar to human cognitive abilities, result in a strong positive manifold.Consequently, models that perform well on one task also tend to perform well on others, suggesting the possibility of underlying general processes.Number of model parameters was found to be an appreciable, positive predictor of general and Gkn/Grw LLM performance.However, in the absence of other complementary model characteristics (e.g., number of tokens), the number of model parameters is likely to manifest an effect of diminishing returns.Our findings help describe the structure of artificial system capabilities and underscore the potential for further optimizing LLM performance through a balanced approach to model design.Additional work investigating LLM performance with differential psychology approaches may facilitate further advancements in both artificial and human intelligence research.</p>
<p>CRediT authorship contribution statement</p>
<p>David Ilić: Writingreview &amp; editing, Software, Methodology, Investigation, Formal analysis, Data curation, Conceptualization.Gilles E. Gignac: Writingoriginal draft, Methodology, Investigation, Formal analysis, Conceptualization.</p>
<p>Declaration of generative AI and AI-assisted technologies in the writing process</p>
<p>During the preparation of this work the authors used ChatGPT, Claude, and Perplexity to help with the generation of R scripts, as well as to suggest superior and more concise writing.After using these tools/ services, the authors reviewed and edited the content as needed and take full responsibility for the content of the publication.</p>
<p>ability factor scores was r = 0.54, 95% CI: [0.48, 0.59].The corresponding Spearman correlation was r = 0.62, 95% CI: [0.60, 0.67].A nonlinear model (cubic spline) fit the relationship between parameter count and general ability scores significantly better than a linear model, F(2, 573) = 27.93,p &lt; .001,Δη 2 = 0.063.Next, we examined the nature of the association in a scatter plot with a LOESS regression line of fit.As there were only 10 LLMs with more than 80 billion parameters, we restricted the scatter plot analysis to values less than 80 billion parameters.</p>
<p>Fig. 1 .
1
Fig. 1.Latent Variable model with completely standardized coefficients.Note.N = 591; AGA = artificial general ability; Gkn = domain-specific knowledge; Grw = reading/writing; all coefficient statistically significant, p &lt; .001;seeTable 1 for model indicator descriptions; see Table S2 for 95% CIs.</p>
<p>Table 1
1
Selected LLM Benchmark Tests and the Corresponding CHC Model Categorisations.classifications, number of items, and test score reliabilities, see Table 1. 1
StratumStratum I AbilityTestsModelItemsαIIIndicatorAbilityNameQuantitativeElementaryGfReasoningMathematicsRQ510.74QuantitativeGfReasoningGSM8KGSM8K13190.99GeneralSequentialGfReasoningHellaswagHellaswag10,0420.99InternationalLaw, BusinessLaw &amp; EthicsEthics,GknKnowledgePhilosophyEthics5320.97MedicalGenetics,ClinicalKnowledge,Human Aging,Health ScienceHumanGknKnowledgeSexualityHealth7190.97Global Facts,Miscellaneous,ComputerMiscellaneousSecurity,GknKnowledgeMarketingMisc.12170.87ReadingHS EuropeanGrwComprehensionHistoryEuro. Hist440.96ReadingGrwComprehensionHS US HistoryUS Hist.480.97ReadingGrwComprehensionWinograndeWinogrande12670.99High SchoolStatistics,AbstractMathematicalAlgebra,GqKnowledgeEconometricsKM530.93MathematicalElementaryGqAccomplishmentMathematicsA3.E410.87ElementaryMathematics,MathematicalHigh SchoolGqAccomplishmentMathematicsA3.HS290.72
Note.Gf = fluid reasoning; Gkn = domain-specific knowledge; Grw = reading/ writing; Gq = quantitative knowledge; α = internal consistency reliability.model</p>
<p>Table 2
2
Benchmark LLM test performance descriptive statistics and Pearson inter-correlations.
TestII1.2.3.4.5.6.7.8.9.10.11.MSDMdnskewkurtosis1. HellaswagGf1.072.1821.0181.96− 1.04− 0.272. RQGf0.451.032.8310.9931.370.370.103. GSM8KGf0.580.621.018.0921.418.611.05− 0.214. KMGq0.610.730.801.043.3520.1337.740.52− 0.825. A3.EGq0.370.350.620.631.031.4517.2429.270.44− 0.856. A3.HSGq0.540.560.670.730.651.033.1915.6933.330.700.427. European HistoryGrw0.790.620.680.800.510.641.060.7029.1170.45− 0.28− 1.618. US HistoryGrw0.820.600.670.780.500.640.971.065.3431.4879.17− 0.32− 1.649. WinograndeGrw0.950.560.690.730.470.600.860.891.074.2713.8279.09− 0.49− 1.1010. EthicsGkn0.850.650.730.840.550.700.940.950.911.051.0719.9357.03− 0.20− 1.4711. HealthGkn0.830.680.750.860.590.710.940.950.900.981.050.0519.5953.98− 0.11− 1.5012. MiscellaneousGkn0.860.630.710.810.550.690.950.960.910.990.9850.9419.8058.60− 0.32− 1.54
For reasons that are unclear, the Bryan and Mayer meta-analysis did not include Schipolowski et al.'s (2014) results.D.Ilić and G.E. Gignac   Intelligence 106 (2024) 101858
Data availabilityData and scripts available on the OSF linkDeclaration of competing interestThe authors declare that they have no conflict of interest.Appendix A. Supplementary dataSupplementary data to this article can be found online at https://doi.org/10.1016/j.intell.2024.101858.D.Ilić and G.E. GignacIntelligence 106 (2024) 101858
What is AGI. 2024. May 26 thAmazon Web Services</p>
<p>R Anil, A M Dai, O Firat, M Johnson, D Lepikhin, A Passos, Y Wu, arXiv:2305.10403Palm 2 technical report. 2023arXiv. preprint</p>
<p>A general intelligence factor in dogs. R Arden, M J Adams, Intelligence. 552016</p>
<p>Perspectives on fluid and crystallized intelligence: Facets for verbal, numerical, and figural intelligence. A Beauducel, B Brocke, D Liepmann, Personality and Individual Differences. 3062001</p>
<p>A method based on the Levenshtein distance metric for the comparison of multiple movement patterns described by matrix sequences of different length. J Beernaerts, E Debever, M Lenoir, B De Baets, N Van De Weghe, Expert Systems with Applications. 1152019</p>
<p>Superintelligence: Paths, dangers, strategies. N Bostrom, 2014Oxford University Press</p>
<p>Exploring the dimensionality of digit span. S C Bowden, V M Petrauskas, F J Bardenhagen, C E Meade, L C Simpson, Assessment. 2022013</p>
<p>Differentiation hypotheses of intelligence: A systematic review of the empirical evidence and an agenda for future research. M Breit, M Brunner, D Molenaar, F Preckel, Psychological Bulletin. 1487-82022</p>
<p>A meta-analysis of the correlations among broad intelligences: Understanding their relations. V M Bryan, J D Mayer, Intelligence. 811014692020</p>
<p>The higher-stratum structure of cognitive abilities: Current evidence supports g and about ten broad factors. J B Carroll, Arthur R. Jensen2003PergamonThe scientific study of general intelligence: Tribute to</p>
<p>Manymome: An R package for computing the indirect effects, conditional effects, and conditional indirect effects, standardized or unstandardized, and their bootstrap confidence intervals, in many (though not all) models. S F Cheung, S H Cheung, Behavior Research Methods. 2023</p>
<p>Locally weighted regression: An approach to regression analysis by local fitting. W S Cleveland, S J Devlin, Journal of the American Statistical Association. 834031988</p>
<p>K Cobbe, V Kosaraju, M Bavarian, M Chen, H Jun, L Kaiser, M Plappert, J Tworek, J Hilton, R Nakano, C Hesse, J Schulman, arXiv.preprintarXiv:2110.14168Training verifiers to solve math word problems. 2021</p>
<p>Working memory and intelligence: An overview. A R A Conway, B N Macnamara, P M J Engel De Abreu, Working memory: The connected intelligence. T P Alloway, R G Alloway, Psychology Press2013</p>
<p>Evaluation of parallel analysis methods for determining the number of factors. A V Crawford, S B Green, R Levy, W J Lo, L Scott, D Svetina, M S Thompson, Educational and Psychological Measurement. 7062010</p>
<p>The reliability of estimating visual working memory capacity. M Dai, Y Li, S Gan, F Du, Scientific Reports. 9111552019</p>
<p>L A Damerius, J M Burkart, M A Van Noordwijk, D B Haun, Z K Kosonen, B M Galdikas, C P Van Schaik, General cognitive abilities in orangutans (Pongo abelii and Pongo pygmaeus). 201974</p>
<p>Genetic foundations of human intelligence. I J Deary, W Johnson, L M Houlihan, Human Genetics. 1262009</p>
<p>A theoretical framework to formalize AGI-hard problems. P Demasi, J L Szwarcfiter, A J Cruz, 3d conference on artificial general intelligence (AGI-2010). Atlantis Press2010. June</p>
<p>A challenge to Watson. D K Detterman, Intelligence. 392-32011</p>
<p>Correlations of mental tests with each other and with cognitive variables are highest for low IQ groups. D K Detterman, M H Daniel, Intelligence. 1341989</p>
<p>Neuronal factors determining high intelligence. U Dicke, G Roth, Philosophical Transactions of the Royal Society, B: Biological Sciences. 3712016. 1685. 20150180</p>
<p>Investigating the theoretical structure of the differential ability scales-Second edition through hierarchical exploratory factor analysis. S C Dombrowski, R J Mcgill, G L Canivez, C H Peterson, Journal of Psychoeducational Assessment. 3712019</p>
<p>How abilities in large language models are affected by supervised fine-tuning data composition. G Dong, H Yuan, K Lu, C Li, M Xue, D Liu, W Wang, Z Yuan, C Zhou, J Zhou, arXiv.preprintarXiv:2310.054922023</p>
<p>A density-based algorithm for discovering clusters in large spatial databases with noise. M Ester, H.-P Kriegel, J Sander, X Xu, Proceedings of the 2nd International Conference on Knowledge Discovery and Data Mining (KDD-96). the 2nd International Conference on Knowledge Discovery and Data Mining (KDD-96)AAAI Press1996</p>
<p>Relations between measures of Cattellhorn-Carroll (CHC) cognitive abilities and mathematics achievement across the school-age years. R G Floyd, J J Evans, K S Mcgrew, Psychology in the Schools. 4022003</p>
<p>Working memory components that predict word problem solving: Is it merely a function of reading, calculation, and fluid intelligence?. W Fung, H L Swanson, Memory &amp; Cognition. 452017</p>
<p>Dynamic mutualism versus g factor theory: An empirical test. G E Gignac, Intelligence. 422014a</p>
<p>Fluid intelligence shares closer to 60% of its variance with working memory capacity and is a better indicator of general intelligence. G E Gignac, Intelligence. 472014b</p>
<p>Raven's is not a pure measure of general intelligence: Implications for g factor theory and the brief measurement of g. G E Gignac, Intelligence. 522015</p>
<p>Defining intelligence: Bridging the gap between human and artificial perspectives. G E Gignac, E T Szodorai, Intelligence. 1042024. 101832</p>
<p>Bifactor modeling and the estimation of modelbased reliability in the WAIS-IV. G E Gignac, M W Watkins, Multivariate Behavioral Research. 4852013</p>
<p>Digit span is (mostly) related linearly to general intelligence: Every extra bit of span counts. G E Gignac, L G Weiss, Psychological Assessment. 27413122015</p>
<p>A meta-analysis of dependability coefficients (test-retest reliabilities) for measures of the big five. T Gnambs, Journal of Research in Personality. 522014</p>
<p>A primer on neural network models for natural language processing. Y Goldberg, Journal of Artificial Intelligence Research. 572016</p>
<p>Large and fast human pyramidal neurons associate with intelligence. N A Goriounova, D B Heyer, R Wilbers, M B Verhoog, M Giugliano, C Verbist, H D Mansvelder, 2018elife, 7, Article e41714</p>
<p>On the hierarchical structure of ability and personality. J.-E Gustafsson, Intelligence and personality: Bridging the gap in theory and measurement. J M Collis, &amp; S Messick, Mahwah, NJErlbaum2001</p>
<p>Find it on a map: Country location identification in a university geography classroom, 2016-2022. P D Hagge, Journal of Geography. 12252023</p>
<p>D Hendrycks, C Burns, S Basart, A Zou, M Mazeika, D Song, J Steinhardt, arXiv:2009.03300Measuring massive multitask language understanding. 2020arXiv. preprint</p>
<p>The human brain in numbers: A linearly scaled-up primate brain. S Herculano-Houzel, Frontiers in Human Neuroscience. 3312009</p>
<p>Stability and change in adult intelligence: II. Simultaneous analysis of longitudinal means and covariance structures. C Hertzog, K W Schaie, Psychology and Aging. 321221988</p>
<p>Training compute-optimal large language models. J Hoffmann, S Borgeaud, A Mensch, E Buchatskaya, T Cai, E Rutherford, L Sifre, ArXiv. 2022</p>
<p>Model complexity of deep learning: A survey. X Hu, L Chu, J Pei, W Liu, J Bian, Knowledge and Information Systems. 632021</p>
<p>Hugging Face Hub documentation. Hugging Face, 2024</p>
<p>S Imani, L Du, H Shrivastava, arXiv:2303.05398Mathprompter: Mathematical reasoning using large language models. 2023arXiv. preprint</p>
<p>Multidimensional aptitude battery II (MAB-II. D N Jackson, 2003Measurement Instrument</p>
<p>The g factor: The science of mental ability. A R Jensen, 1998Praeger</p>
<p>Clocking the mind: Mental chronometry and individual differences. A R Jensen, 2006Elsevier</p>
<p>What is a good g?. A R Jensen, L J Weng, Intelligence. 1831994</p>
<p>Distinctive properties of biological neural networks and recent advances in bottom-up approaches toward a better biologically plausible neural network. I Jeon, T Kim, Frontiers in Computational Neuroscience. 172023</p>
<p>The structure of human intelligence: It is verbal, perceptual, and image rotation (VPR), not fluid and crystallized. W Johnson, T J Bouchard, Jr, Intelligence. 3342005</p>
<p>Little jiffy, mark IV. H F Kaiser, J Rice, Educational and Psychological Measurement. 3411974</p>
<p>S Kazi, A Elmahdy, Top large language models (LLMs): GPT-4, LLaMA 2, mistral 7B, ChatGPT, and more. 2023. October 17blog post</p>
<p>Vectara. </p>
<p>Y Kuratov, A Bulatov, P Anokhin, D Sorokin, A Sorokin, M Burtsev, arXiv:2402.10790search of needles in a 10M haystack: Recurrent memory finds what LLMs miss. 2024arXiv. preprint</p>
<p>The relation between fluid intelligence and the general factor as a function of cultural background: A test of Cattell's investment theory. A V Kvist, J E Gustafsson, Intelligence. 3652008</p>
<p>What is fluid intelligence? Can it be improved?. P Kyllonen, H Kell, Cognitive abilities and educational outcomes: A festschrift in honour of Jan-Eric Gustafsson. M Rosén, K Yang Hansen, &amp; U Wolff, Springer International Publishing/Springer Nature2017</p>
<p>Binary codes capable of correcting deletions, insertions, and reversals. V I Levenshtein, Soviet Physics Doklady. 1081966</p>
<p>Speciality vs generality: An empirical study on catastrophic forgetting in fine-tuning foundation models. Y Lin, L Tan, H Lin, Z Zheng, R Pi, J Zhang, T Zhang, arXiv:2309.062562023</p>
<p>An empirical study of the impact of data splitting decisions on the performance of AIOps solutions. Y Lyu, H Li, M Sayagh, Z M Jiang, A E Hassan, ACM Transactions on Software Engineering and Methodology (TOSEM). 3042021</p>
<p>How much intelligence is there in artificial intelligence? A 2020 update. H L Van Der Maas, L Snoek, C E Stevenson, Intelligence. 872021. Article 101548</p>
<p>The risks associated with artificial general intelligence: A systematic review. S Mclean, G J Read, J Thompson, C Baber, N A Stanton, P M Salmon, Journal of Experimental &amp; Theoretical Artificial Intelligence. 3552023</p>
<p>Artificial intelligence: A guide for thinking humans. M Mitchell, 2019Farrar, Straus and Giroux1st ed.</p>
<p>The poor fit of model fit for selecting number of factors in exploratory factor analysis for scale evaluation. A K Montoya, M C Edwards, Educational and Psychological Measurement. 8132021</p>
<p>Inspection time and measured intelligence. T Nettelbeck, M Lally, British Journal of Psychology. 6711976</p>
<p>The future of intelligence research in the coming age of artificial intelligence-With a special consideration of the philosophical movements of transand posthumanism. A C Neubauer, Intelligence. 871015632021</p>
<p>. D Ilić, G E Gignac, Intelligence. 1061018582024</p>
<p>A decade of test-retest reliability of functional connectivity: A systematic review and meta-analysis. S Noble, D Scheinost, R T Constable, Neuroimage. 2032019. 116157</p>
<p>J C Nunnally, I H Bernstein, Psychometric theory. McGraw-Hill19943rd ed.</p>
<p>From machine learning to artificial general intelligence: A roadmap and implications. O I Obaid, Mesopotamian Journal of Big Data. 2023. 2023</p>
<p>Using confidence intervals for assessing reliability of real tests. P R Oosterwijk, L A Van Der Ark, K Sijtsma, Assessment. 2672019</p>
<p>Human-like problemsolving abilities in large language models using ChatGPT. G Orrù, A Piarulli, C Conversano, A Gemignani, Frontiers in Artificial Intelligence. 611993502023</p>
<p>How predictable is language model benchmark performance?. D Owen, arXiv.preprintarXiv:2401.047572024</p>
<p>Can large language models put 2 and 2 together? Probing for entailed arithmetical relationships. D Panas, S Seth, V Belle, arXiv:2404.194322024arXiv. preprint</p>
<p>Study of variability of cognitive performance in captive fallow deer (Dama dama) through g and c factors. C I Pastrana, F J N Gonzalez, M G P Inostroza, A A Arbulu, J V D Bermejo, M J R Aguilera, Journal of Veterinary Behavior. 472022</p>
<p>Limitations of language models in arithmetic and symbolic induction. J Qian, H Wang, Z Li, S Li, X Yan, arXiv:2208.050512022arXiv. preprint</p>
<p>The Raven's progressive matrices: Change and stability over culture and time. J Raven, Cognitive Psychology. 4112000</p>
<p>Artificial general intelligence: Roadmap to achieving human-level capabilities. A Rayhan, R Rayhan, S Rayhan, 2023</p>
<p>Lavaan: An R package for structural equation modeling. Y Rosseel, 10.18637/jss.v048.i02Journal of Statistical Software. 4822012</p>
<p>Evolution of the brain and intelligence. G Roth, U Dicke, Trends in Cognitive Sciences. 952005</p>
<p>Winogrande: An adversarial Winograd Schema challenge at scale. K Sakaguchi, R Le Bras, C Bhagavatula, Y Choi, Communications of the ACM. 6492021</p>
<p>On the nature of crystallized intelligence: The relationship between verbal ability and factual knowledge. S Schipolowski, O Wilhelm, U Schroeders, Intelligence. 462014</p>
<p>The Cattell-Horn-Carroll theory of cognitive abilities. W J Schneider, K S Mcgrew, Contemporary intellectual assessment: Theories, tests, and issues. D P Flanagan, E M Mcdonough, The Guilford Press20184th ed.</p>
<p>Intelligence and giftedness. R J Sternberg, G Tyen, H Mansoor, P Chen, T Mak, V Cȃrbune, arXiv:2311.08516LLMs cannot find reasoning errors, but can correct them! arXiv. R J Sternberg, L Jarvin, E L Grigorenko, Cambridge University Press2011. 2023Explorations in giftedness. preprint</p>
<p>Who's the best detective? Large language models vs. traditional machine learning in detecting incoherent fourth grade math answers. F Urrutia, R Araya, Journal of Educational Computing Research. 82024</p>
<p>Do large language models perform the way people expect? Measuring the human generalization function. K Vafa, A Rambachan, S Mullainathan, arXiv:2406.013822024arXiv. preprint</p>
<p>Mental rotations, a group test of threedimensional spatial visualization. S G Vandenberg, A R Kuse, Perceptual and Motor Skills. 4721978</p>
<p>The association between intelligence and face processing abilities: A conceptual and meta-analytic review. D L Walker, R Palermo, Z Callis, G E Gignac, Intelligence. 962023. 101718</p>
<p>Spearman's g found in 31 non-Western nations: Strong evidence that g is a universal phenomenon. R T Warne, C Burningham, Psychological Bulletin. 14532019</p>
<p>WAIS-IV: Wechsler adult intelligence scale-Fourth edition: Technical and interpretive manual. D Wechsler, Wechsler Adult Intelligence Scale. Pearson, D Wechsler, Pearson1981. 2008a. 2008bWechsler Adult Intelligence Scale-Revised</p>
<p>C Welty, P Paritosh, L Aroyo, arXiv:1911.01875Metrology for AI: From benchmarks to instruments. 2019arXiv. preprint</p>
<p>ggplot2: Elegant graphics for data analysis. H Wickham, 2016Springer-VerlagNew York</p>
<p>ChatGLM-Math: Improving math problem-solving in large language models with a self-critique pipeline. Y Xu, X Liu, X Liu, Z Hou, Y Li, X Zhang, Y Dong, arXiv:2404.028932024arXiv. preprint</p>
<p>How well do large language models perform in arithmetic tasks?. Z Yuan, H Yuan, C Tan, W Wang, S Huang, arXiv.preprintarXiv:2304.020152023</p>
<p>Hellaswag: Can a machine really finish your sentence?. R Zellers, A Holtzman, Y Bisk, A Farhadi, Y Choi, arXiv.preprintarXiv:1905.078302019</p>
<p>A survey of large language models. W X Zhao, K Zhou, J Li, T Tang, X Wang, Y Hou, J Wen, 2023</p>
<p>. D Ilić, G E Gignac, Intelligence. 1061018582024</p>            </div>
        </div>

    </div>
</body>
</html>