<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2421 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2421</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2421</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-65.html">extraction-schema-65</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <p><strong>Paper ID:</strong> paper-273502005</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2410.15048v2.pdf" target="_blank">MorphAgent: Empowering Agents through Self-Evolving Profiles and Decentralized Collaboration</a></p>
                <p><strong>Paper Abstract:</strong> Large Language Model (LLM) based multi-agent systems (MAS) have shown promise in tackling complex tasks, but often rely on predefined roles and centralized coordination, limiting their adaptability to evolving challenges. This paper introduces MorphAgent, a novel Autonomous, Self-Organizing, and Self-Adaptive Multi-Agent System for decentralized agent collaboration that enables agents to dynamically evolve their roles and capabilities. Our approach employs self-evolving agent profiles, optimized through three key metrics, guiding agents in refining their individual expertise while maintaining complementary team dynamics. MorphAgent implements a two-phase process: a Profile Update phase for profile optimization, followed by a Task Execution phase where agents continuously adapt their roles based on task feedback. Our experimental results show that MorphAgent outperforms existing frameworks in terms of task performance and adaptability to changing requirements, paving the way for more robust and versatile multi-agent collaborative systems.</p>
                <p><strong>Cost:</strong> 0.018</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2421.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2421.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MORPHAGENT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>MORPHAGENT: Autonomous, Self-Organizing, and Self-Adaptive Multi-Agent System</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A decentralized LLM-based multi-agent framework that endows agents with dynamic, self-evolving profiles and metric-driven profile optimization to achieve self-organization and self-adaptability for robust collaborative problem solving.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>MORPHAGENT</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Decentralized multi-agent system where each agent is an LLM-driven actor with a dynamic profile p_i = (f_i, c_i, r_i) that evolves via a profile update function ψ implemented using an LLM. The system runs an iterative two-phase pipeline: (1) Profile Update phase (up to 5 rounds with early stopping) that optimizes profiles by maximizing three metrics (Role Clarity Score RCS, Role Differentiation Score RDS, and Task-Role Alignment Score TRAS) via adaptive prompts and peer observations, and (2) Task Execution phase where optimized agents perform Observe-Think-Act cycles (planning via ReAct/Reflexion patterns) and can re-enter profile updates upon feedback or task/environment changes. Coordination is emergent and decentralized: agents choose collaborators based on local observations, past interactions and profile similarity/dissimilarity; no central controller is used.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>3 (benchmarks); tested with 3/5/10 in scalability experiments</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>Agents are initialized homogeneously and self-specialize through profile updates; observed emergent roles include coordination/communication agent, development (implementation) agent, debugging/verification agent, and domain-specific evaluators (example from case study: communication, development, debugging in software-engineering task). Profiles explicitly encode functional capabilities, contextual adjustments, and interaction rules.</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>Idea/task decomposition (implicit via profile update and planning), planning and execution (Observe-Think-Act cycles), implementation/subtask execution, iterative evaluation and refinement (profile updates and task feedback), and role-refinement/self-reflection; demonstrated on code generation, general reasoning, mathematical reasoning, and a software-engineering case study.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>Decentralized self-organization: pairwise and local-neighborhood decisions determine interaction topology; dynamic topology emerges from agents selecting collaborators based on local observations, past interactions and profile embeddings. Coordination alternates between profile-optimization rounds (synchronous up to a limit) and asynchronous task execution rounds with consensus via a 'skip' action (when all agents choose skip, execution ends).</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>Natural language prompts/messages mediated by LLMs, augmented by structured prompt templates and occasional constrained JSON-format self-reflection outputs (Appendix examples). Profile and metric data are represented as textual profiles and embeddings (Sentence-BERT 'all-MiniLM-L6-v2'). Agents exchange actions/observations and receive adaptive textual feedback prompts; embeddings are used for similarity/dissimilarity calculations.</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>Metric-driven adaptive prompts: agents receive targeted feedback based on changes in RCS, RDS, and TRAS (e.g., requests to clarify role, differentiate, or better align to task). Agents perform self-reflection (structured JSON template in prompts) and peer observation; task outcomes (including partial failures) trigger profile updates. During task execution agents log outcomes and can re-enter Phase 1 upon feedback or detection of requirement changes.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>Iterative rounds: Profile Update phase runs up to 5 rounds initially (early stopping if metrics improve by >0.1); subsequent adjustments often run one lightweight round. During Task Execution, agents communicate each interaction round (Observe-Think-Act cycles) and exchange feedback whenever failures or task changes occur (on-demand return to profile update).</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>General scientific/research-support tasks demonstrated on Code Generation (BigCodeBench), General Reasoning (BigBenchHard), Mathematical Reasoning (MATH), and a software-engineering case study; cross-domain adaptation experiments (domain shifts) also evaluated.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Reported metrics include task accuracy (percentage) on benchmarks, RCS/RDS/TRAS profile metric values, and average interaction rounds. Example numbers: benchmark accuracy on BigCodeBench: MORPHAGENT 52.00% (GPT-4o-mini backbone) vs ablation baselines; robustness under high node-failure (failure prob = 0.8): MORPHAGENT retains ~40.10%–54.00% across tasks while baselines drop to ~1.43%–19.52%. Scalability results (MATH, GPT-4o-mini): 3 agents => 66.67% accuracy, avg rounds 1.5456; 5 agents => 66.19% accuracy, avg rounds 1.6110; 10 agents => 65.71% accuracy, avg rounds 2.06.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared experimentally against GPTSwarm, AgentVerse, and AFLOW on Code Generation, General Reasoning, and Mathematical Reasoning tasks; MORPHAGENT consistently outperforms these baselines across LLM backbones and shows superior robustness in node-failure and domain-shift scenarios.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>Improved robustness to node failure (retains substantial accuracy at high failure rates: 40.10–54.00% vs baselines 1.43–19.52%), better cross-domain adaptability with smaller accuracy drops under domain shift, higher benchmark accuracy (e.g., +~1.33–13 percentage points depending on comparison), and emergent specialization reducing redundancy (higher RCS and RDS correlated with better performance).</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>Computational and communication overhead from continuous profile updating; increasing number of agents raises average interaction rounds and communication cost (not linear but present); potential for profile update cost to be significant in large deployments (not fully optimized).</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td>Yes — ablation on using none or single metric vs all three: using no additional metric (+ None) yields 50.67% (GPT-4o-mini) and 38.33% (GPT-3.5-Turbo) baselines; RCS-only: 50.00% / 39.33%; RDS-only: 41.66% / 37.00%; TRAS-only: 49.66% / 35.33%; integrated RCS+RDS+TRAS (MORPHAGENT): 52.00% / 43.33% — showing the combined metrics outperform single-metric configurations.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td>Recommended initial Profile Update phase of up to 5 rounds with early stopping criterion (stop if all three metrics improve by >0.1); experimental default of N=3 agents for benchmarks (used throughout main evaluations); subsequent lightweight profile updates use a single round. LLM temperature used in experiments: 0.7; embeddings computed with Sentence-BERT 'all-MiniLM-L6-v2'.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'MorphAgent: Empowering Agents through Self-Evolving Profiles and Decentralized Collaboration', 'publication_date_yy_mm': '2024-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2421.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2421.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPTSwarm</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPTSwarm: Language agents as optimizable graphs</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An MAS approach that models agents as nodes in an optimizable graph (SOP-like workflows/subnets) to coordinate agent actions; cited as a baseline SOP-style system and compared experimentally.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>GPTSwarm: Language agents as optimizable graphs</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>GPTSwarm</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Described as an approach that models agents as optimizable graph/subnet of action nodes and constructs workflows to coordinate tasks; characterized by structured SOP-like coordination rather than fully emergent decentralized self-organization.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>variable (paper compares using N=3 agents for baselines)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>SOP/workflow-defined subroles (action nodes) — implementation details not provided in this paper beyond being SOP/workflow-based.</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>Task decomposition and workflow-driven execution (SOP-style pipeline), typically used for structured task execution such as code generation.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>SOP-based workflow / graph-based coordination (centralized or pre-defined orchestration of nodes/workflows rather than emergent self-organization).</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>Not specified in detail in this paper; described as constructing workflows/subnets (implies structured messages/actions rather than free-form emergent natural-language peer messaging).</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>Not detailed here; treated as baseline that does not implement MORPHAGENT's dynamic profile metric-driven feedback.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>Implied synchronous workflow stages; not detailed.</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>Used as baseline on Code Generation, General Reasoning, and Mathematical Reasoning benchmarks in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Reported in paper as baseline in Figures/Tables (exact per-task numbers not enumerated here beyond comparative statements); cited that GPTSwarm experiences large drops under domain shift (LEVEL-2, ~45% drop when shifting to MATH).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared to MORPHAGENT: GPTSwarm shows much larger performance degradation under domain shift and node failure compared to MORPHAGENT.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>Provides structured coordination and can be efficient in predefined workflow tasks; good for adhering to SOPs.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>Poor adaptability to domain shifts and vulnerability to node failures; lacks fully decentralized emergent role evolution according to the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td>No internal ablation reported here; used as a baseline in MORPHAGENT experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td>Not provided in this paper beyond being used as a baseline in the experimental setup.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'MorphAgent: Empowering Agents through Self-Evolving Profiles and Decentralized Collaboration', 'publication_date_yy_mm': '2024-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2421.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2421.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AgentVerse</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>AgentVerse: Facilitating multi-agent collaboration and exploring emergent behaviors</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A multi-agent framework referenced as an approach that supports multi-agent collaboration but relies on centralized monitoring or coordinators in some instantiations; used as a baseline for comparison.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>AgentVerse</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Described in the paper as a system that facilitates multi-agent collaboration and explores emergent behaviors; characterized in related work as relying on centralized mechanisms (single role or subset of agents monitoring and evaluating system performance).</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>variable (used as a baseline with N=3 in experiments)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>Often includes specialized monitoring/evaluation roles (central coordinator); exact specializations not detailed in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>Collaborative execution and evaluation phases; specifics not detailed here.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>Centralized or semi-centralized coordination (a single role or subset of agents monitors and evaluates overall performance).</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>Not specified in detail in this paper; implied natural language agent messaging under centralized control.</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>Centralized monitoring/evaluation by coordinator agents; not metric-driven dynamic profiles as in MORPHAGENT.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>Not specified; likely periodic monitoring/evaluation by the coordinator.</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>Used as baseline across Code Generation, General Reasoning, and Mathematical Reasoning benchmarks.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Compared in Figures — MORPHAGENT outperforms AgentVerse across tasks (exact baseline numbers not enumerated in-text here).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>AgentVerse is one of the SOTA baselines compared; MORPHAGENT yields higher robustness and accuracy than AgentVerse in reported experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>Central monitoring can improve focused evaluation and detect failures globally.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>Scalability bottlenecks and potential single-point-of-failure due to centralized monitoring.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td>Not applicable in this paper; AgentVerse used as baseline only.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td>Not provided in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'MorphAgent: Empowering Agents through Self-Evolving Profiles and Decentralized Collaboration', 'publication_date_yy_mm': '2024-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2421.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2421.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AFLOW</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>AFLOW: Automating agentic workflow generation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An SOP/workflow-oriented MAS that constructs workflows for diverse tasks, cited as a baseline SOP-style system.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>AFLOW: Automating agentic workflow generation</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>AFLOW</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Approach that models agents and tasks as automated workflows or subnets of action nodes to generate SOP-like coordination between agents; described as lacking flexibility compared to dynamic profile adaptation.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>variable (baseline experiments use N=3)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>Workflow-defined roles / action-node specialists according to the generated SOP; details not provided here.</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>Workflow-based planning and execution stages for structured tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>Predefined SOP/workflow orchestration (centralized or pre-specified sequences), not decentralized emergent coordination.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>Not detailed in this paper; implied structured workflow messages/prompts.</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>Not described in-depth here; lacks MORPHAGENT's metric-driven iterative profile updates.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>Stage-based according to workflow; not specified.</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>Used as a baseline on code, reasoning, and math benchmarks.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Used for experimental comparison; reported to degrade more under node-failure and domain-shift scenarios relative to MORPHAGENT.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>MORPHAGENT outperforms AFLOW in robustness and adaptability across reported benchmarks.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>Efficient for standardized procedures and predefined workflows.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>Lack of flexibility for unforeseen skills or domain shifts; limited self-adaptability without external coordination.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td>Not applicable here; used as a baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td>Not detailed in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'MorphAgent: Empowering Agents through Self-Evolving Profiles and Decentralized Collaboration', 'publication_date_yy_mm': '2024-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2421.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2421.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MetaGPT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>MetaGPT: Meta programming for a multi-agent collaborative framework</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An MAS that implements human workflows as rigid organizational structures to coordinate multiple agents; cited as an example of a system with predefined roles and limited adaptability.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>MetaGPT: Meta programming for a multi-agent collaborative framework</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>MetaGPT</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Described as implementing human-style workflow with rigid organizational structures and predefined agent roles optimized for tasks like code generation but lacking generalization and flexibility to other tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>variable / not specified in this paper</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>Predefined role-playing agents (e.g., project manager, coder, tester) determined by workflow templates.</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>Workflow-based planning and execution (particularly code generation/workflow-driven projects).</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>Centralized or pre-specified workflow orchestration; rigid organizational structure.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>Role-play prompts/natural language messages constrained by workflow templates.</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>Workflow checkpoints and human-like role interactions; not the autonomous metric-driven feedback used in MORPHAGENT.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>Per workflow stage/checkpoint; not detailed.</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>Software development/code generation primarily (as cited).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Not provided here; described qualitatively as improving code-generation but lacking generalization.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Referenced as an approach with limited adaptability compared to MORPHAGENT.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>Effective for tasks that map well to human workflows.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>Rigidness restricts adaptability to new domains or tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td>Not applicable in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td>Not specified here.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'MorphAgent: Empowering Agents through Self-Evolving Profiles and Decentralized Collaboration', 'publication_date_yy_mm': '2024-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2421.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e2421.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CAMEL</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>CAMEL: Communicative Agents for Mind Exploration</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A role-playing multi-agent approach where agents have predefined roles through role-playing; cited as having difficulty adapting to tasks requiring unforeseen skills.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Camel: Communicative agents for "mind" exploration of large language model society</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>CAMEL</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Employs agents with predefined role-playing to structure multi-agent conversation and task execution. Presented as a related approach that uses predefined roles and thus has limited adaptability to unforeseen requirements.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>variable (not specified here)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>Role-play defined agents (e.g., different persona/roles as needed by the workflow).</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>Collaborative conversation and task execution phases where role-play assists in division of labor.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>Predefined role interactions; not emergent decentralized coordination.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>Natural language role-based conversations.</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>Role-based inter-agent critique/interaction; not metric-driven profile updates.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>Per conversational turn or workflow stage.</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>General multi-agent tasks; cited in context of limitations for unforeseen skill requirements.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Not provided in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Mentioned as related work with constrained adaptability compared to MORPHAGENT.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>Simplicity of role assignment and clearer human-analogous workflows.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>Limited adaptability when novel skills are required.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td>Not provided in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td>Not specified here.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'MorphAgent: Empowering Agents through Self-Evolving Profiles and Decentralized Collaboration', 'publication_date_yy_mm': '2024-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2421.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e2421.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AgentCoder</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>AgentCoder: Multi-agent-based code generation with iterative testing and optimisation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An SOP-style multi-agent system for code generation that iteratively tests and optimizes code; cited as a structured workflow approach in related work.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>AgentCoder: Multi-agent-based code generation with iterative testing and optimisation</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>AgentCoder</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Structured multi-agent approach for code development that uses iteration, testing, and optimization; referenced as part of SOP-based MAS work.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>variable (not specified here)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>Typical roles include code generator, tester, and optimizer per SOP workflows.</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>Implementation/execution and iterative testing/optimization phases for code-generation tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>SOP/workflow-driven iterative pipeline.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>Prompt-driven interactions and test reports (natural language/structured outputs).</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>Iterative testing and optimization loops (test results drive updates).</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>Iteration-driven (after each test/optimization cycle).</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>Code generation and software engineering tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Not reported in this paper (cited as related work).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Referenced as structured workflow approach; MORPHAGENT presented as more adaptive alternative.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>Efficient for testing-driven code improvement.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>Less flexible for open-ended or cross-domain tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td>Not provided here.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td>Not specified.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'MorphAgent: Empowering Agents through Self-Evolving Profiles and Decentralized Collaboration', 'publication_date_yy_mm': '2024-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2421.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e2421.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Criticize-Reflect</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Criticize-Reflect</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A multi-agent approach employing critique and reflection loops among agents; cited as partially supporting self-organization and self-adaptability but relying on centralized elements in some variants.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Criticize-Reflect</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Criticize-Reflect</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Approach that uses critique and reflective loops to improve agent outputs; in related work cited as having some self-organization and adaptability but potentially using centralized orchestration in practice.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>variable (not specified here)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>Roles include generators and critics/reflection agents.</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>Generation and evaluation/reflection phases.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>Critic-reflection interactions; may include centralized aspects per citation context.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>Natural language critique and reflection messages.</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>Critic agents provide feedback and reflection processes inform next actions.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>Iterative after generation steps.</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>General tasks requiring iterative improvement; cited in related work.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Not given in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Positioned among methods that partially support self-organization/self-adaptability.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>Improved output quality via critique/reflection.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>Potential centralization in monitoring/evaluation; limited scalability described.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td>Not provided here.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td>Not specified.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'MorphAgent: Empowering Agents through Self-Evolving Profiles and Decentralized Collaboration', 'publication_date_yy_mm': '2024-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2421.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e2421.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>EvoMAC</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>EvoMAC: Self-evolving multi-agent collaboration networks for software development</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A self-evolving MAS focused on software development that supports self-organization; discussed as related work with some centralized evaluation components in prior variants.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Self-evolving multi-agent collaboration networks for software development</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>EvoMAC</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>An approach that enables agents to self-evolve collaboration networks for software development tasks; cited as partially embodying self-organization and some adaptability features.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>variable (not specified)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>Software-development-focused roles (e.g., coding, review, integration) as per the cited work.</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>Software development lifecycle phases including development, review, and adaptation.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>Self-evolving collaboration networks (decentralized), though some variants rely on monitoring/evaluation components.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>Not detailed in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>Network evolution driven by performance and interactions; details deferred to cited work.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>Not specified here.</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>Software development / code-related tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Not reported in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Cited as related work with partial overlap in goals (self-organization/self-adaptability).</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>Supports emergent specialization and adaptation in software tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>May include centralized evaluators in some implementations; scalability/effectiveness depend on specific design.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td>Not detailed here.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td>Not specified in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'MorphAgent: Empowering Agents through Self-Evolving Profiles and Decentralized Collaboration', 'publication_date_yy_mm': '2024-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>GPTSwarm: Language agents as optimizable graphs <em>(Rating: 2)</em></li>
                <li>Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors <em>(Rating: 2)</em></li>
                <li>AFLOW: Automating agentic workflow generation <em>(Rating: 2)</em></li>
                <li>MetaGPT: Meta programming for a multi-agent collaborative framework <em>(Rating: 2)</em></li>
                <li>Self-evolving multi-agent collaboration networks for software development <em>(Rating: 2)</em></li>
                <li>AgentCoder: Multi-agent-based code generation with iterative testing and optimisation <em>(Rating: 1)</em></li>
                <li>Criticize-Reflect <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2421",
    "paper_id": "paper-273502005",
    "extraction_schema_id": "extraction-schema-65",
    "extracted_data": [
        {
            "name_short": "MORPHAGENT",
            "name_full": "MORPHAGENT: Autonomous, Self-Organizing, and Self-Adaptive Multi-Agent System",
            "brief_description": "A decentralized LLM-based multi-agent framework that endows agents with dynamic, self-evolving profiles and metric-driven profile optimization to achieve self-organization and self-adaptability for robust collaborative problem solving.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "MORPHAGENT",
            "system_description": "Decentralized multi-agent system where each agent is an LLM-driven actor with a dynamic profile p_i = (f_i, c_i, r_i) that evolves via a profile update function ψ implemented using an LLM. The system runs an iterative two-phase pipeline: (1) Profile Update phase (up to 5 rounds with early stopping) that optimizes profiles by maximizing three metrics (Role Clarity Score RCS, Role Differentiation Score RDS, and Task-Role Alignment Score TRAS) via adaptive prompts and peer observations, and (2) Task Execution phase where optimized agents perform Observe-Think-Act cycles (planning via ReAct/Reflexion patterns) and can re-enter profile updates upon feedback or task/environment changes. Coordination is emergent and decentralized: agents choose collaborators based on local observations, past interactions and profile similarity/dissimilarity; no central controller is used.",
            "number_of_agents": "3 (benchmarks); tested with 3/5/10 in scalability experiments",
            "agent_specializations": "Agents are initialized homogeneously and self-specialize through profile updates; observed emergent roles include coordination/communication agent, development (implementation) agent, debugging/verification agent, and domain-specific evaluators (example from case study: communication, development, debugging in software-engineering task). Profiles explicitly encode functional capabilities, contextual adjustments, and interaction rules.",
            "research_phases_covered": "Idea/task decomposition (implicit via profile update and planning), planning and execution (Observe-Think-Act cycles), implementation/subtask execution, iterative evaluation and refinement (profile updates and task feedback), and role-refinement/self-reflection; demonstrated on code generation, general reasoning, mathematical reasoning, and a software-engineering case study.",
            "coordination_mechanism": "Decentralized self-organization: pairwise and local-neighborhood decisions determine interaction topology; dynamic topology emerges from agents selecting collaborators based on local observations, past interactions and profile embeddings. Coordination alternates between profile-optimization rounds (synchronous up to a limit) and asynchronous task execution rounds with consensus via a 'skip' action (when all agents choose skip, execution ends).",
            "communication_protocol": "Natural language prompts/messages mediated by LLMs, augmented by structured prompt templates and occasional constrained JSON-format self-reflection outputs (Appendix examples). Profile and metric data are represented as textual profiles and embeddings (Sentence-BERT 'all-MiniLM-L6-v2'). Agents exchange actions/observations and receive adaptive textual feedback prompts; embeddings are used for similarity/dissimilarity calculations.",
            "feedback_mechanism": "Metric-driven adaptive prompts: agents receive targeted feedback based on changes in RCS, RDS, and TRAS (e.g., requests to clarify role, differentiate, or better align to task). Agents perform self-reflection (structured JSON template in prompts) and peer observation; task outcomes (including partial failures) trigger profile updates. During task execution agents log outcomes and can re-enter Phase 1 upon feedback or detection of requirement changes.",
            "communication_frequency": "Iterative rounds: Profile Update phase runs up to 5 rounds initially (early stopping if metrics improve by &gt;0.1); subsequent adjustments often run one lightweight round. During Task Execution, agents communicate each interaction round (Observe-Think-Act cycles) and exchange feedback whenever failures or task changes occur (on-demand return to profile update).",
            "task_domain": "General scientific/research-support tasks demonstrated on Code Generation (BigCodeBench), General Reasoning (BigBenchHard), Mathematical Reasoning (MATH), and a software-engineering case study; cross-domain adaptation experiments (domain shifts) also evaluated.",
            "performance_metrics": "Reported metrics include task accuracy (percentage) on benchmarks, RCS/RDS/TRAS profile metric values, and average interaction rounds. Example numbers: benchmark accuracy on BigCodeBench: MORPHAGENT 52.00% (GPT-4o-mini backbone) vs ablation baselines; robustness under high node-failure (failure prob = 0.8): MORPHAGENT retains ~40.10%–54.00% across tasks while baselines drop to ~1.43%–19.52%. Scalability results (MATH, GPT-4o-mini): 3 agents =&gt; 66.67% accuracy, avg rounds 1.5456; 5 agents =&gt; 66.19% accuracy, avg rounds 1.6110; 10 agents =&gt; 65.71% accuracy, avg rounds 2.06.",
            "baseline_comparison": "Compared experimentally against GPTSwarm, AgentVerse, and AFLOW on Code Generation, General Reasoning, and Mathematical Reasoning tasks; MORPHAGENT consistently outperforms these baselines across LLM backbones and shows superior robustness in node-failure and domain-shift scenarios.",
            "coordination_benefits": "Improved robustness to node failure (retains substantial accuracy at high failure rates: 40.10–54.00% vs baselines 1.43–19.52%), better cross-domain adaptability with smaller accuracy drops under domain shift, higher benchmark accuracy (e.g., +~1.33–13 percentage points depending on comparison), and emergent specialization reducing redundancy (higher RCS and RDS correlated with better performance).",
            "coordination_challenges": "Computational and communication overhead from continuous profile updating; increasing number of agents raises average interaction rounds and communication cost (not linear but present); potential for profile update cost to be significant in large deployments (not fully optimized).",
            "ablation_studies": "Yes — ablation on using none or single metric vs all three: using no additional metric (+ None) yields 50.67% (GPT-4o-mini) and 38.33% (GPT-3.5-Turbo) baselines; RCS-only: 50.00% / 39.33%; RDS-only: 41.66% / 37.00%; TRAS-only: 49.66% / 35.33%; integrated RCS+RDS+TRAS (MORPHAGENT): 52.00% / 43.33% — showing the combined metrics outperform single-metric configurations.",
            "optimal_configurations": "Recommended initial Profile Update phase of up to 5 rounds with early stopping criterion (stop if all three metrics improve by &gt;0.1); experimental default of N=3 agents for benchmarks (used throughout main evaluations); subsequent lightweight profile updates use a single round. LLM temperature used in experiments: 0.7; embeddings computed with Sentence-BERT 'all-MiniLM-L6-v2'.",
            "uuid": "e2421.0",
            "source_info": {
                "paper_title": "MorphAgent: Empowering Agents through Self-Evolving Profiles and Decentralized Collaboration",
                "publication_date_yy_mm": "2024-10"
            }
        },
        {
            "name_short": "GPTSwarm",
            "name_full": "GPTSwarm: Language agents as optimizable graphs",
            "brief_description": "An MAS approach that models agents as nodes in an optimizable graph (SOP-like workflows/subnets) to coordinate agent actions; cited as a baseline SOP-style system and compared experimentally.",
            "citation_title": "GPTSwarm: Language agents as optimizable graphs",
            "mention_or_use": "use",
            "system_name": "GPTSwarm",
            "system_description": "Described as an approach that models agents as optimizable graph/subnet of action nodes and constructs workflows to coordinate tasks; characterized by structured SOP-like coordination rather than fully emergent decentralized self-organization.",
            "number_of_agents": "variable (paper compares using N=3 agents for baselines)",
            "agent_specializations": "SOP/workflow-defined subroles (action nodes) — implementation details not provided in this paper beyond being SOP/workflow-based.",
            "research_phases_covered": "Task decomposition and workflow-driven execution (SOP-style pipeline), typically used for structured task execution such as code generation.",
            "coordination_mechanism": "SOP-based workflow / graph-based coordination (centralized or pre-defined orchestration of nodes/workflows rather than emergent self-organization).",
            "communication_protocol": "Not specified in detail in this paper; described as constructing workflows/subnets (implies structured messages/actions rather than free-form emergent natural-language peer messaging).",
            "feedback_mechanism": "Not detailed here; treated as baseline that does not implement MORPHAGENT's dynamic profile metric-driven feedback.",
            "communication_frequency": "Implied synchronous workflow stages; not detailed.",
            "task_domain": "Used as baseline on Code Generation, General Reasoning, and Mathematical Reasoning benchmarks in experiments.",
            "performance_metrics": "Reported in paper as baseline in Figures/Tables (exact per-task numbers not enumerated here beyond comparative statements); cited that GPTSwarm experiences large drops under domain shift (LEVEL-2, ~45% drop when shifting to MATH).",
            "baseline_comparison": "Compared to MORPHAGENT: GPTSwarm shows much larger performance degradation under domain shift and node failure compared to MORPHAGENT.",
            "coordination_benefits": "Provides structured coordination and can be efficient in predefined workflow tasks; good for adhering to SOPs.",
            "coordination_challenges": "Poor adaptability to domain shifts and vulnerability to node failures; lacks fully decentralized emergent role evolution according to the paper.",
            "ablation_studies": "No internal ablation reported here; used as a baseline in MORPHAGENT experiments.",
            "optimal_configurations": "Not provided in this paper beyond being used as a baseline in the experimental setup.",
            "uuid": "e2421.1",
            "source_info": {
                "paper_title": "MorphAgent: Empowering Agents through Self-Evolving Profiles and Decentralized Collaboration",
                "publication_date_yy_mm": "2024-10"
            }
        },
        {
            "name_short": "AgentVerse",
            "name_full": "AgentVerse: Facilitating multi-agent collaboration and exploring emergent behaviors",
            "brief_description": "A multi-agent framework referenced as an approach that supports multi-agent collaboration but relies on centralized monitoring or coordinators in some instantiations; used as a baseline for comparison.",
            "citation_title": "Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors",
            "mention_or_use": "use",
            "system_name": "AgentVerse",
            "system_description": "Described in the paper as a system that facilitates multi-agent collaboration and explores emergent behaviors; characterized in related work as relying on centralized mechanisms (single role or subset of agents monitoring and evaluating system performance).",
            "number_of_agents": "variable (used as a baseline with N=3 in experiments)",
            "agent_specializations": "Often includes specialized monitoring/evaluation roles (central coordinator); exact specializations not detailed in this paper.",
            "research_phases_covered": "Collaborative execution and evaluation phases; specifics not detailed here.",
            "coordination_mechanism": "Centralized or semi-centralized coordination (a single role or subset of agents monitors and evaluates overall performance).",
            "communication_protocol": "Not specified in detail in this paper; implied natural language agent messaging under centralized control.",
            "feedback_mechanism": "Centralized monitoring/evaluation by coordinator agents; not metric-driven dynamic profiles as in MORPHAGENT.",
            "communication_frequency": "Not specified; likely periodic monitoring/evaluation by the coordinator.",
            "task_domain": "Used as baseline across Code Generation, General Reasoning, and Mathematical Reasoning benchmarks.",
            "performance_metrics": "Compared in Figures — MORPHAGENT outperforms AgentVerse across tasks (exact baseline numbers not enumerated in-text here).",
            "baseline_comparison": "AgentVerse is one of the SOTA baselines compared; MORPHAGENT yields higher robustness and accuracy than AgentVerse in reported experiments.",
            "coordination_benefits": "Central monitoring can improve focused evaluation and detect failures globally.",
            "coordination_challenges": "Scalability bottlenecks and potential single-point-of-failure due to centralized monitoring.",
            "ablation_studies": "Not applicable in this paper; AgentVerse used as baseline only.",
            "optimal_configurations": "Not provided in this paper.",
            "uuid": "e2421.2",
            "source_info": {
                "paper_title": "MorphAgent: Empowering Agents through Self-Evolving Profiles and Decentralized Collaboration",
                "publication_date_yy_mm": "2024-10"
            }
        },
        {
            "name_short": "AFLOW",
            "name_full": "AFLOW: Automating agentic workflow generation",
            "brief_description": "An SOP/workflow-oriented MAS that constructs workflows for diverse tasks, cited as a baseline SOP-style system.",
            "citation_title": "AFLOW: Automating agentic workflow generation",
            "mention_or_use": "use",
            "system_name": "AFLOW",
            "system_description": "Approach that models agents and tasks as automated workflows or subnets of action nodes to generate SOP-like coordination between agents; described as lacking flexibility compared to dynamic profile adaptation.",
            "number_of_agents": "variable (baseline experiments use N=3)",
            "agent_specializations": "Workflow-defined roles / action-node specialists according to the generated SOP; details not provided here.",
            "research_phases_covered": "Workflow-based planning and execution stages for structured tasks.",
            "coordination_mechanism": "Predefined SOP/workflow orchestration (centralized or pre-specified sequences), not decentralized emergent coordination.",
            "communication_protocol": "Not detailed in this paper; implied structured workflow messages/prompts.",
            "feedback_mechanism": "Not described in-depth here; lacks MORPHAGENT's metric-driven iterative profile updates.",
            "communication_frequency": "Stage-based according to workflow; not specified.",
            "task_domain": "Used as a baseline on code, reasoning, and math benchmarks.",
            "performance_metrics": "Used for experimental comparison; reported to degrade more under node-failure and domain-shift scenarios relative to MORPHAGENT.",
            "baseline_comparison": "MORPHAGENT outperforms AFLOW in robustness and adaptability across reported benchmarks.",
            "coordination_benefits": "Efficient for standardized procedures and predefined workflows.",
            "coordination_challenges": "Lack of flexibility for unforeseen skills or domain shifts; limited self-adaptability without external coordination.",
            "ablation_studies": "Not applicable here; used as a baseline.",
            "optimal_configurations": "Not detailed in this paper.",
            "uuid": "e2421.3",
            "source_info": {
                "paper_title": "MorphAgent: Empowering Agents through Self-Evolving Profiles and Decentralized Collaboration",
                "publication_date_yy_mm": "2024-10"
            }
        },
        {
            "name_short": "MetaGPT",
            "name_full": "MetaGPT: Meta programming for a multi-agent collaborative framework",
            "brief_description": "An MAS that implements human workflows as rigid organizational structures to coordinate multiple agents; cited as an example of a system with predefined roles and limited adaptability.",
            "citation_title": "MetaGPT: Meta programming for a multi-agent collaborative framework",
            "mention_or_use": "mention",
            "system_name": "MetaGPT",
            "system_description": "Described as implementing human-style workflow with rigid organizational structures and predefined agent roles optimized for tasks like code generation but lacking generalization and flexibility to other tasks.",
            "number_of_agents": "variable / not specified in this paper",
            "agent_specializations": "Predefined role-playing agents (e.g., project manager, coder, tester) determined by workflow templates.",
            "research_phases_covered": "Workflow-based planning and execution (particularly code generation/workflow-driven projects).",
            "coordination_mechanism": "Centralized or pre-specified workflow orchestration; rigid organizational structure.",
            "communication_protocol": "Role-play prompts/natural language messages constrained by workflow templates.",
            "feedback_mechanism": "Workflow checkpoints and human-like role interactions; not the autonomous metric-driven feedback used in MORPHAGENT.",
            "communication_frequency": "Per workflow stage/checkpoint; not detailed.",
            "task_domain": "Software development/code generation primarily (as cited).",
            "performance_metrics": "Not provided here; described qualitatively as improving code-generation but lacking generalization.",
            "baseline_comparison": "Referenced as an approach with limited adaptability compared to MORPHAGENT.",
            "coordination_benefits": "Effective for tasks that map well to human workflows.",
            "coordination_challenges": "Rigidness restricts adaptability to new domains or tasks.",
            "ablation_studies": "Not applicable in this paper.",
            "optimal_configurations": "Not specified here.",
            "uuid": "e2421.4",
            "source_info": {
                "paper_title": "MorphAgent: Empowering Agents through Self-Evolving Profiles and Decentralized Collaboration",
                "publication_date_yy_mm": "2024-10"
            }
        },
        {
            "name_short": "CAMEL",
            "name_full": "CAMEL: Communicative Agents for Mind Exploration",
            "brief_description": "A role-playing multi-agent approach where agents have predefined roles through role-playing; cited as having difficulty adapting to tasks requiring unforeseen skills.",
            "citation_title": "Camel: Communicative agents for \"mind\" exploration of large language model society",
            "mention_or_use": "mention",
            "system_name": "CAMEL",
            "system_description": "Employs agents with predefined role-playing to structure multi-agent conversation and task execution. Presented as a related approach that uses predefined roles and thus has limited adaptability to unforeseen requirements.",
            "number_of_agents": "variable (not specified here)",
            "agent_specializations": "Role-play defined agents (e.g., different persona/roles as needed by the workflow).",
            "research_phases_covered": "Collaborative conversation and task execution phases where role-play assists in division of labor.",
            "coordination_mechanism": "Predefined role interactions; not emergent decentralized coordination.",
            "communication_protocol": "Natural language role-based conversations.",
            "feedback_mechanism": "Role-based inter-agent critique/interaction; not metric-driven profile updates.",
            "communication_frequency": "Per conversational turn or workflow stage.",
            "task_domain": "General multi-agent tasks; cited in context of limitations for unforeseen skill requirements.",
            "performance_metrics": "Not provided in this paper.",
            "baseline_comparison": "Mentioned as related work with constrained adaptability compared to MORPHAGENT.",
            "coordination_benefits": "Simplicity of role assignment and clearer human-analogous workflows.",
            "coordination_challenges": "Limited adaptability when novel skills are required.",
            "ablation_studies": "Not provided in this paper.",
            "optimal_configurations": "Not specified here.",
            "uuid": "e2421.5",
            "source_info": {
                "paper_title": "MorphAgent: Empowering Agents through Self-Evolving Profiles and Decentralized Collaboration",
                "publication_date_yy_mm": "2024-10"
            }
        },
        {
            "name_short": "AgentCoder",
            "name_full": "AgentCoder: Multi-agent-based code generation with iterative testing and optimisation",
            "brief_description": "An SOP-style multi-agent system for code generation that iteratively tests and optimizes code; cited as a structured workflow approach in related work.",
            "citation_title": "AgentCoder: Multi-agent-based code generation with iterative testing and optimisation",
            "mention_or_use": "mention",
            "system_name": "AgentCoder",
            "system_description": "Structured multi-agent approach for code development that uses iteration, testing, and optimization; referenced as part of SOP-based MAS work.",
            "number_of_agents": "variable (not specified here)",
            "agent_specializations": "Typical roles include code generator, tester, and optimizer per SOP workflows.",
            "research_phases_covered": "Implementation/execution and iterative testing/optimization phases for code-generation tasks.",
            "coordination_mechanism": "SOP/workflow-driven iterative pipeline.",
            "communication_protocol": "Prompt-driven interactions and test reports (natural language/structured outputs).",
            "feedback_mechanism": "Iterative testing and optimization loops (test results drive updates).",
            "communication_frequency": "Iteration-driven (after each test/optimization cycle).",
            "task_domain": "Code generation and software engineering tasks.",
            "performance_metrics": "Not reported in this paper (cited as related work).",
            "baseline_comparison": "Referenced as structured workflow approach; MORPHAGENT presented as more adaptive alternative.",
            "coordination_benefits": "Efficient for testing-driven code improvement.",
            "coordination_challenges": "Less flexible for open-ended or cross-domain tasks.",
            "ablation_studies": "Not provided here.",
            "optimal_configurations": "Not specified.",
            "uuid": "e2421.6",
            "source_info": {
                "paper_title": "MorphAgent: Empowering Agents through Self-Evolving Profiles and Decentralized Collaboration",
                "publication_date_yy_mm": "2024-10"
            }
        },
        {
            "name_short": "Criticize-Reflect",
            "name_full": "Criticize-Reflect",
            "brief_description": "A multi-agent approach employing critique and reflection loops among agents; cited as partially supporting self-organization and self-adaptability but relying on centralized elements in some variants.",
            "citation_title": "Criticize-Reflect",
            "mention_or_use": "mention",
            "system_name": "Criticize-Reflect",
            "system_description": "Approach that uses critique and reflective loops to improve agent outputs; in related work cited as having some self-organization and adaptability but potentially using centralized orchestration in practice.",
            "number_of_agents": "variable (not specified here)",
            "agent_specializations": "Roles include generators and critics/reflection agents.",
            "research_phases_covered": "Generation and evaluation/reflection phases.",
            "coordination_mechanism": "Critic-reflection interactions; may include centralized aspects per citation context.",
            "communication_protocol": "Natural language critique and reflection messages.",
            "feedback_mechanism": "Critic agents provide feedback and reflection processes inform next actions.",
            "communication_frequency": "Iterative after generation steps.",
            "task_domain": "General tasks requiring iterative improvement; cited in related work.",
            "performance_metrics": "Not given in this paper.",
            "baseline_comparison": "Positioned among methods that partially support self-organization/self-adaptability.",
            "coordination_benefits": "Improved output quality via critique/reflection.",
            "coordination_challenges": "Potential centralization in monitoring/evaluation; limited scalability described.",
            "ablation_studies": "Not provided here.",
            "optimal_configurations": "Not specified.",
            "uuid": "e2421.7",
            "source_info": {
                "paper_title": "MorphAgent: Empowering Agents through Self-Evolving Profiles and Decentralized Collaboration",
                "publication_date_yy_mm": "2024-10"
            }
        },
        {
            "name_short": "EvoMAC",
            "name_full": "EvoMAC: Self-evolving multi-agent collaboration networks for software development",
            "brief_description": "A self-evolving MAS focused on software development that supports self-organization; discussed as related work with some centralized evaluation components in prior variants.",
            "citation_title": "Self-evolving multi-agent collaboration networks for software development",
            "mention_or_use": "mention",
            "system_name": "EvoMAC",
            "system_description": "An approach that enables agents to self-evolve collaboration networks for software development tasks; cited as partially embodying self-organization and some adaptability features.",
            "number_of_agents": "variable (not specified)",
            "agent_specializations": "Software-development-focused roles (e.g., coding, review, integration) as per the cited work.",
            "research_phases_covered": "Software development lifecycle phases including development, review, and adaptation.",
            "coordination_mechanism": "Self-evolving collaboration networks (decentralized), though some variants rely on monitoring/evaluation components.",
            "communication_protocol": "Not detailed in this paper.",
            "feedback_mechanism": "Network evolution driven by performance and interactions; details deferred to cited work.",
            "communication_frequency": "Not specified here.",
            "task_domain": "Software development / code-related tasks.",
            "performance_metrics": "Not reported in this paper.",
            "baseline_comparison": "Cited as related work with partial overlap in goals (self-organization/self-adaptability).",
            "coordination_benefits": "Supports emergent specialization and adaptation in software tasks.",
            "coordination_challenges": "May include centralized evaluators in some implementations; scalability/effectiveness depend on specific design.",
            "ablation_studies": "Not detailed here.",
            "optimal_configurations": "Not specified in this paper.",
            "uuid": "e2421.8",
            "source_info": {
                "paper_title": "MorphAgent: Empowering Agents through Self-Evolving Profiles and Decentralized Collaboration",
                "publication_date_yy_mm": "2024-10"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "GPTSwarm: Language agents as optimizable graphs",
            "rating": 2,
            "sanitized_title": "gptswarm_language_agents_as_optimizable_graphs"
        },
        {
            "paper_title": "Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors",
            "rating": 2,
            "sanitized_title": "agentverse_facilitating_multiagent_collaboration_and_exploring_emergent_behaviors"
        },
        {
            "paper_title": "AFLOW: Automating agentic workflow generation",
            "rating": 2,
            "sanitized_title": "aflow_automating_agentic_workflow_generation"
        },
        {
            "paper_title": "MetaGPT: Meta programming for a multi-agent collaborative framework",
            "rating": 2,
            "sanitized_title": "metagpt_meta_programming_for_a_multiagent_collaborative_framework"
        },
        {
            "paper_title": "Self-evolving multi-agent collaboration networks for software development",
            "rating": 2,
            "sanitized_title": "selfevolving_multiagent_collaboration_networks_for_software_development"
        },
        {
            "paper_title": "AgentCoder: Multi-agent-based code generation with iterative testing and optimisation",
            "rating": 1,
            "sanitized_title": "agentcoder_multiagentbased_code_generation_with_iterative_testing_and_optimisation"
        },
        {
            "paper_title": "Criticize-Reflect",
            "rating": 1,
            "sanitized_title": "criticizereflect"
        }
    ],
    "cost": 0.017716,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>MORPHAGENT: EMPOWERING AGENTS THROUGH SELF-EVOLVING PROFILES AND DECENTRALIZED COLLABORATION
3 Sep 2025</p>
<p>Siyuan Lu 
Queen Mary University of London</p>
<p>School of Engineering
Westlake University</p>
<p>Jiaqi Shao 
Duke Kunshan University</p>
<p>Hong Kong University of Science and Technology</p>
<p>Bing Luo 
Duke Kunshan University</p>
<p>Tao Lin 
School of Engineering
Westlake University</p>
<p>Research Center for Industries of the Future
Westlake University</p>
<p>MORPHAGENT: EMPOWERING AGENTS THROUGH SELF-EVOLVING PROFILES AND DECENTRALIZED COLLABORATION
3 Sep 2025989DDB3D6A596AD5E77CA2895A924C68arXiv:2410.15048v2[cs.AI]
Large Language Model (LLM) based multi-agent systems (MAS) have shown promise in tackling complex tasks, but often rely on predefined roles and centralized coordination, limiting their adaptability to evolving challenges.This paper introduces MORPHAGENT, a novel Autonomous, Self-Organizing, and Self-Adaptive Multi-Agent System for decentralized agent collaboration that enables agents to dynamically evolve their roles and capabilities.Our approach employs self-evolving agent profiles, optimized through three key metrics, guiding agents in refining their individual expertise while maintaining complementary team dynamics.MORPHAGENT implements a two-phase process: a Profile Update phase for profile optimization, followed by a Task Execution phase where agents continuously adapt their roles based on task feedback.Our experimental results show that MORPHAGENT outperforms existing frameworks in terms of task performance and adaptability to changing requirements, paving the way for more robust and versatile multi-agent collaborative systems.* Equal contributions.Work was done during Siyuan's visit to Westlake University, and Jiaqi's visit to Duke Kunshan University.</p>
<p>Introduction</p>
<p>The rapid advancement of Large Language Models (LLMs) (Achiam et al., 2023;Touvron et al., 2023b) has ushered in a new era of artificial intelligence, enabling the creation of sophisticated AI agents capable of tackling complex tasks across diverse domains (Nakajima, 2023;Torantulino, 2023).As these AI systems become more intricate, there has been notable progress in developing communicative agents for completing collaborative tasks together (Guo et al., 2024a;Wang et al., 2024;Qian et al., 2023;Hong et al., 2024).This collaborative approach, known as Multi-Agent Systems (MAS) (Han et al., 2024), has shown great promise in addressing challenges that are too complex or diverse for single-agent systems (Hong et al., 2024;Liu et al., 2023).</p>
<p>In the meanwhile, natural systems demonstrate remarkable forms of collective behavior through decentralized interactions among individuals (Beni &amp; Wang, 1993).From ant colonies coordinating complex foraging patterns to bird flocks executing synchronized aerial maneuvers, these systems achieve sophisticated group behaviors without central control (Duan et al., Table 1: Comparison of methods on three key properties: Individual Autonomy, Self-Organization, and Self-Adaptability.✔ indicates full support, ✗ indicates no support, and ✔ ✗ indicates partial support.Some approaches [5; 10; 15], as illustrated in Figure 1 (a), attempt Self-Organization by using specialized agents for task coordination.However, this centralized orchestration restricts the flexibility and robustness of agent-driven collaboration.Other methods [45; 43], shown in Figure 1 (b), use predefined mechanisms to structure collaboration workflows for different tasks, limiting emergent organization.</p>
<p>Method</p>
<p>Individual Autonomy Self-Organization Self-Adaptability</p>
<p>MetaGPT (Hong et al., 2024) ✗ ✗ ✗ GPTSwarm (Zhuge et al., 2024) ✗ ✔ ✗ ✗ AFLOW (Zhang et al., 2025) ✗ ✔ ✗ ✗ AgentVerse (Chen et al., 2024) ✔ ✔ ✗ ✗ Criticize-Reflect (Guo et al., 2024b) ✔ ✔ ✗ ✔ ✗ EvoMAC (Hu et al., 2024)
✔ ✔ ✗ ✔ ✗ MORPHAGENT ✔ ✔ ✔2023
).The success of these natural swarms lies in their ability to exhibit emergent intelligence that surpasses individual capabilities, offering valuable insights for designing more robust and adaptable multi-agent systems (Rosenberg &amp; Willcox, 2020).</p>
<p>Inspired by the remarkable emergent intelligence observed in these swarm systems (Brambilla et al., 2013;Rosenberg &amp; Willcox, 2020;Nguyen, 2024), we distill three fundamental principles that serve as the foundation for designing decentralized and adaptive multi-agent systems:</p>
<ol>
<li>Individual Autonomy: each agent processes local information and independently determines its actions during collaboration, rather than following rigid workflows.2. Self-Organization: agents spontaneously form collaborate patterns through simple interaction rules, including information sharing, behavioral alignment, and mutual adaptation.This dynamic collaboration structures is crucial for handling unpredictable environments.3. Self-Adaptability: agents dynamically adjust their roles, responsibilities, and behaviors to ensure resilience in dynamic environments.</li>
</ol>
<p>However, existing Multi-Agent Systems (MAS) fall short of fully embodying the three key principles outlined in Table 1.First, individual autonomy is compromised in systems such as GPTSwarm [45], AFLOW [43], and MetaGPT [13], where rigid workflows predetermine agent roles and actions, limiting the agents' independent decision-making capabilities.</p>
<p>Although some methods incorporate aspects of self-organization, they often rely on centralized task coordinators-as seen in AgentVerse [5], Criticize-Reflect [10], and EvoMAC [15]-or predefined collaboration structures [45; 43].These constraints hinder the emergence of truly decentralized and adaptive teamwork.Finally, self-adaptability remains limited across most MAS.In many cases, agent roles are either fixed or can only be modified through external coordination rather than through intrinsic, self-driven evolution [5; 10; 15].</p>
<p>To address these limitations, as illustrated in Figure 1 (c), we propose MORPHAGENT, a robust, scalable, and adaptive decentralized system capable of addressing complex and dynamic challenges.Our framework enables each LLM-based agent to independently adapt to dynamic tasks and environments, exemplifying individual Autonomy.Additionally, MORPHAGENT introduces a dynamic profile mechanism, which defines and continuously evolves each agent's roles, capabilities, and expertise based on interactions and task demands without a centralized control.To ensure selforganization and self-adaptability, we introduce three metrics-namely role clarity, team diversity, and capability matching-to enhance collaboration and facilitate continuous adaptation to changing environments.Through dynamic profile optimization and agent collaboration, MORPHAGENT achieves swarm intelligence in decentralized multi-agent systems.</p>
<p>Contributions.We summarize the key contributions:</p>
<p>• We propose MORPHAGENT, a decentralized multi-agent framework with the properties of individual autonomy, self-organization, and self-adaptability.• We present an innovative dynamic profile mechanism incorporating three metrics, which facilitates the continuous evolution of agents' roles and capabilities, thereby enabling effective self-organization and collaboration in dynamic environments.• Comprehensive empirical results demonstrate that our method consistently outperforms SOTA methods across various tasks.Notably, in a challenging environment with high failure rates (0.8), which means that the agent has a 80% probability of failing to act, our method maintains robust performance (40.10 ∼ 54.00% across tasks) while baselines degrade significantly (1.43 ∼ 19.52%).</p>
<p>Related Work</p>
<p>LLM-based Multi-Agent Systems (MAS).The emergence of Large Language Model (Achiam et al., 2023;Touvron et al., 2023a) has led to LLM-based autonomous agent capable of tackling complex tasks, like BabyAGI (Nakajima, 2023) and AutoGPT (Torantulino, 2023).However, single LLM agent often struggle with cooperative work, such as software engineering (Jimenez et al., 2024).To address these limitations, recent studies have proposed LLM-based MAS (Han et al., 2024;Zhou et al., 2023), where multiple AI agents collaborate on solving complex tasks.</p>
<p>However, current approaches often rely on predefined roles (Li et al., 2023;Hong et al., 2024), centralized coordination (Chen et al., 2024), or rigid organizational structures (Hong et al., 2024;Qian et al., 2024).For example, CAMEL (Li et al., 2023) and ChatEval (Chan et al., 2023) employ agents with predefined roles through role-playing, but struggle to adapt to tasks requiring unforeseen skills.MetaGPT (Hong et al., 2024) implements human workflow in rigid organizational structures, showing improvements in code-generation but lacking generalization to other tasks like writing a research paper.Our work addresses these limitations by initializing agents homogeneously without predefined roles or collaboration structures, allowing them to naturally develop cooperation through interaction.</p>
<p>Organization optimization for MAS.Recent research in LLM-based MAS has focused on optimizing organizational structures (Guo et al., 2024b;Zhuge et al., 2024) and enhancing agent performance (Zhang et al., 2024) to reduce communication costs and increase team efficiency.Approaches like AgentVerse (Chen et al., 2024), Criticize-Reflect (Guo et al., 2024b), and EvoMAC (Hu et al., 2024) rely on centralized mechanisms, where a single role or a subset of agents monitor and evaluate the system's overall performance.While effective in certain scenarios, these centralized methods may face scalability issues and potential bottlenecks in large-scale MAS.Our decentralized approach leverages LLM-based agents' self-reflection capabilities (Madaan et al., 2023;Shinn et al., 2023;Renze &amp; Guven, 2024), and enables agents to dynamically adjust their responsibilities based on the change of tasks for better adaptivity.</p>
<p>Standard Operating Procedure (SOP) based MAS.Another line of research has explored more structured collaboration methodologies in LLM-based multi-agent systems.SOP-based approaches such as AgentCoder (Huang et al., 2023) and MetaGPT (Hong et al., 2024) have demonstrated performance gains through standardized workflows.</p>
<p>GPTSwarm (Zhuge et al., 2024) and AFLOW (Zhang et al., 2025) extends these methods by modeling agents as subnets of action nodes and constructing workflows for diverse tasks.Although SOP-based approaches offer efficient coordination for adhering to predefined procedures in specific scenarios, they lack flexibility.Our framework empowers multi-agent collaboration with autonomous planning capabilities of advanced LLM-based agents (Huang et al., 2022;Guan et al., 2023;Wang et al., 2023): instead of relying on rigid SOPs, it facilitates the dynamic development of collaborative strategies and efficient role adaptation, improving overall performance and robustness.</p>
<p>MORPHAGENT</p>
<p>Our framework, MORPHAGENT, enables decentralized and adaptive multi-agent collaboration by integrating three key components.First, we define the fundamental agent properties (c.f.Section 3.1), introducing dynamic profiles that allow agents to autonomously adjust their roles and behaviors.Next, we present the Decentralized Collaboration Framework (in Section 3.2), which orchestrates agent interactions through iterative and decentralized coordination.Finally, we introduce profile evaluation and optimization metrics (c.f.Section 3.3), which ensure role clarity, team diversity, and effective task alignment, facilitating robust collaboration.</p>
<p>System Properties</p>
<p>The LLM-based agent serves as the fundamental building block of our framework, capable of autonomous reasoning, decision-making, and interaction with other agents.To facilitate systematic analysis and optimization of agent behavior in a MAS, we begin by a concrete definition of agent's profile in a MAS.Definition 3.1 (Agent's Profile).Each agent a i ∈ A in a MAS is associated with a profile p i , which encodes its roles, capabilities, and interaction preferences.Formally, the profile is represented as p i = (f i , c i , r i ), where f i denotes the agent's functional capabilities (e.g., specific skills), c i captures contextual or task-specific adjustments, and r i defines the rules for interaction with other agents.</p>
<p>Remark 3.2.Profiles can be either immutable, remaining constant throughout the system's operation, or dynamic, evolving over time based on local observations, task requirements, and peer interactions.Dynamic profiles enable agents to adapt to changing environments, unlike the static, immutable profiled used in traditional MAS (Li et al., 2023;Hong et al., 2024).</p>
<p>Specifically, we focus on the dynamic profile, which evolves over time based on local observations, task requirements, and peer interactions.The dynamic profile mechanism is defined as follows: Definition 3.3 (Dynamic Profile Mechanism).The Dynamic Profile Mechanism enables agents to autonomously refine their roles and collaboration strategies by updating their profiles based on evolving observations, past interactions, and task demands.If agents operate with Individual Autonomy, they can independently determine adjustments to their profiles.Formally, at time t, an agent a i ∈ A updates its profile p t i as:
p t i = ψ(o t i , p t−1 i , {α t j } j∈N t i ) , where o t i represents local observations, p t−1 i
is the previous profile, and {α t j } j∈N t i are actions from neighboring agents.The function ψ, implemented using an LLM, enables agents to dynamically adjust their roles.</p>
<p>Building upon the dynamic profile, we define three core principles derived from natural systems, namely, Individual Autonomy, Self-Organization, and Self-Adaptability, as defined below: Definition 3.4 (Property # 1: Individual Autonomy).Each agent a i ∈ A at time t operates independently, without relying on a central controller or predefined workflows.More precisely, the action of α t i of agent a i is sampled from a policy function π, based on the local observations o t i , historical states h t−1 i , and its dynamic profile p t i :
α t i ∼ π(o t i , h t−1 i , p t i )
, where policy π can be implemented as a LLM, by mapping these inputs to a probability distribution over actions.</p>
<p>Remark 3.5.Unlike existing MAS constrained to a limited set of predefined actions or skill sets (Li et al., 2023;Hong et al., 2024), α t i can involve high-level reasoning or complex behaviors.By generating diverse actions through π, each agent exemplifies autonomy, enabling flexible responses to evolving tasks and environments.Definition 3.6 (Property # 2: Self-Organization).A MAS exhibits Self-Organization if agents independently establish and adapt their interaction patterns without relying on predefined structures or centralized coordination.Such interaction topology evolves dynamically based on the changes in agent states, task requirements, and environmental conditions, as shown in Figure 1c.</p>
<p>Remark 3.7.Each agent independently determines which other agents to collaborate with based on its own observations, dynamic profile, and past interactions.These decisions follow adaptive interaction rules that guide how connections are formed and adjusted over time.This decentralized mechanism enables the system to dynamically reconfigure its topology in real time, adapting to changes in tasks or resources.Unlike centralized systems relying on a single coordinator (Figure 1a) or decentralized systems with fixed topologies (Figure 1b), self-organizing systems preserve scalability and adaptability in dynamic environments.Definition 3.8 (Property # 3: Self-Adaptability).A MAS exhibits Self-Adaptability if agents can dynamically adjust their roles and interactions in response to evolving observations, past states, and peer behaviors.This capability ensures that agents continuously refine their expertise and collaboration strategies, allowing the system to remain flexible and resilient in dynamic environments.</p>
<p>Summary.MORPHAGENT utilizes the dynamic profile mechanism to integrate Individual Autonomy into profile evolution, embodying Self-Adaptability by enabling agents to continuously refine their roles and interactions.This adaptation process further promotes Self-Organization, as agents collectively adjust collaboration structures without a centralized control (see Section 4.3 for details).</p>
<p>Decentralized Collaboration Framework</p>
<p>In this section, we introduce our Decentralized Collaboration Framework, which orchestrates agent interactions through an iterative process.The evaluation and optimization of profiles are supported by Section 3.3, while Figure 2 illustrates how these two key phases are executed.</p>
<p>The framework employs autonomous agents equipped with dynamic profile mechanism (Theorem 3.3) to enable seamless coordination.Each agent in the framework employ LLMs (e.g., GPT-4 (Achiam et al., 2023)) to execute an iterative Observe-Think-Act cycle: (1) observing their environment and peers' actions, (2) planning via frameworks like ReAct (Yao et al., 2022) and Reflexion (Shinn et al., 2023), and (3) acting based on dynamic profiles.The agent profile is continuously updated through task feedback and peer interactions, enabling skill recalibration and fostering Individual Autonomy.</p>
<p>The framework operates in two key phases, ensuring robust collaboration in dynamic environments (c.f. Figure 2): Table 2 provides concrete examples of how prompts are generated for each case, illustrating the refinement process.This process reduces ambiguities, fosters diversity, and aligns roles with task demands.Profile updates continue until stabilization or meeting stopping criteria (see examples in Table 2 and full details in Appendices B and C.1).After the profile update phase, the agents are equipped with optimized profiles, and are ready for the task execution phase.</p>
<p>Phase 2: Task Execution.With optimized profiles, agents execute task iteratively: each agent observes the environment and task state, decides whether to execute or skip (the "skip" action is designed to terminate the agent's task execution.When all agents choose "skip," they reach a consensus on the final answer.)its assigned subtask, and -if it actslogs the resulting outcomes.Agents re-enter Phase 1 upon receiving new feedback (e.g., partial failures) or detecting changes in task requirements or environmental conditions.This dual-level adaptation ensures (1) individual role refinement through profile updates, and (2) collective adjustments to collaboration patterns.</p>
<p>In our implementation, the initial Profile Update phase runs for up to five rounds, with an early stopping mechanism: if all three metrics (RCS, RDS, TRAS) improve by more than 0.1, the process ends early.After the initial phase, subsequent updates require only one round as a lightweight adjustment in response to task changes By alternating between profile refinement (Phase 1) and task execution (Phase 2), the framework integrates self-adaptivity and self-organization between agents, ensuring coherence with evolving task objectives.</p>
<p>Profile Optimization: Challenges and Solutions</p>
<p>In dynamic and complex environments, resolving role ambiguity is crucial to clarify agent responsibilities and enhance their profiles.With well-described agent profiles, fostering diversity equips the system to address multifaceted problems, while alignment between agent capabilities and task requirements ensures effectiveness in executing complex tasks.</p>
<p>To enhance the self-adaptability of MAS, we introduce three key metrics for evaluating and optimizing each agent's profile: Role Clarity Score (RCS), Role Differentiation Score (RDS), and Task-Role Alignment Score (TRAS).These metrics serve distinct but complementary purposes: RCS measures how clearly an agent's role is defined, RDS captures the diversity of roles across the team, and TRAS assesses how well an agent's role aligns with task requirements.Together, they guide dynamic profile optimization to ensure effective collaboration.Intuitions and key components of each metric are summarized in Table 3.</p>
<p>Definition 3.9 (Role Clarity Score (Informal)).For an agent a ∈ A with profile p ∈ S, where S is the set of all possible profile strings, role clarity considers the syntactic structure, lexical diversity, and skill relevance of the profile, which can be defined as:
RCS(a) = β1 • DEP(p) + β2 • ENT(p) + β3 • SKILL(p)
where β 1 + β 2 + β 3 = 1, and</p>
<p>• DEP : S → [0, 1] is the dependency score, measuring syntactic complexity.</p>
<p>• ENT : S → [0, 1] is the entropy score, quantifying lexical diversity.</p>
<p>• SKILL : S → [0, 1] is the skill score, measuring relevance to skill-related concepts.</p>
<p>We defer the detailed implementation of RCS to Appendix A, e.g., the formal definition of each component.</p>
<p>Definition 3.10 (Role Differentiation Score).Let A = {a 1 , . . ., a n } be a set of n agents, with profiles P = {p 1 , . . ., p n }.The role differentiation of A measures the average dissimilarity between agent profiles, which can be defined as:
RDS = h   2 n(n − 1) 1≤i&lt;j≤n d(a i , a j )   ,
where d(a i , a j ) = 1 − e(pi)•e(pj ) ∥e(pi)∥∥e(pj )∥ is the dissimilarity between agents a i and a j measured by the embeddings of their profiles p i and p j , and h is a sigmoid function to normalize the score.Definition 3.11 (Task-Role Alignment Score (Informal)).Given a task T ∈ T and a set of agent profiles P = {p 1 , . . ., p n }, task-role alignment investigates how well the agents' roles align with the task requirements, which is defined as:
TRAS = α • S sim (T, P) + (1 − α) • S cap (T, P) ,
where:</p>
<p>• Semantic Similarity (S sim ): Measures alignment between task requirements and agent expertise by computing the average similarity score between task descriptions and agent profiles.• Capability Compatibility (S cap ): Evaluates how well the agent capabilities match the task's complexity demands.</p>
<p>We defer the implementation details of TRAS to Appendix A, e.g., the formal construction for S sim and S cap .These three scores jointly offer a comprehensive basis for assessing and refining agent roles, thus enabling flexible and adaptive teamwork.Appendix A details the practical implementation of each metric, and Appendix D demonstrates their effectiveness through quantitative evaluations on various agent configurations and task scenarios.</p>
<p>Experiments</p>
<p>In this section, we comprehensively evaluate our multi-agent collaboration framework MORPHAGENT from three perspectives.First, in Section 4.1, we compare MORPHAGENT with existing MAS approaches on benchmark tasks, assessing its robustness under varying conditions.Next, in Section 4.2, we conduct an ablation study to examine the impact of profile optimization metrics and scalability with increasing agent numbers.Finally, in Section 4.3, a case study illustrates how agents iteratively refine profiles and adapt roles, demonstrating emergent self-organization in a software engineering task.These evaluations collectively validate the effectiveness of our framework in dynamic multi-agent environments.Additionally, we assess its adaptability to evolving task requirements in Appendix F.1 and scalability of this system in Appendix F.2.</p>
<p>Collaboration in Dynamic Environments</p>
<p>Experimental Setup.We compare our method with these state-of-the-art MAS methods: GPTSwarm (Zhuge et al., 2024), AgentVerse (Chen et al., 2024) and AFLOW (Zhang et al., 2025) on the following benchmark tasks: Code Generation (BigCodeBench (Zhuo et al., 2024)), General Reasoning (BigBenchHard (Suzgun et al., 2022)), Mathematical Reasoning (MATH (Hendrycks et al., 2021)).And a benchmark analysis is provided in Appendix E, explaining why we choose these tasks.For each benchmark task, we use a set of N = 3 agents3 , with each agent initialized as the same LLM model including one close-source model -GPT-4o-mini 4 and one open-source model -DeepSeek-V35 .Regarding LLM configurations, we set the temperature to 0.7 and kept all other parameters as default.Detailed prompts are in Appendix C.2. Dynamic Environment.In order to better evaluate the performance of these methods in real-world scenarios, we introduce the Node Failure setting.Specifically, in each round of interaction, one agent in MAS has a certain probability of failing to respond.For all methods, all agents have an independent probability of failure in each interaction.In this setting, we evaluate the robustness of each method in the face of potential agent failures, which can be crucial in real-world applications.</p>
<p>Results.As shown in Figure 3, the results demonstrate that across different models and scenarios, MORPHAGENT outperforms other baselines in both performance and robustness.As the failure probability increases, the performance of our method degrades significantly less than the other methods, showcasing its superior resilience to failures.This highlights the necessity of implementing self-adaptivity for handling single node of failure in real-world applications, providing a more reliable solution.</p>
<p>Ablation Study</p>
<p>To comprehensively evaluate our framework, we conduct ablation studies from two key aspects:</p>
<p>• Performance on benchmarks: Validating our approach on the BigCodeBench dataset and comparing it against existing MAS methods across different LLM backbones.</p>
<p>• Impact of our metrics: Analyzing the contributions of three profile optimization metrics by testing performance with individual or no metrics.Our method consistently outperforms prior approaches.</p>
<p>Results: performance on benchmarks.To further validate the effectiveness of our approach, we conduct a benchmark evaluation using BigCodeBench which compares our method with other MAS methods.As shown in Figure 4, our method consistently outperforms prior approaches across different LLM backbones, including both open-source (DeepSeek-V3) and proprietary models (GPT-4o-mini, GPT-3.5-Turbo6 ).This demonstrates that our framework not only enhances adaptability but also generalizes well to standardized benchmarks, validating its robustness across diverse setting.</p>
<p>Results: impact of our metrics.As shown in Table 4, employing no additional metric (+ None) yields 50.67% accuracy for GPT-4o-mini and 38.33% for GPT-3.5-Turbo,serving as a baseline.Using any single metric alone generally does not outperform this baseline.For instance, using only the RCS results in 50.00% for GPT-4o-mini (slightly below its baseline) and 39.33% for GPT-3.5-Turbo(marginally above its baseline).</p>
<p>Similarly, RDS sees a more pronounced drop to 41.66% and 37.00% respectively, suggesting that role diversity alone is insufficient for tasks of this level of complexity.TRAS also remains around or below the baseline (49.66% and 35.33%).Notably, our profile update mechanism that integrates all three metrics achieves the highest performance, highlighting the complementary nature of these metrics.The combination of clear role definition, role diversity, and task alignment enables the agents to collaborate more effectively and adapt to varying task demands.</p>
<p>Case Study of Profile Update</p>
<p>To demonstrate the effectiveness of our profile optimization approach (discussed in Section 3.3), we present a case study of MORPHAGENT applied to a software engineering task.</p>
<p>Limitation and Conclusion</p>
<p>Limitations In this work, we proposed a decentralized multi-agent system that enhances complex problem-solving through dynamic, profile-based collaboration.While effective across benchmarks, the continuous updating of agent profiles introduces computational overhead.Future work could explore more efficient decentralized and peer-to-peer communication strategies to retain performance while reducing costs.</p>
<p>Conclusion.</p>
<p>In this paper, we introduced MORPHAGENT, a decentralized multi-agent system that employs dynamic, profile-based collaboration to improve problem-solving in complex tasks.By incorporating profile evaluation and optimization, we present a flexible approach to role adaptation, addressing the limitations of predefined roles in traditional MAS and the vulnerability of centralized systems to node failures.MORPHAGENT offers a promising foundation for developing resilient, self-organizing multi-agent systems capable of responding to unforeseen challenges.</p>
<p>Contents of Appendix</p>
<p>A Detailed Implementation for metrics</p>
<p>In this section, we provide a detailed implementation of the metrics used in MORPHAGENT.The implementation metrics uses the Sentence-BERT model 'all-MiniLM-L6-v2' for generating embeddings, for short text similarity tasks and provides high-quality embeddings.</p>
<p>The implementation of our metrics relies on carefully constructed vector representations of various concepts.These vectors are created through a systematic process that combines predefined term sets as detailed in Appendix A.1.The vectors are then used to evaluate task complexity and agent capability, as described in Appendix A.3.Definition A.1 (Role Clarity Score (RCS)).For an agent a ∈ A with profile p ∈ S, where S is the set of all possible profile strings, RCS considers the syntactic structure, lexical diversity, and skill relevance of the profile, which can be defined as:
RCS(a) = β 1 • DEP(p) + β 2 • ENT(p) + β 3 • SKILL(p) ,
where β 1 + β 2 + β 3 = 1, and</p>
<p>• DEP : S → [0, 1] is the dependency score, measuring syntactic complexity.This builds on established principles in dependency parsing (Kübler et al., 2009) and syntactic role analysis (Jurafsky, 2000).It captures the structural depth and richness of the profile:
DEP(p) = h 1   1 |D(p)| t∈D(p) |ST (t)|   ,
where D(p) is the set of tokens in p involved in key dependency relations (e.g., subject, object), ST (t) is the subtree of token t, and h 1 : R + → [0, 1] is a normalizing function capturing syntactic complexity.Higher DEP scores indicate more detailed, complex profiles.• ENT : S → [0, 1] is the entropy score, quantifying lexical diversity, defined as:
ENT(p) = h 2   − w∈W(p) f (w) |W(p)| log 2 f (w) |W(p)|   ,
where W(p) is the set of unique words in p, f (w) is the frequency of word w in p, and h 2 : R + → [0, 1] is a normalizing function.Higher ENT scores indicate diverse, less repetitive language.• SKILL : S → [0, 1] is the skill score, measuring relevance to skill-related concepts, computed as:
SKILL(p) = γ |T (p)| t∈T (p) e(t) • e(s) ∥e(t)∥ ∥e(s)∥ + (1 − γ) |PS(p)| |T (p)| ,
where s is the skill prototype, a vector capturing the essence of skill-related concepts, defined as the average embedding of terms like "skill", "expertise", and "competence".e(•) is a word embedding function, T (p) is the set of tokens in p, and PS(p) is the set of potential skill tokens, identified through syntactic and semantic criteria, including similarity to s and dependency relations (e.g., PROPN, NOUN in compound relations).Higher SKILL scores indicate stronger alignment with relevant skills.Definition A.2 (Task-Role Alignment Score (TRAS)).Given a task T ∈ T and a set of agent profiles P = {p 1 , . . ., p n }, TRAS investigates how well the agents' roles align with the task requirements, which is defined as:
TRAS = α • S sim (T, P) + (1 − α) • S cap (T, P) ,
where:</p>
<p>• Semantic Similarity (S sim ):
S sim (T, P) = 1 n n i=1 e(T ) • e(p i ) ∥e(T )∥ ∥e(p i )∥
,</p>
<p>where e(T ) and e(p i ) are vector representations of the task and the i-th agent profile, respectively, obtained via a pretrained language model.These vectors capture the semantic proximity between task descriptions and agent profiles.• Capability Compatibility (S cap ):
S cap (T, P) = 1 − C T (T ) − 1 n n i=1 C A (p i ) ,
where C T (T ) assesses task complexity and C A (p i ) evaluates the capability of an agent.C T (T ) is defined as:
C T (T ) = 1 2 (1 + cos(v T , v complex ) − cos(v T , v simple )) ,
where v T is the vector representation of the task, and v complex , v simple are vector representations of predefined complexity and simplicity indicators.Specifically, v complex includes terms like "complex" for technical challenges, and "challenging" for task difficulty.Conversely, v simple focuses on simplicity indicators like "basic" for scope and "routine", "standard" for effort.C A (p i ) evaluates the capability of the i-th agent profile as:
C A (p i ) = 1 2 (1 + cos(v pi , v capable ) − cos(v pi , v limited )) ,
where v pi represents the agent profile, while v capable and v limited capture capability and limitation indicators, respectively.v capable includes terms like "expert", "senior", "specialist", "experienced", "proficient", "certified", "trained", "advanced" and v limited covers "beginner", "junior", "apprentice", "trainee", "learning", "novice", "developing".</p>
<p>A.1 Prototype Term Sets</p>
<p>For each conceptual dimension, we define comprehensive sets of indicator terms.These sets are constructed to capture different aspects of each concept:</p>
<p>T complex = {"complex", "challenging", "difficult", "advanced", "sophisticated", "critical", "demanding"} T simple = {"basic", "simple", "straightforward", "routine", "standard", "elementary", "fundamental"} T capable = {"expert", "senior", "specialist", "experienced", "proficient", "certified", "trained", "advanced"} T limited = {"beginner", "junior", "apprentice", "trainee", "learning", "novice", "developing"}</p>
<p>(1)</p>
<p>A.2 Vector Construction Process</p>
<p>For each term set T x , we construct its corresponding vector representation v x using a pre-trained language model.The process follows:
v x = 1 |T x | t∈Tx e(t)(2)
where e(t) is the embedding function that maps a term to its vector representation, and |T x | is the cardinality of the term set.</p>
<p>A.3 Complexity and Capability Assessment</p>
<p>Task Complexity Evaluation The task complexity score C T (T ) is computed using the constructed vectors:
C T (T ) = 1 2 (1 + cos(v T , v complex ) − cos(v T , v simple ))(3)
where v T is the vector representation of the task description.This formulation ensures that: -Tasks with high similarity to complexity indicators and low similarity to simplicity indicators score high -The score is normalized to [0,1] through the averaging and shifting operations -The difference of cosine similarities captures relative alignment with complex versus simple concepts Agent Capability Assessment Similarly, agent capability C A (p i ) is evaluated as:
C A (p i ) = 1 2 (1 + cos(v pi , v capable ) − cos(v pi , v limited ))(4)</p>
<p>B Dynamic profile optimization process</p>
<p>In this section, we provide supplementary explanations on how the three key metrics-Clarity, Differentiation, and Alignment guide the generation and optimization of agent profiles.As shown in Figure 6, agents receive adaptive prompts based on their metric scores, offering targeted feedback to refine specific aspects of their profiles.For instance, agents with low clarity scores are prompted to better define their roles, while those with low alignment scores are encouraged to adjust their strategies to align more closely with task requirements.The detailed process of how metric changes translate into actionable prompts is further outlined in Appendix C.1, where various scenarios such as initial evaluations, improved profiles, and degraded profiles are explored.</p>
<p>Figure 6: Illustration of the dynamic profile optimization process using the three key metrics.Each agent's profile is evaluated against these metrics to provide actionable feedback.Metric scores guide the refinement of agent profiles, with adaptive prompts providing feedback for improvement.</p>
<p>Table 5 presents detailed profiles and corresponding metric scores for one agent, illustrating how an agent's profile evolves over the course of interactions, with metric scores reflecting the progressive refinement of roles and strategies.Specifically, the examples shown reflect the profile changes of one agent as it works on a task from the BigBenchHard dataset, addressing a causation scenario involving medical negligence and premature death.The metric scores highlight the agent's progressive refinement of roles and strategies in response to task demands.This analysis demonstrates the crucial role of the metrics in shaping well-optimized profiles, facilitating effective and adaptive collaboration.</p>
<p>Table 5: Profiles of an agent and their corresponding metric scores.Each agent profile is evaluated using three key metrics: role's clarity (RCS), differentiation (RDS), and alignment (TRAS) with their respective scores provided in the table.</p>
<p>Agent Profile RCS RDS TRAS Agent_0: collaborative agent with unique perspective 0.4215 0.0068 0.3626 Agent_0: collaborative agent with a focus on evaluating causation in complex scenarios.</p>
<p>0.6800 0.0492 0.3892 Agent_0: collaborative agent focused on evaluating causation in complex scenarios, particularly in high-stakes medical incidents and ethical dilemmas.Your unique capability lies in dissecting the interplay of human actions and systemic factors, enabling nuanced assessments of responsibility and outcomes.0.7158 0.2324 0.4717 Agent_0: collaborative agent focused on evaluating causation in complex medical incidents and ethical dilemmas, particularly in high-stakes scenarios involving human actions and systemic factors.Your unique capability lies in dissecting the intricate relationships between individual decisions, environmental influences, and health outcomes, enabling a thorough understanding of responsibility and accountability in critical contexts.You excel in providing nuanced assessments that inform decision-making processes and improve patient safety.0.7256 0.2556 0.4464 Agent_0: collaborative agent dedicated to evaluating causation in complex medical incidents and ethical dilemmas, with a unique focus on the interplay between individual decisions, systemic factors, and environmental influences in high-stakes scenarios.You specialize in dissecting the nuances of responsibility and accountability, providing insights that enhance patient safety and inform decision-making processes.Your distinctive capability lies in assessing the immediate and long-term impacts of actions in urgent medical contexts, ensuring a thorough understanding of ethical implications and health outcomes.• Compare your approach with those of other agents.What unique perspectives or methods did they bring?</p>
<p>• Identify any synergies or conflicts between your action and those of other agents.</p>
<p>• Evaluate the collective progress towards the task goal.Are all agents contributing effectively?3. Task-oriented reflection:</p>
<p>• Consider how well the current approaches align with the overall task objective.</p>
<p>• Suggest any adjustments in strategy or focus that might benefit the group's performance.4. Learning and adaptation:</p>
<p>• Based on this analysis, what key lessons can be drawn for future actions?</p>
<p>• Propose specific changes or improvements you plan to implement in your next action.5. Collaboration insights:</p>
<p>• Identify opportunities for better collaboration or task division among agents.</p>
<p>• Suggest ways to leverage the diverse strengths of different agents more effectively.Please structure your feedback clearly, addressing each point systematically.Be constructive, specific, and actionable in your analysis and suggestions.Your feedback MUST be in the following JSON format (within 100 words):</p>
<p>{</p>
<p>"self_reflection": "Your self-reflection here", "agent_analysis": "Your analysis of other agents here", "task_reflection": "Your task-oriented reflection here", "learning_adaptation": "Your learning and adaptation here", "collaboration_insights": "Your collaboration insights here" }</p>
<p>Execute Prompt</p>
<p>Based on the current context and your self reflection, you will execute the task by choosing your action.Remember: 1. Do not rush to give the final answer to the user requirement.2. Your action could be an intermediate step towards the final answer.3. A valid answer is one that correctly addresses the user's requirement in the proper format, even if it might be improved or expanded later.4.You can provide a valid answer without it being the final one -further improvements, alternatives, or expansions can still be explored in subsequent steps.Current context (User Request, History of agents' actions): {context} Your self-reflection: {self_reflection} Your action: Provide your execution content.If your action involves writing code, please enclose it in triple backticks with the language specified (e.g., "'python).Is this a valid answer?(Yes/No): Determine if your execution provides a valid answer to the user's requirement.A valid answer correctly addresses the requirement in the proper format, even if it could potentially be improved or expanded further.You MUST respond in the following JSON format: • EXECUTE: Perform a task such as data analysis, code generation, or problem-solving based on the current context, the execution will be shared with other agents to update the progress of task completion.• SKIP: Opt not to take any action, allowing other agents to proceed first.</p>
<p>IMPORTANT CONSIDERATIONS:</p>
<p>• Analyze the progress made so far towards fulfilling the user requirement.</p>
<p>• Consider how your action will contribute to the overall goal.</p>
<p>• Assess whether the current approach is effective or if a correction is needed, be mindful of potential risks or limitations in other agents' action.• Consider the actions and inputs of other agents to avoid redundancy and promote synergy.WARNING:</p>
<p>• Deciding to skip or indicating task completion prematurely may result in an incomplete or suboptimal solution.• However, continuing unnecessary actions may waste computational resources and time.</p>
<p>• Your decision impacts the entire multi-agent system's performance.</p>
<p>• Other agents' actions may not correctly address the user requirement, so be prepared to adjust your action accordingly.Your response MUST be in the following JSON format:</p>
<p>{</p>
<p>"thoughts": str = "Your analysis and rationale", "action": str = "EXECUTE/SKIP", "state": bool } Then, we investigate these groups of agents in the context of five different tasks, each requiring a specific set of skills and expertise as shown in Table 8.Specifically, we measure the Task-Role Alignment Score (TRAS) for each team of agent given the task.For instance, the Finance and TECH agent team achieves the highest TRAS for the task of developing a mobile app for real-time stock trading, indicating a strong alignment between the task requirements and the agents' profiles.</p>
<p>F Additional Experiments</p>
<p>F.1 Flexibility to Domain Shift</p>
<p>Table 10: Accuracy comparison of GPTSwarm, Naive, and Ours across two levels of tasks using gpt-4o-mini for all agents.</p>
<p>For each paradigm, the first number indicates the average accuracy on the source domain tasks (BigCodeBench), while the second number shows the average accuracy on the target domain tasks (BigBenchHard or MATH) after completing all sequences.To evaluate our framework's adaptability to changing task requirements, we construct two distinct cross-domain evaluation datasets by the complexity of the target tasks:</p>
<p>Method</p>
<p>• LEVEL-1: This dataset involves a domain shift from BigCodeBench to BigBenchHard, representing a moderate domain shift.• LEVEL-2: This dataset involves a domain shift from BigCodeBench to more challenging MATH that require precise symbolic reasoning and step-by-step logical deductions.</p>
<p>For each dataset, it consists of 50 sequences, where each sequence contains six samples: the first three samples are from the preceding dataset (BigCodeBench), while the latter three are sampled from the target dataset (either BigBenchHard or MATH).In this case, multi-agent systems need to complete tasks in sequence, transitioning from the source domain to the target domain without altering its structure or components.The performance is evaluated separately: accuracy on the source domain is based on the first three samples of each sequence, while accuracy on the target domain is based on the latter three.Each sequence represents a domain shift from one task domain to another, simulating a dynamic environment where task requirements change over time.We also include a Naive solution in the comparison, which designs the profile update as an optional action (without optimizing metrics) in the execution phase.</p>
<p>As shown in Table 10, GPTSwarm exhibits a drastic drop of around 45% when shifting MATH in LEVEL 2, underscoring SOP-based MAS's difficulty in adapting to domain shift.In contrast, our approach maintains robust performance, effectively handling domain shifts with minimal loss in accuracy.This highlights the framework's flexibility and superior ability to maintain high performance across a range of tasks.</p>
<p>F.2 Scalability Analysis</p>
<p>To evaluate the scalability of our method, we examine our method as the number of agents increases, with 3, 5, and 10 agents in MAS.Specifically, we measure the accuracy of problem-solving using the MATH dataset and the average number of interaction rounds required to reach a solution, as shown in Table 11.Firstly, we observe our method maintains relatively stable performance even with a larger number of agents.More interestingly, the average number of interaction rounds increases as more agents are added to the system, as more agents require more communication and coordination.We note that the increase is not linear, indicating that our method's scalability even with larger agent groups.</p>
<p>These findings demonstrate that our method scales reasonably well with an increasing number of agents.However, the increase in interaction rounds with more agents highlights a potential optimization.</p>
<p>Figure 1 :
1
Figure 1: Comparison of LLM-based MAS architectures: (a) Centralized systems with a single coordinator; (b) Decentralized systems with fixed topologies; (c) Decentralized systems with dynamic yet self-organizing topologies.</p>
<p>Figure 2 :
2
Figure 2: Pipeline of MORPHAGENT.Agents start from user requirements, undergo a profile update phase to optimize profiles based on metrics (terminating after a set number of rounds or upon reaching the metric threshold), and then proceed to the task execution phase, where profiles are updated iteratively.The task execution phase ends when consensus is reached or required rounds are completed, with feedback loops ensuring continuous adaptation.</p>
<p>Figure 3 :
3
Figure 3: Comparison with state-of-art baseline methods: Our approach consistently outperforms baseline methods across all three benchmark tasks (Code Generation, General Reasoning, and Mathematical Reasoning) in multiple LLM backbones.</p>
<p>Figure 4 :
4
Figure 4: Standard Performance comparison on Big-CodeBench.We evaluate different MAS frameworks on standard BigCodeBench across multiple LLM backbones.Our method consistently outperforms prior approaches.</p>
<p>Figure 5 :
5
Figure 5: Evolution of agent roles through profile updates.Visualization of agents' role specialization and collaboration network transformation across multiple iterations in a software engineering task.</p>
<p>Table 2 :
2
Examples of feedback prompts for different profile evaluation cases.Agents begin with identical or minimally specified profiles, which are iteratively refined using three key metrics (see Section 3.3 for details).Each iteration, agents receive adaptive feedback prompts based on the changes of their metric scores compared to the previous iteration.The feedback prompts are designed for four different cases for score
CasesExample Feedback PromptInitial Profile
"Refine your role description to focus on key skills and eliminate ambiguity."Improved Profile "Your profile clarity has improved.Keep refining it."Degraded Profile "Your profile's performance has degraded.Revisit recent updates to improve clarity and better align with the task."Similar Profiles "Your profile is too similar to others.Highlight unique skills or responsibilities."Phase 1: Profile Update.changes: (i) initial profile, where profiles typically lack clear descriptions and task alignment; (ii) improved profile, when scores increase, reinforcing positive refinements; (iii) degraded profile, where scores decrease, prompting rollback suggestions; and (iv) similar profiles, which indicate a lack of differentiation among agents, leading to recommendations for better role specialization.</p>
<p>Table 3 :
3
Metrics for Evaluating and Optimizing Agent Profiles.This table presents the three key metrics used for profile optimization: Role Clarity Score (RCS), Role Differentiation Score (RDS), and Task-Role Alignment Score (TRAS).Each metric is described with its core intuition, key components, and a detailed explanation.
Metric IntuitionKey ComponentsExplanationDefines agent unambiguous pro-Syntactic Complexity (DEP)Measures structural richness using dependencyRCSfiles by combining clear gram-parsing. Profiles with deeper syntactic treesmatical structure, non-repetitivescore higher than flat statements.language, and relevant skills.Lexical Diversity (ENT)Computes the entropy of word usage to pe-nalize repetition for semantically diverse lan-guage.Skill Relevance (SKILL)Evaluates alignment with task-specific exper-tise by comparing profile tokens to skill proto-types and identifying skill-bearing nouns.RDSPromotes specialization byPairwise-profile DissimilarityQuantifies how distinct an agent's profile isencouraging diversity.from others.TRAS Matches agents' roles and capa-bilities with task requirements.Profile-task Similarity (S sim )Measures how closely task requirements lin-guistically align with agent profiles using em-beddings from pretrained language models.Capability Compatibility (S cap )Ensures agents' capability match task'scomplexity.</p>
<p>Table 4 :
4
Ablation
+ None50.67%38.33%+ RCS50.00%39.33%+ RDS41.66%37.00%+ TRAS49.66%35.33%MORPHAGENT52.00%43.33%
study on BigCodeBench analyzing the effect of individual profile optimization metrics.Results show that using any single metric does not consistently outperform the combination of RCS, RDS, and TRAS.Setting GPT-4o-mini GPT-3.5-Turbo</p>
<p>Agents begin with identical, minimally defined profiles, resulting in undifferentiated behavior.All agents redundantly perform Code Development without coordination, leading to low efficiency due to a lack of role diversity and structured interaction.2. Iteration II: Emerging Specialization.Profile updates introduce early role differentiation, reflected by rising RCS and TRAS scores.One agent begins focusing on Communication, improving coordination.However, most agents still overlap in Code Development, limiting efficiency gains despite denser interaction.
3. Iteration V: Optimized Collaboration. With continued adaptation, agents exhibit distinct and complementaryroles-e.g., coordination, development, and debugging. Higher RCS (0.7877) and RDS (0.5051) indicate refinedprofiles and efficient task-role alignment, resulting in structured, dynamic collaboration and reduced redundancy.
1. Iteration I: Unstructured Collaboration.This case study showcases the impact of Dynamic Profile Mechanism (Definition 3.3) in refining agent roles, enhancing task allocation, and boosting system efficiency.It demonstrates how agents continuously adapt to evolving requirements, enabling Self-Organization in decentralized MAS.</p>
<p>Prototype Term Sets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .15 A.2 Vector Construction Process . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .15 A.3 Complexity and Capability Assessment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .15 Detailed Prompts for Agent Profile Updates . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .18 C.2 Action Prompts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .19 Flexibility to Domain Shift . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .24 F.2 Scalability Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .24
A Detailed Implementation for metrics14A.1 B Dynamic profile optimization process16C Detailed Prompts18C.1 D Profile Analysis21E Benchmark Analysis23F Additional Experiments24F.1</p>
<p>Based on your own and other agents' recent actions and results.You are tasked with providing feedback.Analyze the information provided and give constructive feedback.Current context (User Request, History of agents' actions): {context} Your Latest Execution: {execution} Your Latest Execution result: {execution_result} Please provide feedback addressing the following points: 1. Self-reflection: • Evaluate the effectiveness of your approach.Was it aligned with the task requirements?• Identify strengths in your execution.What worked well?• Recognize areas for improvement.What could you have done differently?• Assess the quality and relevance of your result.Does it contribute significantly to the overall task? 2. Analysis of other agents:
C.2 Action PromptsFeedback Prompt0.7300 0.5051 0.6664</p>
<p>Based on the user requirement and the current context (other agents' progress), analyze the situation and decide on your next action.Consider the following actions:
{"execution_content": "Your execution content here","is_valid": boolean}Update PromptYou will update your profile based on the user requirement, the current context, last Execution and result andyour own self-reflection.User Requirement: {user_requirement}Latest Execution: {latest_execution}Latest Execution Result: {latest_execution_result}Feedback: {feedback}Previous agents' profiles updates: {context}{prompt}Please update your profile directly below:Agent PromptUser Requirement: {user_requirement}Context (Other agents' Progress): {context}</p>
<p>Table 8 :
8
Measuring Task-Role Alignment Score (TRAS) for Different Teams of Agents: Finance, TECH, CREATIVE, Healthcare, and VAGUE for five different tasks.
TaskTeamTRASFinance0.54Develop a mobile app forTECH0.38real-time stock tradingCREATIVE0.34HEALTHCARE0.30VAGUE0.30HEALTHCARE0.50Create a comprehensive patientTECH0.44management systemFinance0.37VAGUE0.36CREATIVE0.34CREATIVE0.43Design and launch a globalFinance0.35brand campaignTECH0.32VAGUE0.30HEALTHCARE0.24Finance0.50Implement a blockchain-basedTECH0.39supply chain tracking systemCREATIVE0.33VAGUE0.33HEALTHCARE0.31HEALTHCARE0.42Conduct a clinical trial for aFinance0.39novel cancer treatmentVAGUE0.36TECH0.35CREATIVE0.34</p>
<p>Table 11 :
11
Scalability analysis on MATH dataset using GPT-4o-mini.While more agents lead to slightly higher communication overhead, the interaction rounds increase with more agents but not linearly, showing MORPHAGENT's scalability.</p>
<h1>Agents Accuracy Avg. Interaction Rounds366.67%1.54566.19%1.611065.71%2.06</h1>
<p>As shown in Appendix F.2, we set agent number as 3 which is sufficient for benchmark problem solving. This configuration will be consistently applied in subsequent benchmark evaluations.
The version is gpt-4o-mini-2024-07-18.
https://api-docs.deepseek.com/news/news1226.
The version is gpt-3.5-turbo-0125.
C Detailed Prompts C.1 Detailed Prompts for Agent Profile UpdatesIn this section, we provide detailed prompts generated for agent profile updates based on the evaluation metrics.Table6presents a comprehensive overview of the profile evaluation process, outlining four key scenarios: initial evaluation, improved profile, degraded profile, and similar profiles among agents.Given the metrics, the generated prompts provide corresponding feedback to agents to guide them in refining their profiles.For example, in the initial evaluation scenario, the prompt highlights the lack of clarity and differentiation in the agent's profile, prompting them to consider adjusting their profile text.Ensure your profile remains clear and aligned with the task while striving for distinctiveness.In contrast, the improved profile scenario acknowledges the positive changes in the agent's profile, encouraging them to maintain their progress.Similarly, the degraded profile scenario draws attention to negative changes, prompting agents to refine their profiles accordingly.Lastly, the similar profiles scenario emphasizes the need for differentiation, especially when profiles are similar to those of other agents.Through these varied scenarios and targeted prompts, we demonstrate the flexibility and effectiveness of our prompt generation system in fostering continuous improvement and adaptation within the multi-agent environment.D Profile AnalysisIn this section, we provide a detailed analysis of agent profiles across different teams to show the effectiveness of our proposed metrics in evaluating agent profiles.We consider five teams of agents, each representing a distinct domain: TECH, HEALTHCARE, CREATIVE, Finance, and VAGUE.Each group consists of three agents, with each agent having a unique profile as shown in Table7. Notably, the VAGUE agent team gets the lowest Role Clarity Score (RCS) due to the lack of specificity in their profiles.In contrast, the TECH and Health agent teams exhibit higher RCS values, indicating clear and well-defined profiles.For RDS, the CREATIVE agent team achieves the lowest score, suggesting less differentiation among agents for the similar roles between CreativeAgent1 and CreativeAgent3.interestingly, VAGUE agent team has a relative high RDS, indicating a higher level of differentiation among agents.This highlight differentiation along can be misleading and should be considered in conjunction with other metrics such as TRAS.E Benchmark AnalysisTo comprehensively understand the MAS benchmarks, we conducted a review of 7 ICLR 2025 papers focused on LLM-based MAS (including Oral, Highlight and Poster).For clarity, we've included only datasets used in multiple papers to highlight established benchmarks.As shown in the table below, we claim:1. Our evaluation spans the same critical domains as existing work (code generation, reasoning, and math problem solving).2. We use more recent and hard benchmarks than others, i.e., BigBenchHard (2022) for reasoning instead of MMLU (2020) and BigCodeBench (2023) for code instead of HumanEval(2021).3. Future developments of benchmarks will advance MAS, but that is not our current focus.Specifically, our carefully selected datasets directly correspond to the domains covered in existing work while offering more recent and comprehensive alternatives:1. MATH (2021) aligns with the advanced mathematical reasoning domain covered in 2 papers (EvoMAC and our work).It provides a more structured evaluation of collaborative problem-solving capabilities than elementary math datasets like GSM8K. 2. BigBenchHard (BBH) (2022) corresponds to the reasoning tasks assessed by MMLU (2020), ARC (2018), and DROP (2019), but offers more challenging problems specifically selected to be difficult for standard LLMs.This makes it particularly suitable for demonstrating the advantages of multi-agent collaboration.3. BigCodeBench (2023) covers the same code generation domain as HumanEval (2021) but provides a more comprehensive evaluation with 1,140 tasks across 7 domains compared to HumanEval's 164 problems.Our evaluation not only spans the same critical domains as existing work (code generation, reasoning, and math problem solving) but also uses more recent benchmarks.
Swarm intelligence in cellular robotic systems. Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, arXiv:2303.08774Robots and biological systems: towards a new bionics?. Springer2023. 1993Gpt-4 technical report. arXiv preprintGerardo Beni and Jing Wang</p>
<p>Swarm robotics: a review from the swarm engineering perspective. Manuele Brambilla, Eliseo Ferrante, Mauro Birattari, Marco Dorigo, Swarm Intelligence. 72013</p>
<p>Chi-Min Chan, Weize Chen, Yusheng Su, Jianxuan Yu, Wei Xue, Shanghang Zhang, Jie Fu, Zhiyuan Liu, arXiv:2308.07201Chateval: Towards better llm-based evaluators through multi-agent debate. 2023arXiv preprint</p>
<p>Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors. Weize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei Yuan, Chi-Min Chan, Heyang Yu, Yaxi Lu, Yi-Hsin Hung, Chen Qian, Yujia Qin, Xin Cong, Ruobing Xie, Zhiyuan Liu, Maosong Sun, Jie Zhou, The Twelfth International Conference on Learning Representations. 2024</p>
<p>From animal collective behaviors to swarm robotic cooperation. Haibin Duan, Mengzhen Huo, Yanming Fan, National Science Review. 105402023</p>
<p>ACC-collab: An actor-critic approach to multiagent LLM collaboration. Andrew Estornell, Jean-Francois Ton, Yuanshun Yao, Yang Liu, The Thirteenth International Conference on Learning Representations. 2025</p>
<p>Leveraging pre-trained large language models to construct and utilize world models for model-based task planning. Lin Guan, Karthik Valmeekam, Sarath Sreedharan, Subbarao Kambhampati, Thirty-seventh Conference on Neural Information Processing Systems. 2023</p>
<p>Large language model based multi-agents: A survey of progress and challenges. Taicheng Guo, Xiuying Chen, Yaqi Wang, Ruidi Chang, Shichao Pei, V Nitesh, Olaf Chawla, Xiangliang Wiest, Zhang, 10.24963/ijcai.2024/890Proceedings of the Thirty-Third International Joint Conference on Artificial Intelligence, IJCAI-24. Kate Larson, the Thirty-Third International Joint Conference on Artificial Intelligence, IJCAI-2482024</p>
<p>Embodied llm agents learn to cooperate in organized teams. Xudong Guo, Kaixuan Huang, Jiale Liu, Wenhui Fan, Natalia Vélez, Qingyun Wu, Huazheng Wang, Thomas L Griffiths, Mengdi Wang ; Shanshan Han, Qifan Zhang, Yuhang Yao, arXiv:2403.12482arXiv:2402.03578Weizhao Jin, Zhaozhuo Xu, and Chaoyang He. Llm multi-agent systems: Challenges and open problems. 2024b. 2024arXiv preprint</p>
<p>Measuring mathematical problem solving with the math dataset. Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song, Jacob Steinhardt, 2021NeurIPS</p>
<p>MetaGPT: Meta programming for a multi-agent collaborative framework. Sirui Hong, Mingchen Zhuge, Jonathan Chen, Xiawu Zheng, Yuheng Cheng, Jinlin Wang, Ceyao Zhang, Zili Wang, Steven Ka, Shing Yau, Zijuan Lin, Liyang Zhou, Chenyu Ran, Lingfeng Xiao, Chenglin Wu, Jürgen Schmidhuber, The Twelfth International Conference on Learning Representations. 2024</p>
<p>Automated design of agentic systems. Shengran Hu, Cong Lu, Jeff Clune, The Thirteenth International Conference on Learning Representations. 2025a</p>
<p>Self-evolving multi-agent collaboration networks for software development. Yue Hu, Yuzhu Cai, Yaxin Du, Xinyu Zhu, Xiangrui Liu, Zijie Yu, Yuchen Hou, Shuo Tang, Siheng Chen, arXiv:2410.169462024arXiv preprint</p>
<p>Selfevolving multi-agent collaboration networks for software development. Yue Hu, Yuzhu Cai, Yaxin Du, Xinyu Zhu, Xiangrui Liu, Zijie Yu, Yuchen Hou, Shuo Tang, Siheng Chen, The Thirteenth International Conference on Learning Representations. 2025b</p>
<p>Agentcoder: Multi-agent-based code generation with iterative testing and optimisation. Dong Huang, Qingwen Bu, M Jie, Michael Zhang, Heming Luck, Cui, arXiv:2312.130102023arXiv preprint</p>
<p>Language models as zero-shot planners: Extracting actionable knowledge for embodied agents. Wenlong Huang, Pieter Abbeel, Deepak Pathak, Igor Mordatch, Proceedings of the 39th International Conference on Machine Learning. the 39th International Conference on Machine Learning2022</p>
<p>SWE-bench: Can language models resolve real-world github issues?. Carlos E Jimenez, John Yang, Alexander Wettig, Shunyu Yao, Kexin Pei, ; Karthik R Narasimhan, The Twelfth International Conference on Learning Representations. Ofir Press2024</p>
<p>Speech and language processing. Daniel Jurafsky, 2000</p>
<p>Dependency parsing. Sandra Kübler, Ryan Mcdonald, Joakim Nivre, Dependency parsing. Springer2009</p>
<p>Agent-oriented planning in multiagent systems. Ao Li, Yuexiang Xie, Songze Li, Fugee Tsung, Bolin Ding, Yaliang Li, The Thirteenth International Conference on Learning Representations. 2025</p>
<p>Camel: Communicative agents for" mind" exploration of large language model society. Guohao Li, Hasan Hammoud, Hani Itani, Dmitrii Khizbullin, Bernard Ghanem, Advances in Neural Information Processing Systems. 202336</p>
<p>Training socially aligned language models on simulated social interactions. Ruibo Liu, Ruixin Yang, Chenyan Jia, Ge Zhang, Denny Zhou, Andrew M Dai, Diyi Yang, Soroush Vosoughi, arXiv:2305.169602023arXiv preprint</p>
<p>Breaking mental set to improve reasoning through diverse multi-agent debate. Yexiang Liu, Jie Cao, Zekun Li, The Thirteenth International Conference on Learning Representations. 2025Ran He, and Tieniu Tan</p>
<p>Self-refine: Iterative refinement with self-feedback. Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, Shashank Gupta, Bodhisattwa Prasad Majumder, Katherine Hermann, Sean Welleck, Amir Yazdanbakhsh, Peter Clark, Thirty-seventh Conference on Neural Information Processing Systems. 2023</p>
<p>. Yohei Nakajima, Babyagi, 2023</p>
<p>Swarm intelligence-based multi-robotics: A comprehensive review. Luong Vuong, Nguyen , AppliedMath. 442024</p>
<p>Chen Qian, Xin Cong, Cheng Yang, Weize Chen, Yusheng Su, Juyuan Xu, Zhiyuan Liu, Maosong Sun, arXiv:2307.07924Communicative agents for software development. 62023arXiv preprint</p>
<p>Chatdev: Communicative agents for software development. Chen Qian, Wei Liu, Hongzhang Liu, Nuo Chen, Yufan Dang, Jiahao Li, Cheng Yang, Weize Chen, Yusheng Su, Xin Cong, Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics. Long Papers. the 62nd Annual Meeting of the Association for Computational Linguistics20241</p>
<p>Scaling large language model-based multi-agent collaboration. Chen Qian, Zihao Xie, Yifei Wang, Wei Liu, Kunlun Zhu, Hanchen Xia, Yufan Dang, Zhuoyun Du, Weize Chen, Cheng Yang, Zhiyuan Liu, Maosong Sun, The Thirteenth International Conference on Learning Representations. 2025</p>
<p>Self-reflection in llm agents: Effects on problem-solving performance. Matthew Renze, Erhan Guven, 2024</p>
<p>Artificial swarm intelligence. Louis Rosenberg, Gregg Willcox, Intelligent Systems and Applications: Proceedings of the 2019 Intelligent Systems Conference (IntelliSys. Springer20201</p>
<p>Reflexion: language agents with verbal reinforcement learning. Noah Shinn, Federico Cassano, Ashwin Gopinath, Shunyu Karthik R Narasimhan, Yao, Thirty-seventh Conference on Neural Information Processing Systems. 2023</p>
<p>Challenging big-bench tasks and whether chain-of-thought can solve them. Mirac Suzgun, Nathan Scales, Nathanael Schärli, Sebastian Gehrmann, Yi Tay, Hyung Won Chung, Aakanksha Chowdhery, Ed H Quoc V Le, Denny Chi, Jason Zhou, Wei, arXiv:2210.092612022arXiv preprint</p>
<p>. Torantulino, Autogpt, 2023</p>
<p>Thibaut Hugo Touvron, Gautier Lavril, Xavier Izacard, Marie-Anne Martinet, Timothée Lachaux, Baptiste Lacroix, Naman Rozière, Eric Goyal, Hambro, arXiv:2302.13971Faisal Azhar, et al. Llama: Open and efficient foundation language models. 2023aarXiv preprint</p>
<p>Edouard Grave, and Guillaume Lample. Llama: Open and efficient foundation language models. Thibaut Hugo Touvron, Gautier Lavril, Xavier Izacard, Marie-Anne Martinet, Timothée Lachaux, Baptiste Lacroix, Naman Rozière, Eric Goyal, Faisal Hambro, Aurelien Azhar, Armand Rodriguez, Joulin, 2023b</p>
<p>A survey on large language model based autonomous agents. Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang, Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, Frontiers of Computer Science. 1861863452024</p>
<p>Describe, explain, plan and select: Interactive planning with LLMs enables open-world multi-task agents. Zihao Wang, Shaofei Cai, Guanzhou Chen, Anji Liu, Xiaojian Ma, Yitao Liang, Thirty-seventh Conference on Neural Information Processing Systems. 2023</p>
<p>Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, Yuan Cao, arXiv:2210.03629React: Synergizing reasoning and acting in language models. 2022arXiv preprint</p>
<p>Proagent: building proactive cooperative agents with large language models. Ceyao Zhang, Kaijie Yang, Siyi Hu, Zihao Wang, Guanghe Li, Yihang Sun, Cheng Zhang, Zhaowei Zhang, Anji Liu, Song-Chun Zhu, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202438</p>
<p>AFLOW: Automating agentic workflow generation. Jiayi Zhang, Jinyu Xiang, Zhaoyang Yu, Fengwei Teng, Xiong-Hui Chen, Jiaqi Chen, Mingchen Zhuge, Xin Cheng, Sirui Hong, Jinlin Wang, Bingnan Zheng, Bang Liu, Yuyu Luo, Chenglin Wu, The Thirteenth International Conference on Learning Representations. 2025</p>
<p>Xuhui Zhou, Hao Zhu, Leena Mathur, Ruohong Zhang, Haofei Yu, Zhengyang Qi, Louis-Philippe Morency, Yonatan Bisk, Daniel Fried, Graham Neubig, arXiv:2310.11667Interactive evaluation for social intelligence in language agents. 2023arXiv preprint</p>
<p>GPTSwarm: Language agents as optimizable graphs. Mingchen Zhuge, Wenyi Wang, Louis Kirsch, Francesco Faccio, Dmitrii Khizbullin, Jürgen Schmidhuber, Forty-first International Conference on Machine Learning. 2024</p>
<p>Terry Yue Zhuo, Minh Chien Vu, Jenny Chim, Han Hu, Wenhao Yu, Ratnadira Widyasari, Imam Nur, Bani Yusuf, Haolan Zhan, arXiv:2406.15877Junda He, Indraneil Paul, et al. Bigcodebench: Benchmarking code generation with diverse function calls and complex instructions. 2024arXiv preprint</p>            </div>
        </div>

    </div>
</body>
</html>