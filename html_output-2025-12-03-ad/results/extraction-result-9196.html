<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-9196 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-9196</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-9196</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-162.html">extraction-schema-162</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <p><strong>Paper ID:</strong> paper-266359648</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2312.10968v1.pdf" target="_blank">PARs: Predicate-based Association Rules for Efficient and Accurate Model-Agnostic Anomaly Explanation</a></p>
                <p><strong>Paper Abstract:</strong> While new and effective methods for anomaly detection are frequently introduced, many studies prioritize the detection task without considering the need for explainability. Yet, in real-world applications, anomaly explanation, which aims to provide explanation of why specific data instances are identified as anomalies, is an equally important task. In this work, we present a novel approach for efficient and accurate model-agnostic anomaly explanation for tabular data using Predicate-based Association Rules (PARs). PARs can provide intuitive explanations not only about which features of the anomaly instance are abnormal, but also the reasons behind their abnormality. Our user study indicates that the anomaly explanation form of PARs is better comprehended and preferred by regular users of anomaly detection systems as compared to existing model-agnostic explanation options. Furthermore, we conduct extensive experiments on various benchmark datasets, demonstrating that PARs compare favorably to state-of-the-art model-agnostic methods in terms of computing efficiency and explanation accuracy on anomaly explanation tasks. The code for PARs tool is available at https://github.com/NSIBF/PARs-EXAD.</p>
                <p><strong>Cost:</strong> 0.005</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <p class="empty-note">No extracted data.</p>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <p class="empty-note">No potentially relevant new papers extracted.</p>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-9196",
    "paper_id": "paper-266359648",
    "extraction_schema_id": "extraction-schema-162",
    "extracted_data": [],
    "potentially_relevant_new_papers": [],
    "cost": 0.0045604999999999995,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>PARs: Predicate-based Association Rules for Efficient and Accurate Model-Agnostic Anomaly Explanation
18 Dec 2023</p>
<p>Cheng Feng cheng.feng@siemens.com 
Siemens Technology China</p>
<p>PARs: Predicate-based Association Rules for Efficient and Accurate Model-Agnostic Anomaly Explanation
18 Dec 2023847509991064707F09164BA4776A7873arXiv:2312.10968v1[cs.LG]
While new and effective methods for anomaly detection are frequently introduced, many studies prioritize the detection task without considering the need for explainability.Yet, in real-world applications, anomaly explanation, which aims to provide explanation of why specific data instances are identified as anomalies, is an equally important task.In this work, we present a novel approach for efficient and accurate model-agnostic anomaly explanation for tabular data using Predicate-based Association Rules (PARs).PARs can provide intuitive explanations not only about which features of the anomaly instance are abnormal, but also the reasons behind their abnormality.Our user study indicates that the anomaly explanation form of PARs is better comprehended and preferred by regular users of anomaly detection systems as compared to existing model-agnostic explanation options.Furthermore, we conduct extensive experiments on various benchmark datasets, demonstrating that PARs compare favorably to state-of-the-art model-agnostic methods in terms of computing efficiency and explanation accuracy on anomaly explanation tasks.The code for PARs tool is available at https://github.com/NSIBF/PARs-EXAD.</p>
<p>Introduction</p>
<p>Anomaly detection, which aims to identify data instances that do not conform to the expected behavior, is a classic machine learning task with numerous applications in various domains including fraud detection, intrusion detection, predictive maintenance, etc.Over the past decades, numerous methods have been proposed to tackle this challenging problem.Examples include one-class classificationbased (Manevitz and Yousef 2001;Ruff et al. 2018), nearest neighbor-based (Breunig et al. 2000), clustering-based (Jiang and An 2008), isolation-based (Liu, Ting, and Zhou 2012;Hariri, Kind, and Brunner 2019), density-based (Liu, Tan, and Zhou 2022;Feng and Tian 2021) and deep anomaly detection models based on autoencoders (Zhou and Paffenroth 2017;Zong et al. 2018), generative adversarial networks (Zenati et al. 2018;Han, Chen, and Liu 2021), to name a few.However, comparing to the vast body of literature on the detection task, anomaly explanation techniques have received relatively little attention so far (Ruff et al. 2021).In fact, providing accurate explanations of why specific data instances are detected as anomalies is equally critical for many real-world applications.For instance, when an anomaly is reported by a fault detection application for a critical device in a factory, human operators need straightforward clues regarding the reported anomaly, and then can decide what next steps -such as fault diagnosis, predictive maintenance and system shutdown -should be taken.The required clues include which feature(s) is abnormal, why that feature(s) is abnormal.Furthermore, since model selection has a significant impact on the performance of anomaly detection tasks for tabular data (Han et al. 2022), providing model-agnostic anomaly explanation is considered more helpful than model-specific approaches that are only applicable to specific detection models.</p>
<p>To fill this gap, we propose a novel approach for efficient and accurate model-agnostic anomaly explanation for tabular data.Specifically, we leverage association rule mining (Agrawal, Imieli≈Ñski, and Swami 1993) to learn Predicatebased Association Rules (PARs) which capture normal behaviors exhibited by training data.During inference, we efficiently find the precise PARs for explaining anomalies identified by arbitrary anomaly detection models.PARs provide intuitive explanations not only about which features of the anomaly instance are abnormal, but also why those features are abnormal.Our user study shows that the anomaly explanation form of PARs is better understood and favoured by regular anomaly detection system users compared with existing model-agnostic anomaly explanation options.In our experiments, we demonstrate that it is significantly more efficient to find PARs than anchors (Ribeiro, Singh, and Guestrin 2018), another rule-based explanation, for identified anomaly instances.Moreover, PARs are also far more accurate than anchors for anomaly explanation, meaning that they have considerably higher precision and recall when applied as anomaly detection rules on unseen data other than the anomaly instance on which they were originally derived for explanation.Additionally, we show that PARs can also achieve higher accuracy on abnormal feature identification compared with many state-of-the-art model-agnostic explanation methods including LIME (Ribeiro, Singh, and Guestrin 2016), SHAP (Lundberg and Lee 2017), COIN (Liu, Shin, and Hu 2018) and ATON (Xu et al. 2021).We summarize the main contributions of this paper as follows:</p>
<p>‚Ä¢ We introduce PARs, a novel and informative explanation form for anomalies, and the form of PARs is more appealing to regular anomaly detection system users ac-cording to our user study.‚Ä¢ We provide a purely data-driven approach to efficiently constructing and finding the precise PARs for anomaly explanation.‚Ä¢ We reduce the expected time cost of deriving explanation rules for a single anomaly instance from tens of seconds to less than one second compared to anchors, which is critical for online anomaly detection and diagnosis applications.‚Ä¢ We conduct extensive experiments on public benchmark datasets to show that PARs can achieve more accurate anomaly explanation than existing model-agnostic explanation methods.</p>
<p>PARs as Anomaly Explanations</p>
<p>Given a black box anomaly detection model f : X ‚àí‚Üí Y where Y ‚àà {0, 1} with 0 indicating normality and 1 indicating abnormality, and an anomaly data instance x ‚àà X with f (x) = 1, let F be all the features of X , our modelagnostic anomaly explanation aims to achieve two goals: 1) identify the abnormal feature subspace F sub ‚àà F of x; 2) intuitively explain why the feature subspace F sub of x is abnormal.Both goals can be well achieved by PARs.Specifically, a PAR is an association rule in the following form: P ‚àí‚Üí p where P represents a set of antecedent predicates and p represents a single consequent predicate such that p / ‚àà P .PARs describe patterns of behavior that normal data instances should follow.An anomaly instance x can be explained by a PAR if it violates the PAR, i.e., all the antecedent predicates of the PAR are satisfied but the consequent predicate is not satisfied by x.For example, in Table 1, the PAR Level&gt;10, Pump=ON ‚àí‚Üí Valve=Open gives following explanation for the anomaly instance x=[11.1,ON,Close,25]with features F=[Level, Pump, Valve, Temperature]: the Valve feature is abnormal because according to the PAR, when Level&gt;10 and Pump=ON, then Valve should be Open, however, Valve=Close in x.This PAR actually describes a physical law that governs the behavior of a water tank system, where the outlet valve must be open to prevent the tank from exploding when the water level in the tank exceeds a certain threshold and the inlet pump remains on.Utilizing such rules with potential physical meanings for anomaly explanation is highly helpful for assisting users in understanding and diagnosing detected anomalies.Due to limited space, we put more examples of PARs for explaining anomaly instances in real-world usecases in the appendix.</p>
<p>Related Work</p>
<p>Model-agnostic Anomaly Explanation</p>
<p>The mainstream of prior art on model-agnostic anomaly explanation is to find the most anomalous/outlying feature subspace of anomaly instances in the score-and-search manner (Duan et al. 2015;Vinh et al. 2016;Samariya et al. 2020;Samariya, Ma, and Aryal 2020).Specifically, these methods identify abnormal features by searching for possible feature subspaces and compute the anomalous/outly-ing score of the anomaly instance in each subspace.However, since the number of possible subspaces increases exponentially with the growth of feature dimension, these methods are oftentimes too costly and potentially ineffective for high-dimensional data.Consequently, some methods are proposed to improve the efficiency and accuracy of abnormal feature identification.For example, SOAM (L√ºdtke, Bartelt, and Stuckenschmidt 2023) is an outlying feature mining method which fits an Sum-Product Network (SPN) to model high-dimensional feature distributions, and leverages the tractability of marginal inference in SPNs to efficiently compute outlier scores in feature subsets.COIN (Liu, Shin, and Hu 2018) transforms the anomaly explanation task into a classification problem which involves training a series of l1‚àínorm classifiers that separate augmented anomalies from clusters of normal data in close proximity, and uses the classifiers' weights as anomaly contribution weights of features.ATON (Xu et al. 2021) leverages the attention mechanism of neural networks to assign anomaly contribution weights to feature dimensions.Specifically, it utilizes a triplet deviation-based loss which estimates the separability of the anomaly instance and some heuristically sampled informative normal data within the triplets, and then a selfattention module is optimized to compute the contribution of each feature dimension to the anomaly instance.</p>
<p>It is noteworthy to mention that most model-agnostic anomaly explanation methods like above focus on providing explanations for why the data instance is abnormal rather than why the anomaly detection algorithm has deemed it to be so.This is because the primary objective of anomaly explanation is to assist users for subsequent decision-making and diagnosis regarding the reported anomalies.PARs also focus on explaining the abnormality of data instead of the decision logic of the anomaly detection algorithm.</p>
<p>General Local Model-agnostic Explanation</p>
<p>Although not specifically designed for anomaly explanation tasks, some general local model-agnostic explanation methods that employ a perturbation-based strategy to generate local explanations for predictions of black box machine learning models, such as LIME (Ribeiro, Singh, and Guestrin 2016), SHAP (Lundberg and Lee 2017) and Anchor (Ribeiro, Singh, and Guestrin 2018), are frequently used for anomaly explanation by considering anomaly detection as a binary classification problem.However, there are certain drawbacks of utilizing these general methods for anomaly explanation: 1) the perturbation-based strategy to generate local explanations for the algorithms is rather timeconsuming, this makes such methods less applicable in typical online anomaly detection applications.2) Determining the precise form to explain the decision logic of a complex anomaly detection algorithm is far more difficult than identifying the correct cause for the abnormality of data, which makes the derived explanations less robust than those methods directly explaining the abnormality of data.</p>
<p>Anomaly Explanation Forms</p>
<p>It is important to emphasize that both informativeness and intuitiveness are crucial for anomaly explanation methods.To show the differences between the anomaly explanation forms provided by various model-agnostic methods, we illustrate the explanations of SOAM, COIN, ATON, SHAP, LIME, Anchor and PAR to an anomaly instance in a water tank condition monitoring dataset in Table 1.As can be seen, most existing anomaly explanation methods only handle the abnormal feature identification task but do not provide intuitive explanations about why the corresponding features are abnormal.The only exception is Anchor, which also provides rule-based explanation about why a data instance is reported as anomaly.However, PARs are more informative than anchors.Referring to the example presented in Table 1, when the predicate violation on the right-hand side is known, specifically Valve=Open, the user is able to identify the suspected abnormal feature.However, the anchor rule fails to accurately pinpoint the specific abnormal feature.Additionally, understanding the predicate violation on the right-hand side also informs the user about the correct behavior expected from the abnormal feature.In this instance, the valve should be in an open state rather than closed.This crucial information cannot be derived from the anchor rule when the variable can assume more than two potential values.</p>
<p>Relation to Explainable Anomaly Detection</p>
<p>There are existing methods which leverage association rules (Yairi, Kato, and Hori 2001;Pal, Adepu, and Goh 2017;Feng et al. 2019) and other dependency-based methods (Paulheim and Meusel 2015;Lu et al. 2020;Feng et al. 2020) for explainable anomaly detection (Li, Zhu, and Van Leeuwen 2023).However, we emphasize that our work is fundamentally different from those explainable anomaly detection methods.Specifically, those methods did not separate the anomaly detection task from the anomaly explanation task.Consequently, their application in practice is significantly limited due to their reliance on a relatively weak or less-general model for anomaly detection.In contrast, our approach designs a novel systematic framework for efficiently constructing and leveraging association rules exclusively for anomaly explanation.The decoupling of the anomaly explanation task from the anomaly detection task makes our method highly general and useful in practical applications.</p>
<p>Learning PARs from Data</p>
<p>In contrast to general local model-agnostic explanation methods where explanations are generated by a costly perturbation-based process during inference, we learn and store all PARs in the training stage.During inference, we simply need to efficiently find the precise PARs to explain the anomaly instance.</p>
<p>Learning PARs from a given dataset D mainly consists of two steps: predicate generation and PAR mining.Firstly, we derive a global predicate set P in the predicate generation step.We then transform each data instance x ‚àà D as a set of satisfied predicates P such that P ‚äÜ P. Let P 1 , . . ., P |D| represent the records of satisfied predicates for all data instances in D, we then mine all PARs that satisfy a minimum support condition and a minimum confidence condition from the records.Specifically, let P ‚àí‚Üí p be a PAR, Œ∏ and Œ≥ be the minimum support and minimum confidence thresholds respectively, we require sup(P ‚àí‚Üí p) &gt; Œ∏ and conf (P ‚àí‚Üí p) &gt; Œ≥ where sup(P ‚àí‚Üí p) = #(P ‚à™p) |D| measures the frequency of apparition of P ‚à™ p within the dataset, conf (P ‚àí‚Üí p) = sup(P ‚àí‚Üíp) sup(P ) measures the percentage of data satisfying all the predicates in P that also satisfy the consequent predicate p. Intuitively, a higher support for a PAR indicates a higher coverage of data whereas a higher confidence indicates a higher precision for explaining anomalies.</p>
<p>Predicate Generation</p>
<p>The quality of the global predicate set P is critical in our method.Specifically, the generated predicates should have high likelihoods leading to PARs.Furthermore, the form of generated predicates should be as simple as possible to maximize the interpretability of PARs.With these points in mind, we propose two algorithms for generating predicates, one specifically for categorical features and the other for numeric features.Before presenting the algorithms, it is important to highlight that in order for any generated predicate p to have a nonzero probability of contributing to a PAR, sup(p) &gt; Œ∏ is required.It can be seen that if the support of a predicate p is less than Œ∏, then p can never contribute to any PAR due to the anti-monotone constraint (Ng et al. 1998).</p>
<p>Predicate Generation for Categorical Features The algorithm of generating predicates for categorical features is straightforward.Let {1, . . ., U } be the set of observed values for a categorical feature F c in D, we generate candidate predicates p : F c = u for all u ‚àà {1, . . ., U }.If sup(p) &gt; Œ∏, we add p to P. Otherwise, we add p to a list L which stores candidate predicates whose supports are less than the threshold.Then, we traverse all predicates in L and use the "or"("|") operator to generate combined predicates until their supports are larger than the threshold.For example, let sup(p 1 ) &lt; Œ∏ and sup(p 2 ) &lt; Œ∏, we generate a combined predicate p :
p 1 |p 2 if sup(p 1 |p 2 ) &gt; Œ∏.
It is noteworthy to mention that we also prioritize the combination of predicates belonging to the same feature to optimize interpretability.Implementation details of the algorithm for categorical features is given in the appendix.</p>
<p>Predicate Generation for Numeric Features</p>
<p>To promote interpretability, we generate predicates for each numeric feature by a set of proposed cut-off values.For example, assuming there are three cut-off values œÑ 1 , œÑ 2 , œÑ 3 for a numeric feature F n where œÑ 1 &lt; œÑ 2 &lt; œÑ 3 , we generate four predicates which are p 1 :
F n &lt; œÑ 1 , p 2 : œÑ 1 ‚â§ F n &lt; œÑ 2 , p 3 : œÑ 2 ‚â§ F n &lt;
œÑ 3 and p 4 : F n ‚â• œÑ 3 and add them to P if the support for each predicate is larger than Œ∏.Moreover, we prefer cut-off values for a numeric feature which maximize the reduction of uncertainty in other features.In this way, predicates generated by such cut-off values could contribute to PARs with high likelihoods.Concretely, we employ a dependency-based approach which consists of following two steps to generate predicates for numeric features: 1) propose a set of candidate cut-off values by learning decision tree (DT) models on D, 2) select cut-off values with higher impurity decrease to generate predicates.</p>
<p>Propose candidate cut-off values: In this step, we learn two sets of DT models on D to propose candidate cut-off values.Specifically, Let F c and F n be the set of all categorical features and the set of all numeric features of the dataset, we first learn a DT classification model DT (F n ) ‚àí‚Üí F c for each categorical feature F c ‚àà F c where all the numeric features F n are used as input variables and F c is the prediction target.As for the second set, we learn a DT regression model DT (F n ‚àíi ) ‚àí‚Üí F n i for each numeric feature F n i ‚àà F n where all the remaining numeric features F n ‚àíi are used as input variables.Information gain and variance reduction1 are used to measure the quality of a split for the classification models and the regression models, respectively.We set the minimum number of samples required at a leaf node to be greater than |D| √ó Œ∏ as the stop criterion for the training of DT models.This avoids creating cut-off values which would definitely lead to predicates with support lower than Œ∏.Since each internal node in a learned DT model defines a split rule 1 (œÑ,‚àû) (x F n ) where œÑ is a cut-off value on feature F n that directs an instance x to the left/right child node, we can extract a tuple (F n , œÑ, q œÑ ) from an internal node where q œÑ is the impurity decrease of the node.Specifically,
q œÑ = N |D| (H ‚àí N lef t N H lef t ‚àí N right N H right )
where N , N lef t and N right are the number of data instances reaching the node, its left child and its right child; H, H lef t and H right are the impurity of the target feature for data reaching the node, its left child and right child, respectively.More specifically, impurity at a node is calculated as the entropy of the target feature for the data reaching the node for DT classification models and variance of the target feature for the data reaching the node for DT regression models.</p>
<p>Select cut-off values for predicate generation: It is beneficial to select cut-off values with higher q œÑ values to generate predicates because such cut-off values reduce more uncertainty for the corresponding target feature and thus are more likely to contribute to PARs containing that feature.Therefore, after extracting all the cut-off values for a numeric feature F n from all the trained DT models, we arrange F n : (œÑ 1 , . . ., œÑ J ) for the numeric feature such that q œÑ1 ‚â• ... ‚â• q œÑ J , i.e., the q œÑ value for its cut-off values are sorted in a descending order.Then, we sequentially traverse the list of cut-off values and only keep a cut-off value for predicate generation for F n if its inclusion will not cancel the predicate of a cut-off value with a higher q œÑ value.The logic of whether to keep a cut-off value for predicate generation is illustrated in Figure 1.Implementation details of the whole algorithm is given in the appendix.</p>
<p>PAR Mining</p>
<p>After obtaining the global predicate set P, we transform each data instance x ‚àà D as a set of satisfied predicates P such that P ‚äÜ P. Given the records of satisfied predicates for the data as P 1 , . . ., P |D| , mining PARs becomes an association rule mining problem.Concretely, we first find all frequent itemsets (predicate sets) with the minimum support threshold Œ∏ from the records using the FPGrowth algorithm (Han, Pei, and Yin 2000).Then, for an arbitrary frequent predicate set P , regarding each p ‚àà P , we partition P into two parts p and P ‚àí p, a PAR P ‚àí p ‚àí‚Üí p is generated if its confidence is larger than Œ≥.</p>
<p>Besides, we also generate a set of special PARs called univariate PARs for explaining anomalies with simply out-ofrange feature values.Concretely, for each categorical feature F c , we generate an univariate PAR:
‚àÖ ‚àí‚Üí F c ‚àà ùùâ ùüè ùùâ ùüê Keep ùùâ ùüí only if ùê¨ùêÆùê© ùùâ ùüè ‚â§ ùë≠ ùíè &lt; ùùâ ùüí &gt; ùúΩ and ùê¨ùêÆùê© ùùâ ùüí ‚â§ ùë≠ ùíè &lt; ùùâ ùüê &gt; ùúΩ ùùâ ùüí ùùâ ùüë ùùâ ùüì Keep ùùâ ùüë only if ùê¨ùêÆùê© ùùâ ùüë ‚â§ ùë≠ ùíè &lt; ùùâ ùüè &gt; ùúΩ Keep ùùâ ùüì only if ùê¨ùêÆùê© ùùâ ùüê ‚â§ ùë≠ ùíè &lt; ùùâ ùüì &gt; ùúΩ
Figure 1: Illustration of the logic for whether keeping a cutoff value with a lower q œÑ value for predicate generation.In the example, we assume q œÑ1 ‚â• q œÑ2 ‚â• q œÑ3 ‚â• q œÑ4 ‚â• q œÑ5 .{1, . . ., U }, where {1, . . ., U } is the set of seen values for F c in D. For each numeric feature F n , we generate an univariate PAR:
‚àÖ ‚àí‚Üí ¬µ ‚àí 3œÉ ‚â§ F n ‚â§ ¬µ + 3œÉ
, where ¬µ and œÉ are the mean and standard deviation of the values for F n in D.</p>
<p>Finding Precise PARs for Explanation</p>
<p>Let A be the set of all PARs learned from the training data D.</p>
<p>In the inference stage, when an anomaly instance x is identified by a black box anomaly detection model f , we find the top-k PARs with the highest supports and confidences that are violated by x to precisely explain the anomalous behavior of x.Concretely, the top-k PARs are selected as follows:
{A1, ..., A k } = arg Topk A‚ààA and A(x)=1 sup(A) ‚àí Œ∏ 1 ‚àí Œ∏ + Œª conf (A) ‚àí Œ≥ 1 ‚àí Œ≥
where we call ( sup(A)‚àíŒ∏
1‚àíŒ∏ + Œª conf (A)‚àíŒ≥ 1‚àíŒ≥
) the accuracy score of PAR A for anomaly explanation, in which Œª denotes the relative importance weight for the confidence with respect to the support; A(x) = 1 if and only if A is violated by x.Intuitively, this means we prefer to search for violated PARs with the highest coverage of data (support) and highest precision (confidence) to accurately explain anomalies.</p>
<p>Importantly, finding such top-k PARs for an arbitrary anomaly instance x can be done rather efficiently.We sort all the PARs in A by their accuracy scores in a descending order in advance.Then, for an arbitrary identified anomaly instance x, we only need to sequentially traverse the sorted PARs in A until k violated PARs are found.</p>
<p>Hyperparameters and Potential Issues</p>
<p>As noticed, we allow only one predicate in the right-hand side of a PAR.We outline the reason for doing this as follows: suppose there are three rules, A 1 : P ‚àí‚Üí p 1 , A 2 : P ‚àí‚Üí p 2 and A 3 : P ‚àí‚Üí {p 1 , p 2 }.Then, due to the anti-monotone constraint, we have sup
(A 1 ) = #(P ‚à™p1) |D| ‚â• #(P ‚à™{p1,p2}) |D| = sup(A 3 ) and conf (A 1 ) = sup(A1) sup(P ) ‚â• sup(A3) sup(P ) = conf (A 3 ), likewise sup(A 2 ) ‚â• sup(A 3 ) and conf (A 2 ) ‚â• conf (A 3
).As a result, according to the accuracy score defined in the previous section, if the data satisfy P and violates p 1 and/or p 2 , then we prefer to pick A 1 and/or A 2 for anomaly explanation as they must have higher accuracy scores than A 3 .Therefore, it is redundant to generating PARs with more than one predicate in the right-hand.Regarding the maximum number of predicates in the left-hand side of a PAR, we limit it to four to make derived PARs not over-complicated for users.</p>
<p>Regarding the minimum confidence threshold Œ≥ and the minimum support threshold Œ∏ in the PAR mining step, they define the lower limit for the confidence and support required for a PAR to be eligible for selection during the anomaly explanation process.Our algorithm is capable of identifying PARs with highest support and confidence using the accuracy score as the criterion for PAR selection.As a result, we do not recommend setting Œ≥ and Œ∏ to values that are too high because it will increase the risk of failing to find any PARs for explaining anomalies.In fact, we recommend to set Œ≥ and Œ∏ to values less than which the found PARs are deemed to be entirely useless.Regarding Œª, the importance weight for confidence, we recommend to set it to a value larger than one.This is because we generally prioritize high precision over high coverage of data for explaining anomalies, thus the confidence of PARs is much more important than their support in terms of facilitating accurate anomaly explanation.Throughout our experimentation, we fixed these hyperparameters to reasonable values Œ∏ = max(10/|D|, 0.01), Œ≥ = 0.9, Œª = 5, and achieved robust results.Note that by setting Œª to 5, we assign nearly identical accuracy score to a PAR with 100% confidence and minimum support and another PAR with 98% confidence and 100% support.This weighting reflects our preference for confidence over support as the primary factor in selecting PARs.We leave an analysis of the sensitivity of our approach to these hyperparameters for future works.</p>
<p>User Study</p>
<p>We conducted a user study with 30 participants who use anomaly detection systems regularly in their work for different applications including equipment predictive maintenance, process condition monitoring and network intrusion detection.The sole objective of the user study is to investigate which anomaly explanation form is more useful to users under the assumption that all the explanations are accurate.Thus, we presented the users with various forms of anomaly explanations as shown in Table 1, and asked them two questions: 1) "Please rank the usefulness of different explanation forms in the table", and 2) "Please provide reasons why you rank the particular explanation form as the best one".In the end, PAR was selected as the most useful form by 24 users for mainly two reasons: 1) rule-based format of PARs is more intuitive and understandable than other options, 2) PARs provide concrete information about the suspected abnormal feature.The average rankings for all algorithms are presented in Table 2, which shows that users generally prefer rule-based anomaly explanations, such as PAR and Anchor, over other alternatives.</p>
<p>Experiments</p>
<p>In our experiments, two popular algorithms, Isolation Forecast (IF) (Liu, Ting, and Zhou 2012) and Autoencoder (AE) (Sakurada and Yairi 2014), are selected as our representative anomaly detection models.The ADBench (Han et al. 2022) is used as our benchmark datasets.Concretely, each tabular dataset in ADBench is split into a training set and a test set at a 4:1 ratio.We then train IF and AE models on the training set and tune anomaly thresholds for both models to achieve the best F 1 score on the testing set.We select all datasets on which both models can achieve at least 0.5 F 1 score on the testing set as our benchmark datasets for further experiments.This leads to 17 datasets being selected.The details of the select benchmark datasets are given in Table 3.</p>
<p>Efficiency of Finding Explanation Rules</p>
<p>We first investigate how efficient to find PARs for anomaly explanation.Anchor, which also provides rulebased anomaly explanation, is used as our baseline for comparison.We report the average time cost for computing the top 5 PARs and the anchor at each anomaly instance identified by IF and AE on the benchmark datasets in Table 7.Note that we only report the average metric across all the benchmark datasets in the table, detailed dataset-wise metrics are given in the appendix, and this also applies for all experiment results hereafter.As can be seen from the table, the average time cost of finding PARs is less than one second, whereas the average time cost for finding anchors is more than 25 seconds.This high computing efficiency makes PARs far more suitable for online anomaly explanation compared with Anchors.</p>
<p>Accuracy of Explanation Rules</p>
<p>We then compare the accuracy of PARs to anchors.According to (Molnar 2020), the accuracy of an explanation is defined as "How well does an explanation predict unseen data?".Thus for each dataset, to evaluate the accuracy of PARs and anchors, we use the top 5 PARs and the anchor computed for explaining a single anomaly instance as a anomaly detection model to detect anomalies in the remaining part of test set.We report the average performance, in terms of precision, recall and F 1 score, of using anchors and top 5 PARs computed at each identified anomaly instance to detect anomalies in unseen data in Table 7.As shown in the table, the selected PARs are much more accurate than anchors for anomaly explanation since on average PARs achieve 22% improvement on precision, 86% improvement on recall and 83% improvement on F 1 score compared with anchors.</p>
<p>Accuracy of Abnormal Feature Identification</p>
<p>In this subsection, we study PARs' accuracy of abnormal feature identification compared with other state-of-the-art model-agnostic abnormal feature identification methods including LIME, SHAP, COIN and ATON.Specifically, for each identified anomaly, we output the features in the consequent predicates of the top 5 PARs as the suspected abnormal feature list.Since LIME, SHAP, COIN and ATON can output a feature weight vector per identified anomaly indicating the suspected anomaly contribution, we output a list of suspected abnormal features sorted by their anomaly contribution weights in a descending order for these methods.Datasets preparation Evaluating the accuracy of abnormal feature identification requires benchmark datasets with ground-truth annotations of abnormal feature subspace.To the best of our knowledge, there is no publicly available real-world tabular dataset with such annotations.As a result, we propose to use the 17 selected benchmark datasets for experiments.Specifically, we create ground-truth annotations of abnormal features for the benchmark datasets by randomly perturbing 1 to 3 features for the normal instances in the testing set.The perturbed features at each instance are labeled as abnormal features.We only apply different methods to identify abnormal features for perturbed data which are actually identified as anomalies by IF and AE models in our experiments.</p>
<p>Evaluation metrics and results Similar to (Su et al. 2019), we borrow the idea of HitRate@K for recommender systems (Yang et al. 2012) as the metrics to evaluate the accuracy of abnormal feature identification.Specifically, we define a metric HitRate@P%= Hit@‚åäP %√ó|GF |‚åã</p>
<p>|GF |</p>
<p>where |GF | is the size of ground-truth abnormal features and P can be 100 or 150.HitRate@P% measures the number of overlapping features between ground-truth abnormal features and the top ‚åäP % √ó |GF |‚åã suspected abnormal features suggested by the anomaly explanation methods.For example, if ground-truth abnormal features are {2, 6} and the suspected abnormal feature list is [2,3,6,1,5,4], the result is 0.5 for HitRate@100% and 1.0 for HitRate@150%.In Table 8, we report the metrics HitRate@100% and HitRate@150% for LIME, SHAP, COIN, ATON and PAR on the benchmark datasets.As can be seen from the table, PAR achieves the highest average HitRate@100% and the second highest Hi-tRate@150% which demonstrate its high accuracy on abnormal feature identification.</p>
<p>Probability of Finding PARs for Anomalies</p>
<p>In this subsection, we study the probability of finding at least one PAR (PoF for abbreviation) for explaining identified anomalies using our method.Concretely, we report PoF@TPs (PoF for True Positives) and PoF@FPs (PoF for True Positives) for predicated anomalies by IF and AE models on the benchmark datasets in Figure 2a.From the figure, we make two important observations: 1) PoF is discernibly higher when the predicted anomalies are TPs than when the predicted anomalies are FPs.This is desirable since we prefer to find PARs for explaining TPs.With respect to FPs, failure to finding a PAR for them actually gives the chance to mitigate their negative impact.2) PoF is closely related to the feature dimension of datasets.This is as expected because we rely on the dependency between different features to construct PARs, thus the difficulty in finding PARs grows with fewer feature dimension.However, the good news is that we find PoF@TPs in 12 out of 17 datasets achieves 100%.Moreover, there is a clear trend that when the feature dimension of dataset is larger than 10, PoF@TPs quickly converges to 100% as shown in Figure 2a.</p>
<p>Impact of Noise Contamination</p>
<p>To evaluate the robustness of our approach with respect to noise/anomaly contamination in the training data, we measure PoF@TPs and the accuracy of selected PARs when setting noise proportion within training data at levels ranging from 0% to 20%.Specifically, we report PoF@TPs, the average precision, recall and F 1 score of applying top-5 PARs for explaining a single detected anomaly instance to anomaly detection on unseen data in Figure 2b.As can be seen, the impact of noise contamination on both PoF@TPs and the accuracy of selected PARs for anomaly explanation is limited when the noise contamination is less than 10%, implying that PARs are relatively robust to noise contamination in real-world anomaly detection scenarios.However, when the proportion of noise contamination exceeds 10%, which is an uncommon occurrence in real-world applications, the recall of selected PARs is primarily affected by the noise.This is likely due to the fact that the noise level has surpassed a certain threshold, causing a number of PARs to be unable to meet the minimum confidence threshold.This hypothesis is consistent with the decreasing trend of PoF@TPs as the proportion of noise contamination increases beyond 10%.Nevertheless, it is important to note that the precision of PARs still remains at a relatively high level, indicating that selected PARs remain rather reliable as they do not generate an excessive amount of false positives compared to PARs learned from noise-free data.</p>
<p>Conclusion</p>
<p>We introduced Predicate-based Association Rules (PARs), a novel and intuitive form of model-agnostic anomaly explanation.PARs not only highlight the suspected abnormal features, but also the reasons behind their abnormality.Our user study shows that PARs are better understood and preferred by regular anomaly detection system users compared with existing model-agnostic explanation options.We demonstrated the efficiency and the accuracy of PARs for anomaly explanation on various benchmark datasets.As people have increasingly highlighted the importance and imperativeness on providing tangible explanations in the anomaly detection field (Ruff et al. 2021;Pang and Aggarwal 2021), PARs can make a highly valuable practical contribution to this domain.</p>
<p>Decision tree learning</p>
<p>Decision trees (DTs) are a family of machine learning algorithms primarily designed for classification and regression.Their representability and ability to produce rules with relevant attributes make them the most commonly used technique when seeking interpretable machine learning models (Freitas 2014;Nanfack, Temple, and Fr√©nay 2022).</p>
<p>Specifically, let X be the input variables with M dimensions X i where i = 1, . . ., M , Y be the output variable (Y ‚àà {1, . . ., C} for classification, Y ‚àà R for regression), D be the dataset formed by sampling from the unknown joint distribution P XY .A DT consists of a hierarchy of internal nodes with defined splitting rules based on X, and a set of leaf nodes with predictions about Y .Splitting rules can involve one variable each time leading to univariate DTs, or multiple variables each time leading to multivariate DTs.To promote interpretability, we only consider univariate DTs in this work.Following (Nunes et al. 2020), we denote a decision rule on a single variable X i as f (x) = 1 A (x i ) where 1 A (x i ) is an indicator function, taking value 1 for x i ‚àà A and 0 otherwise.For numerical X i , we have: f (x) = 1 (œÑ,‚àû) (x i ) where œÑ is the selected cut-off value.Intuitively, a 0/1 outcome directs the instance x to the left/right child node.</p>
<p>The learning of DTs is mainly composed by induction and pruning.Induction is about learning the DT structure and its splitting rules.(Laurent and Rivest 1976) shows that learn-ing an optimal DT that maximizes prediction performance while minimizing the size of the tree is NP-complete owing to the discrete and sequential nature of the splits.As a result, standard DT algorithms such as CHAID (Kass 1980), CART (Breiman et al. 2017), ID3 (Quinlan 1986), and C4.5 (Quinlan 2014) learn a DT by following locally optimal induction strategies.Specifically, locally optimal induction selects splitting rules that maximize an objective at each node, e.g., variance reduction for regression, information gain for classification.The splitting procedure stops when a specific criterion, e.g., the maximum depth of the tree and the minimum number of samples required to be at a leaf node, is reached and a leaf node is created.By using this locally optimal search heuristic, learned greedy trees can be very accurate but significantly overfit.To avoid that, pruning techniques are commonly applied to find a trade-off between reducing the complexity of the tree and maintaining a certain level of accuracy (Barros, De Carvalho, and Freitas 2015;Nanfack, Temple, and Fr√©nay 2022).</p>
<p>Examples of Using PARs for Anomaly Explanation</p>
<p>To demonstrate the informativeness and intuitivenenss of PARs for anomaly explanation, we conducted additional experiments applying PARs to explain detected anomalies in SWAT, a dataset collected from a real-world water treatment testbed (Mathur and Tippenhauer 2016).Note that we did not use the same datasets from ADBench only because they do not have feature names with physical meanings, which makes them less useful for illustrating the informativeness of PARs.We present selected PARs (using the same hyperparameter values as in the paper) for explaining three example anomaly instances with labeled ground-truth abnormal features as below:</p>
<p>‚Ä¢ Anomaly instance 1:</p>
<p>-Ground-truth abnormal features: MV101 -Top-1 selected PAR for anomaly explanation: LIT101‚â•811.18‚àí‚ÜíMV101=1 -Translation: If the reading of level indicator LIT101 is larger than 811.18, then the state of valve MV101 should be 1, however, MV101 is not in state 1.This means that MV101 is suspected to be abnormal.</p>
<p>‚Ä¢ Anomaly instance 2:</p>
<p>-Ground-truth abnormal features: AIT202, P203 -Top-1 selected PAR for anomaly explanation: ‚àÖ ‚àí‚Üí8.21‚â§AIT202‚â§8.84-Translation: The reading of AIT202 should be in the range between 8.21 and 8.84, the current reading of AIT202 is not within the correct range.This means AIT202 is suspected to be abnormal.-Top-2 selected PAR for anomaly explanation: P205=1‚àí‚ÜíP203=1 -Translation: If pump P205 is in state 1, then pump P203 should also be in state 1.However, pump P203 is not in state 1.This means P203 is suspected to be abnormal.</p>
<p>‚Ä¢ Anomaly instance 3:</p>
<p>-Ground-truth abnormal features: LIT101</p>
<p>Implementation Details for Predicate Generation Algorithms</p>
<p>Algorithm 1 gives the details of generating predicates for categorical features.Algorithm 2 gives the details of predicate generation for numeric features.</p>
<p>Implementation Details for Experiments</p>
<p>Regarding baseline anomaly explanation methods, we implement Anchor based on the Github repository in github.com/marcotcr/anchor.We set its hyperparameters B = 10, œµ = 0.1, Œ¥ = 0.05 as suggested in the original paper (Ribeiro, Singh, and Guestrin 2018).We implement LIME based on the Github repository in github.com/marcotcr/lime.We implement SHAP based on the Github repository in github.com/slundberg/shap.Specifically, the KernelExplainer is used with 20 samples generated by KMeans as background dataset for integrating out features.COIN and ATON are implementated based on the Github repository in github.com/xuhongzuo/outlier-interpretation.For all methods, the default hyperparameter values are used unless specifically mentioned here.</p>
<p>Regarding Isolation Forest (IF) and Autoencoder (AE), we implement IF using Scikit-Learn (Pedregosa et al. 2011) library of version 1.1.2.The default hyperparameter values are used.We implement a vanilla version of AE with three hidden layers, the number of neurons in the bottleneck layer is set to 1 3 of the input dimension.Each model is trained with 10 epochs to minimize the reconstruction error on the training set.All of our experiments were run on a Linux machine with 64 GiB memory, 8 4.2GHz Intel Cores and a GTX 1080 GPU.</p>
<p>Further Experiments for Ablation Study</p>
<p>We also demonstrate the importance of our dependencybased predicate generation method for numeric features by conducting an ablation study.Concretely, we replace our dependency-based predicate generation method for numeric features with an uniform interval-based and a KMeansbased discretization method which simply discretize the value of numeric features to 10 bins for predicate generation.Then, we generate PARs for the benchmark datasets based on three different predicate generation method for numeric features, namely Uniform Bins, KMeans Bins and dependency-based.Furthermore, we compare two important metrics on the performance of anomaly explanation: PoF@TPs, the average accuracy score of the top1 PAR.</p>
<p>The result is given in Table 6.As can be seen, there are discernible improvements on both metrics when using our dependency-based method for predicate generation of numeric features compared with Uniform Bins and KMeans Bins methods.</p>
<p>Detailed Experiment Results</p>
<p>We give the dataset-specific results for Table 4 of the main paper in Table 7.We give the dataset-specific results for Table 5 of the main paper in Table 8.The dataset-specific results for PoF@TPs and PoF@FPs are given in Table 9. for u = 1, . .For each internal node j in the trained DT model, add (F n j , œÑ j , q œÑj ) to T based on its split rule 5: end for 6:
for i = 1, . . . , |F n | do 7: Train a DT regression model DT (F n ‚àíi ) ‚àí‚Üí F n i on D 8:
For each internal node j in the trained DT model, add (F n j , œÑ j , q œÑj ) to T based on its split rule 9: end for 10: for i = 1, . . ., |F n | do 11:</p>
<p>Get F n i : (œÑ 1 , . . ., œÑ J ) from T where q œÑ1 ‚â• ... ‚â• q œÑ J 12:</p>
<p>L ‚Üê [œÑ 1 ] # list of cut-off values to keep 13:</p>
<p>for j = 2, . . ., J do 14:</p>
<p>k ‚Üê 1 # insert position of œÑ j 15:
while k ‚â§ |L| and œÑ j &lt; L[k] do 16: k ‚Üê k + 1 17: end while 18: if k = 1 then 19: if sup(œÑ j ‚â§ F n i &lt; L[1]) &gt; Œ∏ then 20: Insert œÑ j to L at position k 21: end if 22: else if k = |L| + 1 then 23: if sup(L[k ‚àí 1] ‚â§ F n i &lt; œÑ j ) &gt; Œ∏
Figure 2 :
2
Figure 2: (a): PoF@TPs and PoF@FPs for datasets with different number of features.(b): PoF@TPs and average accuracy of PARs with different percentage of noise contamination in the training data.</p>
<p>Algorithm 1 :
1
Predicate generation for categorical features Require: The dataset D, the minimum support threshold Œ∏, the categorical feature set F c 1: P ‚Üê ‚àÖ, L ‚Üê ‚àÖ 2: for i = 1, . . ., |F c | do . . ., U } be the set of possible values for a categorical feature F c i 5:</p>
<p>Table 1 :
1
Illustration of explanations of various model-agnostic methods to an anomaly instance (x): Level=11.1,Pump=ON, Valve=Close, Temperature=25 in a water tank condition monitoring dataset.
Method ExplanationSOAM{Level, Pump, Valve} Level, Pump and Valve are abnormal features.COINLevel: 0.3, Pump: 0.2, Valve: 0.4, Temperature: 0.1ATONThe abnormality weights for above features are [0.3, 0.2, 0.4, 0.1].Level: 0.3‚Üë, Pump: 0.2‚Üë, Valve: 0.4‚Üë, Temperature: 0.1‚ÜìSHAPLevel, Pump and Valve features push the probability of prediction to anomaly higherand the Temperature feature pushes the probability lower with different degrees.Level&gt;10: 0.3‚Üë, Pump=ON: 0.2‚Üë, Valve=Close: 0.4‚Üë, Temperature&lt;30: 0.1‚ÜìLIMELevel&gt;10, Pump=ON and Valve=Close push the probability of prediction to anomalyhigher and Temperature&lt;30 pushes the probability lower with different degrees.AnchorLevel&gt;10, Pump=ON, Valve=Close ‚àí‚Üí f (x) = 1 If Level&gt;10, Pump=ON and Valve=Close, then x is classified as an anomaly.Level&gt;10, Pump=ON ‚àí‚Üí Valve=OpenPARIf Level&gt;10 and Pump=ON, then Valve should be OPEN.If Level&gt;10, Pump=ON but ValveÃ∏ =Open, then x is classified as an anomaly.</p>
<p>Table 2 :
2
The average rankings of the usefulness of explanation forms provided by different methods in the user study.
Method SOAM COIN SHAP LIME Anchor PARRank5.34.14.13.82.31.4Table 3: Details of benchmark datasetsDataset# Features # Samplesbreastw9683cardio211831Cardiotocography212114fault271941Ionosphere32351Lymphography18148magic1019020Pima8768satellite366435satimage-2365803shuttle949097skin3245057Stamps9340thyroid63772WBC9223WDBC30367wine13129</p>
<p>Table 4 :
4
The average time cost to compute the anchors and top 5 PARs at each anomaly instance in the benchmark datasets identified by IF and AE models, and the average precision, recall and F 1 score of using anchors and top 5 PARs computed at each anomaly instance to do anomaly detection in unseen data.
Anchor PAR ImprovementAvg. time cost (secs)25.710.22-99%Avg. precision0.550.67+22%Avg. recall0.210.39+86%Avg. F 1 score0.230.42+83%Table 5: Accuracy of abnormal feature identification interms of HitRate@100% and HitRate@150%.HitRate@100%HitRate@150%Avg. Avg. Rank Avg. Avg. RankLIME 0.394.470.484.35SHAP 0.592.240.682.12COIN 0.543.530.653.18ATON 0.622.530.712.47PAR0.662.000.702.53</p>
<p>The dataset D, the global predicate set P, the minimum support threshold Œ∏ Require: The categorical feature set F c , the numeric feature set F n 1: T ‚Üê ‚àÖ 2: for i = 1, . . ., |F c | do
Algorithm 2: Predicate generation for numeric featuresRequire: 3: Train a DT classification model DT (F n ) ‚àí‚Üí F c i on D4:. , U do6:Generate predicate p: F c i = u7:if sup(p) &gt; Œ∏ then8:Add p to P9:else10:Add p to T11:end if12:end for13:if |T | &gt; 1 then14:Generate predicate p: p 1 | . . . |p |T |# combine predicates for a single feature15:if sup(p) &gt; Œ∏ then16:Add p to P17:else18:Add p to L19:end if20:else if |T | = 1 then21:Add p in T to L22:end if23: end for24: k ‚Üê 125: for j = 2, . . . , |L| do26:if sup(p k | . . . |p j ) &gt; Œ∏ then27:if sup(p j+1 | . . . |p |L| ) &gt; Œ∏ then28:Generate predicate p: p k | . . . |p j29:Add p to P30:k ‚Üê j + 131:else32:Generate predicate p: p k | . . . |p |L|33:Add p to P34:break35:end if36:end if37: end for38: return P</p>
<p>Table 6 :
6
PoF@TPs and the average accuracy score of the top1 PAR, when using different methods to generate predicates for numeric features.
then
if sup(L[k ‚àí 1] ‚â§ F n i &lt; œÑ j ) &gt; Œ∏ and sup(œÑ j ‚â§ F n i &lt; L[k]) &gt; Œ∏ then 28:Insert œÑ j to L at position k</p>
<p>Table 7 :
7
The average time cost to compute the anchors and top 5 PARs at each anomaly instance in the benchmark datasets identified by IF and AE models, and the average precision, recall and F1 score of using anchors and top 5 PARs computed at each anomaly instance to do anomaly detection in unseen data.
DatasetPrecisionRecallF 1 scoreTime Cost (secs)Anchor PAR Anchor PAR Anchor PAR AnchorPARbreastw0.970.830.450.580.590.655.670.03cardio0.290.610.030.160.050.2535.340.27Cardiotocography0.540.550.030.050.050.0916.890.35fault0.430.480.070.020.120.033.191.77Ionosphere0.610.940.030.500.050.6479.690.11Lymphography1.000.610.330.560.500.576.720.10magic0.690.680.070.040.120.073.590.10Pima0.470.440.040.040.070.074.190.03satellite0.880.870.050.190.080.2956.860.43satimage-20.490.850.420.440.320.5188.640.26shuttle0.930.990.170.950.240.975.970.04skin0.520.570.410.190.430.281.530.01Stamps0.500.330.220.200.300.254.520.03thyroid0.080.650.260.170.090.273.770.02WBC0.500.590.670.920.570.716.380.02WDBC0.000.720.001.000.000.84108.90.09wine0.500.670.240.670.330.675.160.03Avg.0.550.670.210.390.230.4225.710.22Improvement.-+22%-+86%-+83%--99%</p>
<p>Table 8 :
8
Accuracy of abnormal feature identification in terms of HitRate@100% and HitRate@150%..820.90/0.950.60/0.710.64/0.740.72/0.75WBC 0.37/0.500.73/1.000.66/0.830.88/0.980.53/0.53WDBC 0.04/0.040.17/0.170.16/0.330.42/0.420.42/0.42wine 0.69/0.740.81/0.850.54/0.680.65/0.710.57/0.79Avg.0.39/0.480.59/0.680.54/0.65 0.62/0.710.66/0.70Avg.Rank 4.47/4.352.24/2.123.53/3.182.53/2.472.00/2.53
DatasetLIMESHAPCOINATONPARbreastw0.19/0.26 0.65/0.87 0.48/0.56 0.80/0.80 0.69/0.69cardio0.38/0.55 0.73/0.78 0.42/0.49 0.54/0.64 0.60/0.68Cardiotocography 0.31/0.47 0.65/0.73 0.38/0.50 0.68/0.72 0.76/0.76fault0.17/0.25 0.42/0.58 0.33/0.55 0.52/0.58 0.75/0.75Ionosphere0.43/0.43 0.60/0.60 0.43/0.43 0.51/0.66 0.63/0.70Lymphography0.33/0.50 0.17/0.33 0.65/0.88 0.48/0.68 0.83/1.00magic0.48/0.58 0.70/0.82 0.64/0.74 0.72/0.80 0.69/0.77Pima0.61/0.71 0.86/0.91 0.66/0.78 0.64/0.88 0.67/0.76satellite0.08/0.11 0.21/0.30 0.66/0.68 0.48/0.56 0.67/0.68satimage-20.04/0.04 0.16/0.20 0.48/0.57 0.50/0.52 0.56/0.56shuttle0.41/0.53 0.75/0.81 0.67/0.73 0.60/0.68 0.62/0.67skin0.74/0.92 0.90/0.95 0.85/0.98 0.84/0.98 0.84/0.84Stamps0.58/0.64 0.64/0.78 0.54/0.64 0.58/0.68 0.61/0.61thyroid0.71/0</p>
<p>Table 9 :
9
The PoF for explaining predicated anomalies when the predicated anomalies are True Positives (TPs) and False Positives (FPs).When there is no FP, we set PoF to n.a.
DatasetNum. features @TPs @FPs PoF PoFbreastw91.001.00cardio211.001.00Cardiotocography211.000.94fault271.000.97Ionosphere321.001.00Lymphography181.00n.amagic100.790.23Pima80.630.27satellite361.000.87satimage-2361.00n.ashuttle91.000.55skin30.430.32Stamps90.860.80thyroid60.820.25WBC91.00n.aWDBC301.001.00wine131.001.00Avg.17.470.910.73
For DT regression models, the target feature is standardized before training such that variance reduction for different features are comparable.
Appendix Association rule miningAssociation rule mining, one of the most important data mining techniques, is used to discover the frequently occurring patterns in the database(Agrawal, Imieli≈Ñski, and Swami 1993).The main aim of association rule mining is to find out the interesting relationships and correlations among the different items of the database.Specifically, let I = {i 1 , i 2 , . . .i m } be a set of items and D be a set of transactions, where each transaction T is a set of items such that T ‚äÜ I.An association rule is expressed as X ‚áí Y where X, Y ‚äÜ I and X ‚à© Y = ‚àÖ.Furthermore, there are two basic measures for an association rule: support (s) and confidence (c).A rule has support s if s proportion of the transactions in D contains X ‚à™ Y .A rule X ‚áí Y has confidence c, if c proportion of transactions in D that support X also support Y. Given a set of transactions D (the database), the problem of mining association rules is to discover all association rules that have support and confidence greater than the user-specified minimum support (called minsup) and minimum confidence (called minconf ).More specifically, association rules are commonly generated using the following two steps: 1) Find all the frequent itemsets whose support is larger than minsup.2) Based on these frequent itemsets, association rules which have confidence above minconf are generated.The first step is much more difficult than the second step.Many algorithms have been developed to mine frequent itemsets, including Apriori(Agrawal, Srikant et al. 1994), FP-Growth(Han, Pei, and Yin 2000)and genetic algorithms(Sharma and Tivari 2012), etc.
Mining association rules between sets of items in large databases. R Agrawal, T Imieli≈Ñski, A Swami, Proceedings of the 1993 ACM SIGMOD international conference on Management of data. the 1993 ACM SIGMOD international conference on Management of data1993</p>
<p>Automatic design of decision-tree induction algorithms. R Agrawal, R Srikant, Proc. 20th int. conf. very large data bases. 20th int. conf. very large data basesSpringer1994. 20151215Fast algorithms for mining association rules</p>
<p>Classification and regression trees. L Breiman, J H Friedman, R A Olshen, C J Stone, H.-P Kriegel, R T Ng, J Sander, 2017</p>
<p>LOF: identifying density-based local outliers. Proceedings of the 2000 ACM SIGMOD international conference on Management of data. the 2000 ACM SIGMOD international conference on Management of data</p>
<p>RelSen: An Optimization-based Framework for Simultaneously Sensor Reliability Monitoring and Data Cleaning. L Duan, G Tang, J Pei, J Bailey, A Campbell, C Tang, C Feng, X Liang, D Schneegass, P Tian, Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management. the 29th ACM International Conference on Information &amp; Knowledge Management2015. 202029Mining outlying aspects on numeric data</p>
<p>Time series anomaly detection for cyber-physical systems via neural system identification and bayesian filtering. C Feng, V R Palleti, A Mathur, D Chana, Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining. the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data MiningSan Diego, California, USA2019. February 24-27, 2019. 202126th Annual Network and Distributed System Security Symposium, NDSS 2019</p>
<p>Comprehensible classification models: a position paper. A A Freitas, ACM SIGKDD explorations newsletter. 1512014</p>
<p>Mining frequent patterns without candidate generation. J Han, J Pei, Y Yin, ACM sigmod record. 2922000</p>
<p>Adbench: Anomaly detection benchmark. S Han, X Hu, H Huang, M Jiang, Y Zhao, Advances in Neural Information Processing Systems. 202235</p>
<p>Gan ensemble for anomaly detection. X Han, X Chen, L.-P Liu, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202135</p>
<p>Extended isolation forest. S Hariri, M C Kind, R J Brunner, IEEE Transactions on Knowledge and Data Engineering. 3342019</p>
<p>An exploratory technique for investigating large quantities of categorical data. S Jiang, Q.-B -Y.; And An, H Laurent, R L Rivest, 2008 Fifth international conference on fuzzy systems and knowledge discovery. IEEE2008. 1980. 19762Constructing optimal binary decision trees is NP-complete. Information processing letters</p>
<p>A survey on explainable anomaly detection. Z Li, Y Zhu, M Van Leeuwen, ACM Transactions on Knowledge Discovery from Data. 1812023</p>
<p>Unsupervised Anomaly Detection by Robust Density Estimation. B Liu, P.-N Tan, J Zhou, F T Liu, K M Ting, Z.-H Zhou, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence2022. 20126Isolationbased anomaly detection</p>
<p>Contextual outlier interpretation. N Liu, D Shin, X Hu, Proceedings of the 27th International Joint Conference on Artificial Intelligence. the 27th International Joint Conference on Artificial Intelligence2018</p>
<p>Lopad: A local prediction approach to anomaly detection. S Lu, L Liu, J Li, T D Le, J Liu, Pacific-Asia Conference on Knowledge Discovery and Data Mining. Springer2020</p>
<p>Outlying Aspect Mining via Sum-Product Networks. S L√ºdtke, C Bartelt, H Stuckenschmidt, Pacific-Asia Conference on Knowledge Discovery and Data Mining. Springer2023</p>
<p>A unified approach to interpreting model predictions. S M Lundberg, S.-I Lee, 201730Advances in neural information processing systems</p>
<p>One-class SVMs for document classification. L M Manevitz, M Yousef, Journal of machine Learning research. 22001. Dec</p>
<p>SWaT: A water treatment testbed for research and training on ICS security. A P Mathur, N O Tippenhauer, G Temple, P Fr√©nay, B , 2016 international workshop on cyber-physical systems for smart water networks (CySWater). 2016. 2020. 2022Lulu. com. Nanfack,</p>
<p>Learning decision trees through Monte Carlo tree search: An empirical evaluation. R T Ng, L V Lakshmanan, J Han, A Pang, C Nunes, M De Craene, H Langet, O Camara, A Jonsson, Data Mining and Knowledge Discovery. 272e13481998. 2020Wiley Interdisciplinary ReviewsACM Sigmod Record</p>
<p>Effectiveness of association rules mining for invariants generation in cyberphysical systems. K Pal, S Adepu, J Goh, 2017 IEEE 18th International Symposium on High Assurance Systems Engineering (HASE). IEEE2017</p>
<p>Toward explainable deep anomaly detection. G Pang, C Aggarwal, Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining. the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining2021</p>
<p>A decomposition of the outlier detection problem into a set of supervised learning problems. H Paulheim, R Meusel, Machine Learning. 2015100</p>
<p>Scikit-learn: Machine learning in Python. F Pedregosa, G Varoquaux, A Gramfort, V Michel, B Thirion, O Grisel, M Blondel, P Prettenhofer, R Weiss, V Dubourg, Journal of machine Learning research. 122011</p>
<p>Induction of decision trees. J R Quinlan, Machine learning. 111986</p>
<p>C4. 5: programs for machine learning. J R Quinlan, 2014Elsevier</p>
<p>Explaining the predictions of any classifier. M T Ribeiro, S Singh, C Guestrin, Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining. the 22nd ACM SIGKDD international conference on knowledge discovery and data mining2016Why should i trust you?</p>
<p>Anchors: High-precision model-agnostic explanations. M T Ribeiro, S Singh, C Guestrin, Proceedings of the AAAI conference on artificial intelligence. the AAAI conference on artificial intelligence201832</p>
<p>A Unifying Review of Deep and Shallow Anomaly Detection. L Ruff, J R Kauffmann, R A Vandermeulen, G Montavon, W Samek, M Kloft, T G Dietterich, K.-R M√ºller, Proceedings of the IEEE. 10952021</p>
<p>Deep one-class classification. L Ruff, R Vandermeulen, N Goernitz, L Deecke, S A Siddiqui, A Binder, E M√ºller, M Kloft, International conference on machine learning. PMLR2018</p>
<p>Anomaly detection using autoencoders with nonlinear dimensionality reduction. M Sakurada, T Yairi, Proceedings of the MLSDA 2014 2nd workshop on machine learning for sensory data analysis. the MLSDA 2014 2nd workshop on machine learning for sensory data analysis2014</p>
<p>A new effective and efficient measure for outlying aspect mining. D Samariya, S Aryal, K M Ting, J Ma, Web Information Systems Engineering-WISE 2020: 21st International Conference. Amsterdam, The NetherlandsSpringer2020. October 20-24, 202021</p>
<p>D Samariya, J Ma, S Aryal, arXiv:2005.02637A comprehensive survey on outlying aspect mining methods. 2020arXiv preprint</p>
<p>A survey of association rule mining using genetic algorithm. A Sharma, N Tivari, International Journal of Computer Applications &amp; Information Technology. 122012</p>
<p>Robust anomaly detection for multivariate time series through stochastic recurrent neural network. Y Su, Y Zhao, C Niu, R Liu, W Sun, D Pei, Proceedings of the 25th ACM SIGKDD international conference on knowledge discovery &amp; data mining. the 25th ACM SIGKDD international conference on knowledge discovery &amp; data mining2019</p>
<p>Discovering outlying aspects in large datasets. N X Vinh, J Chan, S Romano, J Bailey, C Leckie, K Ramamohanarao, J Pei, Data Mining and Knowledge Discovery. 3062016</p>
<p>Beyond outlier detection: Outlier interpretation by attention-guided triplet deviation network. H Xu, Y Wang, S Jian, Z Huang, Y Wang, N Liu, F Li, Proceedings of the Web Conference 2021. the Web Conference 20212021</p>
<p>Fault detection by mining association rules from house-keeping data. T Yairi, Y Kato, K Hori, proceedings of the 6th International Symposium on Artificial Intelligence, Robotics and Automation in Space. the 6th International Symposium on Artificial Intelligence, Robotics and Automation in SpaceCiteseer20011821</p>
<p>On top-k recommendation using social networks. X Yang, H Steck, Y Guo, Y Liu, Proceedings of the sixth ACM conference on Recommender systems. the sixth ACM conference on Recommender systems2012</p>
<p>Adversarially learned anomaly detection. H Zenati, M Romain, C.-S Foo, B Lecouat, V Chandrasekhar, 2018 IEEE International conference on data mining (ICDM). IEEE2018</p>
<p>Anomaly detection with robust deep autoencoders. C Zhou, R C Paffenroth, Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery and data mining. the 23rd ACM SIGKDD international conference on knowledge discovery and data mining2017</p>
<p>Deep autoencoding gaussian mixture model for unsupervised anomaly detection. B Zong, Q Song, M R Min, W Cheng, C Lumezanu, D Cho, H Chen, 2018In International conference on learning representations</p>            </div>
        </div>

    </div>
</body>
</html>