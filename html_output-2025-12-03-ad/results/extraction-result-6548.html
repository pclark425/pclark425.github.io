<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-6548 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-6548</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-6548</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-130.html">extraction-schema-130</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models solving spatial puzzle games, including details about the model, the puzzle, the reasoning or prompting method, performance metrics, internal representations, use of external tools, and any analysis or limitations reported.</div>
                <p><strong>Paper ID:</strong> paper-271039467</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2407.03956v1.pdf" target="_blank">Solving Zebra Puzzles Using Constraint-Guided Multi-Agent Systems</a></p>
                <p><strong>Paper Abstract:</strong> Prior research has enhanced the ability of Large Language Models (LLMs) to solve logic puzzles using techniques such as chain-of-thought prompting or introducing a symbolic representation. These frameworks are still usually insufficient to solve complicated logical problems, such as Zebra puzzles, due to the inherent complexity of translating natural language clues into logical statements. We introduce a multi-agent system, ZPS, that integrates LLMs with an off the shelf theorem prover. This system tackles the complex puzzle-solving task by breaking down the problem into smaller, manageable parts, generating SMT (Satisfiability Modulo Theories) code to solve them with a theorem prover, and using feedback between the agents to repeatedly improve their answers. We also introduce an automated grid puzzle grader to assess the correctness of our puzzle solutions and show that the automated grader is reliable by evaluating it in a user-study. Our approach shows improvement in all three LLMs we tested, with GPT-4 showing 166% improvement in the number of fully correct solutions.</p>
                <p><strong>Cost:</strong> 0.011</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e6548.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e6548.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models solving spatial puzzle games, including details about the model, the puzzle, the reasoning or prompting method, performance metrics, internal representations, use of external tools, and any analysis or limitations reported.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A high-capability instruction-tuned large language model used as the primary Solver LLM-Agent in the multi-agent ZPS system to translate natural-language Zebra puzzles into SMT-LIB and iterate via theorem-prover feedback.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Solving Zebra Puzzles Using Constraint-Guided Multi-Agent Systems</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Instruction-tuned large language model used as an agent to decompose puzzles, generate SMT-LIB translations, evaluate theorem-prover output, and iterate in a feedback loop.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_name</strong></td>
                            <td>Zebra puzzle (logic grid / Einstein puzzle)</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_type</strong></td>
                            <td>Constraint satisfaction / logic grid puzzle (contains spatial relations such as left/right ordering)</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>114 Zebra puzzles (59 from GitHub dataset + 55 curated from the web)</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_method</strong></td>
                            <td>Agent-based decomposition and solver loop: Decomposition agent + Solver LLM-Agent generating SMT-LIB; deterministic generation (temperature=0) with optional cold-start retries at higher temperature; interaction constrained to a maximum number of actions (4) per attempt; autograder evaluated outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_technique</strong></td>
                            <td>SMT-based formal reasoning: LLM translates NL clues into SMT-LIB; uses Z3 SMT solver to find satisfying assignments; iterative evaluate-and-refine feedback loop between LLM and theorem prover (error-driven refinement).</td>
                        </tr>
                        <tr>
                            <td><strong>internal_representation</strong></td>
                            <td>SMT-LIB encoding of entities, attributes, and constraints (define-fun, assert, distinct, check-sat, get-model); occasional lookup tables in SMT-LIB comments for mapping model outputs to answer keys; puzzles first decomposed into entity/attribute components by a Decomposition agent.</td>
                        </tr>
                        <tr>
                            <td><strong>use_of_external_tool</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_description</strong></td>
                            <td>Z3 SMT solver used to check satisfiability of SMT-LIB encodings and produce models; GPT-4o (separately) used as an autograder to compare solver outputs to ground truth and produce partial/full scores.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Average Partial Score (Avg.PS) across puzzles and number of puzzles fully solved (#Solved); also % accuracy and manual-grader correlation statistics (Avg.Abs.Diff., Avg.Rel.Diff., Joint Full Credit).</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Baseline (LLM-only, temp=0): Avg.PS = 0.524, #Solved = 27/114 (23.7%). With SMT solver integration (temp=0): Avg.PS = 0.687 (∆ = +31.1% vs baseline). With solver + decomposition agent: Avg.PS = 0.700 (∆ = +33.58% vs baseline). Paper reports up to a 133.33% increase in number of fully solved puzzles over baseline; under variable-temperature retries GPT-4 maintains a high accuracy rate (~76.1%).</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_findings</strong></td>
                            <td>Integrating an external constraint solver (Z3) with LLM reasoning substantially increases partial and full-solution rates; decomposition provides modest further gains. GPT-4 produced fewer syntactic SMT-LIB errors than smaller models and benefited strongly from the error-feedback loop. Retries (increased temperature) can fix syntactic issues but risk producing logically inconsistent solutions; autograder correlates well with human graders (Joint Full Credit >85%). Common failure modes include incorrect translation of NL subtleties, syntactic SMT-LIB errors, and sensitivity to prompt construction.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_comparison</strong></td>
                            <td>LLM-only baseline vs LLM+Z3: GPT-4 Avg.PS improved from 0.524 to 0.687 (≈+31.1%). Adding a decomposition agent further increased Avg.PS to 0.700 (≈+33.58% vs baseline). Removing solver integration substantially reduced performance (baseline figures). Variable-temperature retries preserved high GPT-4 performance (~76.1% reported accuracy) while helping correct syntax in some cases.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Results limited to three tested models; dependence on carefully constructed prompts and SMT-LIB generation quality; dataset relatively small (114 puzzles) and biased toward medium difficulty; some solutions contained complex lookup tables which complicated grading and were excluded from parts of the user study; retries may trade syntactic correctness for logical correctness in some cases.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Solving Zebra Puzzles Using Constraint-Guided Multi-Agent Systems', 'publication_date_yy_mm': '2024-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6548.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e6548.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models solving spatial puzzle games, including details about the model, the puzzle, the reasoning or prompting method, performance metrics, internal representations, use of external tools, and any analysis or limitations reported.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-3.5</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-3.5</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An instruction-following LLM evaluated as a Solver LLM-Agent within the ZPS multi-agent system for translating Zebra puzzles to SMT-LIB and iteratively refining solutions with theorem-prover feedback.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Solving Zebra Puzzles Using Constraint-Guided Multi-Agent Systems</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Instruction-capable language model used as a Solver agent to produce SMT-LIB encodings and partake in the iterative feedback loop with Z3.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_name</strong></td>
                            <td>Zebra puzzle (logic grid / Einstein puzzle)</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_type</strong></td>
                            <td>Constraint satisfaction / logic grid puzzle (includes spatial relations)</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>114 Zebra puzzles (59 from GitHub dataset + 55 curated from the web)</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_method</strong></td>
                            <td>Agent-based decomposition + SMT translation; deterministic generation (temperature=0) with optional retries; autograder evaluation; decomposition agent optional.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_technique</strong></td>
                            <td>SMT-LIB translation and Z3 theorem-prover feedback loop; step-by-step decomposition of puzzle into entities/attributes.</td>
                        </tr>
                        <tr>
                            <td><strong>internal_representation</strong></td>
                            <td>SMT-LIB encodings of constraints and entity attributes; decomposed structured representations produced by Decomposition agent prior to translation.</td>
                        </tr>
                        <tr>
                            <td><strong>use_of_external_tool</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_description</strong></td>
                            <td>Z3 SMT solver used to check and produce models from SMT-LIB translations; autograder (GPT-4o) used to score outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Average Partial Score (Avg.PS) and number of fully solved puzzles (#Solved), plus manual-grader correlation measures.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Baseline (LLM-only, temp=0): Avg.PS = 0.471, #Solved = 17/114 (15.0%). Paper reports similar positive improvements with solver integration to those seen for GPT-4, but exact integrated numbers for GPT-3.5 are not precisely enumerated in the text.</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_findings</strong></td>
                            <td>GPT-3.5 showed a positive trend when integrated with the SMT solver similar to GPT-4, indicating solver feedback helps smaller instruction models; gains were smaller than GPT-4 in absolute terms. The paper notes overall improvement across GPT-3.5 experiments with solver feedback and optional decomposition.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_comparison</strong></td>
                            <td>Baseline vs solver-integration: reported improvements analogous to GPT-4 but smaller; addition of decomposition agent yielded small improvements (<~5.5% reported for GPT-family models). Exact numeric deltas for GPT-3.5 are not fully enumerated in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Paper does not provide full per-setting numeric breakdown for GPT-3.5 across every ablation; still subject to prompt sensitivity, syntactic SMT-LIB errors, and limited dataset size as with other models.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Solving Zebra Puzzles Using Constraint-Guided Multi-Agent Systems', 'publication_date_yy_mm': '2024-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6548.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e6548.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models solving spatial puzzle games, including details about the model, the puzzle, the reasoning or prompting method, performance metrics, internal representations, use of external tools, and any analysis or limitations reported.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Llama3-8b</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Llama3-8b</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An 8-billion-parameter Llama v3 variant evaluated as a Solver LLM-Agent; it struggled relatively more with generating syntactically correct SMT-LIB encodings but still showed improvement when paired with an SMT solver.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Solving Zebra Puzzles Using Constraint-Guided Multi-Agent Systems</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Llama3-8b</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>8B-parameter LLM (Llama v3 family) used as a Solver agent to produce SMT-LIB encodings; fewer parameters correlated with higher rate of syntactic/semantic SMT-LIB errors.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>8B</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_name</strong></td>
                            <td>Zebra puzzle (logic grid / Einstein puzzle)</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_type</strong></td>
                            <td>Constraint satisfaction / logic grid puzzle (includes spatial relations)</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>114 Zebra puzzles (59 from GitHub dataset + 55 curated from the web)</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_method</strong></td>
                            <td>Agent-based decomposition + SMT translation; deterministic generation (temperature=0) with optional retries; autograder evaluation; decomposition agent optional.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_technique</strong></td>
                            <td>SMT-LIB translation and Z3 theorem-prover external reasoning; iterative feedback to correct syntactic/semantic errors in encodings.</td>
                        </tr>
                        <tr>
                            <td><strong>internal_representation</strong></td>
                            <td>SMT-LIB code produced by the LLM agent after decomposition; explicit define-fun, assert, distinct constructs used to represent assignments and constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>use_of_external_tool</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_description</strong></td>
                            <td>Z3 SMT solver used to check SMT-LIB encodings and return models/errors to guide iterative LLM refinements; autograder (GPT-4o) used externally for grading.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Average Partial Score (Avg.PS) and number of fully solved puzzles (#Solved), plus error counts (number of final solutions containing errors) and manual-grader correlation measures.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Baseline (LLM-only, temp=0): Avg.PS = 0.47, #Solved = 14/114 (12.3%). With SMT integration Llama3 improved but less dramatically than GPT-family models; paper reports up to ~50% improvement in number of correct solutions over baseline. Under variable-temperature retries, Llama3 performance degraded (reported accuracy ≈ 48.4%).</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_findings</strong></td>
                            <td>Llama3 frequently generated syntactically incorrect SMT-LIB: 'no less than 50 final solutions contained errors' across experiments, higher than GPT-4/GPT-3.5 (<=42). This suggests smaller models have more difficulty reliably producing correct formal encodings; retries/temperature adjustments sometimes harmed logical correctness while correcting syntax.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_comparison</strong></td>
                            <td>Solver integration improved results (≈50% more correct solutions than baseline), but adding decomposition sometimes lowered average partial score (<~5% drop) and reduced #Solved in some settings. Variable-temperature retries reduced performance for Llama3 (from baseline to ~48.4% accuracy reported).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>High rate of SMT-LIB syntactic errors relative to GPT models; fewer parameters limit reliable code-generation for formal encodings; performance sensitive to retry policy and temperature; dataset size and prompt engineering constraints also apply.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Solving Zebra Puzzles Using Constraint-Guided Multi-Agent Systems', 'publication_date_yy_mm': '2024-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Satlm: Satisfiability-aided language models using declarative prompting <em>(Rating: 2)</em></li>
                <li>Language agent tree search unifies reasoning acting and planning in language models <em>(Rating: 2)</em></li>
                <li>Pal: Program-aided language models <em>(Rating: 2)</em></li>
                <li>Puzzler: An automated logic puzzle solver <em>(Rating: 2)</em></li>
                <li>Measuring reasoning capabilities of chatgpt <em>(Rating: 1)</em></li>
                <li>Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-6548",
    "paper_id": "paper-271039467",
    "extraction_schema_id": "extraction-schema-130",
    "extracted_data": [
        {
            "name_short": "GPT-4",
            "name_full": "GPT-4",
            "brief_description": "A high-capability instruction-tuned large language model used as the primary Solver LLM-Agent in the multi-agent ZPS system to translate natural-language Zebra puzzles into SMT-LIB and iterate via theorem-prover feedback.",
            "citation_title": "Solving Zebra Puzzles Using Constraint-Guided Multi-Agent Systems",
            "mention_or_use": "use",
            "model_name": "GPT-4",
            "model_description": "Instruction-tuned large language model used as an agent to decompose puzzles, generate SMT-LIB translations, evaluate theorem-prover output, and iterate in a feedback loop.",
            "model_size": null,
            "puzzle_name": "Zebra puzzle (logic grid / Einstein puzzle)",
            "puzzle_type": "Constraint satisfaction / logic grid puzzle (contains spatial relations such as left/right ordering)",
            "dataset_name": "114 Zebra puzzles (59 from GitHub dataset + 55 curated from the web)",
            "prompting_method": "Agent-based decomposition and solver loop: Decomposition agent + Solver LLM-Agent generating SMT-LIB; deterministic generation (temperature=0) with optional cold-start retries at higher temperature; interaction constrained to a maximum number of actions (4) per attempt; autograder evaluated outputs.",
            "reasoning_technique": "SMT-based formal reasoning: LLM translates NL clues into SMT-LIB; uses Z3 SMT solver to find satisfying assignments; iterative evaluate-and-refine feedback loop between LLM and theorem prover (error-driven refinement).",
            "internal_representation": "SMT-LIB encoding of entities, attributes, and constraints (define-fun, assert, distinct, check-sat, get-model); occasional lookup tables in SMT-LIB comments for mapping model outputs to answer keys; puzzles first decomposed into entity/attribute components by a Decomposition agent.",
            "use_of_external_tool": true,
            "external_tool_description": "Z3 SMT solver used to check satisfiability of SMT-LIB encodings and produce models; GPT-4o (separately) used as an autograder to compare solver outputs to ground truth and produce partial/full scores.",
            "evaluation_metric": "Average Partial Score (Avg.PS) across puzzles and number of puzzles fully solved (#Solved); also % accuracy and manual-grader correlation statistics (Avg.Abs.Diff., Avg.Rel.Diff., Joint Full Credit).",
            "performance": "Baseline (LLM-only, temp=0): Avg.PS = 0.524, #Solved = 27/114 (23.7%). With SMT solver integration (temp=0): Avg.PS = 0.687 (∆ = +31.1% vs baseline). With solver + decomposition agent: Avg.PS = 0.700 (∆ = +33.58% vs baseline). Paper reports up to a 133.33% increase in number of fully solved puzzles over baseline; under variable-temperature retries GPT-4 maintains a high accuracy rate (~76.1%).",
            "analysis_findings": "Integrating an external constraint solver (Z3) with LLM reasoning substantially increases partial and full-solution rates; decomposition provides modest further gains. GPT-4 produced fewer syntactic SMT-LIB errors than smaller models and benefited strongly from the error-feedback loop. Retries (increased temperature) can fix syntactic issues but risk producing logically inconsistent solutions; autograder correlates well with human graders (Joint Full Credit &gt;85%). Common failure modes include incorrect translation of NL subtleties, syntactic SMT-LIB errors, and sensitivity to prompt construction.",
            "ablation_comparison": "LLM-only baseline vs LLM+Z3: GPT-4 Avg.PS improved from 0.524 to 0.687 (≈+31.1%). Adding a decomposition agent further increased Avg.PS to 0.700 (≈+33.58% vs baseline). Removing solver integration substantially reduced performance (baseline figures). Variable-temperature retries preserved high GPT-4 performance (~76.1% reported accuracy) while helping correct syntax in some cases.",
            "limitations": "Results limited to three tested models; dependence on carefully constructed prompts and SMT-LIB generation quality; dataset relatively small (114 puzzles) and biased toward medium difficulty; some solutions contained complex lookup tables which complicated grading and were excluded from parts of the user study; retries may trade syntactic correctness for logical correctness in some cases.",
            "uuid": "e6548.0",
            "source_info": {
                "paper_title": "Solving Zebra Puzzles Using Constraint-Guided Multi-Agent Systems",
                "publication_date_yy_mm": "2024-07"
            }
        },
        {
            "name_short": "GPT-3.5",
            "name_full": "GPT-3.5",
            "brief_description": "An instruction-following LLM evaluated as a Solver LLM-Agent within the ZPS multi-agent system for translating Zebra puzzles to SMT-LIB and iteratively refining solutions with theorem-prover feedback.",
            "citation_title": "Solving Zebra Puzzles Using Constraint-Guided Multi-Agent Systems",
            "mention_or_use": "use",
            "model_name": "GPT-3.5",
            "model_description": "Instruction-capable language model used as a Solver agent to produce SMT-LIB encodings and partake in the iterative feedback loop with Z3.",
            "model_size": null,
            "puzzle_name": "Zebra puzzle (logic grid / Einstein puzzle)",
            "puzzle_type": "Constraint satisfaction / logic grid puzzle (includes spatial relations)",
            "dataset_name": "114 Zebra puzzles (59 from GitHub dataset + 55 curated from the web)",
            "prompting_method": "Agent-based decomposition + SMT translation; deterministic generation (temperature=0) with optional retries; autograder evaluation; decomposition agent optional.",
            "reasoning_technique": "SMT-LIB translation and Z3 theorem-prover feedback loop; step-by-step decomposition of puzzle into entities/attributes.",
            "internal_representation": "SMT-LIB encodings of constraints and entity attributes; decomposed structured representations produced by Decomposition agent prior to translation.",
            "use_of_external_tool": true,
            "external_tool_description": "Z3 SMT solver used to check and produce models from SMT-LIB translations; autograder (GPT-4o) used to score outputs.",
            "evaluation_metric": "Average Partial Score (Avg.PS) and number of fully solved puzzles (#Solved), plus manual-grader correlation measures.",
            "performance": "Baseline (LLM-only, temp=0): Avg.PS = 0.471, #Solved = 17/114 (15.0%). Paper reports similar positive improvements with solver integration to those seen for GPT-4, but exact integrated numbers for GPT-3.5 are not precisely enumerated in the text.",
            "analysis_findings": "GPT-3.5 showed a positive trend when integrated with the SMT solver similar to GPT-4, indicating solver feedback helps smaller instruction models; gains were smaller than GPT-4 in absolute terms. The paper notes overall improvement across GPT-3.5 experiments with solver feedback and optional decomposition.",
            "ablation_comparison": "Baseline vs solver-integration: reported improvements analogous to GPT-4 but smaller; addition of decomposition agent yielded small improvements (&lt;~5.5% reported for GPT-family models). Exact numeric deltas for GPT-3.5 are not fully enumerated in the paper.",
            "limitations": "Paper does not provide full per-setting numeric breakdown for GPT-3.5 across every ablation; still subject to prompt sensitivity, syntactic SMT-LIB errors, and limited dataset size as with other models.",
            "uuid": "e6548.1",
            "source_info": {
                "paper_title": "Solving Zebra Puzzles Using Constraint-Guided Multi-Agent Systems",
                "publication_date_yy_mm": "2024-07"
            }
        },
        {
            "name_short": "Llama3-8b",
            "name_full": "Llama3-8b",
            "brief_description": "An 8-billion-parameter Llama v3 variant evaluated as a Solver LLM-Agent; it struggled relatively more with generating syntactically correct SMT-LIB encodings but still showed improvement when paired with an SMT solver.",
            "citation_title": "Solving Zebra Puzzles Using Constraint-Guided Multi-Agent Systems",
            "mention_or_use": "use",
            "model_name": "Llama3-8b",
            "model_description": "8B-parameter LLM (Llama v3 family) used as a Solver agent to produce SMT-LIB encodings; fewer parameters correlated with higher rate of syntactic/semantic SMT-LIB errors.",
            "model_size": "8B",
            "puzzle_name": "Zebra puzzle (logic grid / Einstein puzzle)",
            "puzzle_type": "Constraint satisfaction / logic grid puzzle (includes spatial relations)",
            "dataset_name": "114 Zebra puzzles (59 from GitHub dataset + 55 curated from the web)",
            "prompting_method": "Agent-based decomposition + SMT translation; deterministic generation (temperature=0) with optional retries; autograder evaluation; decomposition agent optional.",
            "reasoning_technique": "SMT-LIB translation and Z3 theorem-prover external reasoning; iterative feedback to correct syntactic/semantic errors in encodings.",
            "internal_representation": "SMT-LIB code produced by the LLM agent after decomposition; explicit define-fun, assert, distinct constructs used to represent assignments and constraints.",
            "use_of_external_tool": true,
            "external_tool_description": "Z3 SMT solver used to check SMT-LIB encodings and return models/errors to guide iterative LLM refinements; autograder (GPT-4o) used externally for grading.",
            "evaluation_metric": "Average Partial Score (Avg.PS) and number of fully solved puzzles (#Solved), plus error counts (number of final solutions containing errors) and manual-grader correlation measures.",
            "performance": "Baseline (LLM-only, temp=0): Avg.PS = 0.47, #Solved = 14/114 (12.3%). With SMT integration Llama3 improved but less dramatically than GPT-family models; paper reports up to ~50% improvement in number of correct solutions over baseline. Under variable-temperature retries, Llama3 performance degraded (reported accuracy ≈ 48.4%).",
            "analysis_findings": "Llama3 frequently generated syntactically incorrect SMT-LIB: 'no less than 50 final solutions contained errors' across experiments, higher than GPT-4/GPT-3.5 (&lt;=42). This suggests smaller models have more difficulty reliably producing correct formal encodings; retries/temperature adjustments sometimes harmed logical correctness while correcting syntax.",
            "ablation_comparison": "Solver integration improved results (≈50% more correct solutions than baseline), but adding decomposition sometimes lowered average partial score (&lt;~5% drop) and reduced #Solved in some settings. Variable-temperature retries reduced performance for Llama3 (from baseline to ~48.4% accuracy reported).",
            "limitations": "High rate of SMT-LIB syntactic errors relative to GPT models; fewer parameters limit reliable code-generation for formal encodings; performance sensitive to retry policy and temperature; dataset size and prompt engineering constraints also apply.",
            "uuid": "e6548.2",
            "source_info": {
                "paper_title": "Solving Zebra Puzzles Using Constraint-Guided Multi-Agent Systems",
                "publication_date_yy_mm": "2024-07"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Satlm: Satisfiability-aided language models using declarative prompting",
            "rating": 2,
            "sanitized_title": "satlm_satisfiabilityaided_language_models_using_declarative_prompting"
        },
        {
            "paper_title": "Language agent tree search unifies reasoning acting and planning in language models",
            "rating": 2,
            "sanitized_title": "language_agent_tree_search_unifies_reasoning_acting_and_planning_in_language_models"
        },
        {
            "paper_title": "Pal: Program-aided language models",
            "rating": 2,
            "sanitized_title": "pal_programaided_language_models"
        },
        {
            "paper_title": "Puzzler: An automated logic puzzle solver",
            "rating": 2,
            "sanitized_title": "puzzler_an_automated_logic_puzzle_solver"
        },
        {
            "paper_title": "Measuring reasoning capabilities of chatgpt",
            "rating": 1,
            "sanitized_title": "measuring_reasoning_capabilities_of_chatgpt"
        },
        {
            "paper_title": "Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks",
            "rating": 1,
            "sanitized_title": "program_of_thoughts_prompting_disentangling_computation_from_reasoning_for_numerical_reasoning_tasks"
        }
    ],
    "cost": 0.0113905,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Solving Zebra Puzzles Using Constraint-Guided Multi-Agent Systems
9 Jul 2024</p>
<p>Shmuel Berman 
Kathleen Mckeown 
Mark Chen 
Jerry Tworek 
Heewoo Jun 
Qiming Yuan 
Henrique Ponde 
Oliveira Pinto 
Jared Kaplan 
Harri Edwards 
Yuri Burda 
Nicholas Joseph 
Greg Brockman 
Alex Ray rayb@cs.columbia.edu 
Raul Puri 
Gretchen Krueger 
Michael Petrov 
Heidy Khlaaf 
Girish Sastry 
Pamela Mishkin 
Brooke Chan 
Scott Gray 
Nick Ryder 
Mikhail Pavlov 
Alethea Power 
Lukasz Kaiser 
Mohammad Bavarian 
Christopher Hesse 
Andrew N Carr 
Jan Leike 
Josh Achiam 
Vedant Misra 
Evan Morikawa 
Alec Radford 
Matthew Knight 
Miles Brundage 
Mira Murati 
Katie Mayer 
Peter Welinder 
Bob Mcgrew 
Dario Amodei 
Sam Mccandlish 
Ilya Sutskever 
Wojciech 2021 Zaremba 
Eval 
Solving Zebra Puzzles Using Constraint-Guided Multi-Agent Systems
9 Jul 2024546159572B597E792D3EDBE2F0995F02arXiv:2407.03956v2[cs.MA]
Prior research has enhanced the ability of Large Language Models (LLMs) to solve logic puzzles using techniques such as chainof-thought prompting or introducing a symbolic representation.These frameworks are still usually insufficient to solve complicated logical problems, such as Zebra puzzles, due to the inherent complexity of translating natural language clues into logical statements.We introduce a multi-agent system, ZPS, that integrates LLMs with an off the shelf theorem prover.This system tackles the complex puzzle-solving task by breaking down the problem into smaller, manageable parts, generating SMT (Satisfiability Modulo Theories) code to solve them with a theorem prover, and using feedback between the agents to repeatedly improve their answers.We also introduce an automated grid puzzle grader to assess the correctness of our puzzle solutions and show that the automated grader is reliable by evaluating it in a user-study.Our approach shows improvement in all three LLMs we tested, with GPT-4 showing 166% improvement in the number of fully correct solutions.</p>
<p>Introduction</p>
<p>Automated problem solving has long been a major goal in the field of Artificial Intelligence.This task ranges from trivial problems, like simple arithmetic or string searches, to more complex ones, such as solving a chess position..However, unstructured problems presented in natural language introduce additional complications in modeling the problem accurately.Solving such problems has been extensively studied, from simple mathematical problems in the subfield of word problem solving to applications like automated code generation by Large Language Models (LLMs) (Mukherjee and Garain, 2009;Chen et al., 2021).These problems are particularly difficult because translating natural language into a precise logical or computational form requires sophisticated understanding and interpretation, making it a significant challenge in AI research.2. The person with the Dogs plays Basketball.</p>
<ol>
<li>
<p>There is one house between the person who plays Football and the Red house on the right.</p>
</li>
<li>
<p>The person with the Fishes lives directly to the left of the person with the Cats.</p>
</li>
<li>
<p>The person with the Dogs lives directly to the right of the Green house.</p>
</li>
</ol>
<p>6.The German lives in house three.In this paper, we focus on a particular type of unstructured natural language problem known as a logic grid problem, or colloquially, an Einstein or Zebra puzzle.A Zebra puzzle is a set of natural language assertions involving multiple entities that are linked by various attributes (Fig. 1 shows an example).To solve a puzzle, the user must correctly assign attributes to all of the entities.These attributes range from descriptions to relative ordering.Participants are provided with a series of clues in natural language, which they must use to deduce the correct relationships using logical reasoning and by adhering to implicit domain constraints.</p>
<p>These puzzles require the solver to map from natural language to structured space, understand implicit assumptions, and in some cases use domain-specific knowledge.For instance, as illustrated in Fig. 1, the solver must assign the correct attributes for three houses based on a series of interconnected clues.</p>
<p>Zebra puzzles are particularly challenging due to:</p>
<p>• Complex Inferences: Each clue provides partial information that must be combined with others to deduce the solution.</p>
<p>• High Interdependency: An error on one clue significantly impacts others, making the solution space highly interconnected.</p>
<p>• Natural Language (NL) Clues: Translating ambigous NL clues into logical statements or formal representations is challenging.</p>
<p>• Large Solution Space: The solver needs to explore numerous possibilities and combinations to find the solution.</p>
<p>• Consistency Checking: Potential solutions must be checked against all clues, which is a computationally intensive and requires sophisticated, domain-specific reasoning.</p>
<p>The factors mentioned make Zebra puzzles difficult for both humans and AI systems due to the need for precise interpretation, inference, and logical reasoning.In Fig. 1, for example, a solver cannot simply map the spatial relationship between the Football house and the Red house.It must also encode additional constraints: the Football and Red houses occupy House 1 or House 3, respectively, and they must not be the same house.Encoding these constraints is non-trivial, as it requires detailed semantic interpretation of the clue's subtext.Failure to accurately encode these subtleties usually renders the puzzle unsolvable.This complexity has empirically been shown to challenge puzzle-solving models significantly.Prior work often employed human-in-the-loop methods.Milicevic et al. (2012) translated puzzles into formal logic but required users to rephrase or rewrite ambiguous clues.Claes et al. (2019) developed ZebraTutor, which creates a puzzle-specific lexicon to formalize the problem but needed users to edit the lexicon for accuracy.Prior research using ChatGPT to solve Zebra puzzles reported a correctness rate of only 8.33% (Groza, 2023), with performance deteriorating significantly as the problem's complexity increases.</p>
<p>Due to their complexity, solving Zebra puzzles effectively requires the use of a constraint solver; a solver can efficiently determine the feasible and infeasible solution space within the given constraints.However, converting natural language clues into a formal representation suitable for a solver is a non-trivial task.This process often involves intricate interpretation of clues, which must be precise to ensure that the solver can operate correctly.Additionally, maintaining consistency across all clues requires iterative back-and-forth reasoning.</p>
<p>To address the challenges inherent in solving Zebra puzzles, we introduce a multi-agent based system, ZPS.This system decomposes the problem-solving process into discrete, manageable components, enhancing the handling of complex interdependencies and constraints.Each agent is responsible for a specific aspect of the problem, working collaboratively and using feedback loops to refine their answers and ensure consistency.</p>
<p>In this framework, we conceptualize integrating Large Language Models (LLMs) with formal reasoning.First, an LLM agent decompose a given puzzle to sub-problems.Then, another LLM agent interprets NL clues of each subproblem and generates SMT-LIB translations of the constraints and parameters.An off-theshelf SMT solver1 then processes these translations to produce a model that corresponds to the solution.The output, including the model and any syntactic errors, is fed back to the LLM which generates a new translation addressing syntactic and semantic errors, emulating back and forth reasoning.This continuous feedback refines the model's predictions and ensures the translations are both syntactically correct and solvable.To this end, our approach demonstrates improvements across all three LLMs we tested, with GPT-4 showing up to a 166% increase in the number of fully correct solutions.The main contributions of our research are as follows:</p>
<ol>
<li>
<p>We demonstrate that combining a formal constraint solver with an LLM interpreter using an agent-based approach for solving Zebra Puzzles significantly improves upon existing baseline methodologies.</p>
</li>
<li>
<p>We implement a plan generation and decomposition strategy, enabling step-bystep reasoning that enhances the solving process.</p>
</li>
<li>
<p>We introduce an iterative conversationbased feedback mechanism that allows for continual refinement of solutions, adapting dynamically to the solving context.</p>
</li>
<li>
<p>We incorporate an autograder within our system to evaluate the accuracy of solutions, ensuring reliability and precision in automated assessments.We also present the results of a user study showing that this autograder correlates very well with human graders.</p>
</li>
</ol>
<p>Our code is available at https: //anonymous.4open.science/r/anon_emnlp-1AD0/README.md.</p>
<p>Methodology</p>
<p>We integrate LLMs with formal systems within a multi-agent framework to solve Zebra puzzles.The process involves a series of steps where the problem is decomposed, translated into a formal language (SMT-LIB), solved using a theorem prover, and iteratively refined based on feedback.This approach aims to leverage the strengths of both LLMs and formal solvers, ensuring robust problem-solving capabilities.</p>
<p>Multi-Agent Workflow</p>
<p>The workflow, as illustrated in Figure 2, integrates multiple agents to transform a natural language puzzle into a logically solvable structure and then iteratively refines the solution.The process is initiated by the Decomposition Agent and continuously refined through a feedback loop that encompasses both the translation to SMT-LIB and the solving phases.Decomposition The input puzzle, expressed in natural language, is first decomposed by the Decomposition LLM-Agent.This agent identifies and isolates key entities, attributes, and relationships, structuring them into smaller, systematically translatable components.This is a first step that ensures the puzzle is presented in a format amenable to formal processing.</p>
<p>Feedback Loop</p>
<p>The core of our methodology lies in the feedback loop where continuous refinement of the solution occurs.This loop integrates the translation of decomposed components into SMT-LIB format by the Solver LLM-Agent and the subsequent problem solving using a theorem prover, whose output serves as feedback.Each iteration through the loop consists of the following steps: • Translation to SMT-LIB: After decomposition, the puzzle components are systematically translated into SMT-LIB (Satisfiability Modulo Theories Library) by the Solver LLM-Agent.This format is essential for interfacing with theorem provers and ensures that logical constraints and relationships are accurately represented.• Solving with Theorem Prover: The SMT-LIB formatted components are then processed by the theorem prover (Z3 in our implementation).The theorem prover attempts to find a satisfying assignment that adheres to all given constraints.• Evaluate and Refine: The solution generated by the theorem prover is evaluated by the Solver LLM-Agent to determine if it meets the puzzle's requirements.If the solution is deemed insufficient-either due to to explicit errors or because of how the attributes are assigned-modifications are made to the translation of the SMT-LIB formalization of the puzzle and the cycle repeats.</p>
<p>Otherwise, the LLM-agent submits its final answer.This iterative process ensures that the Solver LLM-Agent and the Theorem Prover continually refine the solution until the Solver LLM-Agent is satisfied with the final assignments.</p>
<p>Modeling the Agent Environment</p>
<p>The feedback loop is how the agents engage with each other.This loop is mathematically modeled using a combination of evaluation functions and error detection mechanisms, which together guide the system towards a solution that optimally satisfies the problem constraints.</p>
<p>More formally, let D, G, T , E, and F represent the decomposition, translation to SMT-LIB, theorem solving, evaluation, and feedback functions, respectively.The feedback loop can be described by the following recursive function:
S k+1 = F(E(T (G(D(P )), S k )), S k )
Where, P : initial puzzle in natural language.S k : solution state at the k-th iteration.D(P ): decomposes P into a structured format amenable to translation.G: translates this structure into the SMT-LIB format.</p>
<p>T : applies the theorem prover to find a solution that satisfies the logical constraints.E: evaluates this solution to determine its adequacy in solving the puzzle's clues.F: adjusts the translation based on the evaluation, aiming to correct any errors or optimize the solution.</p>
<p>Convergence Criteria The convergence of this iterative process is governed by the Solver LLM-agent's evaluation function E, which assesses both the correctness of the solution against the domain-specific requirements and the presence of any syntactic or semantic errors detected by T .We assume that E is a black-box function defined by the instructions given to the LLM.The loop terminates when E returns a value indicating that the solution S k sufficiently meets all puzzle requirements and contains no detectable errors, or when a maximum retry limit has been reached.</p>
<p>Optimization and Refinement Each iteration through the feedback loop serves to progressively refine the solution, optimizing the representation and alignment with the puzzle's constraints.This optimization process is critical for moving the solution towards a local optimum, where no further improvements can be detected by E or F.</p>
<p>Experimental Setup</p>
<p>To comprehensively evaluate ZPS's performance, we examine its effectiveness across 114 Zebra Puzzles.Our assessment emphasizes ZPS's capability to solve the puzzles using the different agents.</p>
<p>Selection of Logic Puzzles</p>
<p>We compiled two datasets to evaluate the problem-solving capabilities of our agentcentric approach.The first dataset, sourced from GitHub2 , contains 59 Zebra puzzles involving entity-attribute matching.We further curated 55 additional puzzles from different sources from the Web and manually crosschecked them to determine they are valid zebra problems.</p>
<p>Agent Configuration</p>
<p>We experimented with three different LLMs: GPT-4, GPT-3.5,andLlama3-8b .We used z3 as the automated theorem solver.Our total cost across all experiments was approximately 2500 USD.</p>
<p>Number of Retries</p>
<p>In our experimental setup, we initially conduct the feedback loop once.To enhance performance and address syntactical errors in the final output, we implement an additional cold-start retry mechanism if we reach the action-limit without an error-free solution.This involves restarting the workflow from scratch with an increased temperature.</p>
<p>Response Limit To limit the conversation length and prevent hallucination, we define a maximum number of actions that the LLMagent can take.All experiments performed allow the LLM to perform up to 4 actions; this limit is reset if the puzzle-solving task is retried.</p>
<p>Grading</p>
<p>To assess solution accuracy, we created an autograder LLM-agent that provides a numeric grade to every solution generated by the solving agent.Each assignment is worth 1 point.In order to evaluate the reliability of this autograder, we also conducted a user study where a subset of the problems were regraded by humans and then compared to the autograder's results.</p>
<p>Autograding GPT-4o was used for autograding.It received the ground-truth answer, final SMT-LIB output, and conversation history to assess the consistency and correctness of each solution.For each problem, the model compared the logical assignments produced by the solving agent against the reference assignments, producing a final accuracy score.</p>
<p>To demonstrate the autograding process, consider a scenario where the output of the SMT-LIB solver is evaluated against a pre-defined answer key.The solver's output and subsequent interpretation by the grader are detailed below.</p>
<p>SMT-LIB Solver Output Below is a sample SMT solution for the logic grid puzzle given in Fig. 1.</p>
<p>; 1 is Brazilian, 2 is German ; 3 is American (define-fun H1_Color () String "Blue") (define-fun H1_N () Int 1) (define-fun H1_Anml () String "Cats") (define-fun H1_Sp () String "Football") (define-fun H2_Color () String "Green") (define-fun H2_N () Int 3) (define-fun H2_Anml () String "Dogs") (define-fun H2_Sp () String "Basketball") (define-fun H3_Color () String "Red") (define-fun H3_N () Int 2) (define-fun H3_Anml () String "Fishes") (define-fun H3_Sp () String "Baseball")</p>
<p>Ground Truth Answer</p>
<p>• House 1: Blue, Brazilian, Fishes, Football • House 2: Green, American, Cats, Baseball • House 3: Red, German, Dogs, Basketball</p>
<p>The autograder evaluates the solution by mapping the SMT-LIB output to the expected results either using contextual clues or an explicitly defined lookup table, which would be defined in the SMT-LIB comments, converting function definitions into comparable assignments, as in Table 1.</p>
<p>Partial Scoring (PS) Each correct match between the SMT-LIB output and the answer key earns a point.The autograder agent also calculates the total number of assignments which is equal to the number of points it is possible to receive.In this example, all matches are correct, thus:
Partial Score = Correct Matches Total Matches = 8 12 = 0.67
If the animals and sports had been chosen correctly, the score would be 1.Manual User Study Grading A separate user study manually graded 50 solutions from the state-of-the-art workflow, 35 solutions from a non-optimal variant, and 20 solutions from the naive approach.Though it was impractical to have all of the thousands of solutions that the LLM-agent generated be hand-graded, this user study allows us to quantify the correctness of our results and verify that our autograder correlates well with the ground-truth grades.</p>
<p>The manual grading team included five undergraduate computer science students and one master's student.We then used their manual grades to capture various statistical measures of similarity between human grading and LLM grading; these stats are explained in the "Results" section.</p>
<p>A large percentage of the attempted solutions included explicit lookup tables, making these solutions significantly more time-consuming to grade (see "SMT-LIB Solver Output" and "Answer Key" above).The lookup table could appear anywhere in the generated text, which comprises multiple blocks of SMT-LIB code, errors, and intermediate SMT models.We therefore do not include them in our user study.</p>
<p>Results</p>
<p>This analysis is structured around four key research questions: Firstly, we examine the baseline performance of different LLMs in solving logic puzzles without solver assistance to understand their intrinsic problem-solving capabilities.Secondly, we assess the improvements in accuracy and problem-solving completeness when integrating solver feedback, evaluating how external theorem provers enhance LLM effectiveness.Thirdly, we explore the impact of using a decomposition agent, analyzing whether segmenting puzzles into simpler components before solving improves overall solution quality.Four, we conduct a user study to evaluate our LLM-Grader and substantiate the validity of our results.</p>
<p>ZPS Performance over Baselines</p>
<p>To establish a baseline, we first evaluate the performance of LLMs without the assistance of a solver by asking the LLM to solve the logic grid puzzle.This baseline configuration yields mediocre puzzle-solving accuracy, as detailed in Table 2.We report both the average partial score, given by the "Avg.PS" column, and the number of puzzles solved fully correctly, given by the "#Solved" column.For instance, GPT-4 under a baseline achieves an average partial score of of 52.4% and solves 27/114 logic grid puzzles completely correctly.</p>
<p>The effectiveness of the LLM-agent workflow increases markedly when solver feedback is incorporated.As shown in Table 3, the integration of theorem prover feedback, without retries and under a deterministic generation setting (temperature = 0), increases GPT-4's average partial score to 0.687 from baseline of 0.524 (∆ = 31.1%).The inclusion of a decomposition agent further improves this to 0.700 (∆ = 33.58%).In terms of the total number solutions that can be completely solved, GPT4 with solver solves up to 133.33% more problems than the baseline settings.GPT-3.5 shows a similar positive trend.</p>
<p>Llama3's improvement is more subtle; we believe this is because its fewer number of parameters limits its ability to generate syntactically correct SMT-LIB code.This theory is supported by the fact that in every Llama3 experiment, no less than 50 final solutions contained errors, whereas in every GPT-4 or GPT-3.5 experiment, the number was no more than 42.Nonetheless, Llama3 can also improve the total number of correct solutions by 50% over baseline.</p>
<p>ZPS Performance under Different Settings</p>
<p>For the variable temperature experiments, we set the model temperature to zero and increased it if the solution contained errors.While this approach provides the flexibility to bypass a solution if the deterministic solution is erroneous, it risks generating less stable solutions that may inadvertently replace syntactically incorrect yet valid solutions with syntactically correct but logically flawed ones.This phenomenon is particularly pronounced in models with fewer parameters, where the performance tends to decline with the introduction of retries.For example, under variable temperature conditions with retries, GPT-4 maintains a high accuracy rate of 76.1%, while Llama3's accuracy degrades to 48.4%.The addition of a decomposition agent to the SMT-integrated LLM-agent yielded mixed results.For both GPT-4 and GPT-3.5, the average partial score and number solved fully correctly slightly improved, in all cases by less than 5.5%.However, Llama-3's average partial score declined by less than 5% and it was able to solve 3 fewer problems than with just SMT integration.Because of the relatively small differences in all cases, more experimentation is needed to determine when decomposition increases performance.</p>
<p>Model T D Avg. P.S #Solved</p>
<p>Llama3-8b 0 ✗ 0.47 14 (12.3%)GPT-3.5 0 ✗ 0.471 17 (15.0%)GPT-4 0 ✗ 0.524 27 (23.7%)</p>
<p>Manual Analysis of Grading</p>
<p>Based on our user study, our LLM-based grading systems demonstrate high accuracy accross a variety of models and settings.The system maintains consistent scoring accuracy, with exact match rates exceeding 78% across all tested scenarios.</p>
<p>To evaluate the LLM-grader, we employed various statistical measures: (i) Avg.Abs.Diff.:  The average magnitude of the difference between the partial score given by the LLM-grader and the human evaluator.(ii) Avg.Rel.Diff.:
Model T D Avg. PS #Solved ∆#Solved Llama3-8b 0 ✗ 0.
The expected percent difference between the the partial score given by the LLM-grader and the human evaluator.% problems for which the LLM-grader (iii) overestimated and (iv) underestimated the partial score provided by the human evaluator.(v) % problems for which the LLM-grader and the human evaluator gave exactly the same partial score, and (vi) Joint Full Credit: The count of problems for which both the user and the LLM assigned full credit, normalized over the total number of problems that either party marked for full credit.This metric helps in understanding the extent of agreement in the grading of solutions between the human and machine evaluators.The metric of "Joint Full Credit," which consistently registers above 85%, serves as a robust indicator of the LLM-grader's capability to accurately assess fully correct solutions as demonstrated by the level of agreement between the LLM and a human grader.Additionally, the analysis indicates a propensity for the grader to overestimate the score of the LLM without SMT integration, whereas the integration of SMT tends to result in slight underestimations by the grader.This observation suggests that the integration of SMT and a feedback based loop may contribute more significantly to performance improvements than the raw grading differentials indicate.</p>
<p>Background and Related Work</p>
<p>The concept of agent-centric LLM agents, as discussed in recent literature revolves around creating systems (usually backed by LLMs) that can act independently in diverse environments, both physical and virtual (Wang et al., 2024).This framework shifts the focus from passive systems to proactive entities capable of dynamic interaction and problem-solving.In these models, agents are designed to perceive and react to multi-modal data, integrating visual, auditory, and textual input to generate appropriate actions in real time.The most tangible benefit of this framework is feedback, which can take the form of a physical environment, error correction, or manual input (Durante et al., 2024).</p>
<p>Significant work has been done to apply this framework to solving text-based puzzles.Zhou et al. (2023) used a process called Language Agent Tree Search (LATS), which integrates planning, reasoning, and acting within LLMs to decompose and solve a high-level reasoning task.Gao et al. (2023) showed that generating intermediate representations as Python programs allowed small LLMs to outperform much larger ones Logic-LM and SatLM both used LLMs to generate formal representations of general natural language problem and used off the shelf theorem provers to generate answers (Pan et al., 2023;Ye et al., 2023).While none of these approaches focus on Zebra puzzles, they each show that LLMs perform better when used as agents in a formally grounded system.</p>
<p>Research has shown that natural language cannot be mapped one-to-one with a formal space due to inherent ambiguities (Osama et al., 2020).For our approach, it was thus vital to create an agent that can take into account context and background knowledge to figure out the correct translation into a formal space.Even if the clues were perfectly translated as they are presented, a formal solver will not be able to generate a fully correct solution without additional encoding by the problem translator of this general context.Our approach is different from prior agent approaches in that we use a structured symbolic space (SMT-LIB) but use the syntactic and semantic feedback from an automated theorom prover for analysis in an LLM agent.We also provide a conceptual framework to understand LLM interaction with the automated theorem prover and its generated text as an agent.</p>
<p>Conclusion</p>
<p>This research shows the effectiveness of a multiagent LLM and SMT framework that bolsters the performance of large language models (LLMs) in solving logic puzzles and other natural language task.Our work demonstrates the importance of integrating LLMs and SMTs in the task, boosting preformance over an LLM alone.We also show that the interagent critique mechanism plays a crucial role.Through dialogues, agents critique and refine each other's contributions, which leads to more accurate and consistent results.The development of an autograder, with a verified correlation to human evaluation, played a role in the feedback mechanism by indicating when a solution was not judged logically correct and also enabled iterative development of our approach.Our findings suggest that structured planning and agent-feedback greatly enhance LLMs' capability to solve logical problems.</p>
<p>Looking ahead, further research could optimize retry mechanisms for discovering more effective solutions, informed by approaches like Program-of-Thoughts and Graph-of-Thoughts-Rationale (Chen et al., 2023;Besta et al., 2024).Additionally, increasing the agent-environment size and the feedback loop length would enhance the solving agent's self-correction capabilities by expanding the actual and effective context limits for remembering past strategies.</p>
<p>Limitations</p>
<p>This study, while advancing our understanding of LLMs in solving logic puzzles, has several limitations that warrant further investigation.Firstly, the experiments were confined to only three models: GPT-4, GPT-3.5, and Llama3-8b.Investigation of generalizability across different LLMs is warranted, especially because our performance gains occurred mainly in the GPT family.</p>
<p>Secondly, our approach relied on specific prompt constructions for both the grader and the solver agents.There exists a possibility that alternative prompting strategies could yield more accurate or efficient problem-solving and grading results.Further research is needed to explore and optimize these prompts to fully leverage the potential of LLMs in this domain.</p>
<p>Additionally, our user study inherently carries some uncertainty regarding its correlation to actual problem-solving performance.Solutions involving complex lookup tables were excluded from the user study due to how time consuming they were to grade, which might affect the study's comprehensiveness and the general applicability of our findings.</p>
<p>Lastly, our bank of logic grid puzzles used in this study was somewhat limited in both size-we used 114 problems-and range of difficulty.The majority of puzzles used were subjectively rated as medium difficulty.Extending this research to include a larger and more varied dataset would verify the usefulness of our findings.</p>
<p>Ethics Statement</p>
<p>Use of Generative AI.Generative models carry ethical risks, including the potential to produce harmful content or content that closely mirrors pre-training data.However, we are using the generative models to solve puzzles rather than showing their direct output, minimizing this risk.Compute.Employing deep learning models is computationally intensive and can have environmental implications.However, as no models were trained as part of this research, the computational impact remains relatively low.Human Evaluator.We use only 5 human evaluators who are undergraduate/masters students in the lab environment and were given full disclosure about the nature of the study and its unpaid nature.No ethical violations were committed in such setting.</p>
<p>Brazilian does not live in house two.</p>
<p>Figure 1 :
1
Figure 1: An Example Zebra Puzzle.</p>
<p>Figure 2: Logic Puzzle Solver Workflow</p>
<p>Figure 3 shows a working example of puzzle solving by our method.</p>
<p>Figure 3 :
3
Figure 3: Example Feedback Puzzle Solving Process.The puzzle is decomposed and then the LLM-agent attempts to translate it into a logical SMT formula.The theorem prover attempts to solve it, and the feedback is fed back into the LLM-agent so that it can modify its formal representation.</p>
<p>Table 1 :
1
Validation Results
Entity AssignmentResultHouse 1 Color: Blue✓House 1 Nationality: Brazilian ✓House 1 Animal: Cats✗House 1 Sport: Football✓House 2 Color: Green✓House 2 Nationality: American ✓House 2 Animal: Dogs✓House 2 Sport: Basketball✗House 3 Color: Red✓House 3 Nationality: German✓House 3 Animal: Fishes✗House 3 Sport: Baseball✗</p>
<p>Table 2 :
2
Baseline Performance of LLMs Without Solver Integration.The "D" column indicates if a decomposition agent was present in the workflow.The "T" column indicates Temperature.</p>
<p>Table 3 :
3
Enhancements from Solver Integration with Percentage Improvement Over Baseline.The "D" column indicates if a decomposition agent was present in the workflow.The "T" column indicates Temperature.</p>
<p>Satisfiability Modulo Theories (SMT) is a decision problem that involves determining whether a given logical formula is satisfiable, considering various background theories like Arithmetic, Arrays, Bit-Vector, etc. SMT extends the concept of Boolean satisfiability (SAT) by incorporating more complex theories.
https://github.com/ross-nordstrom/ LogicSolver/tree/master/data
Acknowledgments ReferencesA AppendixA.1 Example Puzzle WorkflowWe begin by inputting the puzzle and its entities into the Solver LLM-Agent (in this case, GPT-4).first, second, third, fourth Bridget,Kermit,Ophelia,Stretch #105,#118,#126,#128The ostrich that finished second was #128.First place was either #118 or #126.Third place was either #126 or Bridget.Ophelia finished second.Stretch finished 2 places after Kermit.The solver agent responds by attempting to translate the puzzle and its clues into SMT-LIB: ; Ophelia finished second.(assert (= Ophelia_Place 2)); Stretch finished 2 places after Kermit.(assert (= Stretch_Place (+ Kermit_Place 2))); Distinct places (assert (distinct Bridget_Place Kermit_Place Ophelia_Place Stretch_Place)); Distinct numbers (assert (distinct Bridget_Number Kermit_Number Ophelia_Number Stretch_Number))This SMT-LIB code is then fed into z3, which produces the following output:(error ""line 15 column 0: invalid command, '(' expected"") (error ""line 15 column 2: unexpected character"") (error ""line 15 column 77: unexpected character"") (error ""line 15 column 88: unexpected character"") (error ""line 15 column 117: unexpected character"") (error ""line 15 column 136: unexpected character"") (error ""line 15 column 142: unexpected character"") (error ""line 31 column 0: invalid command, '(' expected"") (error ""line 31 column 7: unexpected character"") (error ""line 57 column 0: invalid command, '(' expected"") (error ""line 57 column 7: unexpected character"") (error ""line 65 column 0: invalid command, '(' expected"") sat This output is fed back into the Solver LLM-Agent, which then produces the following modified SMT-LIB code: ; Distinct numbers (assert (distinct Bridget_Number Kermit_Number Ophelia_Number Stretch_Number))(check-sat) (get-model)Z3 produces the following output, which is then determined to be both error-free and consistent: The autograder evaluates the solution by mapping the SMT-LIB output to the expected results either using contextual clues or an explicitly defined lookup table, which would be defined in the SMT-LIB comments, converting function definitions into comparable assignments, as in Table5.In this case, the solution gets full credit.A.2 User Study InstructionsThe following instructions were presented to our manual graders before they began grading.The full UI can be found at https://anonymous.4open.science/r/anon_emnlp-1AD0by running the "autograder_flask.py"file.
Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks. Wenhu Chen, Xueguang Ma, Xinyi Wang, William W Cohen, arXiv:2211.125882023Preprint</p>
<p>User-oriented solving and explaining of natural language logic grid puzzles. Jens Claes, Bart Bogaerts, The Third Workshop on Progress Towards the Holy Grail. 201914Rocsildes Canoy, and Tias Guns</p>
<p>Zane Durante, Qiuyuan Huang, Naoki Wake, Ran Gong, Jae Sung Park, Bidipta Sarkar, Rohan Taori, Yusuke Noda, Demetri Terzopoulos, Yejin Choi, Katsushi Ikeuchi, Hoi Vo, Li Fei-Fei, Jianfeng Gao, 10.48550/arXiv.2401.03568arXivAgent ai: Surveying the horizons of multimodal interaction. 2024</p>
<p>Pal: Program-aided language models. Luyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon, Pengfei Liu, Yiming Yang, Jamie Callan, Graham Neubig, International Conference on Machine Learning. PMLR2023</p>
<p>Measuring reasoning capabilities of chatgpt. Adrian Groza, arXiv2023</p>
<p>Puzzler: An automated logic puzzle solver. Aleksandar Milicevic, Joseph P Near, Rishabh Singh, 2012Massachusetts Institute of Technology (MIT)</p>
<p>A review of algorithms for solving mathematical word problems in natural language texts. Anirban Mukherjee, Utpal Garain, 10.1007/s10462-009-9110-0Artificial Intelligence Review. 3242009</p>
<p>Score-based automatic detection and resolution of syntactic ambiguity in natural language requirements. Mohamed Osama, Aya Zaki-Ismail, Mohamed Abdelrazek, John Grundy, Amani Ibrahim, 10.1109/ICSME46990.2020.000672020 IEEE International Conference on Software Maintenance and Evolution (ICSME). 2020</p>
<p>Yizhen Shirui Pan, Yixin Zheng, Liu, arXivIntegrating graphs with large language models: Methods and prospects. 2023</p>
<p>A survey on large language model based autonomous agents. Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang, Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, Frontiers of Computer Science. 1862024</p>
<p>Satlm: Satisfiability-aided language models using declarative prompting. Xi Ye, Qiaochu Chen, Isil Dillig, Greg Durrett, Advances in Neural Information Processing Systems. Curran Associates, Inc202336</p>
<p>Language agent tree search unifies reasoning acting and planning in language models. Andy Zhou, Kai Yan, Michal Shlapentokh-Rothman, Haohan Wang, Yu-Xiong Wang, 10.48550/arXiv.2310.04406arXiv2023</p>            </div>
        </div>

    </div>
</body>
</html>