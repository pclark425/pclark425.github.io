<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2833 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2833</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2833</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-71.html">extraction-schema-71</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM-based agents that use memory systems to play text games, including details about the memory architecture, the text games played, and performance results.</div>
                <p><strong>Paper ID:</strong> paper-274965733</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2412.15266v1.pdf" target="_blank">On the Structural Memory of LLM Agents</a></p>
                <p><strong>Paper Abstract:</strong> Memory plays a pivotal role in enabling large language model~(LLM)-based agents to engage in complex and long-term interactions, such as question answering (QA) and dialogue systems. While various memory modules have been proposed for these tasks, the impact of different memory structures across tasks remains insufficiently explored. This paper investigates how memory structures and memory retrieval methods affect the performance of LLM-based agents. Specifically, we evaluate four types of memory structures, including chunks, knowledge triples, atomic facts, and summaries, along with mixed memory that combines these components. In addition, we evaluate three widely used memory retrieval methods: single-step retrieval, reranking, and iterative retrieval. Extensive experiments conducted across four tasks and six datasets yield the following key insights: (1) Different memory structures offer distinct advantages, enabling them to be tailored to specific tasks; (2) Mixed memory structures demonstrate remarkable resilience in noisy environments; (3) Iterative retrieval consistently outperforms other methods across various scenarios. Our investigation aims to inspire further research into the design of memory systems for LLM-based agents.</p>
                <p><strong>Cost:</strong> 0.016</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2833.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2833.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM-based agents that use memory systems to play text games, including details about the memory architecture, the text games played, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>StructuralMemoryLLMAgent</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLM-based QA agent studied in 'On the Structural Memory of LLM Agents' (Zeng et al., 2024)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>This paper's experimental agent architecture that generates structured memories (chunks, knowledge triples, atomic facts, summaries, and mixed) from documents, stores them (embeddings via text-embedding-3-small / LangChain) and uses retrieval-augmented prompts (single-step, reranking, iterative) with GPT-4o-mini-128k to answer long-context QA tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>LLM-based QA agent (Zeng et al., 2024)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Documents D_q are transformed into structural memories M_q of types: chunks (fixed-length text segments), knowledge triples (⟨head; relation; tail⟩), atomic facts (concise factual sentences), and summaries. Memories are embedded with text-embedding-3-small and stored via LangChain. At query time a Retriever identifies Top-K candidates; an optional LLM-based reranker or iterative query-refinement (LLM with prompt P_Refine) is applied; retrieved memories M_r are provided as context to GPT-4o-mini-128k to generate answers. Two answer-generation modes are used: Memory-Only (use M_r directly) and Memory-Doc (locate original documents referenced by M_r and use those as context).</td>
                        </tr>
                        <tr>
                            <td><strong>base_llm</strong></td>
                            <td>GPT-4o-mini-128k (temperature 0.2, input window 4k tokens)</td>
                        </tr>
                        <tr>
                            <td><strong>uses_memory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>Structured/mixed memory: chunks, knowledge triples, atomic facts, summaries (retrieval-augmented memory stored as vector embeddings)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_architecture</strong></td>
                            <td>Structural memory generation: LLM prompts (P_T, P_A, P_S) convert raw documents into C_q, T_q, A_q, S_q. Memories are embedded (text-embedding-3-small) and stored with LangChain. Retrieval methods: single-step Retriever(q, M_q, K) (classic retriever), reranking via an LLM prompt P_Rerank applied to an initial Top-K, and iterative retrieval where retrieved memories refine the query via LLM (P_Refine) over N iterations then final retrieval. Retrieved memories are prepended to LLM prompts for answer generation (Memory-Only or Memory-Doc).</td>
                        </tr>
                        <tr>
                            <td><strong>memory_capacity</strong></td>
                            <td>Configured experiments with K up to 200 (single-step retrieval), reranked R up to 75, iterative T up to 75 per iteration and N up to 4 iterations; chunk maximum size up to 1k tokens; input window 4k tokens.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_method</strong></td>
                            <td>Single-step retrieval (Retriever per Robertson et al. / standard retriever), LLM-based reranking (prompt P_Rerank), iterative retrieval with LLM-based query refinement (P_Refine).</td>
                        </tr>
                        <tr>
                            <td><strong>memory_update_strategy</strong></td>
                            <td>Structural memories are generated from raw documents (D_q) before retrieval; paper does not report online per-action memory updates during episodes (memories are document-derived and used at query time).</td>
                        </tr>
                        <tr>
                            <td><strong>text_game_benchmark</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>game_characteristics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>Reported QA results (examples): using Mixed memory + Iterative retrieval: HotPotQA EM=67.00, F1=82.11%; 2WikiMultihopQA EM=51.00, F1=68.15%; MuSiQue EM=39.00, F1=61.38%; NarrativeQA EM=12.50, F1=28.36%; QuALITY accuracy ≈79.50%. (Table 1; iterative retrieval + mixed memory gave best F1 on multi-hop datasets cited.)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td>Full-content baseline (no structured memory retrieval) reported as: HotPotQA EM=55.50, F1=75.77; 2WikiMultihopQA EM=44.00, F1=54.33; MuSiQue EM=36.00, F1=51.60; NarrativeQA EM=7.00, F1=24.99; LoCoMo EM=13.61, F1=41.82; QuALITY ACC=81.50 (Table 1 row labeled 'Full Content').</td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_ablation_results</strong></td>
                            <td>Systematic comparisons across memory structures (chunks, triples, atomic facts, summaries, mixed) and retrieval methods (single-step, reranking, iterative). Key ablation findings: mixed memory + iterative retrieval delivered most balanced/top performance; chunks/summaries better for long-context tasks; triples/atomic facts better for relational precision in multi-/single-hop QA. Sensitivity analyses performed for K, R, T, and N, and robustness to added noisy documents was measured.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_memory_types</strong></td>
                            <td>Direct comparisons in experiments: Mixed memory + iterative retrieval outperformed individual memory types (example iterative-F1 on HotPotQA: Mixed 82.11% > Atomic Facts 81.29% > Chunks 79.10% > Triples 78.78% > Summaries 78.11%). Triples delivered strong relational-reasoning performance on 2WikiMultihopQA (iterative F1=62.06% for triples as reported in prose), and atomic facts gave high HotPotQA precision (iterative F1=81.29%).</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings_about_memory_effectiveness</strong></td>
                            <td>Mixed (composite) memory structures provide robust and balanced performance across diverse QA tasks and are more resilient to noisy documents; iterative retrieval consistently yields better retrieval/QA performance than single-step or reranking; task type matters—chunks/summaries help extensive-context tasks (reading comprehension, dialogue understanding), while triples/atomic facts help relational and precision-demanding QA (multi-/single-hop).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'On the Structural Memory of LLM Agents', 'publication_date_yy_mm': '2024-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2833.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2833.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM-based agents that use memory systems to play text games, including details about the memory architecture, the text games played, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>HiAgent</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>HiAgent: Hierarchical working memory management for solving long-horizon agent tasks with large language model</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Mentioned as an example of using sub-goals as memory chunks to manage working memory in LLM-based agents for task continuity and coherence.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Hiagent: Hierarchical working memory management for solving long-horizon agent tasks with large language model.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>HiAgent</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Described in this paper as using sub-goals represented as memory chunks to manage working memory and maintain task continuity; cited in related work but not evaluated in this paper's experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>base_llm</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_memory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>Working memory implemented as sub-goal chunks</td>
                        </tr>
                        <tr>
                            <td><strong>memory_architecture</strong></td>
                            <td>Reported briefly: sub-goals are organized as chunks to manage working memory; specific storage/retrieval mechanics not detailed in this paper (citation to Hu et al., 2024).</td>
                        </tr>
                        <tr>
                            <td><strong>memory_capacity</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_update_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>text_game_benchmark</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>game_characteristics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_ablation_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_memory_types</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings_about_memory_effectiveness</strong></td>
                            <td>Mentioned as an approach that uses chunked sub-goals for working-memory management to support long-horizon tasks; no text-game usage stated in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'On the Structural Memory of LLM Agents', 'publication_date_yy_mm': '2024-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2833.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2833.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM-based agents that use memory systems to play text games, including details about the memory architecture, the text games played, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Arigraph</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Arigraph: Learning knowledge graph world models with episodic memory for LLM agents</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Cited work that adopts knowledge triples combining semantic and episodic memories to store factual and detailed information for complex reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Arigraph: Learning knowledge graph world models with episodic memory for llm agents.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Arigraph</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Mentioned as an agent that uses knowledge triples (graph-style memory) to combine semantic and episodic memories for storing factual details; cited in related work only.</td>
                        </tr>
                        <tr>
                            <td><strong>base_llm</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_memory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>Knowledge-graph style (knowledge triples), combining semantic and episodic memory</td>
                        </tr>
                        <tr>
                            <td><strong>memory_architecture</strong></td>
                            <td>Representational memory using triples ⟨head; relation; tail⟩ to capture entity relationships and events; specifics of storage/retrieval not provided in this paper (referenced to Anokhin et al., 2024).</td>
                        </tr>
                        <tr>
                            <td><strong>memory_capacity</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_update_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>text_game_benchmark</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>game_characteristics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_ablation_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_memory_types</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings_about_memory_effectiveness</strong></td>
                            <td>Cited as suitable for complex reasoning due to structured relational representation; no text-game experiments reported in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'On the Structural Memory of LLM Agents', 'publication_date_yy_mm': '2024-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2833.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2833.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM-based agents that use memory systems to play text games, including details about the memory architecture, the text games played, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ReadAgent/GraphReader</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ReadAgent / GraphReader (Li et al., 2024a) referenced for gist/summarization and graph-based memory</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Mentioned works that compress memory episodes into gist summaries and use graph-based representations to improve precision in multi-hop QA and long-context tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Graphreader: Building graph-based agent to enhance long-context abilities of large language models.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>GraphReader / ReadAgent (as cited)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Referenced for compressing memory episodes into gist summaries and organizing them in a structured memory directory (ReadAgent), and for using graph-structured memory to improve multi-hop QA precision (GraphReader). These are cited in related work; not used in experiments here.</td>
                        </tr>
                        <tr>
                            <td><strong>base_llm</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_memory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>Gist/summary memory and graph-based memory (knowledge graph)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_architecture</strong></td>
                            <td>Described at high level: ReadAgent compresses episodes into gist summaries organized in a directory; GraphReader uses graph structures to represent relations for multi-hop QA. Implementation details are in the cited works (Li et al., 2024a).</td>
                        </tr>
                        <tr>
                            <td><strong>memory_capacity</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_update_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>text_game_benchmark</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>game_characteristics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_ablation_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_memory_types</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings_about_memory_effectiveness</strong></td>
                            <td>Cited as evidence that summarization/gist memory and graph-based representations help long-context and multi-hop reasoning; no text-game applications reported here.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'On the Structural Memory of LLM Agents', 'publication_date_yy_mm': '2024-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2833.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2833.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM-based agents that use memory systems to play text games, including details about the memory architecture, the text games played, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MemGPT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>MemGPT: Towards LLMs as operating systems</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Cited as a work focusing on memory modules in LLM agents (MemGPT) and general memory augmentation, referenced in related work.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Memgpt: Towards llms as operating systems.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>MemGPT</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Referenced in the context of memory modules for LLM-based agents; this paper mentions MemGPT in related work but does not evaluate it.</td>
                        </tr>
                        <tr>
                            <td><strong>base_llm</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_memory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>Long-term / system-level memory (as discussed in MemGPT literature)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_architecture</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_capacity</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_update_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>text_game_benchmark</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>game_characteristics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_ablation_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_memory_types</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings_about_memory_effectiveness</strong></td>
                            <td>Mentioned as part of prior art on memory-augmented LLM systems; no experiments or text-game usage presented in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'On the Structural Memory of LLM Agents', 'publication_date_yy_mm': '2024-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2833.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e2833.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM-based agents that use memory systems to play text games, including details about the memory architecture, the text games played, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Memorybank</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Memorybank: Enhancing large language models with long-term memory</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Cited as a work that augments LLMs with long-term memory modules; referenced in related work for memory mechanisms.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Memorybank: Enhancing large language models with long-term memory.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Memorybank</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Referenced as an approach to enhance LLMs with long-term memory; cited but not experimentally used in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>base_llm</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_memory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>Long-term memory augmentation</td>
                        </tr>
                        <tr>
                            <td><strong>memory_architecture</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_capacity</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_update_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>text_game_benchmark</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>game_characteristics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_ablation_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_memory_types</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings_about_memory_effectiveness</strong></td>
                            <td>Cited as related work on long-term memory for LLMs; no text-game usage described in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'On the Structural Memory of LLM Agents', 'publication_date_yy_mm': '2024-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Hiagent: Hierarchical working memory management for solving long-horizon agent tasks with large language model. <em>(Rating: 2)</em></li>
                <li>Arigraph: Learning knowledge graph world models with episodic memory for llm agents. <em>(Rating: 2)</em></li>
                <li>Graphreader: Building graph-based agent to enhance long-context abilities of large language models. <em>(Rating: 2)</em></li>
                <li>Memgpt: Towards llms as operating systems. <em>(Rating: 2)</em></li>
                <li>Memorybank: Enhancing large language models with long-term memory. <em>(Rating: 2)</em></li>
                <li>A survey on the memory mechanism of large language model based agents. <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2833",
    "paper_id": "paper-274965733",
    "extraction_schema_id": "extraction-schema-71",
    "extracted_data": [
        {
            "name_short": "StructuralMemoryLLMAgent",
            "name_full": "LLM-based QA agent studied in 'On the Structural Memory of LLM Agents' (Zeng et al., 2024)",
            "brief_description": "This paper's experimental agent architecture that generates structured memories (chunks, knowledge triples, atomic facts, summaries, and mixed) from documents, stores them (embeddings via text-embedding-3-small / LangChain) and uses retrieval-augmented prompts (single-step, reranking, iterative) with GPT-4o-mini-128k to answer long-context QA tasks.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "LLM-based QA agent (Zeng et al., 2024)",
            "agent_description": "Documents D_q are transformed into structural memories M_q of types: chunks (fixed-length text segments), knowledge triples (⟨head; relation; tail⟩), atomic facts (concise factual sentences), and summaries. Memories are embedded with text-embedding-3-small and stored via LangChain. At query time a Retriever identifies Top-K candidates; an optional LLM-based reranker or iterative query-refinement (LLM with prompt P_Refine) is applied; retrieved memories M_r are provided as context to GPT-4o-mini-128k to generate answers. Two answer-generation modes are used: Memory-Only (use M_r directly) and Memory-Doc (locate original documents referenced by M_r and use those as context).",
            "base_llm": "GPT-4o-mini-128k (temperature 0.2, input window 4k tokens)",
            "uses_memory": true,
            "memory_type": "Structured/mixed memory: chunks, knowledge triples, atomic facts, summaries (retrieval-augmented memory stored as vector embeddings)",
            "memory_architecture": "Structural memory generation: LLM prompts (P_T, P_A, P_S) convert raw documents into C_q, T_q, A_q, S_q. Memories are embedded (text-embedding-3-small) and stored with LangChain. Retrieval methods: single-step Retriever(q, M_q, K) (classic retriever), reranking via an LLM prompt P_Rerank applied to an initial Top-K, and iterative retrieval where retrieved memories refine the query via LLM (P_Refine) over N iterations then final retrieval. Retrieved memories are prepended to LLM prompts for answer generation (Memory-Only or Memory-Doc).",
            "memory_capacity": "Configured experiments with K up to 200 (single-step retrieval), reranked R up to 75, iterative T up to 75 per iteration and N up to 4 iterations; chunk maximum size up to 1k tokens; input window 4k tokens.",
            "memory_retrieval_method": "Single-step retrieval (Retriever per Robertson et al. / standard retriever), LLM-based reranking (prompt P_Rerank), iterative retrieval with LLM-based query refinement (P_Refine).",
            "memory_update_strategy": "Structural memories are generated from raw documents (D_q) before retrieval; paper does not report online per-action memory updates during episodes (memories are document-derived and used at query time).",
            "text_game_benchmark": null,
            "game_characteristics": null,
            "performance_with_memory": "Reported QA results (examples): using Mixed memory + Iterative retrieval: HotPotQA EM=67.00, F1=82.11%; 2WikiMultihopQA EM=51.00, F1=68.15%; MuSiQue EM=39.00, F1=61.38%; NarrativeQA EM=12.50, F1=28.36%; QuALITY accuracy ≈79.50%. (Table 1; iterative retrieval + mixed memory gave best F1 on multi-hop datasets cited.)",
            "performance_without_memory": "Full-content baseline (no structured memory retrieval) reported as: HotPotQA EM=55.50, F1=75.77; 2WikiMultihopQA EM=44.00, F1=54.33; MuSiQue EM=36.00, F1=51.60; NarrativeQA EM=7.00, F1=24.99; LoCoMo EM=13.61, F1=41.82; QuALITY ACC=81.50 (Table 1 row labeled 'Full Content').",
            "has_ablation_study": true,
            "memory_ablation_results": "Systematic comparisons across memory structures (chunks, triples, atomic facts, summaries, mixed) and retrieval methods (single-step, reranking, iterative). Key ablation findings: mixed memory + iterative retrieval delivered most balanced/top performance; chunks/summaries better for long-context tasks; triples/atomic facts better for relational precision in multi-/single-hop QA. Sensitivity analyses performed for K, R, T, and N, and robustness to added noisy documents was measured.",
            "comparison_with_other_memory_types": "Direct comparisons in experiments: Mixed memory + iterative retrieval outperformed individual memory types (example iterative-F1 on HotPotQA: Mixed 82.11% &gt; Atomic Facts 81.29% &gt; Chunks 79.10% &gt; Triples 78.78% &gt; Summaries 78.11%). Triples delivered strong relational-reasoning performance on 2WikiMultihopQA (iterative F1=62.06% for triples as reported in prose), and atomic facts gave high HotPotQA precision (iterative F1=81.29%).",
            "key_findings_about_memory_effectiveness": "Mixed (composite) memory structures provide robust and balanced performance across diverse QA tasks and are more resilient to noisy documents; iterative retrieval consistently yields better retrieval/QA performance than single-step or reranking; task type matters—chunks/summaries help extensive-context tasks (reading comprehension, dialogue understanding), while triples/atomic facts help relational and precision-demanding QA (multi-/single-hop).",
            "uuid": "e2833.0",
            "source_info": {
                "paper_title": "On the Structural Memory of LLM Agents",
                "publication_date_yy_mm": "2024-12"
            }
        },
        {
            "name_short": "HiAgent",
            "name_full": "HiAgent: Hierarchical working memory management for solving long-horizon agent tasks with large language model",
            "brief_description": "Mentioned as an example of using sub-goals as memory chunks to manage working memory in LLM-based agents for task continuity and coherence.",
            "citation_title": "Hiagent: Hierarchical working memory management for solving long-horizon agent tasks with large language model.",
            "mention_or_use": "mention",
            "agent_name": "HiAgent",
            "agent_description": "Described in this paper as using sub-goals represented as memory chunks to manage working memory and maintain task continuity; cited in related work but not evaluated in this paper's experiments.",
            "base_llm": null,
            "uses_memory": true,
            "memory_type": "Working memory implemented as sub-goal chunks",
            "memory_architecture": "Reported briefly: sub-goals are organized as chunks to manage working memory; specific storage/retrieval mechanics not detailed in this paper (citation to Hu et al., 2024).",
            "memory_capacity": null,
            "memory_retrieval_method": null,
            "memory_update_strategy": null,
            "text_game_benchmark": null,
            "game_characteristics": null,
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_ablation_study": null,
            "memory_ablation_results": null,
            "comparison_with_other_memory_types": null,
            "key_findings_about_memory_effectiveness": "Mentioned as an approach that uses chunked sub-goals for working-memory management to support long-horizon tasks; no text-game usage stated in this paper.",
            "uuid": "e2833.1",
            "source_info": {
                "paper_title": "On the Structural Memory of LLM Agents",
                "publication_date_yy_mm": "2024-12"
            }
        },
        {
            "name_short": "Arigraph",
            "name_full": "Arigraph: Learning knowledge graph world models with episodic memory for LLM agents",
            "brief_description": "Cited work that adopts knowledge triples combining semantic and episodic memories to store factual and detailed information for complex reasoning.",
            "citation_title": "Arigraph: Learning knowledge graph world models with episodic memory for llm agents.",
            "mention_or_use": "mention",
            "agent_name": "Arigraph",
            "agent_description": "Mentioned as an agent that uses knowledge triples (graph-style memory) to combine semantic and episodic memories for storing factual details; cited in related work only.",
            "base_llm": null,
            "uses_memory": true,
            "memory_type": "Knowledge-graph style (knowledge triples), combining semantic and episodic memory",
            "memory_architecture": "Representational memory using triples ⟨head; relation; tail⟩ to capture entity relationships and events; specifics of storage/retrieval not provided in this paper (referenced to Anokhin et al., 2024).",
            "memory_capacity": null,
            "memory_retrieval_method": null,
            "memory_update_strategy": null,
            "text_game_benchmark": null,
            "game_characteristics": null,
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_ablation_study": null,
            "memory_ablation_results": null,
            "comparison_with_other_memory_types": null,
            "key_findings_about_memory_effectiveness": "Cited as suitable for complex reasoning due to structured relational representation; no text-game experiments reported in this paper.",
            "uuid": "e2833.2",
            "source_info": {
                "paper_title": "On the Structural Memory of LLM Agents",
                "publication_date_yy_mm": "2024-12"
            }
        },
        {
            "name_short": "ReadAgent/GraphReader",
            "name_full": "ReadAgent / GraphReader (Li et al., 2024a) referenced for gist/summarization and graph-based memory",
            "brief_description": "Mentioned works that compress memory episodes into gist summaries and use graph-based representations to improve precision in multi-hop QA and long-context tasks.",
            "citation_title": "Graphreader: Building graph-based agent to enhance long-context abilities of large language models.",
            "mention_or_use": "mention",
            "agent_name": "GraphReader / ReadAgent (as cited)",
            "agent_description": "Referenced for compressing memory episodes into gist summaries and organizing them in a structured memory directory (ReadAgent), and for using graph-structured memory to improve multi-hop QA precision (GraphReader). These are cited in related work; not used in experiments here.",
            "base_llm": null,
            "uses_memory": true,
            "memory_type": "Gist/summary memory and graph-based memory (knowledge graph)",
            "memory_architecture": "Described at high level: ReadAgent compresses episodes into gist summaries organized in a directory; GraphReader uses graph structures to represent relations for multi-hop QA. Implementation details are in the cited works (Li et al., 2024a).",
            "memory_capacity": null,
            "memory_retrieval_method": null,
            "memory_update_strategy": null,
            "text_game_benchmark": null,
            "game_characteristics": null,
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_ablation_study": null,
            "memory_ablation_results": null,
            "comparison_with_other_memory_types": null,
            "key_findings_about_memory_effectiveness": "Cited as evidence that summarization/gist memory and graph-based representations help long-context and multi-hop reasoning; no text-game applications reported here.",
            "uuid": "e2833.3",
            "source_info": {
                "paper_title": "On the Structural Memory of LLM Agents",
                "publication_date_yy_mm": "2024-12"
            }
        },
        {
            "name_short": "MemGPT",
            "name_full": "MemGPT: Towards LLMs as operating systems",
            "brief_description": "Cited as a work focusing on memory modules in LLM agents (MemGPT) and general memory augmentation, referenced in related work.",
            "citation_title": "Memgpt: Towards llms as operating systems.",
            "mention_or_use": "mention",
            "agent_name": "MemGPT",
            "agent_description": "Referenced in the context of memory modules for LLM-based agents; this paper mentions MemGPT in related work but does not evaluate it.",
            "base_llm": null,
            "uses_memory": true,
            "memory_type": "Long-term / system-level memory (as discussed in MemGPT literature)",
            "memory_architecture": null,
            "memory_capacity": null,
            "memory_retrieval_method": null,
            "memory_update_strategy": null,
            "text_game_benchmark": null,
            "game_characteristics": null,
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_ablation_study": null,
            "memory_ablation_results": null,
            "comparison_with_other_memory_types": null,
            "key_findings_about_memory_effectiveness": "Mentioned as part of prior art on memory-augmented LLM systems; no experiments or text-game usage presented in this paper.",
            "uuid": "e2833.4",
            "source_info": {
                "paper_title": "On the Structural Memory of LLM Agents",
                "publication_date_yy_mm": "2024-12"
            }
        },
        {
            "name_short": "Memorybank",
            "name_full": "Memorybank: Enhancing large language models with long-term memory",
            "brief_description": "Cited as a work that augments LLMs with long-term memory modules; referenced in related work for memory mechanisms.",
            "citation_title": "Memorybank: Enhancing large language models with long-term memory.",
            "mention_or_use": "mention",
            "agent_name": "Memorybank",
            "agent_description": "Referenced as an approach to enhance LLMs with long-term memory; cited but not experimentally used in this paper.",
            "base_llm": null,
            "uses_memory": true,
            "memory_type": "Long-term memory augmentation",
            "memory_architecture": null,
            "memory_capacity": null,
            "memory_retrieval_method": null,
            "memory_update_strategy": null,
            "text_game_benchmark": null,
            "game_characteristics": null,
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_ablation_study": null,
            "memory_ablation_results": null,
            "comparison_with_other_memory_types": null,
            "key_findings_about_memory_effectiveness": "Cited as related work on long-term memory for LLMs; no text-game usage described in this paper.",
            "uuid": "e2833.5",
            "source_info": {
                "paper_title": "On the Structural Memory of LLM Agents",
                "publication_date_yy_mm": "2024-12"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Hiagent: Hierarchical working memory management for solving long-horizon agent tasks with large language model.",
            "rating": 2,
            "sanitized_title": "hiagent_hierarchical_working_memory_management_for_solving_longhorizon_agent_tasks_with_large_language_model"
        },
        {
            "paper_title": "Arigraph: Learning knowledge graph world models with episodic memory for llm agents.",
            "rating": 2,
            "sanitized_title": "arigraph_learning_knowledge_graph_world_models_with_episodic_memory_for_llm_agents"
        },
        {
            "paper_title": "Graphreader: Building graph-based agent to enhance long-context abilities of large language models.",
            "rating": 2,
            "sanitized_title": "graphreader_building_graphbased_agent_to_enhance_longcontext_abilities_of_large_language_models"
        },
        {
            "paper_title": "Memgpt: Towards llms as operating systems.",
            "rating": 2,
            "sanitized_title": "memgpt_towards_llms_as_operating_systems"
        },
        {
            "paper_title": "Memorybank: Enhancing large language models with long-term memory.",
            "rating": 2,
            "sanitized_title": "memorybank_enhancing_large_language_models_with_longterm_memory"
        },
        {
            "paper_title": "A survey on the memory mechanism of large language model based agents.",
            "rating": 2,
            "sanitized_title": "a_survey_on_the_memory_mechanism_of_large_language_model_based_agents"
        }
    ],
    "cost": 0.0156215,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>On the Structural Memory of LLM Agents
17 Dec 2024</p>
<p>Ruihong Zeng 
University of Glasgow</p>
<p>Jinyuan Fang j.fang.2@research.gla.ac.uk 
University of Glasgow</p>
<p>Siwei Liu siwei.liu@abdn.ac.uk 
University of Aberdeen</p>
<p>Zaiqiao Meng zaiqiao.meng@glasgow.ac.uk 
University of Glasgow</p>
<p>On the Structural Memory of LLM Agents
17 Dec 2024637475C957B6B0C97C369F96409ED5ADarXiv:2412.15266v1[cs.CL]
Memory plays a pivotal role in enabling large language model (LLM)-based agents to engage in complex and long-term interactions, such as question answering (QA) and dialogue systems.While various memory modules have been proposed for these tasks, the impact of different memory structures across tasks remains insufficiently explored.This paper investigates how memory structures and memory retrieval methods affect the performance of LLMbased agents.Specifically, we evaluate four types of memory structures, including chunks, knowledge triples, atomic facts, and summaries, along with mixed memory that combines these components.In addition, we evaluate three widely used memory retrieval methods: singlestep retrieval, reranking, and iterative retrieval.Extensive experiments conducted across four tasks and six datasets yield the following key insights: (1) Different memory structures offer distinct advantages, enabling them to be tailored to specific tasks; (2) Mixed memory structures demonstrate remarkable resilience in noisy environments; (3) Iterative retrieval consistently outperforms other methods across various scenarios.Our investigation aims to inspire further research into the design of memory systems for LLM-based agents. 1</p>
<p>Introduction</p>
<p>Large Language Models (LLMs) (Minaee et al., 2024) have attracted widespread attention in natural language tasks due to their remarkable capability.Recent advancements have significantly accelerated the development of LLM-based agents, with research primarily focusing on profile (Park et al., 2023;Hong et al.), planning (Qian et al., 2024;Qiao et al., 2024), action (Qin et al., 2023  et al., 2024c), self-evolving (Zhang et al., 2024a) and memory (Packer et al., 2023;Lee et al., 2024).These innovations have unlocked a wide range of applications across diverse applications (Li et al., 2023;Wang et al., 2024b;Chen et al., 2024).</p>
<p>A fundamental element that underpins the effectiveness of LLM-based agents is the memory module.In cognitive science (Simon and Newell, 1971;Anderson, 2013), memory is the cornerstone of human cognition, enabling the storage, retrieval, and drawing from past experiences for strategic thinking and decision-making.Similarly, the memory module is vital for LLM-based agents by facilitating the retention and organization of past interactions, supporting complex reasoning capabilities, e.g., multi-hop question answering (QA) (Li et al., 2024a;Lee et al., 2024), and ensuring consistency and continuity in user interactions (Nuxoll and Laird, 2007).</p>
<p>Developing an effective memory module in LLM-based agents typically involves two critical components: structural memory generation and memory retrieval methods (Wang et al., 2024a;Zhang et al., 2024b).Among the various memory structures used by agents, chunks (Hu et al., 2024), knowledge triples (Anokhin et al., 2024), atomic facts (Li et al., 2024a), and summaries (Lee et al., 2024) are the most prevalent.For instance, HiAgent (Hu et al., 2024) utilizes sub-goals as memory chunks to manage the working memory of LLM-based agents, ensuring task continuity and coherence, while Arigraph (Anokhin et al., 2024) adopts knowledge triples, which combine both semantic and episodic memories to store factual and detailed information, making it suitable for complex reasoning tasks.Meanwhile, ReadAgent (Li et al., 2024a) compresses memory episodes into gits memory with summaries manner, organizing them within a structured memory directory.</p>
<p>Upon reviewing the aforementioned memory structures, an important but under-explored question arises: Which memory structures are best suited for specific tasks, and how do their distinct characteristics impact the performance of LLM-based agents?This question mirrors how humans organize memory into distinct forms, such as episodic memory for recalling events and semantic memory for understanding relationships (Simon and Newell, 1971;Anderson, 2013).Each form serves a unique purpose, enabling humans to tackle a variety of challenges with flexibility and precision.Moreover, humans rely on effective retrieval processes to access relevant memories, ensuring the accurate recall of past experiences for problemsolving.This highlights the need to jointly explore memory structures and retrieval methods to enhance the reasoning capabilities and overall effectiveness of LLM-based agents.</p>
<p>To bridge this gap, we systematically explore the impact of various memory structures and retrieval methods in LLM-based agents.Specifically, we evaluate existing four types of memory structures: chunks (Hu et al., 2024), knowledge triples (Anokhin et al., 2024), atomic facts (Li et al., 2024a), and summaries (Li et al., 2024a).Building on these, we explore the potential of mixed memory structures, which combine multiple types of memories to examine whether their complementary characteristics can enhance performance.Additionally, we assess the robustness of these memory structures to noise, as understanding their reliability under such conditions is essential for ensuring effectiveness across diverse tasks.Furthermore, we investigate three memory retrieval methods, including single-step retrieval (Packer et al., 2023), reranking (Gao et al., 2023a), and iterative retrieval (Li et al., 2024b), to uncover how different combinations of retrieval methods and memory structures influence overall performance.</p>
<p>The main contributions of this work can be summarized as follows: (1) We present the first comprehensive study on the impact of memory struc-tures and memory retrieval methods in LLM-based agents on six datasets across four tasks: multi-hop QA, single-hop QA, dialogue understanding, and reading comprehension.(2) Our findings reveal that mixed memory consistently achieves balanced and competitive performance across diverse tasks.Chunks and summaries excel in tasks involving extensive and lengthy context (e.g., reading comprehension and dialogue understanding), while knowledge triples and atomic facts are particularly effective for relational reasoning and precision in multihop and single-hop QA.Additionally, mixed memory demonstrates remarkable resilience to noise.</p>
<p>(3) Iterative retrieval stands out as the most effective memory retrieval method across most tasks, such as multi-hop QA, dialogue understanding and reading comprehension.</p>
<p>Related Works</p>
<p>LLM-based Agents</p>
<p>The advent of Large Language Model (LLM) has positioned them as a transformative step towards achieving Artificial General Intelligence (AGI) (Wang et al., 2024a), offering robust capabilities for the development of LLM-based agents (Xi et al., 2023;Xu et al., 2024).Current research in this field primarily focuses on agent planning (Wang et al., 2023;Yao et al., 2024;Qian et al., 2024;Qiao et al., 2024), reflection mechanisms (Shinn et al., 2024;Zhang et al., 2024a), external tools utilization (Qin et al., 2023;Wang et al., 2024c), self-evolving capabilities (Zhang et al., 2024a) and memory modules (Hu et al., 2024;Lee et al., 2024).</p>
<p>Memory Structures</p>
<p>Memory module serves as the foundation of LLMbased agents, enabling them to structure knowledge, retrieve relevant information, and leverage prior experiences for reasoning tasks (Zhang et al., 2024b).Among the widely adopted memory structures of memory module are chunks (Packer et al., 2023;Liu et al., 2023;Hu et al., 2024), knowledge triples (Anokhin et al., 2024), atomic facts (Li et al., 2024a), and summaries (Lee et al., 2024).For instance, HiAgent (Hu et al., 2024) incorporates sub-goals as memory chunks to maintain task continuity and coherence across interactions.On the other hand, GraphReader (Li et al., 2024a)   that improves precision in multi-hop question answering tasks.In this paper, we investigate how various memory structures impact the performance of LLM-based agents.</p>
<p>Memory Retrieval</p>
<p>The memory retrieval method is another critical component of the memory module, enabling LLMbased agents to retrieve relevant memories to advanced reasoning.To facilitate this, LLM-based agents often employ retrieval-augmented generation (RAG) (Lewis et al., 2020;Fang et al., 2024), where relevant memories are first retrieved and then used to generate answers with LLMs.In this setting, the retrieved memories are prepended to the queries and serve as input to the LLM to generate response (Ram et al., 2023).The most straightforward retrieval method is the single-step retrieval (Packer et al., 2023;Zhong et al., 2024), which aims to identify the Top-K most relevant memories for the query.Additionally, reranking (Gao et al., 2023a;Ji et al., 2024) leverages the language understanding capabilities of LLMs to prioritize retrieved memories, while iterative retrieval (Li et al., 2024b;Shi et al., 2024) focuses on reformulating queries to improve retrieval accuracy.These innovations make memory retrieval more adaptive and consistent with the query, maintaining effective performance across diverse and complex tasks.In this paper, we explore how different combinations of retrieval methods and memory structures influence overall performance.</p>
<p>Methodology</p>
<p>Figure 2 illustrates the overview of the memory module within LLM-based agents, highlighting three key components: Structural Memory Generation, Memory Retrieval Methods and Answer Generation.This section begins with an introduction to structural memory generation in § 3.1.Next, we introduce memory retrieval methods in § 3.2.Finally, § 3.3 discusses answer generation methods.</p>
<p>Structural Memory Generation</p>
<p>Structural memory generation enables agents to organize raw documents into structured representations.By transforming unstructured documents D q into structural memory M q , the agent gains the ability to store, retrieve, and reason over information more effectively.In this work, we explore four distinct forms of structural memory: chunks C q , knowledge triples T q , atomic facts A q , or summaries S q .The generation process for each structural memory is detailed as follows: Chunks (C q ).Chunks (Gao et al., 2023b) are a widely used form of structural memory in LLMbased agents.Each chunk represents a continuous segment of text from a document, typically constrained to a fixed number of tokens L. Formally, raw documents D q can be divided into a series of chunks, as defined: C q (D q ) = {c 1 , c 2 , . . ., c j }, where each chunk c j contains at most L tokens.</p>
<p>Chunks</p>
<p>Definition: Chunks are continuous, fixedlength segments of text from the document.Example: Generated chunks C q :</p>
<p>(1) Moneybomb (alternatively money bomb, money-bomb, or fundraising bomb) is a neologism coined in 2007;</p>
<p>(2) to describe a grassroots fundraising effort over a brief fixed time period.</p>
<p>Knowledge Triples (T q ).Knowledge triples represent a structured form of memory that captures semantic relationships between entities.Each triple is composed of three components: a head entity, a relation, and a tail entity, represented in the format ⟨head; relation; tail entity⟩.Following previous works (Anokhin et al., 2024;Fang et al., 2024), raw documents D q are processed by an LLM guided by a tailored prompt P T to generate a set of semantic triples T q .The generation process can be formally defined as: T q = LLM(D q , P T ).</p>
<p>Knowledge Triples</p>
<p>Definition: Knowledge triples capture relationships between entities.Example: Generated triples T q : (1) ⟨Moneybomb; type; neologism⟩;</p>
<p>(2) ⟨Moneybomb; coined in; 2007⟩.</p>
<p>Atomic Facts (A q ).Atomic facts are the smallest, indivisible units of information, presented as concise sentences that capture essential details.They represent a granular form of structural memory, simplifying raw documents by preserving critical entities, actions, and attributes.Following Li et al. (2024a), atomic facts are generated from raw documents D q using an LLM guided by a tailored prompt P A , formally denoted as: A q = LLM(D q , P A ).</p>
<p>Atomic Facts</p>
<p>Definition: Atomic facts are the smallest units of indivisible information.Example: Generated atomic facts A q :</p>
<p>(1) Moneybomb is also known as money bomb, money-bomb, or fundraising bomb;</p>
<p>(2) Moneybomb is a neologism.</p>
<p>Summaries (S q ).Summaries provide a condensed and comprehensive description of documents, cap-turing both global content and key details.Following Lee et al. (2024), summaries are generated from raw documents D q using an LLM guided by a tailored prompt P S , defined as: S q = LLM(D q , P S ).</p>
<p>Summaries</p>
<p>Definition: Summaries compress the document into a comprehensive description.Example: Generated summaries S q : Moneybomb, alternatively referred to as money bomb, money-bomb, or fundraising bomb, is a neologism coined in 2007.It describes a grassroots fundraising effort that occurs over a brief fixed time period.</p>
<p>Mixed (M Mixed q</p>
<p>). Mixed memories represent a composite form of structural memory, combining all the aforementioned types: chunks, knowledge triples, atomic facts, and summaries.This integration provides a comprehensive representation, formally defined as follows:
M Mixed q = C q ∪ T q ∪ A q ∪ S q .
Details of the prompts used by the LLM for generating each type of structural memory, e.g., P T , P A and P S , are provided in Appendix B.</p>
<p>Memory Retrieval Methods</p>
<p>Given the generated structural memories M q , we employ a memory retrieval method to identify and integrate the most relevant supporting memories M r ⊂ M q for the query q.Without this step, the agent would need to process all available memories, leading to inefficiency and potential inaccuracies due to irrelevant information.Our study mainly focuses on three retrieval approaches: single-step retrieval (Robertson et al., 2009;Rubin et al., 2022), reranking (Gao et al., 2023a;Ji et al., 2024), and iterative retrieval (Li et al., 2024b;Shi et al., 2024).The details of each memory retrieval method are outlined as follows:</p>
<p>Single-step Retrieval.In the single-step retrieval process, the goal is to identify the Top-K memories M r that are most relevant to the query q.This process is formally defined as: M r = Retriever(q, M q , K), where the Retriever (Robertson et al., 2009;Rubin et al., 2022) serves as the core component.</p>
<p>Reranking.In the reranking process (Gao et al., 2023a;Dong et al., 2024), an initial retriever selects a candidate set of Top-K memories M i , which are then reranked by an LLM prompted with P Rerank based on their relevance scores.From this reranked list, the Top-R memories M r , selected in descending order of relevance scores, are identified as the most relevant.This step enhances retrieval precision by leveraging the LLM to strengthen query-memory connections, filtering out irrelevant memories, and prioritizing the most pertinent memories for the query.This process is formally defined as: M r = LLM(q, M i , R, P R ) , where M i = Retriever(q, M q , K).</p>
<p>Iterative Retrieval.The iterative retrieval approach (Gao et al., 2023b) begins with an initial query q 0 = q and retrieves the Top-T most relevant structural memories M j .These retrieved memories are used to refine the query through an LLM prompted by P Refine .This process is repeated over N iterations, refining the query to produce the final version q N that is informative for retrieving relevant memories.Formally, the iterative retrieval process can be defined as follows: q j = LLM(M j , P Refine ), where M j = Retriever(q j−1 , M q , T ).After N iterations, the final refined query q N is used to retrieve the Top-K most relevant memories for answer generation.This step can be expressed as: M r = Retriever(q N , M q , K).The detailed prompts P Rerank and P Refine can be found in Appendix B.</p>
<p>Answer Generation</p>
<p>Finally, the agent leverages the LLM to generate the answer based on the retrieved memory.To achieve this, we propose two methods of answer generation.In the first method, termed Memory-Only, the retrieved memories M r are directly utilized as the context for generating the answer.The second method, termed Memory-Doc, uses the retrieved memories to locate their corresponding original documents from D q .These documents then serve as the context for answer generation, providing the agent with more detailed and contextually enriched information.</p>
<p>Experiments</p>
<p>4.1 Datasets.We conduct experiments on six datasets across four tasks.For multi-hop long-context QA datasets, we experiment with HotPotQA (Yang et al., 2018), 2WikiMultihopQA (Ho et al., 2020), and MuSiQue (Trivedi et al., 2022).The single-hop long-context QA task is evaluated with Narra-tiveQA (Kočiskỳ et al., 2018) from Longbench (Bai et al., 2023).Additionally, we leverage the Lo-CoMo dataset (Maharana et al., 2024) for dialoguebased long-context QA task, while the QuAL-ITY (Pang et al., 2022) dataset is used for the reading comprehension QA task 2 .</p>
<p>Evaluation.</p>
<p>To evaluate QA performance, we follow previous work (Li et al., 2024a) and use standard metrics such as Exact Match (EM) score and F1 score for the datasets HotPotQA, 2WikiMultihopQA, MuSiQue, NarrativeQA and LoCoMo.For QuAL-ITY, we follow the approach in (Lee et al., 2024) and use accuracy as the evaluation metric, with 25% indicating chance performance.</p>
<p>Implementation Details.</p>
<p>In our experiments, we use GPT-4o-mini-128k with a temperature setting of 0.2.The input window is set to 4k tokens, while the maximum chunk size is up to 1k tokens.For text embedding, we employ the text-embedding-3-small model 3 from OpenAI and store the vectorized memories using LangChain (Chase, 2022).</p>
<p>Results and Analysis</p>
<p>Impact of Memory Structures</p>
<p>Finding 1: Mixed memories delivers more balanced performance.The results as presented in Table 1 reveal key insights into the impact of various memory structures on task performance:</p>
<p>(1) Mixed memories consistently outperform other memory structures.This is particularly evident under iterative retrieval, where mixed memories achieve the highest F1 scores of 82.11% on Hot-PotQA and 68.15% on 2WikiMultihopQA.(2) Chunks excel in tasks requiring a balance between concise and comprehensive contexts, as shown in datasets with long contexts.This is evidenced by its F1 score of 31.63% on NarrativeQA and an accuracy of 78.5% on QuALITY under reranking.Summaries, which condense large contexts, is effective for tasks demanding abstraction, as shown by its competitive F1 score of 32.26% on NarrativeQA and solid performance on LoCoMo.(3) Knowledge triples and atomic facts are particularly effective for relational reasoning and precision.Knowledge  triples achieve an F1 score of 62.06% on 2Wiki-MultihopQA under iterative retrieval, while atomic facts achieve an F1 score of 81.29% on HotPotQA.These findings emphasize the importance of tailoring memory structures to specific task requirements and demonstrate that integrating complementary memory types in mixed memories significantly enhances performance across tasks.</p>
<p>Impact of Memory Retrieval Methods</p>
<p>Finding 2: Iterative retrieval as the optimal retrieval method.The results in Table 1 demonstrate the significant influence of the retrieval method on performance: (1) Iterative retrieval consistently outperforms the others, achieving the highest scores across most datasets.Notably, with mixed memories, iterative retrieval achieved an F1 score of 82.11% on HotPotQA and 68.15% on 2WikiMul-tihopQA, showcasing its ability to refine queries iteratively for enhanced accuracy.(2) Reranking demonstrates strong performance on datasets with moderate complexity.For instance, it achieved F1 scores of 44.27% on LoCoMo and 28.19% on NarrativeQA with atomic fact memory.</p>
<p>(3) In contrast, single-step retrieval performs competitively in tasks requiring minimal contextual integration.Using summary memory, it achieved an F1 score of 32.93% on NarrativeQA, leveraging abstraction to extract coherent information.These findings emphasize the importance of aligning retrieval mechanisms with task requirements, and iterative retrieval excels in reasoning tasks.</p>
<p>Impact of Answer Generation Approaches</p>
<p>Finding 3: Extensive Context tasks favor Memory-Doc, while precision tasks benefit from Memory-Only.As shown in Figure 3, which compares their performance across various datasets.retrieving documents through retrieved memories provides a more comprehensive understanding, much like how humans integrate immediate recall with broader context to interpret complex narratives.In contrast, for datasets involving multi-hop reasoning and dialogue understanding, such as Hot-PotQA and LoCoMo, the Memory-Only approach proves to be the more effective strategy.These findings highlight that tasks requiring extensive context benefit from the Memory-Doc approach, which incorporates broader document-level information for enriched responses.On the other hand, tasks prioritizing precision are better suited to the Memory-Only approach, ensuring focused and accurate retrieval.</p>
<p>Hyperparameter Sensitivity</p>
<p>Effect of Number of Retrieved Memories K. We first evaluate the impact of K in single-step retrieval, with a limit of K = 200 due to computational resource limitations.As depicted in summaries improve up to K = 100 but then declined at K = 200, likely due to noise introduced by retrieving excessive memories.These findings indicate that the optimal K depends on both the dataset and memory structure.While moderate K values generally enhance performance, excessively large values can introduce irrelevant information, leading to a degraded performance.</p>
<p>Effect of Number of Reranked Memories R. To evaluate the impact of R in reranking, we investigate performance across a range of values, with a maximum R of 75 due to computational cost constraints, while fixing K at 100.As depicted in Figure 5, the results highlight that increasing the number of reranked memories does not always lead to better performance.For instance, chunks achieve the highest F1 score at R = 10 in Hot-PotQA, with a subsequent decline in performance beyond R = 50.This pattern is consistent with triples and atomic facts, indicating that selecting a smaller number of highly relevant memories can outperform retrieving and reranking larger sets, which often introduces noise.A similar trend can be observed in LoCoMo.These findings suggest that reranking is more effective when it focuses on a smaller subset of highly relevant memories.</p>
<p>Effect of Number of Retrieved Memories T on Each Iteration.We first investigate performance across a range of values of T using iterative retrieval, with a maximum T of 75 and N of 4 due to computational cost constraints while keeping K fixed at 100.As illustrated in Figure 6, increasing the number of retrieved memories per iteration generally improves performance across datasets, though the gains diminish beyond a certain threshold.For instance, in HotPotQA, atomic facts achieve an F1 score of approximately 81% at T = 50, with minimal additional gains from increasing T further.Similarly, in LoCoMo, chunks improve up to T = 50 before declining at T = 75.</p>
<p>These results indicate that while increasing T can enhance query refinement and performance, excessively large T values may introduce noise, ultimately reducing effectiveness.</p>
<p>Effect of Number of Iteration Turns N .Next, we examine the impact of iteration turns N , with the number of retrieved memories T fixed at 50.As depicted in Figure 6, the results reveal that increasing N initially enhances performance significantly, but the rate of improvement diminishes as N continues to rise.For HotPotQA, both triples and summars show notable gains from N = 1 to N = 3, after which the improvements become marginal.In the case of LoCoMo, triples, atomic facts, and summaries reach a peak at N = 3 and stop increasing afterwards.These results suggest that an intermediate number of iteration turns, typically between 2 and 3, achieves optimal performance improvements, striking a balance between maximizing effectiveness and minimizing resource expenditure.</p>
<p>Impact of Noise Documents</p>
<p>Finding 4: Mix memory excels in noise resilience.</p>
<p>Finally, we evaluate the robustness of various memory structures under increasing levels of noise using single-step retrieval with a fixed K = 100.As depicted in Figure 8, the performance of all memory structures declines as the number of noise documents increases.For HotPotQA, the mix memory consistently achieves the highest F1 scores, demon- strating superior resilience to noise.While triples and summaries exhibit similar rates of decline, the chunks experience a slower decline, maintaining a competitive F1 score when increasing the number of noise documents.A similar pattern is shown in LoCoMo.These findings reveal the robustness of the mixed memory structure, which consistently outperforms others across datasets, making it the most effective choice in noisy environments.</p>
<p>Conclusion &amp; Future Work</p>
<p>In this paper, we present the first comprehensive study on the impact of structural memories and memory retrieval methods in LLM-based agents, aiming to identify the most suitable memory structures for specific tasks and explore how retrieval methods influence performance.This study yielded several key findings: (1) Mixed memories consistently deliver balanced performance.Chunks and summaries excel in tasks involving lengthy contexts, such as reading comprehension and dialogue understanding, while knowledge triples and atomic facts are effective for relational reasoning and precision in multi-hop and single-hop QA.</p>
<p>(2) Mixed memories also demonstrate remarkable resilience to noise.(3) Iterative retrieval stands out as the most effective memory retrieval method, consistently outperforming in tasks such as multi-hop QA, dialogue understanding and reading comprehension.While these findings provide valuable insights, further research is needed to explore how memory impacts areas such as self-evolution and social simulation, highlighting the importance of investigating how structural memories and retrieval techniques support these applications.</p>
<p>Limitations</p>
<p>We identify the following limitations in our work:</p>
<p>(1) Our experiments are limited to tasks such as multi-hop QA, single-hop QA, dialogue understanding, and reading comprehension, which restricts the applicability of our findings to other complex domains like self-evolving agents or social simulation.Investigating the role of memory structures and retrieval methods in these topics could provide broader insights;</p>
<p>(2) The evaluation of memory robustness primarily considers random document noise, leaving other challenging noise types, such as irrelevant or contradictory information, unexplored.Investigating these addition noise in future studies could offer a more comprehensive understanding of memory resilience; (3) Due to computational constraints, we limit the hyperparameter ranges (e.g., K, R, T , N ) in memory retrieval methods.Expanding these ranges in future research could yield deeper insights into their impact on performance.</p>
<p>Figure 1 :
1
Figure 1: The framework of LLM-based agents, where we focus on the study of memory modules, including memory structures and retrieval methods.</p>
<p>Figure 2 :
2
Figure 2: Overview of the memory module workflow in LLM-based agents.Raw information is organized into structural memories, which are processed through retrieval methods to identify the most relevant memories for the query, enabling the generation of precise and contextually enriched responses.</p>
<p>Figure 3 :
3
Figure 3: Performance across six datasets using two answer generation approaches: Memory-Only and Memory-Doc.</p>
<p>Figure 4 :
4
Figure 4: Performance of different numbers of retrieved memories K on HotPotQA and LoCoMo using singlestep retrieval.</p>
<p>Figure 5 :Figure 6 :
56
Figure 5: Performance of different numbers of reranked memories R on HotPotQA and LoCoMo in reranking.</p>
<p>Figure 7 :
7
Figure 7: Performance of different numbers of retrieved memories N in each interaction on HotPotQA and Lo-CoMo using iterative retrieval.</p>
<p>Figure 8 :
8
Figure 8: Performance across varying numbers of noise documents using single-step retrieval.</p>
<p>Atomic Facts Fact: The</p>
<p>massive coordinate online donation drive was conducted on behalf of presidential candidate Ron Paul.
The term Moneybomb wascoined by Trevor Lyman todescribe a massive onlinedonation drive on behalf ofa presidential candidatethat was the first chairmanof what PAC?Structural MemoryChunksTriplesMoneybomb (alternatively money bomb, money-bomb, or fundraising bomb) is aMoneybombneologism coined in 2007 to describe aCoined TermSupportedgrassroots fundraising effort over a brieffixed time period, ...Trevor LymanRon PaulSummariesSummary: Trevor Lyman coined the term"moneybomb" to refer to a massive,coordinated online donation drive organizedin support of presidential candidate RonPaul, ...employsatomic facts to compress chunks into finer details,providing agents with highly granular information</p>
<p>User Structural Memory Top-K Retriever Single-step Retrieval Structural Memory Top-K Retriever Top-R Rerank Rerank Retrieval Structural Memory Top-T Retriever Iterative Retrieval Enhanced Query LLM N Turns Memory Retrieval Raw Information Moneybomb</p>
<p>(alternatively money bomb, money-bomb, or fundraising bomb) is a neologism coined in 2007 to describe a grassroots fundraising effort over a brief fixed time period, usually to support a candidate for election by dramatically increasing, ...</p>
<p>LLMCitizens for a Sound EconomyResponse</p>
<p>Table 1 :
1
Overall Performance (%) of various memory structures utilizing different retrieval methods across six datasets.The best performance is marked in boldface, while the second-best performance is underlined.
Memory StructureHotPotQA2WikiMultihopQAMuSiQueNarrativeQALoCoMoQuALITYEMF1EMF1EMF1EMF1EMF1ACCFull Content55.50 75.77 44.0054.3336.00 51.60 7.00 24.99 13.61 41.8281.50Single-step RetrievalChunks61.50 76.93 43.5059.1735.50 54.45 13.50 29.78 9.95 40.6376.00Triples59.50 74.09 44.5060.8231.00 50.13 11.50 22.04 8.42 41.0861.50Atomic Facts62.50 77.22 39.5058.6330.50 51.31 13.50 27.49 9.42 42.9271.50Summaries57.00 74.81 42.0057.2134.00 52.83 16.50 32.93 10.99 44.9476.00Mixed60.00 77.10 48.5065.2533.00 51.65 14.50 29.86 10.47 44.7378.00RerankingChunks63.00 77.35 45.0061.3137.00 55.32 16.00 31.63 9.95 43.4778.50Triples61.00 76.75 43.5055.4326.50 42.05 10.00 20.65 8.83 41.8260.00Atomic Facts63.00 78.31 40.5059.3128.50 49.95 14.00 28.19 8.90 44.2767.50Summaries61.00 77.80 45.0061.1835.50 54.59 16.00 32.26 12.04 44.8375.00Mixed65.00 78.58 45.5061.7734.00 52.45 11.98 28.02 9.42 44.5177.50Iterative RetrievalChunks63.00 79.10 46.5062.1337.00 56.78 14.50 30.88 10.47 45.1477.00Triples64.00 78.78 47.5062.0638.00 55.93 10.50 21.67 9.47 41.4160.50Atomic Facts65.50 81.29 44.0063.8934.50 57.55 14.50 28.28 9.95 43.6267.50Summaries60.50 78.11 46.5062.3533.50 53.12 17.00 31.79 12.04 43.9375.00Mixed67.00 82.11 51.0068.1539.00 61.38 12.50 28.36 7.85 45.2579.5072ChunksTriplesAtomic Facts Summaries
2 More details and statistics about the datasets are provided in Appendix A.3 https://platform.openai.com/docs/guides/embeddings/</p>
<p>A DatasetsWe conduct experiments on the following six datasets across four tasks, including multi-hop QA, single-hop QA, dialogue understanding and reading comprehension.The statistical information of datasets is provided in Table2.B PromptsIn this section, we present the prompts employed in our experiments, with detailed descriptions provided in the respective subsections.B.1 Prompt for Generating Knowledge TriplesThe prompt used for extracting knowledge triples from a document is illustrated in Figure9.B.2 Prompt for Generation SummariesThe prompt designed for generating document summaries is depicted in Figure10.B.3 Prompt for Generating Atomic FactsThe prompt for generating atomic facts from a document is shown in Figure11.B.4 Prompt for Reranking RetrievedMemories The prompt used for reranking retrieved memories is presented in Figure12.B.5 Prompt for Iterative Refining QueryThe prompt for iterative query refinement is provided in Figure13.You are a knowledge graph constructor tasked with extracting knowledge triples in the form of <head entity; relation; tail entity> from a document.Each triple denotes a specific relationship between entities or an event.The head entity and tail entity can be the provided title or phrases in the text.If multiple tail entities share the same relation with a head entity, aggregate these tail entities using commas.Format your output in the form of <head entity; relation; tail entity>.are a helpful assistant responsible for generating a comprehensive summary of the data provided below.Make sure to include information collected from all the documents.If the provided documents are contradictory, please resolve the contradictions and provide a single, coherent summary.Make sure it is written in third person, and include the names so we have the full context.Demonstrations{DOCUMENT}Summaries:Figure10: Prompt for generating summaries from a document.You are now an intelligent assistant tasked with meticulously extracting both key elements and atomic facts from a context.Key Elements:The essential nouns (e.g., characters, times, events, places, numbers), verbs (e.g., actions), and adjectives (e.g., states, feelings) that are pivotal to the text's narrative.Atomic Fact:The smallest, indivisible facts, presented as concise sentences.These include propositions, theories, existences, concepts, and implicit elements like logic, causality, event sequences, interpersonal relationships, timelines, etc.Requirements:1. Ensure that all the atomic facts contain full and complete information, reflecting the entire context of the sentence without omitting any key details. 2. Ensure that all identified key elements are reflected within the corresponding atomic facts.3. Whenever applicable, replace pronouns with their specific noun counterparts (e.g., change I, He, She to actual names).A list of documents is shown below.Each document has a number next to it along with a summary of the document.A question is also provided.Respond with the numbers of the documents you should consult to answer the question, in order of relevance, as well as the relevance score.The relevance score is a number from 1-10 based on how relevant you think the document is to the question.Respond with the numbers of <strong>all</strong> the documents along with a relevance score.Follow the examples to answer the input question by reasoning step-by-step.Output both reasoning steps and the answer.DemonstrationsDemonstrations:##### Question: Nobody Loves You was written by John Lennon and released on what album that was issued by Apple Records, and was written, recorded, and released during his 18 month separation from Yoko Ono? Thought: The album issued by Apple Records, and written, recorded, and released during John Lennon's 18 month separation from Yoko Ono is Walls and Bridges.Nobody Loves You was written by John Lennon on Walls and Bridges album.So the answer is: Walls and Bridges.Question: What is known as the Kingdom and has National Route 13 stretching towards its border?Thought: Cambodia is officially known as the Kingdom of Cambodia.National Route 13 streches towards border to Cambodia.So the answer is: Cambodia.Question: Jeremy Theobald and Christopher Nolan share what profession?Thought: Jeremy Theobald is an actor and producer.Christopher Nolan is a director, producer, and screenwriter.Therefore, they both share the profession of being a producer.So the answer is: producer.
The architecture of cognition. John R Anderson, 2013Psychology Press</p>
<p>Arigraph: Learning knowledge graph world models with episodic memory for llm agents. Petr Anokhin, Nikita Semenov, Artyom Sorokin, Dmitry Evseev, Mikhail Burtsev, Evgeny Burnaev, arXiv:2407.043632024arXiv preprint</p>
<p>Longbench: A bilingual, multitask benchmark for long context understanding. Yushi Bai, Xin Lv, Jiajie Zhang, Hongchang Lyu, Jiankai Tang, Zhidian Huang, Zhengxiao Du, Xiao Liu, Aohan Zeng, Lei Hou, arXiv:2308.145082023arXiv preprint</p>
<p>. Harrison Chase, 2022LangChain</p>
<p>Jiangjie Chen, Xintao Wang, Rui Xu, Siyu Yuan, Yikai Zhang, Wei Shi, Jian Xie, Shuang Li, Ruihan Yang, Tinghui Zhu, arXiv:2404.18231From persona to personalization: A survey on role-playing language agents. 2024arXiv preprint</p>
<p>Don't forget to connect! improving rag with graph-based reranking. Jialin Dong, Bahare Fatemi, Bryan Perozzi, Lin F Yang, Anton Tsitsulin, arXiv:2405.184142024arXiv preprint</p>
<p>TRACE the evidence: Constructing knowledge-grounded reasoning chains for retrievalaugmented generation. Jinyuan Fang, Zaiqiao Meng, Craig Macdonald, Findings of the Association for Computational Linguistics: EMNLP 2024. Miami, Florida, USAAssociation for Computational Linguistics2024</p>
<p>Precise zero-shot dense retrieval without relevance labels. Luyu Gao, Xueguang Ma, Jimmy Lin, Jamie Callan, Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics. Long Papers. the 61st Annual Meeting of the Association for Computational Linguistics2023a1</p>
<p>Retrieval-augmented generation for large language models: A survey. Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi Dai, Jiawei Sun, Meng Wang, Haofen Wang, arXiv:2312.109972023barXiv preprint</p>
<p>Constructing a multi-hop qa dataset for comprehensive evaluation of reasoning steps. Xanh Ho, Anh-Khoa Duong Nguyen, Saku Sugawara, Akiko Aizawa, Proceedings of the 28th International Conference on Computational Linguistics. the 28th International Conference on Computational Linguistics2020</p>
<p>Metagpt: Meta programming for a multi-agent collaborative framework. Sirui Hong, Mingchen Zhuge, Jonathan Chen, Xiawu Zheng, Yuheng Cheng, Jinlin Wang, Ceyao Zhang, Zili Wang, Steven Ka, Shing Yau, Zijuan Lin, The Twelfth International Conference on Learning Representations. </p>
<p>Hiagent: Hierarchical working memory management for solving long-horizon agent tasks with large language model. Mengkang Hu, Tianxing Chen, Qiguang Chen, Yao Mu, Wenqi Shao, Ping Luo, arXiv:2408.095592024arXiv preprint</p>
<p>Dynamic and textual graph generation via largescale llm-based agent simulation. Jiarui Ji, Runlin Lei, Jialing Bi, Zhewei Wei, Yankai Lin, Xuchen Pan, Yaliang Li, Bolin Ding, arXiv:2410.098242024arXiv preprint</p>
<p>The narrativeqa reading comprehension challenge. Tomáš Kočiskỳ, Jonathan Schwarz, Phil Blunsom, Chris Dyer, Karl Moritz Hermann, Gábor Melis, Edward Grefenstette, Transactions of the Association for Computational Linguistics. 62018</p>
<p>A human-inspired reading agent with gist memory of very long contexts. Kuang-Huei Lee, Xinyun Chen, Hiroki Furuta, John F Canny, Ian Fischer, Forty-first International Conference on Machine Learning, ICML 2024. Vienna, Austria2024. July 21-27, 2024OpenReview.net</p>
<p>Retrieval-augmented generation for knowledge-intensive nlp tasks. Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-Tau Yih, Tim Rocktäschel, Advances in Neural Information Processing Systems. 202033</p>
<p>Shilong Li, Yancheng He, Hangyu Guo, Xingyuan Bu, Ge Bai, Jie Liu, Jiaheng Liu, Xingwei Qu, Yangguang Li, Wanli Ouyang, arXiv:2406.14550Graphreader: Building graph-based agent to enhance long-context abilities of large language models. 2024aarXiv preprint</p>
<p>Corpuslm: Towards a unified language model on corpus for knowledge-intensive tasks. Xiaoxi Li, Zhicheng Dou, Yujia Zhou, Fangchao Liu, Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval. the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval2024b</p>
<p>Yuan Li, Yixuan Zhang, Lichao Sun, arXiv:2310.06500Metaagents: Simulating interactions of human behaviors for llm-based task-oriented coordination via collaborative generative agents. 2023arXiv preprint</p>
<p>Lei Liu, Xiaoyan Yang, Yue Shen, Binbin Hu, Zhiqiang Zhang, Jinjie Gu, Guannan Zhang, arXiv:2311.08719Thinkin-memory: Recalling and post-thinking enable llms with long-term memory. 2023arXiv preprint</p>
<p>Evaluating very long-term conversational memory of LLM agents. Adyasha Maharana, Dong-Ho Lee, Sergey Tulyakov, Mohit Bansal, Francesco Barbieri, Yuwei Fang, Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics. Long Papers. the 62nd Annual Meeting of the Association for Computational LinguisticsBangkok, ThailandAssociation for Computational Linguistics20241</p>
<p>Shervin Minaee, Tomas Mikolov, Narjes Nikzad, Meysam Chenaghlu, Richard Socher, Xavier Amatriain, Jianfeng Gao, arXiv:2402.06196Large language models: A survey. 2024arXiv preprint</p>
<p>Extending cognitive architecture with episodic memory. M Andrew, John E Nuxoll, Laird, AAAI. 2007</p>
<p>Charles Packer, Sarah Wooders, Kevin Lin, Vivian Fang, G Shishir, Ion Patil, Joseph E Stoica, Gonzalez, arXiv:2310.08560Memgpt: Towards llms as operating systems. 2023arXiv preprint</p>
<p>Quality: Question answering with long input texts, yes!. Richard Yuanzhe Pang, Alicia Parrish, Nitish Joshi, Nikita Nangia, Jason Phang, Angelica Chen, Vishakh Padmakumar, Johnny Ma, Jana Thompson, He He, Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies2022</p>
<p>Generative agents: Interactive simulacra of human behavior. Sung Joon, Park, O' Joseph, Carrie Jun Brien, Meredith Ringel Cai, Percy Morris, Michael S Liang, Bernstein, Proceedings of the 36th annual acm symposium on user interface software and technology. the 36th annual acm symposium on user interface software and technology2023</p>
<p>Chatdev: Communicative agents for software development. Chen Qian, Wei Liu, Hongzhang Liu, Nuo Chen, Yufan Dang, Jiahao Li, Cheng Yang, Weize Chen, Yusheng Su, Xin Cong, Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics. Long Papers. the 62nd Annual Meeting of the Association for Computational Linguistics20241</p>
<p>Autoact: Automatic agent learning from scratch via self-planning. Shuofei Qiao, Ningyu Zhang, Runnan Fang, Yujie Luo, Wangchunshu Zhou, Yuchen Eleanor Jiang, Chengfei Lv, Huajun Chen, arXiv:2401.052682024arXiv preprint</p>
<p>Yujia Qin, Shihao Liang, Yining Ye, Kunlun Zhu, Lan Yan, Yaxi Lu, Yankai Lin, Xin Cong, Xiangru Tang, Bill Qian, arXiv:2307.16789Toolllm: Facilitating large language models to master 16000+ real-world apis. 2023arXiv preprint</p>
<p>In-context retrieval-augmented language models. Ori Ram, Yoav Levine, Itay Dalmedigos, Dor Muhlgay, Amnon Shashua, Kevin Leyton-Brown, Yoav Shoham, Transactions of the Association for Computational Linguistics. 112023</p>
<p>The probabilistic relevance framework: Bm25 and beyond. Stephen Robertson, Hugo Zaragoza, Foundations and Trends® in Information Retrieval. 342009</p>
<p>Learning to retrieve prompts for in-context learning. Ohad Rubin, Jonathan Herzig, Jonathan Berant, Proceedings of the 2022 Conference of the North American Chapter. the 2022 Conference of the North American ChapterHuman Language Technologies2022</p>
<p>Generate-then-ground in retrieval-augmented generation for multi-hop question answering. Zhengliang Shi, Shuo Zhang, Weiwei Sun, Shen Gao, Pengjie Ren, Zhumin Chen, Zhaochun Ren, Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics. the 62nd Annual Meeting of the Association for Computational LinguisticsLong Papers20241</p>
<p>Reflexion: Language agents with verbal reinforcement learning. Noah Shinn, Federico Cassano, Ashwin Gopinath, Karthik Narasimhan, Shunyu Yao, Advances in Neural Information Processing Systems. 202436</p>
<p>Human problem solving: The state of the theory in 1970. A Herbert, Allen Simon, Newell, American psychologist. 2621451971</p>
<p>Musique: Multihop questions via single-hop question composition. Harsh Trivedi, Niranjan Balasubramanian, Tushar Khot, Ashish Sabharwal, Transactions of the Association for Computational Linguistics. 102022</p>
<p>Voyager: An open-ended embodied agent with large language models. Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke Zhu, Linxi Fan, Anima Anandkumar, arXiv:2305.162912023arXiv preprint</p>
<p>A survey on large language model based autonomous agents. Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang, Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, Frontiers of Computer Science. 6182024a</p>
<p>Incharacter: Evaluating personality fidelity in role-playing agents through psychological interviews. Xintao Wang, Yunze Xiao, Jen-Tse Huang, Siyu Yuan, Rui Xu, Haoran Guo, Quan Tu, Yaying Fei, Ziang Leng, Wei Wang, Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics. Long Papers. the 62nd Annual Meeting of the Association for Computational Linguistics2024b1</p>
<p>Rcagent: Cloud root cause analysis by autonomous agents with tool-augmented large language models. Zefan Wang, Zichuan Liu, Yingying Zhang, Aoxiao Zhong, Jihong Wang, Fengbin Yin, Lunting Fan, Lingfei Wu, Qingsong Wen, Proceedings of the 33rd ACM International Conference on Information and Knowledge Management. the 33rd ACM International Conference on Information and Knowledge Management2024c</p>
<p>Zhiheng Xi, Wenxiang Chen, Xin Guo, Wei He, Yiwen Ding, Boyang Hong, Ming Zhang, Junzhe Wang, Senjie Jin, Enyu Zhou, arXiv:2309.07864The rise and potential of large language model based agents: A survey. 2023arXiv preprint</p>
<p>Yao Xu, Shizhu He, Jiabei Chen, Zihao Wang, Yangqiu Song, Hanghang Tong, Guang Liu, Kang Liu, Jun Zhao, arXiv:2404.14741Generate-on-graph: Treat llm as both agent and kg in incomplete knowledge graph question answering. 2024arXiv preprint</p>
<p>Hotpotqa: A dataset for diverse, explainable multi-hop question answering. Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William Cohen, Ruslan Salakhutdinov, Christopher D Manning, Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing. the 2018 Conference on Empirical Methods in Natural Language Processing2018</p>
<p>Tree of thoughts: Deliberate problem solving with large language models. Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Tom Griffiths, Yuan Cao, Karthik Narasimhan, Advances in Neural Information Processing Systems. 202436</p>
<p>Wenqi Zhang, Ke Tang, Hai Wu, Mengna Wang, Yongliang Shen, Guiyang Hou, Zeqi Tan, Peng Li, Yueting Zhuang, Weiming Lu, arXiv:2402.17574Agentpro: Learning to evolve via policy-level reflection and optimization. 2024aarXiv preprint</p>
<p>Zeyu Zhang, Xiaohe Bo, Chen Ma, Rui Li, Xu Chen, Quanyu Dai, Jieming Zhu, Zhenhua Dong, Ji-Rong Wen, arXiv:2404.13501A survey on the memory mechanism of large language model based agents. 2024barXiv preprint</p>
<p>Memorybank: Enhancing large language models with long-term memory. Wanjun Zhong, Lianghong Guo, Qiqi Gao, He Ye, Yanlin Wang, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202438</p>            </div>
        </div>

    </div>
</body>
</html>