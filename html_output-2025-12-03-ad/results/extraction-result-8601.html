<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-8601 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-8601</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-8601</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-154.html">extraction-schema-154</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being evaluated on strict logical reasoning tasks, including details about the models, the logical reasoning tasks or benchmarks, the methods or approaches used to improve logical reasoning, the performance or results, comparisons to baselines or ablations, and any reported limitations or failure cases.</div>
                <p><strong>Paper ID:</strong> paper-272880951</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2409.16461v1.pdf" target="_blank">Strategies for Improving NL-to-FOL Translation with LLMs: Data Generation, Incremental Fine-Tuning, and Verification</a></p>
                <p><strong>Paper Abstract:</strong> Logical reasoning is a fundamental task in natural language processing that presents significant challenges to Large Language Models (LLMs). The inherent characteristics of logical reasoning makes it well-suited for symbolic representations such as first-order logic (FOL). Research in symbolic logical reasoning explored FOL generation using state-of-the-art LLMs (i.e., GPT-4) to produce FOL translations of natural language (NL) statements, but errors in translation are usually not the focus. We address this by categorizing the translation errors in FOL statements generated by LLMs. To make progress towards improving the quality of FOL translations for smaller language models such as LLaMA-2 13B and Mistral 7B, we create ProofFOL, a high-quality FOL-annotated subset of ProofWriter dataset using GPT-4o. The models fine-tuned on this silver standard data achieve a significant gain in performance when compared to larger language models such as LLaMA-2 70B. In addition to improving the model using large data, we also tackle the issue of data scarcity and introduce an incremental framework encompassing of data augmentation and verification steps. In the augmentation process, a single pair of (premises, conclusion) is split into multiple new instances based on the predicates and FOLs. This data is used for fine-tuning, and the inference on this model generates FOLs with fewer errors over the model trained on the original data. Our investigation on the translation errors leads to generation of a perturbation dataset, which is used to train a verifier that corrects potential syntactic and semantic FOL translation errors. We demonstrate an efficient method for making the most of a limited existing human-annotated dataset. Our results show state-of-the-art performance for ProofWriter and ProntoQA datasets using ProofFOL on LLaMA-2 and Mistral models.</p>
                <p><strong>Cost:</strong> 0.017</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e8601.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e8601.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being evaluated on strict logical reasoning tasks, including details about the models, the logical reasoning tasks or benchmarks, the methods or approaches used to improve logical reasoning, the performance or results, comparisons to baselines or ablations, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLaMA-2-13B (SFT on PROOFFOL)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLaMA-2 13B fine-tuned on PROOFFOL (LoRA, 8-bit inference)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A 13-billion-parameter LLaMA-2 decoder model that the paper fine-tunes (LoRA) on a large silver-standard NL→FOL corpus (PROOFFOL) and on augmented/incremental variants to improve strict deductive NL-to-FOL translation and downstream deductive reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLaMA-2 13B</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Decoder-only transformer family (LLaMA-2) used in this work; fine-tuned with LoRA adapters, 8-bit quantized at inference, trained with supervised fine-tuning on PROOFFOL and incremental augmented variants.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>13B</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_name</strong></td>
                            <td>ProofWriter, FOLIO, ProntoQA (deductive reasoning / NL-to-FOL translation)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_description</strong></td>
                            <td>Multi-premise deductive reasoning: translate multiple natural-language premises and a conclusion into first-order logic (Prover9 format) and check validity of the conclusion (True/False/Unknown) via theorem prover; tasks include ProofWriter (synthetic depth-based proofs), FOLIO (human-annotated FOL sentences, semantically complex), and ProntoQA (test-only variant related to ProofWriter).</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_approach</strong></td>
                            <td>Supervised fine-tuning on PROOFFOL (GPT-4o-generated + Prover9 filtered silver data), incremental data augmentation (split outputs into predicate + per-statement FOL generation), incremental inference, and optional online/offline T5 verifiers for predicates and FOL.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>ProofWriter (FOL pipeline): 86% accuracy reported for LLaMA-2 13B after SFT on PROOFFOL; FOLIO: improved from ~24% (ICL) to ~34% after fine-tuning (on-par with LLaMA-2 70B); incremental SFT on small-data settings further improves FOLIO (e.g., incremental + verifier offline achieves ~37% in 1k-augmented experiments).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Before fine-tuning, LLaMA-2 13B lagged behind larger models (LLaMA-2 70B) in few-shot ICL; after SFT on PROOFFOL and augmentation, LLaMA-2 13B matches or exceeds the larger LLaMA-2 70B baseline on several tasks (e.g., FOLIO parity, strong gains on ProofWriter). Ablations show incremental (predicate-first then per-statement FOL) instructions and verifier use improve results vs vanilla SFT.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Struggles remain with syntactic and semantic NL→FOL errors (missing quantifiers, parenthesis, incorrect quantifier choice, arity/predicate mismatch); observed negative overfitting on ProntoQA when increasing training data from 5k→10k for LLaMA-2 (authors attribute to memorization effects); online verifier mode can cause a 'domino effect' where a verifier correction error propagates to later steps and harms performance.</td>
                        </tr>
                        <tr>
                            <td><strong>insights_or_conclusions</strong></td>
                            <td>High-quality and task-aligned NL→FOL data is crucial: smaller models (13B) can surpass much larger models after targeted fine-tuning. Incremental training (splitting outputs into predicate and per-statement FOL subtasks) and verification/correction (T5 verifiers) both materially improve strict logical reasoning performance by reducing syntactic and semantic translation errors.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Strategies for Improving NL-to-FOL Translation with LLMs: Data Generation, Incremental Fine-Tuning, and Verification', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8601.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e8601.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being evaluated on strict logical reasoning tasks, including details about the models, the logical reasoning tasks or benchmarks, the methods or approaches used to improve logical reasoning, the performance or results, comparisons to baselines or ablations, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Mistral-7B (SFT on PROOFFOL)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Mistral 7B fine-tuned on PROOFFOL (LoRA, 8-bit inference)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A 7-billion-parameter dense decoder model (Mistral) fine-tuned on PROOFFOL; used as a computationally efficient model for NL→FOL generation and deductive reasoning, attaining state-of-the-art FOL generation performance on some benchmarks in this work.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Mistral 7B</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Decoder-only transformer (Mistral family); fine-tuned with LoRA on PROOFFOL; inference done in 8-bit with LoRA adapter applied.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_name</strong></td>
                            <td>ProofWriter, ProntoQA, FOLIO (deductive NL→FOL reasoning)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_description</strong></td>
                            <td>Same multi-premise deductive reasoning benchmarks as above: translate NL premises+conclusion to Prover9 FOL and verify conclusion via theorem prover.</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_approach</strong></td>
                            <td>Supervised fine-tuning on PROOFFOL and augmented/incremental training; evaluation both with direct (Standard) generation and with FOL translation + Prover9 verification; combined with T5 verifiers as optional correction.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Reported as state-of-the-art in FOL generation for ProofWriter in this paper: Mistral 7B fine-tuned on PROOFFOL produced zero syntax errors after fine-tuning (per authors) and outperformed baselines on ProntoQA. Exact numeric FOL accuracy claims: Mistral fine-tuned models achieve among the highest FOL-based accuracy on ProofWriter (text reports SOTA behavior); in few-shot settings Mistral/Mixtral generally showed higher standard accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Outperforms its larger-family baseline (Mixtral 8×7B) on some few-shot and SFT settings and outperforms several prior baselines on ProntoQA and ProofWriter after fine-tuning; achieves lower syntax error counts (zero syntax errors reported for ProofWriter after fine-tuning).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>As with other small models, semantic errors (wrong quantifiers, arity mismatches, predicate mismatch) can persist even if syntactic errors are reduced; performance varies by dataset and overfitting patterns differ from LLaMA family (authors observed Mistral did not show the same overfitting on larger training sets as LLaMA-2 in their experiments).</td>
                        </tr>
                        <tr>
                            <td><strong>insights_or_conclusions</strong></td>
                            <td>Smaller models (7B) can achieve state-of-the-art strict FOL generation on deductive benchmarks when fine-tuned on high-quality task-aligned NL→FOL data; aggressive fine-tuning and verification can eliminate syntactic errors and substantially improve practical theorem-prover-driven reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Strategies for Improving NL-to-FOL Translation with LLMs: Data Generation, Incremental Fine-Tuning, and Verification', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8601.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e8601.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being evaluated on strict logical reasoning tasks, including details about the models, the logical reasoning tasks or benchmarks, the methods or approaches used to improve logical reasoning, the performance or results, comparisons to baselines or ablations, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLaMA-2-70B (ICL baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLaMA-2 70B (few-shot in-context baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A 70-billion-parameter LLaMA-2 model used as a strong few-shot in-context learning baseline; serves as a comparison point to show the value of fine-tuning smaller models for NL→FOL translation and deductive reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLaMA-2 70B</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Large decoder-only transformer model (70B parameters) from the LLaMA-2 family; used in the paper primarily as an in-context learning (ICL) baseline for Standard and FOL generation.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>70B</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_name</strong></td>
                            <td>ProofWriter, FOLIO, ProntoQA (deductive reasoning benchmarks used as baselines)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_description</strong></td>
                            <td>Same multi-premise deductive reasoning tasks: translate NL to FOL and verify via Prover9 or answer directly in NL (Standard).</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_approach</strong></td>
                            <td>In-context few-shot prompting (n-shot ICL) for Standard and FOL generation; no supervised fine-tuning performed in this paper for the 70B model (used as baseline).</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Used as a strong ICL baseline; specific reported baseline: LLaMA-2 70B ICL accuracy on FOLIO is reported as 34.97% (paper compares incremental verifier to this number). On some datasets and tasks LLaMA-2 70B outperforms smaller models in few-shot FOL generation before fine-tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Smaller models (13B, 7B) fine-tuned on PROOFFOL can match or exceed LLaMA-2 70B ICL performance on the evaluated deductive benchmarks (e.g., LLaMA-2 13B SFT reached parity on FOLIO and exceeded 70B baseline in some settings).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Even large models like LLaMA-2 70B make systematic NL→FOL translation errors (syntax/semantic) in multi-statement deductive settings; the paper cites prior work noting GPT-4 also makes systematic translation mistakes, implying large size alone does not cure NL→FOL failure modes.</td>
                        </tr>
                        <tr>
                            <td><strong>insights_or_conclusions</strong></td>
                            <td>Large-size ICL is insufficient to guarantee correct NL→FOL translations across multi-statement deductive problems; targeted fine-tuning and verification are practical ways to close the gap using much smaller models.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Strategies for Improving NL-to-FOL Translation with LLMs: Data Generation, Incremental Fine-Tuning, and Verification', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8601.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e8601.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being evaluated on strict logical reasoning tasks, including details about the models, the logical reasoning tasks or benchmarks, the methods or approaches used to improve logical reasoning, the performance or results, comparisons to baselines or ablations, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Mixtral (8x7B)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Mixtral 8×7B (ensemble / mixture baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An ensemble/mixture model composed of eight 7B submodels (Mixtral) used as another baseline family for comparison; evaluated in few-shot and SFT baselines for the deductive tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Mixtral 8×7B</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Mixture/ensemble of eight 7B models (Mixtral family) used as a strong baseline in few-shot ICL comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>8×7B</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_name</strong></td>
                            <td>ProofWriter, FOLIO, ProntoQA (deductive reasoning benchmarks)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_description</strong></td>
                            <td>Same multi-premise deductive reasoning benchmarks requiring NL→FOL translation and theorem-prover verification or direct NL Standard reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_approach</strong></td>
                            <td>Few-shot in-context learning (ICL) and SFT baselines reported; used for comparison with fine-tuned smaller models.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>On FOLIO few-shot ICL, Mixtral recorded the highest reported few-shot accuracy in the paper (about 42% per text); performance varies across datasets and modes.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Serves as a competitive few-shot baseline; smaller models fine-tuned on PROOFFOL narrow the gap or outperform Mixtral on some SFT/FOL tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Same kinds of NL→FOL translation semantic errors remain in few-shot settings; SFT on relevant data remains necessary for robust multi-statement translation.</td>
                        </tr>
                        <tr>
                            <td><strong>insights_or_conclusions</strong></td>
                            <td>Mixture/ensemble few-shot performance can be strong, but targeted SFT on task-aligned FOL data still yields superior FOL generation quality for downstream deduction.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Strategies for Improving NL-to-FOL Translation with LLMs: Data Generation, Incremental Fine-Tuning, and Verification', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8601.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e8601.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being evaluated on strict logical reasoning tasks, including details about the models, the logical reasoning tasks or benchmarks, the methods or approaches used to improve logical reasoning, the performance or results, comparisons to baselines or ablations, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-4o (data generation)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-4o (used to generate silver-standard PROOFFOL FOL annotations)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>OpenAI GPT-4o was used to generate NL→FOL translations for ProofWriter training records; outputs were filtered/validated by Prover9 and only matching examples were retained to make the PROOFFOL silver-standard dataset.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4o</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Large instruction-following chat model (GPT-4 family variant) used in this work to produce NL-to-Prover9 FOL translations for ProofWriter training records; outputs post-processed via pattern matching and Prover9 verification.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_name</strong></td>
                            <td>Data generation for ProofWriter → FOL (creating PROOFFOL)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_description</strong></td>
                            <td>Generate first-order logic (Prover9 format) translations of multi-premise ProofWriter records to serve as silver-standard training data for SFT of smaller models.</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_approach</strong></td>
                            <td>Prompt GPT-4o with adapted Prover9 FOL format examples (2-shot), parse/clean generations, run Prover9 parser + theorem-prover check to filter outputs, keep examples where Prover9 result (True/False/Unknown) matches ground truth label; retained ~70% of initial generated data.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Data-generation yield: from 15k GPT-4o outputs sampled, after parsing/filtering 10,424 high-quality PROOFFOL examples were retained (the paper reports a final PROOFFOL size of 10,424).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>PROOFFOL (GPT-4o-generated + Prover9-filtered) provided much larger NL→FOL training data than existing human-annotated sets (e.g., FOLIO ~1k), enabling fine-tuned small models to outperform larger models without such SFT.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>GPT-generated translations require careful parsing and solver-based filtering; GPT-4o outputs often need format fixes (extra explanation text, numbering, etc.) and ~30% of initial generations were discarded. The generated FOLs can still produce semantic errors that pass Prover9 (i.e., syntactically valid but semantically wrong).</td>
                        </tr>
                        <tr>
                            <td><strong>insights_or_conclusions</strong></td>
                            <td>High-quality silver data produced by a strong LLM plus automated theorem-prover filtering can be an effective way to scale NL→FOL supervision and enable smaller models to achieve or exceed larger-model baselines on strict logical reasoning tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Strategies for Improving NL-to-FOL Translation with LLMs: Data Generation, Incremental Fine-Tuning, and Verification', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8601.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e8601.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being evaluated on strict logical reasoning tasks, including details about the models, the logical reasoning tasks or benchmarks, the methods or approaches used to improve logical reasoning, the performance or results, comparisons to baselines or ablations, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>T5-Large Verifiers</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>T5-Large predicate and FOL verifier models (trained on perturbed data)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Separate T5-Large models fine-tuned as verifiers/correctors: one for predicates and one for FOL statements; trained on controlled perturbations (simulated syntactic & semantic NL→FOL errors) plus real SFT model errors to detect and correct translations at inference-time.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>T5-Large (verifier)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Encoder-decoder transformer (T5-Large) fine-tuned on a perturbation dataset crafted from FOLIO and PROOFFOL (synthetic perturbations: omitted quantifiers, moved quantifiers, bracket omissions, predicate variable omissions/additions, operator swaps, etc.). Trained 10 epochs with AdamW, lr 5e-5.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_name</strong></td>
                            <td>Predicate / FOL verification and correction for NL→FOL translation</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_description</strong></td>
                            <td>Given (NL statement + predicted predicates) or (NL statement + predicted FOL), the verifier outputs 'correct' or a corrected predicate/FOL string; used online (during incremental decoding) or offline (post-processing) to reduce syntactic/semantic errors that would harm theorem-prover-based deduction.</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_approach</strong></td>
                            <td>Fine-tune T5-Large on a mix of controlled perturbations (omitted quantifiers/brackets, wrong operators, predicate perturbations) and real errors from SFT inference runs; apply verifier during inference either online (per-step) or offline (post-generation).</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Authors report verifier use yields further improvements: e.g., verifier mechanism brought a further ~17% improvement on FOLIO; in 1k incremental experiments an Offline verifier setting achieved ~37% on FOLIO (exceeding LLaMA-2 70B ICL at 34.97%). Exact metric depends on dataset and SFT scale.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Verifier-corrected outputs outperform pure SFT/incremental SFT outputs; offline verifier often performs better than online due to reduced error propagation; using Prover9 alone for sampling/selection proved ineffective/time-consuming compared to trained verifiers.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Online (synchronous) verifier corrections can propagate errors forward (domino effect) and sometimes reduce accuracy; verifiers depend on representative perturbation data and need a higher proportion of perturbed instances during training to be robust.</td>
                        </tr>
                        <tr>
                            <td><strong>insights_or_conclusions</strong></td>
                            <td>A separate learned verifier/corrector trained on realistic syntactic and semantic perturbations is an effective and efficient mechanism to catch and fix NL→FOL translation errors at inference time, especially when scaling SFT data is constrained.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Strategies for Improving NL-to-FOL Translation with LLMs: Data Generation, Incremental Fine-Tuning, and Verification', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8601.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e8601.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being evaluated on strict logical reasoning tasks, including details about the models, the logical reasoning tasks or benchmarks, the methods or approaches used to improve logical reasoning, the performance or results, comparisons to baselines or ablations, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PROOFFOL (dataset)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>PROOFFOL: PROOFWriter → FOL silver-standard dataset (this work)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A silver-standard dataset of NL (premises, conclusion, label) paired with Prover9-formatted FOL translations, created by prompting GPT-4o and filtering/parsing via Prover9; designed to provide large-scale NL→FOL supervision for fine-tuning smaller LLMs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Dataset containing 10,424 records (premises, conclusion, deduction label, corresponding Prover9-formatted FOLs) sampled from ProofWriter depth-5 training set; generated with GPT-4o, parsed and filtered using Prover9, and post-processed with regex and grammar-rule fixes.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_name</strong></td>
                            <td>ProofWriter NL→FOL translation / deductive reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_description</strong></td>
                            <td>Provides ground-truth FOL translations aligned to ProofWriter multi-premise deductive examples for supervised fine-tuning of NL→FOL translation models and verification systems.</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_approach</strong></td>
                            <td>Generate FOL translations with GPT-4o (2-shot demonstrations), parse/clean output, run Prover9 to check syntax and semantics (matching True/False/Unknown labels), discard mismatches; produce final silver dataset used to SFT LLaMA and Mistral models.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Dataset creation: out of ~15k GPT-4o generations (depth-5 ProofWriter samples), 10,424 high-quality FOL records retained (~70% retention after parsing and Prover9 checks). Using PROOFFOL for SFT produced large gains: e.g., LLaMA-2 13B reached 86% on ProofWriter FOL pipeline after SFT with PROOFFOL.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>PROOFFOL is orders of magnitude larger than human-annotated FO-LIO/FOLIO (~1k) and MALLS synthetic 28k sentence-level data differs in scope; PROOFFOL enabled small-model SFT that outperforms larger-model few-shot baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Silver-standard nature: despite Prover9 filtering, GPT-generated FOLs can include subtle semantic errors that pass syntactic/parsing checks; generation required engineering to fix formatting issues; dataset covers ProofWriter style data and may not cover all linguistic/semantic phenomena found in other corpora.</td>
                        </tr>
                        <tr>
                            <td><strong>insights_or_conclusions</strong></td>
                            <td>A practical way to scale NL→FOL supervision is to combine a strong LLM for generation with an automated theorem prover for filtering; such silver data can substantially boost small-model performance on strict logical reasoning benchmarks.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Strategies for Improving NL-to-FOL Translation with LLMs: Data Generation, Incremental Fine-Tuning, and Verification', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Logic-LM: Empowering Large Language Models with Symbolic Solvers for Faithful Logical Reasoning <em>(Rating: 2)</em></li>
                <li>Natural language reasoning with first-order logic <em>(Rating: 2)</em></li>
                <li>ProofWriter: Generating and evaluating deductive reasoning <em>(Rating: 2)</em></li>
                <li>Harnessing the Power of Large Language Models for Natural Language to First-Order Logic Translation <em>(Rating: 2)</em></li>
                <li>Satlm: Satisfiability-aided language models using declarative prompting <em>(Rating: 1)</em></li>
                <li>LINC: A neurosymbolic approach for logical reasoning by combining language models with first-order logic provers <em>(Rating: 1)</em></li>
                <li>Certified deductive reasoning with language models <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-8601",
    "paper_id": "paper-272880951",
    "extraction_schema_id": "extraction-schema-154",
    "extracted_data": [
        {
            "name_short": "LLaMA-2-13B (SFT on PROOFFOL)",
            "name_full": "LLaMA-2 13B fine-tuned on PROOFFOL (LoRA, 8-bit inference)",
            "brief_description": "A 13-billion-parameter LLaMA-2 decoder model that the paper fine-tunes (LoRA) on a large silver-standard NL→FOL corpus (PROOFFOL) and on augmented/incremental variants to improve strict deductive NL-to-FOL translation and downstream deductive reasoning.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "LLaMA-2 13B",
            "model_description": "Decoder-only transformer family (LLaMA-2) used in this work; fine-tuned with LoRA adapters, 8-bit quantized at inference, trained with supervised fine-tuning on PROOFFOL and incremental augmented variants.",
            "model_size": "13B",
            "reasoning_task_name": "ProofWriter, FOLIO, ProntoQA (deductive reasoning / NL-to-FOL translation)",
            "reasoning_task_description": "Multi-premise deductive reasoning: translate multiple natural-language premises and a conclusion into first-order logic (Prover9 format) and check validity of the conclusion (True/False/Unknown) via theorem prover; tasks include ProofWriter (synthetic depth-based proofs), FOLIO (human-annotated FOL sentences, semantically complex), and ProntoQA (test-only variant related to ProofWriter).",
            "method_or_approach": "Supervised fine-tuning on PROOFFOL (GPT-4o-generated + Prover9 filtered silver data), incremental data augmentation (split outputs into predicate + per-statement FOL generation), incremental inference, and optional online/offline T5 verifiers for predicates and FOL.",
            "performance": "ProofWriter (FOL pipeline): 86% accuracy reported for LLaMA-2 13B after SFT on PROOFFOL; FOLIO: improved from ~24% (ICL) to ~34% after fine-tuning (on-par with LLaMA-2 70B); incremental SFT on small-data settings further improves FOLIO (e.g., incremental + verifier offline achieves ~37% in 1k-augmented experiments).",
            "baseline_comparison": "Before fine-tuning, LLaMA-2 13B lagged behind larger models (LLaMA-2 70B) in few-shot ICL; after SFT on PROOFFOL and augmentation, LLaMA-2 13B matches or exceeds the larger LLaMA-2 70B baseline on several tasks (e.g., FOLIO parity, strong gains on ProofWriter). Ablations show incremental (predicate-first then per-statement FOL) instructions and verifier use improve results vs vanilla SFT.",
            "limitations_or_failures": "Struggles remain with syntactic and semantic NL→FOL errors (missing quantifiers, parenthesis, incorrect quantifier choice, arity/predicate mismatch); observed negative overfitting on ProntoQA when increasing training data from 5k→10k for LLaMA-2 (authors attribute to memorization effects); online verifier mode can cause a 'domino effect' where a verifier correction error propagates to later steps and harms performance.",
            "insights_or_conclusions": "High-quality and task-aligned NL→FOL data is crucial: smaller models (13B) can surpass much larger models after targeted fine-tuning. Incremental training (splitting outputs into predicate and per-statement FOL subtasks) and verification/correction (T5 verifiers) both materially improve strict logical reasoning performance by reducing syntactic and semantic translation errors.",
            "uuid": "e8601.0",
            "source_info": {
                "paper_title": "Strategies for Improving NL-to-FOL Translation with LLMs: Data Generation, Incremental Fine-Tuning, and Verification",
                "publication_date_yy_mm": "2024-09"
            }
        },
        {
            "name_short": "Mistral-7B (SFT on PROOFFOL)",
            "name_full": "Mistral 7B fine-tuned on PROOFFOL (LoRA, 8-bit inference)",
            "brief_description": "A 7-billion-parameter dense decoder model (Mistral) fine-tuned on PROOFFOL; used as a computationally efficient model for NL→FOL generation and deductive reasoning, attaining state-of-the-art FOL generation performance on some benchmarks in this work.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "Mistral 7B",
            "model_description": "Decoder-only transformer (Mistral family); fine-tuned with LoRA on PROOFFOL; inference done in 8-bit with LoRA adapter applied.",
            "model_size": "7B",
            "reasoning_task_name": "ProofWriter, ProntoQA, FOLIO (deductive NL→FOL reasoning)",
            "reasoning_task_description": "Same multi-premise deductive reasoning benchmarks as above: translate NL premises+conclusion to Prover9 FOL and verify conclusion via theorem prover.",
            "method_or_approach": "Supervised fine-tuning on PROOFFOL and augmented/incremental training; evaluation both with direct (Standard) generation and with FOL translation + Prover9 verification; combined with T5 verifiers as optional correction.",
            "performance": "Reported as state-of-the-art in FOL generation for ProofWriter in this paper: Mistral 7B fine-tuned on PROOFFOL produced zero syntax errors after fine-tuning (per authors) and outperformed baselines on ProntoQA. Exact numeric FOL accuracy claims: Mistral fine-tuned models achieve among the highest FOL-based accuracy on ProofWriter (text reports SOTA behavior); in few-shot settings Mistral/Mixtral generally showed higher standard accuracy.",
            "baseline_comparison": "Outperforms its larger-family baseline (Mixtral 8×7B) on some few-shot and SFT settings and outperforms several prior baselines on ProntoQA and ProofWriter after fine-tuning; achieves lower syntax error counts (zero syntax errors reported for ProofWriter after fine-tuning).",
            "limitations_or_failures": "As with other small models, semantic errors (wrong quantifiers, arity mismatches, predicate mismatch) can persist even if syntactic errors are reduced; performance varies by dataset and overfitting patterns differ from LLaMA family (authors observed Mistral did not show the same overfitting on larger training sets as LLaMA-2 in their experiments).",
            "insights_or_conclusions": "Smaller models (7B) can achieve state-of-the-art strict FOL generation on deductive benchmarks when fine-tuned on high-quality task-aligned NL→FOL data; aggressive fine-tuning and verification can eliminate syntactic errors and substantially improve practical theorem-prover-driven reasoning.",
            "uuid": "e8601.1",
            "source_info": {
                "paper_title": "Strategies for Improving NL-to-FOL Translation with LLMs: Data Generation, Incremental Fine-Tuning, and Verification",
                "publication_date_yy_mm": "2024-09"
            }
        },
        {
            "name_short": "LLaMA-2-70B (ICL baseline)",
            "name_full": "LLaMA-2 70B (few-shot in-context baseline)",
            "brief_description": "A 70-billion-parameter LLaMA-2 model used as a strong few-shot in-context learning baseline; serves as a comparison point to show the value of fine-tuning smaller models for NL→FOL translation and deductive reasoning.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "LLaMA-2 70B",
            "model_description": "Large decoder-only transformer model (70B parameters) from the LLaMA-2 family; used in the paper primarily as an in-context learning (ICL) baseline for Standard and FOL generation.",
            "model_size": "70B",
            "reasoning_task_name": "ProofWriter, FOLIO, ProntoQA (deductive reasoning benchmarks used as baselines)",
            "reasoning_task_description": "Same multi-premise deductive reasoning tasks: translate NL to FOL and verify via Prover9 or answer directly in NL (Standard).",
            "method_or_approach": "In-context few-shot prompting (n-shot ICL) for Standard and FOL generation; no supervised fine-tuning performed in this paper for the 70B model (used as baseline).",
            "performance": "Used as a strong ICL baseline; specific reported baseline: LLaMA-2 70B ICL accuracy on FOLIO is reported as 34.97% (paper compares incremental verifier to this number). On some datasets and tasks LLaMA-2 70B outperforms smaller models in few-shot FOL generation before fine-tuning.",
            "baseline_comparison": "Smaller models (13B, 7B) fine-tuned on PROOFFOL can match or exceed LLaMA-2 70B ICL performance on the evaluated deductive benchmarks (e.g., LLaMA-2 13B SFT reached parity on FOLIO and exceeded 70B baseline in some settings).",
            "limitations_or_failures": "Even large models like LLaMA-2 70B make systematic NL→FOL translation errors (syntax/semantic) in multi-statement deductive settings; the paper cites prior work noting GPT-4 also makes systematic translation mistakes, implying large size alone does not cure NL→FOL failure modes.",
            "insights_or_conclusions": "Large-size ICL is insufficient to guarantee correct NL→FOL translations across multi-statement deductive problems; targeted fine-tuning and verification are practical ways to close the gap using much smaller models.",
            "uuid": "e8601.2",
            "source_info": {
                "paper_title": "Strategies for Improving NL-to-FOL Translation with LLMs: Data Generation, Incremental Fine-Tuning, and Verification",
                "publication_date_yy_mm": "2024-09"
            }
        },
        {
            "name_short": "Mixtral (8x7B)",
            "name_full": "Mixtral 8×7B (ensemble / mixture baseline)",
            "brief_description": "An ensemble/mixture model composed of eight 7B submodels (Mixtral) used as another baseline family for comparison; evaluated in few-shot and SFT baselines for the deductive tasks.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "Mixtral 8×7B",
            "model_description": "Mixture/ensemble of eight 7B models (Mixtral family) used as a strong baseline in few-shot ICL comparisons.",
            "model_size": "8×7B",
            "reasoning_task_name": "ProofWriter, FOLIO, ProntoQA (deductive reasoning benchmarks)",
            "reasoning_task_description": "Same multi-premise deductive reasoning benchmarks requiring NL→FOL translation and theorem-prover verification or direct NL Standard reasoning.",
            "method_or_approach": "Few-shot in-context learning (ICL) and SFT baselines reported; used for comparison with fine-tuned smaller models.",
            "performance": "On FOLIO few-shot ICL, Mixtral recorded the highest reported few-shot accuracy in the paper (about 42% per text); performance varies across datasets and modes.",
            "baseline_comparison": "Serves as a competitive few-shot baseline; smaller models fine-tuned on PROOFFOL narrow the gap or outperform Mixtral on some SFT/FOL tasks.",
            "limitations_or_failures": "Same kinds of NL→FOL translation semantic errors remain in few-shot settings; SFT on relevant data remains necessary for robust multi-statement translation.",
            "insights_or_conclusions": "Mixture/ensemble few-shot performance can be strong, but targeted SFT on task-aligned FOL data still yields superior FOL generation quality for downstream deduction.",
            "uuid": "e8601.3",
            "source_info": {
                "paper_title": "Strategies for Improving NL-to-FOL Translation with LLMs: Data Generation, Incremental Fine-Tuning, and Verification",
                "publication_date_yy_mm": "2024-09"
            }
        },
        {
            "name_short": "GPT-4o (data generation)",
            "name_full": "GPT-4o (used to generate silver-standard PROOFFOL FOL annotations)",
            "brief_description": "OpenAI GPT-4o was used to generate NL→FOL translations for ProofWriter training records; outputs were filtered/validated by Prover9 and only matching examples were retained to make the PROOFFOL silver-standard dataset.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "GPT-4o",
            "model_description": "Large instruction-following chat model (GPT-4 family variant) used in this work to produce NL-to-Prover9 FOL translations for ProofWriter training records; outputs post-processed via pattern matching and Prover9 verification.",
            "model_size": null,
            "reasoning_task_name": "Data generation for ProofWriter → FOL (creating PROOFFOL)",
            "reasoning_task_description": "Generate first-order logic (Prover9 format) translations of multi-premise ProofWriter records to serve as silver-standard training data for SFT of smaller models.",
            "method_or_approach": "Prompt GPT-4o with adapted Prover9 FOL format examples (2-shot), parse/clean generations, run Prover9 parser + theorem-prover check to filter outputs, keep examples where Prover9 result (True/False/Unknown) matches ground truth label; retained ~70% of initial generated data.",
            "performance": "Data-generation yield: from 15k GPT-4o outputs sampled, after parsing/filtering 10,424 high-quality PROOFFOL examples were retained (the paper reports a final PROOFFOL size of 10,424).",
            "baseline_comparison": "PROOFFOL (GPT-4o-generated + Prover9-filtered) provided much larger NL→FOL training data than existing human-annotated sets (e.g., FOLIO ~1k), enabling fine-tuned small models to outperform larger models without such SFT.",
            "limitations_or_failures": "GPT-generated translations require careful parsing and solver-based filtering; GPT-4o outputs often need format fixes (extra explanation text, numbering, etc.) and ~30% of initial generations were discarded. The generated FOLs can still produce semantic errors that pass Prover9 (i.e., syntactically valid but semantically wrong).",
            "insights_or_conclusions": "High-quality silver data produced by a strong LLM plus automated theorem-prover filtering can be an effective way to scale NL→FOL supervision and enable smaller models to achieve or exceed larger-model baselines on strict logical reasoning tasks.",
            "uuid": "e8601.4",
            "source_info": {
                "paper_title": "Strategies for Improving NL-to-FOL Translation with LLMs: Data Generation, Incremental Fine-Tuning, and Verification",
                "publication_date_yy_mm": "2024-09"
            }
        },
        {
            "name_short": "T5-Large Verifiers",
            "name_full": "T5-Large predicate and FOL verifier models (trained on perturbed data)",
            "brief_description": "Separate T5-Large models fine-tuned as verifiers/correctors: one for predicates and one for FOL statements; trained on controlled perturbations (simulated syntactic & semantic NL→FOL errors) plus real SFT model errors to detect and correct translations at inference-time.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "T5-Large (verifier)",
            "model_description": "Encoder-decoder transformer (T5-Large) fine-tuned on a perturbation dataset crafted from FOLIO and PROOFFOL (synthetic perturbations: omitted quantifiers, moved quantifiers, bracket omissions, predicate variable omissions/additions, operator swaps, etc.). Trained 10 epochs with AdamW, lr 5e-5.",
            "model_size": null,
            "reasoning_task_name": "Predicate / FOL verification and correction for NL→FOL translation",
            "reasoning_task_description": "Given (NL statement + predicted predicates) or (NL statement + predicted FOL), the verifier outputs 'correct' or a corrected predicate/FOL string; used online (during incremental decoding) or offline (post-processing) to reduce syntactic/semantic errors that would harm theorem-prover-based deduction.",
            "method_or_approach": "Fine-tune T5-Large on a mix of controlled perturbations (omitted quantifiers/brackets, wrong operators, predicate perturbations) and real errors from SFT inference runs; apply verifier during inference either online (per-step) or offline (post-generation).",
            "performance": "Authors report verifier use yields further improvements: e.g., verifier mechanism brought a further ~17% improvement on FOLIO; in 1k incremental experiments an Offline verifier setting achieved ~37% on FOLIO (exceeding LLaMA-2 70B ICL at 34.97%). Exact metric depends on dataset and SFT scale.",
            "baseline_comparison": "Verifier-corrected outputs outperform pure SFT/incremental SFT outputs; offline verifier often performs better than online due to reduced error propagation; using Prover9 alone for sampling/selection proved ineffective/time-consuming compared to trained verifiers.",
            "limitations_or_failures": "Online (synchronous) verifier corrections can propagate errors forward (domino effect) and sometimes reduce accuracy; verifiers depend on representative perturbation data and need a higher proportion of perturbed instances during training to be robust.",
            "insights_or_conclusions": "A separate learned verifier/corrector trained on realistic syntactic and semantic perturbations is an effective and efficient mechanism to catch and fix NL→FOL translation errors at inference time, especially when scaling SFT data is constrained.",
            "uuid": "e8601.5",
            "source_info": {
                "paper_title": "Strategies for Improving NL-to-FOL Translation with LLMs: Data Generation, Incremental Fine-Tuning, and Verification",
                "publication_date_yy_mm": "2024-09"
            }
        },
        {
            "name_short": "PROOFFOL (dataset)",
            "name_full": "PROOFFOL: PROOFWriter → FOL silver-standard dataset (this work)",
            "brief_description": "A silver-standard dataset of NL (premises, conclusion, label) paired with Prover9-formatted FOL translations, created by prompting GPT-4o and filtering/parsing via Prover9; designed to provide large-scale NL→FOL supervision for fine-tuning smaller LLMs.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": null,
            "model_description": "Dataset containing 10,424 records (premises, conclusion, deduction label, corresponding Prover9-formatted FOLs) sampled from ProofWriter depth-5 training set; generated with GPT-4o, parsed and filtered using Prover9, and post-processed with regex and grammar-rule fixes.",
            "model_size": null,
            "reasoning_task_name": "ProofWriter NL→FOL translation / deductive reasoning",
            "reasoning_task_description": "Provides ground-truth FOL translations aligned to ProofWriter multi-premise deductive examples for supervised fine-tuning of NL→FOL translation models and verification systems.",
            "method_or_approach": "Generate FOL translations with GPT-4o (2-shot demonstrations), parse/clean output, run Prover9 to check syntax and semantics (matching True/False/Unknown labels), discard mismatches; produce final silver dataset used to SFT LLaMA and Mistral models.",
            "performance": "Dataset creation: out of ~15k GPT-4o generations (depth-5 ProofWriter samples), 10,424 high-quality FOL records retained (~70% retention after parsing and Prover9 checks). Using PROOFFOL for SFT produced large gains: e.g., LLaMA-2 13B reached 86% on ProofWriter FOL pipeline after SFT with PROOFFOL.",
            "baseline_comparison": "PROOFFOL is orders of magnitude larger than human-annotated FO-LIO/FOLIO (~1k) and MALLS synthetic 28k sentence-level data differs in scope; PROOFFOL enabled small-model SFT that outperforms larger-model few-shot baselines.",
            "limitations_or_failures": "Silver-standard nature: despite Prover9 filtering, GPT-generated FOLs can include subtle semantic errors that pass syntactic/parsing checks; generation required engineering to fix formatting issues; dataset covers ProofWriter style data and may not cover all linguistic/semantic phenomena found in other corpora.",
            "insights_or_conclusions": "A practical way to scale NL→FOL supervision is to combine a strong LLM for generation with an automated theorem prover for filtering; such silver data can substantially boost small-model performance on strict logical reasoning benchmarks.",
            "uuid": "e8601.6",
            "source_info": {
                "paper_title": "Strategies for Improving NL-to-FOL Translation with LLMs: Data Generation, Incremental Fine-Tuning, and Verification",
                "publication_date_yy_mm": "2024-09"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Logic-LM: Empowering Large Language Models with Symbolic Solvers for Faithful Logical Reasoning",
            "rating": 2,
            "sanitized_title": "logiclm_empowering_large_language_models_with_symbolic_solvers_for_faithful_logical_reasoning"
        },
        {
            "paper_title": "Natural language reasoning with first-order logic",
            "rating": 2,
            "sanitized_title": "natural_language_reasoning_with_firstorder_logic"
        },
        {
            "paper_title": "ProofWriter: Generating and evaluating deductive reasoning",
            "rating": 2,
            "sanitized_title": "proofwriter_generating_and_evaluating_deductive_reasoning"
        },
        {
            "paper_title": "Harnessing the Power of Large Language Models for Natural Language to First-Order Logic Translation",
            "rating": 2,
            "sanitized_title": "harnessing_the_power_of_large_language_models_for_natural_language_to_firstorder_logic_translation"
        },
        {
            "paper_title": "Satlm: Satisfiability-aided language models using declarative prompting",
            "rating": 1,
            "sanitized_title": "satlm_satisfiabilityaided_language_models_using_declarative_prompting"
        },
        {
            "paper_title": "LINC: A neurosymbolic approach for logical reasoning by combining language models with first-order logic provers",
            "rating": 1,
            "sanitized_title": "linc_a_neurosymbolic_approach_for_logical_reasoning_by_combining_language_models_with_firstorder_logic_provers"
        },
        {
            "paper_title": "Certified deductive reasoning with language models",
            "rating": 1,
            "sanitized_title": "certified_deductive_reasoning_with_language_models"
        }
    ],
    "cost": 0.016898749999999997,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Strategies for Improving NL-to-FOL Translation with LLMs: Data Generation, Incremental Fine-Tuning, and Verification
24 Sep 2024</p>
<p>Ramya Keerthy Thatikonda 
Department of Data Science &amp; AI
Monash University</p>
<p>Jiuzhou Han 
Department of Data Science &amp; AI
Monash University</p>
<p>Wray Buntine 
College of Engineering and Computer Science
VinUniversity</p>
<p>Ehsan Shareghi 
Department of Data Science &amp; AI
Monash University</p>
<p>Strategies for Improving NL-to-FOL Translation with LLMs: Data Generation, Incremental Fine-Tuning, and Verification
24 Sep 2024A5FE30548B4F02757873E2CF9F6E3449arXiv:2409.16461v1[cs.CL]
Logical reasoning is a fundamental task in natural language processing that presents significant challenges to Large Language Models (LLMs).The inherent characteristics of logical reasoning makes it well-suited for symbolic representations such as first-order logic (FOL).Research in symbolic logical reasoning explored FOL generation using state-of-the-art LLMs (i.e., GPT-4) to produce FOL translations of natural language (NL) statements, but errors in translation are usually not the focus.We address this by categorizing the translation errors in FOL statements generated by LLMs, specifically for deductive logical reasoning tasks.In order to make progress towards improving the quality of FOL translations for smaller language models such as LLaMA-2 13B and Mistral 7B, we create PROOFFOL, a high-quality FOL-annotated subset of ProofWriter dataset using GPT-4o.The models finetuned on this silver standard data achieve a significant gain in performance when compared to larger language models such as LLaMA-2 70B.In addition to improving the model using large data, we also tackle the issue of data scarcity and introduce an incremental framework encompassing of data augmentation and verification steps.In the augmentation process, a single pair of (premises, conclusion) is split into multiple new instances based on the predicates and FOLs.This data is used for fine-tuning, and the inference on this model generates FOLs with fewer errors over the model trained on the original data.Our investigation on the translation errors leads to generation of a perturbation dataset consisting of simulated NL-to-FOL translation errors and their corresponding corrections.This data is used to train a verifier, which corrects potential syntactic and semantic FOL translation errors.We demonstrate an efficient method for making the most of a limited existing human-annotated dataset.Our results show state-of-the-art performance for ProofWriter and ProntoQA datasets using PROOFFOL on LLaMA-2 and Mistral models. 1</p>
<p>Introduction</p>
<p>Recent state-of-the-art methods for logical reasoning from natural language (NL) descriptions work via translation (Pan et al. 2023;Ye et al. 2024;Olausson et al. 2023).An LLM is tasked to translate statements from NL to first order logic (FOL), which is then sent for execution to external SMT solvers such as Z3 (De Moura and Bjørner 2008) and Prover9 (McCune 2005).Recent work (Yang et al. 2024) has highlighted the systematic errors that even the most capable LLMs (such as GPT-4) make during translation of a single NL statement into its corresponding FOL.A realistic logical reasoning scenario is much more demanding as it involves several premise statements followed by a conclusion to be verified.This requires consistency of NL-to-FOL translations (e.g., in predicate naming or translation of logical operators) across several statements.However, very little is explored on the pattern of syntactic and semantic errors LLMs make during such translation scenario.</p>
<p>Existing approaches to reduce NL-to-FOL translation errors are of limited impact.They rely on the LLM's capability to understand and self-correct the translation inaccuracies only based on the error message from the external SMT solver (Pan et al. 2023), but the ability to comprehend an error message is often restricted to larger scale of models (i.e., 175B), and not possible in smaller LLMs (i.e., 7B, 13B).Also, while syntactic translation mistakes (e.g., misplaced operator: P ∧ → Q, or missing quantifiers: P (x) → Q(x)) result in run-time errors by tools, many semantic errors (e.g., use of incorrect quantifiers: All men are mortal.∃x(Man(x) → Mortal(x)) ) are passed through SMT tools without causing any run-time error, limiting the ability of such an approach to correct less trivial errors.A straightforward solution to reduce errors is to fine-tune the smaller models on large scale of NL-to-FOL translation data.However, the existing datasets offer very little support, with FO-LIO (Han et al. 2022) as the only human-annotated dataset to have around 1k examples of NL (premises, conclusion) and their FOL translations.MALLS (Yang et al. 2024) is another synthetic dataset which has 28k pair of single statements and FOL translations.Even in the presence of larger scale fine-tuning data, it is still desired to have a correction mechanism for smaller models that could catch both syntactic and semantic errors on-the-fly at inference time.</p>
<p>In this paper we combine a number of methods to reduce NL-to-FOL translation errors.First, to overcome the shortage of ground truth for fine-tuning, we utilise GPT-4o to create PROOFFOL, a new large corpus of (premises, conclusion) pairs and corresponding FOL translations.More concretely, we use the existing pairs of (premises, conclu-sion) of ProofWriter dataset (Tafjord, Mishra, and Clark 2020) and prompt GPT-4 to generate the corresponding FOL translations.To ensure the correctness of the FOL translations, we pass them through Prover9 and filter out examples that produce outputs (i.e., true, false, uncertain) that do not match the ground truth in ProofWriter.PROOFFOL is the largest existing dataset consisting of in 10424 examples of (premises, conclusion and their corresponding FOL translations.We show that fine-tuned LLaMA-2 13B (Touvron et al. 2023) and Mistral 7B (Jiang et al. 2023) models on PROOFFOL outperform larger baselines such as LLaMA-2 70B and Mixtral 8 × 7B, both in terms of translation quality and performance on logical reasoning task on ProofWriter and ProntoQA (Saparov and He 2022).</p>
<p>Second, to effectively utilize existing scarce but highquality human-generated data (i.e., FOLIO), we propose a set of incremental techniques for both the training and inference phases.More concretely, to increase the number of training instances, we split each record of FOLIO into multiple records for an incremental training process where the model is trained to first produce the predicates of premises and conclusions, and then to produce the FOL of each statements of premises and conclusion one by one.This model further improves the predictive accuracy on FOLIO by 41%.</p>
<p>Third and finally, to allow for fine-grained correction of semantic and syntactic errors at inference time, we train separate T5 (Raffel et al. 2020) models to exclusively verify predicates and FOLs on-the-fly, and apply necessary corrections when needed.In particular, we first define categories of semantic and syntactic errors made by LLMs during NLto-FOL Translation.To simulate these errors, we apply controlled perturbations on ground truth labels of FOLIO and create a new training set consisting of statements and their corresponding perturbed predicates and FOLs.Then, we train T5 models which take as input statements and their predicates, or statements and their FOLs, and either verifies their correctness (i.e., outputs correct) or outputs corrected versions.This added mechanism brought a further 17% improvement on FOLIO.</p>
<p>Our findings highlight that data is crucial for surpassing the current performance limits of several large language models, particularly when employing more accessible models for logical reasoning tasks.Our data generation pipeline allows us to create, PROOFFOL, the largest FOL-annotated logical reasoning dataset to this date.Our incremental training presents an effective data augmentation method particularly useful for data scarce conditions, while the verifier mechanism and corresponding training protocol offers a promising pathway to verify correctness of symbolic forms generated by LLMs at inference time.</p>
<p>NL-to-FOL Translation Errors</p>
<p>First-order logic (FOL) is a form of logic representation that covers the use of variables, functions, and quantifiers.FOLs are suitable for logical reasoning tasks involving natural language.Large Language Models (LLMs) are shown to be capable of translating natural language into various types of formal representations with varying degree of success.Among these formalism, NL-to-FOL translation presents unique syntactic (FOL syntax) and semantic (interpreting the meaning of the NL statements) challenges.We first attempt to categorize these syntactic and semantic errors in this section.This will serve as the basis for our data perturbation protocol to train FOL verifiers (presented shortly).</p>
<p>The translation of language to FOL follows grammatical rules and any deviation from the rules can cause syntax errors.For the rule "every free variable assigned to a predicate has a quantifier" can be applied to the statement "Green people are blue" with predicates 'green' and 'blue', a free variable 'x' and a quantifier '∀' to quantify the variable.A missing quantifier can be a parsing error in syntax for this rule.The Prover9 tool, used as a logical solver in our paper, is designed to send a feedback when encountered with syntax errors.We use this to detect and categorize the syntactic errors during translation into the following categories:</p>
<p>• Parsing errors: This occurs when the logical statement has missing or invalid operators, or missing parentheses.• Type errors: The tool returns none value when a sentence level discrepancy, e.g.missing quantifier, is encountered.• Token errors: This type of error is observed when an invalid token is part of the FOL, such as a $ symbol.</p>
<p>Semantic errors are generally not detectable as they follow the structure of formal language, but can be identified by observing the incorrect predictions of the parsable FOL statements.This process is tedious as it requires effort to scan through translations and point the occurrence of the error.An example of semantic error is when the language model predicts a wrong operator.In case of the sentence "All rabbits have fur", the FOL ∃x(Rabbit(x) → Have(x, fur)) incorrectly represents the quantifier of the sentence.Semantic errors are broadly categorized as • Sense errors: This is a general form of semantic error where the prediction from the tool is incorrect, pointing to inaccuracy between natural language and FOL.• Arities errors: This is a specific error thrown by a tool to indicate that there are duplicate predicate values with mismatch in number of arguments.</p>
<p>These errors are further studied manually to divide into more specific categories.Due to space constraints, we define them in detail in the Appendix.We provide an empirical distribution of these errors in Section and Figure 2.</p>
<p>Incremental Fine-Tuning and Verification Data Generation and Fine-tuning</p>
<p>The alignment of a language model to follow instructions for a specific task can be accomplished by fine-tuning on substantial data.The task of formal translations require firstorder logic of their natural language counterparts.Ideally, this task is at a passage level rather than sentence level, which makes it challenging for a language model to follow a required format.To overcome this, we need sufficient passage level translations, which are time-consuming to generate through human annotations.We introduce a streamlined process for generating this FOL data and ensuring correctness of the format, grammar, and order of the translations.</p>
<p>Data Generation For the data generation process, we pick ProofWriter which comes with large number of training records, each consisting of multipe premises and a conclusion, and variations in depth of reasoning.The format of the FOLs is set to be consistent with the "Prover9" theorem prover, which has a human understandable, formal language syntax. 2 The fixed format of demonstrations is adapted from Pan et al. (2023), where we generate predicates followed by first-order logic statements for each sentence.We change the formal language to Prover9 and keep it fixed for all datasets.</p>
<p>At a glance, the output from the GPT model has formatting issues, such as assigning numbers to each generation, explaining the task before generation, and solving for conclusion after producing translations.These issues are parsed using pattern matching to obtain the maximum number of translations.After the parsing stage, the syntax check is done by the Prover9, where the tool can provide unique feedback for each form of syntax error.When analysing these errors, we observed grammar rules that can be fixed in the tool to include unicode decoding, allow unordered quantifiers and support negation of a full formula.This addition of grammar rules minimized the penalization for translations.The semantic errors were identified by comparing the ground truth label from ProofWriter with Prover9-generated output based on FOLs.This systematic pipeline enabled the retention of 70% of the silver-standard data.We term this dataset PROOFFOL, which consists of 10424 pairs of (Premises, Conclusions), deduction label, and corresponding FOLs.</p>
<p>Supervised Fine-tuning (SFT) Each input x to the SFT is a set of premise statements P x (= {P 1 , P 2 , . . ., P n }), a conclusion C x , and an instruction (I) represented as [P x , C x , I].In order to avoid over-fitting the model to certain spurious patterns in GPT-4o translations, we include humangenerated dataset (FOLIO) in the mix.We create a set of models built on the full dataset, providing a perspective for model behaviour with size of the dataset.Since this SFT model employs both existing and synthetic data, it imposes a dilemma of the effect of gold-standard data on the results when compared to the generated silver-standard.To validate the reliability of our generated data, we fine-tune the model on a subset of the dataset and examine how increasing the data size impacts logical reasoning tasks.For a given input x, the output of SFT models are predicates of x (denoted as P red x ), and FOLs of its premises and conclusion, [P red x , F OL Px , F OL Cx ].For experiments, see Section .</p>
<p>Incremental Techniques</p>
<p>The SFT method described in the previous section uses the FOLIO dataset as just a small component of the overall approach.With high number of records associated with PROOFFOL, we can assume that the in-distribution dataset will show a major improvement when compared to FOLIO.</p>
<p>To enhance the performance of FOLIO dataset (and in general any similar data-scarce scenario), we introduce 'Incremental Techniques' for maximizing the use of limited data.These techniques encompass data augmentation, incremental fine-tuning and inference, and incremental verification of predicates and FOLs, creating a comprehensive setup for FOL generation.We further expand this method to a smaller subset of PROOFFOL to simulate data scarce environment.</p>
<p>Data Augmentation Supervised Fine-tuning a decoder model is technically an unannotated form of training as the supervised part of the fine-tuning refers to the label that is passed with the input.During a vanilla SFT process, we pass the whole output along with the input, and the model performs inference as a text completion task.This motivates our data augmentation method, where the model examines smaller part of the output rather than training on the whole output at a time.The FOL translation is one such task where the output sequence is lengthy and the model can deviate from generating the correct syntax.</p>
<p>To initiate the data augmentation process, we split the output of the original record to represent incremental data, where the first output is [P red x ], the second output is [P red x , F OL P1 ], and so on till we reach the full output [P red x , F OL P1 ..., F OL Pn , F OL Cx ].This splits a single record into n + 2 records, where n is the number of premises and '+2' is for predicate and conclusion generation.The input remains the same for all the records.This data augmentation increases the dataset size to about 7× and 20× for FOLIO and ProofWriter, respectively.With this enhanced data, we train a set of SFT models for FOL translation tasks.</p>
<p>Inference The SFT for augmented data is performed using two instructions, indicating two types of tasks.The first instruction is "Generate predicates for the given natural language sentences."to generate the predicates, and the second is "Given a premise and conclusion, generate the first order logic form of the premises and conclusion." to generate the FOL statements.At inference, we provide the model with the instruction to generate the predicates.These predicates, along with the input, are then passed to the model to infer the FOL statements.We categorize FOL inference into two forms.</p>
<p>• Vanilla Inference: In vanilla inference, the model is provided with the natural language statements and is asked to generate the predicates and the FOL translations for the complete input.• Incremental Inference: In incremental inference, we first generate the predicates, and then limit the generation to a single FOL translation at a time by setting a low maximum new token parameter.For every FOL generation, we pass the previously generated values as input.For example, if we are generating F OL P3 , the input would be
[P x , C x , P red x , F OL P1 , F OL P2 ].
Verification and Correction Since the incremental inference allows individual predicate and FOL generation, we train two verifiers; predicate and FOL, to detect and correct the potential errors.The term 'verifier' refers to both the verification and correction processes.• Predicate Verifier The Predicate verifier takes the [P x , C x , P red x ], as the input, and evaluates the predicted predicate P red x .If the verifier considers P red x correct, the output is just 'correct', otherwise the verifier will generate the corrected predicates set.To achieve this outcome, the verifier is trained on the perturbed predicates of the training dataset used for SFT.The perturbations for predicates are created based on the semantic errors related to predicates.Few perturbations used are; omitting predicate, omitting variable, adding variable, and adding duplicate predicate.The predicate perturbations are explained in detail in the Appendix.</p>
<p>• FOL Verifier</p>
<p>The FOL verifier takes [P red NL , F OL NL , NL] as the input, where F OL NL represents predicted FOL form of a single premise (P i ) or conclusion (C x ) statement (represented as NL).The verifier evaluates F OL NL as 'correct' or will generate a corrected FOL.Similar to predicate verifier, we use the original SFT training set and applied perturbations to train this Verifier model.The perturbations used in this method are crafted based on the common syntax and semantic errors in translations (Section ).Few perturbation used in this verifier are; changing quantifier position, omitting a quantifier, omitting parenthesis, tweaking negations, and replacing operators.We discuss these in detail in the Appendix.</p>
<p>In addition to these perturbation instances, we incorporate real errors from the SFT training data.Specifically, we run the inference of the training data on the SFT model and collect the predicate and FOL, which do not match the ground truth, as errors.We add these errors to the fully-controlled created perturbations to form the 'incorrect verifier training instances'.Finally, in order to verify 'correct' predictions, we take the predicate and FOL values from the ground-truth and label them as 'correct'.We generate the perturbation dataset from a seed of 1k examples of FOLIO and similarly for ProofWriter.For detail statistics on the size of the resulting perturbation datasets, please see Appendix.</p>
<p>Inspired by Han et al. (2023), after the creation of the training data for the two verifiers, we fine-tune a T5-Large (Raffel et al. 2020) 2023), where we generate predicates and FOL statements, each paired with a corresponding natural language text.We generate FOLs for 15000 training data points.These records are parsed using regex pattern match, specifically to separate the FOLs from unintended text.The predicted FOL and input NL statements are mapped and generations with incomplete or excess text are filtered out.The FOL statements are then passed to the Prover9 tool to perform deductive reasoning, where the tool returns 'True', 'False', 'Unknown', or 'None' in case of an error.The generated labels are compared against the ground truth and any mismatch is removed.The prompt templates and statistics of PROOFFOL are provided in the Appendix.</p>
<p>Vanilla SFT</p>
<p>We choose two families of models; LLaMA-2 and Mistral, and examine their performance on three deductive logical benchmarks; ProofWriter, FOLIO, and ProntoQA.The output of the LLMs are either based on the truth value of the conclusion given the NL format of premises and conclusions (denoted in results as Standard), or the formal language translations of the input which is then passed to Prover9 for generating the output (denoted in results as FOL).The initial baselines use in-context learning (ICL) for standard and FOL generation.The few-shot examples for standard generation are randomly sampled from the training data, ensuring a balanced output distribution.Since ProntoQA is a test-set only benchmark, we use ProofWriter demonstrations during inference on ProntoQA.We consider ProntoQA as out-ofdistribution (OOD) since it was not represented in the SFT data.The few-shot FOL generation is similar to the process used in data generation, with variations in examples.The number of few-shot examples and their respective templates are presented in the Appendix.</p>
<p>SFT with PROOFFOL is performed on two models; LLaMA-2 13B and Mistral 7B.These models are selected based on their low computational cost and model parameters.The models are fine-tuned for 3-epochs with a fixed batch size and LoRA (Hu et al. 2022).The inference is done using an 8-bit quantization with the trained LoRA adaptor.Temperature and top p are fixed at 0 and 1 respectively, with a variation of maximum new token value based on the dataset.ProofWriter requires larger number of tokens at inference when compared to FOLIO because of the size of input.Additionally, as NL-based baseline, separate versions of models are also fine-tuned on textual data without symbolic translations (the corresponding results are reported under Standard).The test data used in our experiments are taken from Pan et al. (2023) for ProofWriter and ProntoQA.FOLIO comes with a pre-defined dev dataset, that is used for evaluations.</p>
<p>Incremental SFT</p>
<p>Incremental SFT follows the same process as vanilla SFT for training.The augmented data is passed through LLaMA-2 13B model for fine-tuning.The maximum new token value is reduced to produce individual generation for incremental inference.This additionally ensures minimal time lag between vanilla and incremental inferences.The incremental setup is performed on FOLIO and ProofWriter datasets.For FOLIO, the whole training set (1000 records) is used and the data augmentation results in an increase in data size (∼ 7000 records).To measure the generalizability of this technique, we sample 1000 records from our PROOFFOL dataset and apply the data augmentation, resulting in ∼ 20000 records since the number of statements in ProofWriter are larger.We also perform SFT on the original records to create a baseline for these models.</p>
<p>Verifier Training</p>
<p>The verifier model, used during the inference of FOL and predicate generation, is a T5 large model trained on a perturbation dataset.For our experiments, we train a total of 4 verifiers, two for FOLIO and another two for ProofWriter.The perturbations are applied on their respective training data and vary with respect to the complexity of the FOL statements.ProofWriter consists of shorter sentences, that use less operators and predicates, and can have variations of perturbations without excess manual effort.FOLIO, on the other hand, covers a wide range of operators.We run our SFT model on the training dataset to get the perturbations in addition to the defined ones.The proportion of perturbed instances are kept higher than the correct instances in the final verifier training set for all the datasets.The T5 model is trained for 10 epochs with AdamW optimizer (Loshchilov and Hutter 2019) and a learning rate of 5 × e −5 .</p>
<p>Once trained, the verifiers could run in synchronous (online) or asynchronous (offline) mode.While the online mode corrects errors at each step of inference, before moving to next step (i.e., correction at time step t impacts step t + 1 during generation), the offline mode applies corrections on the fully generated predicate and FOLs as a post-processing step (i.e., correction at time step t does not have any consequential effect on t + 1).For time overhead of incremental decoding and verification, see</p>
<p>Results and Discussion</p>
<p>Main Results</p>
<p>Table 1 refers to a set of results on logical reasoning dataset using in-context learning and SFT.The main focus of these experiments is to assess how much of a gap exists between large and smaller language models prior to fine-tuning, and how this gap is bridged with further fine-tuning of smaller LMs.LLaMA-2 70B is assumed to be the baseline for LLaMA-2 13B, and Mixtral 8 × 7B model for Mistral 7B.</p>
<p>Standard experiment reports free-form reasoning, where the LLM is given a question (premises and a conclusion) and is tasked to produce a direct response.The standard generation varies vastly for n-shot across the datasets.Mistral and Mixtral models show higher accuracy for few-shot learning, but the the results are mixed under SFT.LLaMA-2 13B model responses well with the 10k examples from PROOF-FOL for ProofWriter, but does not show a significant gain for FOLIO and ProntoQA.The fine-tuned Mistral models have higher accuracy over the few-shot results for both 5k and 10k records.This can be attributed to the unreliable output from FOL in the absence of a reasoning path.FOL experiments show correlation of performance with model size, where, for few-shot ICL, LLaMA-2 70B and Mixtral perform consistently better than their smaller versions.ProofWriter achieves 86% accuracy with LLaMA-2 13B model, fine-tuned on PROOFFOL, which is a significant gain in performance when compared to the few-shot setting.Mistral fine-tuned models are the state-of-the-art in FOL generation for ProofWriter datasets, where the model produces 0 syntax errors after fine-tuning.ProntoQA, an altered form of ProofWriter, shows similar trends in performance gain with our fine-tuned models.Mistral 7B fine-tuned on PROOFFOL data outperforms all the ProntoQA baselines.For ProntoQA, there is an observed negative effect of overfitting, when LLaMA-2 is trained on larger dataset (increasing training data from 5k to 10k), but we don't notice this for Mistral.We speculate this might be reflective of difference in model size and how it impacts potential training memorization (i.e., overfitting) for larger models.FOLIO, as expected, is a challenging dataset with complex language and structure.Mixtral model shows has the highest accuracy with FOLIO dataset using few-shot at 42%.LLaMA-2 13b models improve from 24% to 34% when fine-tuned, and is on-par with a much larger LLaMA-2 70B.The syntax and semantic error counts for each of these results are specified in the Appendix.</p>
<p>Error Distribution We provide an error distribution of models on NL-to-FOL translation errors.The results for LLaMA-2 70B with ICL and LLaMA-2 13B after finetuning is provided in Fig 2 .ProofWriter and ProntoQA show decline in errors, whereas FOLIO stays equivalent to the LLaMA-2 70B ICL model.This plot indicates that a model significantly smaller in size can achieve better generation over a larger model when fine-tuned with relevant data.</p>
<p>Incremental Results</p>
<p>Incremental techniques are performed on ground truth FO-LIO and a subset of PROOFFOL dataset.The intention be-   hind the incremental technique is to show that the data augmentation method improves the translations over the original dataset.In Table 2, we focus on the shift in performance between LLaMA-2 13B model fine-tuned on the original 1000 records and augmented 1000 × n records, where n represents the scale at which the data grows after augmentation.Both FOLIO and ProofWriter have low performance in FOL generation when trained with a small dataset.FOLIO shows a steady improvement using vanilla and incremental inferences.This pushes us to use a verifier to further the performance.With the predicates corrected during generation and FOLs corrected after inference, this verifier based incremental setting achieves 37% using Offline verifier, which outperforms LLaMA-2 70B ICL accuracy 34.97% (Table 1).ProofWriter, when trained incrementally, provides varied results with different inferences.The verifier inference model achieves 29% an 32% accuracy when compared to the SFT model on original dataset, 24%.It can be noted that the performance of the FOLIO model is lower when the FOL verifier is online, since any error from the verifier is passed on to the next generation and can cause a domino effect.The change in inference times between incremental and verifier settings is minimal. 3</p>
<p>Ablation Studies</p>
<p>The incremental methods follows certain rules of finetuning and generation.Our model uses two instructions for predicate and FOL generation.We performed an ablation study on using different variation of incremental training and inference for FOLIO dataset.The type of ablations and their performances are given in Table 3.These were performed before training the verifier module.In place of the verifier, we initially used Prover9 to check for syntax and any invalid generation followed a sampling by the LLM, and the first error free FOL was selected.This method proved ineffective as the sampling method was time-consuming.The results in the table are after the tool verification, except for the Check model, where we use LLM as a verifier.</p>
<p>Mixed is the current method of incremental training and inference, where we use different instructions for predicate and FOL generation.Single method uses only one instruction;'Complete the generation'.This performs equivalent to the Mixed, but results in additional syntax errors, presumably because of the vague instruction.Ordered uses different instructions for each FOL generation.The instructions carry information about the sentence that is required to be translated.This method helped keep the syntax errors low, but lowered the overall performance.Instead of passing the previously generated FOL to the next generation, we applied Unique, where the statements are split and passed one at a time with the predicate values.This performs poorly and does not include passage level translations.In Check, we use the perturbation dataset with specific instructions along with the training dataset for fine-tuning.We instruct the model to identify and correct the errors at inference.This method relies on the language model to perform a new task with limited data and proves to be ineffective.</p>
<p>Related Work</p>
<p>LLM for symbolic translation The use of formal language translations by LLMs was initially attempted by Nye et al. (2021), with an intent to emphasize the importance of dual process theory for logical reasoning tasks.Following this, the process of reasoning was offloaded to theorem provers and LLMs served as systems to generate symbolic translations (Pan et al. 2023;Ye et al. 2024;Olausson et al. 2023).The available research in this method majorly differs in variation of formal language (used by different theorem provers) and verification process to handle translation errors.These methods make use of the expensive and ambiguous4 GPT models, restricting the symbolic framework to noncritical domains.Corresponding to the work in formal logic, Yang et al. (2024) applied supervised finetuning to LLaMA model to improve the natural language to first-order logic translations at a sentence level.Our research shifts the focus to building a complete translation system that can handle multiple statements.In addition to this, we perform a systematic analysis of translation errors which enabled us to build a verification mechanism.</p>
<p>Symbolic Decoding with LLMs</p>
<p>The choice of decoding strategies can improve text generation, specifically in LLMs where the output follows a structured format.In neuro-symbolic models, neuro-logic decoding (Lu et al. 2020(Lu et al. , 2021) ) applies symbolic constraints.Interactive theorem provers were also used alongside LLMs to ensure a constrained generation of the reasoning path (Poesia et al. 2023).Other techniques like contrastive step-wise decoding helped with improving the probability of a correct reasoning path (Su et al. 2023).The success of these symbolic decoding strategies motivates our research to apply verification during the inference stage.</p>
<p>Deductive reasoning benchmarks Deductive reasoning requires logical derivation of conclusion using a set of premises.The available benchmarks, ProofWriter (Tafjord, Mishra, and Clark 2020) and ProntoQA (Saparov and He 2022), show a reasoning path for identifying the validity of question from its context.These datasets have a simple, yet multi-hop deductive style.We develop FOL data for the training set of ProofWriter dataset to make it suitable for translation tasks.FOLIO (Han et al. 2022) is another deductive task which is semantically complex with human annotated FOL sentences.The presence of gold-standard FOL should ideally make FOLIO suitable for developing or improving formal language translation models, however the limited size of this dataset impedes the realization of this goal.We present data augmentation technique to overcome this issue.To the best of our knowledge, our work is the first at using the incremental setting, with augmentation and verification, in the context of logical reasoning with NL.</p>
<p>Conclusion</p>
<p>Formal language translation systems for logical reasoning task worked effectively in the era of LLMs, with persisting translation errors.In this paper, we provided an understanding of general translation errors by LLMs, when used as NL-to-FOL translation systems.We highlighted the importance of first-order logic (FOL) ground truth data and present a pipeline to generate high quality FOLs for ProofWriter dataset, introducing an FOL-annotated data called PROOF-FOL.Using PROOFFOL, we fine-tuned a set of smaller language models and showed an increase in performance over larger LMs.Additionally, the issue of data scarcity is addressed via proposing incremental techniques, which cover data augmentation, inference verification, and correction.Our experiments on 3 benchmarks highlight the potential of our proposed framework.</p>
<p>Data Generation</p>
<p>The data pipeline applied for generating ProofFOL is detailed in Fig 3 .The train data is 15000 data points with depth-5 from ProofWriter dataset.The 15k records are sampled randomly ensuring a fair distribution of the labels; True, False, and Uncertain.The LLM here is GPT4o with a output token length of 1000 for each generation.We use url = /v1/chat/completions format for batch generations of GPT4o.The logical solver is Prover 9, a theorem prover suitable to run in python environment with nltk library, that uses CNF conversions, quantifier operations, and skolemization to transform the clauses into a tree format.Parsing errors by Prover 9 occur when the FOL formula cannot be converted to a tree structure because it does not follow specific grammar rules.After filter adn parsing stages, we get 10424 records with FOL statements.Syntax errors are the errors thrown by the tool and semantic errors are measured by comparing the ground truth label with the solver output.</p>
<p>Few Shot Examples</p>
<p>In this section, the few-shot format used for all the in-context learning tasks are presented.</p>
<p>Few-shot for Data-augmentation The Fig 4 shows the format of the few-shot example for data generation.We tried this with 2 examples for 50 unique training data points, but it did not generate better translation results.Instead, we ensured that all operators are covered in this example, specifically negation.We first generate Predicates associated with the sentence.This is followed by FOL generation.Each FOL generation comes with the natural language and this format is adapted from (Pan et al. 2023).We use the same format of generation for all of our experiments with an exception of Predicates description, as this part is harder to verify.The description is removed from ProofFOL.</p>
<p>Datasets</p>
<p>We use three datasets for our experiments.</p>
<p>Data Augmentation</p>
<p>Data augmentation for FOL generation uses incremental data assignment, where the output is divided into multiple tasks, as shown in Fig 9 .This method is applied on two datasets; ProofWriter and FOLIO.A subset of the ProofWriter dataset is extracted from the ProofFOL data and passed for data augmentation, increasing the size to 20X the original.For FOLIO, we take the full dataset and perform augmentation, making it 7X larger.Given the style of incremental data, we remove few records from FOLIO dataset which do not follow the one-to-one mapping of text and FOL.The size stats are detailed in Table 5.</p>
<p>Dataset Original Augmented</p>
<p>ProofWriter 1000 7288 FOLIO 998 20145</p>
<p>Table 5: Size of training datasets before and after data augmentation</p>
<p>SFT Models</p>
<p>Table 6 is an extension of Table 2 from the main paper.It shows how the syntax and semantic errors vary with ICl and fine-tuning.There is a constant trend of lower syntax errors with fine-tuning the models with relevant data for both Llama and Mistral models.</p>
<p>Error Analysis</p>
<p>The NL-FOL translation errors can be identified using the tool feedback or a mismatch in tool output with the ground truth.We identify these issues and categorize them into syntax and semantic errors.quantifier is incorrectly chosen in situations that require a universal quantifier, leading to a logical contradiction between the terms.This mismatch between the chosen quantifier and the necessary logical condition can result in flawed reasoning and inconsistencies in logical analysis.</p>
<p>• Predicate mismatch: It occurs when LLMs are tasked with generating predicates based on text passages and fail to recognize synonymous terms as equivalent.This results in the tool counting synonyms as distinct tokens, leading to discrepancies in predicate generation.</p>
<p>• Arities error: It occurs when predicates are inconsistently applied with a varying number of constants across different statements.Such discrepancies can introduce ambiguity in logical inferences.This is a semantic error that is captured by the tool.</p>
<p>• Subject predicate: The logic is flawed when a subject is used both as a predicate and a constant in the expression.</p>
<p>Verification Perturbations</p>
<p>The perturbations used for training T5 verifier models are designed from the errors in the previously discussed error analysis.The perturbations are different for FOLIO and ProofWriter dataset, as FOLIO is a complex dataset with additional operators when compared to ProofWriter.To handle the complexity of FOLIO dataset, we pass the training set data to the SFT model and match the translations with ground truth.Any mismatch is treated as a perturbation.Other perturbations are based manually included.This dataset has a portion of correct values, making it a verification and correction system.The count of these datasets is detailed in Table 8.</p>
<p>FOLIO Perturbations</p>
<p>The predicate perturbations are designed based on the commonly observed errors in the predicates.These are not complex errors, but usually a missing predicate or variable.Based on this, we use three types of perturbations.</p>
<p>• Omit One Predicate: We randomly omit a predicate from all predicates.</p>
<p>• Omit One Variable: We choose a predicate with the maximum number of variables and omit the last one in the chosen predicate.</p>
<p>• Omit Both Variable and Predicate: We choose a predicate with the maximum number of variables, omit the last argument in the chosen predicate, and also randomly omit a predicate from the rest of the predicates.</p>
<p>The FOL perturbations tackle the syntax errors that are common while generating FOL for FOLIO test data.</p>
<p>• Change Quantifier Position: We move the quantifier position to different positions in a FOL statement.</p>
<p>• Omit One Quantifier: We randomly omit one quantifier from a FOL statement.</p>
<p>• Omit Last Bracket: We omit the last bracket in a FOL statement.</p>
<p>ProofWriter Perturbations The ProofWriter dataset has simpler, but larger number of predicates.based on this, we design 4 types of perturbations.</p>
<p>• Omit one predicate: We randomly omit a predicate from all predicates.• Omit or add one variable: We choose a random predicate, and if the predicate consists of multiple variables, we omit one, and if it consists of only one variable, we add one.• Add plural predicates: To handle the synonymous predicate issue, we randomly select a predicate, create a plural form, and add it to the set of predicates.• Duplicate predicate: We select a random predicate and add a variable to it.This is added back to the set of predicates.</p>
<p>In addition to the quantifier, FOL generations in ProofWriter consists of three major operators; and, imply, and negation.We include variations in this for our perturbation data.ProofWriter can be divided into simple FOL statements (facts) and complex ones (rules).The simple statements usually do not contain any operators or quantifiers.Based on this, we design 5 types of perturbations.</p>
<p>• Add or omit negations: We randomly select facts and either add a negation or remove an existing one.• Omit arguments from facts: We randomly select predicates from facts and omit the variables if the predicate has more than one variable.• Add or omit quantifier: We randomly select rules and either add a quantifier or remove an existing one.• Swap operators: We replace 'and' with 'imply' operator or vice-versa if the operator exists in the FOL statements.• Add plural predicates: To handle the synonymous predicate issue, we randomly select a predicate, create a plural form, and add it to the set of predicates.</p>
<p>Incremental and Verification Ablation We present additional ablation done on the incremental methods and analyse their results.</p>
<p>• Incremental Ablation: The incremental finetuning uses two instruction; generate predicates and generate FOL (brief).This allows us to perform a full scale inference rather than an incremental one, by increasing the output token size.We first let the model predict the predicates and the input along with the predicates is passed to the LLM for full FOL generation.Since the data in the augmented set consist of such a case (last value in augmentation), the model is able to generate the FOL in a flow.We performed inference in this manner and the results are in Table 9, where vanilla<em> represents the full FOL inference.The results in ProofWriter are higher than the incremental results, but on closer observation, we determine that the model hallucinates few cases in the vanilla</em> and helps with better performance.The incremental method allows a strict format of generation and forces the model to generate the FOL for one statement at a time, without adding additional values.Additionally, because of this mismatch in number of statements, we cannot use a FOL verifier on vanilla*.</p>
<p>System Requirements for Experimentation</p>
<p>The Llama 2 model weights are downloaded from the official Llama website https://llama.meta.com/llamadownloads/. Mistral-7B (https://huggingface.co/mistralai/ Mistral-7B-v0.3) model and Mixtral-8x7B(https: //huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1) are accessed via the Hugging Face interface.All the models are gated and require access, which is typically a safety measure and can be easily granted.The transformer version used in our experiments is v4.40.0 and should ideally be above v4.28.0 or the latest version to run Llama and Mistral models without any errors.All the other library requirements will be specified in the code.</p>
<p>Figure 1 :
1
Figure 1: The overall flow of the incremental generation and verification at inference time.Here P i s and C denote Premises and Conclusion.For predicate and FOL generation, the output is run through the corresponding verifier.</p>
<p>model to work as the verifier.We train two separate models for the Predicate and FOL verification on each dataset.During incremental inference, the verifier is incorporated into the decoding phase, as shown in Fig 1.</p>
<p>SpecificationsFor the data generation process, we used the training set of ProofWriter Open World Assumption (OWA) with the highest complexity, depth of 5.The training data is passed along with 2-shot ProofWriter examples, which cover all the required operators, to gpt4-o.The format of FOL generation is adapted fromPan et al. (</p>
<p>Figure 2 :
2
Figure 2: Error distribution of LLaMA-2 70B (top) and LLaMA-2 13B (bottom) post fine-tuning on PROOFFOL.</p>
<ul>
<li>the 1k vanilla SFT data under incremental SFT expands to 7k (FOLIO) and 20k (ProofWriter) data points for training.The inference time for SFT models for each record is reported on an average in the format (MM:SS).Vanilla: All predicates and FOLs are generated in one pass.Incremental: All predicates are generated in one pass and then fed into the next step along with premises and conclusions to generate FOLs one by one.+Verifier (On-Off): Predicate verifiers are called during inference (Online) while FOL verifiers are called once all FOLs are generated (Offline).+Verifier (On-On): Applies both verifiers during inference (both in online mode).</li>
</ul>
<p>Figure 3 :
3
Figure 3: Overview of the Data Generation Pipeline and Key Statistics</p>
<p>•</p>
<p>ProofWriter: The training set for ProofWriter is sampled from the depth-5 records.For test-set, we use the one provided in (Pan et al. 2023) • ProntoQA: ProntoQA is a test dataset.We use ProofWriter examples as training set and test-set sample from (Pan et al. 2023) • FOLIO: FOLIO has 1001 training set records and 203 dev set.We use the original training set for SFT models and dev for evaluating the model.</p>
<p>Figure 4 :
4
Figure 4: Few shot example with instruction for Data Generation process</p>
<p>Figure 6 :
6
Figure 6: Standard Generation Few-shot examples for ProofWriter and ProntoQA</p>
<p>Figure 7 :
7
Figure 7: FOL Generation Few-shot examples for FOLIO</p>
<p>Figure 8 :
8
Figure 8: FOL Generation Few-shot examples for ProofWriter and ProntoQA</p>
<p>Figure 9 :
9
Figure 9: Data augmentation: the vanilla represents original data point.Incremental is the data that is present after augmentation.</p>
<p>Table 2 .
2TypeModelStandard FOLLLaMA-2 70B41.8378.33ProofWriterICL n-shot 5000 SFT 10000LLaMA-2 13B Mistral 7B Mixtral 8 × 7B LLaMA-2 13B Mistral 7B LLaMA-2 13B Mistral 7B44.16 49.67 45.83 64.16 70.33 85.66 69.5024.66 66.50 85.00 53.50 98.17 86.33 97.83LLaMA 70B50.6038.80ProntoQAICL n-shot 5000 SFT 10000LLaMA-2 13B Mistral 7B Mixtral 8 × 7B LLaMA-2 13B Mistral 7B LLaMA-2 13B Mistral 7B47.19 50.60 58.40 55.40 60.00 53.20 70.4011.4 10.80 13.00 53.20 78.60 47.80 85.40LLaMA-2 70B50.7434.97FOLIOICL n-shot 5000 SFT 10000LLaMA-2 13B Mistral 7B Mixtral 8 × 7B LLaMA-2 13B Mistral 7B LLaMA-2 13B Mistral 7B43.84 51.23 57.14 40.89 67.98 40.89 66.0124.13 35.96 42.36 26.11 26.11 34.48 27.59</p>
<p>Table 1 :
1
Comparison of models' deductive reasoning accuracy under Standard and FOL-based output prediction.</p>
<p>Here ICL denotes "in-context learning" with n-shots (details of shots in appendix), and SFT denotes "supervised finetuning" (on 5k or 10k training data subset from PROOF-FOL).Accuracy metrics in bold signify notably high performance within the same benchmark, while underline indicates best results under Standard and FOL for ICL and SFT.</p>
<p>) +Verifier (On-Off) 37.44 (03:05) 29.05 (03:10) SFT Incremental (1k * ) +Verifier (On-On) 29.56 (03:27) 32.50 (03:31)
ModelsInferenceFOLIOProofWriterICL BaselineVanilla24.1324.66SFT Vanilla (1k)Vanilla22.66 (01:55) 24.50 (03:36)SFT Incremental (1k
* ) Incremental 32.02 (02:58) 27.16 (02:42) SFT Incremental (1k *</p>
<p>Table 2 :
2
Comparison of LLaMA-2 13B models across FO-LIO and ProofWriters under different training and inference protocols.</p>
<p>Table 3 :
3
Comparison of Incremental Methods with Instruction Fine-tuning.Each method represents the type of instruction used for fine-tuning and inference.The syntax errors are out of 203 test records in FOLIO dataset.
Instruction Accuracy Syntax errorsMixed35.4664Single35.4770Ordered32.0263Unique21.1880Check27.09108</p>
<p>Table 4 :
4
Number of Few-shot examples used for creating baselines in Table 1
• Standard generation: For standard generation, we ran-domly sample examples from the training set. We use5-shot for FOLIO and 4-shot for ProofWriter and Pron-toQA as shown in Fig 5 and Fig 6• FOL generation: For FOL generation, we use partiallyuse examples from (Pan et al. 2023) and sample the restfrom the training set. The FOL syntax is fixed to repre-sent Prover9 format. We use 3-shot for FOLIO and 2-shotfor ProofWriter and ProntoQA as shown in Fig 7 and Fig8</p>
<p>Table 6 :
6
Fig 7 shows examples of each type of error.These are identified by manually analysing the FOL Syntax and Semantic error count for FOL generation statements in cases where there was no feedback from the tool.The details of each error are provided here.
TypeModelSyntax SemanticProofWriter(600)ICL n-shot 5000 SFT 10000LLaMA-2 70B LLaMA-2 13B Mistral 7B Mixtral 8 × 7B LLaMA-2 13B Mistral 7B LLaMA-2 13B Mistral 7B44 314 130 44 71 0 69 086 138 71 46 15 11 13 13LLaMA 70B203103ProntoQA(500)ICL n-shot 5000 SFT 10000LLaMA-2 13B Mistral 7B Mixtral 8 × 7B LLaMA-2 13B Mistral 7B LLaMA-2 13B Mistral 7B266 420 413 108 26 139 13177 26 22 126 81 122 60LLaMA-2 70B19113FOLIO(203)ICL n-shot 5000 SFT 10000LLaMA-2 13B Mistral 7B Mixtral 8 × 7B LLaMA-2 13B Mistral 7B LLaMA-2 13B Mistral 7B95 95 79 103 64 88 4859 35 38 47 86 45 99• Missing quantifier: When a predicate includes a variable,it must have either a Universal Quantifier '∀' or an Exis-tential Quantifier '∃'. This error occurs if either quantifieris missing.• Parenthesis error: The formula becomes invalid if thereis an extra or a missing parenthesis.• Completion error: The FOL is either incomplete or con-tains additional text that disrupts its logical flow.• Quantifier location: Quantifiers that are either repetitiveor incorrectly positioned result in grammatical inaccura-cies in the expression.• Missing variable: When multiple quantifiers are present,the tool fails to parse predicates that lack free variables.• Special token: The tool does not handle special charac-ters in the input.• Unknown operator: The tool does not support parsingmathematical equations.• Predicate error: These errors arise when predicates arereused with different subjects, omitted entirely, or con-joined inappropriately, leading to erroneous interpreta-tions of the logical constructs in FOL statements. Suchmisinterpretations can affect the accuracy and reliabilityof responses generated by LLMs.• Incorrect quantifier: This occurs when an existential
The code for fine-tuning, augmentation and verification, and PROOFFOL dataset are available at https://github.com/RamyaKeerthy/Translation-NL2FOL.
Given the requisite for diversity in syntax and semantic, we first chose a few combinations of demonstrations, and ran a small scale experiment through GPT-4o for each combination. We then selected the most optimal demonstrations with the least format and translation issues in the resulting generated FOL data. We report these final demonstrations in Appendix.
Since ProofWriter has larger number of sentences, we use an adaptive inference token size, where token with less than 5 words have lower token size. For example, "Dog chases the cat" can be translated to "Chases(Dog, Cat)", which require less than 16 tokens. This adaptive technique lowers incremental time for ProofWriter.
We refer to ambiguity in the data used to train the GPT model.</p>
<p>Z3: An efficient SMT solver. L De Moura, N Bjørner, International conference on Tools and Algorithms for the Construction and Analysis of Systems. Springer2008</p>
<p>Pive: Prompting with iterative verification improving graphbased generative capability of llms. J Han, N Collier, W Buntine, E Shareghi, arXiv:2305.123922023arXiv preprint</p>
<p>S Han, H Schoelkopf, Y Zhao, Z Qi, M Riddell, L Benson, L Sun, E Zubova, Y Qiao, M Burtell, arXiv:2209.00840Folio: Natural language reasoning with first-order logic. 2022arXiv preprint</p>
<p>. E J Hu, yelong shen</p>
<p>LoRA: Low-Rank Adaptation of Large Language Models. P Wallis, Z Allen-Zhu, Y Li, S Wang, L Wang, W Chen, International Conference on Learning Representations. 2022</p>
<p>A Q Jiang, A Sablayrolles, A Mensch, C Bamford, D S Chaplot, D Casas, F Bressand, G Lengyel, G Lample, L Saulnier, arXiv:2310.06825Mistral 7B. 2023arXiv preprint</p>
<p>Decoupled Weight Decay Regularization. I Loshchilov, F Hutter, ICLR 20197th International Conference on Learning Representations. New Orleans, LA, USA2019. May 6-9, 2019OpenReview.net</p>
<p>Neurologic a* esque decoding: Constrained text generation with lookahead heuristics. X Lu, S Welleck, P West, L Jiang, J Kasai, D Khashabi, R L Bras, L Qin, Y Yu, R Zellers, arXiv:2112.087262021arXiv preprint</p>
<p>Neurologic decoding:(un) supervised neural text generation with predicate logic constraints. X Lu, P West, R Zellers, R L Bras, C Bhagavatula, Y Choi, arXiv:2010.128842020arXiv preprint</p>
<p>Release of prover9. W Mccune, Mile high conference on quasigroups, loops and nonassociative systems. Denver, Colorado2005</p>
<p>Improving coherence and consistency in neural sequence models with dual-system, neuro-symbolic reasoning. M Nye, M Tessler, J Tenenbaum, B M Lake, Advances in Neural Information Processing Systems. 202134</p>
<p>LINC: A neurosymbolic approach for logical reasoning by combining language models with first-order logic provers. T X Olausson, A Gu, B Lipkin, C E Zhang, A Solar-Lezama, J B Tenenbaum, R Levy, arXiv:2310.151642023arXiv preprint</p>
<p>Logic-LM: Empowering Large Language Models with Symbolic Solvers for Faithful Logical Reasoning. L Pan, A Albalak, X Wang, W Wang, Findings of the Association for Computational Linguistics: EMNLP 2023. H Bouamor, J Pino, K Bali, Association for Computational Linguistics2023Singapore</p>
<p>Exploring the limits of transfer learning with a unified text-to-text transformer. G Poesia, K Gandhi, E Zelikman, N D Goodman, C Raffel, N Shazeer, A Roberts, K Lee, S Narang, M Matena, Y Zhou, W Li, P J Liu, arXiv:2306.04031Certified deductive reasoning with language models. 2023. 202021arXiv preprint</p>
<p>Language models are greedy reasoners: A systematic formal analysis of chain-of-thought. A Saparov, H He, arXiv:2210.012402022arXiv preprint</p>
<p>Harnessing the Power of Large Language Models for Natural Language to First-Order Logic Translation. Y Su, X Fu, M Liu, Z Guo, O Tafjord, B D Mishra, P Clark, H Touvron, T Lavril, G Izacard, X Martinet, M.-A Lachaux, T Lacroix, B Rozière, N Goyal, E Hambro, F Azhar, arXiv:2311.06736arXiv:2302.13971Are LLMs Rigorous Logical Reasoner? Empowering Natural Language Proof Generation with Contrastive Stepwise Decoding. Long Papers. L.-W Ku, A Martins, V Srikumar, Bangkok, ThailandAssociation for Computational Linguistics2023. 2020. 2023. 20241arXiv preprintProceedings of the 62nd Annual Meeting of the Association for Computational Linguistics</p>
<p>Satlm: Satisfiability-aided language models using declarative prompting. X Ye, Q Chen, I Dillig, G Durrett, Advances in Neural Information Processing Systems. 202436</p>            </div>
        </div>

    </div>
</body>
</html>