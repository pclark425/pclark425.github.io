<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1537 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1537</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1537</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-29.html">extraction-schema-29</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <p><strong>Paper ID:</strong> paper-396e494d2cd84b873e9f2280c9515a9de34d0118</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/396e494d2cd84b873e9f2280c9515a9de34d0118" target="_blank">Quantifying the Reality Gap in Robotic Manipulation Tasks</a></p>
                <p><strong>Paper Venue:</strong> IEEE International Conference on Robotics and Automation</p>
                <p><strong>Paper TL;DR:</strong> It is quantified the accuracy of various simulators compared to a real world robotic reaching and interaction task, and shows the relative strengths and weaknesses of numerous contemporary simulators, assisting researchers in the field in their selection of appropriate simulators for their use cases.</p>
                <p><strong>Paper Abstract:</strong> We quantify the accuracy of various simulators compared to a real world robotic reaching and interaction task. Simulators are used in robotics to design solutions for real world hardware without the need for physical access. The ‘reality gap’ prevents solutions developed or learnt in simulation from performing well, or at all, when transferred to real-world hardware. Making use of a Kinova robotic manipulator and a motion capture system, we record a ground truth enabling comparisons with various simulators, and present quantitative data for various manipulation-oriented robotic tasks. We show the relative strengths and weaknesses of numerous contemporary simulators, highlighting areas of significant discrepancy, and assisting researchers in the field in their selection of appropriate simulators for their use cases.</p>
                <p><strong>Cost:</strong> 0.018</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1537.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1537.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MuJoCo</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>MuJoCo (Multi-Joint dynamics with Contact)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A high-performance physics engine and simulator for model-based control of articulated systems, used here (via mujoco-py) to simulate a 6DOF Kinova manipulator and object interactions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Quantifying the Reality Gap in Robotic Manipulation Tasks</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_name</strong></td>
                            <td>MuJoCo</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_description</strong></td>
                            <td>Physics engine for model-based control of robots; simulates rigid-body dynamics with contact handling and actuators. Used via the mujoco-py Python wrapper; URDF converted to MuJoCo XML and actuators/sensors added.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>mechanics / robotic manipulation</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_level</strong></td>
                            <td>medium-to-high fidelity for rigid-body dynamics (tuned timestep and actuators), but limited/incorrect contact behaviour for some interaction scenarios</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_characteristics</strong></td>
                            <td>small simulator timestep set to 0.0001s for stable integration; requires conversion of URDF to XML and manual actuator/sensor specification; models inertia, gravity and contacts but produced unrealistic cube rotations in interaction tests (indicating limitations in contact modelling).</td>
                        </tr>
                        <tr>
                            <td><strong>model_or_agent_name</strong></td>
                            <td>Proportional joint-velocity controller (Kinova controller)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>A basic proportional feedback controller issuing joint velocity commands at 5 Hz (same controller used in both sim and real-world experiments). Not a learned ML agent in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task</strong></td>
                            <td>Robotic manipulation tasks (single-joint motion, multi-joint coordinated motion, and pushing a cube along a plane) — i.e., reproducing real-world kinematics and dynamics of a manipulator and object interaction.</td>
                        </tr>
                        <tr>
                            <td><strong>training_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_target</strong></td>
                            <td>Real-world Kinova Mico2 manipulator (motion-capture ground truth comparison)</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance</strong></td>
                            <td>Quantified sim-to-real discrepancy in position over experiments: Total accumulated positional error (across three scenes) = 97.138 (units reported in paper: metres, Table I). Scene-specific: MuJoCo produced the earliest cube contact (~11.4s) and moved the cube 0.1137 m (compared to real 0.0975 m) but produced ~90° pitch rotation (unrealistic).</td>
                        </tr>
                        <tr>
                            <td><strong>compares_fidelity_levels</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td>MuJoCo was comparatively good at initiating early interaction with the cube and produced large cube displacement, but contact dynamics were unrealistic (large rotation). For kinematic control MuJoCo was less accurate than Newton, Vortex or PyBullet for some motion segments; overall MuJoCo had higher cumulative error than the best-performing engines (Table I).</td>
                        </tr>
                        <tr>
                            <td><strong>minimal_fidelity_discussion</strong></td>
                            <td>Paper concludes that accurate kinematic control is largely solvable but that realistic contact/interaction physics (friction, contact resolution, multi-body contact) are needed to close the reality gap; MuJoCo's failures in contact suggest contact fidelity is critical.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>Despite stable integration, MuJoCo produced unrealistic cube rotation (~90° pitch) during push interactions, indicating contact modelling failures; had higher cumulative error (97.138) relative to best engines.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Quantifying the Reality Gap in Robotic Manipulation Tasks', 'publication_date_yy_mm': '2018-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1537.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e1537.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PyBullet</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>PyBullet (Bullet physics via Python)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Python module exposing the Bullet physics engine for robotics, games and ML; in this paper used to simulate the Kinova arm and cube with an explicitly set timestep.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Quantifying the Reality Gap in Robotic Manipulation Tasks</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_name</strong></td>
                            <td>PyBullet (Bullet)</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_description</strong></td>
                            <td>Real-time rigid-body dynamics and collision/contact simulation (Bullet) accessed via the PyBullet Python API; used here with a fixed timestep of 0.01s.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>mechanics / robotic manipulation</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_level</strong></td>
                            <td>medium-fidelity: real-time-orientated rigid-body dynamics with contact/collision; good kinematic/control fidelity in these experiments but limitations in some interactions</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_characteristics</strong></td>
                            <td>discrete fixed timestep of 0.01s (explicitly set by authors); default friction/inertia and actuator defaults used unless changed; in experiments PyBullet often modelled kinematic control accurately but sometimes failed to produce expected object interaction (e.g., gripper passed over cube in one scene).</td>
                        </tr>
                        <tr>
                            <td><strong>model_or_agent_name</strong></td>
                            <td>Proportional joint-velocity controller (Kinova controller)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Basic proportional feedback joint-velocity controller used consistently across sims and real robot; not a learned agent here.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task</strong></td>
                            <td>Robotic manipulation and interaction (trajectory following and pushing a cube).</td>
                        </tr>
                        <tr>
                            <td><strong>training_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_target</strong></td>
                            <td>Real-world Kinova manipulator (motion-capture ground truth comparison)</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance</strong></td>
                            <td>Total accumulated positional error (three scenes) = 45.513 (Table I), one of the best cumulative performers; however, in the cube-push Scene PyBullet did not make contact (gripper moved over cube), so interaction transfer failed for that scene.</td>
                        </tr>
                        <tr>
                            <td><strong>compares_fidelity_levels</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td>PyBullet (as used) produced low cumulative error and good kinematic fidelity, outperforming V-Rep's Bullet integrations; however, it failed to model some interactions (no cube contact) indicating good kinematics but imperfect contact modelling.</td>
                        </tr>
                        <tr>
                            <td><strong>minimal_fidelity_discussion</strong></td>
                            <td>Paper suggests that sim features required for transfer include accurate joint/actuator dynamics and contact modelling; PyBullet's strong kinematic results but failed interactions illustrate that contact fidelity is necessary for manipulation transfer.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>In Scene 3 PyBullet's simulated gripper passed over the cube (no interaction), demonstrating a failure in contact detection/resolution for that setup despite good kinematic fidelity.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Quantifying the Reality Gap in Robotic Manipulation Tasks', 'publication_date_yy_mm': '2018-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1537.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e1537.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>V-Rep</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>V-Rep (now CoppeliaSim)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A versatile and scalable robot simulation framework supporting multiple physics engines (Bullet, Newton, Vortex, ODE) used here to host different engine implementations and compare to real-world motion-capture.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Quantifying the Reality Gap in Robotic Manipulation Tasks</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_name</strong></td>
                            <td>V-Rep (with multiple physics engines: Bullet 2.78/2.83, Newton, Vortex, ODE)</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_description</strong></td>
                            <td>General-purpose robotics simulator with plugin support for multiple physics engines and a scripting/API interface; used here with various internal engine choices to test fidelity differences.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>mechanics / robotic manipulation</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_level</strong></td>
                            <td>variable fidelity depending on the embedded physics engine; when using Newton/Vortex produced good kinematic fidelity; Bullet integrations in V-Rep showed higher cumulative error in these experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_characteristics</strong></td>
                            <td>Authors left most parameters at defaults for each V-Rep engine; V-Rep's default timestep differs from PyBullet (e.g., generic V-Rep default ~0.05s vs PyBullet's 0.01s set by authors), which affected performance; some embedded engines (ODE) were unstable with this model.</td>
                        </tr>
                        <tr>
                            <td><strong>model_or_agent_name</strong></td>
                            <td>Proportional joint-velocity controller (Kinova controller)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Basic proportional feedback controller issuing joint velocity commands at 5 Hz; used across simulators for comparison.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task</strong></td>
                            <td>Robotic manipulation tasks (reaching, multi-joint motion, and object pushing).</td>
                        </tr>
                        <tr>
                            <td><strong>training_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_target</strong></td>
                            <td>Real-world Kinova robot</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance</strong></td>
                            <td>Cumulative position errors varied by engine within V-Rep: V-Rep (Newton) total = 45.458; V-Rep (Vortex) total = 45.680; V-Rep (Bullet2.78) total = 133.611; V-Rep (Bullet2.83) total = 131.916; ODE unstable produced extremely large errors (1.31e+17 to 1.88e+18).</td>
                        </tr>
                        <tr>
                            <td><strong>compares_fidelity_levels</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td>Within V-Rep, Newton and Vortex gave low accumulated errors and closely followed motion-capture for control tasks; V-Rep's Bullet integrations performed much worse, suggesting that both engine choice and default parameter settings strongly affect fidelity.</td>
                        </tr>
                        <tr>
                            <td><strong>minimal_fidelity_discussion</strong></td>
                            <td>Paper argues that choosing the appropriate physics engine and tuning contact/solver parameters is important; leaving defaults can lead to large reality gaps (e.g., V-Rep+BULLET defaults performed poorly).</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>ODE in V-Rep was unstable for this Kinova URDF (very large accumulated error). V-Rep's Bullet implementations had much larger cumulative errors than PyBullet (despite both using Bullet), illustrating configuration and integration differences can cause failures.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Quantifying the Reality Gap in Robotic Manipulation Tasks', 'publication_date_yy_mm': '2018-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1537.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e1537.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Bullet</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Bullet Physics Library</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A widely-used open-source rigid-body physics engine for real-time simulation of collision, contact and dynamics; appears in this paper both via PyBullet and V-Rep integrations (two versions: 2.78 and 2.83).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Quantifying the Reality Gap in Robotic Manipulation Tasks</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_name</strong></td>
                            <td>Bullet (via PyBullet and V-Rep integrations, versions 2.78 and 2.83)</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_description</strong></td>
                            <td>Real-time rigid-body dynamics and collision/contact solver used in robotics and games; integrated differently by different simulators (standalone PyBullet vs V-Rep's internal integration).</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>mechanics / robotic manipulation</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_level</strong></td>
                            <td>medium-fidelity; real-time oriented with discrete timesteps; fidelity depends strongly on integration and default parameters set by host simulator.</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_characteristics</strong></td>
                            <td>Different hosts used different default timesteps (PyBullet explicitly set to 0.01s; V-Rep used larger default ~0.05s), solvers and integration options; produced oscillations in joint convergence in some versions and unrealistic cube rotations in others; contact handling varies by host integration.</td>
                        </tr>
                        <tr>
                            <td><strong>model_or_agent_name</strong></td>
                            <td>Proportional joint-velocity controller (as test controller)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Controller is a basic proportional controller; the paper did not train a learning agent using Bullet but evaluated its simulation fidelity.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task</strong></td>
                            <td>Simulation of robotic kinematics and dynamic interactions (reach and push tasks).</td>
                        </tr>
                        <tr>
                            <td><strong>training_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_target</strong></td>
                            <td>Real-world Kinova arm</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance</strong></td>
                            <td>Performance varied by integration: PyBullet (Bullet) total error = 45.513; V-Rep (Bullet2.78) total = 133.611; V-Rep (Bullet2.83) total = 131.916. Some Bullet variants exhibited oscillatory convergence and unrealistic contact outcomes (e.g., 90° cube rotation).</td>
                        </tr>
                        <tr>
                            <td><strong>compares_fidelity_levels</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td>Host integration and configuration (timesteps, solver settings) produce large fidelity differences even for the same underlying engine: standalone PyBullet performed much better than V-Rep's Bullet integrations in these tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>minimal_fidelity_discussion</strong></td>
                            <td>Paper emphasizes that engine choice alone is insufficient; integration details and parameter defaults materially affect transfer — thus minimal fidelity must include appropriate timestep/solver/contact parameter configuration.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>V-Rep's Bullet integrations had much worse cumulative error; some Bullet variants produced large oscillations and incorrect object rotations (interaction failure).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Quantifying the Reality Gap in Robotic Manipulation Tasks', 'publication_date_yy_mm': '2018-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1537.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e1537.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Newton</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Newton Game Dynamics (Newton)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A rigid-body physics engine (Newton) used within V-Rep for simulating the Kinova arm; in experiments provided good kinematic fidelity for control segments.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Quantifying the Reality Gap in Robotic Manipulation Tasks</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_name</strong></td>
                            <td>Newton (as used inside V-Rep)</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_description</strong></td>
                            <td>A physics engine focused on accurate rigid-body dynamics used within V-Rep; exhibited good kinematic control fidelity in the experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>mechanics / robotic manipulation</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_level</strong></td>
                            <td>medium-fidelity for kinematics/control; contact modelling adequate for some interactions but not perfect.</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_characteristics</strong></td>
                            <td>Used with V-Rep default parameters; produced low accumulated error on kinematic/control tasks (Table I), indicating good joint/actuator modelling for this robot model under default settings.</td>
                        </tr>
                        <tr>
                            <td><strong>model_or_agent_name</strong></td>
                            <td>Proportional joint-velocity controller</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Basic proportional joint-velocity feedback controller used consistently across simulations.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task</strong></td>
                            <td>Trajectory following and manipulation control tasks (kinematics focus).</td>
                        </tr>
                        <tr>
                            <td><strong>training_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_target</strong></td>
                            <td>Real-world Kinova arm</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance</strong></td>
                            <td>V-Rep (Newton) total accumulated positional error = 45.458 (Table I), comparable to best performing engines for kinematic accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>compares_fidelity_levels</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td>Newton (inside V-Rep) was among the best for modelling manipulator control, suggesting some engines better capture joint/actuator dynamics under default settings.</td>
                        </tr>
                        <tr>
                            <td><strong>minimal_fidelity_discussion</strong></td>
                            <td>Paper implies accurate actuator and kinematic modelling (as seen with Newton) is obtainable, but contact fidelity remains a bottleneck for manipulation transfer.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>Although Newton modelled kinematics well, no engine perfectly modelled multi-body contact dynamics; interactions still diverged from reality.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Quantifying the Reality Gap in Robotic Manipulation Tasks', 'publication_date_yy_mm': '2018-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1537.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e1537.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Vortex</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Vortex (CM Labs)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A commercial physics engine (Vortex) available in V-Rep; in these experiments it modelled the Kinova arm kinematics closely and had low cumulative error for control tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Quantifying the Reality Gap in Robotic Manipulation Tasks</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_name</strong></td>
                            <td>Vortex (via V-Rep)</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_description</strong></td>
                            <td>Physics engine targeting simulation of articulated systems and multi-body contact; used within V-Rep with default settings in the paper's experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>mechanics / robotic manipulation</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_level</strong></td>
                            <td>medium-fidelity for kinematics and some contact behaviour; good for control segments in these tests but not perfect for complex interactions.</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_characteristics</strong></td>
                            <td>Used with V-Rep defaults; produced similar low accumulated error to Newton for joint control tasks (Table I); contact behaviour still not fully realistic for pushing interactions.</td>
                        </tr>
                        <tr>
                            <td><strong>model_or_agent_name</strong></td>
                            <td>Proportional joint-velocity controller</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Basic proportional controller issuing joint velocities.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task</strong></td>
                            <td>Robotic control and manipulation (reach and push tasks).</td>
                        </tr>
                        <tr>
                            <td><strong>training_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_target</strong></td>
                            <td>Real-world Kinova arm</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance</strong></td>
                            <td>V-Rep (Vortex) total accumulated error = 45.680 (Table I); tracked motion-capture closely for many control segments.</td>
                        </tr>
                        <tr>
                            <td><strong>compares_fidelity_levels</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td>Vortex performed on par with Newton for control tasks, indicating that some engines provide acceptable kinematic fidelity out-of-the-box.</td>
                        </tr>
                        <tr>
                            <td><strong>minimal_fidelity_discussion</strong></td>
                            <td>Paper suggests such engines may suffice for kinematic learning/control but that improved contact fidelity is necessary for manipulation tasks involving object interactions.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>Although Vortex modelled control well, it exhibited limited fidelity in the cube interaction (minimal cube displacement due to poor contact in one scenario).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Quantifying the Reality Gap in Robotic Manipulation Tasks', 'publication_date_yy_mm': '2018-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1537.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e1537.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ODE</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Open Dynamics Engine (ODE)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An open-source rigid-body dynamics engine; when used via V-Rep in this study it became unstable for the Kinova URDF and produced extremely large errors.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Quantifying the Reality Gap in Robotic Manipulation Tasks</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_name</strong></td>
                            <td>ODE (via V-Rep)</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_description</strong></td>
                            <td>A real-time rigid-body dynamics engine; in this paper used through V-Rep with default settings resulting in unstable simulation for this robot model.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>mechanics / robotic manipulation</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_level</strong></td>
                            <td>low-to-medium fidelity in this configuration—unstable for the tested model under default settings</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_characteristics</strong></td>
                            <td>Left at V-Rep defaults; produced self-contacts/instability for the Kinova URDF causing simulation divergence and massive accumulated errors.</td>
                        </tr>
                        <tr>
                            <td><strong>model_or_agent_name</strong></td>
                            <td>Proportional joint-velocity controller</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Basic proportional controller; instability prevented meaningful evaluation of control or transfer.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task</strong></td>
                            <td>Trajectory following and manipulation (attempted), but simulation instability prevented useful interaction testing.</td>
                        </tr>
                        <tr>
                            <td><strong>training_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_target</strong></td>
                            <td>Real-world Kinova arm</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance</strong></td>
                            <td>Reported extremely large accumulated errors: 1.31e+17 (1 Joint), 1.19e+18 (2 Joints), 1.88e+18 (Cube), total 3.20e+18 (Table I) — indicative of simulation failure.</td>
                        </tr>
                        <tr>
                            <td><strong>compares_fidelity_levels</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td>ODE failed catastrophically in this setup, demonstrating that engine-host combinations and defaults can yield unusable fidelity.</td>
                        </tr>
                        <tr>
                            <td><strong>minimal_fidelity_discussion</strong></td>
                            <td>Paper highlights that default parameters can make an otherwise-capable engine unusable; therefore minimum fidelity includes stable solver settings and reasonable defaults for the specific robot model.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>ODE produced unstable simulation with self-contacts for the Kinova arm in V-Rep leading to simulation divergence and unusable results.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Quantifying the Reality Gap in Robotic Manipulation Tasks', 'publication_date_yy_mm': '2018-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1537.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e1537.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Domain Adaptation (Bousmalis et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Using Simulation and Domain Adaptation to Improve Efficiency of Deep Robotic Grasping (Bousmalis et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Referenced work reporting sim-to-real transfer for grasping using simulation plus domain adaptation, achieving substantial real-world grasp success when training in simulation supplemented with adaptation techniques.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Using Simulation and Domain Adaptation to Improve Efficiency of Deep Robotic Grasping</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_name</strong></td>
                            <td>Simulation + Domain Adaptation (technique, paper-level)</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_description</strong></td>
                            <td>Approach trains deep visuomotor policies in simulation, then uses domain adaptation techniques (including access to some real data) to improve transfer to real-world grasping tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>robotic manipulation / vision-guided grasping</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_level</strong></td>
                            <td>approach leverages simulation as a training scaffold plus data-driven adaptation — simulation fidelity need not be perfect if adaptation is effective (paper implication).</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_characteristics</strong></td>
                            <td>Method uses simulated images and domain adaptation; requires both simulated and some real-world data for adaptation phases; does not rely solely on high-fidelity contact physics.</td>
                        </tr>
                        <tr>
                            <td><strong>model_or_agent_name</strong></td>
                            <td>Deep visuomotor grasping model (unspecified in this paper, referenced work used CNN-based visuomotor policies)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Deep learning based visuomotor policy trained in simulation then adapted using domain adaptation techniques (GANs or other methods).</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task</strong></td>
                            <td>Real-world robotic grasp success for unseen objects (grasp detection/execution).</td>
                        </tr>
                        <tr>
                            <td><strong>training_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_target</strong></td>
                            <td>Real-world grasping tasks (unseen objects)</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance</strong></td>
                            <td>Referenced result: achieved 76.7% real-world grasp success rate on a dataset of unseen objects when using simulation + domain adaptation (as reported in this paper's related work).</td>
                        </tr>
                        <tr>
                            <td><strong>compares_fidelity_levels</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td>Not detailed in this paper beyond the referenced success number; implied that domain adaptation can compensate for some simulation inaccuracies.</td>
                        </tr>
                        <tr>
                            <td><strong>minimal_fidelity_discussion</strong></td>
                            <td>Referenced work supports the idea that with adaptation, perfect simulation fidelity is not strictly necessary for useful transfer; however, this paper emphasizes that contact fidelity remains a key challenge for pure sim-to-real transfer.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>Not detailed here; referenced work requires some real-world data for effective domain adaptation and may not fully remove errors due to contact dynamics.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Quantifying the Reality Gap in Robotic Manipulation Tasks', 'publication_date_yy_mm': '2018-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Domain randomization for transferring deep neural networks from simulation to the real world <em>(Rating: 2)</em></li>
                <li>Using Simulation and Domain Adaptation to Improve Efficiency of Deep Robotic Grasping <em>(Rating: 2)</em></li>
                <li>Evaluation of real-time physics simulation systems <em>(Rating: 2)</em></li>
                <li>Simulation tools for model-based robotics: Comparison of Bullet, Havok, MuJoCo, ODE and PhysX <em>(Rating: 2)</em></li>
                <li>Crossing the reality gap in evolutionary robotics by promoting transferable controllers <em>(Rating: 1)</em></li>
                <li>20 Years of Reality Gap <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1537",
    "paper_id": "paper-396e494d2cd84b873e9f2280c9515a9de34d0118",
    "extraction_schema_id": "extraction-schema-29",
    "extracted_data": [
        {
            "name_short": "MuJoCo",
            "name_full": "MuJoCo (Multi-Joint dynamics with Contact)",
            "brief_description": "A high-performance physics engine and simulator for model-based control of articulated systems, used here (via mujoco-py) to simulate a 6DOF Kinova manipulator and object interactions.",
            "citation_title": "Quantifying the Reality Gap in Robotic Manipulation Tasks",
            "mention_or_use": "use",
            "simulator_name": "MuJoCo",
            "simulator_description": "Physics engine for model-based control of robots; simulates rigid-body dynamics with contact handling and actuators. Used via the mujoco-py Python wrapper; URDF converted to MuJoCo XML and actuators/sensors added.",
            "scientific_domain": "mechanics / robotic manipulation",
            "fidelity_level": "medium-to-high fidelity for rigid-body dynamics (tuned timestep and actuators), but limited/incorrect contact behaviour for some interaction scenarios",
            "fidelity_characteristics": "small simulator timestep set to 0.0001s for stable integration; requires conversion of URDF to XML and manual actuator/sensor specification; models inertia, gravity and contacts but produced unrealistic cube rotations in interaction tests (indicating limitations in contact modelling).",
            "model_or_agent_name": "Proportional joint-velocity controller (Kinova controller)",
            "model_description": "A basic proportional feedback controller issuing joint velocity commands at 5 Hz (same controller used in both sim and real-world experiments). Not a learned ML agent in this paper.",
            "reasoning_task": "Robotic manipulation tasks (single-joint motion, multi-joint coordinated motion, and pushing a cube along a plane) — i.e., reproducing real-world kinematics and dynamics of a manipulator and object interaction.",
            "training_performance": null,
            "transfer_target": "Real-world Kinova Mico2 manipulator (motion-capture ground truth comparison)",
            "transfer_performance": "Quantified sim-to-real discrepancy in position over experiments: Total accumulated positional error (across three scenes) = 97.138 (units reported in paper: metres, Table I). Scene-specific: MuJoCo produced the earliest cube contact (~11.4s) and moved the cube 0.1137 m (compared to real 0.0975 m) but produced ~90° pitch rotation (unrealistic).",
            "compares_fidelity_levels": true,
            "fidelity_comparison_results": "MuJoCo was comparatively good at initiating early interaction with the cube and produced large cube displacement, but contact dynamics were unrealistic (large rotation). For kinematic control MuJoCo was less accurate than Newton, Vortex or PyBullet for some motion segments; overall MuJoCo had higher cumulative error than the best-performing engines (Table I).",
            "minimal_fidelity_discussion": "Paper concludes that accurate kinematic control is largely solvable but that realistic contact/interaction physics (friction, contact resolution, multi-body contact) are needed to close the reality gap; MuJoCo's failures in contact suggest contact fidelity is critical.",
            "failure_cases": "Despite stable integration, MuJoCo produced unrealistic cube rotation (~90° pitch) during push interactions, indicating contact modelling failures; had higher cumulative error (97.138) relative to best engines.",
            "uuid": "e1537.0",
            "source_info": {
                "paper_title": "Quantifying the Reality Gap in Robotic Manipulation Tasks",
                "publication_date_yy_mm": "2018-11"
            }
        },
        {
            "name_short": "PyBullet",
            "name_full": "PyBullet (Bullet physics via Python)",
            "brief_description": "Python module exposing the Bullet physics engine for robotics, games and ML; in this paper used to simulate the Kinova arm and cube with an explicitly set timestep.",
            "citation_title": "Quantifying the Reality Gap in Robotic Manipulation Tasks",
            "mention_or_use": "use",
            "simulator_name": "PyBullet (Bullet)",
            "simulator_description": "Real-time rigid-body dynamics and collision/contact simulation (Bullet) accessed via the PyBullet Python API; used here with a fixed timestep of 0.01s.",
            "scientific_domain": "mechanics / robotic manipulation",
            "fidelity_level": "medium-fidelity: real-time-orientated rigid-body dynamics with contact/collision; good kinematic/control fidelity in these experiments but limitations in some interactions",
            "fidelity_characteristics": "discrete fixed timestep of 0.01s (explicitly set by authors); default friction/inertia and actuator defaults used unless changed; in experiments PyBullet often modelled kinematic control accurately but sometimes failed to produce expected object interaction (e.g., gripper passed over cube in one scene).",
            "model_or_agent_name": "Proportional joint-velocity controller (Kinova controller)",
            "model_description": "Basic proportional feedback joint-velocity controller used consistently across sims and real robot; not a learned agent here.",
            "reasoning_task": "Robotic manipulation and interaction (trajectory following and pushing a cube).",
            "training_performance": null,
            "transfer_target": "Real-world Kinova manipulator (motion-capture ground truth comparison)",
            "transfer_performance": "Total accumulated positional error (three scenes) = 45.513 (Table I), one of the best cumulative performers; however, in the cube-push Scene PyBullet did not make contact (gripper moved over cube), so interaction transfer failed for that scene.",
            "compares_fidelity_levels": true,
            "fidelity_comparison_results": "PyBullet (as used) produced low cumulative error and good kinematic fidelity, outperforming V-Rep's Bullet integrations; however, it failed to model some interactions (no cube contact) indicating good kinematics but imperfect contact modelling.",
            "minimal_fidelity_discussion": "Paper suggests that sim features required for transfer include accurate joint/actuator dynamics and contact modelling; PyBullet's strong kinematic results but failed interactions illustrate that contact fidelity is necessary for manipulation transfer.",
            "failure_cases": "In Scene 3 PyBullet's simulated gripper passed over the cube (no interaction), demonstrating a failure in contact detection/resolution for that setup despite good kinematic fidelity.",
            "uuid": "e1537.1",
            "source_info": {
                "paper_title": "Quantifying the Reality Gap in Robotic Manipulation Tasks",
                "publication_date_yy_mm": "2018-11"
            }
        },
        {
            "name_short": "V-Rep",
            "name_full": "V-Rep (now CoppeliaSim)",
            "brief_description": "A versatile and scalable robot simulation framework supporting multiple physics engines (Bullet, Newton, Vortex, ODE) used here to host different engine implementations and compare to real-world motion-capture.",
            "citation_title": "Quantifying the Reality Gap in Robotic Manipulation Tasks",
            "mention_or_use": "use",
            "simulator_name": "V-Rep (with multiple physics engines: Bullet 2.78/2.83, Newton, Vortex, ODE)",
            "simulator_description": "General-purpose robotics simulator with plugin support for multiple physics engines and a scripting/API interface; used here with various internal engine choices to test fidelity differences.",
            "scientific_domain": "mechanics / robotic manipulation",
            "fidelity_level": "variable fidelity depending on the embedded physics engine; when using Newton/Vortex produced good kinematic fidelity; Bullet integrations in V-Rep showed higher cumulative error in these experiments.",
            "fidelity_characteristics": "Authors left most parameters at defaults for each V-Rep engine; V-Rep's default timestep differs from PyBullet (e.g., generic V-Rep default ~0.05s vs PyBullet's 0.01s set by authors), which affected performance; some embedded engines (ODE) were unstable with this model.",
            "model_or_agent_name": "Proportional joint-velocity controller (Kinova controller)",
            "model_description": "Basic proportional feedback controller issuing joint velocity commands at 5 Hz; used across simulators for comparison.",
            "reasoning_task": "Robotic manipulation tasks (reaching, multi-joint motion, and object pushing).",
            "training_performance": null,
            "transfer_target": "Real-world Kinova robot",
            "transfer_performance": "Cumulative position errors varied by engine within V-Rep: V-Rep (Newton) total = 45.458; V-Rep (Vortex) total = 45.680; V-Rep (Bullet2.78) total = 133.611; V-Rep (Bullet2.83) total = 131.916; ODE unstable produced extremely large errors (1.31e+17 to 1.88e+18).",
            "compares_fidelity_levels": true,
            "fidelity_comparison_results": "Within V-Rep, Newton and Vortex gave low accumulated errors and closely followed motion-capture for control tasks; V-Rep's Bullet integrations performed much worse, suggesting that both engine choice and default parameter settings strongly affect fidelity.",
            "minimal_fidelity_discussion": "Paper argues that choosing the appropriate physics engine and tuning contact/solver parameters is important; leaving defaults can lead to large reality gaps (e.g., V-Rep+BULLET defaults performed poorly).",
            "failure_cases": "ODE in V-Rep was unstable for this Kinova URDF (very large accumulated error). V-Rep's Bullet implementations had much larger cumulative errors than PyBullet (despite both using Bullet), illustrating configuration and integration differences can cause failures.",
            "uuid": "e1537.2",
            "source_info": {
                "paper_title": "Quantifying the Reality Gap in Robotic Manipulation Tasks",
                "publication_date_yy_mm": "2018-11"
            }
        },
        {
            "name_short": "Bullet",
            "name_full": "Bullet Physics Library",
            "brief_description": "A widely-used open-source rigid-body physics engine for real-time simulation of collision, contact and dynamics; appears in this paper both via PyBullet and V-Rep integrations (two versions: 2.78 and 2.83).",
            "citation_title": "Quantifying the Reality Gap in Robotic Manipulation Tasks",
            "mention_or_use": "use",
            "simulator_name": "Bullet (via PyBullet and V-Rep integrations, versions 2.78 and 2.83)",
            "simulator_description": "Real-time rigid-body dynamics and collision/contact solver used in robotics and games; integrated differently by different simulators (standalone PyBullet vs V-Rep's internal integration).",
            "scientific_domain": "mechanics / robotic manipulation",
            "fidelity_level": "medium-fidelity; real-time oriented with discrete timesteps; fidelity depends strongly on integration and default parameters set by host simulator.",
            "fidelity_characteristics": "Different hosts used different default timesteps (PyBullet explicitly set to 0.01s; V-Rep used larger default ~0.05s), solvers and integration options; produced oscillations in joint convergence in some versions and unrealistic cube rotations in others; contact handling varies by host integration.",
            "model_or_agent_name": "Proportional joint-velocity controller (as test controller)",
            "model_description": "Controller is a basic proportional controller; the paper did not train a learning agent using Bullet but evaluated its simulation fidelity.",
            "reasoning_task": "Simulation of robotic kinematics and dynamic interactions (reach and push tasks).",
            "training_performance": null,
            "transfer_target": "Real-world Kinova arm",
            "transfer_performance": "Performance varied by integration: PyBullet (Bullet) total error = 45.513; V-Rep (Bullet2.78) total = 133.611; V-Rep (Bullet2.83) total = 131.916. Some Bullet variants exhibited oscillatory convergence and unrealistic contact outcomes (e.g., 90° cube rotation).",
            "compares_fidelity_levels": true,
            "fidelity_comparison_results": "Host integration and configuration (timesteps, solver settings) produce large fidelity differences even for the same underlying engine: standalone PyBullet performed much better than V-Rep's Bullet integrations in these tasks.",
            "minimal_fidelity_discussion": "Paper emphasizes that engine choice alone is insufficient; integration details and parameter defaults materially affect transfer — thus minimal fidelity must include appropriate timestep/solver/contact parameter configuration.",
            "failure_cases": "V-Rep's Bullet integrations had much worse cumulative error; some Bullet variants produced large oscillations and incorrect object rotations (interaction failure).",
            "uuid": "e1537.3",
            "source_info": {
                "paper_title": "Quantifying the Reality Gap in Robotic Manipulation Tasks",
                "publication_date_yy_mm": "2018-11"
            }
        },
        {
            "name_short": "Newton",
            "name_full": "Newton Game Dynamics (Newton)",
            "brief_description": "A rigid-body physics engine (Newton) used within V-Rep for simulating the Kinova arm; in experiments provided good kinematic fidelity for control segments.",
            "citation_title": "Quantifying the Reality Gap in Robotic Manipulation Tasks",
            "mention_or_use": "use",
            "simulator_name": "Newton (as used inside V-Rep)",
            "simulator_description": "A physics engine focused on accurate rigid-body dynamics used within V-Rep; exhibited good kinematic control fidelity in the experiments.",
            "scientific_domain": "mechanics / robotic manipulation",
            "fidelity_level": "medium-fidelity for kinematics/control; contact modelling adequate for some interactions but not perfect.",
            "fidelity_characteristics": "Used with V-Rep default parameters; produced low accumulated error on kinematic/control tasks (Table I), indicating good joint/actuator modelling for this robot model under default settings.",
            "model_or_agent_name": "Proportional joint-velocity controller",
            "model_description": "Basic proportional joint-velocity feedback controller used consistently across simulations.",
            "reasoning_task": "Trajectory following and manipulation control tasks (kinematics focus).",
            "training_performance": null,
            "transfer_target": "Real-world Kinova arm",
            "transfer_performance": "V-Rep (Newton) total accumulated positional error = 45.458 (Table I), comparable to best performing engines for kinematic accuracy.",
            "compares_fidelity_levels": true,
            "fidelity_comparison_results": "Newton (inside V-Rep) was among the best for modelling manipulator control, suggesting some engines better capture joint/actuator dynamics under default settings.",
            "minimal_fidelity_discussion": "Paper implies accurate actuator and kinematic modelling (as seen with Newton) is obtainable, but contact fidelity remains a bottleneck for manipulation transfer.",
            "failure_cases": "Although Newton modelled kinematics well, no engine perfectly modelled multi-body contact dynamics; interactions still diverged from reality.",
            "uuid": "e1537.4",
            "source_info": {
                "paper_title": "Quantifying the Reality Gap in Robotic Manipulation Tasks",
                "publication_date_yy_mm": "2018-11"
            }
        },
        {
            "name_short": "Vortex",
            "name_full": "Vortex (CM Labs)",
            "brief_description": "A commercial physics engine (Vortex) available in V-Rep; in these experiments it modelled the Kinova arm kinematics closely and had low cumulative error for control tasks.",
            "citation_title": "Quantifying the Reality Gap in Robotic Manipulation Tasks",
            "mention_or_use": "use",
            "simulator_name": "Vortex (via V-Rep)",
            "simulator_description": "Physics engine targeting simulation of articulated systems and multi-body contact; used within V-Rep with default settings in the paper's experiments.",
            "scientific_domain": "mechanics / robotic manipulation",
            "fidelity_level": "medium-fidelity for kinematics and some contact behaviour; good for control segments in these tests but not perfect for complex interactions.",
            "fidelity_characteristics": "Used with V-Rep defaults; produced similar low accumulated error to Newton for joint control tasks (Table I); contact behaviour still not fully realistic for pushing interactions.",
            "model_or_agent_name": "Proportional joint-velocity controller",
            "model_description": "Basic proportional controller issuing joint velocities.",
            "reasoning_task": "Robotic control and manipulation (reach and push tasks).",
            "training_performance": null,
            "transfer_target": "Real-world Kinova arm",
            "transfer_performance": "V-Rep (Vortex) total accumulated error = 45.680 (Table I); tracked motion-capture closely for many control segments.",
            "compares_fidelity_levels": true,
            "fidelity_comparison_results": "Vortex performed on par with Newton for control tasks, indicating that some engines provide acceptable kinematic fidelity out-of-the-box.",
            "minimal_fidelity_discussion": "Paper suggests such engines may suffice for kinematic learning/control but that improved contact fidelity is necessary for manipulation tasks involving object interactions.",
            "failure_cases": "Although Vortex modelled control well, it exhibited limited fidelity in the cube interaction (minimal cube displacement due to poor contact in one scenario).",
            "uuid": "e1537.5",
            "source_info": {
                "paper_title": "Quantifying the Reality Gap in Robotic Manipulation Tasks",
                "publication_date_yy_mm": "2018-11"
            }
        },
        {
            "name_short": "ODE",
            "name_full": "Open Dynamics Engine (ODE)",
            "brief_description": "An open-source rigid-body dynamics engine; when used via V-Rep in this study it became unstable for the Kinova URDF and produced extremely large errors.",
            "citation_title": "Quantifying the Reality Gap in Robotic Manipulation Tasks",
            "mention_or_use": "use",
            "simulator_name": "ODE (via V-Rep)",
            "simulator_description": "A real-time rigid-body dynamics engine; in this paper used through V-Rep with default settings resulting in unstable simulation for this robot model.",
            "scientific_domain": "mechanics / robotic manipulation",
            "fidelity_level": "low-to-medium fidelity in this configuration—unstable for the tested model under default settings",
            "fidelity_characteristics": "Left at V-Rep defaults; produced self-contacts/instability for the Kinova URDF causing simulation divergence and massive accumulated errors.",
            "model_or_agent_name": "Proportional joint-velocity controller",
            "model_description": "Basic proportional controller; instability prevented meaningful evaluation of control or transfer.",
            "reasoning_task": "Trajectory following and manipulation (attempted), but simulation instability prevented useful interaction testing.",
            "training_performance": null,
            "transfer_target": "Real-world Kinova arm",
            "transfer_performance": "Reported extremely large accumulated errors: 1.31e+17 (1 Joint), 1.19e+18 (2 Joints), 1.88e+18 (Cube), total 3.20e+18 (Table I) — indicative of simulation failure.",
            "compares_fidelity_levels": true,
            "fidelity_comparison_results": "ODE failed catastrophically in this setup, demonstrating that engine-host combinations and defaults can yield unusable fidelity.",
            "minimal_fidelity_discussion": "Paper highlights that default parameters can make an otherwise-capable engine unusable; therefore minimum fidelity includes stable solver settings and reasonable defaults for the specific robot model.",
            "failure_cases": "ODE produced unstable simulation with self-contacts for the Kinova arm in V-Rep leading to simulation divergence and unusable results.",
            "uuid": "e1537.6",
            "source_info": {
                "paper_title": "Quantifying the Reality Gap in Robotic Manipulation Tasks",
                "publication_date_yy_mm": "2018-11"
            }
        },
        {
            "name_short": "Domain Adaptation (Bousmalis et al.)",
            "name_full": "Using Simulation and Domain Adaptation to Improve Efficiency of Deep Robotic Grasping (Bousmalis et al.)",
            "brief_description": "Referenced work reporting sim-to-real transfer for grasping using simulation plus domain adaptation, achieving substantial real-world grasp success when training in simulation supplemented with adaptation techniques.",
            "citation_title": "Using Simulation and Domain Adaptation to Improve Efficiency of Deep Robotic Grasping",
            "mention_or_use": "mention",
            "simulator_name": "Simulation + Domain Adaptation (technique, paper-level)",
            "simulator_description": "Approach trains deep visuomotor policies in simulation, then uses domain adaptation techniques (including access to some real data) to improve transfer to real-world grasping tasks.",
            "scientific_domain": "robotic manipulation / vision-guided grasping",
            "fidelity_level": "approach leverages simulation as a training scaffold plus data-driven adaptation — simulation fidelity need not be perfect if adaptation is effective (paper implication).",
            "fidelity_characteristics": "Method uses simulated images and domain adaptation; requires both simulated and some real-world data for adaptation phases; does not rely solely on high-fidelity contact physics.",
            "model_or_agent_name": "Deep visuomotor grasping model (unspecified in this paper, referenced work used CNN-based visuomotor policies)",
            "model_description": "Deep learning based visuomotor policy trained in simulation then adapted using domain adaptation techniques (GANs or other methods).",
            "reasoning_task": "Real-world robotic grasp success for unseen objects (grasp detection/execution).",
            "training_performance": null,
            "transfer_target": "Real-world grasping tasks (unseen objects)",
            "transfer_performance": "Referenced result: achieved 76.7% real-world grasp success rate on a dataset of unseen objects when using simulation + domain adaptation (as reported in this paper's related work).",
            "compares_fidelity_levels": null,
            "fidelity_comparison_results": "Not detailed in this paper beyond the referenced success number; implied that domain adaptation can compensate for some simulation inaccuracies.",
            "minimal_fidelity_discussion": "Referenced work supports the idea that with adaptation, perfect simulation fidelity is not strictly necessary for useful transfer; however, this paper emphasizes that contact fidelity remains a key challenge for pure sim-to-real transfer.",
            "failure_cases": "Not detailed here; referenced work requires some real-world data for effective domain adaptation and may not fully remove errors due to contact dynamics.",
            "uuid": "e1537.7",
            "source_info": {
                "paper_title": "Quantifying the Reality Gap in Robotic Manipulation Tasks",
                "publication_date_yy_mm": "2018-11"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Domain randomization for transferring deep neural networks from simulation to the real world",
            "rating": 2
        },
        {
            "paper_title": "Using Simulation and Domain Adaptation to Improve Efficiency of Deep Robotic Grasping",
            "rating": 2
        },
        {
            "paper_title": "Evaluation of real-time physics simulation systems",
            "rating": 2
        },
        {
            "paper_title": "Simulation tools for model-based robotics: Comparison of Bullet, Havok, MuJoCo, ODE and PhysX",
            "rating": 2
        },
        {
            "paper_title": "Crossing the reality gap in evolutionary robotics by promoting transferable controllers",
            "rating": 1
        },
        {
            "paper_title": "20 Years of Reality Gap",
            "rating": 1
        }
    ],
    "cost": 0.017723,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Quantifying the Reality Gap in Robotic Manipulation Tasks</h1>
<p>Jack Collins ${ }^{1,2}$, David Howard ${ }^{2}$ and Jürgen Leitner ${ }^{1,3}$</p>
<h4>Abstract</h4>
<p>We quantify the accuracy of various simulators compared to a real world robotic reaching and interaction task. Simulators are used in robotics to design solutions for real world hardware without the need for physical access. The 'reality gap' prevents solutions developed or learnt in simulation from performing well, or at at all, when transferred to real-world hardware. Making use of a Kinova robotic manipulator and a motion capture system, we record a ground truth enabling comparisons with various simulators, and present quantitative data for various manipulation-oriented robotic tasks. We show the relative strengths and weaknesses of numerous contemporary simulators, highlighting areas of significant discrepancy, and assisting researchers in the field in their selection of appropriate simulators for their use cases. All code and parameter listings are publicly available from: https://bitbucket.csiro.au/scm/ col549/quantifying-the-reality-gap-in-robotic-manipulation-tasks.git.</p>
<h2>I. INTRODUCTION</h2>
<p>Simulators are widely used in the robotics community as they allow for real world systems to be quickly and cheaply prototyped without the need for physical access to hardware. Although used throughout robotics as a whole, simulators are particularly amenable to usage in robotic learning research.</p>
<p>The advent of data-hungry Deep Learning approaches, particularly Reinforcement Learning, heavily employ simulation to overcome the high costs intrinsic to repeated realworld data collection experiments, as well as obviating potential damage to expensive hardware during the early stages of learning. Simulated environments harness increasingly powerful and ubiquitous compute resources to cheaply and quickly generate synthetic data to accelerate the learning process. The use of simulation over reality carries numerous advantages, namely:</p>
<ul>
<li>No wear or damage to real-world hardware.</li>
<li>Many instantiations of a simulation can run in parallel;</li>
<li>(Often) Faster than real-time operation;</li>
<li>Instant access to robots without having to purchase; and</li>
<li>Human intervention is not required;</li>
</ul>
<p>However, these benefits come with downsides; primarily that there are discrepancies between simulations and the real world brought about by the necessity to abstract, approximate, or remove certain physical phenomena, which prevents control systems created in simulation from performing to the same standard in reality. Learning-based approaches are known to exploit situations and achieve goals which are</p>
<p>This research was supported by a Data61 PhD Scholarship. This research was further supported by the Australian Research Council Centre of Excellence for Robotic Vision (project number CE140100016).
${ }^{1}$ Queensland University of Technology (QUT), Brisbane, Australia
${ }^{2}$ Data61/CSIRO, Brisbane, Australia
${ }^{3}$ Australian Centre for Robotic Vision (ACRV)
<img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Fig. 1. Real-World and simulated environments with the Kinova arm and cube visualised. (A) Real-world setup with tracking markers attached to dynamic elements; (B) the MuJoCo environment; (C) the PyBullet environment; (D) the V-Rep environment.
simulated artefacts and not realistically plausible in the real world [1], further complicating the transfer to real world robotic applications. This disparity is a prominent issue with recent efforts in sim-to-real learning [2], [3], as well as in Evolutionary Robotics (where simulations are crucial to speeding up these iterative, population-based algorithms), where it is referred to as 'Reality Gap' [4]. Gaps mainly relate to actuators (i.e. torque characteristics, gear backlash, ...), sensors (i.e. sensor noise, latencies, and faults), temporal dynamics, and the physics that govern interactions between robots and objects in their environment (i.e. deformable objects, fluid dynamics, ...).</p>
<p>Here we focus on reality gaps found in robotic grasping, which is selected as a 'grand challenge' that is actively harnessing simulation-based learning [5], [6], and is relevant to a vast swathe of application domains, ranging from industrial assembly to assisted living. From a simulation perspective, grasping is particularly challenging as interactions frequently occur between the robot and objects in its environment, which are rarely captured with any real veracity.</p>
<p>With a growing selection of physics engines and simulation environments available to researchers, the 'correct' combination of simulator/physics for a given task is becoming harder to ascertain. It is also becoming more and more important to know where these gaps exist, and how large they are, as a precursor to overcoming them such that simulation and reality more seamlessly meld. It is therefore timely and important to know how accurate these simulators are when performing various tasks, both to appropriately select a simulator for a particular research endeavour.</p>
<p>In this paper, we attempt to quantify the reality gap. We do this for a range of robotic manipulation experiments</p>
<p>performed by a real 6DOF Kinova Mico2 arm. We simulate the same scenarios across a range of popular simulators and physics engines, and compare the data from the simulation runs to the real movements of the manipulator as recorded by a highly accurate motion capture setup, which we use as a ground truth (Fig. 1).</p>
<p>The question we endeavour to answer is; to what accuracy can a range of popular robotic simulators replicate real world manipulation-related tasks? In particular, we ask;</p>
<ul>
<li>What are the differences between the chosen physics engines when simulating the same scenario?</li>
<li>Are there specific types of interactions that some simulators can accurately model, compared to other simulators we test?</li>
</ul>
<p>We provide a detailed statistical analysis of these simulators when approximating movements of the real Kinova arm. Results quantify the disparity between the trajectory of the simulated Kinova arm and the real-world arm, and highlight that certain movements of the arm are more susceptible to misrepresentation in the simulator.</p>
<p>Our work provides novel contributions to several fields of research in robotics, Deep Machine Learning, Evolutionary Robotics and Manipulation to name a few. We supply strong evidence to measure the accuracy of various simulators and physics engines when compared to a real-world ground truth. Additionally, we provide evidence that simulators are able to model the control and kinematics of manipulators accurately, but the dynamic interactions of a simulation remain unsolved. Our research is set to assist fellow researchers in the selection of simulators for their manipulation tasks.</p>
<h2>II. Related Work</h2>
<p>Robotics is an embodied discipline focused on building systems that act in the physical world. However, for numerous reasons highlighted in Section I, simulation is a key tool to many successful robotic engineering and integration efforts. Simulation is fast, cheap, and allows for rapid prototyping and iteration over the composition and control of a robotic system. These benefits are perhaps most strongly felt when learning is used, due to the data-hungry nature of many contemporary learning approaches. Because simulators necessarily abstract various features (e.g., sensory delays, actuator slop), away from the physical reality, there exists a gap between what is simulated and how the final system performs in the real world. Of course, we can in some situations learn directly on real hardware, however this requires sophisticated learning testbeds [7], [8], [9] and, depending on the amount of data required, may be prohibitive in terms of required resources [10]. Here we focus on simulated efforts to learn.</p>
<h2>A. Bridging the Reality Gap</h2>
<p>This 'reality gap' is of increasing importance, as current deep learning approaches require a significant amount of data to achieve acceptable performance. Although increased computing power has narrowed this gap by facilitating more complex, high-fidelity simulations [11], the issue is as yet unsolved.</p>
<p>Domain randomisation is a popular technique in robotic vision, whereby a trained model is subjected to randomised inputs (i.e., colour, shading, rendering, camera position, etc.) [12], [13]. Tobin et al. [14] employ visual randomisation to teach a manipulator the 3D object position in simulation with a reasonable transfer to the real-world. Such approaches trace their lineage back to the first mention of the 'reality gap', in the context of evolutionary robotics, which found success by introducing sensory noise into a simulator to discourage overspecialisation to simulated artefacts [4].</p>
<p>This sim-to-real transfer problem has recently been tackled by numerous research groups. Earlier approaches mainly highlight the issues around this transfer [15], with more recent efforts proposing solutions, including domain adaptation and Generative Adversarial Networks (GAN) which requires both real world and simulated data [3]. Results showing the early promise of these techniques - using domain adaptation, Bousmalis et al. [16] were able to achieve a success rate for real world grasping trained in simulation of $76.7 \%$ on a dataset of unseen objects.</p>
<p>An alternative method to randomisation is the optimisation of the simulated environments, with the goal to emulate the real world better. This approach requires real world data for the simulator to be able to fit to the real world observations, making it robot and application specific [17], [18].</p>
<p>There are several methods originating in Evolutionary Robotics that focus on grading a simulation based on the confidence of its prediction in an attempt to avoid poorly simulated scenarios. One such method implemented by Koos et al. [19] offers a multi-objective approach that optimises both the fitness and the transferability of controllers. The transferability of a controller is evaluated using a surrogate model generated from data collected from controllers previously transferred to the test robot. Mouret et al. [20] state that a promising idea to cross the reality gap is to teach the limits of the simulator to a supervised learning algorithm with access to a real robot. This is then used to provide an accuracy prediction for simulated controllers. They report increased performance of the generated controllers. These scoring methods reduce the Reality Gap, but do so by limiting the simulator to predicting only things that it can accurately calculate, which reduces the applicability of the approach. They also require real-world data recorded directly from the platform to improve the simulation.</p>
<p>Other approaches employ multiple simulators to overcome the biases from a single simulator. Boeing et al. [21] created the Physics Abstraction Layer (PAL), a unified interface between multiple physics engines and successfully evolved a PID controller for an Autonomous Underwater Vehicle. More recently Eaton et al. [22] evolved behaviour for a Nao robot using first the V-Rep simulator and then for successful controllers the Webots simulator to remove controllers that were exploiting unrealistic scenarios. The evolved controllers showed improved real-world performance after a small amount of human intervention to rectify an instability of the</p>
<p>humanoid robot.</p>
<h3>II-B Physics Engines</h3>
<p>There are many physics engines targeting such diverse fields as gaming, movie effects, and robotics. Physics engines are created to model real-world physical properties in computer simulations with properties such as gravity, friction and contacts typically computed. These models are a simplification of the real-world, to compute a reasonable approximation within a restricted time and resource budget.</p>
<p>Reviews of physics engines in the past have proven many times over that no one engine is capable of modelling all scenarios. Boeing et al. [23] compared PhysX, Bullet, JigLib, Newton, Open Dynamics Engine (ODE), Tokamak and True Axis; they reported that Bullet performed best overall however no physics engine was best at all tasks. Chung et al. [24] likewise found when testing Bullet, Dynamic Animation and Robotics Toolkit (DART), MuJoCo, and ODE, that no one engine performed better at all tasks, stating that for different tasks and different conditions a different physics engine was found to be better. These findings are further corroborated by Gonzalez-Badillo et al. [25], who showed that PhysX performs better than Bullet for non-complex geometries but is unable to simulate more complex geometries to the same degree as Bullet.</p>
<p>One aim of our research is to provide a comprehensive study focused specifically around manipulation tasks, which we believe will be useful to the research community given the ongoing popularity of ‘learning to grasp’. Although several other researchers have evaluated physics engines, varying complexity and tasks [26], [25], [27], little research has been done on comparing real-world data to simulated data to draw conclusions as to the accuracy of physics engines and simulators. To our knowledge this is the first research that compares a highly accurate motion capture baseline with modern physics engines and simulators for real-world robot interaction tasks.</p>
<h3>II-C Simulation Selection</h3>
<p>The list of robotic simulators is long, with many niche areas targeted by specific simulators. We are interested in robotic manipulation and looking for mature, well maintained simulators with active communities and good documentation practices to facilitate the development of robotics research. Additionally, we wanted to find a collection of simulators that provided a common programming language interface whilst also providing access to the Robot Operating System (ROS). We were left with the following: V-Rep, MuJoCo and PyBullet. These simulators expose the following 5 physics engines: Bullet, ODE, Vortex, Newton and Mujoco. This range of physics engines and simulators is attractive due to the range and crossover that the simulators afford whilst also providing a mature user interface.</p>
<h2>III Method</h2>
<p>The setup consists of a Kinova Mico2 6DOF arm with an attached KG-3 gripper. The arm sits on a table, next to a manipulable cube. Simulators use the official Kinova URDF file. In all cases, the Kinova arm is controlled using joint velocities as it allows higher fidelity over the position controller, and avoids the issue of a simulators position controller interfering with the sent motion commands. A basic proportional controller updated at 5Hz is used to control the joints as this rate was feasible for all selected simulators. We perform sets of identical movements, such that each movement happens in each simulator, and on the real arm, and record the results in each case.</p>
<h3>III-A Real World Ground Truth</h3>
<p>A Qualisys motion capture system utilising 24 cameras mounted to a $8\times 8\times 4$ metre gantry records the real-world data (Fig. 2). A $0.75\times 1.8$ metre table with a laminated table top acts as the ground plane for all experiments. Four tracking markers were attached to the wrist of the Kinova arm using a 3D printed mount and rigid marker base. Another rigid base with 4 markers lies on the table top flush against the bracket supporting the arm. The global coordinate frame sits on the opposite end of the table, out of reach of the arm. A 3D printed cube, made from ABS plastic, sits on top of the table. The cube is 7.5cm per side, with a weight of 88.4 grams, including 4 tracking markers (Fig. 3).</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Fig. 2. Motion Capture System: 24 cameras fixed on a $8 \times 8 \times 4$ metre gantry records marker position at 100 Hz to within 1 millimetre accuracy.</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Fig. 3. The real-world setup of the 6DOF Kinova Mico2 Arm with tracking markers attached to wrist via a rigid marker base. On the opposite end of the table sits the L-frame which acts as the global coordinate system. The cube with 4 markers attached is also visible.</p>
<p>We recorded 6DOF poses - x, y and z positions and orientation as Euler angles - of the rigid bases with offset rotations and translations for the co-ordinate systems. The co-ordinate system of the wrist mounted base was set to be at the centre of the wrist, analogue to the simulations. The co-ordinate system at the centre of the cube also followed the simulators XYZ frame. The base marker was used as the global co-ordinate system for both the cube and the wrist tracking, allowing for comparative results between simulation and motion tracking.</p>
<p>Control of the Kinova arm was through ROS using the official Kinova package, which supplies joint rotations in degrees and allows for joint velocity commands to be sent at a rate of 100 Hz . Using the same proportional controller and actions as generated in simulation, scenarios were able to be run in python using the ROS interface.</p>
<h2>B. Simulation</h2>
<p>Three leading simulators are compared in our experiments: V-Rep [28], Mujoco [29] and PyBullet [30]. The Kinova arm was imported into each simulator’s scene with the cube modelled as a primitive cuboid object. The following points highlight the additional simulator specific changes required after importing the manipulator, with the only shared changes being the starting pose and the starting position (elevated 0.055 metres to account for the Kinova base plate). Other general setup included modelling the weight ( 0.0884 kilograms), size $\left(0.075 m^{3}\right)$ and position $(0.5,0,0.375)$ of the cube. All other parameters of the simulations were kept to each simulator’s defaults, unless otherwise stated. These include friction models, inertia properties, actuator settings, simulation step sizes, integrators, solvers, etc. The majority of settings are left to their default value as we want to see how well a generic scene can perform without the knowledge of an expert.</p>
<p>1) V-Rep: The scene was imported using V-Reps plug-in and saved as a .ttt binary file after creation. The joint settings were changed to “Lock motor when target velocity is zero”.
2) PyBullet: PyBullet’s time step was explicitly fixed to the value of 0.01 seconds.
3) MuJoCo: The mujoco-py Python wrapper maintained by OpenAI was used as the interface for MuJoCo. The URDF needed to be converted to an Extensible Markup Language (XML) file with MuJoCo modelling layout; this was done using the MuJoCo compile script. The actuator type and sensors needed to be added manually with the only altered parameter in the XML file being the $k v$ velocity feedback gain. The simulator time step of the simulation was set at 0.0001 seconds as this provided a stable simulation.</p>
<h2>IV. EXPERIMENTS AND RESULTS</h2>
<p>The experimentation is designed to assess the ability of robotic physics simulations to reproduce real-world scenarios. All experiments are repeated 20 times to ensure reproducible, unbiased results. Data collected for each experiment</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup>is limited to the 6DOF pose of the Kinova wrist joint and for one experiment the 6DOF pose of the cube. There are three scenarios in total: (a) beginning with a very basic robotic movement of one joint, (b) moving onto more complex multijoint movement tasks, and (c) finally an interaction task where the robot arm is pushing the cube along the table.</p>
<p>The motion capture system once calibrated provides accuracy to within 1 millimetre and records $100 \%$ "measured" data without the need for interpolation. We therefore consider the motion capture an accurate approximation of the ground truth in our real-world experiments, and the baseline we compare the simulators to.</p>
<h2>A. Scene 1: Single Joint Movement</h2>
<p>This experiment was designed to compare the control of a single joint of the Kinova arm. For that (Joint #2) rotates from a starting to a final pose, for a rotation of 100 degrees, in about 6 seconds (i.e. 120 control cycles at 5 Hz ). All other joints are controlled to the set rotation of 0 degrees.</p>
<p>Fig. 4 presents the results for Scene 1 data as a graph where each plot is the euclidean distance error (Eq. 1) plotted over time. Where $p_{x, y, z}$ are the mean position of the motion capture/physics engine at each time step and $g_{x, y, z}$ is the goal position of the wrist at 100 degrees.</p>
<p>$$
e=\sqrt{\left(p_{x}-g_{x}\right)^{2}+\left(p_{y}-g_{y}\right)^{2}+\left(p_{z}-g_{z}\right)^{2}}
$$</p>
<p>Most noticeable in Fig. 4 is the lack of results for the ODE physics engine, this is due to the instability of the V-Rep simulation which appears to be caused by self-contacts of the Kinova arm model. The accumulated error for ODE as seen in Table I proves the instability of the physics engine through the comparatively large value; this could not be rectified by tuning the parameters of the simulation. All plotted results begin at the same start position, with Vortex, Newton and PyBullet following the Motion Capture error most closely. This is quantified in Table I where the accumulated error for Vortex, Newton and PyBullet is markedly lower then the other physics engines.</p>
<p>The convergence of the physics engines to the goal position is also of note, as Bullet283 and Bullet278 arrive approximately 1 second earlier than all other plots. Bullet283 and Bullet278 also oscillate noticeably before reaching their final state (Fig. 4 (i)) which replicates the motion capture convergence as it too oscillates (Fig. 4 (ii)). The remaining physics engines show very little to no oscillation. Also included in the plot is the standard deviation of the motion capture system for comparison. Standard deviations for other plots are not displayed as the discrepancies in simulation are negligible. Finally, it appears that the motion capture is the only one to reach exactly 100 degrees as no other plots reach the same final position.</p>
<h2>B. Scene 2: Multi Joint Movement</h2>
<p>Scene 2 is a more complex scene where joints two and five are moved multiple times within 20 seconds. Joint 2 is programmed to move between $0|90| 0|90| 0$ degrees and joint 5 moves between $0|90| 0|-90| 0$ degrees.</p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Fig. 4. A single joint motion performed on the Kinova arm both in the real world and in simulators. Plotted is the mean Euclidean distance from the goal position, calculated from 20 runs. (i) and (ii) are areas of note within the plot.</p>
<p>Fig. 5 depicts the euclidean error plot (Eq. 1) where $g_{x, y, z}$ for (a) is the final goal position of the wrist and (b) is the equivalent time step motion capture position. Newton and Vortex follow the motion capture path closely with an accumulated error of $\pm 5.5-6$ metres, while PyBullet also has a low accumulated error of $\pm 7$ metres. MuJoCo, Bullet283 and Bullet278 model the motion capture closer between $0-5$ seconds and $10-15$ seconds, this is due to the arms moving with gravity towards the goal state and then during the errorfull periods slowly moving aginst gravity and accruing more error. When moving against gravity only MuJoCo is able to reach the final position before changing trajectory. Some of the simulators (i.e. Mujoco and Bullet283) also generate the oscillation seen by the motion capture as the proportional controller attempts to correct the rotation, although none are able to imitate the exact motion of real robot.</p>
<h3><em>C. Scene 3: Interaction with the cube</em></h3>
<p>The most complex scene where joints two, three and four move in a sequence and push a cube along a flat plane within 20 seconds. There are three phases of this scene, the first two position the arm to make contact with the cube and the third initiates the contact and pushes the cube. This scene tests both the control and the physics of the system through the movement of the Kinova arm and the interaction with the cube. Fig. 6 shows three plots: (i) the euclidean distance error (Eq. 1) where $g_{x, y, z}$ is the goal position of the wrist; (ii) the euclidean distance error of the cube (Eq. 1) where $g_{x, y, z}$ is the start position of the cube (i.e. x:0.5, y:0, z:0.0375); and (iii) the rotation of the cube around the y-axis. The first plot shows that no physics engine outperforms any other by a distinguishable margin. This is reinforced by the results in Table I, where the accumulated error for Newton, Vortex and Pybullet are approximately $\pm 45$ metres. It also appears that the motion capture is the closest to reach the goal state, however all plots settle close to the x-axis. The second plot shows the physical interaction between two rigid objects. The greatest displacement is made by MuJoCo followed by the Motion Capture, Bullet283, and then Bullet278. Vortex has very little displacement as the cube makes minimal contact with the Kinova gripper due to the large error seen in the first plot at 15 seconds. Pybullet does not interact with the cube at all, with the gripper moving over the cube. Mujoco is the first to interact with the cube and does so early at about 11.4 seconds whereas all other physics engines begin at about 14 seconds; this is at the conclusion of the previous phase designed to get the gripper in a position to interact with the cube. The final plot shows the pitch of the cube and this is important due to the discrepancies between the physics engines and the ground truth. The plot clearly shows that both Bullet283 and MuJoCo knock the cube in such a way that it rotates 90 degrees. The same movement in reality moves the cube forward with only the smallest amount of discernible rotation. The only physics engine which is able to match the lack of rotation is PyBullet and that is due to it not interacting with the gripper at all. This is particularly relevant given our focus on robotic manipulation, which would benefit greatly from reasonable modelling of these multi-body interactions.</p>
<p>The crossover between physics engines shows PyBullets implementation of Bullet and V-Rep's two implementations of Bullet. The total column from Table I shows a vast difference between the two simulators, with PyBullet drastically better at simulating the chosen scenes with a cumulative position error of $\pm 45.5$ metres while V-Rep's implementations of Bullet both attained $\pm 131$ metres. This could be due to several effects, the first being the default values being set differently (i.e. we set the timestep of PyBullet to be 0.01 seconds while V-Rep generically uses 0.05 seconds), the second could be the underlying implementation between the V-Rep simulator and the physics engine at a scale inaccessible to the user.</p>
<p>For the control of the manipulator Newton, Bullet (PyBullet implementation) and Vortex were considerably and consistently better. For interaction between objects there was no physics engine that modelled the collision well. In reality the cube moved a total of 0.0975 metres in x,y and z with a change in rotation of roll: 0.01, pitch: 0.11 and yaw: 0.89 degrees. The physics engines that were closest to modelling position (Mujoco: 0.1137 metres and Bullet283: 0.0869 metres) had incorrect rotations (MuJoCo and Bullet283 pitch: 90 degrees) and those that had similar real-world rotations had minimal positional movement (&lt; 0.0134 metres).</p>
<p>By stitching together physics engines for discrete periods within a simulation it is believed that a model capable of further reducing the reality gap can be generated. This is backed up by the results which show for the control of the manipulator we should select Newton, PyBullet and Vortex to model the kinematics, without using the results of the remaining physics engines. The control segments could then be combined to the results of MuJoCo, Bullet283 and Bullet278 for the period of interaction with the cube. By populating periods in the simulation timeline with only the</p>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Fig. 5. Plot of Scene 2 with the goal position set to the ground truth. Plotted lines are the euclidean distance from the goal position calculated using the mean of 20 results. (i) and (ii) are areas of note within the plot.</p>
<p><img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Fig. 6. Three plots of Scene 3: (a) plotted lines represent the wrist's euclidean distance from the final goal position calculated using the mean of 20 results; (b) the x-axis represents the start position of the cube with lines the cubes euclidean distance away; and (c) the pitch of the cube (where pitch is the rotation around the y-axis).(i-iv) are areas of note within the plot.</p>
<p>TABLE I</p>
<table>
<thead>
<tr>
<th></th>
<th>1 Joint</th>
<th>2 Joints</th>
<th>Cube</th>
<th>Total</th>
</tr>
</thead>
<tbody>
<tr>
<td>MuJoCo</td>
<td>24.237</td>
<td>49.430</td>
<td>23.471</td>
<td>97.138</td>
</tr>
<tr>
<td>PyBullet</td>
<td>18.429</td>
<td>7.000</td>
<td>20.084</td>
<td>45.513</td>
</tr>
<tr>
<td>V-Rep (Bullet2.78)</td>
<td>27.412</td>
<td>81.166</td>
<td>25.034</td>
<td>133.611</td>
</tr>
<tr>
<td>V-Rep (Bullet2.83)</td>
<td>26.698</td>
<td>80.004</td>
<td>25.215</td>
<td>131.916</td>
</tr>
<tr>
<td>V-Rep (Newton)</td>
<td>18.810</td>
<td>5.579</td>
<td>21.069</td>
<td>45.458</td>
</tr>
<tr>
<td>V-Rep (Vortex)</td>
<td>18.887</td>
<td>5.664</td>
<td>21.130</td>
<td>45.680</td>
</tr>
<tr>
<td>V-Rep (ODE)</td>
<td>1.31e+17</td>
<td>1.19e+18</td>
<td>1.88e+18</td>
<td>3.20e+18</td>
</tr>
</tbody>
</table>
<p>optimal performing physics engine the resulting simulation should display a closer realisation of reality.</p>
<h2>V. CONCLUSION</h2>
<p>We have demonstrated the ability of a range of physics engines to simulate a set of manipulation tasks. Using a motion capture system as the ground truth we record 6DOF pose of a robotic manipulator and directly compare it to simulated data collected from the MuJoCo, PyBullet and V-Rep simulators. The range of tasks test the kinematic and dynamic modelling capabilities of Bullet, Mujoco, Newton, ODE and Vortex. Contributions are both the quantified evidence of the capability of physics engines to model manipulation tasks and the analysis of the simulated and real-world data, including a highly accurate ground truth.</p>
<p>We show the simulation of the kinematic model and control of manipulators is largely solved when compared to the real world, however there are considerable developments necessary for interactions between simulated objects. The physics behind contacts remains a complex problem that is difficult to replicate in simulated environments, and we suggest that a focus on such interactions will bring increasing benefits for the 'learning to grasp' community.</p>
<p>The results highlight the strengths and weaknesses of con-</p>
<p>temporary simulators with focus on discrepancies between the real-world ground truth. Our contributions will assist researches in the field in their selection of simulators.</p>
<h2>REFERENCES</h2>
<p>[1] J. Lehman, J. Clune, D. Misevic, C. Adami, J. Beaulieu, P. J. Bentley, S. Bernard, G. Belson, D. M. Bryson, N. Cheney et al., "The surprising creativity of digital evolution: A collection of anecdotes from the evolutionary computation and artificial life research communities," arXiv preprint arXiv:1803.03453, 2018.
[2] N. Sünderhauf, O. Brock, W. Scheirer, R. Hadsell, D. Fox, J. Leitner, B. Upcroft, P. Abbeel, W. Burgard, M. Milford, and P. Corke, "The limits and potentials of deep learning for robotics," The International Journal of Robotics Research, vol. 37, no. 4-5, pp. 405-420, 2018. [Online]. Available: https://doi.org/10.1177/0278364918770733
[3] F. Zhang, J. Leitner, M. Milford, and P. Corke, "Modular Deep Q Networks for Sim-to-real Transfer of Visuo-motor Policies," Tech. Rep. [Online]. Available: http://cattle3d.com/pap146s1-file1.pdf
[4] N. Jakobi, P. Husbands, and I. Harvey, "Noise and the reality gap: The use of simulation in evolutionary robotics," in European Conference on Artificial Life. Springer Berlin Heidelberg, 1995, pp. 704-720.
[5] S. Levine, C. Finn, T. Darrell, and P. Abbeel, "End-to-end training of deep visuomotor policies," The Journal of Machine Learning Research, vol. 17, no. 1, pp. 1334-1373, 2016.
[6] I. Lenz, H. Lee, and A. Saxena, "Deep learning for detecting robotic grasps," The International Journal of Robotics Research, vol. 34, no. 4-5, pp. 705-724, 2015.
[7] D. Howard and T. Merz, "A platform for the direct hardware evolution of quadcopter controllers," in IEEE International Conference on Intelligent Robots and Systems, vol. 2015-Decem. IEEE, 9 2015, pp. 4614-4619. [Online]. Available: http://ieeexplore.ieee.org/document/ 7354034/
[8] L. Pinto and A. Gupta, "Supersizing self-supervision: Learning to grasp from 50k tries and 700 robot hours," in Robotics and Automation (ICRA), 2016 IEEE International Conference on. IEEE, 2016, pp. 3406-3413.
[9] H. Heijnen, D. Howard, and N. Kottege, "A testbed that evolves hexapod controllers in hardware," in Proceedings - IEEE International Conference on Robotics and Automation. IEEE, 5 2017, pp. 1065-1071. [Online]. Available: http://ieeexplore.ieee.org/ document/7989128/
[10] S. Levine, P. Pastor, A. Krizhevsky, and D. Quillen, "Learning hand-eye coordination for robotic grasping with deep learning and large-scale data collection," CoRR, vol. abs/1603.02199, 2016. [Online]. Available: http://arxiv.org/abs/1603.02199
[11] J. Collins, D. Howard, W. Geles, and F. Maire, "Towards the targeted environment-specific evolution of robot components," in GECCO 2018 - Proceedings of the 2018 Genetic and Evolutionary Computation Conference, 2018.
[12] S. James, A. J. Davison, and E. Johns, "Transferring End-to-End Visuomotor Control from Simulation to Real World for a Multi-Stage Task," 7 2017. [Online]. Available: http://arxiv.org/abs/1707.02267
[13] J. Borrego, R. Figueiredo, A. Dehban, P. Moreno, A. Bernardino, and J. Santos-Victor, "A generic visual perception domain randomisation framework for Gazebo," in 18th IEEE International Conference on Autonomous Robot Systems and Competitions, ICARSC 2018. IEEE, 4 2018, pp. 237-242. [Online]. Available: https://ieeexplore.ieee.org/ document/8374189/
[14] J. Tobin, R. Fong, A. Ray, J. Schneider, W. Zaremba, and P. Abbeel, "Domain randomization for transferring deep neural networks from simulation to the real world," in IEEE International Conference on Intelligent Robots and Systems, vol. 2017-Septe. IEEE, 9 2017, pp. 23-30. [Online]. Available: http://ieeexplore.ieee.org/document/ 8202133/
[15] F. Zhang, J. Leitner, M. Milford, B. Upcroft, and P. Corke, "Towards Vision-Based Deep Reinforcement Learning for Robotic Motion Control," 11 2015. [Online]. Available: http://arxiv.org/abs/1511.03791
[16] K. Bousmalis, A. Irpan, P. Wohlhart, Y. Bai, M. Kečcey, M. Kalakrishnan, L. Downs, J. Ibarz, P. Pastor, K. Konolige, S. Levine, and V. Vanhoucke, "Using Simulation and Domain Adaptation to Improve Efficiency of Deep Robotic Grasping," 2017. [Online]. Available: http://arxiv.org/abs/1709.07857
[17] J. C. Zagal, J. Ruiz-del Solar, and P. Vallejos, "Back to reality: Crossing the reality gap in evolutionary robotics," IFAC Proceedings Volumes, vol. 37, no. 8, pp. 834-839, 72004. [Online]. Available: https://www.sciencedirect.com/science/article/pii/ S1474667017320840
[18] T. Laue and M. Hebbel, "Automatic Parameter Optimization for a Dynamic Robot Simulation," in RoboCup 2008: Robot Soccer World Cup XII, L. Iocchi, H. Matsubara, A. Weitzenfeld, and C. Zhou, Eds. Berlin, Heidelberg: Springer Berlin Heidelberg, 2009, pp. 121-132.
[19] S. Koos, J.-B. Mouret, and S. Doncieux, "Crossing the reality gap in evolutionary robotics by promoting transferable controllers," in Proceedings of the 12th annual conference on Genetic and evolutionary computation - GECCO '10, 2010, p. 119. [Online]. Available: http://portal.acm.org/citation.cfm?doid=1830483.1830505
[20] J.-B. Mouret and K. Chatzilygeroudis, "20 Years of Reality Gap," in Proceedings of the Genetic and Evolutionary Computation Conference Companion on - GECCO '17, 2017, pp. 1121-1124. [Online]. Available: http://dl.acm.org/citation.cfm?doid=3067695.3082052
[21] A. Boeing and T. Bräunl, "Leveraging multiple simulators for crossing the reality gap," in 2012 12th International Conference on Control, Automation, Robotics and Vision, ICARCV 2012, 2012, pp. 11131119.
[22] M. Eaton, "Bridging the reality gap - A dual simulator approach to the evolution of whole-body motion for the nao humanoid robot," in IJCCI 2016 - Proceedings of the 8th International Joint Conference on Computational Intelligence, vol. 1, 2016, pp. 186-192.
[23] A. Boeing and T. Bräunl, "Evaluation of real-time physics simulation systems," in Proceedings of the 5th international conference on Computer graphics and interactive techniques in Australia and Southeast Asia - GRAPHITE '07. New York, New York, USA: ACM Press, 2007, p. 281. [Online]. Available: http://portal.acm.org/citation.cfm?doid=1321261.1321312
[24] S. J. Chung and N. Pollard, "Predictable behavior during contact simulation: A comparison of selected physics engines," Computer Animation and Virtual Worlds, vol. 27, no. 3-4, pp. 262-270, 2016.
[25] G. Gonzalez-Badillo, H. I. Medellin-Castillo, T. Lim, J. M. Ritchie, R. C. Sung, and S. Garbaya, "A new methodology to evaluate the performance of physics simulation engines in haptic virtual assembly," Assembly Automation, vol. 34, no. 2, pp. 128-140, 2014.
[26] J. Fabry and S. Sinclair, "Interactive visualizations for testing physics engines in robotics," in Proceedings - 2016 IEEE Working Conference on Software Visualization, VISSOFT 2016, 2016, pp. 106-110.
[27] T. Erez, Y. Tassa, and E. Todorov, "Simulation tools for model-based robotics: Comparison of Bullet, Havok, MuJoCo, ODE and PhysX," in 2015 IEEE International Conference on Robotics and Automation (ICRA). IEEE, 5 2015, pp. 4397-4404. [Online]. Available: http://ieeexplore.ieee.org/document/7139807/
[28] E. Rohmer, S. P. Singh, and M. Freese, "V-REP: A versatile and scalable robot simulation framework," in IEEE International Conference on Intelligent Robots and Systems. IEEE, 11 2013, pp. 1321-1326. [Online]. Available: http://ieeexplore.ieee.org/document/ 6696520/
[29] E. Todorov, T. Erez, and Y. Tassa, "MuJoCo: A physics engine for model-based control," in IEEE International Conference on Intelligent Robots and Systems. IEEE, 10 2012, pp. 5026-5033. [Online]. Available: http://ieeexplore.ieee.org/document/6386109/
[30] E. Coumans and Y. Bai, "Pybullet, a Python Module for Physics Simulation for Games, Robotics and Machine Learning," 2016. [Online]. Available: https://pybullet.org</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{1}$ All code and parameter listings are publicly available from: https://bitbucket.csiro.au/scmi*col549/quantifying-the-reality-gap-in-robotic-manipulation-tasks.git&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>