<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2634 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2634</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2634</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-66.html">extraction-schema-66</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated research systems, AI scientists, or automated idea generation/implementation systems, including details about what types of research problems they were applied to, the characteristics of those problems, and the success or failure rates of the automated system.</div>
                <p><strong>Paper ID:</strong> paper-91b68391df0b16d22bffbbf4d0c09f13dee36561</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/91b68391df0b16d22bffbbf4d0c09f13dee36561" target="_blank">GPT-Lab: Next Generation Of Optimal Chemistry Discovery By GPT Driven Robotic Lab</a></p>
                <p><strong>Paper Venue:</strong> arXiv.org</p>
                <p><strong>Paper TL;DR:</strong> This work introduces GPT-Lab, a paradigm that employs GPT models to give robots human-like intelligence in robotic experimentation, and mines literature for materials and methods and validates findings through high-throughput synthesis.</p>
                <p><strong>Paper Abstract:</strong> The integration of robots in chemical experiments has enhanced experimental efficiency, but lacking the human intelligence to comprehend literature, they seldom provide assistance in experimental design. Therefore, achieving full-process autonomy from experiment design to validation in self-driven laboratories (SDL) remains a challenge. The introduction of Generative Pre-trained Transformers (GPT), particularly GPT-4, into robotic experimentation offers a solution. We introduce GPT-Lab, a paradigm that employs GPT models to give robots human-like intelligence. With our robotic experimentation platform, GPT-Lab mines literature for materials and methods and validates findings through high-throughput synthesis. As a demonstration, GPT-Lab analyzed 500 articles, identified 18 potential reagents, and successfully produced an accurate humidity colorimetric sensor with a root mean square error (RMSE) of 2.68%. This showcases the rapid materials discovery and validation potential of our system.</p>
                <p><strong>Cost:</strong> 0.019</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2634.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2634.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated research systems, AI scientists, or automated idea generation/implementation systems, including details about what types of research problems they were applied to, the characteristics of those problems, and the success or failure rates of the automated system.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-Lab</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-Lab: GPT driven robotic lab</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An integrated automated discovery system combining a GPT-4-based agent with an algorithm-driven robotic experimentation platform to perform end-to-end literature mining, experiment design, and high-throughput experimental validation for materials discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>GPT-Lab</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A closed-loop automated discovery system that couples an LLM-based agent (ChatGPT/GPT-4 API) with a robotic liquid-handling and sensing platform. The agent implements the ARMFE pipeline (Analysis - Retrieval - Mining - Feedback Execution) to: (1) take researcher requirements and generate search keywords, (2) retrieve and filter literature (titles/abstracts), (3) use GPT to extract substances, roles and build structured JSON records, (4) present curated candidate materials to humans for selection, (5) translate selected materials into machine-readable exchange files (CAS codes + concentrations) and (6) send parameters to the robotic platform for automated recipe preparation, testing, and iterative optimization. The robotic side executes high-throughput wet experiments (96 samples/batch), captures visual data (color vs time), computes multi-indicator scores, and iterates using an algorithm-guided optimization loop (DBTM + Bayesian optimization). The system also supports human-in-the-loop feedback for selection and verification.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>Automated Discovery System / AI Scientist / Automated Experimentation Platform</td>
                        </tr>
                        <tr>
                            <td><strong>problem_domain</strong></td>
                            <td>Chemistry and materials science (sensor materials discovery), specifically development and optimization of colorimetric relative-humidity (RH) sensors; demonstrated also for perovskite solar-cell materials discovery and chromatographic methods for alkaloid detection in mulberry leaves.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Discover candidate sensing materials and formulation recipes for a colorimetric humidity sensor by (a) mining literature for relevant reagents and their roles, (b) proposing a materials design space and candidate recipes, and (c) executing high-throughput formulation and testing to optimize sensor performance (sensitivity, response time, reversibility, and RH prediction accuracy). The system was also used to search materials lists for perovskite solar cells and to propose experimental methods for alkaloid detection.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Multi-step, multi-objective experimental optimization with mixed tasks: open-ended literature mining (large, unstructured search space) and continuous formulation optimization. Quantitative aspects: literature mining processed 500 articles; candidate generation produced 50 potential reagents (18 with relevance >=80%, including 8 candidate core materials). Experimental optimization explored a 7-dimensional continuous formulation space (8 reagents with fixed total quantity, so 7 degrees of freedom) using batches of 96 samples per round and 5 rounds (480 experiments total). Objectives combined multiple metrics (color change amplitude, response time, reversibility, sensitivity) into a weighted score; final evaluation used RH prediction RMSE.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Literature-rich for mining: 500 articles were collected and processed in the demonstration. Experimental data was generated by the robotic platform (480 high-throughput samples). Data quality benefited from robotic consistency (liquid handler, controlled gas path, fixed lighting) but required aggregation of multi-indicator metrics to form a composite score. Some human curation remained necessary (researchers selected from the candidate list and filtered experimental parameters).</td>
                        </tr>
                        <tr>
                            <td><strong>computational_requirements</strong></td>
                            <td>Literature processing: the agent processed ~100 articles/hour (single-threaded) and can be accelerated 3–5x with multi-threading; claimed >100x time saving vs manual extraction for large corpora. Experimental evaluation: 480 wet experiments over 5 rounds; compute for image processing and Bayesian optimization unspecified but modest relative to LLM API costs. Additional compute/cost drivers: repeated GPT (ChatGPT/GPT-4) API calls for extraction/filtering and retries to handle hallucinations (authors note increased GPT usage cost and programmatic retry overhead).</td>
                        </tr>
                        <tr>
                            <td><strong>problem_structure</strong></td>
                            <td>Hybrid problem: literature mining is open-ended, language-understanding heavy and prone to ambiguity; formulation optimization is continuous, stochastic (experimental noise), multi-objective, and has clear evaluation metrics derived from sensor measurements. Requires domain knowledge (chemistry/materials) for valid reagent suggestions and safe experimental parameters. The experimental loop is deterministic at the robotic execution level but measurements have experimental variability.</td>
                        </tr>
                        <tr>
                            <td><strong>success_metric</strong></td>
                            <td>Quantitative: (a) materials-mining yield (number of candidate reagents and those above relevance threshold), (b) experimental optimization score (composite weighted metric from color-change measures), and (c) final functional performance: RH prediction root mean square error (RMSE = 2.68% over 5–95% RH). Secondary metrics: throughput (articles/hour), time-to-proof-of-concept (built a working sensor within one week with minor human interference).</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td>Demonstrated success on the humidity-sensor task: from 500 articles the system proposed 50 reagent candidates and after filtering flagged 18 reagents with >=80% relevance (8 core candidates). Robotic optimization ran 480 experiments (5 rounds of 96) and delivered a two-recipe sensor array that predicted RH across 5–95% with RMSE = 2.68%. Processing speed ~100 articles/hour (single-threaded), claimed >100x time saving vs manual literature search. No explicit failure rate is given for tasks such as reagent suggestions, but authors note GPT hallucinations and the need for human filtering.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>Observed: (1) GPT hallucination and inaccurate outputs requiring programmatic checks and retries; (2) GPT's limited domain-specific knowledge outside its training/exposed literature, forcing human filtering of experimental parameters; (3) some suggested substances by raw GPT were infeasible for robotic execution—necessitating additional filtering/feasibility checks; (4) exploration-heavy optimization produced many low-score recipes (deliberate exploration causing poor-performing samples) and made finding better recipes in high-uncertainty regions difficult; (5) increased monetary cost and system complexity due to heavy GPT API usage and retry logic.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Key enablers: (a) integration of literature mining with robotic high-throughput execution enabling rapid iteration; (b) structured pipeline (ARMFE) that converts text to machine-executable parameters (CAS codes and concentrations); (c) algorithm-guided experimental design (DBTM + Bayesian optimization) to efficiently explore a continuous 7D formulation space; (d) consistent robotic execution and standardized measurement (controlled gas mixing, lighting, and automated computer-vision color extraction) producing high-quality data; (e) human-in-the-loop selection to prevent infeasible suggestions from causing unsafe or impossible robot tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>comparative_results</strong></td>
                            <td>Authors report qualitative and quantitative advantages vs alternatives: (a) vs manual literature review: >100x speed-up in extraction for large corpora; (b) vs 'pure GPT': GPT-Lab produced higher accuracy and feasibility — fewer hallucinated or robot-infeasible material suggestions and provided literature sources and theoretical justifications; (c) generalization: the approach produced useful outputs in heterogeneous problems (humidity sensors, perovskite materials list, alkaloid analysis methods), indicating domain-transfer capability. No controlled head-to-head numerical benchmark versus human experts or other automated systems is provided beyond the stated throughput and final RMSE.</td>
                        </tr>
                        <tr>
                            <td><strong>human_baseline</strong></td>
                            <td>No precise numeric human baseline provided; qualitative comparisons: manual literature extraction is stated to be over 100x slower for large literature volumes; human experts still required to filter and select experimental parameters (authors retained human researcher feedback step). There is no direct human-vs-system accuracy comparison for reagent selection or final sensor performance.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'GPT-Lab: Next Generation Of Optimal Chemistry Discovery By GPT Driven Robotic Lab', 'publication_date_yy_mm': '2023-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2634.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2634.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated research systems, AI scientists, or automated idea generation/implementation systems, including details about what types of research problems they were applied to, the characteristics of those problems, and the success or failure rates of the automated system.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ARMFE</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ARMFE (Analysis - Retrieval - Mining - Feedback Execution)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The procedural pipeline used inside GPT-Lab that structures end-to-end automated research: requirements analysis, literature retrieval, text mining, human researcher feedback, and automated experiment execution.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>ARMFE pipeline</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A stepwise agent workflow: (1) Requirements analysis: agent prompts researchers and generates five keywords for searches; (2) Literature retrieval: online search by keywords, title/abstract filtering; (3) Text mining: GPT extracts substances, CAS numbers, roles and builds JSON files; (4) Human researcher feedback: curated parameters presented to researchers for selection; (5) Experiment execution: agent compiles exchange files (CAS + concentrations) for the robotic platform and triggers automated experiments. ARMFE integrates human-in-the-loop selection to ensure feasibility.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>Automated Pipeline / Agent-based literature-to-experiment pipeline</td>
                        </tr>
                        <tr>
                            <td><strong>problem_domain</strong></td>
                            <td>Literature mining and automated experimental design for chemistry/materials science (sensor materials), applicable to other experimental R&D tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Transform natural-language experimental requirements into a curated materials and parameter space suitable for robotic execution by mining literature and generating machine-readable experimental plans.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Handles large unstructured text corpora and translates to structured experimental variables; complexity driven by diversity and ambiguity of literature, necessity of correct extraction (CAS, roles), and mapping to robot-capable parameterizations.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Demonstrated on 500 articles; depends on public availability of articles, abstracts and full-text retrieval. The pipeline preserves JSON records for downstream selection and execution.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_requirements</strong></td>
                            <td>Requires repeated LLM API calls for keyword generation, relevance filtering and text extraction; reported throughput ~100 articles/hour (single-threaded), scaleable via multi-threading to 3–5x that rate.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_structure</strong></td>
                            <td>Semi-structured: mapping from language to structured experimental parameters is rule-like but requires semantic understanding and external validation; the execution side is well-defined and requires robot-feasible parameter formats.</td>
                        </tr>
                        <tr>
                            <td><strong>success_metric</strong></td>
                            <td>Throughput (articles/hour), yield of feasible candidates (e.g., 50 candidates from 500 articles; 18 >=80% relevance), and downstream experimental success when executed by the robot.</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td>On the demonstration corpus (500 articles) ARMFE produced 50 candidate reagents and after filtering highlighted 18 reagents with relevance >=80%. No explicit precision/recall metrics reported for extraction accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>Errors from LLM extraction (hallucinations, incorrect CAS or roles), missing or paywalled full texts limiting retrieval, and mismatch between extracted experimental details and robot execution constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Structured prompts, multi-stage filtering (title/abstract then full-text), JSON structuring for downstream use, human-in-the-loop verification, and strong integration with the robotic execution format (CAS + concentrations).</td>
                        </tr>
                        <tr>
                            <td><strong>comparative_results</strong></td>
                            <td>Authors claim ARMFE outperforms naive LLM-only extraction by reducing hallucinations and focus on robot-feasible materials; also far faster than manual extraction. No quantitative baseline beyond the stated yields and throughput.</td>
                        </tr>
                        <tr>
                            <td><strong>human_baseline</strong></td>
                            <td>Human researchers typically must read and extract from many papers manually; authors estimate manual extraction is >100x slower for large corpora, though no controlled timing study is provided.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'GPT-Lab: Next Generation Of Optimal Chemistry Discovery By GPT Driven Robotic Lab', 'publication_date_yy_mm': '2023-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2634.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2634.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated research systems, AI scientists, or automated idea generation/implementation systems, including details about what types of research problems they were applied to, the characteristics of those problems, and the success or failure rates of the automated system.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-4 agent</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-4-based experimental design agent (via ChatGPT API)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A generative large language model used as the core reasoning and text-mining component of GPT-Lab to generate keywords, filter literature, extract reagent information, assemble JSON structured outputs, and interact via clarifying questions for incomplete requisitions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>GPT-4 (ChatGPT API)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Used as an agent to: generate search keywords from researcher requirements; filter titles/abstracts for relevance; read full-text articles and extract reagent names, CAS numbers, roles and rationales; assemble JSON entries; ask clarifying questions to refine requirements; and produce experimental-parameter JSON for robot execution. The model was accessed through ChatGPT API prompts; authors note extensive prompt engineering and programmatic checks to reduce hallucination.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>Large Language Model Agent / Automated Idea Generation System</td>
                        </tr>
                        <tr>
                            <td><strong>problem_domain</strong></td>
                            <td>Text mining, experimental protocol design and translation of natural language literature into structured experimental parameters for chemistry/materials R&D.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Semantic extraction of materials and methods from scientific literature and generation of experiment designs suitable for robotic execution.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Requires deep language understanding and domain grounding; must map ambiguous textual mentions to concrete entities (e.g., CAS numbers, roles) and determine feasibility for robot execution.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Operates on retrieved literature (titles, abstracts, full-text). No fine-tuning reported; relies on in-context prompting over the API. Authors note limits where GPT lacks domain-specific knowledge not present in its exposure.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_requirements</strong></td>
                            <td>Frequent API calls at scale (processing 500 articles required hundreds to thousands of prompts); the authors flag increased monetary cost and additional programmatic retry logic to handle incorrect outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_structure</strong></td>
                            <td>Open-ended natural language understanding task; not purely deterministic due to LLM stochasticity; outputs require structured extraction and downstream validation.</td>
                        </tr>
                        <tr>
                            <td><strong>success_metric</strong></td>
                            <td>Number of feasible reagent suggestions, throughput (articles/hour ~100), and contribution to downstream experimental success (final RMSE 2.68% when integrated into GPT-Lab).</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td>Practical success demonstrated: with the LLM agent in GPT-Lab the system identified 50 potential reagents from 500 articles and 18 with high relevance. However, authors report many raw GPT outputs can be infeasible or hallucinated if used alone; GPT-Lab's additional filtering improved feasibility.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>Hallucination (inventing reagents/roles without theoretical basis), inaccurate numeric or CAS outputs, limited domain-specific knowledge beyond its training exposures, and costs from repeated API usage and programmatic retries.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Prompt engineering, multi-stage filtering (title/abstract then full-text), integration with downstream feasibility filters and human-in-the-loop checks, and coupling with robotic validation to close the loop.</td>
                        </tr>
                        <tr>
                            <td><strong>comparative_results</strong></td>
                            <td>Authors state GPT-Lab's agent (with pipeline and filters) had higher accuracy/feasibility than 'pure GPT' usage, which tended to hallucinate and propose experimentally infeasible materials. No formal numerical head-to-head reported.</td>
                        </tr>
                        <tr>
                            <td><strong>human_baseline</strong></td>
                            <td>Human experts still required for final filtering of experimental parameters; the LLM accelerated literature triage but did not fully remove human oversight.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'GPT-Lab: Next Generation Of Optimal Chemistry Discovery By GPT Driven Robotic Lab', 'publication_date_yy_mm': '2023-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2634.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2634.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated research systems, AI scientists, or automated idea generation/implementation systems, including details about what types of research problems they were applied to, the characteristics of those problems, and the success or failure rates of the automated system.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Robotic platform</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Algorithm-driven robotic experimentation platform (liquid handling workstation + sensing/darkroom)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A high-throughput robotic laboratory setup that prepares liquid formulations, fabricates colorimetric sensing units, exposes them to controlled humidity streams, records color-change data by imaging, and returns quantitative metrics for optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Robotic experimentation platform (liquid handler + darkroom + sensing chamber)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Consists of a liquid handling workstation (stock solution area, pipette tip area, recipe configuration area, sensing unit fabrication area), a self-built darkroom with controlled lighting and camera, and a gas path with two MFCs to create controlled RH conditions. The robot fabricates 96 sensing samples per batch, tests them by exposing to different humidities and records color vs. time for each sample. Image data are processed to compute indicators (amplitude, response time, reversibility, sensitivity) that are weighted into a composite score for optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>Automated Experimentation Platform / High-throughput Robotic Lab</td>
                        </tr>
                        <tr>
                            <td><strong>problem_domain</strong></td>
                            <td>Experimental fabrication and testing in chemistry/materials science — development of humidity colorimetric sensors.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Execute recipes produced by the agent at scale, fabricate sensing units, test under controlled humidity ranges (5%–95% RH), and produce measurement data for iterative optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>High-throughput experimental workload with physical noise and variability; formulation space of 8 reagents (7 DOF) with continuous concentrations, multiple competing objectives to optimize (sensitivity, response time, reversibility, prediction accuracy).</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Generates primary experimental data (480 sample experiments in the demonstration). Data are of high consistency due to robotic preparation and controlled testing environment.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_requirements</strong></td>
                            <td>Experimental throughput: 96 samples per batch; 5 rounds = 480 samples. Image processing and score computation per sample are modest compute loads. No explicit CPU/memory/time in seconds provided, but robotic runtime and physical testing time dominate.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_structure</strong></td>
                            <td>Well-defined execution tasks (robotic protocols) but stochastic measurement noise; experiments yield quantitative metrics and clear evaluation functions enabling closed-loop optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>success_metric</strong></td>
                            <td>Composite weighted score from colorimetric indicators and final RH prediction RMSE (2.68%). Tracking of score distributions across rounds (max score increases as optimization proceeds).</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td>Using agent-specified materials and DBTM-guided exploration, the robot executed 480 experiments leading to a near-optimal recipe set and a sensor array achieving RMSE = 2.68% across 5%–95% RH. Some batches contained many low-score (near-zero) recipes due to exploration-heavy sampling.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>Exploratory sampling can produce many low-performing recipes; physical execution limits (reagent incompatibilities) if upstream filtering fails; potential for measurement noise leading to uncertainty and difficulty finding improvements in high-uncertainty regions.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Precise liquid handling, controlled gas-mixing for RH, standardized imaging/darkroom environment, and integration with Bayesian optimization informed sampling.</td>
                        </tr>
                        <tr>
                            <td><strong>comparative_results</strong></td>
                            <td>No direct baseline robotic comparison provided; authors emphasize that robotic consistency enables generation of high-quality data for algorithmic optimization and that integration with GPT-based literature mining speeds end-to-end discovery vs manual workflows.</td>
                        </tr>
                        <tr>
                            <td><strong>human_baseline</strong></td>
                            <td>Human-executed experiments would be much slower and more variable; no direct numeric human baseline provided.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'GPT-Lab: Next Generation Of Optimal Chemistry Discovery By GPT Driven Robotic Lab', 'publication_date_yy_mm': '2023-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2634.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2634.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated research systems, AI scientists, or automated idea generation/implementation systems, including details about what types of research problems they were applied to, the characteristics of those problems, and the success or failure rates of the automated system.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DBTM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>DBTM process (algorithm-guided iterative experimental process)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An iterative algorithm-guided experimental process used on the robotic platform that cycles 'recipe generation - robotic preparation - robotic testing - data processing - next-round recipe generation' to efficiently search formulation space.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>DBTM (algorithm-guided experimental loop)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>DBTM is an iterative closed-loop experimental strategy implemented on the robot: initial recipes are generated (first round random), fabricated and tested by the robot, data processed into metrics, and the algorithm (Bayesian optimization) uses results to propose next-round recipes mixing exploration and exploitation. The authors reference earlier work (their ref. 26) for a similar DBTM implementation.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>Automated Experimentation Control / Iterative Optimization Process</td>
                        </tr>
                        <tr>
                            <td><strong>problem_domain</strong></td>
                            <td>Automated experimental optimization in chemistry/materials (sensor formulation optimization).</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Efficient sampling of a continuous, multi-dimensional formulation space to discover high-performing recipes with minimal experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Search in a 7-dimensional continuous space with noisy objective evaluations and multi-objective trade-offs (combined into a single weighted score). Starts with 96 random recipes then iterates using Bayesian strategies.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Relies on robot-generated experimental outcomes; demonstrated with 5 rounds (96 samples each) for 480 total experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_requirements</strong></td>
                            <td>Requires experiment scheduling and Bayesian optimization compute between rounds; physical execution time per batch dominates compute costs. No concrete CPU or cost numbers provided.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_structure</strong></td>
                            <td>Well-defined iterative optimization problem with stochastic evaluations and settings for exploration vs exploitation.</td>
                        </tr>
                        <tr>
                            <td><strong>success_metric</strong></td>
                            <td>Composite recipe score improvement across rounds and final functional performance (RMSE = 2.68%). The distribution of scores shows rising maximums across rounds toward a near-global optimum.</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td>After 5 rounds (480 samples) the system approached a quasi-global optimum; improvements in maximum scores tapered after 5 rounds, indicating practical convergence in this task.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>Algorithmic exploration yields many low-scoring recipes; finding better recipes in regions of high uncertainty is challenging; diminishing returns after several rounds.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>High-throughput robotics to generate data, Bayesian optimization to target uncertain/high-potential regions, a composite scoring function to aggregate multiple performance indicators.</td>
                        </tr>
                        <tr>
                            <td><strong>comparative_results</strong></td>
                            <td>No explicit comparison with alternative optimization strategies in this paper, though the approach is claimed to be efficient and to reach near-optimal recipes within 5 rounds.</td>
                        </tr>
                        <tr>
                            <td><strong>human_baseline</strong></td>
                            <td>Manual iterative tuning would be substantially slower and more resource-intensive; no direct timing or quality comparison is provided.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'GPT-Lab: Next Generation Of Optimal Chemistry Discovery By GPT Driven Robotic Lab', 'publication_date_yy_mm': '2023-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2634.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e2634.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated research systems, AI scientists, or automated idea generation/implementation systems, including details about what types of research problems they were applied to, the characteristics of those problems, and the success or failure rates of the automated system.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Bayesian optimization</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Bayesian optimization algorithm (for experimental design)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A probabilistic optimization algorithm used to select subsequent experimental recipes by balancing exploration and exploitation in the continuous formulation space.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Bayesian optimization</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Used after the initial random batch to propose next recipes with a tunable inclination toward exploration or exploitation; chooses samples in regions of high model uncertainty or high predicted improvement to optimize the composite score.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>Automated Optimization Algorithm</td>
                        </tr>
                        <tr>
                            <td><strong>problem_domain</strong></td>
                            <td>Optimization of continuous formulation parameters in chemistry/materials experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Select next experiments in a 7-dimensional continuous space to efficiently improve sensor performance metrics aggregated into a score.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Continuous, noisy, multi-objective (collapsed into a single weighted objective), dimensionality = 7, batch evaluations (96/round).</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Uses robot-generated experimental outcomes as training points; initial 96 random samples seeded the model, then iteratively augmented.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_requirements</strong></td>
                            <td>Standard Bayesian optimization compute between rounds (surrogate model fitting and acquisition optimization) — modest relative to LLM API costs and experimental runtime.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_structure</strong></td>
                            <td>Stochastic, well-defined optimization problem with clear scalar objective and experimental noise.</td>
                        </tr>
                        <tr>
                            <td><strong>success_metric</strong></td>
                            <td>Improvement in maximum observed composite score across rounds and final application metric (RMSE = 2.68% when combined into final sensor selection).</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td>Contributed to progressive improvement in the maximum scores across rounds and to near-convergence by round 5; exploration choices produced some low-score recipes but enabled global search and avoided local optima.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>Exploration strategy yields many poor-performing candidates; difficulty in further improvement when nearing quasi-global optimum; performance subject to surrogate model fidelity and noise.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Batch evaluation capability (96 per round), informative composite score, and high-quality robotic data reduce surrogate noise and improve BO effectiveness.</td>
                        </tr>
                        <tr>
                            <td><strong>comparative_results</strong></td>
                            <td>No direct empirical comparisons to other optimizers reported; authors attribute observed convergence pattern and score improvements to Bayesian strategies.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'GPT-Lab: Next Generation Of Optimal Chemistry Discovery By GPT Driven Robotic Lab', 'publication_date_yy_mm': '2023-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2634.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e2634.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated research systems, AI scientists, or automated idea generation/implementation systems, including details about what types of research problems they were applied to, the characteristics of those problems, and the success or failure rates of the automated system.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CMU GPT Agent (related work)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Emergent autonomous scientific research capabilities of large language models (CMU demonstration)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A referenced prior demonstration (Boiko et al.) showing GPT-based agents assisting researchers by reading hardware documents and using the Opentrons API to control lab equipment, motivating GPT-Lab's approach.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Emergent autonomous scientific research capabilities of large language models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>CMU GPT Agent (Boiko et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Mentioned as pioneering work where a GPT Agent was used to read hardware documents and call lab-control APIs (Opentrons) to assist experimental design and automation. Cited as evidence that GPT-4 can be effective in experimental design processes.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>AI Agent / Automated Experimental Assistant (prior work)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_domain</strong></td>
                            <td>Automation of lab protocols and hardware control (wet lab automation assistance).</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Use of large language models to interpret documentation and programmatically control lab equipment via APIs.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Document understanding plus API usage; complexity depends on hardware control safety and protocol correctness.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Not detailed in this paper; cited as prior art.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_requirements</strong></td>
                            <td>Not detailed here.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_structure</strong></td>
                            <td>Structured API-call problem driven by language understanding; safety and correctness critical.</td>
                        </tr>
                        <tr>
                            <td><strong>success_metric</strong></td>
                            <td>Reported as motivation; specifics are in the cited paper (Boiko et al.).</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td>Not quantified in this paper (reference only).</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>Not discussed here; authors cite this work only as evidence of GPT utility in experimental design.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>LLM language understanding and API accessibility (Opentrons).</td>
                        </tr>
                        <tr>
                            <td><strong>comparative_results</strong></td>
                            <td>Used as context motivating GPT-Lab; GPT-Lab aims to go further by integrating literature mining and full materials discovery validation.</td>
                        </tr>
                        <tr>
                            <td><strong>human_baseline</strong></td>
                            <td>Not provided in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'GPT-Lab: Next Generation Of Optimal Chemistry Discovery By GPT Driven Robotic Lab', 'publication_date_yy_mm': '2023-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2634.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e2634.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated research systems, AI scientists, or automated idea generation/implementation systems, including details about what types of research problems they were applied to, the characteristics of those problems, and the success or failure rates of the automated system.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Robot scientist (King et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Functional genomic hypothesis generation and experimentation by a robot (Robot Scientist)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A classic prior example of an automated 'robot scientist' that generated hypotheses and executed experiments in functional genomics (cited as historical antecedent to modern SDLs).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Functional genomic hypothesis generation and experimentation by a robot</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Robot Scientist (King et al., 2004)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Cited as foundational work in automated hypothesis generation and experiment execution (robot scientist capable of generating and testing functional genomic hypotheses). Used in the introduction to position GPT-Lab in the lineage of self-driving laboratories.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>Automated Discovery System / Robot Scientist (prior work)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_domain</strong></td>
                            <td>Functional genomics and automated hypothesis-driven experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Automated generation and experimental testing of biological hypotheses.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Historically significant example of closed-loop automation in biology; details are in the cited work.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Not detailed here.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_requirements</strong></td>
                            <td>Not detailed here.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_structure</strong></td>
                            <td>Hypothesis generation and experimental testing loop.</td>
                        </tr>
                        <tr>
                            <td><strong>success_metric</strong></td>
                            <td>Not quantified in this paper (reference only).</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td>Not provided here.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>Not discussed in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Historical demonstration of effective automation and hypothesis-generation coupling.</td>
                        </tr>
                        <tr>
                            <td><strong>comparative_results</strong></td>
                            <td>Serves as background; GPT-Lab extends the lineage by integrating modern LLMs for literature mining and experimental design.</td>
                        </tr>
                        <tr>
                            <td><strong>human_baseline</strong></td>
                            <td>Not provided here.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'GPT-Lab: Next Generation Of Optimal Chemistry Discovery By GPT Driven Robotic Lab', 'publication_date_yy_mm': '2023-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Functional genomic hypothesis generation and experimentation by a robot <em>(Rating: 2)</em></li>
                <li>Emergent autonomous scientific research capabilities of large language models <em>(Rating: 2)</em></li>
                <li>A mobile robotic chemist <em>(Rating: 2)</em></li>
                <li>Controlling an organic synthesis robot with machine learning to search for new reactivity <em>(Rating: 2)</em></li>
                <li>Opentrons Python Protocol API <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2634",
    "paper_id": "paper-91b68391df0b16d22bffbbf4d0c09f13dee36561",
    "extraction_schema_id": "extraction-schema-66",
    "extracted_data": [
        {
            "name_short": "GPT-Lab",
            "name_full": "GPT-Lab: GPT driven robotic lab",
            "brief_description": "An integrated automated discovery system combining a GPT-4-based agent with an algorithm-driven robotic experimentation platform to perform end-to-end literature mining, experiment design, and high-throughput experimental validation for materials discovery.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "GPT-Lab",
            "system_description": "A closed-loop automated discovery system that couples an LLM-based agent (ChatGPT/GPT-4 API) with a robotic liquid-handling and sensing platform. The agent implements the ARMFE pipeline (Analysis - Retrieval - Mining - Feedback Execution) to: (1) take researcher requirements and generate search keywords, (2) retrieve and filter literature (titles/abstracts), (3) use GPT to extract substances, roles and build structured JSON records, (4) present curated candidate materials to humans for selection, (5) translate selected materials into machine-readable exchange files (CAS codes + concentrations) and (6) send parameters to the robotic platform for automated recipe preparation, testing, and iterative optimization. The robotic side executes high-throughput wet experiments (96 samples/batch), captures visual data (color vs time), computes multi-indicator scores, and iterates using an algorithm-guided optimization loop (DBTM + Bayesian optimization). The system also supports human-in-the-loop feedback for selection and verification.",
            "system_type": "Automated Discovery System / AI Scientist / Automated Experimentation Platform",
            "problem_domain": "Chemistry and materials science (sensor materials discovery), specifically development and optimization of colorimetric relative-humidity (RH) sensors; demonstrated also for perovskite solar-cell materials discovery and chromatographic methods for alkaloid detection in mulberry leaves.",
            "problem_description": "Discover candidate sensing materials and formulation recipes for a colorimetric humidity sensor by (a) mining literature for relevant reagents and their roles, (b) proposing a materials design space and candidate recipes, and (c) executing high-throughput formulation and testing to optimize sensor performance (sensitivity, response time, reversibility, and RH prediction accuracy). The system was also used to search materials lists for perovskite solar cells and to propose experimental methods for alkaloid detection.",
            "problem_complexity": "Multi-step, multi-objective experimental optimization with mixed tasks: open-ended literature mining (large, unstructured search space) and continuous formulation optimization. Quantitative aspects: literature mining processed 500 articles; candidate generation produced 50 potential reagents (18 with relevance &gt;=80%, including 8 candidate core materials). Experimental optimization explored a 7-dimensional continuous formulation space (8 reagents with fixed total quantity, so 7 degrees of freedom) using batches of 96 samples per round and 5 rounds (480 experiments total). Objectives combined multiple metrics (color change amplitude, response time, reversibility, sensitivity) into a weighted score; final evaluation used RH prediction RMSE.",
            "data_availability": "Literature-rich for mining: 500 articles were collected and processed in the demonstration. Experimental data was generated by the robotic platform (480 high-throughput samples). Data quality benefited from robotic consistency (liquid handler, controlled gas path, fixed lighting) but required aggregation of multi-indicator metrics to form a composite score. Some human curation remained necessary (researchers selected from the candidate list and filtered experimental parameters).",
            "computational_requirements": "Literature processing: the agent processed ~100 articles/hour (single-threaded) and can be accelerated 3–5x with multi-threading; claimed &gt;100x time saving vs manual extraction for large corpora. Experimental evaluation: 480 wet experiments over 5 rounds; compute for image processing and Bayesian optimization unspecified but modest relative to LLM API costs. Additional compute/cost drivers: repeated GPT (ChatGPT/GPT-4) API calls for extraction/filtering and retries to handle hallucinations (authors note increased GPT usage cost and programmatic retry overhead).",
            "problem_structure": "Hybrid problem: literature mining is open-ended, language-understanding heavy and prone to ambiguity; formulation optimization is continuous, stochastic (experimental noise), multi-objective, and has clear evaluation metrics derived from sensor measurements. Requires domain knowledge (chemistry/materials) for valid reagent suggestions and safe experimental parameters. The experimental loop is deterministic at the robotic execution level but measurements have experimental variability.",
            "success_metric": "Quantitative: (a) materials-mining yield (number of candidate reagents and those above relevance threshold), (b) experimental optimization score (composite weighted metric from color-change measures), and (c) final functional performance: RH prediction root mean square error (RMSE = 2.68% over 5–95% RH). Secondary metrics: throughput (articles/hour), time-to-proof-of-concept (built a working sensor within one week with minor human interference).",
            "success_rate": "Demonstrated success on the humidity-sensor task: from 500 articles the system proposed 50 reagent candidates and after filtering flagged 18 reagents with &gt;=80% relevance (8 core candidates). Robotic optimization ran 480 experiments (5 rounds of 96) and delivered a two-recipe sensor array that predicted RH across 5–95% with RMSE = 2.68%. Processing speed ~100 articles/hour (single-threaded), claimed &gt;100x time saving vs manual literature search. No explicit failure rate is given for tasks such as reagent suggestions, but authors note GPT hallucinations and the need for human filtering.",
            "failure_modes": "Observed: (1) GPT hallucination and inaccurate outputs requiring programmatic checks and retries; (2) GPT's limited domain-specific knowledge outside its training/exposed literature, forcing human filtering of experimental parameters; (3) some suggested substances by raw GPT were infeasible for robotic execution—necessitating additional filtering/feasibility checks; (4) exploration-heavy optimization produced many low-score recipes (deliberate exploration causing poor-performing samples) and made finding better recipes in high-uncertainty regions difficult; (5) increased monetary cost and system complexity due to heavy GPT API usage and retry logic.",
            "success_factors": "Key enablers: (a) integration of literature mining with robotic high-throughput execution enabling rapid iteration; (b) structured pipeline (ARMFE) that converts text to machine-executable parameters (CAS codes and concentrations); (c) algorithm-guided experimental design (DBTM + Bayesian optimization) to efficiently explore a continuous 7D formulation space; (d) consistent robotic execution and standardized measurement (controlled gas mixing, lighting, and automated computer-vision color extraction) producing high-quality data; (e) human-in-the-loop selection to prevent infeasible suggestions from causing unsafe or impossible robot tasks.",
            "comparative_results": "Authors report qualitative and quantitative advantages vs alternatives: (a) vs manual literature review: &gt;100x speed-up in extraction for large corpora; (b) vs 'pure GPT': GPT-Lab produced higher accuracy and feasibility — fewer hallucinated or robot-infeasible material suggestions and provided literature sources and theoretical justifications; (c) generalization: the approach produced useful outputs in heterogeneous problems (humidity sensors, perovskite materials list, alkaloid analysis methods), indicating domain-transfer capability. No controlled head-to-head numerical benchmark versus human experts or other automated systems is provided beyond the stated throughput and final RMSE.",
            "human_baseline": "No precise numeric human baseline provided; qualitative comparisons: manual literature extraction is stated to be over 100x slower for large literature volumes; human experts still required to filter and select experimental parameters (authors retained human researcher feedback step). There is no direct human-vs-system accuracy comparison for reagent selection or final sensor performance.",
            "uuid": "e2634.0",
            "source_info": {
                "paper_title": "GPT-Lab: Next Generation Of Optimal Chemistry Discovery By GPT Driven Robotic Lab",
                "publication_date_yy_mm": "2023-09"
            }
        },
        {
            "name_short": "ARMFE",
            "name_full": "ARMFE (Analysis - Retrieval - Mining - Feedback Execution)",
            "brief_description": "The procedural pipeline used inside GPT-Lab that structures end-to-end automated research: requirements analysis, literature retrieval, text mining, human researcher feedback, and automated experiment execution.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "ARMFE pipeline",
            "system_description": "A stepwise agent workflow: (1) Requirements analysis: agent prompts researchers and generates five keywords for searches; (2) Literature retrieval: online search by keywords, title/abstract filtering; (3) Text mining: GPT extracts substances, CAS numbers, roles and builds JSON files; (4) Human researcher feedback: curated parameters presented to researchers for selection; (5) Experiment execution: agent compiles exchange files (CAS + concentrations) for the robotic platform and triggers automated experiments. ARMFE integrates human-in-the-loop selection to ensure feasibility.",
            "system_type": "Automated Pipeline / Agent-based literature-to-experiment pipeline",
            "problem_domain": "Literature mining and automated experimental design for chemistry/materials science (sensor materials), applicable to other experimental R&D tasks.",
            "problem_description": "Transform natural-language experimental requirements into a curated materials and parameter space suitable for robotic execution by mining literature and generating machine-readable experimental plans.",
            "problem_complexity": "Handles large unstructured text corpora and translates to structured experimental variables; complexity driven by diversity and ambiguity of literature, necessity of correct extraction (CAS, roles), and mapping to robot-capable parameterizations.",
            "data_availability": "Demonstrated on 500 articles; depends on public availability of articles, abstracts and full-text retrieval. The pipeline preserves JSON records for downstream selection and execution.",
            "computational_requirements": "Requires repeated LLM API calls for keyword generation, relevance filtering and text extraction; reported throughput ~100 articles/hour (single-threaded), scaleable via multi-threading to 3–5x that rate.",
            "problem_structure": "Semi-structured: mapping from language to structured experimental parameters is rule-like but requires semantic understanding and external validation; the execution side is well-defined and requires robot-feasible parameter formats.",
            "success_metric": "Throughput (articles/hour), yield of feasible candidates (e.g., 50 candidates from 500 articles; 18 &gt;=80% relevance), and downstream experimental success when executed by the robot.",
            "success_rate": "On the demonstration corpus (500 articles) ARMFE produced 50 candidate reagents and after filtering highlighted 18 reagents with relevance &gt;=80%. No explicit precision/recall metrics reported for extraction accuracy.",
            "failure_modes": "Errors from LLM extraction (hallucinations, incorrect CAS or roles), missing or paywalled full texts limiting retrieval, and mismatch between extracted experimental details and robot execution constraints.",
            "success_factors": "Structured prompts, multi-stage filtering (title/abstract then full-text), JSON structuring for downstream use, human-in-the-loop verification, and strong integration with the robotic execution format (CAS + concentrations).",
            "comparative_results": "Authors claim ARMFE outperforms naive LLM-only extraction by reducing hallucinations and focus on robot-feasible materials; also far faster than manual extraction. No quantitative baseline beyond the stated yields and throughput.",
            "human_baseline": "Human researchers typically must read and extract from many papers manually; authors estimate manual extraction is &gt;100x slower for large corpora, though no controlled timing study is provided.",
            "uuid": "e2634.1",
            "source_info": {
                "paper_title": "GPT-Lab: Next Generation Of Optimal Chemistry Discovery By GPT Driven Robotic Lab",
                "publication_date_yy_mm": "2023-09"
            }
        },
        {
            "name_short": "GPT-4 agent",
            "name_full": "GPT-4-based experimental design agent (via ChatGPT API)",
            "brief_description": "A generative large language model used as the core reasoning and text-mining component of GPT-Lab to generate keywords, filter literature, extract reagent information, assemble JSON structured outputs, and interact via clarifying questions for incomplete requisitions.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "GPT-4 (ChatGPT API)",
            "system_description": "Used as an agent to: generate search keywords from researcher requirements; filter titles/abstracts for relevance; read full-text articles and extract reagent names, CAS numbers, roles and rationales; assemble JSON entries; ask clarifying questions to refine requirements; and produce experimental-parameter JSON for robot execution. The model was accessed through ChatGPT API prompts; authors note extensive prompt engineering and programmatic checks to reduce hallucination.",
            "system_type": "Large Language Model Agent / Automated Idea Generation System",
            "problem_domain": "Text mining, experimental protocol design and translation of natural language literature into structured experimental parameters for chemistry/materials R&D.",
            "problem_description": "Semantic extraction of materials and methods from scientific literature and generation of experiment designs suitable for robotic execution.",
            "problem_complexity": "Requires deep language understanding and domain grounding; must map ambiguous textual mentions to concrete entities (e.g., CAS numbers, roles) and determine feasibility for robot execution.",
            "data_availability": "Operates on retrieved literature (titles, abstracts, full-text). No fine-tuning reported; relies on in-context prompting over the API. Authors note limits where GPT lacks domain-specific knowledge not present in its exposure.",
            "computational_requirements": "Frequent API calls at scale (processing 500 articles required hundreds to thousands of prompts); the authors flag increased monetary cost and additional programmatic retry logic to handle incorrect outputs.",
            "problem_structure": "Open-ended natural language understanding task; not purely deterministic due to LLM stochasticity; outputs require structured extraction and downstream validation.",
            "success_metric": "Number of feasible reagent suggestions, throughput (articles/hour ~100), and contribution to downstream experimental success (final RMSE 2.68% when integrated into GPT-Lab).",
            "success_rate": "Practical success demonstrated: with the LLM agent in GPT-Lab the system identified 50 potential reagents from 500 articles and 18 with high relevance. However, authors report many raw GPT outputs can be infeasible or hallucinated if used alone; GPT-Lab's additional filtering improved feasibility.",
            "failure_modes": "Hallucination (inventing reagents/roles without theoretical basis), inaccurate numeric or CAS outputs, limited domain-specific knowledge beyond its training exposures, and costs from repeated API usage and programmatic retries.",
            "success_factors": "Prompt engineering, multi-stage filtering (title/abstract then full-text), integration with downstream feasibility filters and human-in-the-loop checks, and coupling with robotic validation to close the loop.",
            "comparative_results": "Authors state GPT-Lab's agent (with pipeline and filters) had higher accuracy/feasibility than 'pure GPT' usage, which tended to hallucinate and propose experimentally infeasible materials. No formal numerical head-to-head reported.",
            "human_baseline": "Human experts still required for final filtering of experimental parameters; the LLM accelerated literature triage but did not fully remove human oversight.",
            "uuid": "e2634.2",
            "source_info": {
                "paper_title": "GPT-Lab: Next Generation Of Optimal Chemistry Discovery By GPT Driven Robotic Lab",
                "publication_date_yy_mm": "2023-09"
            }
        },
        {
            "name_short": "Robotic platform",
            "name_full": "Algorithm-driven robotic experimentation platform (liquid handling workstation + sensing/darkroom)",
            "brief_description": "A high-throughput robotic laboratory setup that prepares liquid formulations, fabricates colorimetric sensing units, exposes them to controlled humidity streams, records color-change data by imaging, and returns quantitative metrics for optimization.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Robotic experimentation platform (liquid handler + darkroom + sensing chamber)",
            "system_description": "Consists of a liquid handling workstation (stock solution area, pipette tip area, recipe configuration area, sensing unit fabrication area), a self-built darkroom with controlled lighting and camera, and a gas path with two MFCs to create controlled RH conditions. The robot fabricates 96 sensing samples per batch, tests them by exposing to different humidities and records color vs. time for each sample. Image data are processed to compute indicators (amplitude, response time, reversibility, sensitivity) that are weighted into a composite score for optimization.",
            "system_type": "Automated Experimentation Platform / High-throughput Robotic Lab",
            "problem_domain": "Experimental fabrication and testing in chemistry/materials science — development of humidity colorimetric sensors.",
            "problem_description": "Execute recipes produced by the agent at scale, fabricate sensing units, test under controlled humidity ranges (5%–95% RH), and produce measurement data for iterative optimization.",
            "problem_complexity": "High-throughput experimental workload with physical noise and variability; formulation space of 8 reagents (7 DOF) with continuous concentrations, multiple competing objectives to optimize (sensitivity, response time, reversibility, prediction accuracy).",
            "data_availability": "Generates primary experimental data (480 sample experiments in the demonstration). Data are of high consistency due to robotic preparation and controlled testing environment.",
            "computational_requirements": "Experimental throughput: 96 samples per batch; 5 rounds = 480 samples. Image processing and score computation per sample are modest compute loads. No explicit CPU/memory/time in seconds provided, but robotic runtime and physical testing time dominate.",
            "problem_structure": "Well-defined execution tasks (robotic protocols) but stochastic measurement noise; experiments yield quantitative metrics and clear evaluation functions enabling closed-loop optimization.",
            "success_metric": "Composite weighted score from colorimetric indicators and final RH prediction RMSE (2.68%). Tracking of score distributions across rounds (max score increases as optimization proceeds).",
            "success_rate": "Using agent-specified materials and DBTM-guided exploration, the robot executed 480 experiments leading to a near-optimal recipe set and a sensor array achieving RMSE = 2.68% across 5%–95% RH. Some batches contained many low-score (near-zero) recipes due to exploration-heavy sampling.",
            "failure_modes": "Exploratory sampling can produce many low-performing recipes; physical execution limits (reagent incompatibilities) if upstream filtering fails; potential for measurement noise leading to uncertainty and difficulty finding improvements in high-uncertainty regions.",
            "success_factors": "Precise liquid handling, controlled gas-mixing for RH, standardized imaging/darkroom environment, and integration with Bayesian optimization informed sampling.",
            "comparative_results": "No direct baseline robotic comparison provided; authors emphasize that robotic consistency enables generation of high-quality data for algorithmic optimization and that integration with GPT-based literature mining speeds end-to-end discovery vs manual workflows.",
            "human_baseline": "Human-executed experiments would be much slower and more variable; no direct numeric human baseline provided.",
            "uuid": "e2634.3",
            "source_info": {
                "paper_title": "GPT-Lab: Next Generation Of Optimal Chemistry Discovery By GPT Driven Robotic Lab",
                "publication_date_yy_mm": "2023-09"
            }
        },
        {
            "name_short": "DBTM",
            "name_full": "DBTM process (algorithm-guided iterative experimental process)",
            "brief_description": "An iterative algorithm-guided experimental process used on the robotic platform that cycles 'recipe generation - robotic preparation - robotic testing - data processing - next-round recipe generation' to efficiently search formulation space.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "DBTM (algorithm-guided experimental loop)",
            "system_description": "DBTM is an iterative closed-loop experimental strategy implemented on the robot: initial recipes are generated (first round random), fabricated and tested by the robot, data processed into metrics, and the algorithm (Bayesian optimization) uses results to propose next-round recipes mixing exploration and exploitation. The authors reference earlier work (their ref. 26) for a similar DBTM implementation.",
            "system_type": "Automated Experimentation Control / Iterative Optimization Process",
            "problem_domain": "Automated experimental optimization in chemistry/materials (sensor formulation optimization).",
            "problem_description": "Efficient sampling of a continuous, multi-dimensional formulation space to discover high-performing recipes with minimal experiments.",
            "problem_complexity": "Search in a 7-dimensional continuous space with noisy objective evaluations and multi-objective trade-offs (combined into a single weighted score). Starts with 96 random recipes then iterates using Bayesian strategies.",
            "data_availability": "Relies on robot-generated experimental outcomes; demonstrated with 5 rounds (96 samples each) for 480 total experiments.",
            "computational_requirements": "Requires experiment scheduling and Bayesian optimization compute between rounds; physical execution time per batch dominates compute costs. No concrete CPU or cost numbers provided.",
            "problem_structure": "Well-defined iterative optimization problem with stochastic evaluations and settings for exploration vs exploitation.",
            "success_metric": "Composite recipe score improvement across rounds and final functional performance (RMSE = 2.68%). The distribution of scores shows rising maximums across rounds toward a near-global optimum.",
            "success_rate": "After 5 rounds (480 samples) the system approached a quasi-global optimum; improvements in maximum scores tapered after 5 rounds, indicating practical convergence in this task.",
            "failure_modes": "Algorithmic exploration yields many low-scoring recipes; finding better recipes in regions of high uncertainty is challenging; diminishing returns after several rounds.",
            "success_factors": "High-throughput robotics to generate data, Bayesian optimization to target uncertain/high-potential regions, a composite scoring function to aggregate multiple performance indicators.",
            "comparative_results": "No explicit comparison with alternative optimization strategies in this paper, though the approach is claimed to be efficient and to reach near-optimal recipes within 5 rounds.",
            "human_baseline": "Manual iterative tuning would be substantially slower and more resource-intensive; no direct timing or quality comparison is provided.",
            "uuid": "e2634.4",
            "source_info": {
                "paper_title": "GPT-Lab: Next Generation Of Optimal Chemistry Discovery By GPT Driven Robotic Lab",
                "publication_date_yy_mm": "2023-09"
            }
        },
        {
            "name_short": "Bayesian optimization",
            "name_full": "Bayesian optimization algorithm (for experimental design)",
            "brief_description": "A probabilistic optimization algorithm used to select subsequent experimental recipes by balancing exploration and exploitation in the continuous formulation space.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "Bayesian optimization",
            "system_description": "Used after the initial random batch to propose next recipes with a tunable inclination toward exploration or exploitation; chooses samples in regions of high model uncertainty or high predicted improvement to optimize the composite score.",
            "system_type": "Automated Optimization Algorithm",
            "problem_domain": "Optimization of continuous formulation parameters in chemistry/materials experiments.",
            "problem_description": "Select next experiments in a 7-dimensional continuous space to efficiently improve sensor performance metrics aggregated into a score.",
            "problem_complexity": "Continuous, noisy, multi-objective (collapsed into a single weighted objective), dimensionality = 7, batch evaluations (96/round).",
            "data_availability": "Uses robot-generated experimental outcomes as training points; initial 96 random samples seeded the model, then iteratively augmented.",
            "computational_requirements": "Standard Bayesian optimization compute between rounds (surrogate model fitting and acquisition optimization) — modest relative to LLM API costs and experimental runtime.",
            "problem_structure": "Stochastic, well-defined optimization problem with clear scalar objective and experimental noise.",
            "success_metric": "Improvement in maximum observed composite score across rounds and final application metric (RMSE = 2.68% when combined into final sensor selection).",
            "success_rate": "Contributed to progressive improvement in the maximum scores across rounds and to near-convergence by round 5; exploration choices produced some low-score recipes but enabled global search and avoided local optima.",
            "failure_modes": "Exploration strategy yields many poor-performing candidates; difficulty in further improvement when nearing quasi-global optimum; performance subject to surrogate model fidelity and noise.",
            "success_factors": "Batch evaluation capability (96 per round), informative composite score, and high-quality robotic data reduce surrogate noise and improve BO effectiveness.",
            "comparative_results": "No direct empirical comparisons to other optimizers reported; authors attribute observed convergence pattern and score improvements to Bayesian strategies.",
            "uuid": "e2634.5",
            "source_info": {
                "paper_title": "GPT-Lab: Next Generation Of Optimal Chemistry Discovery By GPT Driven Robotic Lab",
                "publication_date_yy_mm": "2023-09"
            }
        },
        {
            "name_short": "CMU GPT Agent (related work)",
            "name_full": "Emergent autonomous scientific research capabilities of large language models (CMU demonstration)",
            "brief_description": "A referenced prior demonstration (Boiko et al.) showing GPT-based agents assisting researchers by reading hardware documents and using the Opentrons API to control lab equipment, motivating GPT-Lab's approach.",
            "citation_title": "Emergent autonomous scientific research capabilities of large language models",
            "mention_or_use": "mention",
            "system_name": "CMU GPT Agent (Boiko et al.)",
            "system_description": "Mentioned as pioneering work where a GPT Agent was used to read hardware documents and call lab-control APIs (Opentrons) to assist experimental design and automation. Cited as evidence that GPT-4 can be effective in experimental design processes.",
            "system_type": "AI Agent / Automated Experimental Assistant (prior work)",
            "problem_domain": "Automation of lab protocols and hardware control (wet lab automation assistance).",
            "problem_description": "Use of large language models to interpret documentation and programmatically control lab equipment via APIs.",
            "problem_complexity": "Document understanding plus API usage; complexity depends on hardware control safety and protocol correctness.",
            "data_availability": "Not detailed in this paper; cited as prior art.",
            "computational_requirements": "Not detailed here.",
            "problem_structure": "Structured API-call problem driven by language understanding; safety and correctness critical.",
            "success_metric": "Reported as motivation; specifics are in the cited paper (Boiko et al.).",
            "success_rate": "Not quantified in this paper (reference only).",
            "failure_modes": "Not discussed here; authors cite this work only as evidence of GPT utility in experimental design.",
            "success_factors": "LLM language understanding and API accessibility (Opentrons).",
            "comparative_results": "Used as context motivating GPT-Lab; GPT-Lab aims to go further by integrating literature mining and full materials discovery validation.",
            "human_baseline": "Not provided in this paper.",
            "uuid": "e2634.6",
            "source_info": {
                "paper_title": "GPT-Lab: Next Generation Of Optimal Chemistry Discovery By GPT Driven Robotic Lab",
                "publication_date_yy_mm": "2023-09"
            }
        },
        {
            "name_short": "Robot scientist (King et al.)",
            "name_full": "Functional genomic hypothesis generation and experimentation by a robot (Robot Scientist)",
            "brief_description": "A classic prior example of an automated 'robot scientist' that generated hypotheses and executed experiments in functional genomics (cited as historical antecedent to modern SDLs).",
            "citation_title": "Functional genomic hypothesis generation and experimentation by a robot",
            "mention_or_use": "mention",
            "system_name": "Robot Scientist (King et al., 2004)",
            "system_description": "Cited as foundational work in automated hypothesis generation and experiment execution (robot scientist capable of generating and testing functional genomic hypotheses). Used in the introduction to position GPT-Lab in the lineage of self-driving laboratories.",
            "system_type": "Automated Discovery System / Robot Scientist (prior work)",
            "problem_domain": "Functional genomics and automated hypothesis-driven experiments.",
            "problem_description": "Automated generation and experimental testing of biological hypotheses.",
            "problem_complexity": "Historically significant example of closed-loop automation in biology; details are in the cited work.",
            "data_availability": "Not detailed here.",
            "computational_requirements": "Not detailed here.",
            "problem_structure": "Hypothesis generation and experimental testing loop.",
            "success_metric": "Not quantified in this paper (reference only).",
            "success_rate": "Not provided here.",
            "failure_modes": "Not discussed in this paper.",
            "success_factors": "Historical demonstration of effective automation and hypothesis-generation coupling.",
            "comparative_results": "Serves as background; GPT-Lab extends the lineage by integrating modern LLMs for literature mining and experimental design.",
            "human_baseline": "Not provided here.",
            "uuid": "e2634.7",
            "source_info": {
                "paper_title": "GPT-Lab: Next Generation Of Optimal Chemistry Discovery By GPT Driven Robotic Lab",
                "publication_date_yy_mm": "2023-09"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Functional genomic hypothesis generation and experimentation by a robot",
            "rating": 2
        },
        {
            "paper_title": "Emergent autonomous scientific research capabilities of large language models",
            "rating": 2
        },
        {
            "paper_title": "A mobile robotic chemist",
            "rating": 2
        },
        {
            "paper_title": "Controlling an organic synthesis robot with machine learning to search for new reactivity",
            "rating": 2
        },
        {
            "paper_title": "Opentrons Python Protocol API",
            "rating": 1
        }
    ],
    "cost": 0.01907625,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>GPT-LAB: NEXT GENERATION OF OPTIMAL CHEMISTRY DISCOVERY BY GPT DRIVEN ROBOTIC LAB</h1>
<p>Xiaokai Qin<br>Research Center for Intelligent Sensing Systems<br>Zhejiang Laboratory<br>Hangzhou, Zhejiang 311121, China<br>qi0002ai@e.ntu.edu.sg<br>Yangguan Chen<br>Research Center for Intelligent Sensing Systems<br>Zhejiang Laboratory<br>Hangzhou, Zhejiang 311121, China<br>chenyg@zhejianglab.com</p>
<p>Mingda Song<br>Research Center for Intelligent Sensing Systems<br>Zhejiang Laboratory<br>Hangzhou, Zhejiang 311121, China<br>u7386168@anu.edu.au<br>Zhehong Ai<br>Research Center for Intelligent Sensing Systems<br>Zhejiang Laboratory<br>Hangzhou, Zhejiang 311121, China<br>aizhehong20@mails.ucas.ac.cn</p>
<p>Jing Jiang*<br>Research Center for Intelligent Sensing Systems<br>Zhejiang Laboratory<br>Hangzhou, Zhejiang 311121, China<br>jiangj@zhejianglab.com</p>
<p>October 2, 2023</p>
<h4>Abstract</h4>
<p>The integration of robots in chemical experiments has enhanced experimental efficiency, but lacking the human intelligence to comprehend literature, they seldom provide assistance in experimental design. Therefore, achieving full-process autonomy from experiment design to validation in self-driven laboratories (SDL) remains a challenge. The introduction of Generative Pre-trained Transformers (GPT), particularly GPT-4, into robotic experimentation offers a solution. We introduce GPT-Lab, a paradigm that employs GPT models to give robots human-like intelligence. With our robotic experimentation platform, GPT-Lab mines literature for materials and methods and validates findings through high-throughput synthesis. As a demonstration, GPT-Lab analyzed 500 articles, identified 18 potential reagents, and successfully produced an accurate humidity colorimetric sensor with a root mean square error (RMSE) of $2.68 \%$. This showcases the rapid materials discovery and validation potential of our system.</p>
<p>Keywords Large Language Models $\cdot$ Intelligent Agents $\cdot$ Generative AI $\cdot$ Autonomous Experimentation $\cdot$ Automation $\cdot$ Chemical Sciences $\cdot$ Robot Experimentation $\cdot$ Materia Sciences</p>
<h2>1 Introduction</h2>
<p>In recent years, the applications of self-driven laboratory (SDL) in fields of materials, chemical synthesis, biology, and medicine aroused widespread attention. SDLs typically includes the automation of experiments conduction with robotics and the usage of algorithm to guide robots to design, conduct and optimize the experiments. Leveraging the advantages of robotic executions in high consistency and accuracy, this application enables the generation of high-quality data for large scale search problems. The easier integration of advanced data-driven algorithms also</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>surpassed human researchers in the context of high dimensionality and large scale of data processing. To some extent, this technique has showcased a significant acceleration in the discovery and design of new functional materials, synthetic paths, medicines [1-8]. However, most reported SDLs still relied on experienced scientist in designing and defining the search space for the robots in the first place, which includes searching and reviewing related literatures, propose possible product designs, and even some early stage manual experimental verifications. This still requires investing a considerable amount of time which can easily become the bottleneck for SDL applications [9,10].
Text mining holds the potential to expedite this process by preprocessing literatures for human experts. Many researchers have attempted to employ Natural Language Processing (NLP) techniques for text mining to extract information about experimental materials, protocols, and designs [11-18]. With the emergence of large language models (LLMs), researchers have explored their application in various traditional NLP tasks with promising results [19-21]. The advent of GPT-4, in particular, has garnered significant attention due to its impressive capabilities in language understanding and generation demonstrated across multiple domains [22]. Compared to traditional NLP models, GPT is better suited for literature mining and experimental protocol design with limited training data, demonstrating impressive performance even without extensive fine-tuning [23].
Pioneering work in this direction has been conducted by researchers at CMU [24], who showcased the application of GPT's Agent to assist scientific researchers in reading hardware documents and utilizing the Opentrons API [25]. This experiment demonstrated the remarkable effectiveness of GPT-4 in the experimental design process, providing valuable insights into the potential of GPT for further exploration in the realm of experimental automation. Indeed, while there have been some promising initial attempts to utilize GPT for controlling experimental equipment and achieving success in that domain, fully replacing the role of researchers in collecting and referencing extensive literature for discovering novel reagents or materials has not been accomplished yet. The potential of GPT for assisting with literature text mining and material discovery is undeniable, given its language understanding capabilities and context-awareness. However, certain challenges remain to be addressed before GPT can autonomously and reliably identify new experimental reagents with minimal human intervention.
In this work, we designed a GPT enhanced SDL pipeline called ARMFE (Analysis - Retrieval - Mining - Feedback Execution) to support automated end-to-end new material R\&amp;Ds. An GPT-4-based agent was designed to empower the SDLs with the ability to rapidly and accurately explore research and development process experimental protocols based on the requests of human researchers and execute these protocols. As a proof of concept, we applied this pipeline on our self-built algorithm-guided robotic autonomous platform [26] to develop new relative humidity (RH) colorimetric sensors, which rely on detecting color change of sensing materials upon exposure to target analyte. The agent demonstrated promising abilities to autonomously design experiment search space for the development of colorimetric sensing materials. A highly sensitive RH colorimetric sensor was developed and optimized via the pipeline and showed accurate prediction to RH with a root mean square error (RMSE) of $2.68 \%$. Our preliminary results have shown the potential of LLMs' application in empowering SDLs with robotic researchers capable of conducting independent R\&amp;Ds with minimal human interventions.</p>
<h1>2 Method</h1>
<p>Our GPT-Lab is primarily comprised of two major modules: one is an automated experimental design agent based on the GPT framework, and the other is an algorithm-driven robotic experimentation platform. These two components synergistically establish a closed-loop automated workflow spanning from experimental requisites to empirical outcomes. The procedural workflow, which we refer to as ARMFE, is visually represented in Figure. 1.The Agent follows a step-bystep process, including "requirements analysis," "literature retrieval," "text mining," "human researcher feedback," and "experiment execution," to establish a pathway from requirements to experimental results. Then the Agent conducted experiments using these substances.</p>
<p>Requirements analysis. In this phase, researchers are required to present a specific experimental requirement to the agent. We accomplish this task by utilizing the ChatGPT API. Through our meticulously crafted prompts and algorithms, the agent processes the provided experimental requisition to generate five pivotal keywords for conducting literature searches. In instances where the requisition lacks precision, the agent further engages with the researchers by posing clarifying questions, such as inquiring about the necessary methodologies to fulfill the experimental demands.</p>
<p>Literature retrieval. Upon obtaining the keywords derived from the initial step, the agent initiates an online search using these keywords to retrieve pertinent articles along with their respective titles and abstracts. Subsequently, the agent employs the ChatGPT API once again, utilizing the titles and abstracts of the articles to winnow out documents with relatively lower relevance. Following this filtration process, the agent procures complete articles from the internet to serve as the basis for subsequent analysis.</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: The ARMFE workflow of GPT-Lab</p>
<p>Text mining. We will employ the GPT to facilitate the comprehension of each individual article. Through this process, the agent will extract pertinent information regarding the utilized substances and their roles within the experiments, thereby constructing coherent textual passages. Subsequently, utilizing the GPT once more, the agent will analyze and organize these distilled textual segments into a JSON data structure. These foundational details will encompass: the substance's nomenclature, its associated CAS registry number, its functional significance within the experiment, and the role it assumes during the experimental procedure. These JSON files will be preserved for further processing in the subsequent phase.</p>
<p>Human researcher feedback. GPT-Lab will curate the experimental substance parameters in the form of highly comprehensible text from the JSON data structure, presenting this information to the researchers for their consideration. Following the selection process, the researchers will inform the agent regarding the chosen experimental substances. Subsequently, the agent, through a feedback loop, will generate experimental parameters structured in JSON format, which will be transmitted to the robotic experimentation platform for actual execution.</p>
<p>Experiment execution. The robotic platform will undertake the process of liquid formulation and subsequent iterative operations based on the experimental parameters furnished by the agent. The principles underlying this aspect will be expounded upon in greater detail in the forthcoming section.After the processing and designing of the GPT-based research agent, a material design space composing of the synthetic ingredients, their roles in the design, and typical compositions are proposed. For the sake of robotic platform execution, the Agent will compile a exchange file according the our robotic platform's requirements containing CAS codes for the experimental substances and their corresponding concentration values. This file will then be transmitted to the robotic experimentation platform for subsequent executions.</p>
<h1>3 Experiment</h1>
<h3>3.1 Article mining with Agent</h3>
<p>In evaluating Agent's efficiency in GPT-Lab, the system processed an average of 100 research articles within an hour. Utilizing multi-threading techniques, this processing speed can be augmented three to five-fold, representing a time-saving advantage of over a hundredfold compared to traditional manual extraction, especially when dealing with literature volumes in the tens of thousands. Furthermore, while human researchers may grapple with summarizing ultrahigh dimensional variables, our system seamlessly integrates and analyzes a plethora of potential reagents, pinpointing those likely relevant to the research theme.
From the 500 articles analyzed, GPT-Lab identified fifty potential reagents. After filtration, 18 of these reagents with a relevance score of $80 \%$ or higher were highlighted. Among them, there are 8 candidate core materials. For each, the system elucidated its experimental role, intended use, source, and rationale for its relevance. This curated list is then presented to researchers, allowing them to make informed selections based on their expertise and experimental needs.</p>
<p>Compared to pure GPT, our system has higher accuracy and better feasibility. Many substances provided by GPT cannot meet the conditions of subsequent robot experiments. In addition, GPT may hallucinate and generate output lacking theoretical basis. In contrast, the materials suggested by our GPT-Lab are more suitable and feasible for our experimental setup. At the same time, our system provides corresponding theoretical foundations and literature sources to back up its recommendations. The system automatically searches and obtains accurate material information focused on downstream robot experiments, rather than speculating without evidence. Compared to tedious manual literature searches, GPT-Lab greatly saves researchers time and effort while improving efficiency. Our system achieves full automation without needing human intervention at each step. Finally, after screening and selecting appropriate materials, the system seamlessly inputs them into downstream robots to complete the automated closed loop experimentation process.</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: Dialogue demonstration with the agent</p>
<p>To demonstrate the versatility of our method, we explored applications beyond humidity sensor materials discovery. We utilized the system to search for key materials information for perovskite solar cells, obtaining a list of 7 materials including Methylammonium iodide, Lead iodide, Cesium Lead Chloride, Nickel oxide, Titanium dioxide, Lead bromide and Titanium tetrachloride. These materials serve purposes such as forming the perovskite structure, constituting the electronic band structure, acting as hole transport layer, and forming the TiO2 layer. This again proves the ability of our approach for broad discovery and optimization of new materials.</p>
<p>Similarly, we explored a completely different problem - how to detect alkaloid content in mulberry leaves. We obtained some feasible key methods including using TSK gel Amide-80 column, C18 Phenomenex Synergi Fusion Stainless Steel Column for chromatographic separation, derivatizing the compound and separating it using different strategies, using MS to concurrently detect and identify the compound, and utilizing intra-day, inter-day, accuracy, precision, specificity and stability tests. After evaluation by domain experts, these methods were deemed viable and insightful for research in this field.
By achieving positive results across multiple distinct areas, we demonstrate that the method can be generalized for discovery of diverse materials and methods, not limited to a single application domain. This showcases the versatility of our approach and its potential to aid scientific discovery. We believe that with further research and refinement, this method can play an important role in a wide range of fields like materials science and drug development.</p>
<h1>3.2 Robotic experiment execution</h1>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3: The robotic R\&amp;D system. (a) Schematic of the liquid handling workstation. (b) The functional modules of the liquid handling workstation, including the stock solution area, pipette tip area, recipe configuration area, and sensing unit fabrication area. (c) Image of sensing units. Each color dot represents a gas-sensitive unit whose color is extracted by a computer vision algorithm. (d) Schematic of the gas path. The $\mathrm{N}_{2}$ flow is split into two paths, passing through a dryer and a humidifier. The flow rates of the two streams are controlled by two MFCs and are mixed to achieve different RH for the gas-sensitive unit testing. (e) Gas testing setup, comprising a darkroom, light source, camera, and gas chamber. The gas-sensitive units are placed within the transparent upper chamber under uniform light conditions created by the darkroom and light source. The camera records the gas-sensitive units' color changes in different atmospheres.</p>
<p>The selected reagents are classified into three categories: colorants, additives, and solvents. Colorants include cobalt chloride $\left(\mathrm{CoCl}<em 2="2">{2}\right)$, nickel iodide $\left(\mathrm{NiI}</em>}\right)$, and nickel bromide $\left(\mathrm{NiBr<em 2="2">{2}\right)$. Additives include calcium chloride $\left(\mathrm{CaCl}</em>\right)$, tetramethylammonium iodide (TMAI), polyethylene glycol (PEG), and ethyl cellulose (EC). The solvent used is isopropanol (IPA). In the specific experiments, the dosage of each reagent is considered as a variable, resulting in a total of 8 variables. With a fixed total quantity, determining the dosages of the first 7 reagents automatically sets the dosage of the last reagent, resulting in a 7-dimensional variable space.
The execution of the wet experiment is close to the previously reported DBTM process ${ }^{26}$. The DBTM process is an efficient algorithm-guided process, implemented on a robot autonomous experiment platform, as shown in the Figure. 3. According to user requirements, the optimal recipe can be obtained quickly by adjusting parameters. Specifically, the DBTM process involves a cycle of "recipe generation - robotic preparation - robotic testing - data processing - the next round of recipe generation". The robot equipment consists of a liquid handler and a self-built darkroom. Preparation steps are performed on the liquid handler, while testing is conducted in the darkroom. The testing involves flowing</p>
<p>nitrogen (N2) gas of different humidities to gas-sensitive samples fixed in the gas chamber. A camera continuously records their color changes under uniform lighting conditions, generating a color vs. time curve. From this curve, color change amplitude, response time, reversibility, sensitivity, and other indicators can be calculated. These indicators are weighted to derive the final score. The iterative process is guided by a Bayesian optimization algorithm, which determines the next round’s sampling with higher uncertainty or higher potential of score improvement based on the inclination towards exploration or exploitation. In the specific experimental execution, 96 samples are collected in a single batch. While the first round’s 96 recipes are randomly generated, the recipes for subsequent rounds are generated using Bayesian strategies. Each round includes a certain degree of exploration and exploitation tendencies.</p>
<p>The distribution of sample scores in different batches of experiments is depicted in Figure. 4a. With increasing rounds, the maximum score of each round gradually increased. Starting from the third round, a substantial portion of samples clustered around the 0-score range. This phenomenon was due to the iterative strategy’s deliberated inclination towards exploration to prevent getting trapped in local optima. However, some recipes influenced by this exploratory tendency exhibit higher uncertainty and tend to have more extreme values, resulting in lower scores. After 5 rounds of experiments and the accumulation of 480 samples, the increase in the maximum score became less significant. It was also worth noting that the score distribution in the fifth round is broader, as more samples achieved higher scores, and these scores were edging closer to 0 compared to the previous round. This implied that finding superior recipes within the realm of heightened uncertainty is challenging, and the current optimal recipe was nearing a quasi-global optimum.</p>
<p>Figure 4: The wet experimental results. (a) The score distribution of recipes at different iteration rounds. (b) Total composition proportions of the 8 variables of 96 recipes in each batch. (c) Components of the selected two recipes. (d) The RH predicting accuracy of the array composed of the two selected recipes.</p>
<p>Figure. 4b presents the total usage of each substance in the 96 recipes for each of the five iterative rounds. In the first round, as the recipes were generated randomly, although the proportions of each substance might vary significantly within specific recipes, their total proportions remained similar. As the iterations progressed, the usage of CoCl2 exhibited an overall increasing trend, indicating a tendency for its utilization. Conversely, the usage of CaCl2, NiBr2, and TMAI showed a general decrease, gradually being discarded. This tendency suggested that recipes with more CoCl2 may yield better results, while CaCl2, NiBr2, and TMAI had limited or even adverse effects. The selected two recipes were presented in Figure. 4c, where NiBr2 and TMAI were excluded. Recipe 1 included a small amount of NiI2, while Recipe 2 incorporated a small amount of CaCl2, enhancing sensitivity to low and high humidity conditions. The predictive accuracy of the array composed of these two recipes towards RH, as shown in Figure. 4d, achieved precise quantification across RH from 5% to 95% at room temperature, with a root mean square error (RMSE) of 2.68%.</p>
<h1>4 Conclusion</h1>
<p>The current iteration of GPT-Lab has been primarily engaged in three key endeavors: Firstly, it has demonstrated the commendable performance of GPT in the domain of experimental design. Secondly, it has substantiated the viability of an automated closed-loop process encompassing the trajectory from experimental requisition to empirical outcomes. Thirdly, this innovation has empowered chemists lacking computer science expertise to seamlessly harness the robotic platform for high-throughput experimentation, thereby augmenting experimental efficiency. As a proof of concept, a colorimetric humidity sensor was built within a week with minor human interference, capable of predicting the relative humidity at room temperature in the range of $5-95 \%$ with an RMSE of $2.68 \%$.</p>
<p>However, during the experimentation process, we have encountered several challenges: (a) GPT's intelligence is still limited, often leading to inaccuracies in its outputs. When inappropriate responses occur, it necessitates programmatic checks and retries to ensure the agent's robustness. This significantly escalates the cost of GPT utilization. (b) Despite the present capabilities of GPT-Lab in economizing researchers' time by circumventing extensive literature review and experimentation, GPT's capacity to acquire domain-specific knowledge outside the literature it has been exposed to remains limited. This imposes the need for researchers to manually filter experimental parameters. Potential remedies involve training larger models endowed with substantial chemical knowledge to supplant the current GPT, or exploring approaches like knowledge graphs and fine-tuning on extensive datasets to enhance GPT's breadth of knowledge. As larger models continue to evolve, the landscape of chemical research is poised to become increasingly efficient and streamlined.</p>
<h2>References</h2>
<p>[1] King, R. D. et al. Functional genomic hypothesis generation and experimentation by a robot scientist. Nature, 427:247-252, 2004.
[2] Zhang, H. et al. Dramatically enhanced combination of ultimate tensile strength and electric conductivity of alloys via machine learning screening. Acta Mater., 200:803-810, 2020.
[3] Granda, J. M. et al. Controlling an organic synthesis robot with machine learning to search for new reactivity. Nature, 559:377-381, 2018.
[4] Wang, C. et al. A property-oriented design strategy for high performance copper alloys via machine learning. $n p j$ Comput. Mater, 5:1-8, 2019.
[5] Xue, Dezhen, et al. Accelerated search for materials with targeted properties by adaptive design. Nature communications, 7.1:1-9, 2016.
[6] Wen, C. et al. Machine learning assisted design of high entropy alloys with desired property. Acta Mater., 170:109-117, 2019.
[7] Raccuglia, P. et al. Machine-learning-assisted materials discovery using failed experiments. Nature, 533:73-76, 2016.
[8] Zhang, Y. et al. Phase prediction in high entropy alloys with a rational selection of materials descriptors and machine learning models. Acta Mater., 185:528-539, 2020.
[9] Burger, B. et al. A mobile robotic chemist. Nature, 583:237-241, 2020.
[10] Segler, M. H. S., Preuss, M. \&amp; Waller, M. P. Planning chemical syntheses with deep neural networks and symbolic AI. Nature, 555:604-610, 2018.
[11] Wang, W, et al. Automated pipeline for superalloy data by text mining. NPJ Computational Materials, 8.1, 2022.
[12] Pei Z, Yin J, Liaw PK, et al. Toward the design of ultrahigh-entropy alloys via mining six million texts. Nature Communications, 14(1):54, 2023.
[13] Zhou, Q. et al. Learning atoms for materials discovery. Proc. Natl Acad. Sci. USA, 115:E6411-E6417, 2018.
[14] Tshitoyan, V. et al. Unsupervised word embeddings capture latent knowledge from materials science literature. Nature, 571:95-98, 2019.
[15] Nie, Z., Liu, Y., Yang, L., Li, S. \&amp; Pan, F. Construction and application of materials knowledge graph based on author disambiguation: revisiting the evolution of LiFePO4. Adv. Energy Mater., 11:2003580, 2021.
[16] Hakimi, O., Krallinger, M. \&amp; Ginebra, M.-P. Time to kick-start text mining for biomaterials. Nat. Rev. Mater., 5:553-556, 2020.
[17] Court, C. J. \&amp; Cole, J. M. Magnetic and superconducting phase diagrams and transition temperatures predicted using text mining and machine learning. npj Comput. Materials, 6:1-9, 2020.</p>
<p>[18] Krenn, M. \&amp; Zeilinger, A. Predicting research trends with semantic and neural networks with an application in quantum physics. Proc. Natl. Acad. Sci., 117:1910-1916, 2020.
[19] Hoffmann, J. et al. Training Compute-Optimal Large Language Models. 2022.
[20] Lin, Z. et al. Evolutionary-scale prediction of atomic-level protein structure with a language model. Science, 379:1123-1130, 2023.
[21] Luo, R. et al. BioGPT: generative pre-trained transformer for biomedical text generation and mining. Brief Bioinform, 23, 2022.
[22] OpenAI. GPT-4 Technical Report. 2023.
[23] Brown, T. et al. Language Models are Few-Shot Learners. In Advances in Neural Information Processing Systems (eds. Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M. F. \&amp; Lin, H.), vol. 33:1877-1901. Curran Associates, Inc., 2020.
[24] Boiko, Daniil A., Robert MacKnight, and Gabe Gomes. Emergent autonomous scientific research capabilities of large language models. arXiv preprint arXiv:2304.05332, 2023.
[25] opentrons. Opentrons Python Protocol API. https://docs.opentrons.com/v2/.
[26] Chen, Yangguan, et al. Robot-accelerated development of a colorimetric CO2 sensing array with wide ranges and high sensitivity via multi-target Bayesian optimizations. Sensors and Actuators B: Chemical, 390:133942, 2023.</p>
<h1>Acknowledgement</h1>
<p>This work was supported by funding from the Center-initiated Research Project of Zhejiang Lab (Grant No. 113015AL2202). Special thanks to Longhan Zhang from Zhejiang Lab, for his assistance in reviewing and editing the manuscript.</p>
<h2>Author</h2>
<p>Xiaokai Qin has a B.Sc. degree in Computer Science from University of Liverpool and B.Sc. degree in Information and Computing Science from Xi'an Jiaotong Liverpool University. Presently, he is pursuing his Master's degree in Artificial Intelligence at Nanyang Technological University, Singapore. Before his Master's study, he worked as a machine learning intern at Zhejiang Lab.
Mingda Song graduated from the Australian National University with a Master's degree in Computing, specializing in machine learning. He is currently an intern at Zhejiang Lab, working on natural language process research.
Yangguan Chen has a B.Sc in Material Chemistry from Sun Yat-Sen University and a Ph.D. in Polymer Chemistry and Physics from Sun Yat-Sen University. His current research includes gas-sensing materials and sensing array construction. He is currently working at the Zhejiang Laboratory in Hangzhou, China.
Zhehong Ai is a Ph.D. candidate at Hangzhou Institute for Advanced Study of the University of Chinese Academy of Sciences. He has a Bachelor of Engineering degree from the College of Electronic Science and Engineering of Jilin University. His research interests include sensor technology and autonomous R\&amp;D, and his current work involves the automatic AI (artificial intelligence) platform of colorimetric sensor development.
Jing Jiang received his Ph.D. from the Department of Electrical and Computer Engineering at the University of Illinois at Urbana-Champaign (UIUC) under the supervision of Prof. G. Logan Liu. After graduation, he co-founded a startup that uses mobile robots to conduct synthetic biology research and worked as a lecturer at UIUC. His research includes the nanofabrication and development of biosensors with the robotic platform. He has won multiple international prizes, including Vodafone Wireless Innovation Project and Nokia Sensing XChallenge based on smartphone-based sensors. Now he is a researcher (principal investigator) at Zhejiang Lab, Hangzhou, China, focusing on developing biology, materials, and sensors based on intelligent computing and robotic automation systems.</p>
<h1>Appendix</h1>
<p>Table 1: The chemicals generated by GPT-Lab Agent</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Code</th>
<th style="text-align: center;">Name</th>
<th style="text-align: center;">Role</th>
<th style="text-align: center;">Purpose</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">25233-30-1</td>
<td style="text-align: center;">Polyaniline</td>
<td style="text-align: center;">reactor</td>
<td style="text-align: center;">Used as the sensing material for humidity detection.</td>
</tr>
<tr>
<td style="text-align: center;">7646-79-9</td>
<td style="text-align: center;">Cobalt(II) chloride</td>
<td style="text-align: center;">colorant</td>
<td style="text-align: center;">Exhibits absorption bands; causes color change in polymer solutions.</td>
</tr>
<tr>
<td style="text-align: center;">100-20-9</td>
<td style="text-align: center;">Terephthaloyl chloride</td>
<td style="text-align: center;">reactor</td>
<td style="text-align: center;">Used to crosslink gelatin for humidity sensitive capsules.</td>
</tr>
<tr>
<td style="text-align: center;">25852-37-3</td>
<td style="text-align: center;">Poly(ethylene glycol) methacrylate</td>
<td style="text-align: center;">additive</td>
<td style="text-align: center;">Used as analytes and causes color change of CP1.</td>
</tr>
<tr>
<td style="text-align: center;">9003-39-8</td>
<td style="text-align: center;">Polyvinylpyrrolidone</td>
<td style="text-align: center;">additive</td>
<td style="text-align: center;">Polymer layer for PVPP-based humidity sensors.</td>
</tr>
<tr>
<td style="text-align: center;">7647-15-6</td>
<td style="text-align: center;">Sodium Bromide</td>
<td style="text-align: center;">adjuster</td>
<td style="text-align: center;">Controls humidity inside test chamber.</td>
</tr>
<tr>
<td style="text-align: center;">141-78-6</td>
<td style="text-align: center;">Ethyl acetate</td>
<td style="text-align: center;">reactor</td>
<td style="text-align: center;">Used as analytes and solvent for character izing optical properties.</td>
</tr>
<tr>
<td style="text-align: center;">7732-18-5</td>
<td style="text-align: center;">Water</td>
<td style="text-align: center;">adjuster</td>
<td style="text-align: center;">Used for humidity response testing and as analyte for humidity sensing.</td>
</tr>
<tr>
<td style="text-align: center;">7647-14-5</td>
<td style="text-align: center;">Sodium Chloride</td>
<td style="text-align: center;">adjuster</td>
<td style="text-align: center;">Used to control relative humidity for testing.</td>
</tr>
<tr>
<td style="text-align: center;">13462-88-9</td>
<td style="text-align: center;">Nickel (II) bromide</td>
<td style="text-align: center;">colorant</td>
<td style="text-align: center;">Sensing thin-film layer for the humidity sensor.</td>
</tr>
<tr>
<td style="text-align: center;">7718-54-9</td>
<td style="text-align: center;">Nickel(II) iodide</td>
<td style="text-align: center;">colorant</td>
<td style="text-align: center;">Main moisture-sensitive material.</td>
</tr>
<tr>
<td style="text-align: center;">79-06-1</td>
<td style="text-align: center;">Acrylamide</td>
<td style="text-align: center;">reactor</td>
<td style="text-align: center;">Used to prepare humidity-responsive polymer networks.</td>
</tr>
<tr>
<td style="text-align: center;">79-10-7</td>
<td style="text-align: center;">Acrylic acid</td>
<td style="text-align: center;">reactor</td>
<td style="text-align: center;">Used to prepare humidity-responsive polymer networks.</td>
</tr>
<tr>
<td style="text-align: center;">9003-05-8</td>
<td style="text-align: center;">Polyacrylamide</td>
<td style="text-align: center;">additive</td>
<td style="text-align: center;">Used as organogel for humidity-responsive films.</td>
</tr>
<tr>
<td style="text-align: center;">10043-52-4</td>
<td style="text-align: center;">Calcium chloride</td>
<td style="text-align: center;">colorant</td>
<td style="text-align: center;">Used to remove moisture.</td>
</tr>
<tr>
<td style="text-align: center;">75-58-1</td>
<td style="text-align: center;">Tetramethylammonium iodide</td>
<td style="text-align: center;">additive</td>
<td style="text-align: center;">Mixed with Nickel(II) iodide to improve sensitivity.</td>
</tr>
<tr>
<td style="text-align: center;">25322-68-3</td>
<td style="text-align: center;">Polyethylene glycol</td>
<td style="text-align: center;">additive</td>
<td style="text-align: center;">Used as a surfactant.</td>
</tr>
<tr>
<td style="text-align: center;">9004-57-3</td>
<td style="text-align: center;">Ethyl cellulose</td>
<td style="text-align: center;">additive</td>
<td style="text-align: center;">Used to adjust the morphology of the substrate.</td>
</tr>
</tbody>
</table>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>*Corresponding author.&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>