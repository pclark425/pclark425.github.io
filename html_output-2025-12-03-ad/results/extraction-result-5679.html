<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-5679 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-5679</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-5679</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-115.html">extraction-schema-115</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <p><strong>Paper ID:</strong> paper-232014530</p>
                <p><strong>Paper Title:</strong> <a href="https://arxiv.org/pdf/2102.11570v1.pdf" target="_blank">Robust and Transferable Anomaly Detection in Log Data using Pre-Trained Language Models</a></p>
                <p><strong>Paper Abstract:</strong> Anomalies or failures in large computer systems, such as the cloud, have an impact on a large number of users that communicate, compute, and store information. Therefore, timely and accurate anomaly detection is necessary for reliability, security, safe operation, and mitigation of losses in these increasingly important systems. Recently, the evolution of the software industry opens up several problems that need to be tackled including (1) addressing the software evolution due software upgrades, and (2) solving the cold-start problem, where data from the system of interest is not available. In this paper, we propose a framework for anomaly detection in log data, as a major troubleshooting source of system information. To that end, we utilize pre-trained general-purpose language models to preserve the semantics of log messages and map them into log vector embeddings. The key idea is that these representations for the logs are robust and less invariant to changes in the logs, and therefore, result in a better generalization of the anomaly detection models. We perform several experiments on a cloud dataset evaluating different language models for obtaining numerical log representations such as BERT, GPT-2, and XL. The robustness is evaluated by gradually altering log messages, to simulate a change in semantics. Our results show that the proposed approach achieves high performance and robustness, which opens up possibilities for future research in this direction.</p>
                <p><strong>Cost:</strong> 0.017</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e5679.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e5679.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Framework (LM+BiLSTM)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Pre-trained sentence-level language model embeddings + Bi-LSTM anomaly detection framework</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A plug-and-play framework that maps parsed log templates to sentence-level embeddings from pre-trained general-purpose language models (BERT, GPT-2, XL), feeds sequences of these embeddings into a Bi-LSTM trained either to predict the next template class (classification) or the next embedding (regression), and detects anomalies via top-k template prediction mismatch or thresholded MSE; supports nearest-template matching and few-shot transfer to new deployments.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Robust and Transferable Anomaly Detection in Log Data using Pre-Trained Language Models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>pipeline: {pre-trained LM (BERT/GPT-2/XL) -> sentence embedding -> Bi-LSTM}</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Sentence-level embeddings are obtained from off-the-shelf pre-trained language models (BERT: bidirectional transformer; GPT-2: autoregressive transformer; XL/XLNet: generalized autoregressive transformer). Embeddings are used as fixed or fine-tuned inputs to a Bi-LSTM sequence model (two directional LSTM) that outputs either class probabilities (next-template classification) or a predicted embedding vector (regression). Post-processing includes nearest-template matching (cosine distance), top-k acceptance for classification, and q-th percentile thresholding on MSE for regression. Few-shot fine-tuning on a small portion of new logs enables transfer.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_method</strong></td>
                            <td>Use of pre-trained LMs for sentence embeddings (plug-and-play) combined with supervised sequential modeling (Bi-LSTM) trained on normal sequences; detection via (A) classification: top-k next-template prediction mismatch or novel-template distance > threshold, and (B) regression: squared error above training q-th percentile; model-transfer via nearest-neighbor mapping and few-shot fine-tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Semi-structured system logs parsed into templates (sequences of log templates / events over time).</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Injected ground-truth anomalies; synthetic semantic anomalies (token deletion, swap, imputation) and structural/sequential anomalies (event deletion, event swap, event imputation/repeat); novel/unseen templates after software updates (cold-start).</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>CloudLab OpenStack log dataset (available at Loghub)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Evaluated using precision, recall, F1 on (1) semantic alterations and (2) sequential (structural) alterations; also evaluated transfer (B-similar and B-different with 15% altered logs) using same metrics. Reported numbers vary by embedding model and objective (see individual model entries).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Authors discuss prior traditional approaches (PCA on event-count vectors, one-hot template LSTM-based methods, keyword/regex matching) and argue the LM+Bi-LSTM approach better preserves semantics and generalizes to unseen templates; no direct numeric head-to-head with traditional baselines reported in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Requires log parsing (Drain) and relies on abundant normal data for training; classification objective assumes a 'close-world' of templates and needs nearest-template matching plus a maximal-distance parameter to avoid false matches; different pre-trained LMs show different robustness to types of change (see per-model limitations); embeddings alone may not always produce separable representations; hyperparameters (window size, top-k, q-percentile, maximal distance) are required.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Robust and Transferable Anomaly Detection in Log Data using Pre-Trained Language Models', 'publication_date_yy_mm': '2021-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5679.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e5679.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BERT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>BERT (Bidirectional Encoder Representations from Transformers)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A pre-trained bidirectional Transformer encoder used to produce sentence-level embeddings of log templates which are then consumed by a Bi-LSTM sequence model for anomaly detection.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Robust and Transferable Anomaly Detection in Log Data using Pre-Trained Language Models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>BERT</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Pre-trained bidirectional Transformer encoder that produces contextualized token and sentence-level embeddings; used here as a sentence-level embedding extractor (plug-and-play). The paper does not specify exact variant/size or if further fine-tuning of the LM was performed (embeddings treated as pre-trained features).</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_method</strong></td>
                            <td>Sentence-level embedding extraction (pre-trained BERT) -> feed sequences of embeddings into Bi-LSTM; two objectives: (A) classification: predict next-template class (cross-entropy) + nearest-template matching + top-k acceptance; (B) regression: predict next embedding (MSE) and flag MSE above q-th percentile as anomaly; transfer via mapping new-template embeddings to nearest-known templates and few-shot fine-tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Sequences of parsed log templates (semi-structured logs).</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Semantic token-level alterations (deletion/swap/imputation), structural/sequential alterations (event deletion/swap/imputation), injected anomalies and novel templates after updates.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>CloudLab OpenStack log dataset (Loghub)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Table I (embedding evaluation): Regression semantic: Precision=0.43, Recall=1.00, F1=0.56; Regression sequential: Precision=0.49, Recall=1.00, F1=0.66. Classification semantic: Precision=0.37, Recall=1.00, F1=0.54; Classification sequential: Precision=0.50, Recall=1.00, F1=0.67. Table II (transfer, P=15%): Regression B-similar: P=0.58,R=0.70,F1=0.63; Regression B-different: P=0.52,R=1.00,F1=0.68. Classification B-similar: P=0.61,R=1.00,F1=0.75; Classification B-different: P=0.68,R=1.00,F1=0.81.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared experimentally to GPT-2 and XL-Transformers embeddings; BERT produced the most consistent and robust results across objectives and transfer scenarios. No numeric comparison to classical PCA/LSTM-one-hot baselines in experiments was provided.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Although generally robust across semantic and sequential alterations and for transfer, BERT performance still depends on design choices (classification vs regression) and on parsing quality; classification requires nearest-template matching for novel templates; overall method assumes sufficient normal training data and requires threshold hyperparameters.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Robust and Transferable Anomaly Detection in Log Data using Pre-Trained Language Models', 'publication_date_yy_mm': '2021-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5679.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e5679.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-2</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-2 (Generative Pre-trained Transformer 2)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An autoregressive Transformer language model used to produce sentence-level embeddings for log templates; embeddings are input to a Bi-LSTM for sequential anomaly detection tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Robust and Transferable Anomaly Detection in Log Data using Pre-Trained Language Models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-2</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Pre-trained autoregressive Transformer (GPT-2) used as a sentence embedding extractor. The paper does not specify the exact GPT-2 variant or parameter count; embeddings are used downstream by a Bi-LSTM and not reported as being fine-tuned extensively.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_method</strong></td>
                            <td>Sentence-level embedding extraction from GPT-2 (plug-and-play) -> Bi-LSTM trained for next-template classification or next-embedding regression; detection via top-k classification mismatch or thresholded MSE; supports nearest-template mapping and few-shot transfer.</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Sequences of parsed log templates (semi-structured logs).</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Semantic and structural/sequential alterations and injected anomalies; novel templates after software updates.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>CloudLab OpenStack log dataset (Loghub)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Table I: Regression semantic: Precision=0.88, Recall=1.00, F1=0.94; Regression sequential: Precision=0.79, Recall=1.00, F1=0.87. Classification semantic: Precision=0.24, Recall=0.70, F1=0.36; Classification sequential: Precision=0.31, Recall=0.70, F1=0.43. Table II (transfer, P=15%): Regression B-similar: P=0.23,R=0.05,F1=0.08; Regression B-different: P=0.94,R=1.00,F1=0.97. Classification B-similar: P=0.27,R=1.00,F1=0.43; Classification B-different: P=0.09,R=1.00,F1=0.17.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared to BERT and XL-Transformers embeddings; GPT-2 excelled in regression tasks (high precision/recall/F1 on synthetic semantic/sequential alteration in regression) but performed worse for classification and was sensitive to transfer/few-shot when alterations were small (B-similar). No direct comparison to classical non-LM baselines with numerical results.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Highly sensitive to the downstream learning objective: strong for regression but substantially weaker in classification; unstable in transfer when changes are small (poor B-similar regression and poor B-different classification); authors note that different pre-trained LMs have strengths/weaknesses for different alteration categories.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Robust and Transferable Anomaly Detection in Log Data using Pre-Trained Language Models', 'publication_date_yy_mm': '2021-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5679.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e5679.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>XL-Transformers</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>XL-Transformers / XLNet (generalized autoregressive pretraining)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A generalized autoregressive transformer pre-training approach used to obtain sentence-level embeddings for log templates, evaluated alongside BERT and GPT-2 for anomaly detection.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Robust and Transferable Anomaly Detection in Log Data using Pre-Trained Language Models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>XL-Transformers (XL/XLNet)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Generalized autoregressive pretraining Transformer family (referred to as XL/XL-Transformers in the paper). Used to extract sentence-level embeddings of log templates. Exact variant/size unspecified and embeddings were used as features for Bi-LSTM.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_method</strong></td>
                            <td>Sentence-level embedding extraction from XL models (plug-and-play) -> Bi-LSTM for next-template classification or next-embedding regression; detection via classification top-k mismatch or regression MSE thresholding; supports nearest-template mapping and few-shot transfer.</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Sequences of parsed log templates (semi-structured logs).</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Semantic token-level alterations and structural/sequential alterations and novel templates after updates.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>CloudLab OpenStack log dataset (Loghub)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Table I: Regression semantic: Precision=0.21, Recall=0.63, F1=0.31; Regression sequential: Precision=0.32, Recall=0.61, F1=0.42. Classification semantic: Precision=0.26, Recall=1.00, F1=0.41; Classification sequential: Precision=0.36, Recall=1.00, F1=0.53. Table II (transfer, P=15%): Regression B-similar: P=0.45,R=0.70,F1=0.55; Regression B-different: P=0.18,R=0.47,F1=0.26. Classification B-similar: P=0.53,R=1.00,F1=0.69; Classification B-different: P=0.23,R=1.00,F1=0.38.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared experimentally to BERT and GPT-2; XL performed between GPT-2 and BERT in many cases but failed in some transfer small-change scenarios (e.g., regression B-different). No traditional baseline numerical comparisons presented.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Less consistent than BERT; fails in some transfer settings especially when changes are not drastic (poor regression results for B-different); classification benefits from close-world recall=1.0 but lower precision/F1 compared to BERT in many cases.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Robust and Transferable Anomaly Detection in Log Data using Pre-Trained Language Models', 'publication_date_yy_mm': '2021-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5679.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e5679.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Bi-LSTM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Bidirectional Long Short-Term Memory network</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A Bi-LSTM sequence model that consumes sequences of sentence-level embeddings of log templates and is trained either to classify the next template or regress the next embedding for anomaly detection.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Robust and Transferable Anomaly Detection in Log Data using Pre-Trained Language Models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Bi-LSTM</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Two-directional LSTM network that processes windows of consecutive log-embedding vectors (size Î´); outputs pass through linear layers to either n-dimensional class logits (classification) or d-dimensional embedding prediction (regression). Training objectives: cross-entropy for classification, mean squared error for regression.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_method</strong></td>
                            <td>Sequential modeling of embedding windows: (A) classification objective produces probability distribution over known templates for next position; anomaly if true template not in top-k or novel template too distant; (B) regression objective predicts next embedding and uses MSE against true embedding (or nearest template embedding) with q-th percentile threshold to flag anomalies.</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Sequences of sentence-level log-template embeddings (temporal sequences).</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Sequence-level anomalies (unexpected successor templates), structural alterations in sequence (deletion/swap/imputation) and novel/unseen templates.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>CloudLab OpenStack log dataset (Loghub)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Reported combined with embedding source; performance depends strongly on embedding type and objective (see per-embedding metrics). Authors report classification objective often slightly outperforms regression for transfer robustness.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared conceptually to single-direction LSTM and one-hot template inputs used in prior work; authors chose Bi-LSTM for improved two-sided sequence modeling. No numeric head-to-head baseline beyond embedding comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Classification variant requires closed-world template knowledge and nearest-template heuristics for novel templates; regression depends on quality of embedding space (if embeddings are not separable, regression will suffer).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Robust and Transferable Anomaly Detection in Log Data using Pre-Trained Language Models', 'publication_date_yy_mm': '2021-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5679.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e5679.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Drain</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Drain log parser</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An online log parsing algorithm used to convert raw log messages to templates and variable parts before embedding; chosen for speed and efficiency.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Robust and Transferable Anomaly Detection in Log Data using Pre-Trained Language Models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Drain</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Deterministic log parsing algorithm that segments log lines into templates and parameters using a fixed-depth parse tree; used as preprocessing to produce templates for sentence embedding.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_method</strong></td>
                            <td>Preprocessing step: raw logs -> templates + variables; templates embedded with pre-trained LMs and used in downstream Bi-LSTM anomaly detection.</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Raw semi-structured logs converted to templates (structured/semi-structured).</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Enables detection of anomalies defined at template/sequence level by structuring logs.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>CloudLab OpenStack log dataset (Loghub)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Not evaluated as a detection model; used as preprocessing. No numeric performance reported.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Drain chosen over other parsers for speed/efficiency; other parsers mentioned in related work but not compared numerically here.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Relies on accurate parsing; parsing errors can propagate and affect embedding and subsequent anomaly detection quality.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Robust and Transferable Anomaly Detection in Log Data using Pre-Trained Language Models', 'publication_date_yy_mm': '2021-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5679.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e5679.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CloudLab OpenStack (Loghub)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>CloudLab OpenStack log dataset (available at Loghub)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The log dataset used for training and evaluating the framework, containing two experiment sets: normal runs and runs with occasionally injected anomalies; authors also synthetically augment the normal data with semantic and sequential alterations to test robustness and transfer.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Robust and Transferable Anomaly Detection in Log Data using Pre-Trained Language Models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>CloudLab OpenStack logs</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Operational logs from OpenStack experiments collected on CloudLab and hosted on the Loghub repository; includes normal runs and anomaly-injected runs; authors additionally created synthetic altered datasets A and B (B-similar and B-different) to simulate software updates.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_method</strong></td>
                            <td>Used as training/test data for evaluating LM-embedding + Bi-LSTM detection under ground-truth anomalies, synthetic token-level and sequence-level alterations, and transfer scenarios.</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Semi-structured log messages (templates + variables), organized as time-ordered sequences.</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Ground-truth injected anomalies, synthetic semantic alterations (deletion/swap/imputation of tokens), synthetic sequential alterations (deletion/swap/imputation of events), and dataset changes simulating software updates.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>CloudLab OpenStack log dataset (Loghub)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Used for measuring precision, recall, F1 under different embedding models and objectives; see model entries for reported scores.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Dataset is a commonly used log dataset referenced in log analysis literature; paper uses it for LM-embedding evaluation and transfer experiments rather than comparing detection methods on multiple datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Authors create synthetic alterations and artificial A/B variants to evaluate transfer; real-world update patterns may differ; results are reported for this dataset and may vary on other log corpora.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Robust and Transferable Anomaly Detection in Log Data using Pre-Trained Language Models', 'publication_date_yy_mm': '2021-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5679.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e5679.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DeepLog (related)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>DeepLog: Anomaly detection and diagnosis from system logs through deep learning</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A prior deep-learning method that uses LSTM to predict subsequent log events based on a window of past events and flags incorrect predictions as anomalies; mentioned as related work and baseline conceptually.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Robust and Transferable Anomaly Detection in Log Data using Pre-Trained Language Models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>DeepLog (LSTM on template indices)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>LSTM-based model trained on one-hot/templated log indices to predict next event; uses synonym/antonym DB for robustness to novel events in original paper. Mentioned as prior art; not re-implemented or numerically compared in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_method</strong></td>
                            <td>Sequence prediction on one-hot template indices with LSTM; detection by mismatch between predicted and actual next template.</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Sequences of log template indices (discrete sequences).</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Unexpected next-template events; inability to handle novel templates due to one-hot representation noted as a weakness.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Not evaluated in this paper; referenced in related work.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Used in related work discussion to motivate semantic embeddings; authors argue DeepLog and similar one-hot template methods cannot cope with novel templates that were not in training.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>One-hot template inputs cannot represent unseen/new templates; relies on template invariance assumptions which break under software updates; authors use this to motivate their semantic embedding approach.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Robust and Transferable Anomaly Detection in Log Data using Pre-Trained Language Models', 'publication_date_yy_mm': '2021-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5679.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e5679.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PCA (related)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Principal Component Analysis on event-count vectors</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A classical unsupervised anomaly detection approach that the authors mention: transform logs into event-count vectors over windows and apply PCA to detect anomalies via reconstruction or projection norms.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Robust and Transferable Anomaly Detection in Log Data using Pre-Trained Language Models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>PCA on log event-count vectors</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Classical linear dimensionality reduction (PCA) applied to count-based features aggregated over time windows; anomalies detected by deviations in principal component space (e.g., high reconstruction error or large norm in lower principal components).</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_method</strong></td>
                            <td>Aggregate log event counts per window -> PCA -> anomaly score from projection / reconstruction; cited as prior unsupervised approach (Xu et al.).</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Aggregated counts of log events (vectorized, non-sequential or windowed sequences).</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Statistical outliers in event-count feature space (large deviations from normal principal-subspace).</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Not evaluated numerically in this paper; mentioned as representative traditional unsupervised baseline in related work.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Authors contrast PCA-based approaches with their semantic-embedding method qualitatively, arguing PCA on counts lacks semantic awareness and is less robust to log evolution.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Cannot capture semantic similarities between templates and is sensitive to changes in event vocabulary and distribution over time; not designed to handle novel templates semantically.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Robust and Transferable Anomaly Detection in Log Data using Pre-Trained Language Models', 'publication_date_yy_mm': '2021-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Deeplog: Anomaly detection and diagnosis from system logs through deep learning <em>(Rating: 2)</em></li>
                <li>Detecting large-scale system problems by mining console logs <em>(Rating: 2)</em></li>
                <li>Drain: An online log parsing approach with fixed depth tree <em>(Rating: 2)</em></li>
                <li>Bert: Pre-training of deep bidirectional transformers for language understanding <em>(Rating: 1)</em></li>
                <li>Language models are unsupervised multitask learners <em>(Rating: 1)</em></li>
                <li>Xlnet: Generalized autoregressive pretraining for language understanding <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-5679",
    "paper_id": "paper-232014530",
    "extraction_schema_id": "extraction-schema-115",
    "extracted_data": [
        {
            "name_short": "Framework (LM+BiLSTM)",
            "name_full": "Pre-trained sentence-level language model embeddings + Bi-LSTM anomaly detection framework",
            "brief_description": "A plug-and-play framework that maps parsed log templates to sentence-level embeddings from pre-trained general-purpose language models (BERT, GPT-2, XL), feeds sequences of these embeddings into a Bi-LSTM trained either to predict the next template class (classification) or the next embedding (regression), and detects anomalies via top-k template prediction mismatch or thresholded MSE; supports nearest-template matching and few-shot transfer to new deployments.",
            "citation_title": "Robust and Transferable Anomaly Detection in Log Data using Pre-Trained Language Models",
            "mention_or_use": "use",
            "model_name": "pipeline: {pre-trained LM (BERT/GPT-2/XL) -&gt; sentence embedding -&gt; Bi-LSTM}",
            "model_description": "Sentence-level embeddings are obtained from off-the-shelf pre-trained language models (BERT: bidirectional transformer; GPT-2: autoregressive transformer; XL/XLNet: generalized autoregressive transformer). Embeddings are used as fixed or fine-tuned inputs to a Bi-LSTM sequence model (two directional LSTM) that outputs either class probabilities (next-template classification) or a predicted embedding vector (regression). Post-processing includes nearest-template matching (cosine distance), top-k acceptance for classification, and q-th percentile thresholding on MSE for regression. Few-shot fine-tuning on a small portion of new logs enables transfer.",
            "model_size": null,
            "anomaly_detection_method": "Use of pre-trained LMs for sentence embeddings (plug-and-play) combined with supervised sequential modeling (Bi-LSTM) trained on normal sequences; detection via (A) classification: top-k next-template prediction mismatch or novel-template distance &gt; threshold, and (B) regression: squared error above training q-th percentile; model-transfer via nearest-neighbor mapping and few-shot fine-tuning.",
            "data_type": "Semi-structured system logs parsed into templates (sequences of log templates / events over time).",
            "anomaly_type": "Injected ground-truth anomalies; synthetic semantic anomalies (token deletion, swap, imputation) and structural/sequential anomalies (event deletion, event swap, event imputation/repeat); novel/unseen templates after software updates (cold-start).",
            "dataset_name": "CloudLab OpenStack log dataset (available at Loghub)",
            "performance_metrics": "Evaluated using precision, recall, F1 on (1) semantic alterations and (2) sequential (structural) alterations; also evaluated transfer (B-similar and B-different with 15% altered logs) using same metrics. Reported numbers vary by embedding model and objective (see individual model entries).",
            "baseline_comparison": "Authors discuss prior traditional approaches (PCA on event-count vectors, one-hot template LSTM-based methods, keyword/regex matching) and argue the LM+Bi-LSTM approach better preserves semantics and generalizes to unseen templates; no direct numeric head-to-head with traditional baselines reported in experiments.",
            "limitations_or_failure_cases": "Requires log parsing (Drain) and relies on abundant normal data for training; classification objective assumes a 'close-world' of templates and needs nearest-template matching plus a maximal-distance parameter to avoid false matches; different pre-trained LMs show different robustness to types of change (see per-model limitations); embeddings alone may not always produce separable representations; hyperparameters (window size, top-k, q-percentile, maximal distance) are required.",
            "uuid": "e5679.0",
            "source_info": {
                "paper_title": "Robust and Transferable Anomaly Detection in Log Data using Pre-Trained Language Models",
                "publication_date_yy_mm": "2021-02"
            }
        },
        {
            "name_short": "BERT",
            "name_full": "BERT (Bidirectional Encoder Representations from Transformers)",
            "brief_description": "A pre-trained bidirectional Transformer encoder used to produce sentence-level embeddings of log templates which are then consumed by a Bi-LSTM sequence model for anomaly detection.",
            "citation_title": "Robust and Transferable Anomaly Detection in Log Data using Pre-Trained Language Models",
            "mention_or_use": "use",
            "model_name": "BERT",
            "model_description": "Pre-trained bidirectional Transformer encoder that produces contextualized token and sentence-level embeddings; used here as a sentence-level embedding extractor (plug-and-play). The paper does not specify exact variant/size or if further fine-tuning of the LM was performed (embeddings treated as pre-trained features).",
            "model_size": null,
            "anomaly_detection_method": "Sentence-level embedding extraction (pre-trained BERT) -&gt; feed sequences of embeddings into Bi-LSTM; two objectives: (A) classification: predict next-template class (cross-entropy) + nearest-template matching + top-k acceptance; (B) regression: predict next embedding (MSE) and flag MSE above q-th percentile as anomaly; transfer via mapping new-template embeddings to nearest-known templates and few-shot fine-tuning.",
            "data_type": "Sequences of parsed log templates (semi-structured logs).",
            "anomaly_type": "Semantic token-level alterations (deletion/swap/imputation), structural/sequential alterations (event deletion/swap/imputation), injected anomalies and novel templates after updates.",
            "dataset_name": "CloudLab OpenStack log dataset (Loghub)",
            "performance_metrics": "Table I (embedding evaluation): Regression semantic: Precision=0.43, Recall=1.00, F1=0.56; Regression sequential: Precision=0.49, Recall=1.00, F1=0.66. Classification semantic: Precision=0.37, Recall=1.00, F1=0.54; Classification sequential: Precision=0.50, Recall=1.00, F1=0.67. Table II (transfer, P=15%): Regression B-similar: P=0.58,R=0.70,F1=0.63; Regression B-different: P=0.52,R=1.00,F1=0.68. Classification B-similar: P=0.61,R=1.00,F1=0.75; Classification B-different: P=0.68,R=1.00,F1=0.81.",
            "baseline_comparison": "Compared experimentally to GPT-2 and XL-Transformers embeddings; BERT produced the most consistent and robust results across objectives and transfer scenarios. No numeric comparison to classical PCA/LSTM-one-hot baselines in experiments was provided.",
            "limitations_or_failure_cases": "Although generally robust across semantic and sequential alterations and for transfer, BERT performance still depends on design choices (classification vs regression) and on parsing quality; classification requires nearest-template matching for novel templates; overall method assumes sufficient normal training data and requires threshold hyperparameters.",
            "uuid": "e5679.1",
            "source_info": {
                "paper_title": "Robust and Transferable Anomaly Detection in Log Data using Pre-Trained Language Models",
                "publication_date_yy_mm": "2021-02"
            }
        },
        {
            "name_short": "GPT-2",
            "name_full": "GPT-2 (Generative Pre-trained Transformer 2)",
            "brief_description": "An autoregressive Transformer language model used to produce sentence-level embeddings for log templates; embeddings are input to a Bi-LSTM for sequential anomaly detection tasks.",
            "citation_title": "Robust and Transferable Anomaly Detection in Log Data using Pre-Trained Language Models",
            "mention_or_use": "use",
            "model_name": "GPT-2",
            "model_description": "Pre-trained autoregressive Transformer (GPT-2) used as a sentence embedding extractor. The paper does not specify the exact GPT-2 variant or parameter count; embeddings are used downstream by a Bi-LSTM and not reported as being fine-tuned extensively.",
            "model_size": null,
            "anomaly_detection_method": "Sentence-level embedding extraction from GPT-2 (plug-and-play) -&gt; Bi-LSTM trained for next-template classification or next-embedding regression; detection via top-k classification mismatch or thresholded MSE; supports nearest-template mapping and few-shot transfer.",
            "data_type": "Sequences of parsed log templates (semi-structured logs).",
            "anomaly_type": "Semantic and structural/sequential alterations and injected anomalies; novel templates after software updates.",
            "dataset_name": "CloudLab OpenStack log dataset (Loghub)",
            "performance_metrics": "Table I: Regression semantic: Precision=0.88, Recall=1.00, F1=0.94; Regression sequential: Precision=0.79, Recall=1.00, F1=0.87. Classification semantic: Precision=0.24, Recall=0.70, F1=0.36; Classification sequential: Precision=0.31, Recall=0.70, F1=0.43. Table II (transfer, P=15%): Regression B-similar: P=0.23,R=0.05,F1=0.08; Regression B-different: P=0.94,R=1.00,F1=0.97. Classification B-similar: P=0.27,R=1.00,F1=0.43; Classification B-different: P=0.09,R=1.00,F1=0.17.",
            "baseline_comparison": "Compared to BERT and XL-Transformers embeddings; GPT-2 excelled in regression tasks (high precision/recall/F1 on synthetic semantic/sequential alteration in regression) but performed worse for classification and was sensitive to transfer/few-shot when alterations were small (B-similar). No direct comparison to classical non-LM baselines with numerical results.",
            "limitations_or_failure_cases": "Highly sensitive to the downstream learning objective: strong for regression but substantially weaker in classification; unstable in transfer when changes are small (poor B-similar regression and poor B-different classification); authors note that different pre-trained LMs have strengths/weaknesses for different alteration categories.",
            "uuid": "e5679.2",
            "source_info": {
                "paper_title": "Robust and Transferable Anomaly Detection in Log Data using Pre-Trained Language Models",
                "publication_date_yy_mm": "2021-02"
            }
        },
        {
            "name_short": "XL-Transformers",
            "name_full": "XL-Transformers / XLNet (generalized autoregressive pretraining)",
            "brief_description": "A generalized autoregressive transformer pre-training approach used to obtain sentence-level embeddings for log templates, evaluated alongside BERT and GPT-2 for anomaly detection.",
            "citation_title": "Robust and Transferable Anomaly Detection in Log Data using Pre-Trained Language Models",
            "mention_or_use": "use",
            "model_name": "XL-Transformers (XL/XLNet)",
            "model_description": "Generalized autoregressive pretraining Transformer family (referred to as XL/XL-Transformers in the paper). Used to extract sentence-level embeddings of log templates. Exact variant/size unspecified and embeddings were used as features for Bi-LSTM.",
            "model_size": null,
            "anomaly_detection_method": "Sentence-level embedding extraction from XL models (plug-and-play) -&gt; Bi-LSTM for next-template classification or next-embedding regression; detection via classification top-k mismatch or regression MSE thresholding; supports nearest-template mapping and few-shot transfer.",
            "data_type": "Sequences of parsed log templates (semi-structured logs).",
            "anomaly_type": "Semantic token-level alterations and structural/sequential alterations and novel templates after updates.",
            "dataset_name": "CloudLab OpenStack log dataset (Loghub)",
            "performance_metrics": "Table I: Regression semantic: Precision=0.21, Recall=0.63, F1=0.31; Regression sequential: Precision=0.32, Recall=0.61, F1=0.42. Classification semantic: Precision=0.26, Recall=1.00, F1=0.41; Classification sequential: Precision=0.36, Recall=1.00, F1=0.53. Table II (transfer, P=15%): Regression B-similar: P=0.45,R=0.70,F1=0.55; Regression B-different: P=0.18,R=0.47,F1=0.26. Classification B-similar: P=0.53,R=1.00,F1=0.69; Classification B-different: P=0.23,R=1.00,F1=0.38.",
            "baseline_comparison": "Compared experimentally to BERT and GPT-2; XL performed between GPT-2 and BERT in many cases but failed in some transfer small-change scenarios (e.g., regression B-different). No traditional baseline numerical comparisons presented.",
            "limitations_or_failure_cases": "Less consistent than BERT; fails in some transfer settings especially when changes are not drastic (poor regression results for B-different); classification benefits from close-world recall=1.0 but lower precision/F1 compared to BERT in many cases.",
            "uuid": "e5679.3",
            "source_info": {
                "paper_title": "Robust and Transferable Anomaly Detection in Log Data using Pre-Trained Language Models",
                "publication_date_yy_mm": "2021-02"
            }
        },
        {
            "name_short": "Bi-LSTM",
            "name_full": "Bidirectional Long Short-Term Memory network",
            "brief_description": "A Bi-LSTM sequence model that consumes sequences of sentence-level embeddings of log templates and is trained either to classify the next template or regress the next embedding for anomaly detection.",
            "citation_title": "Robust and Transferable Anomaly Detection in Log Data using Pre-Trained Language Models",
            "mention_or_use": "use",
            "model_name": "Bi-LSTM",
            "model_description": "Two-directional LSTM network that processes windows of consecutive log-embedding vectors (size Î´); outputs pass through linear layers to either n-dimensional class logits (classification) or d-dimensional embedding prediction (regression). Training objectives: cross-entropy for classification, mean squared error for regression.",
            "model_size": null,
            "anomaly_detection_method": "Sequential modeling of embedding windows: (A) classification objective produces probability distribution over known templates for next position; anomaly if true template not in top-k or novel template too distant; (B) regression objective predicts next embedding and uses MSE against true embedding (or nearest template embedding) with q-th percentile threshold to flag anomalies.",
            "data_type": "Sequences of sentence-level log-template embeddings (temporal sequences).",
            "anomaly_type": "Sequence-level anomalies (unexpected successor templates), structural alterations in sequence (deletion/swap/imputation) and novel/unseen templates.",
            "dataset_name": "CloudLab OpenStack log dataset (Loghub)",
            "performance_metrics": "Reported combined with embedding source; performance depends strongly on embedding type and objective (see per-embedding metrics). Authors report classification objective often slightly outperforms regression for transfer robustness.",
            "baseline_comparison": "Compared conceptually to single-direction LSTM and one-hot template inputs used in prior work; authors chose Bi-LSTM for improved two-sided sequence modeling. No numeric head-to-head baseline beyond embedding comparisons.",
            "limitations_or_failure_cases": "Classification variant requires closed-world template knowledge and nearest-template heuristics for novel templates; regression depends on quality of embedding space (if embeddings are not separable, regression will suffer).",
            "uuid": "e5679.4",
            "source_info": {
                "paper_title": "Robust and Transferable Anomaly Detection in Log Data using Pre-Trained Language Models",
                "publication_date_yy_mm": "2021-02"
            }
        },
        {
            "name_short": "Drain",
            "name_full": "Drain log parser",
            "brief_description": "An online log parsing algorithm used to convert raw log messages to templates and variable parts before embedding; chosen for speed and efficiency.",
            "citation_title": "Robust and Transferable Anomaly Detection in Log Data using Pre-Trained Language Models",
            "mention_or_use": "use",
            "model_name": "Drain",
            "model_description": "Deterministic log parsing algorithm that segments log lines into templates and parameters using a fixed-depth parse tree; used as preprocessing to produce templates for sentence embedding.",
            "model_size": null,
            "anomaly_detection_method": "Preprocessing step: raw logs -&gt; templates + variables; templates embedded with pre-trained LMs and used in downstream Bi-LSTM anomaly detection.",
            "data_type": "Raw semi-structured logs converted to templates (structured/semi-structured).",
            "anomaly_type": "Enables detection of anomalies defined at template/sequence level by structuring logs.",
            "dataset_name": "CloudLab OpenStack log dataset (Loghub)",
            "performance_metrics": "Not evaluated as a detection model; used as preprocessing. No numeric performance reported.",
            "baseline_comparison": "Drain chosen over other parsers for speed/efficiency; other parsers mentioned in related work but not compared numerically here.",
            "limitations_or_failure_cases": "Relies on accurate parsing; parsing errors can propagate and affect embedding and subsequent anomaly detection quality.",
            "uuid": "e5679.5",
            "source_info": {
                "paper_title": "Robust and Transferable Anomaly Detection in Log Data using Pre-Trained Language Models",
                "publication_date_yy_mm": "2021-02"
            }
        },
        {
            "name_short": "CloudLab OpenStack (Loghub)",
            "name_full": "CloudLab OpenStack log dataset (available at Loghub)",
            "brief_description": "The log dataset used for training and evaluating the framework, containing two experiment sets: normal runs and runs with occasionally injected anomalies; authors also synthetically augment the normal data with semantic and sequential alterations to test robustness and transfer.",
            "citation_title": "Robust and Transferable Anomaly Detection in Log Data using Pre-Trained Language Models",
            "mention_or_use": "use",
            "model_name": "CloudLab OpenStack logs",
            "model_description": "Operational logs from OpenStack experiments collected on CloudLab and hosted on the Loghub repository; includes normal runs and anomaly-injected runs; authors additionally created synthetic altered datasets A and B (B-similar and B-different) to simulate software updates.",
            "model_size": null,
            "anomaly_detection_method": "Used as training/test data for evaluating LM-embedding + Bi-LSTM detection under ground-truth anomalies, synthetic token-level and sequence-level alterations, and transfer scenarios.",
            "data_type": "Semi-structured log messages (templates + variables), organized as time-ordered sequences.",
            "anomaly_type": "Ground-truth injected anomalies, synthetic semantic alterations (deletion/swap/imputation of tokens), synthetic sequential alterations (deletion/swap/imputation of events), and dataset changes simulating software updates.",
            "dataset_name": "CloudLab OpenStack log dataset (Loghub)",
            "performance_metrics": "Used for measuring precision, recall, F1 under different embedding models and objectives; see model entries for reported scores.",
            "baseline_comparison": "Dataset is a commonly used log dataset referenced in log analysis literature; paper uses it for LM-embedding evaluation and transfer experiments rather than comparing detection methods on multiple datasets.",
            "limitations_or_failure_cases": "Authors create synthetic alterations and artificial A/B variants to evaluate transfer; real-world update patterns may differ; results are reported for this dataset and may vary on other log corpora.",
            "uuid": "e5679.6",
            "source_info": {
                "paper_title": "Robust and Transferable Anomaly Detection in Log Data using Pre-Trained Language Models",
                "publication_date_yy_mm": "2021-02"
            }
        },
        {
            "name_short": "DeepLog (related)",
            "name_full": "DeepLog: Anomaly detection and diagnosis from system logs through deep learning",
            "brief_description": "A prior deep-learning method that uses LSTM to predict subsequent log events based on a window of past events and flags incorrect predictions as anomalies; mentioned as related work and baseline conceptually.",
            "citation_title": "Robust and Transferable Anomaly Detection in Log Data using Pre-Trained Language Models",
            "mention_or_use": "mention",
            "model_name": "DeepLog (LSTM on template indices)",
            "model_description": "LSTM-based model trained on one-hot/templated log indices to predict next event; uses synonym/antonym DB for robustness to novel events in original paper. Mentioned as prior art; not re-implemented or numerically compared in this paper.",
            "model_size": null,
            "anomaly_detection_method": "Sequence prediction on one-hot template indices with LSTM; detection by mismatch between predicted and actual next template.",
            "data_type": "Sequences of log template indices (discrete sequences).",
            "anomaly_type": "Unexpected next-template events; inability to handle novel templates due to one-hot representation noted as a weakness.",
            "dataset_name": null,
            "performance_metrics": "Not evaluated in this paper; referenced in related work.",
            "baseline_comparison": "Used in related work discussion to motivate semantic embeddings; authors argue DeepLog and similar one-hot template methods cannot cope with novel templates that were not in training.",
            "limitations_or_failure_cases": "One-hot template inputs cannot represent unseen/new templates; relies on template invariance assumptions which break under software updates; authors use this to motivate their semantic embedding approach.",
            "uuid": "e5679.7",
            "source_info": {
                "paper_title": "Robust and Transferable Anomaly Detection in Log Data using Pre-Trained Language Models",
                "publication_date_yy_mm": "2021-02"
            }
        },
        {
            "name_short": "PCA (related)",
            "name_full": "Principal Component Analysis on event-count vectors",
            "brief_description": "A classical unsupervised anomaly detection approach that the authors mention: transform logs into event-count vectors over windows and apply PCA to detect anomalies via reconstruction or projection norms.",
            "citation_title": "Robust and Transferable Anomaly Detection in Log Data using Pre-Trained Language Models",
            "mention_or_use": "mention",
            "model_name": "PCA on log event-count vectors",
            "model_description": "Classical linear dimensionality reduction (PCA) applied to count-based features aggregated over time windows; anomalies detected by deviations in principal component space (e.g., high reconstruction error or large norm in lower principal components).",
            "model_size": null,
            "anomaly_detection_method": "Aggregate log event counts per window -&gt; PCA -&gt; anomaly score from projection / reconstruction; cited as prior unsupervised approach (Xu et al.).",
            "data_type": "Aggregated counts of log events (vectorized, non-sequential or windowed sequences).",
            "anomaly_type": "Statistical outliers in event-count feature space (large deviations from normal principal-subspace).",
            "dataset_name": null,
            "performance_metrics": "Not evaluated numerically in this paper; mentioned as representative traditional unsupervised baseline in related work.",
            "baseline_comparison": "Authors contrast PCA-based approaches with their semantic-embedding method qualitatively, arguing PCA on counts lacks semantic awareness and is less robust to log evolution.",
            "limitations_or_failure_cases": "Cannot capture semantic similarities between templates and is sensitive to changes in event vocabulary and distribution over time; not designed to handle novel templates semantically.",
            "uuid": "e5679.8",
            "source_info": {
                "paper_title": "Robust and Transferable Anomaly Detection in Log Data using Pre-Trained Language Models",
                "publication_date_yy_mm": "2021-02"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Deeplog: Anomaly detection and diagnosis from system logs through deep learning",
            "rating": 2,
            "sanitized_title": "deeplog_anomaly_detection_and_diagnosis_from_system_logs_through_deep_learning"
        },
        {
            "paper_title": "Detecting large-scale system problems by mining console logs",
            "rating": 2,
            "sanitized_title": "detecting_largescale_system_problems_by_mining_console_logs"
        },
        {
            "paper_title": "Drain: An online log parsing approach with fixed depth tree",
            "rating": 2,
            "sanitized_title": "drain_an_online_log_parsing_approach_with_fixed_depth_tree"
        },
        {
            "paper_title": "Bert: Pre-training of deep bidirectional transformers for language understanding",
            "rating": 1,
            "sanitized_title": "bert_pretraining_of_deep_bidirectional_transformers_for_language_understanding"
        },
        {
            "paper_title": "Language models are unsupervised multitask learners",
            "rating": 1,
            "sanitized_title": "language_models_are_unsupervised_multitask_learners"
        },
        {
            "paper_title": "Xlnet: Generalized autoregressive pretraining for language understanding",
            "rating": 1,
            "sanitized_title": "xlnet_generalized_autoregressive_pretraining_for_language_understanding"
        }
    ],
    "cost": 0.01666925,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Robust and Transferable Anomaly Detection in Log Data using Pre-Trained Language Models</p>
<p>Harold Ott 
Distributed and Operating Systems
TU Berlin
BerlinGermany</p>
<p>Jasmin Bogatinovski jasmin.bogatinovski@tu-berlin.de 
Distributed and Operating Systems
TU Berlin
BerlinGermany</p>
<p>Alexander Acker alexander.acker@tu-berlin.de 
Distributed and Operating Systems
TU Berlin
BerlinGermany</p>
<p>Sasho Nedelkoski nedelkoski@tu-berlin.de 
Distributed and Operating Systems
TU Berlin
BerlinGermany</p>
<p>Odej Kao odej.kao@tu-berlin.de 
Distributed and Operating Systems
TU Berlin
BerlinGermany</p>
<p>Robust and Transferable Anomaly Detection in Log Data using Pre-Trained Language Models
* Equal contribution.Index Terms-anomaly detectionlog analysisdeep learninglanguage modelstransfer learning
Anomalies or failures in large computer systems, such as the cloud, have an impact on a large number of users that communicate, compute, and store information. Therefore, timely and accurate anomaly detection is necessary for reliability, security, safe operation, and mitigation of losses in these increasingly important systems. Recently, the evolution of the software industry opens up several problems that need to be tackled including (1) addressing the software evolution due software upgrades, and (2) solving the cold-start problem, where data from the system of interest is not available. In this paper, we propose a framework for anomaly detection in log data, as a major troubleshooting source of system information. To that end, we utilize pre-trained general-purpose language models to preserve the semantics of log messages and map them into log vector embeddings. The key idea is that these representations for the logs are robust and less invariant to changes in the logs, and therefore, result in a better generalization of the anomaly detection models. We perform several experiments on a cloud dataset evaluating different language models for obtaining numerical log representations such as BERT, GPT-2, and XL. The robustness is evaluated by gradually altering log messages, to simulate a change in semantics. Our results show that the proposed approach achieves high performance and robustness, which opens up possibilities for future research in this direction.</p>
<p>I. INTRODUCTION</p>
<p>Modern computer systems such as cloud platforms are a combination of complex multi-layered software and hardware. The complexity implies high maintenance overhead for the operators of these systems, making the manual operation cumbersome. In extreme cases, where system anomalies or failures happen, it can lead to SLA violations. Large service providers are aware of such cases and make the automation operation and maintenance tasks a priority.</p>
<p>Recently, a plethora of methods were introduced to automate and provide scalable AI-driven solutions to perform a range of operational tasks including anomaly detection and failure analysis [1]- [3]. In the foundation of these methods are the system data. Although there are various data sources describing system behaviour, system logs are an omnipresent data source [3], [4]. They are one of the most used data sources for troubleshooting.</p>
<p>The evolution of the software industry opens up several problems that need to be tackled. The detection of the abnormal behaviour of the system is one of them. When considering the anomaly detection models from log data, two of the most important challenges are (1) addressing the software evolution due software upgrades, and (2) solving the cold-start problem [5]. In both cases, anomaly detection models have to be dynamically optimized and adapted to the new setting. Exposing the underlying properties of the log messages in a system-agnostic manner (e.g. semantics, length, etc.) arises as an important requirement from the anomaly detection methods utilizing system logs.</p>
<p>On the contrary, many of the existing approaches are based on the invariant assumption, i.e. log templates never change. Furthermore, they rely on the assumption capturing all possible variations of log messages. Approaches, such as matching certain keywords (e.g. "error"), constructing a black-list of log events or anomalous matching regular expressions, are infertile under the circumstances of constant system's evolution. They usually lead to many unnecessary alarms, a problem known as alarm fatigue.</p>
<p>To mitigate the drawbacks of the invariant assumption, we propose an anomaly detection framework capable of preserving the shared properties between the log messages. More specifically, we utilized transfer learning and deep language modeling to learn a robust, context-aware representation of the log messages. Whenever a new log line is introduced, the framework assigns numerical-vector representation to it utilizing prior information from all the previously presented log messages. As such it is effective in reducing the coldstart problem the anomaly detection model is facing after an update. Through time, the framework reuses the accumulated knowledge for the log messages to improve the performance and the underlying representation. In a nutshell, the framework provides a mechanism to transfer knowledge from previous log messages and automatically detect anomalies in logs affected by pre-processing noise and changes of log events by updates of the underlying software.</p>
<p>The contributions of this work are summarized as follows.</p>
<p>1) A general framework for learning context and semanticaware numerical log vector representations suitable for anomaly detection. 2) Comparison of three semantic-level general-purpose language embedding models for anomaly detection. 3) Comparison of two learning objectives for anomaly detection utilizing general language models. 4) Robust model transfer approach for reduction of the false positive rate after software update. 5) We provide a publicly available implementation of the method and the datasets. 1 The remaining of the paper is structured as follows. In section II, we provide the related work for anomaly detection in log data. In sections III, we present the preliminary the proposed framework. Section IV summarizes the evaluation of the different language models, learning objective as well as model transfer. Section V concludes the paper.</p>
<p>II. RELATED WORK</p>
<p>As a major data type for the system behaviour, the literature recognizes sustainable utilization of the log data for anomaly detection in both the industry and academia [3]- [7]. The work on anomaly detection from log data follows two general directions: supervised and unsupervised methods. In this work, our focus is on unsupervised learning approaches.</p>
<p>The unsupervised approaches have greater practical relevance, because labeling of log messages is an expensive procedure. There is a number of approaches that have been developed using the log event count within a certain window to transform log messages to numerical representations. Xu et al. [6] proposed using the Principal Component Analysis (PCA) method on such vectors. It follows a standard machine learning techniques of investigation of the second norm of the lower principle components to decide if the log is normal or an anomaly.</p>
<p>There are several works for log anomaly detection that utilize deep learning approaches. For example, Zhang et al. [8] used LSTM to predict subsequent log events based on a window of preceding events. The ability to correctly predicting the next event is used to determine anomalous events. DeepLog [4] is utilizing a similar method. It is claimed that robustness to novel events is achieved by a synonym/antonym database that is used to generate auxiliary samples. Vijayakumar et al. [9] trained a stacked-LSTM to model the operation log samples of normal and anomalous events. However, the input to the unsupervised methods is a one-hot vector of logs representing the indices of the log templates. Therefore, it cannot cope with newly appearing log events.</p>
<p>Several studies [5] have leveraged NLP techniques to analyze log data based on the idea that log is a natural language sequence. Those works are utilizing word embeddings which are later averaged in order to represent the full log message. Non-learnable aggregation is a heuristic that often does not hold when going from words to sentences [10]. Different from all the above methods, we utilize state-of-the-art language models for obtaining numerical representations for log messages. It enables using end-to-end trainable vector representations that can be used in various recurrent networks e.g. Bi-LSTM [11] for anomaly detection. The log representations are robust to semantic-invariant changes of the log messages, providing good generalization.</p>
<p>III. ROBUST LOG ANOMALY DETECTION</p>
<p>The architecture of the framework is presented in Figure 2. It is composed of two phases, offline training phase and online anomaly detection.</p>
<p>The training phase is composed of the following steps. First, the raw log messages from the system are preprocessed. This includes a transformation of the log into a template and variable part (e.g., VM Creation took 8 seconds; template: "VM Creation took * seconds", variables: [8]). Each of the templates is then transformed into a numerical vector using language models such as BERT, GPT, and XL [12]- [14]. Utilizing the pre-trained embeddings from these general-purpose models aims to capture the semantic properties the log messages, important for generalization over different data [5]. In the second step, we chain the embedding vectors through time in a recurrent neural network (Bi-LSTM [11]) that learns the normal system behaviour. It is then utilized for anomaly detection by detecting deviations from the expected system behaviour. It enables robust detection of sequential anomalies. Important to note is that the neural network is trained on pre-trained numerical representations, therefore, it largely facilitates the transfer of the learned model to new log data that can appear due to software upgrades or due cold-start problems.</p>
<p>In the prediction phase, the log messages are transformed into log vectors via the same preprocessing steps as in training. Then, the sequences of such log vectors are provided as input to the anomaly detection model. The prediction from the sequential model is utilized to decide if the input sequence is normal or not. In the following, we describe each of the parts in detail.</p>
<p>A. Log preprocessing and log vectorization</p>
<p>The raw log messages generated by the systems are noisy with semi-structured form. To structure them and to obtain the information from the logs needed for the anomaly detection model, they require to be parsed [3]. Log parsing provides a mapping function of the raw log messages into log templates e.g log instruction in the source code. In this work, we adopt Drain [15], due to its speed and efficiency.</p>
<p>Next, the log templates are transformed into numerical vectors. Formally, we write a log vector (embedding) as w i â R d , where d is the size of the vector embedding. The goal of the log vectorization is to preserve important properties of log messages and distinct normal against anomaly log messages.  To better illustrate the importance of the log vectors, in Figure 1, we provide a visual comparison between normal and anomalous log messages when standard one-hot encoding is utilized against vector embeddings obtained from pre-trained methods. Improvements in the log vectorization translate to improvements in the robustness and generalization of the anomaly detection models.</p>
<p>To that end, we formalize two properties that a log vector embedding should poses. (1) Distinguishable: the log vectors should represent semantic differences between the log messages. For example, VM Create finished and VM Fatal error are templates with different semantics, even though they share the same words (instance) and synonyms (terminating, deleting). (2) Tolerance: the embeddings should represent the similarity between different templates with the same or very similar semantics. For example, VM Create finished is semantically very similar to VM Create completed.</p>
<p>To preserve both properties, we refer to the natural language models, where these properties are one of the major parts of research. Exploiting general-purpose language models, which are pre-trained on large corpora of texts (e.g., Wikipedia) enables preserving of general textual structures. We focus on utilizing sentence-level embeddings, in contrary to word level embeddings. Sentence level embedding provide direct and efficient mapping from log message to log vector, without any intermediate steps (e.g. averaging of word vectors).</p>
<p>B. Bi-LSTM for Sequential Anomaly Detection</p>
<p>Once obtained, the log vectors are grouped (by timestamp) into sequences of size Î´ (window size), i.e., the sequences are formed of consecutive log vector embeddings, w i : w i+Î´ . We define two learning tasks which are utilized to learn the normal sequences of log messages: (1)Prediction of the log template as a class (classification, via minimization of the cross-entropy loss), and (2) prediction of the log vector (regression, via minimization of the mean squared error), of the log message that appears at the next position in the sequence W i+Î´+1 , given the w i : w i+Î´ sequence as input. Figure 3 depicts the overview of the Bi-LSTM model used to optimize the objectives [11]. The input data is passed to the forward and backward layers of the Bi-LSTM. We selected this model for learning the sequences as it offers a two-sided view and improved properties for sequence learning, in comparison to the single LSTM networks.</p>
<p>The output of the Bi-LSTM network is an abstract numerical representation of the input sequence, which is then utilized for optimizing the objective. The subsequent two linear layers are applying a transformation to acquire the desired dimensions, i.e., d for regression and n (number of classes) for classification. Finally, an activation function f is applied to the output of the last linear layer. We use cross-entropy for classification and mean squared error for regression.</p>
<p>Anomaly Detection using Multi-Class Classification. For this learning objective, we used all available log templates as a target class (total of n). The training is performed on the assumption that the data contains an abundance of normal log messages, while in the prediction phase, the input data contains normal and anomalous log templates.</p>
<p>One major issue in this setup is that of the "close-world" classification objective requires apriori knowledge of all log templates. However, during prediction, it is expected that novel log templates will emerge. To address the absence of all templates at the prediction phase, we apply a nearest template matching procedure to mitigate this limitation.</p>
<p>In the template matching procedure, we calculate the dis-  tance between the embedding of the novel template and all of the known target embeddings. The novel template is assigned the class target that has the smallest distances to the known target templates. To prevent matching on arbitrary novelties, a parameter maximal distance is introduced. When the minimal distance to the template to the set of known templates greater then some the maximal distance, the novel template is discarded and anomaly label is directly assigned. The matching process is applied on w i i+Î´+1 in order to obtain t i+Î´+1 .</p>
<p>After the matching process, the model predicts a probability distribution P r[t i+Î´+1 |w i:i+Î´ ] = (p(t)|ât â T). It described the probability of a template t â T to occur as a successor of templates w i:i+Î´ . Due to the noise in the sequential appearing of the templates, we consider the top-k (out of |T |) templates with the highest probabilities to appear as relevant as the next template. If the actual template class t i+Î´+1 is within the topâ k predictions with the highest probability, we consider is as normal. Otherwise, it is labeled as an anomaly.</p>
<p>Anomaly Detection using Log Vector Regression. For the regression learning objective, the neural network is trained to minimize the mean squared error (MSE). The input of the network is a sequence of vector embeddings for the templates, while the corresponding target value for the sequence is the vector embedding of the next template. Compared to classification, the log vector embeddings for regression are always obtainable.</p>
<p>After the model is trained, the parameters for the anomaly detection models are calculated. The regression anomaly detection module has as a parameter the q â th percentile of the squared error for the training samples. The mean squared error of every target for each training sequence template at position i + s + 1 and the neural network's predicted template vector, is computed. Afterwards, the q-th percentile of the agglomerated loss values of the training dataset is computed. To detect anomaly, when novel sample from test dataset is introduced, the squared error between the predicted template and the vector embedding of the nearest matched template. The system will then mark every log event whose embedding loss value is above the calculated q-th percentile as an anomaly and normal, otherwise.</p>
<p>C. Model Transfer</p>
<p>Utilizing pre-trained general-purpose language models for extracting log representations and training the Bi-LSTM model allows the transfer of the model to new unseen logs. The model transfer is achieved in the following way.</p>
<p>Let dataset A be the training dataset from already known log messages, and dataset B be a dataset from an updated or new service or system. After the preprocessing, the model is trained on the dataset A. Then, the following steps are executed. First, every log event of dataset B is mapped to the nearest neighbour of dataset A, i.e. the embedding with the shortest cosine distance. In the case of classification, it gets assigned the same class target. Second, a few-shot training on dataset B will be executed. Finally, with the adjusted model on training dataset B, the prediction phase on a test dataset B is executed as previously described for the classification and regression learning objectives.</p>
<p>The initial training on dataset A preserves semantic and contextual information from previous log messages. The fewshow training on dataset B allows the model to adapt to the specifics of the dataset B and improve the results on anomaly detection.</p>
<p>IV. EVALUATION</p>
<p>To demonstrate the usefulness of our framework for anomaly detection and transferability of the models from different software deployments we conducted two evaluation experiments. In the first experimental scenario, we investigate how effective are the representations from sentencelevel language models for anomaly detection on 1) ground truth anomalies and 2) synthetic anomalies obtained via log alteration. In the second experimental scenario, we evaluate the transferability of the models during software updates.</p>
<p>A. Log Datasets</p>
<p>For our experiments, we utilize the CloudLab OpenStack log dataset available at the Loghub [4]. It is composed of two sets of experiments. During the first set of experiments, the Openstack instances were created and their runtime was monitored. The second set of experiments is similar to the former, however, occasionally anomalies were injected. The first dataset, we refer to as a normal dataset while the second one as anomalous dataset. Furthermore, to evaluate the framework, we additionally manipulated the normal dataset and created two additional test sets described in the following.</p>
<p>Log alteration. To evaluate the feasibility of sentence-level based embeddings for anomaly detection in log data we augmented our data with a synthetic dataset. We refer to this data as log alteration data. We identified two points of alteration in the log messages; semantic and contextual alteration. The alterations are applied to normal data. Therefore, the overall anomaly detection model should be robust against these alterations. Classifying suchlike altered log messages as anomalies are considered as false alarms. For both, the semantic and structural changes we identified 3 types of alteration, namely: deletion, swap and imputation.</p>
<p>For the semantic changes, we assume a log event to contains n tokens originating from the normal data. Deletion operation involves deleting of l randomly selected words in the log message. Swap operation involves, replacing l tokens with a random token. Imputation operation involves imputing l words at a random position of original log event. The parameter l controls the intensity of the alternation. It is expected that log events with higher alternation intensity have a higher probability to be detected as anomalies compared to events that were altered with lower intensity.</p>
<p>For the structural changes, we assume a log sequence to contains m log templates originating from the normal data. Deletion operation involves deleting of l random log events from the sequence. Swap operation involves, replacing the k templates appearing after randomly selected index i, to a randomly chosen index j. For the indices the inequality j &lt; i holds. Imputation operation for sequences involves selecting index at position i and repeating it l times consecutively. The parameter l controls the number of imputations. It is expected that log events with higher alternation intensity have a higher probability to be detected as anomalies compared to events that were altered with lower intensity. Augmentation to Simulate a Different Dataset. Since the software is often updated and thus changed constantly by developers, log statements are also subject to change. To simulate the evolution of the system, we construed an artificial dataset that simulates changed log messages. We constructed two datasets, we refer to as dataset A and B, in the following manner. We start with the normal data we refer to dataset A. Firstly, we randomly sample p% of the logs in A. Secondly, the sampled log lines are altered using the three semantic alteration techniques with additional word augmentation. The alteration parameters are set to random values in the range 5-100 % of the range of allowed values for altering parameters. This allows simulating different dataset. We refer to this altered dataset as a dataset B. Finally, we create two versions of the dataset B. If the alteration is not severe (e.g. 20% of the log messages is changed) the dataset is referred to as Bsimilar, otherwise, the dataset is referred to as B-different. The datasets A and B are used for transferring the contextual and semantic accumulated knowledge in the following way. The model is trained on this dataset A for e epochs (60 in our study). Then part of the dataset B is used to conduct few-shot training. The final evaluation is done on the task of anomaly detection in the second part of dataset B.</p>
<p>B. Semantic-level language embedding evaluation</p>
<p>This section presents the evaluation of the results. We first evaluate the sentence-level embeddings capability of the different language models for anomaly detection independent on the learning task. Namely, we compare BERT, XL-Transformers and GPT-2 on the regression-based approach and the classification-based approach for anomaly detection. Afterwards, the results of the evaluation using the model transfer learning approach are presented.</p>
<p>1) Regression-based anomaly detection.: TABLE I enlists the results from the comparison of the three language models on the task of anomaly detection. We divided the experiments into two subsets according to the type of alteration. Semantic alteration is related to the semantic changes of the log messages, while the sequential alteration is related to sequential alteration, described previously. For the semantically alerted log messages, GPT-2 yields better results compared to BERT and XL-Transformers with regards to all metrics. For the sequential altering of the log messages, there is a small drop of F1-score and precision for the GPT-2 embeddings. However, the same metrics increase for BERT and XL embedding. The results from both scenarios imply that GPT-2 and BERT embeddings are more robust when either the semantic or sequential changes are considered.</p>
<p>2) Classification : When considering the classification task we conducted the two separate results as in the case of regression. For semantically alerted log messages the scores are reversed. More specifically, BERT is showing the best results, followed by XL and GPT-2. The same pattern appears when considering the sequential learning scenario. General comparison of the scores between the regression and classification tasks shows that GPT-2 embeddings are highly affected by the optimization objective. The definition of the problem as a classification task is favourable when considering structural and sequential changes.</p>
<p>C. Model Transfer Evaluation</p>
<p>For the evaluation of model transfer we conducted two experiments, for both the regression-and classification learning objectives on the task of anomaly detection. The results are listed in TABLE II. For the regression learning objective when considering the large alteration, it can be seen that the both GPT-2 and BERT are performing well. However, when considering the small alteration, although BERT embeddings still retain high score, the GPT-2 tends to produce weaker results. On contrary, while being good performing method on the task of similar log messages, XL-Transformers fails when the changes of the log messages are not drastic.</p>
<p>On the classification learning objective, when considering both large and small alterations, the model utilizing BERT tends to outperform the remaining two. Comparing the XL-Transformers and GPT-2, it can be observed that the former outperforms the latter. Comparing the results alongside the learning objectives, it can be observed that the classification problem definition, slightly outperforms the definition of the problem as a regression task.</p>
<p>D. Discussion</p>
<p>The good results from both the classification and regression learning objectives show that the framework is useful for anomaly detection in setting where the data is evolving through time. When evaluating the different forms of alteration of the log messages and sequences of log messages BERT, as a general-purpose language model on sentence-level embeddings, shows to perform more consistently and robustly across the two learning objectives. It is followed by XL-Transformers and GPT-2 accordingly. GPT-2 shows strong results in experiment type for regression learning objective, but not as competitive for classification learning objective. Similar observations can be made for model transfer in settings where there are both small and large changes in the log messages.</p>
<p>Comparison of the different learning objectives shows that the definition of the learning task as a classification problem can produce better results compared to it defined as a regression problem. This is an interesting result from this study.</p>
<p>The plug-and-play strategy allows for testing different language models. As seen by the results, the different language models can highly influence the quality of the results for anomaly detection, with different word embeddings having strengths and weaknesses in different categories. Improving the NLP language models via increasing the number of parameters e.g. [16] will result in even better performance.</p>
<p>V. CONCLUSION</p>
<p>This paper addresses the problem of log anomaly detection in large computer systems. We addressed the generalization problem for anomaly detection on unseen logs by introducing a plug-and-play framework that utilizes pre-trained language models for obtaining numerical, semantically aware embeddings for log events. Bi-LSTM neural network is used as a method for exploiting contextual properties of log messages in the task of anomaly detection. Empirically, we show that the proposed approach is robust to alteration in the log messages -scenarios frequently occurring in practice due to software updates and deploying new services or systems. The results show that the framework achieves high performance using state-of-the-art sentence-level language models. Furthermore, we show that not every representation is equally useful for anomaly detection. Some of the language models fail to generate log representations that can be separated by a learned decision boundary. The underlying learning objective is also very important to obtain good results in the task of anomaly detection. The proposed approach opens new potential for anomaly detection not just from log data, but from other sources that have the notion of a distributed representation of an event e.g., distributed tracing data. We believe that the method will motivate further research in the direction of development of pre-trained language models on log data. This would enhance the log representations, and thus, improve the performance of the anomaly detection methods.</p>
<p>Fig. 1 .
1Log vector representation using invariant embeddings (left) and semantically-aware embeddings (right).</p>
<p>Fig. 3 .
3Unfolded Bi-LSTM model used for anomaly detection of the embedding sequence.</p>
<p>Fig. 2. Overview of the framework utilizing sentence level pre-trained language models.Training data </p>
<p>Raw log messages 
... 
i. Took 8 seconds to build 
instance 
... </p>
<p>Templates ( ) 
... 
i. Took * seconds to build 
instance 
... </p>
<p>Log parsing </p>
<p>Language 
Model </p>
<p>... 
i. [0.573, -0.623, ..., -0.249] 
... </p>
<p>Log vectorization </p>
<p>Template -&gt; embedding table </p>
<p>New log data (prediction/test) </p>
<p>Nearest template matching for test logs </p>
<p>Training data </p>
<p>0.132 
0.142 
... 
... </p>
<p>-0.297 
-0.262 
Next template prediction 
(classification) </p>
<p>Next embedding 
prediction 
(regression) </p>
<p>Bi-LSTM Model </p>
<p>Prediction for anomaly </p>
<p>Test data </p>
<p>Input: </p>
<p>Output: </p>
<p>TABLE I COMPARISON
IOF THE SENTANCE-LEVEL LANGUAGE EMBEDDING MODELS FOR THE TASK OF ANOMALY DETECTION.learning objective 
type of 
experiment </p>
<p>Precision score 
Recall score 
F1 score 
GPT-2 
XL 
BERT GPT-2 
XL 
BERT 
GPT-2 XL 
BERT </p>
<p>regression </p>
<p>semantic 
0.88 
0.21 
0.43 
1.00 
0.63 1.00 
0.94 
0.31 
0.56 
sequential 
0.79 
0.32 
0.49 
1.00 
0.61 1.00 
0.87 
0.42 
0.66 </p>
<p>classification </p>
<p>semantic 
0.24 
0.26 
0.37 
0.70 
1.00 1.00 
0.36 
0.41 
0.54 
sequantial 
0.31 
0.36 
0.5 
0.70 
1.00 1.00 
0.43 
0.53 
0.67 </p>
<p>TABLE II EVALUATION
IIRESULTS FOR THE MODEL TRANSFER AFTER SOFTWARE UPDATES. PERCENTAGE OF ALTERED LOG MESSAGES IS P=15%.learning objective 
type of 
experiment </p>
<p>Precision score 
Recall score 
F1 score 
GPT-2 
XL 
BERT GPT-2 
XL 
BERT 
GPT-2 XL 
BERT </p>
<p>regression 
B-similar 
0.23 
0.45 
0.58 
0.05 
0.7 
0.7 
0.08 
0.55 
0.63 
B-different 
0.94 
0.18 
0.52 
1.00 
0.47 1.00 
0.97 
0.26 
0.68 </p>
<p>classification 
B-similar 
0.27 
0.53 
0.61 
1.00 
1.00 1.00 
0.43 
0.69 
0.75 
B-different 
0.09 
0.23 
0.68 
1.00 
1.00 1.00 
0.17 
0.38 
0.81 </p>
<p>https://github.com/haraldott/anomaly detection main</p>
<p>Multi-source anomaly detection in distributed it systems. J Bogatinovski, S Nedelkoski, arXiv:2101.04977arXiv preprintJ. Bogatinovski and S. Nedelkoski, "Multi-source anomaly detection in distributed it systems," arXiv preprint arXiv:2101.04977, 2021.</p>
<p>Selfattentive classification-based anomaly detection in unstructured logs. S Nedelkoski, J Bogatinovski, A Acker, J Cardoso, O Kao, S. Nedelkoski, J. Bogatinovski, A. Acker, J. Cardoso, and O. Kao, "Self- attentive classification-based anomaly detection in unstructured logs," 2020.</p>
<p>Tools and benchmarks for automated log parsing. J Zhu, S He, J Liu, P He, Q Xie, Z Zheng, M R Lyu, 2019 IEEE/ACM 41st International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP). IEEEJ. Zhu, S. He, J. Liu, P. He, Q. Xie, Z. Zheng, and M. R. Lyu, "Tools and benchmarks for automated log parsing," in 2019 IEEE/ACM 41st In- ternational Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP). IEEE, 2019, pp. 121-130.</p>
<p>Deeplog: Anomaly detection and diagnosis from system logs through deep learning. M Du, F Li, G Zheng, V Srikumar, Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security. the 2017 ACM SIGSAC Conference on Computer and Communications SecurityACMM. Du, F. Li, G. Zheng, and V. Srikumar, "Deeplog: Anomaly detection and diagnosis from system logs through deep learning," in Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communica- tions Security. ACM, 2017, pp. 1285-1298.</p>
<p>Robust log-based anomaly detection on unstable log data. X Zhang, Y Xu, Q Lin, B Qiao, H Zhang, Y Dang, C Xie, X Yang, Q Cheng, Z Li, Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering. the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software EngineeringX. Zhang, Y. Xu, Q. Lin, B. Qiao, H. Zhang, Y. Dang, C. Xie, X. Yang, Q. Cheng, Z. Li et al., "Robust log-based anomaly detection on unstable log data," in Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, 2019, pp. 807-817.</p>
<p>Detecting large-scale system problems by mining console logs. W Xu, L Huang, A Fox, D Patterson, M I Jordan, Proceedings of the ACM SIGOPS 22nd symposium on Operating systems principles. the ACM SIGOPS 22nd symposium on Operating systems principlesW. Xu, L. Huang, A. Fox, D. Patterson, and M. I. Jordan, "Detecting large-scale system problems by mining console logs," in Proceedings of the ACM SIGOPS 22nd symposium on Operating systems principles, 2009, pp. 117-132.</p>
<p>Self-supervised log parsing. S Nedelkoski, J Bogatinovski, A Acker, J Cardoso, O Kao, 2020 European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases. SpringerS. Nedelkoski, J. Bogatinovski, A. Acker, J. Cardoso, and O. Kao, "Self-supervised log parsing," in 2020 European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML-PKDD). Springer, 2020.</p>
<p>Automated it system failure prediction: A deep learning approach. K Zhang, J Xu, M R Min, G Jiang, K Pelechrinis, H Zhang, 2016 IEEE International Conference on Big Data (Big Data). K. Zhang, J. Xu, M. R. Min, G. Jiang, K. Pelechrinis, and H. Zhang, "Automated it system failure prediction: A deep learning approach," 2016 IEEE International Conference on Big Data (Big Data), pp. 1291- 1300, 2016.</p>
<p>Long short-term memory based operation log anomaly detection. R Vinayakumar, K P Soman, P Poornachandran, 2017 International Conference on Advances in Computing, Communications and Informatics (ICACCI). R. Vinayakumar, K. P. Soman, and P. Poornachandran, "Long short-term memory based operation log anomaly detection," 2017 International Conference on Advances in Computing, Communications and Informat- ics (ICACCI), pp. 236-242, 2017.</p>
<p>Distributed representations of words and phrases and their compositionality. T Mikolov, I Sutskever, K Chen, G S Corrado, J Dean, Advances in neural information processing systems. T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado, and J. Dean, "Distributed representations of words and phrases and their composi- tionality," in Advances in neural information processing systems, 2013, pp. 3111-3119.</p>
<p>Bidirectional lstm-crf models for sequence tagging. Z Huang, W Xu, K Yu, arXiv:1508.01991arXiv preprintZ. Huang, W. Xu, and K. Yu, "Bidirectional lstm-crf models for sequence tagging," arXiv preprint arXiv:1508.01991, 2015.</p>
<p>Bert: Pre-training of deep bidirectional transformers for language understanding. J Devlin, M.-W Chang, K Lee, K Toutanova, arXiv:1810.04805arXiv preprintJ. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, "Bert: Pre-training of deep bidirectional transformers for language understanding," arXiv preprint arXiv:1810.04805, 2018.</p>
<p>Language models are unsupervised multitask learners. A Radford, J Wu, R Child, D Luan, D Amodei, I Sutskever, A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, and I. Sutskever, "Language models are unsupervised multitask learners."</p>
<p>Xlnet: Generalized autoregressive pretraining for language understanding. Z Yang, Z Dai, Y Yang, J Carbonell, R R Salakhutdinov, Q V Le, Advances in neural information processing systems. Z. Yang, Z. Dai, Y. Yang, J. Carbonell, R. R. Salakhutdinov, and Q. V. Le, "Xlnet: Generalized autoregressive pretraining for language understanding," in Advances in neural information processing systems, 2019, pp. 5753-5763.</p>
<p>Drain: An online log parsing approach with fixed depth tree. P He, J Zhu, Z Zheng, M R Lyu, 2017 IEEE International Conference on Web Services (ICWS). IEEEP. He, J. Zhu, Z. Zheng, and M. R. Lyu, "Drain: An online log parsing approach with fixed depth tree," in 2017 IEEE International Conference on Web Services (ICWS). IEEE, 2017, pp. 33-40.</p>
<p>Language models are few-shot learners. T B Brown, B Mann, N Ryder, M Subbiah, J Kaplan, P Dhariwal, A Neelakantan, P Shyam, G Sastry, A , arXiv:2005.14165arXiv preprintT. B. Brown, B. Mann, N. Ryder, M. Subbiah, J. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell et al., "Language models are few-shot learners," arXiv preprint arXiv:2005.14165, 2020.</p>            </div>
        </div>

    </div>
</body>
</html>