<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-8717 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-8717</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-8717</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-157.html">extraction-schema-157</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models performing self-reflection or iterative answer improvement (e.g., generate-then-reflect, self-critique, reflexion), including descriptions of the methods, tasks, performance results, mechanisms, and any reported limitations or failure cases.</div>
                <p><strong>Paper ID:</strong> paper-276885298</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2503.05179v2.pdf" target="_blank">Sketch-of-Thought: Efficient LLM Reasoning with Adaptive Cognitive-Inspired Sketching</a></p>
                <p><strong>Paper Abstract:</strong> Recent advances in large language models (LLMs) have enabled strong reasoning capabilities through Chain-of-Thought (CoT) prompting, which elicits step-by-step problem solving, but often at the cost of excessive ver-bosity in intermediate outputs, leading to increased computational overhead. We propose Sketch-of-Thought (SoT), a prompting framework that integrates cognitively inspired reasoning paradigms with linguistic constraints to reduce token usage while preserving reasoning accuracy. SoT is designed as a flexible, modular approach and is instantiated with three paradigms— Conceptual Chaining , Chun-ked Symbolism , and Expert Lexicons —each tailored to distinct reasoning tasks and selected dynamically at test-time by a lightweight routing model. Across 15 reasoning datasets spanning multiple domains, languages, and modalities, SoT achieves token reductions of up to 78% with minimal accuracy loss. In tasks such as mathematical and multi-hop reasoning, it even improves accuracy while shortening outputs.</p>
                <p><strong>Cost:</strong> 0.013</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e8717.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e8717.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models performing self-reflection or iterative answer improvement (e.g., generate-then-reflect, self-critique, reflexion), including descriptions of the methods, tasks, performance results, mechanisms, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Self-Consistency</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Self-Consistency (SC)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An ensemble-style iterative answer-improvement method that samples multiple independent reasoning paths from a stochastic LLM decoder and selects the final answer by majority voting over the sampled paths.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Self-consistency improves chain of thought reasoning in language models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Qwen-2.5 family (7B, 14B, 32B)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Qwen-2.5 instruction-tuned family used in 7B, 14B, and 32B sizes; experiments used temperature 0.5 and FlashAttention2 for inference optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>reflection_method_name</strong></td>
                            <td>Self-Consistency (SC)</td>
                        </tr>
                        <tr>
                            <td><strong>reflection_method_description</strong></td>
                            <td>Generate multiple (independent) reasoning paths for the same question using stochastic decoding, then aggregate answers by majority voting; in this paper SC was instantiated by producing 3 reasoning paths per question and taking the majority answer.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>15 reasoning datasets (mathematical, commonsense, logical, multi-hop, scientific, specialized; e.g., GSM8K, HotPotQA, CommonsenseQA, PubMedQA, etc.)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>A suite of 15 reasoning benchmarks covering mathematical problem solving, commonsense, logical reasoning, multi-hop QA, scientific/causal reasoning, and specialized medical tasks; experiments used 150 test samples per dataset (and 100 samples per language-domain for multilingual tests).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_reflection</strong></td>
                            <td>The paper reports that applying Self-Consistency improves accuracy for both CoT and SoT across tasks; SC+SoT maintained comparable accuracy to SC+CoT while preserving SoT's massive token savings (SC+SoT used 76.22%, 71.80%, and 71.90% fewer tokens than SC+CoT for the 32B, 14B, and 7B models respectively). Exact per-benchmark accuracy numbers for SC variants are reported in Table 1 but summarized qualitatively in text as an accuracy improvement for both approaches.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_reflection</strong></td>
                            <td>Baseline single-path CoT/SoT results reported (no-SC) for the same models and tasks; overall SoT vs CoT accuracy differences without SC were small (SoT change vs CoT: -0.46%, -0.14%, -0.74% for 32B, 14B, 7B respectively). The paper reports that adding SC increases accuracy relative to single-path generation for both CoT and SoT but does not give a single aggregated numeric delta for SC vs no-SC across all tasks in the main text.</td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>mechanism_of_reflection</strong></td>
                            <td>Implemented by prompt engineering + stochastic sampling: use the same exemplars/system prompt (CoT or SoT exemplars), generate 3 independent reasoning chains via sampling (temperature=0.5), and aggregate answers via majority voting (software-side ensemble voting).</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_iterations</strong></td>
                            <td>3</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_for_improvement</strong></td>
                            <td>Paper states and reports in results that Self-Consistency 'improves accuracy for both approaches' (CoT and SoT). They show SC+SoT maintains comparable accuracy to SC+CoT while preserving large token reductions (see Results 'Self-Consistency Improvements' paragraph and Table 1 rows for SC+CoT and SC+SoT).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>The paper does not report method-specific failure cases for SC; it notes SC increases token/computational cost because it requires multiple sampled paths (which SoT aims to mitigate), and specialized domains (e.g., medical reasoning) still exhibited larger accuracy declines overall even when using SoT and SC, suggesting SC may not fully recover losses in highly technical domains. No explicit negative effects (e.g., worsening accuracy with SC) are reported in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_methods</strong></td>
                            <td>Directly compared SC+CoT vs SC+SoT: SC improves both CoT and SoT; SC+SoT achieves comparable accuracy to SC+CoT while using far fewer tokens. The paper also situates SC among other methods in related work (Tree of Thoughts, Graph of Thoughts, SCOTT) but experimentally only compares CoT, SoT, and their SC variants.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Sketch-of-Thought: Efficient LLM Reasoning with Adaptive Cognitive-Inspired Sketching', 'publication_date_yy_mm': '2025-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8717.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e8717.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models performing self-reflection or iterative answer improvement (e.g., generate-then-reflect, self-critique, reflexion), including descriptions of the methods, tasks, performance results, mechanisms, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SCOTT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>SCOTT (Self-consistent Chain-of-Thought Distillation)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A two-stage iterative/ensemble-style method that first generates verbose chain-of-thought rationales and then distills them into a more compact/consistent form; cited in related work as an output-side token-efficiency approach.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Scott: Selfconsistent chain-of-thought distillation</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>reflection_method_name</strong></td>
                            <td>Two-stage generate-and-distill (SCOTT)</td>
                        </tr>
                        <tr>
                            <td><strong>reflection_method_description</strong></td>
                            <td>First generate verbose reasoning chains, then distill those chains into compact representations (a two-stage generate-then-distill pipeline) intended to retain correctness while reducing verbosity.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Referenced generally as a reasoning-improvement/output-compression method (original SCOTT work applied to CoT tasks)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Prior work (SCOTT) targeted chain-of-thought style reasoning tasks and sought to compress/distill multiple chains into a single compact rationale with maintained accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_reflection</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_reflection</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_comparison</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>mechanism_of_reflection</strong></td>
                            <td>Two-stage pipeline: generate multiple verbose reasoning chains, then distill/aggregate them to a compact form (output-side distillation); categorized under methods that reduce output verbosity rather than changing model architecture.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_iterations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evidence_for_improvement</strong></td>
                            <td>Mentioned in related work as an approach that 'explored a two-stage approach that first generates verbose reasoning and then distills it into more efficient forms'; the present paper does not provide new empirical results for SCOTT.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>No method-specific limitations reported in this paper (SCOTT is only cited in related work).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_methods</strong></td>
                            <td>Discussed conceptually as an output-side complementary approach to SoT; the present paper positions SoT as an alternative that directly constrains the reasoning output rather than relying on a separate distillation stage.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Sketch-of-Thought: Efficient LLM Reasoning with Adaptive Cognitive-Inspired Sketching', 'publication_date_yy_mm': '2025-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8717.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e8717.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models performing self-reflection or iterative answer improvement (e.g., generate-then-reflect, self-critique, reflexion), including descriptions of the methods, tasks, performance results, mechanisms, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Tree of Thoughts</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Tree of Thoughts (ToT)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An iterative search-style reasoning framework that explores branching thought trajectories (decision trees) of possible intermediate reasoning steps to solve difficult problems by explicit exploration and backtracking.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Tree of thoughts: Deliberate problem solving with large language models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>reflection_method_name</strong></td>
                            <td>Tree of Thoughts (search-based iterative reasoning)</td>
                        </tr>
                        <tr>
                            <td><strong>reflection_method_description</strong></td>
                            <td>Iteratively expand and evaluate branching reasoning nodes (thoughts) to search for high-quality reasoning paths; can be seen as iterative improvement via exploration of multiple partial solutions rather than single linear chains.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Referenced generally as a method for complex/problem-solving reasoning tasks</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Designed for reasoning problems where exploring multiple branching inference paths can find solutions that single-pass CoT may miss (e.g., puzzles, planning-like tasks).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_reflection</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_reflection</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_comparison</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>mechanism_of_reflection</strong></td>
                            <td>Algorithmic search over generated partial solutions (branching/heuristic exploration) implemented external to the base LLM; not used experimentally in this paper but cited as related work.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_iterations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evidence_for_improvement</strong></td>
                            <td>Cited as an example of methods that improve reasoning by exploring diverse paths; no new empirical evidence provided in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Not discussed in detail here; paper notes such exploration-based methods typically increase token/computational cost (and SoT targets token-efficiency in contrast).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_methods</strong></td>
                            <td>Positioned alongside Graph of Thoughts and Self-Consistency as methods that improve reasoning by exploration/ensemble of paths, but typically at the expense of more tokens/computation; SoT is presented as orthogonal (aiming to reduce verbosity while retaining benefits).</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Sketch-of-Thought: Efficient LLM Reasoning with Adaptive Cognitive-Inspired Sketching', 'publication_date_yy_mm': '2025-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Self-consistency improves chain of thought reasoning in language models <em>(Rating: 2)</em></li>
                <li>Scott: Selfconsistent chain-of-thought distillation <em>(Rating: 2)</em></li>
                <li>Tree of thoughts: Deliberate problem solving with large language models <em>(Rating: 2)</em></li>
                <li>Concise thoughts: Impact of output length on llm reasoning and cost <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-8717",
    "paper_id": "paper-276885298",
    "extraction_schema_id": "extraction-schema-157",
    "extracted_data": [
        {
            "name_short": "Self-Consistency",
            "name_full": "Self-Consistency (SC)",
            "brief_description": "An ensemble-style iterative answer-improvement method that samples multiple independent reasoning paths from a stochastic LLM decoder and selects the final answer by majority voting over the sampled paths.",
            "citation_title": "Self-consistency improves chain of thought reasoning in language models",
            "mention_or_use": "use",
            "model_name": "Qwen-2.5 family (7B, 14B, 32B)",
            "model_description": "Qwen-2.5 instruction-tuned family used in 7B, 14B, and 32B sizes; experiments used temperature 0.5 and FlashAttention2 for inference optimization.",
            "reflection_method_name": "Self-Consistency (SC)",
            "reflection_method_description": "Generate multiple (independent) reasoning paths for the same question using stochastic decoding, then aggregate answers by majority voting; in this paper SC was instantiated by producing 3 reasoning paths per question and taking the majority answer.",
            "task_name": "15 reasoning datasets (mathematical, commonsense, logical, multi-hop, scientific, specialized; e.g., GSM8K, HotPotQA, CommonsenseQA, PubMedQA, etc.)",
            "task_description": "A suite of 15 reasoning benchmarks covering mathematical problem solving, commonsense, logical reasoning, multi-hop QA, scientific/causal reasoning, and specialized medical tasks; experiments used 150 test samples per dataset (and 100 samples per language-domain for multilingual tests).",
            "performance_with_reflection": "The paper reports that applying Self-Consistency improves accuracy for both CoT and SoT across tasks; SC+SoT maintained comparable accuracy to SC+CoT while preserving SoT's massive token savings (SC+SoT used 76.22%, 71.80%, and 71.90% fewer tokens than SC+CoT for the 32B, 14B, and 7B models respectively). Exact per-benchmark accuracy numbers for SC variants are reported in Table 1 but summarized qualitatively in text as an accuracy improvement for both approaches.",
            "performance_without_reflection": "Baseline single-path CoT/SoT results reported (no-SC) for the same models and tasks; overall SoT vs CoT accuracy differences without SC were small (SoT change vs CoT: -0.46%, -0.14%, -0.74% for 32B, 14B, 7B respectively). The paper reports that adding SC increases accuracy relative to single-path generation for both CoT and SoT but does not give a single aggregated numeric delta for SC vs no-SC across all tasks in the main text.",
            "has_performance_comparison": true,
            "mechanism_of_reflection": "Implemented by prompt engineering + stochastic sampling: use the same exemplars/system prompt (CoT or SoT exemplars), generate 3 independent reasoning chains via sampling (temperature=0.5), and aggregate answers via majority voting (software-side ensemble voting).",
            "number_of_iterations": 3,
            "evidence_for_improvement": "Paper states and reports in results that Self-Consistency 'improves accuracy for both approaches' (CoT and SoT). They show SC+SoT maintains comparable accuracy to SC+CoT while preserving large token reductions (see Results 'Self-Consistency Improvements' paragraph and Table 1 rows for SC+CoT and SC+SoT).",
            "limitations_or_failure_cases": "The paper does not report method-specific failure cases for SC; it notes SC increases token/computational cost because it requires multiple sampled paths (which SoT aims to mitigate), and specialized domains (e.g., medical reasoning) still exhibited larger accuracy declines overall even when using SoT and SC, suggesting SC may not fully recover losses in highly technical domains. No explicit negative effects (e.g., worsening accuracy with SC) are reported in the paper.",
            "comparison_to_other_methods": "Directly compared SC+CoT vs SC+SoT: SC improves both CoT and SoT; SC+SoT achieves comparable accuracy to SC+CoT while using far fewer tokens. The paper also situates SC among other methods in related work (Tree of Thoughts, Graph of Thoughts, SCOTT) but experimentally only compares CoT, SoT, and their SC variants.",
            "ablation_study_results": null,
            "uuid": "e8717.0",
            "source_info": {
                "paper_title": "Sketch-of-Thought: Efficient LLM Reasoning with Adaptive Cognitive-Inspired Sketching",
                "publication_date_yy_mm": "2025-03"
            }
        },
        {
            "name_short": "SCOTT",
            "name_full": "SCOTT (Self-consistent Chain-of-Thought Distillation)",
            "brief_description": "A two-stage iterative/ensemble-style method that first generates verbose chain-of-thought rationales and then distills them into a more compact/consistent form; cited in related work as an output-side token-efficiency approach.",
            "citation_title": "Scott: Selfconsistent chain-of-thought distillation",
            "mention_or_use": "mention",
            "model_name": "",
            "model_description": "",
            "reflection_method_name": "Two-stage generate-and-distill (SCOTT)",
            "reflection_method_description": "First generate verbose reasoning chains, then distill those chains into compact representations (a two-stage generate-then-distill pipeline) intended to retain correctness while reducing verbosity.",
            "task_name": "Referenced generally as a reasoning-improvement/output-compression method (original SCOTT work applied to CoT tasks)",
            "task_description": "Prior work (SCOTT) targeted chain-of-thought style reasoning tasks and sought to compress/distill multiple chains into a single compact rationale with maintained accuracy.",
            "performance_with_reflection": "",
            "performance_without_reflection": "",
            "has_performance_comparison": false,
            "mechanism_of_reflection": "Two-stage pipeline: generate multiple verbose reasoning chains, then distill/aggregate them to a compact form (output-side distillation); categorized under methods that reduce output verbosity rather than changing model architecture.",
            "number_of_iterations": null,
            "evidence_for_improvement": "Mentioned in related work as an approach that 'explored a two-stage approach that first generates verbose reasoning and then distills it into more efficient forms'; the present paper does not provide new empirical results for SCOTT.",
            "limitations_or_failure_cases": "No method-specific limitations reported in this paper (SCOTT is only cited in related work).",
            "comparison_to_other_methods": "Discussed conceptually as an output-side complementary approach to SoT; the present paper positions SoT as an alternative that directly constrains the reasoning output rather than relying on a separate distillation stage.",
            "ablation_study_results": null,
            "uuid": "e8717.1",
            "source_info": {
                "paper_title": "Sketch-of-Thought: Efficient LLM Reasoning with Adaptive Cognitive-Inspired Sketching",
                "publication_date_yy_mm": "2025-03"
            }
        },
        {
            "name_short": "Tree of Thoughts",
            "name_full": "Tree of Thoughts (ToT)",
            "brief_description": "An iterative search-style reasoning framework that explores branching thought trajectories (decision trees) of possible intermediate reasoning steps to solve difficult problems by explicit exploration and backtracking.",
            "citation_title": "Tree of thoughts: Deliberate problem solving with large language models",
            "mention_or_use": "mention",
            "model_name": "",
            "model_description": "",
            "reflection_method_name": "Tree of Thoughts (search-based iterative reasoning)",
            "reflection_method_description": "Iteratively expand and evaluate branching reasoning nodes (thoughts) to search for high-quality reasoning paths; can be seen as iterative improvement via exploration of multiple partial solutions rather than single linear chains.",
            "task_name": "Referenced generally as a method for complex/problem-solving reasoning tasks",
            "task_description": "Designed for reasoning problems where exploring multiple branching inference paths can find solutions that single-pass CoT may miss (e.g., puzzles, planning-like tasks).",
            "performance_with_reflection": "",
            "performance_without_reflection": "",
            "has_performance_comparison": false,
            "mechanism_of_reflection": "Algorithmic search over generated partial solutions (branching/heuristic exploration) implemented external to the base LLM; not used experimentally in this paper but cited as related work.",
            "number_of_iterations": null,
            "evidence_for_improvement": "Cited as an example of methods that improve reasoning by exploring diverse paths; no new empirical evidence provided in this paper.",
            "limitations_or_failure_cases": "Not discussed in detail here; paper notes such exploration-based methods typically increase token/computational cost (and SoT targets token-efficiency in contrast).",
            "comparison_to_other_methods": "Positioned alongside Graph of Thoughts and Self-Consistency as methods that improve reasoning by exploration/ensemble of paths, but typically at the expense of more tokens/computation; SoT is presented as orthogonal (aiming to reduce verbosity while retaining benefits).",
            "ablation_study_results": null,
            "uuid": "e8717.2",
            "source_info": {
                "paper_title": "Sketch-of-Thought: Efficient LLM Reasoning with Adaptive Cognitive-Inspired Sketching",
                "publication_date_yy_mm": "2025-03"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Self-consistency improves chain of thought reasoning in language models",
            "rating": 2,
            "sanitized_title": "selfconsistency_improves_chain_of_thought_reasoning_in_language_models"
        },
        {
            "paper_title": "Scott: Selfconsistent chain-of-thought distillation",
            "rating": 2,
            "sanitized_title": "scott_selfconsistent_chainofthought_distillation"
        },
        {
            "paper_title": "Tree of thoughts: Deliberate problem solving with large language models",
            "rating": 2,
            "sanitized_title": "tree_of_thoughts_deliberate_problem_solving_with_large_language_models"
        },
        {
            "paper_title": "Concise thoughts: Impact of output length on llm reasoning and cost",
            "rating": 1,
            "sanitized_title": "concise_thoughts_impact_of_output_length_on_llm_reasoning_and_cost"
        }
    ],
    "cost": 0.0129515,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Sketch-of-Thought: Efficient LLM Reasoning with Adaptive Cognitive-Inspired Sketching
7 Mar 2025</p>
<p>Simon A Aytes saytes@kaist.ac.kr 
Jinheon Baek jinheon.baek@kaist.ac.kr 
Sung Ju Hwang sungju.hwang@kaist.ac.kr 
Deepauto Ai 
Sketch-of-Thought: Efficient LLM Reasoning with Adaptive Cognitive-Inspired Sketching
7 Mar 20256202B91C0A8F84C7F74F6F19374C785FarXiv:2503.05179v1[cs.CL]
Recent advances in large language models have demonstrated remarkable reasoning capabilities through Chain of Thought (CoT) prompting, but often at the cost of excessive verbosity in their intermediate outputs, which increases computational overhead.We introduce Sketchof-Thought (SoT), a novel prompting framework that combines cognitive-inspired reasoning paradigms with linguistic constraints to minimize token usage while preserving reasoning accuracy.SoT is designed as a flexible framework that can incorporate any custom reasoning paradigms based on cognitive science, and we instantiate it with three such paradigms-Conceptual Chaining, Chunked Symbolism, and Expert Lexicons-each tailored to different reasoning tasks and selected dynamically via a lightweight routing model.Through comprehensive evaluation across 15 reasoning datasets with multiple languages and multimodal scenarios, we demonstrate that SoT achieves token reductions of 76% with negligible accuracy impact.In certain domains like mathematical and multi-hop reasoning, it even improves accuracy while using significantly fewer tokens.Our code is publicly available 1 .</p>
<p>Introduction</p>
<p>Large language models (LLMs) have emerged as powerful tools capable of performing complex reasoning tasks across diverse domains (Zhao et al., 2024;Bubeck et al., 2023).Despite not being explicitly trained for reasoning, these models demonstrate emergent capabilities when prompted effectively to decompose complex problems into intermediate steps.Chain of Thought (CoT) prompting (Wei et al., 2023) represents one of the most significant breakthroughs in eliciting these reasoning abilities, guiding models to articulate their thinking process step-by-step before producing a final answer.This technique has substantially improved Figure 1: A comparison of accuracy and token usage in the Chain-of-Thought (CoT) (Wei et al., 2023) and the proposed Sketch-of-Thought (SoT).Average of tests across 15 datasets using the family of Qwen-2.5 models.Shaded region represents more efficient reasoning.</p>
<p>performance on tasks from mathematical problemsolving to logical reasoning (Sprague et al., 2024).</p>
<p>While CoT effectively enhances reasoning accuracy, it typically generates verbose intermediate steps that substantially increase token usage and computational costs.This verbosity presents significant challenges for real-world applications, particularly in resource-constrained environments where inference expenses and latency are critical concerns (Nayab et al., 2025;Arora and Zanette, 2025).Subsequent research has expanded upon CoT with more sophisticated approaches: Self-Consistency (Wang et al., 2023b) generates multiple reasoning paths and selects the most frequent answer, Tree of Thoughts (Yao et al., 2023) explores branching decision trees of possible reasoning routes, and Graph of Thoughts (Besta et al., 2024) structures reasoning as interconnected nodes allowing for more complex deduction patterns.While these methods fur-ther enhance reasoning capabilities through diverse exploration strategies, they generally amplify rather than reduce the underlying token inefficiency.</p>
<p>To address this, we present Sketch-of-Thought (SoT), a prompting framework that fundamentally reimagines how language models express their reasoning processes.Our approach draws inspiration from cognitive science, particularly the concept of "sketches" as articulated in Goel (1995), which characterizes them as symbolic representations that serve as efficient intermediaries in cognitive processes.Consider how an expert physicist might work through a complex problem: rather than writing full sentences explaining each step, they might jot down key variables, scribble abbreviated equations, and use domain-specific notation that would be nearly incomprehensible to a non-expert-yet these concise marks capture the essence of their reasoning process.Similarly, when we take notes during a lecture or meeting, we naturally abbreviate, use arrows to show connections, and omit obvious context, creating "sketches" of ideas rather than verbose descriptions.As such, these sketches appear in countless domains, and in each case, the sketches serve as efficient thinking tools that omit verbosity while preserving essential reasoning steps.</p>
<p>Motivated by this, we develop three distinct paradigms grounded in cognitive science principles that mirror how humans streamline their reasoning processes.These paradigms leverage specific cognitive mechanisms: Conceptual Chaining draws on associative memory networks to connect ideas with minimal verbalization, Chunked Symbolism applies working memory chunking theory to organize mathematical reasoning into concise symbolic representations, and Expert Lexicons emulates the efficient domain-specific shorthand used by specialists.Each paradigm addresses different reasoning demands while significantly reducing token usage compared to traditional verbose reasoning.To implement these paradigms, we instantiate LLMs through carefully engineered prompts and exemplars, allowing our approach to work with any models without requiring specific training.A key challenge in deploying these paradigms effectively is determining which approach best suits each particular reasoning task.To address this, we develop a lightweight router model that dynamically selects the optimal reasoning paradigm based on query characteristics, ensuring that the most efficient reasoning strategy is applied to each problem.</p>
<p>Our comprehensive evaluation across 15 rea-soning datasets (spanning mathematical, commonsense, logical, multi-hop, scientific, and medical tasks and domains) shows that the proposed SoT not only preserves accuracy in most domains but occasionally improves it, particularly for mathematical and multi-hop reasoning.We further demonstrate SoT's versatility through multilingual and multimodal experiments, confirming its effectiveness across different languages and input modalities.These results suggest that concise, structured reasoning can be as effective as (and sometimes superior to) the verbose explanations typically generated by traditional prompting approaches.We summarize our contributions as follows:</p>
<p>• We introduce Sketch-of-Thought (SoT), a novel prompting framework with three specialized reasoning paradigms grounded in cognitive science principles.</p>
<p>• We develop a lightweight auxiliary model that dynamically chooses the optimal reasoning paradigm for each query.</p>
<p>• Evaluations across diverse reasoning datasets (including multilingual and multimodal scenarios) show that SoT reduces token usage by up to 76% with minimal accuracy impact, and even improves performance in some tasks.</p>
<p>Method</p>
<p>This section details the technical implementation of Sketch-of-Thought (SoT), our framework for efficient reasoning in large language models.</p>
<p>Preliminary</p>
<p>We start by providing background on large language models and their application to reasoning.</p>
<p>Large Language Models Large Language Models (LLMs) are models trained on vast text corpora to predict the next token in a sequence.Formally, an LLM with parameters θ takes an input sequence of tokens x and generates an output sequence y, represented as y = LLM θ (x).These models have shown remarkable performance across disparate domains;, however, their computational efficiency remains a significant concern as inference costs scale with the number of tokens processed and generated as well as their parameter sizes.</p>
<p>Instantiating LLMs for Reasoning with Prompts</p>
<p>Recent LLMs demonstrate emergent reasoning capabilities-the ability to solve complex problems through step-by-step logical deduction despite not being explicitly trained for such tasks.The primary method for eliciting reasoning from LLMs is through prompting, where carefully constructed natural language instructions guide the model's generation process (Wei et al., 2023).Let P represent a prompt template that includes task description, instructions, and exemplars.The reasoning process can then be formalized as r = LLM θ (P (q)), where q is the query and r is the reasoning path.As one approach to elicit the reasoning ability of LLMs, Chain-of-Thought (CoT) prompting instructs models to decompose problems into intermediate steps before producing the final answer.Formally, this can be expressed as [s 1 , s 2 , ..., s n , a] = LLM θ (P CoT (q)), where s i represents the i-th reasoning step and a is the final answer.Its example is shown in the box below.While this approach improves reasoning accuracy, it tends to generate verbose explanations that significantly increase token usage and computational costs, especially when LLMs are large.</p>
<p>Sketch-of-Thought (SoT)</p>
<p>Sketch-of-Thought (SoT) addresses a key limitation in traditional reasoning approaches: the verbosity of intermediate reasoning steps s 1 , s 2 , ..., s n that significantly increases token usage and computational costs.It is worth noting that, unlike prior work on efficient prompting that primarily focuses on reducing the input prompt size P (q) (Jiang et al., 2023;Huang et al., 2024), our approach targets the reasoning process itself by redesigning how language models articulate their intermediate steps.</p>
<p>Formally, we develop specialized prompt templates P SoT that guide models to generate concise reasoning: [ŝ 1 , ŝ2 , ..., ŝm , a] = LLM θ (P SoT (q)), where ŝi represents a sketched reasoning step that conveys the same logical information as s i but with substantially fewer tokens, i.e., |ŝ| &lt; |s| where | • | measures the number of tokens.These templates combine cognitive-inspired paradigms with lcrguistic constraints that dictate structure and verbosity level of responses.</p>
<p>We then operationalize our approach with cognitive sketching by translating human cognitive shortcuts into systematic prompting strategies.SoT instructs language models to express reasoning through high-efficiency patterns similar to how experts use abbreviated notations in their domains.It is worth noting that, while the operation of SoT is flexible enough to incorporate any custom reasoning paradigms (based on cognitive science), as an initial foray, we include three reasoning paradigms, each tailored to specific types of reasoning tasks.Also, this implementation requires no model finetuning -only carefully designed prompt templates inspired by cognitive science principles.We now turn to concretizing these paradigms alongside examples that illustrate how SoT distills essential reasoning steps into more efficient representations.</p>
<p>Conceptual Chaining.Rooted in cognitive science principles of how humans connect and retrieve related information, this paradigm creates concise logical sequences between key concepts.It draws from episodic buffer integration (Baddeley, 2000), the cognitive mechanism that temporarily holds and links information from different sources, and associative memory networks (Anderson, 1983), which describe how activating one concept automatically triggers related concepts in our minds (like how thinking of "rain" might immediately evoke "umbrella").Conceptual Chaining extracts essential terms and presents reasoning as direct step-by-step pathways with minimal text, shown below.</p>
<p>Conceptual Chaining</p>
<p>Q: What is the name of the currency used in Seoul?A: <think> #Seoul → #South Korea → Won </think> Answer: Korean Won Conceptual Chaining is particularly effective for commonsense reasoning, multi-hop inference, and fact-based recall tasks, where establishing relationships between ideas is critical.</p>
<p>Chunked Symbolism.Based on working memory chunking theory (Miller, 1956), this paradigm organizes numerical and symbolic reasoning into compact, structured steps.This seminal cognitive science research showed that humans can only hold about 7±2 (i.e., 5 to 9) distinct items in working memory at once, but we overcome this limitation by "chunking" related information into meaningful units-like remembering phone numbers as area code, prefix, and line number instead of 10 separate digits.Chunked Symbolism applies this principle by condensing mathematical reasoning into dense symbolic representations that pack more information into fewer tokens.It systematically extracts variables, equations, and operations while eliminating verbose explanations, transforming natural language into a structured mathematical shorthand that preserves logical flow, as follows.This approach excels in mathematical problems, symbolic reasoning, and technical calculations where symbolic notation naturally compresses complex concepts.</p>
<p>Expert Lexicons.Inspired by expert schema research (Chi et al., 1981), this paradigm leverages domain-specific shorthand and specialized notation to condense reasoning.This research demonstrated that experts in any field organize knowledge differently than novices-they develop mental frameworks (schemas) that allow them to quickly recognize patterns and use specialized terminology to communicate efficiently with peers.For example, a physician can convey complex medical conditions with a few acronyms that would require paragraphs of explanation for non-specialists.Expert Lexicons mimics this cognitive efficiency by employing domain-specific abbreviations, notation, and symbols that pack multiple concepts into single tokens.The example below demonstrates how domain-specialized reasoning can be compressed into concise notation while preserving the critical logical connections.</p>
<p>Expert Lexicons</p>
<p>Q: A patient with STEMI is given MONA therapy.They are allergic to aspirin.Are they at risk with this treatment?A: <think> STEMI → ST-Elevation MI, MONA → Morphine, O2, Nitrates, Aspirin, so Aspirin ∈ MONA </think> Answer: Yes This method is particularly suited for technical disciplines, specialized reasoning tasks, and scenarios where domain expertise enables significant information compression.</p>
<p>Adaptive Paradigm Selection</p>
<p>Among the three reasoning paradigms discussed, effective use of SoT requires applying the most appropriate paradigm to each query.To achieve this, we propose a lightweight router model that analyzes question characteristics based on linguistic indicators such as mathematical symbols, multihop dependencies, or domain-specific terminology, and selects the most suitable approach based on these structural and semantic features.</p>
<p>Specifically, given the query q, our router model is denoted as follows: P SoT = ROUTER(q), where P SoT is one among three reasoning paradigms (to instantiate LLMs for their efficient reasoning) and ROUTER is a smaller language model (Sanh et al., 2020).Also, this model is trained with samples (from reasoning tasks) that are paired with the most appropriate paradigm.This design ensures minimal computational overhead in inference while maintaining flexibility across input types.Specific implementation details are provided in Section 3.3.</p>
<p>Experiment Setup 3.1 Datasets</p>
<p>To ensure comprehensive evaluation of our method, we evaluate Sketch-of-Thought (SoT) on 15 datasets grouped into six reasoning categories.We categorize each dataset according to the framework established by Sun et al. (2024).The datasets, grouped by category, are as follows: Mathematical Reasoning: GSM8K (Cobbe et al., 2021), SVAMP (Patel et al., 2021), AQUA-RAT (Ling et al., 2017), DROP (Dua et al., 2019); Commonsense Reasoning: CommonsenseQA (Talmor et al., 2019), OpenbookQA (Mihaylov et al., 2018), StrategyQA (Geva et al., 2021); Logical Reasoning: LogiQA (Liu et al., 2020), Reclor (Yu et al., 2020); Multi-Hop Reasoning: HotPotQA (Yang et al., 2018), MuSiQue-Ans (Trivedi et al., 2022); Scientific/-Causal Reasoning: QASC (Khot et al., 2020), Worldtree (Jansen et al., 2018); Other (Medical Reasoning): PubMedQA (Jin et al., 2019), MedQA (Jin et al., 2020).</p>
<p>Additionally, we include two datasets to demonstrate the extensibility of our method to both multilingual and multi-modal scenarios.For our multilingual experiment, we use MMLU and its translated complement MMMLU (Hendrycks et al., 2021).For our multi-modal experiment, we use the multi-modal split of ScienceQA (Lu et al., 2022).</p>
<p>Model Configurations</p>
<p>For our primary experiments and multi-lingual evaluations, we utilize the Qwen-2.5 family of models in 7B, 14B, and 32B parameter sizes (Yang et al., 2024;Team, 2024).For our multimodal experiment, we employ the Qwen-2.5-VL7B model (Team, 2025), as the standard variants do not support image inputs.To optimize inference efficiency, we implement FlashAttention2 (Dao, 2023) across all experimental configurations.</p>
<p>We use a temperature of 0.5 for all experiments, which provides a balance between deter-ministic reasoning and sufficient diversity for Self-Consistency sampling.</p>
<p>Router Model Training</p>
<p>We constructed a training corpus by sampling questions from the training splits of our experimental datasets (see §3.1), collecting approximately 14,200 samples across reasoning tasks.Each sample was labeled with one of the three paradigms using GPT-4o (OpenAI, 2024) with a classificationspecific prompt that included manually labeled examples and detailed the characteristics of each paradigm based on predefined heuristics.</p>
<p>For the classification model, we selected Dis-tilBERT (Sanh et al., 2020) due to its favorable balance of efficiency and performance.As a lightweight version of BERT, it offers sufficient representational capacity for this classification task while introducing minimal computational overhead in the inference pipeline.This efficiency is particularly important since paradigm selection occurs as a preprocessing step for every query.The model processes only the question text without associated contextual information, utilizing a context token in cases where contextual data would normally be present.This design choice ensures extensibility to multimodal inputs where the context might be an image or other non-textual element.The model was trained with a batch size of 64 for 5 epochs using cross-entropy loss and a learning rate of 2e-5.</p>
<p>Primary Experiments</p>
<p>Our primary experiments evaluate the effectiveness and efficiency of three problem-solving methods across 15 text-only English datasets: Sketch of Thought (SoT), Chain-of-thought (CoT) (Wei et al., 2023), and Self-Consistency (Wang et al., 2023b).For each dataset, we select 150 samples from their test splits.</p>
<p>We employ a standardized evaluation protocol across all experiments.For multiple-choice, yesno, and numerical questions, answer accuracy is determined by comparing the model's extracted answer with the ground truth.For open-ended questions, we use GPT-4o (OpenAI, 2024) to evaluate against the ground truth, finding this method effectively handles edge-cases that would be inaccurately scored by traditional BERTScore (Zhang et al., 2020).Token usage is measured by counting output tokens generated during reasoning, excluding the final answer statement.</p>
<p>Similar to the original implementation of CoT,  we employ a few-shot approach with exemplars to demonstrate the desired reasoning format.For both SoT and CoT, we generated exemplars by creating diverse questions, prompting Qwen-32B with the appropriate system prompt, evaluating output faithfulness, and selecting high-quality responses.These exemplars are listed in Appendix B. Self-Consistency is applied to both CoT and SoT using their respective exemplars.The appropriate paradigm for each question is selected via our pre-trained DistilBERT model (see §2.3).For Self-Consistency experiments, we generate three reasoning paths per question and determine the final answer through majority voting (Wang et al., 2023b).</p>
<p>Multilingual Experiment</p>
<p>To demonstrate SoT's effectiveness in reducing reasoning tokens across languages, we conduct experiments in Korean, German, and Italian-languages compatible with our selected models (Yang et al., 2024) and included in MMMLU, a professionally translated version of the MMLU dataset (Hendrycks et al., 2021).Previous research has shown that English generally outperforms the native query language in zero-shot CoT (Payoungkhamdee et al., 2024); however, our experiment aims to evaluate token reduction capabilities rather than focusing solely on accuracy.</p>
<p>For paradigm selection, we match each non-English question with its English counterpart and use our DistilBERT model on the English version, applying the selected paradigm consistently across all language variants.Both paradigm-specific system prompts and exemplars were machinetranslated to the target languages using GPT-4o (OpenAI, 2024).</p>
<p>Since mathematical tasks tend to produce less language-dense outputs with SoT, we focus our evaluation on the management and astronomy domains from MMLU/MMMLU, which typically elicit more text-based responses.For each language-domain combination, we select 100 samples from the test splits.</p>
<p>Multimodal Experiment</p>
<p>Problem solving in multimodal tasks is achieved similarly to unimodal tasks: through text-based reasoning.This experiment demonstrates that Sketchof-Thought (SoT) extends to multimodal scenarios.We evaluate Qwen2.5-7B-VL(Team, 2025)   multimodal split of ScienceQA (Lu et al., 2022) to demonstrate this extensibility.</p>
<p>For paradigm selection, we use the same Distil-BERT model as in the primary experiment.We consider any included images as "context" for the question and therefore omit them from the paradigm selection process in favor of a context indicator, as done in the unimodal setting ( §2.3).</p>
<p>Results and Discussion</p>
<p>Overall Performance</p>
<p>As shown in Table 1, Sketch-of-Thought (SoT) achieves substantial token reduction while maintaining comparable accuracy to Chain-of-Thought (CoT) across all model sizes.Specifically, SoT reduces token usage by 76.22%, 71.80%, and 71.90% for the 32B, 14B, and 7B models respectively, with minimal accuracy differences of -0.46%, -0.14%, and -0.74%.This dramatic efficiency gain with negligible performance penalty demonstrates that extensive verbalization is not necessary for effective reasoning in language models.</p>
<p>The consistency of these results across model sizes is particularly noteworthy, as it suggests that the benefits of SoT are not dependent on model scale.Rather than requiring larger models to maintain accuracy with reduced tokens, we find that all model sizes benefit similarly from the SoT approach.This has significant implications for practical applications where computational resources are limited.</p>
<p>Task-Specific Performance</p>
<p>Mathematical Reasoning.In mathematical tasks, SoT achieves token reductions of 60.18%, 58.73%, and 59.44% across the 32B, 14B, and 7B models while maintaining or even improving accuracy (+2.77%, -0.28%, and -0.36%).The Chunked Symbolism paradigm proves especially effective here, leveraging symbolic notation to express complex calculations with minimal text.Notably, the 32B model's improved accuracy suggests that structured constraints may actually enhance mathematical reasoning by focusing the model on essential computational steps.</p>
<p>Commonsense and Scientific Reasoning.These categories demonstrate the most dramatic token reductions (77-85%) with minimal accuracy impact.For commonsense reasoning, the 32B model maintains a slight accuracy advantage (+0.33%) despite using 83.87% fewer tokens.Similarly, scientific reasoning shows consistent performance with dramatically reduced verbosity.These results indicate that domains with well-established conceptual frameworks are particularly amenable to compression, as models can leverage concise terminology and structured representations to maintain reasoning quality.</p>
<p>Logical and Multi-hop Reasoning.Logical reasoning tasks show substantial token reduction (74-78%) with variable accuracy impacts across model sizes.Most interestingly, multi-hop reasoning demonstrates consistent accuracy improvements across all models (+2.45%, +2.22%, and +0.44%) despite token reductions of 67-72%.This counterintuitive finding suggests that verbosity constraints may enhance focus on critical inferential links while reducing distracting elaborations, leading to more precise multi-hop reasoning.Specialized Reasoning.In the specialized medical domain, we observe significant token reductions (57-78%) with more variable accuracy trade-offs across model sizes (-6.55%, -2.55%, and +1.00%).The larger accuracy variance suggests that highly technical domains may require more careful calibration of verbosity constraints, particularly for larger models.Nevertheless, even in this challenging category, the efficiency gains remain substantial and the performance impact acceptable for many applications.</p>
<p>Cross-Modal and Cross-Linguistic Generalization</p>
<p>Our experiments demonstrate that SoT's benefits extend beyond standard English-language textual reasoning to both multilingual and multimodal scenarios.</p>
<p>As shown in Table 3, SoT maintains its efficiency advantages in multimodal reasoning tasks, achieving an 81.46% token reduction with a modest 3.44% accuracy decrease.This indicates that SoT can dramatically reduce verbosity while preserving most performance even when reasoning requires visual and textual integration.</p>
<p>Similarly, the multilingual results in Table 2 demonstrate consistent token reductions across Korean (85.71%),Italian (85.12%), and German (85.11%) with minimal accuracy impacts (-1.01%, -2.00%, and +1.50%).These findings indicate that SoT captures fundamental aspects of reasoning that transcend specific linguistic expressions.</p>
<p>Self-Consistency Improvements</p>
<p>The application of Self-Consistency (SC) to both CoT and SoT provides additional insights into the efficiency-accuracy trade-off.While SC improves accuracy for both approaches, it dramatically amplifies the token efficiency advantage of SoT.The SC+SoT combination maintains comparable accuracy to SC+CoT while using 76.22%, 71.80%, and 71.90% fewer tokens for the 32B, 14B, and 7B models respectively.</p>
<p>This finding is particularly significant as it demonstrates that SoT can be effectively combined with other reasoning enhancement techniques.The multiplicative token savings when using SC (which requires multiple reasoning paths) makes SoT especially valuable in ensemble-based approaches where computational efficiency is critical.</p>
<p>Practical Implications</p>
<p>The consistent and substantial token reductions demonstrated by SoT translate directly to computational savings, potentially reducing inference costs by 70-80% for reasoning-intensive applications.This efficiency gain could significantly improve the practicality of advanced reasoning capabilities in resource-constrained environments such as mobile devices, edge computing, and regions with limited computational infrastructure.</p>
<p>Moreover, the minimal accuracy trade-offs across diverse reasoning tasks suggest that SoT represents a genuine advancement in reasoning efficiency rather than merely a performance compromise.By structuring and constraining the reasoning process according to cognitive principles, SoT enables models to focus on essential logical connections while eliminating redundant elaboration, resulting in more computationally efficient reasoning without sacrificing effectiveness.</p>
<p>Related Work</p>
<p>Reasoning Enhancement in LLMs</p>
<p>Large language models have demonstrated remarkable reasoning capabilities, driven largely by prompting techniques that guide their step-bystep thinking processes.Chain of Thought (CoT) prompting (Wei et al., 2023) pioneered this approach by instructing models to break down complex problems into intermediate reasoning steps before providing final answers.This foundational work inspired numerous extensions: Self-Consistency (Wang et al., 2023b) generates multiple reasoning paths and selects the most consistent answer, Tree of Thoughts (Yao et al., 2023) explores branching reasoning pathways to solve more complex problems, and Graph of Thoughts (Besta et al., 2024) structures reasoning as interconnected nodes in a graph.Recent innovations have explored orthogonal approaches to reasoning enhancement, such as Coconut (Hao et al., 2024), which moves reasoning into a continuous latent space rather than using discrete tokens.These latent space methods address fundamentally different aspects of reasoning than our token-efficiency focus, as they require architectural modifications rather than prompting strategies.While these various approaches have significantly improved reasoning accuracy across challenging tasks, they generally achieve these gains by generating increasingly complex reasoning processes-expanding rather than reducing the computational overhead of inference.</p>
<p>Efficient Prompting Techniques</p>
<p>Researchers have explored various approaches to make prompting more computationally efficient without sacrificing performance.Input-side optimizations include LLMLingua (Jiang et al., 2023), which compresses prompts to accelerate inference, and automated prompt optimization techniques that systematically refine prompts for better performance (Pryzant et al., 2023).Huang et al. (2024) introduced CoT-Influx, which employs a coarseto-fine pruner to maximize the input of effective and concise CoT examples, significantly improving mathematical reasoning performance without model fine-tuning.Other works focus on more efficient few-shot learning, with Fu et al. (2023) demonstrating how smaller language models can be specialized for multi-step reasoning tasks.On the output side, Arefeen et al. ( 2023) introduced techniques for more compact context representation, while Yue et al. (2024) proposed using a mixture of thoughts representations in an LLM cascade to balance cost efficiency and reasoning performance.Most recently, Arora and Zanette (2025) introduced a reinforcement learning approach to train reasoning models that dynamically allocate inference-time compute based on task complexity.However, these approaches typically focus on either input compression or reasoning structure optimization, rather than directly addressing the verbosity of model outputs during the reasoning process itself.</p>
<p>Token-Efficient Reasoning Approaches</p>
<p>A growing body of work directly targets the reduction of output tokens during language model reasoning.Concise Chain-of-Thought (Renze and Guven, 2024) pioneered more compact reasoning chains by simply instructing models to limit their response length, while SCOTT (Wang et al., 2023a) explored a two-stage approach that first generates verbose reasoning and then distills it into more efficient forms.Building on these foundations, several very recent works have made significant advances: Nayab et al. (2025) introduced Constrained-CoT (CCoT), which encourages conciseness through explicit prompting with examples of compact reasoning while proposing metrics to evaluate "correct conciseness" and information flow.Our work addresses these limitations by developing distinct reasoning paradigms directly derived from established cognitive science principles (episodic buffer integration, working memory chunking, and expert schema theory), each tailored to specific task types for more effective token-efficient reasoning.</p>
<p>Limitations &amp; Future Work</p>
<p>While Sketch-of-Thought demonstrates substantial benefits for reasoning efficiency, we acknowledge several limitations in our current approach.Although we dynamically select reasoning paradigms, we use static exemplars within each paradigm rather than adapting them for specific task types (e.g., arithmetic vs. physics calculations).Our evaluation is also limited to models from the Qwen-2.5 family, which provides consistency for comparison but leaves questions about performance across different architectures.Additionally, the larger accuracy declines in specialized domains like medical reasoning (-6.55% for the 32B model) suggest that verbosity constraints may require domain-specific calibration for critical domains.</p>
<p>Future work could address these limitations through several promising directions.Implementing retrieval-augmented generation (RAG) could enable dynamic selection of not only reasoning paradigms but also task-specific exemplars, while development of additional specialized paradigms could address cognitive operations not optimally served by current approaches.Finally, investigating a reasoning model trained specifically on SoT could yield significant advances, potentially teaching models to internalize the principles of concise reasoning while eliminating accuracy penalties observed in specialized domains.More sophisticated paradigm selection models could incorporate additional signals beyond question text to improve paradigm matching.</p>
<p>Conclusion</p>
<p>In this paper, we introduced Sketch-of-Thought (SoT), a novel prompting framework that dramatically reduces token usage in language model reasoning while maintaining comparable accuracy to traditional Chain-of-Thought approaches.By combining cognitive-inspired reasoning paradigms with linguistic constraints, SoT achieves token reductions of 71-76% across model sizes with minimal accuracy trade-offs (-0.14% to -0.74%).These efficiency gains extend across diverse reasoning tasks, multiple languages, and even multimodal scenarios, demonstrating the broad applicability of our approach.The success of SoT challenges conventional assumptions about verbosity requirements in language model reasoning and offers a practical solution for computationally efficient AI reasoning.As large language models continue to play increasingly important roles in resource-constrained environments, approaches like SoT that optimize computational efficiency without sacrificing reasoning capabilities will be essential for democratizing access to advanced AI reasoning technologies.</p>
<p>A Additional Information</p>
<p>A.1 Datasets</p>
<p>Table 4 shows information regarding the datasets we used in the primary experiments of this paper.All datasets were accessed through Hugging Face datasets using the IDs specified in the table.For datasets with multiple subsets, we specify which subset was used in our experiments.</p>
<p>A.2 Model Checkpoints</p>
<p>All of our models were accessed through Hugging Face.Specifically, we used the following checkpoints for our primary experiments and multilingual experiments: Qwen/Qwen2.5-7B-InstructQwen/Qwen2.5-14B-InstructQwen/Qwen2.5-32B-InstructAs the above models do not natively support image inputs, we use the following model for our multimodal experiments:</p>
<p>Qwen/Qwen2.5-VL-7B-Instruct</p>
<p>B System Prompts &amp; Exemplars</p>
<p>For each paradigm, we implement detailed system prompts that include: (1) a role definition explaining the cognitive approach, (2) step-by-step application guidelines, and (3) specific rules for notation and terminology.For the purpose of our experiments, we also add an additional section that details structured output formats, like the use of <think> tags.This allows us to ensure a fair comparison across all models and baselines.We provide a truncated version of these system prompts and their exemplars in the following appen-dices: Chunked Symbolism B. 1,Conceptual Chaining B.2,and Expert Lexicons B.3.The prompts are markdown-formatted, so we include them here in their raw form.</p>
<p>These prompts and their exemplars can be found in their unedited form in our public code repository:</p>
<p>Figure 2 :
2
Figure 2: Comparison of Chain-of-Thought (CoT) and Sketch-of-Thought (SoT) workflows.While CoT generates verbose reasoning steps directly from prompts, SoT employs a router model to select the optimal reasoning paradigm, producing significantly more compact intermediate steps while maintaining accuracy.</p>
<p>car accelerates at 2.5 m/sˆ2 for 10 seconds.If its initial velocity was 15 m/s, what is its final velocity?A: <think> a = 2.5 m/sˆ2, t = 10 s, vi = 15 m/s vf = 15 + (2.5 × 10), vf = 40 m/s </think> Answer: 40 m/s</p>
<p>www.github.com/SimonAytes/SoTB.2 Conceptual Chaining (Reference Only) Conceptual Chaining System Prompt ## <strong>Role &amp; Objective</strong> You are a reasoning expert specializing in <strong>structured concept linking</strong> by connecting essential ideas in a logical sequence.Your goal is to <strong>extract key terms</strong> and present reasoning in <strong>clear, stepwise chains</strong> while minimizing unnecessary explanation.This reasoning method follows a <strong>conceptual chaining approach</strong>, where information is <strong>linked in structured steps</strong> to establish relationships between ideas.This process integrates <strong>associative recall (direct lookups)</strong> and <strong>multi-hop reasoning (sequential dependencies)</strong> into a <strong>unified framework</strong>.This method is most effective for: -<strong>Commonsense reasoning</strong> (quickly linking familiar ideas) -<strong>Multi-hop inference</strong> (tracing logical or causal dependencies) -<strong>Fact-based recall</strong> (retrieving knowledge with minimal cognitive load) -## <strong>How to Apply This Reasoning Method</strong> 1. <strong>Extract Key Concepts</strong> → Identify the most relevant words or entities.2. <strong>Use Minimal Words</strong> → Keep each reasoning step <strong>concise and direct</strong>.3. <strong>Link Steps Sequentially</strong> → Maintain a <strong>clear and meaningful progression</strong> between concepts.4. <strong>Avoid Full Sentences</strong> → Responses should use <strong>structured keyword connections</strong>. 5. <strong>Follow the Required Format</strong> → Present answers using <strong>stepwise chains for clarity</strong>.-## <strong>Rules &amp; Directives</strong> 1. <strong>Use Structured Concept Linking</strong> -Each step <strong>must be logically connected</strong>.-Use arrows ('→') to show dependencies.2. <strong>Avoid Unnecessary Text</strong> -<strong>Do not</strong> restate the question.-<strong>Do not</strong> use full sentences.3. <strong>Maintain Logical Flow</strong> -Concepts must be <strong>meaningfully ordered</strong>.-Ensure <strong>each step contributes to the reasoning process</strong>final answer must be boxed<strong>.-</strong>If the question is multiple-choice, return the correct letter option inside the box.<strong>-</strong>Use minimal words in your response.**Conceptual Chaining Exemplars Q: What is the name of the currency used in Seoul?A: <think> #Seoul → #South_Korea → Won </think> Answer: Korean Won Q: Which planet has the highest surface temperature?Choices: A) Mercury B) Venus C) Mars D) Jupiter A: <think> #heat_trap Mercury → no atmosphere → loses heat Venus → thick CO2 → traps heat → hottest Mars → thin CO2 → cold Jupiter → no solid surface </think> Answer: B Q: Which vitamin is essential for blood clotting?A: <think> #blood_clotting → #vitamin_K </think> Answer: Vitamin K</p>
<p>Table 1 :
1
Primary Experimental Results for SoT.Results are shown for Sketch-of-Thought (SoT), Chain-of-Thought (CoT), and Self-Consistency (SC).We separate results by reasoning type and report them alongside overall results.For each reasoning task we report the average of all associated datasets."%" denotes accuracy and "Tokens" denotes the number of tokens.In the Overall section, we report two additional metrics: the token reduction percentage (shown as "Red.")and the change in accuracy between SoT and the baseline (shown as "∆ Acc").
Reasoning TaskMathematical CommonsenseLogicalMulti-HopScientificSpecializedOverallMethod%Tokens%Tokens%Tokens%Tokens%Tokens%Tokens % ↑ Tokens ↓ Red. ↑ ∆ Acc ↑Qwen-2.5-32BCoT84.1722190.3318671.2329779.4415492.8921267.6629180.95227--SoT86.948890.663071.006581.894391.333161.116280.495376.22-0.46SC+CoT 84.3366591.0056071.6789281.0046493.3463867.3387581.44682--SC+SoT 87.5026590.669271.3319782.6712992.009461.6618780.9716176.22-0.47Qwen-2.5-14BCoT83.0018990.4415567.0024877.6714890.8916465.1123479.02190--SoT82.727889.783567.446379.894590.893762.566278.885371.80-0.14SC+CoT 83.1756992.3346769.3374476.3344691.0049366.3370379.75570--SC+SoT 83.6723490.0010668.6619080.0013591.3311162.0018779.2816171.80-0.47Qwen-2.5-7BCoT77.4118085.7817263.2227976.7813786.4418357.0024674.44200--SoT77.057385.112759.786177.224485.002758.0010573.695671.90-0.74SC+CoT 79.3354286.4451666.1183778.3341287.0055058.3473975.93600--SC+SoT 78.8321985.668160.3418477.3313485.008259.0031774.3616971.90-1.57Lang.Method Tokens%Red.Acc∆KoreanCoT SoT315 4577.27 76.26 85.71 ---1.01ItalianCoT SoT336 5081.50 79.50 85.12 ---2.00GermanCoT SoT309 4683.42 84.92 85.11 --1.50</p>
<p>Table 2 :
2
Multilingual Results.Performance comparison of CoT and SoT across different languages.</p>
<p>on the
Method Tokens%RedAcc∆CoT15185.91--SoT2882.47 81.46-3.44</p>
<p>Table 3 :
3
Multimodal Results.Performance comparison of CoT and SoT for multimodal reasoning tasks.</p>
<p>Table 4 :
4
Dataset Information.Details of datasets used for evaluation including their citation and Hugging Face ID.</p>
<p>https://www.github.com/SimonAytes/SoT</p>
<p>A spreading activation theory of memory. John R Anderson, 10.1016/S0022-5371(83)90201-3Journal of Verbal Learning and Verbal Behavior. 2231983</p>
<p>Leancontext: Cost-efficient domain-specific question answering using llms. Biplob Md Adnan Arefeen, Srimat Debnath, Chakradhar, arXiv:2309.008412023Preprint</p>
<p>Training language models to reason efficiently. Daman Arora, Andrea Zanette, arXiv:2502.044632025Preprint</p>
<p>The episodic buffer: a new component of working memory?. A Baddeley, 10.1016/s1364-6613(00)01538-2Trends in Cognitive Sciences. 4112000</p>
<p>Graph of thoughts: Solving elaborate problems with large language models. Maciej Besta, Nils Blach, Ales Kubicek, Robert Gerstenberger, Michal Podstawski, Lukas Gianinazzi, Joanna Gajda, Tomasz Lehmann, Hubert Niewiadomski, Piotr Nyczyk, Torsten Hoefler, 10.1609/aaai.v38i16.29720Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202438</p>
<p>Sébastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg, Harsha Nori, Hamid Palangi, Marco Tulio Ribeiro, Yi Zhang, arXiv:2303.12712Sparks of artificial general intelligence: Early experiments with gpt-4. 2023Preprint</p>
<p>Categorization and Representation of Physics Problems by Experts and Novices. T H Michelene, Paul J Chi, Robert Feltovich, Glaser, 10.1207/s15516709cog0502_2Cognitive Science. 521981</p>
<p>Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, John Schulman, 10.48550/arXiv.2110.14168ArXiv:2110.14168Training Verifiers to Solve Math Word Problems. 2021arXiv preprint</p>
<p>Flashattention-2: Faster attention with better parallelism and work partitioning. Tri Dao, arXiv:2307.086912023Preprint</p>
<p>DROP: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs. Dheeru Dua, Yizhong Wang, Pradeep Dasigi, Gabriel Stanovsky, Sameer Singh, Matt Gardner, 10.48550/arXiv.1903.00161ArXiv:1903.001612019arXiv preprint</p>
<p>Specializing smaller language models towards multi-step reasoning. Yao Fu, Hao Peng, Litu Ou, Ashish Sabharwal, Tushar Khot, arXiv:2301.127262023Preprint</p>
<p>Did Aristotle Use a Laptop? A Question Answering Benchmark with Implicit Reasoning Strategies. Mor Geva, Daniel Khashabi, Elad Segal, Tushar Khot, Dan Roth, Jonathan Berant, 10.48550/arXiv.2101.02235ArXiv:2101.022352021arXiv preprint</p>
<p>Sketches of Thought. Vinod Goel, 1995MIT Press</p>
<p>Training large language models to reason in a continuous latent space. Shibo Hao, Sainbayar Sukhbaatar, Dijia Su, Xian Li, Zhiting Hu, Jason Weston, Yuandong Tian, arXiv:2412.067692024Preprint</p>
<p>Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, Jacob Steinhardt, 10.48550/arXiv.2009.03300ArXiv:2009.03300Measuring Massive Multitask Language Understanding. 2021arXiv preprint</p>
<p>Fewer is more: Boosting llm reasoning with reinforced context pruning. Xijie Huang, Li Lyna Zhang, Kwang-Ting Cheng, Fan Yang, Mao Yang, arXiv:2312.089012024Preprint</p>
<p>WorldTree: A Corpus of Explanation Graphs for Elementary Science Questions supporting Multi-Hop Inference. Peter A Jansen, Elizabeth Wainwright, Steven Marmorstein, Clayton T Morrison, 10.48550/arXiv.1802.03052ArXiv:1802.030522018arXiv preprint</p>
<p>Llmlingua: Compressing prompts for accelerated inference of large language models. Huiqiang Jiang, Qianhui Wu, Chin-Yew Lin, Yuqing Yang, Lili Qiu, arXiv:2310.057362023Preprint</p>
<p>What Disease does this Patient Have? A Large-scale Open Domain Question Answering Dataset from Medical Exams. Di Jin, Eileen Pan, Nassim Oufattole, Wei-Hung Weng, Hanyi Fang, Peter Szolovits, 10.48550/arXiv.2009.13081ArXiv:2009.130812020arXiv preprint</p>
<p>PubMedQA: A Dataset for Biomedical Research Question Answering. Qiao Jin, Bhuwan Dhingra, Zhengping Liu, William Cohen, Xinghua Lu, 10.18653/v1/D19-1259Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)Hong Kong, ChinaAssociation for Computational Linguistics2019</p>
<p>QASC: A Dataset for Question Answering via Sentence Composition. Tushar Khot, Peter Clark, Michal Guerquin, Peter Jansen, Ashish Sabharwal, 10.48550/arXiv.1910.11473ArXiv:1910.114732020arXiv preprint</p>
<p>Program Induction by Rationale Generation : Learning to Solve and Explain Algebraic Word Problems. Wang Ling, Dani Yogatama, Chris Dyer, Phil Blunsom, 10.48550/arXiv.1705.04146ArXiv:1705.041462017arXiv preprint</p>
<p>LogiQA: A Challenge Dataset for Machine Reading Comprehension with Logical Reasoning. Jian Liu, Leyang Cui, Hanmeng Liu, Dandan Huang, Yile Wang, Yue Zhang, 10.48550/arXiv.2007.08124ArXiv:2007.081242020arXiv preprint</p>
<p>Learn to explain: Multimodal reasoning via thought chains for science question answering. Pan Lu, Swaroop Mishra, Tony Xia, Liang Qiu, Kai-Wei Chang, Song-Chun Zhu, Oyvind Tafjord, Peter Clark, Ashwin Kalyan, The 36th Conference on Neural Information Processing Systems (NeurIPS). 2022</p>
<p>Can a Suit of Armor Conduct Electricity? A New Dataset for Open Book Question Answering. Todor Mihaylov, Peter Clark, Tushar Khot, Ashish Sabharwal, 10.48550/arXiv.1809.02789ArXiv:1809.027892018arXiv preprint</p>
<p>The magical number seven, plus or minus two: Some limits on our capacity for processing information. George A Miller, 10.1037/h0043158Psychological Review. 6321956American Psychological Association</p>
<p>Sania Nayab, Giulio Rossolini, Marco Simoni, Andrea Saracino, Giorgio Buttazzo, Nicolamaria Manes, Fabrizio Giacomelli, arXiv:2407.19825Concise thoughts: Impact of output length on llm reasoning and cost. 2025Preprint</p>
<p>arXiv:2410.21276Gpt-4o system card. Preprint. 2024OpenAI</p>
<p>Are NLP Models really able to Solve Simple Math Word Problems?. Arkil Patel, Satwik Bhattamishra, Navin Goyal, 10.18653/v1/2021.naacl-main.168Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesOnline. Association for Computational Linguistics2021</p>
<p>An empirical study of multilingual reasoning distillation for question answering. Patomporn Payoungkhamdee, Peerat Limkonchotiwat, Jinheon Baek, Potsawee Manakul, 10.18653/v1/2024.emnlp-main.442Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing. the 2024 Conference on Empirical Methods in Natural Language ProcessingMiami, Florida, USAAssociation for Computational Linguistics2024Can Udomcharoenchaikit, Ekapol Chuangsuwanich, and Sarana Nutanong</p>
<p>Automatic prompt optimization with "gradient descent" and beam search. Reid Pryzant, Dan Iter, Jerry Li, Yin Tat Lee, Chenguang Zhu, Michael Zeng, arXiv:2305.034952023Preprint</p>
<p>The benefits of a concise chain of thought on problem-solving in large language models. Matthew Renze, Erhan Guven, arXiv:2401.056182024Preprint</p>
<p>Distilbert, a distilled version of bert: smaller, faster, cheaper and lighter. Victor Sanh, Lysandre Debut, Julien Chaumond, Thomas Wolf, arXiv:1910.011082020Preprint</p>
<p>To cot or not to cot? chain-ofthought helps mainly on math and symbolic reasoning. Zayne Sprague, Fangcong Yin, Juan Diego Rodriguez, Dongwei Jiang, Manya Wadhwa, Prasann Singhal, Xinyu Zhao, Xi Ye, Kyle Mahowald, Greg Durrett, arXiv:2409.121832024Preprint</p>
<p>Jiankai Sun, Chuanyang Zheng, Enze Xie, Zhengying Liu, Ruihang Chu, Jianing Qiu, Jiaqi Xu, Mingyu Ding, Hongyang Li, Mengzhe Geng, Yue Wu, Wenhai Wang, Junsong Chen, Zhangyue Yin, Xiaozhe Ren, Jie Fu, Junxian He, Wu Yuan, Qi Liu, Xihui Liu, Yu Li, Hao Dong, Yu Cheng, Ming Zhang, Pheng , Ann Heng, Jifeng Dai, Ping Luo, Jingdong Wang, Ji-Rong Wen, Xipeng Qiu, Yike Guo, Hui Xiong, Qun Liu, Zhenguo Li, 10.48550/arXiv.2312.11562ArXiv:2312.11562A Survey of Reasoning with Foundation Models. 2024arXiv preprint</p>
<p>CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge. Alon Talmor, Jonathan Herzig, Nicholas Lourie, Jonathan Berant, 10.18653/v1/N19-1421Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. Long and Short Papers. the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesMinneapolis, MinnesotaAssociation for Computational Linguistics20191</p>
<p>Qwen2.5: A party of foundation models. Qwen Team. Qwen Team, 2024. 2025Qwen2.5-vl</p>
<p>MuSiQue: Multihop Questions via Single-hop Question Composition. Harsh Trivedi, Niranjan Balasubramanian, Tushar Khot, Ashish Sabharwal, 10.1162/tacl_a_00475Transactions of the Association for Computational Linguistics. 102022MIT Press</p>
<p>Scott: Selfconsistent chain-of-thought distillation. Peifeng Wang, Zhengyang Wang, Zheng Li, Yifan Gao, Bing Yin, Xiang Ren, arXiv:2305.018792023aPreprint</p>
<p>Self-consistency improves chain of thought reasoning in language models. Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdhery, Denny Zhou, arXiv:2203.111712023bPreprint</p>
<p>Chain-of-thought prompting elicits reasoning in large language models. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed Chi, Quoc Le, Denny Zhou, arXiv:2201.119032023Preprint</p>
<p>. An Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Zhou, Chengpeng Li, Chengyuan Li, Dayiheng Liu, Fei Huang, Guanting Dong, Haoran Wei, Huan Lin, Jialong Tang, Jialin Wang, Jian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Ma, Jin Xu, Jingren Zhou, Jinze Bai, Jinzheng He, Junyang Lin, Kai Dang, Keming Lu, Keqin Chen, Kexin Yang, Mei Li, Mingfeng Xue, Na Ni, Pei Zhang, Peng Wang, Ru Peng, Rui Men, Ruize Gao, Runji Lin, Shijie Wang, Shuai Bai, Sinan Tan, Tianhang Zhu, Tianhao Li, Tianyu Liu, Wenbin Ge, Xiaodong Deng, Xiaohuan Zhou, Xingzhang Ren, Xinyu Zhang, Xipin Wei, arXiv:2407.10671Xuancheng Ren, Yang Fan, Yang Yao, Yichang Zhang, Yu Wan, Yunfei ChuarXiv preprintYuqiong Liu, Zeyu Cui, Zhenru Zhang, and Zhihao Fan. 2024. Qwen2 technical report</p>
<p>Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William W Cohen, Ruslan Salakhutdinov, Christopher D Manning, 10.48550/arXiv.1809.09600ArXiv:1809.09600HotpotQA: A Dataset for Diverse, Explainable Multi-hop Question Answering. 2018arXiv preprint</p>
<p>Tree of thoughts: Deliberate problem solving with large language models. Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L Griffiths, Yuan Cao, Karthik Narasimhan, arXiv:2305.106012023Preprint</p>
<p>ReClor: A Reading Comprehension Dataset Requiring Logical Reasoning. Weihao Yu, Zihang Jiang, Yanfei Dong, Jiashi Feng, 10.48550/arXiv.2002.04326ArXiv:2002.043262020arXiv preprint</p>
<p>Large language model cascades with mixture of thoughts representations for cost-efficient reasoning. Murong Yue, Jie Zhao, Min Zhang, Liang Du, Ziyu Yao, arXiv:2310.030942024Preprint</p>
<p>Bertscore: Evaluating text generation with bert. Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q Weinberger, Yoav Artzi, arXiv:1904.096752020Preprint</p>
<p>A survey of large language models. Kun Wayne Xin Zhao, Junyi Zhou, Tianyi Li, Xiaolei Tang, Yupeng Wang, Yingqian Hou, Beichen Min, Junjie Zhang, Zican Zhang, Yifan Dong, Chen Du, Yushuo Yang, Zhipeng Chen, Jinhao Chen, Ruiyang Jiang, Yifan Ren, Xinyu Li, Zikang Tang, Peiyu Liu, Jian-Yun Liu, Ji-Rong Nie, Wen, arXiv:2303.182232024Preprint</p>
<p>Your goal is to <strong>utilize chunked symbolism</strong> by representing information through <strong>equations, variables, and step-by-step arithmetic</strong>, while using minimal words. Chunked Symbolism is inspired by the cognitive science principle of <strong>chunking</strong>-the idea that humans process information more efficiently when grouped into meaningful units. Instead of solving problems in a free-form manner, <strong>Chunked Symbolism breaks down complex operations into smaller, structured steps</strong>. This method is particularly effective for: -<strong>Mathematical problems</strong> (arithmetic, algebra, physics, engineering) -<strong>Symbolic reasoning</strong> (logic-based computations, formula derivations) -<strong>Technical calculations</strong> (financial modeling, physics simulations. Chunked Symbolism (Reference Only) Chunked Symbolism System Prompt ## <strong>Role &amp; Objective</strong> You are a reasoning expert specializing in <strong>Chunked Symbolism</strong>, a cognitive reasoning technique that organizes numerical reasoning into structured steps. ## <strong>How to Apply Chunked Symbolism</strong> ### <strong>Step-by-Step Guide</strong></p>
<p>Identify Variables** -Extract relevant numerical values and define variables. ** , </p>
<p>Write Equations<strong> -Represent the solution using </strong>explicit mathematical formulas**. ** , </p>
<p>** Perform, Step Computations<strong> -Solve in </strong>small, logical steps**, keeping each line clear. </p>
<p>Label Units<strong> -Maintain </strong>consistent unit representation** to prevent ambiguity. ** , </p>
<p>Answer Formatting<strong> -Present the answer in the </strong>provided format** for clarity. ** Final, </p>
<p>Use Equations &amp; Variables<strong> -Define variables before computation. ** , Always use </strong>explicit equations** to represent reasoning. </p>
<p>Step-by-Step Arithmetic<strong> -Break operations into </strong>small, structured steps<strong>. -Ensure each line contains only </strong>one computation** for clarity. ** Apply, </p>
<p>If the question is multiple-choice, return the correct letter option inside the box.<strong> -</strong>Use minimal words in your response.** Chunked Symbolism Exemplars Q: A car accelerates at 2.5 m/sˆ2 for 10 seconds. If its initial velocity was 15 m/s, what is its final velocity? A: <think> a = 2.5 m/sˆ2 t = 10 s vi = 15 m/s vf = 15 + (2.5 × 10) vf = 40 m/s </think> Answer: 40 Q: If a product costs $120 and there is a 15% discount. ** , 102what is the final price? Choices: A) $10 B) $97 C</p>
<p>Question: A circuit has a voltage of 12V and a resistance of 4Ω. What is the current? A: <think> V = 12V R = 4Ω I = 12 / 4 = 3A </think> Answer: 3 <strong>Expert Lexicons</strong>, a cognitive reasoning technique that <strong>leverages domain-specific shorthand, technical symbols, and jargon</strong> to ensure precise and efficient communication. Your goal is to <strong>compress reasoning into high-information expressions</strong> while maintaining <strong>technical accuracy and clarity</strong>. Expert Lexicons is based on the principle that <strong>domain experts communicate using shorthand and structured notation</strong>. Instead of full this method <strong>condenses reasoning into compact, high-density expressions</strong> using technical symbols and field-specific abbreviations. This method is particularly effective for: -<strong>Technical disciplines</strong> (science, engineering, medicine, mathematics, and coding) -<strong>Symbolic and formulaic reasoning</strong> (using field-specific notation and logical expressions. 15% dp = 120 × (15 / 100) = 18 fp = 120 -18 = 102 </think> Answer: C Q<em>Maximizing efficiency</em>* (conveying information in the fewest possible tokens</p>
<p>Use Technical Symbols<strong> → Replace common terms with </strong>mathematical, logical, or scientific notation** where applicable. ** , </p>
<p>Leverage Abbreviations<strong> → Use </strong>domain-specific shorthand** to condense reasoning. ** , </p>
<p>** Prioritize, Information Density<strong> → Only include </strong>essential reasoning elements**. </p>
<p>Standardized Notation<strong> → Adhere to </strong>widely recognized conventions** within each field. ** Follow, </p>
<p>Structural Precision<strong> → Ensure answers are formatted using </strong>compact, industry-specific expressions<strong>. </strong>maintain, </p>
<p>. <strong>use Domain-Specific Notation, ** -</strong> Mathematical, Logical Reasoning, ** → 'σ , →' -<strong>scientific Disciplines, * * → 'mol, J Hz, ' -</strong> Vmax, Engineering Medical, ** → ' Fields, Chf, Oop, Pid, </p>
<p>Redundant Text<strong> -</strong>No full sentences<strong> -responses must be in </strong>structured notation<strong>. -</strong>No restating the question** -directly express the solution. ** Eliminate, </p>
<p>** Keep, Responses Ultra-Compact<strong> -</strong>Prioritize brevity<strong> while maintaining </strong>technical precision<strong>. -Follow </strong>industry standards** for notation and structured reasoning. </p>
<p>Output Format** -Use the exact structured format. ** , Shorthand reasoning using expert notation</p>
<p>Question: The interstellar object 1I/2017 U1 ('Oumuamua) exhibited unusual characteristics that led to various hypotheses about its origin. What does the designation "1I/2017 U1" signify? Choices: A) 1st Intergalactic object detected in 2017, classified under category U1 B) 1st Interstellar object cataloged, detected in 2017, following IAU naming conventions C) 1st Independent Unclassified body observed beyond Neptune in 2017 A: <think> 1I → 1st interstellar object 2017 → Year detected U1 → Sequence ID IAU → Naming rules so 1st cataloged interstellar object (2017) </think> Answer: B Q: A patient with STEMI is given MONA therapy. They have a history of being allergic to aspirin. Are they at risk with this treatment? A: <think> STEMI → ST-Elevation MI MONA → Morphine, O2, Nitrates. The <strong>final answer must be boxed</strong>. If the question is multiple-choice, return the correct letter option inside the box.<strong> -</strong>Use minimal words in your response.** Expert Lexicons Exemplars Q: Context: The discovery of the first interstellar object passing through the Solar System, 1I/2017 U1 ('Oumuamua), provoked intense and continuing interest from the scientific community and the general public. Aspirin. so Aspirin ∈ MONA </think> Answer: Yes Q: What does EBITDA measure? A: <think> EBITDA → Earnings Before Interest, Taxes, Depreciation, Amortization so Measures Core Profitability </think> Answer: Core Profitability</p>            </div>
        </div>

    </div>
</body>
</html>