<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-3364 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-3364</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-3364</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-77.html">extraction-schema-77</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models solving puzzle games that require spatial knowledge (such as Sudoku), including details about the models, the puzzles, the methods used, performance, and any analysis of how the models solve these tasks.</div>
                <p><strong>Paper ID:</strong> paper-64c48ac0cc2baa6d7b9b0ee52fa86e751272b48b</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/64c48ac0cc2baa6d7b9b0ee52fa86e751272b48b" target="_blank">Evaluating the Effectiveness of Large Language Models in Representing Textual Descriptions of Geometry and Spatial Relations</a></p>
                <p><strong>Paper Venue:</strong> International Conference Geographic Information Science</p>
                <p><strong>Paper TL;DR:</strong> The experiments demonstrate that while the LLMs-generated embeddings can preserve geometry types and capture some spatial relations, challenges remain in estimating numeric values and retrieving spatially related objects.</p>
                <p><strong>Paper Abstract:</strong> This research focuses on assessing the ability of large language models (LLMs) in representing geometries and their spatial relations. We utilize LLMs including GPT-2 and BERT to encode the well-known text (WKT) format of geometries and then feed their embeddings into classifiers and regressors to evaluate the effectiveness of the LLMs-generated embeddings for geometric attributes. The experiments demonstrate that while the LLMs-generated embeddings can preserve geometry types and capture some spatial relations (up to 73% accuracy), challenges remain in estimating numeric values and retrieving spatially related objects. This research highlights the need for improvement in terms of capturing the nuances and complexities of the underlying geospatial data and integrating domain knowledge to support various GeoAI applications using foundation models.</p>
                <p><strong>Cost:</strong> 0.004</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <p class="empty-note">No extracted data.</p>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>On the opportunities and challenges of foundation models for geospatial artificial intelligence <em>(Rating: 2)</em></li>
                <li>Mathematical capabilities of chatgpt <em>(Rating: 1)</em></li>
                <li>Language models are few-shot learners <em>(Rating: 1)</em></li>
                <li>Deep learning for symbolic mathematics <em>(Rating: 1)</em></li>
                <li>Locating place names from place descriptions <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-3364",
    "paper_id": "paper-64c48ac0cc2baa6d7b9b0ee52fa86e751272b48b",
    "extraction_schema_id": "extraction-schema-77",
    "extracted_data": [],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "On the opportunities and challenges of foundation models for geospatial artificial intelligence",
            "rating": 2
        },
        {
            "paper_title": "Mathematical capabilities of chatgpt",
            "rating": 1
        },
        {
            "paper_title": "Language models are few-shot learners",
            "rating": 1
        },
        {
            "paper_title": "Deep learning for symbolic mathematics",
            "rating": 1
        },
        {
            "paper_title": "Locating place names from place descriptions",
            "rating": 1
        }
    ],
    "cost": 0.00372975,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Evaluating the Effectiveness of Large Language Models in Representing Textual Descriptions of Geometry and Spatial Relations</h1>
<p>Yuhan Ji $\square$<br>GeoDS Lab, Department of Geography, University of Wisconsin-Madison, USA<br>Song Gao $\square$<br>GeoDS Lab, Department of Geography, University of Wisconsin-Madison, USA</p>
<h4>Abstract</h4>
<p>${ }^{1}$ This research focuses on assessing the ability of large language models (LLMs) in representing geometries and their spatial relations. We utilize LLMs including GPT-2 and BERT to encode the well-known text (WKT) format of geometries and then feed their embeddings into classifiers and regressors to evaluate the effectiveness of the LLMs-generated embeddings for geometric attributes. The experiments demonstrate that while the LLMs-generated embeddings can preserve geometry types and capture some spatial relations (up to $73 \%$ accuracy), challenges remain in estimating numeric values and retrieving spatially related objects. This research highlights the need for improvement in terms of capturing the nuances and complexities of the underlying geospatial data and integrating domain knowledge to support various GeoAI applications using foundation models.</p>
<p>2012 ACM Subject Classification Computing methodologies $\rightarrow$ Artificial intelligence
Keywords and phrases LLMs, foundation models, GeoAI
Acknowledgements The authors would like to acknowledge the support from the H.I. Romnes Fellowship, National Science Foundation (No. 2112606) and Arity.</p>
<h2>1 Introduction</h2>
<p>Deep learning methods have exhibited great performance to tackle many challenging tasks in geographical sciences [16, 9]. However, the models often depend on handcrafted features for specific downstream tasks, thus being hard to be generalized into different tasks. The emergence of representation learning largely mitigated the issue by decomposing the learning process into two steps (task-agnostic data representation and downstream task) [1]. Therefore, an effective location-based representation should preserve key spatial information (e.g., distance, direction, and spatial relations) and make classifiers or other predictors easy to extract useful knowledge [13]. In geospatial artificial intelligence (GeoAI) research, although the geospatial data are usually well-formatted and can be readily understood by GIS software, not all of them can be directly integrated into a deep learning model.</p>
<p>The success of ChatGPT has been a milestone that attracts the general public's attention to Large Language Models (LLMs). With tons of parameters trained on a large text corpus, LLMs have learned profound knowledge across many domains. Other well-known LLMs include the Bidirectional Encoder Representations from Transformers (BERT) [5], the Generative Pre-trained Transformer (GPT) series [14, 2], etc. Despite the differences in network architectures, these LLMs can achieve state-of-the-art performance on natural language processing (NLP) benchmarks. Consequently, researchers have begun the early exploration of integrating LLMs into GIS research, such as geospatial semantic tasks [12] and</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>automating spatial analysis workflows [11]. These studies have demonstrated the ability of LLMs to understand and reason about geospatial phenomena from a semantic perspective as learned from human discourse or formalized programming instructions. In contrast, accurate geometries and spatial relations in GIS are not necessarily expressed in natural languages. Therefore, it can be challenging for LLMs to reconstruct the physical world solely from the textual description of these building blocks, which is the motivation of this research.</p>
<p>In GIScience, spatial relations refer to the connection between spatial objects regarding their geometric properties [8], which play an important role in spatial query, reasoning and question-answering. Using natural language to describe spatial relations is essential for humans to perceive our surroundings and navigate through space. Attempts have been made to formalize the conversion between quantitative models and qualitative human discourse [4]. For topological spatial relations, the RCC-8 (region connection calculus [15]) and the Dimensionally Extended 9-intersection (DE-9IM) model [6] are widely used. Based on the DE-9IM model, five predicates are named by [3] for complex geometries, including crosses, disjoint, touches, overlaps, within. On top of them, the Open Geospatial Consortium (OGC) further added the predicates equals, contains, intersects for computation convenience. In addition, predicates can also be used to describe the distance or direction between a subject and an object. Fuzzy logic can also be adopted to convert precise metrics into narrative predicates such as near and far [18].</p>
<p>However, there remains a gap between the contextual semantics of predicates in everyday language and the abovementioned formalization procedures, yielding disagreement and vagueness in the understanding. It is yet to be determined whether the LLMs can fully capture how people describe spatial objects with predicates in natural language. If so, how we can leverage such knowledge to represent geospatial contexts with LLMs.</p>
<h1>2 Methodology</h1>
<h3>2.1 Workflow</h3>
<p>This research focuses on assessing the ability of LLMs in representing geometries and their spatial relations through a set of downstream tasks. Figure 1 illustrates the workflow we employed, which consists of three primary modules. The first module utilizes a GIS tool to extract the attributes, such as geometry type, centroid, and area, of individual geometries and their spatial relations, including predicates and distances between pairs of geometries. The second module applies LLMs to encode the well-known text (WKT) format of geometries, e.g., LINESTRING (30 10, 10 30, 40 40), which includes the geometry type and the ordered coordinates whereas the map projection is not considered in this work. Finally, the obtained embeddings from LLMs, along with the ground-truth attributes or spatial relations, are fed into classifiers or regressors to evaluate the effectiveness of the LLMs-based embeddings.</p>
<h3>2.2 Notation</h3>
<p>The notations used in this paper are listed in Table 1.</p>
<h3>2.3 Evaluation Tasks</h3>
<p>The downstream tasks are designed for deriving the geometric attributes or identifying spatial relations, as described in Table 2. The targets of Tasks 1-5 are straightforward, that is, to train a neural network classification/regression model that can best approximate the ground-truth values computed from a GIS tool. All of these tasks use a Multilayer Perceptron</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1 The evaluation workflow of this research</p>
<p>Table 1 Notations</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Notation</th>
<th style="text-align: left;">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">$g$</td>
<td style="text-align: left;">A geometry instance (e.g. Point, LineString, and Polygon) that can be <br> processed in GIS tools</td>
</tr>
<tr>
<td style="text-align: left;">WKT $(g)$</td>
<td style="text-align: left;">The WKT format of $g$</td>
</tr>
<tr>
<td style="text-align: left;">Enc $(g)$</td>
<td style="text-align: left;">The location encoding of $g$ using a LLM model to encode $W K T(g)$</td>
</tr>
<tr>
<td style="text-align: left;">Type $(g)$</td>
<td style="text-align: left;">The geometry type of $g$</td>
</tr>
<tr>
<td style="text-align: left;">Centroid $(g)$</td>
<td style="text-align: left;">The centroid of $g$</td>
</tr>
<tr>
<td style="text-align: left;">Area $(g)$</td>
<td style="text-align: left;">The area of $g$</td>
</tr>
<tr>
<td style="text-align: left;">rel</td>
<td style="text-align: left;">A predicate that can be used to represent the spatial relation, which is one <br> of {equals, disjoint, intersects, crosses, touches, contains, within, overlaps}, <br> as defined by OGC and implemented in GeoPandas.</td>
</tr>
<tr>
<td style="text-align: left;">Rel $\left(g_{i}, g_{j}\right)$</td>
<td style="text-align: left;">The spatial relation between the subject $g_{i}$ and the object $g_{j}$</td>
</tr>
<tr>
<td style="text-align: left;">Dist $\left(g_{i}, g_{j}\right)$</td>
<td style="text-align: left;">The minimum euclidean distance between two objects $g_{i}$ and $g_{j}$</td>
</tr>
<tr>
<td style="text-align: left;">$\left[\operatorname{Enc}\left(g_{i}\right) ; \operatorname{Enc}\left(g_{j}\right)\right]$</td>
<td style="text-align: left;">The concatenation of the embeddings of $g_{i}$ and $g_{j}$</td>
</tr>
<tr>
<td style="text-align: left;">$\operatorname{Enc}(\text { rel }, g)$</td>
<td style="text-align: left;">The embedding of the short phrase rel $+W K T(g)$. For example, "within</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">Polygon $((00,01,11,10,00)) "$</td>
</tr>
</tbody>
</table>
<p>(MLP) as the classifier or regressor. Task 6 aims to investigate whether a geometry $g_{i}$ can be predicted based on its neighbor $g_{j}$ and their spatial relation $\operatorname{Rel}\left(g_{i}, g_{j}\right)$. We employ the nearest neighbor retrieval approach to evaluate whether LLMs have learned the meaning of spatial predicates properly. During inference, given an object $g_{j}$ and a spatial relation rel, we retrieve the top-k nearest neighbors of $\operatorname{Enc}\left(\text { rel }, g_{j}\right)$ and examined whether they belong to the set of subjects $\left{g_{i} \mid \operatorname{Rel}\left(g_{i}, g_{j}\right)=\text { rel }\right}$. This approach assesses the ability of the LLMs to relate geographic objects through spatial predicates.</p>
<p>Table 2 Evaluation Tasks</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Task</th>
<th style="text-align: center;">Subtask</th>
<th style="text-align: center;">Model type</th>
<th style="text-align: center;">Input</th>
<th style="text-align: center;">Target</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Geometric attributes</td>
<td style="text-align: center;">T1: Geometry type</td>
<td style="text-align: center;">Classification</td>
<td style="text-align: center;">$\operatorname{Enc}(g)$</td>
<td style="text-align: center;">Type $(g)$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">T2: Area computation</td>
<td style="text-align: center;">Regression</td>
<td style="text-align: center;">$\operatorname{Enc}(g)$</td>
<td style="text-align: center;">Area $(g)$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">T3: Centroid derivation</td>
<td style="text-align: center;">Regression</td>
<td style="text-align: center;">$\operatorname{Enc}(g)$</td>
<td style="text-align: center;">Centroid $(g)$</td>
</tr>
<tr>
<td style="text-align: center;">Spatial relations</td>
<td style="text-align: center;">T4: Spatial predicate</td>
<td style="text-align: center;">Classification</td>
<td style="text-align: center;">$\left[\operatorname{Enc}\left(g_{i}\right) ; \operatorname{En}\left(g_{j}\right)\right]$</td>
<td style="text-align: center;">$\operatorname{Rel}\left(g_{i}, g_{j}\right)$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">T5: Distance measure</td>
<td style="text-align: center;">Regression</td>
<td style="text-align: center;">$\left[\operatorname{Enc}\left(g_{i}\right) ; \operatorname{En}\left(g_{j}\right)\right]$</td>
<td style="text-align: center;">$\operatorname{Dist}\left(g_{i}, g_{j}\right)$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">T6: Location prediction</td>
<td style="text-align: center;">Retrieval</td>
<td style="text-align: center;">$\operatorname{Enc}\left(\operatorname{rel}, g_{j}\right)$</td>
<td style="text-align: center;">$\left{g_{i} \mid \operatorname{Rel}\left(g_{i}, g_{j}\right)=\text { rel }\right}$</td>
</tr>
</tbody>
</table>
<h1>3 Experiments</h1>
<h3>3.1 Dataset and Preprocessing</h3>
<p>Since there is no available benchmark dataset, we constructed real-world multi-sourced geospatial datasets for our case study in Madison, Wisconsin, United States. We downloaded the OpenStreetMap road network data (including links and intersections) using OSMnx ${ }^{2}$, points of interest (POIs) categorized by SLIPO ${ }^{3}$, and Microsoft Building Footprints ${ }^{4}$. Our evaluation tasks focus on the spatial objects with Point, LineString, and Polygon geometry types and assessing their spatial relations, respectively. The datasets are created as follows.</p>
<p>1) For each geometry type, we randomly select 4,000 samples, including 2,000 road intersections and 2,000 POIs for Point data, 4,000 road links for LineString data, and 4,000 building footprints for Polygon data. In total 12,000 samples are used for performing the downstream tasks. The area and centroid of each polygon are also computed.
2) For the spatial predicate disjoint, we randomly generate pairs of geometries and check whether their spatial relation is disjoint. For other predicates, we identify spatially related objects using spatial join. Given each combination of subject/object geometry type and their spatial predicate, we keep 400 triplets (subject, predicate, object) for each category for the task of predicate prediction and distance measure. Then we compute the minimum distance between the subjects and the objects.
3) We further construct data for the task of location prediction. In addition to the subjects and objects that are spatially joined in step 2), we also relate neighboring disjoint geometries using a buffer radius of $0.003^{\circ}$. The predicate of "disjoint" is replaced by "disjoint but near". For each predicate except disjoint, we select 200 objects of each geometry type that are related to more than 5 subjects by the same predicate.</p>
<p>All the computations are performed by using the GeoPandas package in Python. We consider the predicates of crosses, disjoint (but near), touches, overlaps, within, equals, contains in this work but not intersects as it is the opposite of disjoint. The data for downstream tasks are further split into $80 \%$ training, $5 \%$ validation, and $15 \%$ test sets.</p>
<h3>3.2 Encoding</h3>
<p>In this work, we perform the evaluation tasks based on two LLMs: GPT-2 and BERT. Due to the computational and memory resources required to train and use the models, GPT-2 and BERT have a maximum input sequence length (i.e., 1024 and 512 tokens respectively). Therefore, a sliding window approach is employed to tackle the issue as the WKT of LineString and Polygon types can exceed the length limitation. The long input sequences are broken down into smaller segments of 512 tokens with an overlap of 256 tokens between adjacent segments. Each segment is processed by the LLMs separately. We then take the average of the token embeddings to generate the final embedding for the whole sequence of geometries.</p>
<h3>3.3 Training MLPs</h3>
<p>As we hypothesize that the learned embeddings from LLMs can be effectively utilized in downstream geometry-related tasks, we use a simple neural network architecture (i.e., MLP)</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>across all tasks. Specifically, the input layer of the MLP is the embedding layer generated from LLMs, followed by a dropout layer for regularization purposes. Following the dropout layer is a single hidden layer, which employs the Rectified Linear Unit (ReLU) activation function. Finally, the MLP is concluded with the output linear layer. The number of neurons in the output layer varies depending on the specific task.</p>
<p>To facilitate the training process, we apply a logarithmic function to the target values for the area computation and distance measure tasks. In the centroid derivation task, we use the min-max normalization for the target values. The loss function combines the Mean Squared Error (MSE) on both the transformed and original scales. However, for reporting the performance, we only use the original scale of the target values.</p>
<h1>3.4 Results</h1>
<p>As shown in Table 3, the performance of the downstream tasks based on the embeddings generated by GPT-2 and BERT are similar, which can be understood from the similarity in their subword tokenization and transformer-based architecture.</p>
<p>Table 3 LLMs Performance Comparison</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Tasks</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Metric</th>
<th style="text-align: center;">GPT-2</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">BERT</th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Validation</td>
<td style="text-align: center;">Test</td>
<td style="text-align: center;">Validation</td>
<td style="text-align: center;">Test</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">T1: Geometry type</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Accuracy(\%)</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">100</td>
</tr>
<tr>
<td style="text-align: center;">T2: Area computation</td>
<td style="text-align: center;">All geometries</td>
<td style="text-align: center;">MAPE(\%)</td>
<td style="text-align: center;">13124</td>
<td style="text-align: center;">11700</td>
<td style="text-align: center;">12251</td>
<td style="text-align: center;">10850</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Polygon only</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">45.1</td>
<td style="text-align: center;">44.1</td>
<td style="text-align: center;">40.7</td>
<td style="text-align: center;">41.9</td>
</tr>
<tr>
<td style="text-align: center;">T3: Centroid derivation</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">RMSE</td>
<td style="text-align: center;">0.037</td>
<td style="text-align: center;">0.037</td>
<td style="text-align: center;">0.029</td>
<td style="text-align: center;">0.029</td>
</tr>
<tr>
<td style="text-align: center;">T4: Spatial predicate</td>
<td style="text-align: center;">Without geometry type</td>
<td style="text-align: center;">Accuracy(\%)</td>
<td style="text-align: center;">62.6</td>
<td style="text-align: center;">65.7</td>
<td style="text-align: center;">63.8</td>
<td style="text-align: center;">68.7</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">With geometry type</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">73.7</td>
<td style="text-align: center;">71.0</td>
<td style="text-align: center;">73.1</td>
<td style="text-align: center;">72.3</td>
</tr>
<tr>
<td style="text-align: center;">T5: Distance measure</td>
<td style="text-align: center;">Disjoint only</td>
<td style="text-align: center;">RMSE</td>
<td style="text-align: center;">0.064</td>
<td style="text-align: center;">0.063</td>
<td style="text-align: center;">0.057</td>
<td style="text-align: center;">0.075</td>
</tr>
<tr>
<td style="text-align: center;">T6: Location prediction</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Precision@5</td>
<td style="text-align: center;">N/A</td>
<td style="text-align: center;">0.03</td>
<td style="text-align: center;">N/A</td>
<td style="text-align: center;">0.03</td>
</tr>
</tbody>
</table>
<p>For T1-T3, the assessment is conducted on individual geometries. The $100 \%$ accuracy achieved on both the validation and the test dataset of T1 is expected as the geometry type are words that often occur in text documents. Considering the unit of degree in longitude and latitude, significant errors (measured by Mean Absolute Percentage Error (MAPE) and Root Mean Square Error (RMSE)) are observed in area and centroid computations, and increasing or reducing the model complexity does not alleviate the issue, suggesting a potential loss of information when averaging the token embeddings or fragmentation of coordinates during tokenization. Training the regressor on all geometries for T2 does not successfully learn that Point and LineString have an area of 0 . Even when training the regressor on Polygon separately, the results remain unsatisfactory. In T3, the centroids computed from the highdimensional embeddings often fall outside the study area. T4-T6 evaluates the embeddings' ability to capture spatial relations. One interesting finding is that the spatial predicate can be better predicted when combined with the geometry type, with accuracy increased from $62 \% \sim 68 \%$ to $71 \% \sim 73 \%$. This can be attributed to the imbalanced spatial relations among different combinations of geometry types. However, the distance measure task T5 still faces challenges in accurately estimating numeric values even when restricted to the "disjoint" relation only. The poor performance on T6 shows that even though the LLMs can encode the spatial relations and geometries in a consistent way, generating embeddings using an average approach alone is insufficient to support spatial reasoning and conduct geometric manipulations directly. Therefore, a different design to enhance the function of localizing spatial objects from textual descriptions [17] can improve the applications of LLMs in GeoAI.</p>
<p>Overall, the results indicate that the LLMs-generated embeddings have encoded the geometry types and coordinates present in the WKT format of geometries. However, it should be noted that the performance of the embeddings does not consistently meet expectations across all evaluation tasks. While the LLMs-generated embeddings can preserve geometry types and capture some spatial relations, challenges remain in estimating numeric values and retrieving spatially related objects due to the loss of magnitude during tokenization [7]. Despite the possibility of ameliorating the issue by modifying notations or applying chain-of-thought prompting [10], this research highlights the need for improvement in terms of capturing the nuances and complexities of the underlying geospatial data and integrating domain knowledge to support various GeoAI applications using LLMs.</p>
<h1>References</h1>
<p>1 Y. Bengio, A. Courville, and P. Vincent. Representation learning: A review and new perspectives. IEEE transactions on pattern analysis and machine intelligence, 35(8):1798-1828, 2013.</p>
<p>2 T. B. Brown et al. Language models are few-shot learners, 2020.
3 E. Clementini and P. Di Felice. A model for representing topological relationships between complex geometric features in spatial databases. Information sciences, 90(1-4):121-136, 1996.
4 A. G. Cohn and S. M. Hazarika. Qualitative spatial representation and reasoning: An overview. Fundamenta informaticae, 46(1-2):1-29, 2001.
5 J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova. Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805, 2018.
6 M. J. Egenhofer. Reasoning about binary topological relations. In Proceedings of the 2nd Symposium on Advances in Spatial Databases: SSD'91 Zurich, Switzerland, August 28-30, pages 141-160. Springer, 1991.
7 S. Frieder, L. Pinchetti, R.-R. Griffiths, T. Salvatori, T. Lukasiewicz, P. C. Petersen, A. Chevalier, and J. Berner. Mathematical capabilities of chatgpt. arXiv preprint arXiv:2301.13867, 2023.</p>
<p>8 R. Guo. Spatial objects and spatial relationships. Geo-spatial Information Science, 1(1):38-42, 1998.</p>
<p>9 K. Janowicz, S. Gao, G. McKenzie, Y. Hu, and B. Bhaduri. Geoai: spatially explicit artificial intelligence techniques for geographic knowledge discovery and beyond. International Journal of Geographical Information Science, 34(4):625-636, 2020.
10 G. Lample and F. Charton. Deep learning for symbolic mathematics. arXiv preprint arXiv:1912.01412, 2019.
11 Z. Li and H. Ning. Autonomous gis: the next-generation ai-powered gis. arXiv preprint arXiv:2305.06453, 2023.
12 G. Mai, W. Huang, J. Sun, S. Song, D. Mishra, N. Liu, S. Gao, T. Liu, G. Cong, Y. Hu, et al. On the opportunities and challenges of foundation models for geospatial artificial intelligence. arXiv preprint arXiv:2304.06798, 2023.
13 G. Mai, K. Janowicz, Y. Hu, S. Gao, B. Yan, R. Zhu, L. Cai, and N. Lao. A review of location encoding for geoai: methods and applications. International Journal of Geographical Information Science, 36(4):639-673, 2022.
14 A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, I. Sutskever, et al. Language models are unsupervised multitask learners. OpenAI blog, 1(8):9, 2019.
15 D. A. Randell, Z. Cui, and A. G. Cohn. A spatial logic based on regions and connection. $K R$, $92: 165-176,1992$.
16 M. Reichstein, G. Camps-Valls, B. Stevens, M. Jung, J. Denzler, and N. Carvalhais. Deep learning and process understanding for data-driven earth system science. Nature, 566(7743):195204, 2019 .</p>
<p>17 M. Vasardani, S. Winter, and K.-F. Richter. Locating place names from place descriptions. International Journal of Geographical Information Science, 27(12):2509-2532, 2013.
18 Y. Wang, H. Peng, Y. Xiong, and H. Song. Spatial relationship recognition via heterogeneous representation: A review. Neurocomputing, 2023.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>2 http://osmnx.readthedocs.io/
3 http://slipo.eu/
4 http://www.microsoft.com/maps/building-footprints&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>