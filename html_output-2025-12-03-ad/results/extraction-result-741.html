<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-741 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-741</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-741</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-20.html">extraction-schema-20</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <p><strong>Paper ID:</strong> paper-257050688</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2302.10607v2.pdf" target="_blank">Differentiable Multi-Target Causal Bayesian Experimental Design</a></p>
                <p><strong>Paper Abstract:</strong> We introduce a gradient-based approach for the problem of Bayesian optimal experimental design to learn causal models in a batch setting -- a critical component for causal discovery from finite data where interventions can be costly or risky. Existing methods rely on greedy approximations to construct a batch of experiments while using black-box methods to optimize over a single target-state pair to intervene with. In this work, we completely dispose of the black-box optimization techniques and greedy heuristics and instead propose a conceptually simple end-to-end gradient-based optimization procedure to acquire a set of optimal intervention target-state pairs. Such a procedure enables parameterization of the design space to efficiently optimize over a batch of multi-target-state interventions, a setting which has hitherto not been explored due to its complexity. We demonstrate that our proposed method outperforms baselines and existing acquisition strategies in both single-target and multi-target settings across a number of synthetic datasets.</p>
                <p><strong>Cost:</strong> 0.019</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e741.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e741.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DiffCBED</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Differentiable Causal Bayesian Experimental Design</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A gradient-based, policy-parameterized framework that optimizes batches of intervention target-state pairs by maximizing expected information gain (mutual information) for causal discovery; it jointly optimizes discrete targets (via continuous relaxations) and continuous intervention states end-to-end.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Differentiable Causal Bayesian Experimental Design (DiffCBED)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>DiffCBED formulates batch experiment selection as maximizing the expected information gain (EIG) about SCM parameters. It uses differentiable estimators of the joint mutual information (Nested Monte Carlo (NMC) estimator) and a policy π_ϕ that parameterizes a joint distribution over discrete intervention targets and continuous states. Discrete targets are handled via continuous relaxations (Gumbel-Softmax for single-target, Binary Concrete for unconstrained multi-target, and reparameterizable subset relaxations for constrained multi-target) with straight-through gradient estimators; states are parameterized deterministically or with Gaussians. Design parameters are optimized with gradient ascent (Adam) on the estimated EIG, allowing simultaneous optimization of a batch of multi-target-state interventions.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Synthetic SCM environments and semi-synthetic DREAM/E. coli gene network simulator</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Virtual lab style simulation environments where SCMs (Gaussian ANMs or neural-network conditional distributions) generate observational and interventional data; supports batch (static) experimental design where a set of interventions is chosen and executed before posterior updates. Includes synthetic Erdős–Rényi graphs, high-dimensional synthetic graphs, and a semi-synthetic E. coli DREAM gene network simulator.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Active experimentation to disambiguate competing hypotheses by choosing interventions that maximize expected information gain; discrete-target relaxations permit efficient exploration of intervention choices; posterior-weighted likelihoods (when using NMC with posterior samples) implicitly downweight models inconsistent with past data.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Implicitly addresses spurious causal edges arising from non-identifiability and spurious correlations (e.g., edges supported only by observational correlations); measurement noise and irrelevant variables are present in simulation but not singled out by specialized modules.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Detection of spurious or poorly supported hypotheses is implicit via posterior likelihoods and EIG: models that poorly explain past data obtain low likelihoods; failure/mismatch of proposal/prior is detected via diagnostics such as effective sample size (ESS) of importance weights reaching 1.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>When posterior samples are available, DiffCBED uses likelihood reweighting of posterior samples inside the mutual information estimators; when using IWNMC, self-normalized importance weights ω_m ∝ p(h_{t−1} | θ_m) are used to downweight prior samples inconsistent with history.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Select interventions that maximize expected information gain (EIG) to produce interventional outcomes that distinguish between competing causal models; update posterior after running selected interventions and thereby refute spurious edges by lowering posterior mass on explanations incompatible with interventional data.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td>Policy-gradient-style optimization: parameterize a design policy over targets and states, sample candidate batches via continuous relaxations, estimate a differentiable EIG objective (NMC or IWNMC), and perform gradient ascent on policy parameters to concentrate probability mass on high-EIG interventions; repeats across acquisition batches with posterior updates (adaptive mode) or once (non-adaptive).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>On a 40-node constrained multi-target (q=5) experiment with a proposal distribution, diffCBED achieved E-SHD = 0.44 ± 0.21, F1 = 0.99 ± 0.00, i-MMD = 0.07 ± 0.01 (Table 2). Across other synthetic settings (d=50 single-target, d=20 multi-target) the method outperformed baselines (Random, SSGb, SoftCBED) in expected SHD, F1, and i-MMD.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td>Baselines: Random (E-SHD = 43.78 ± 46.67, F1 = 0.91 ± 0.08, i-MMD = 0.16 ± 0.07) and SSGb (E-SHD = 15.59 ± 29.66, F1 = 0.97 ± 0.05, i-MMD = 0.10 ± 0.06) on the same 40-node task; DiffCBED substantially improves over these baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Gradient-based, policy-parameterized experimental design that jointly optimizes targets and states can efficiently find high-EIG interventions and substantially reduce posterior structural error (E-SHD) and interventional distribution discrepancy (i-MMD) compared to random and prior multi-target baselines; the approach leverages discrete relaxations (Gumbel-Softmax/Binary Concrete/subset relaxations) and straight-through estimators to handle discrete target choices, and benefits from using posterior or informative proposal samples for high-dimensional problems.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e741.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e741.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>IWNMC</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Importance Weighted Nested Monte Carlo estimator</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An estimator introduced in this paper that computes an asymptotically exact mutual information estimate by sampling contrastive parameter samples from a proposal (e.g., the prior) and applying self-normalized importance sampling weights derived from the likelihood of past data to correct the outer expectation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Importance Weighted Nested Monte Carlo (IWNMC)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>IWNMC draws contrastive parameter samples θ_{1:L} from a proposal distribution (the prior or a proposal informed by observational data) and uses a leave-one-out, self-normalized importance-sampling scheme to approximate the outer expectation over the posterior. Each sample m contributes with weight ω_m ∝ p(h_{t−1} | θ_m) (normalized across samples), so the objective can be estimated and optimized without directly computing/estimating p(θ | h_{t−1}).</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Same synthetic SCM simulators and semi-synthetic DREAM/E. coli environment as the paper's DiffCBED experiments</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Batch experimental design in simulation where IWNMC is used to optimize intervention batches using only prior or proposal samples; supports non-adaptive single-batch acquisition when posterior estimation is not available.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Likelihood-based self-normalized importance weighting: samples (hypotheses) inconsistent with past data receive small ω_m and thus are downweighted in the mutual information estimate and subsequent design optimization; proposal distributions can be restricted to MEC or otherwise informed subsets to reduce sampling of spurious hypotheses.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Addresses spurious model hypotheses arising from unsupported graphs/parameters (models that spuriously explain observational correlations); does not explicitly model measurement selection bias or explicit nuisance/distractor variables beyond their effect on model likelihood.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Monitoring effective sample size (ESS) of importance weights; degeneracy (ESS ≈ 1) signals that the prior/proposal poorly matches posterior and that IWNMC will be unreliable.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Self-normalized importance sampling: ω_m = p(h_{t−1} | θ_m) / ∑_k p(h_{t−1} | θ_k) ; these ω_m multiply the log-ratio terms in the IWNMC objective, effectively downweighting models inconsistent with historical data.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>By optimizing designs under IWNMC and executing resulting interventions, interventional outcomes will update beliefs (via likelihood evaluations) and reduce weight on spurious hypotheses; but IWNMC itself is non-adaptive when used solely with prior samples (the paper notes designs from IWNMC with prior are non-adaptive).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td>Optimize the IWNMC objective computed from prior or proposal samples (possibly constrained to MEC support) to select a (non-adaptive) batch of interventions; when a proposal informed by observational data is used, IWNMC reuses proposal samples via likelihood weighting to craft designs without full posterior inference.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>On 5-variable experiments (unconstrained multi-target, B=2), optimizing with IWNMC from the prior outperformed a random policy in downstream causal recovery (faster recovery shown by DAG-Bootstrap+GIES downstream metrics). On a 40-variable constrained experiment, using an informed proposal (support on MEC) allowed IWNMC to outperform random and SSGb baselines substantially (see DiffCBED table comparisons where variants using IWNMC/proposals improved performance).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td>IWNMC run with only the raw prior struggled in higher dimensions; the authors report effective sample size degeneracy (ESS→1) for d≥10, indicating failure or unreliable EIG estimates; without an informative proposal or large L, performance degrades to near-random.</td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>IWNMC enables designing experiments without computing an explicit posterior by reweighting prior/proposal samples with likelihoods of historical data, which downweights implausible hypotheses; this can work well in low-dimensions or with informative proposals (e.g., MEC-restricted proposals), but in high dimensions it suffers from importance-sampling degeneracy (low ESS) unless L is very large or the proposal is well matched to the posterior.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e741.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e741.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>NMC</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Nested Monte Carlo estimator</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A nested Monte Carlo estimator for expected information gain that uses a sampled posterior parameter θ^0 and contrastive posterior samples θ^{1:L} to estimate mutual information via a contrastive likelihood ratio; used as a differentiable objective for design optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Nested Monte Carlo (NMC) estimator for EIG</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>NMC samples θ^0 ∼ p(θ | h_{t−1}) and contrastive samples θ^{1:L} ∼ p(θ | h_{t−1}) and computes the expected log ratio of p(y | θ^0, ξ) to the average p(y | θ^ℓ, ξ) across contrastive samples, producing an estimator of mutual information that converges as L→∞. When the design space is continuous, gradients of the NMC estimator with respect to ξ can be computed and used to optimize designs via gradient-based methods.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Synthetic SCM simulators (batch experimental design), same environments used for DiffCBED experiments</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Batch design setting where NMC is used in an adaptive loop: after executing acquisitions, the posterior p(θ | h) is (approximately) computed and then NMC is used to compute gradients to optimize the next batch of designs.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Implicitly can help resolve spurious observational correlations by selecting informative interventions (via EIG), but NMC itself is an estimator and does not include dedicated distractor-specific mechanisms.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Indirect: by choosing high-EIG experiments based on the posterior, NMC-based optimization promotes interventions that should generate data to rule out spurious causal hypotheses when posterior updating reduces their probability.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td>Adaptive BOED: compute/update approximate posterior p(θ | h_{t−1}), use NMC to estimate gradients of EIG with respect to designs, and perform gradient-based optimization (DiffCBED) to propose the next batch of experiments, then execute and update posterior.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>When paired with an approximate posterior (DAG-Bootstrap/GIES) and DiffCBED policy optimization, NMC-based design yields strong empirical performance across synthetic benchmarks (d up to 50 single-target, d=20 multi-target), outperforming baselines; specific numeric improvements reported for those experiments in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td>If posterior approximation is poor or infeasible, NMC cannot be applied effectively; this motivated the IWNMC alternative that avoids posterior estimation.</td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>NMC provides a differentiable EIG objective amenable to gradient-based optimization of designs, enabling adaptive experiment selection that can actively refute spurious causal hypotheses when coupled with posterior approximations; its accuracy depends on quality of posterior samples and number of inner contrastive samples L.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e741.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e741.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DAG-Bootstrap (GIES)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>DAG Bootstrap with GIES posterior sampling</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A bootstrap-based approximate posterior sampling method that applies the GIES causal discovery algorithm to bootstrap-resampled datasets (observational+interventional) to produce an ensemble of causal graphs used as approximate posterior samples over structures.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>DAG-Bootstrap (GIES-based posterior samples)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>The method bootstraps the dataset multiple times and runs a causal discovery algorithm adapted to interventional data (GIES) on each bootstrap to produce an ensemble of DAGs; each DAG is treated as a posterior sample and parameter MLEs are computed per graph (under linear Gaussian assumptions in the experiments). These samples are used as approximate p(θ | h) in NMC/EIG estimation and in design optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Synthetic and semi-synthetic SCM datasets used in experiments (observational + interventional data)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Non-interactive bootstrap-based posterior approximation pipeline: repeated resampling of collected data and offline causal discovery (GIES) to generate graph samples that approximate posterior uncertainty over structures; used as input for design estimators (NMC).</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Can implicitly reflect spurious edges via variability across bootstrap graphs; however, no explicit mechanism for identifying/detecting distractor variables is included beyond bootstrap variability.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Refutation of spurious edges occurs indirectly when interventional data is added to the dataset and subsequent bootstraps/GIES runs produce fewer graphs containing the spurious edge; no explicit targeted refutation procedure is built into DAG-Bootstrap itself.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>Used as the approximate posterior in the paper's NMC experiments; when combined with DiffCBED, resulted in improved experimental designs and downstream recovery metrics across multiple synthetic and semi-synthetic tasks (numerical performance reported in main results).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Bootstrap ensembles of GIES graphs provide a practical and widely-used approximate posterior for BOED in causal discovery, enabling NMC-based gradient optimization; however GIES is non-differentiable and needs conversion to tensors for gradient-based design procedures, and bootstrap variability will reflect but not explicitly correct for distractors.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e741.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e741.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MEC-proposal</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Proposal distribution restricted to Markov Equivalence Class (MEC) support</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A strategy to build an importance-sampling proposal distribution informed by observational data by restricting support to graphs within the Markov Equivalence Class of the observational distribution, improving importance-sampling efficiency for high-dimensional IWNMC.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>MEC-informed proposal distribution (for IWNMC)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Construct a proposal distribution by running an observational causal discovery procedure (e.g., DAG-Bootstrap/GIES) to identify graphs consistent with observational data (MEC) and sample candidate graphs/parameters from this restricted support; these samples then serve as the proposal for IWNMC, which weights them by p(h_{t−1} | θ) to estimate EIG without a full posterior.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>High-dimensional synthetic SCM experiments (e.g., d=40 constrained multi-target tasks)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Non-adaptive single-batch design where a proposal built from observational samples (800 samples in the paper's experiments) and bootstrap-discovered graphs is used to seed IWNMC optimization to produce an experimental batch.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Reduces sampling of implausible/spurious graph hypotheses by restricting proposal support to graphs in or near the MEC of observational data, thereby avoiding wasting importance-sampling mass on spurious models and improving robustness to spurious prior-supported hypotheses.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Targets spurious graph hypotheses and models that are not in observationally plausible MEC support (i.e., models that explain correlations only in ways incompatible with observational data).</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Implicit: by building proposal from observational bootstrap/GIES outputs, graphs not present in MEC are excluded; mismatch is detected by improved ESS and downstream performance.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Indirect: by pre-filtering proposal support to MEC graphs, IWNMC's importance weights become less extreme and spurious models receive little or no sampling mass (reduction in need for strong downweighting).</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Designs produced using MEC-informed proposal still execute interventions and update beliefs to refute remaining spurious hypotheses, but the proposal reduces the initial search space of spurious models.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td>Create an informed proposal from observational data, run IWNMC optimization using that proposal to select a high-EIG batch (non-adaptive single batch in experiments), execute interventions, and then (optionally) run posterior-based procedures for downstream evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>On a 40-variable constrained task (q=5, B=2), using a MEC-informed proposal with IWNMC allowed the method to outperform random and SSGb baselines and produce high-quality designs (see DiffCBED / Table 2 results where methods leveraging informative proposals achieve strong E-SHD/F1/i-MMD).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td>Using only the original prior as proposal led to importance-sampling degeneracy in higher dimensions (ESS→1) and poor design performance; MEC-proposal mitigates this.</td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Informative proposals built from observational data (e.g., restricting to MEC support) greatly improve the viability of importance-sampling-based design estimators (IWNMC) in higher-dimensional causal discovery tasks by avoiding extreme weight degeneracy and reducing the influence of spurious prior-supported hypotheses.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Near-optimal multi-perturbation experimental design for causal structure learning <em>(Rating: 2)</em></li>
                <li>Interventions, where and how? experimental design for causal models at scale <em>(Rating: 2)</em></li>
                <li>Variational bayesian optimal experimental design <em>(Rating: 2)</em></li>
                <li>Gradient-based stochastic optimization methods in bayesian experimental design <em>(Rating: 1)</em></li>
                <li>Abcd-strategy: Budgeted experimental design for targeted causal structure discovery <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-741",
    "paper_id": "paper-257050688",
    "extraction_schema_id": "extraction-schema-20",
    "extracted_data": [
        {
            "name_short": "DiffCBED",
            "name_full": "Differentiable Causal Bayesian Experimental Design",
            "brief_description": "A gradient-based, policy-parameterized framework that optimizes batches of intervention target-state pairs by maximizing expected information gain (mutual information) for causal discovery; it jointly optimizes discrete targets (via continuous relaxations) and continuous intervention states end-to-end.",
            "citation_title": "here",
            "mention_or_use": "use",
            "method_name": "Differentiable Causal Bayesian Experimental Design (DiffCBED)",
            "method_description": "DiffCBED formulates batch experiment selection as maximizing the expected information gain (EIG) about SCM parameters. It uses differentiable estimators of the joint mutual information (Nested Monte Carlo (NMC) estimator) and a policy π_ϕ that parameterizes a joint distribution over discrete intervention targets and continuous states. Discrete targets are handled via continuous relaxations (Gumbel-Softmax for single-target, Binary Concrete for unconstrained multi-target, and reparameterizable subset relaxations for constrained multi-target) with straight-through gradient estimators; states are parameterized deterministically or with Gaussians. Design parameters are optimized with gradient ascent (Adam) on the estimated EIG, allowing simultaneous optimization of a batch of multi-target-state interventions.",
            "environment_name": "Synthetic SCM environments and semi-synthetic DREAM/E. coli gene network simulator",
            "environment_description": "Virtual lab style simulation environments where SCMs (Gaussian ANMs or neural-network conditional distributions) generate observational and interventional data; supports batch (static) experimental design where a set of interventions is chosen and executed before posterior updates. Includes synthetic Erdős–Rényi graphs, high-dimensional synthetic graphs, and a semi-synthetic E. coli DREAM gene network simulator.",
            "handles_distractors": true,
            "distractor_handling_technique": "Active experimentation to disambiguate competing hypotheses by choosing interventions that maximize expected information gain; discrete-target relaxations permit efficient exploration of intervention choices; posterior-weighted likelihoods (when using NMC with posterior samples) implicitly downweight models inconsistent with past data.",
            "spurious_signal_types": "Implicitly addresses spurious causal edges arising from non-identifiability and spurious correlations (e.g., edges supported only by observational correlations); measurement noise and irrelevant variables are present in simulation but not singled out by specialized modules.",
            "detection_method": "Detection of spurious or poorly supported hypotheses is implicit via posterior likelihoods and EIG: models that poorly explain past data obtain low likelihoods; failure/mismatch of proposal/prior is detected via diagnostics such as effective sample size (ESS) of importance weights reaching 1.",
            "downweighting_method": "When posterior samples are available, DiffCBED uses likelihood reweighting of posterior samples inside the mutual information estimators; when using IWNMC, self-normalized importance weights ω_m ∝ p(h_{t−1} | θ_m) are used to downweight prior samples inconsistent with history.",
            "refutation_method": "Select interventions that maximize expected information gain (EIG) to produce interventional outcomes that distinguish between competing causal models; update posterior after running selected interventions and thereby refute spurious edges by lowering posterior mass on explanations incompatible with interventional data.",
            "uses_active_learning": true,
            "inquiry_strategy": "Policy-gradient-style optimization: parameterize a design policy over targets and states, sample candidate batches via continuous relaxations, estimate a differentiable EIG objective (NMC or IWNMC), and perform gradient ascent on policy parameters to concentrate probability mass on high-EIG interventions; repeats across acquisition batches with posterior updates (adaptive mode) or once (non-adaptive).",
            "performance_with_robustness": "On a 40-node constrained multi-target (q=5) experiment with a proposal distribution, diffCBED achieved E-SHD = 0.44 ± 0.21, F1 = 0.99 ± 0.00, i-MMD = 0.07 ± 0.01 (Table 2). Across other synthetic settings (d=50 single-target, d=20 multi-target) the method outperformed baselines (Random, SSGb, SoftCBED) in expected SHD, F1, and i-MMD.",
            "performance_without_robustness": "Baselines: Random (E-SHD = 43.78 ± 46.67, F1 = 0.91 ± 0.08, i-MMD = 0.16 ± 0.07) and SSGb (E-SHD = 15.59 ± 29.66, F1 = 0.97 ± 0.05, i-MMD = 0.10 ± 0.06) on the same 40-node task; DiffCBED substantially improves over these baselines.",
            "has_ablation_study": false,
            "number_of_distractors": null,
            "key_findings": "Gradient-based, policy-parameterized experimental design that jointly optimizes targets and states can efficiently find high-EIG interventions and substantially reduce posterior structural error (E-SHD) and interventional distribution discrepancy (i-MMD) compared to random and prior multi-target baselines; the approach leverages discrete relaxations (Gumbel-Softmax/Binary Concrete/subset relaxations) and straight-through estimators to handle discrete target choices, and benefits from using posterior or informative proposal samples for high-dimensional problems.",
            "uuid": "e741.0"
        },
        {
            "name_short": "IWNMC",
            "name_full": "Importance Weighted Nested Monte Carlo estimator",
            "brief_description": "An estimator introduced in this paper that computes an asymptotically exact mutual information estimate by sampling contrastive parameter samples from a proposal (e.g., the prior) and applying self-normalized importance sampling weights derived from the likelihood of past data to correct the outer expectation.",
            "citation_title": "here",
            "mention_or_use": "use",
            "method_name": "Importance Weighted Nested Monte Carlo (IWNMC)",
            "method_description": "IWNMC draws contrastive parameter samples θ_{1:L} from a proposal distribution (the prior or a proposal informed by observational data) and uses a leave-one-out, self-normalized importance-sampling scheme to approximate the outer expectation over the posterior. Each sample m contributes with weight ω_m ∝ p(h_{t−1} | θ_m) (normalized across samples), so the objective can be estimated and optimized without directly computing/estimating p(θ | h_{t−1}).",
            "environment_name": "Same synthetic SCM simulators and semi-synthetic DREAM/E. coli environment as the paper's DiffCBED experiments",
            "environment_description": "Batch experimental design in simulation where IWNMC is used to optimize intervention batches using only prior or proposal samples; supports non-adaptive single-batch acquisition when posterior estimation is not available.",
            "handles_distractors": true,
            "distractor_handling_technique": "Likelihood-based self-normalized importance weighting: samples (hypotheses) inconsistent with past data receive small ω_m and thus are downweighted in the mutual information estimate and subsequent design optimization; proposal distributions can be restricted to MEC or otherwise informed subsets to reduce sampling of spurious hypotheses.",
            "spurious_signal_types": "Addresses spurious model hypotheses arising from unsupported graphs/parameters (models that spuriously explain observational correlations); does not explicitly model measurement selection bias or explicit nuisance/distractor variables beyond their effect on model likelihood.",
            "detection_method": "Monitoring effective sample size (ESS) of importance weights; degeneracy (ESS ≈ 1) signals that the prior/proposal poorly matches posterior and that IWNMC will be unreliable.",
            "downweighting_method": "Self-normalized importance sampling: ω_m = p(h_{t−1} | θ_m) / ∑_k p(h_{t−1} | θ_k) ; these ω_m multiply the log-ratio terms in the IWNMC objective, effectively downweighting models inconsistent with historical data.",
            "refutation_method": "By optimizing designs under IWNMC and executing resulting interventions, interventional outcomes will update beliefs (via likelihood evaluations) and reduce weight on spurious hypotheses; but IWNMC itself is non-adaptive when used solely with prior samples (the paper notes designs from IWNMC with prior are non-adaptive).",
            "uses_active_learning": false,
            "inquiry_strategy": "Optimize the IWNMC objective computed from prior or proposal samples (possibly constrained to MEC support) to select a (non-adaptive) batch of interventions; when a proposal informed by observational data is used, IWNMC reuses proposal samples via likelihood weighting to craft designs without full posterior inference.",
            "performance_with_robustness": "On 5-variable experiments (unconstrained multi-target, B=2), optimizing with IWNMC from the prior outperformed a random policy in downstream causal recovery (faster recovery shown by DAG-Bootstrap+GIES downstream metrics). On a 40-variable constrained experiment, using an informed proposal (support on MEC) allowed IWNMC to outperform random and SSGb baselines substantially (see DiffCBED table comparisons where variants using IWNMC/proposals improved performance).",
            "performance_without_robustness": "IWNMC run with only the raw prior struggled in higher dimensions; the authors report effective sample size degeneracy (ESS→1) for d≥10, indicating failure or unreliable EIG estimates; without an informative proposal or large L, performance degrades to near-random.",
            "has_ablation_study": false,
            "number_of_distractors": null,
            "key_findings": "IWNMC enables designing experiments without computing an explicit posterior by reweighting prior/proposal samples with likelihoods of historical data, which downweights implausible hypotheses; this can work well in low-dimensions or with informative proposals (e.g., MEC-restricted proposals), but in high dimensions it suffers from importance-sampling degeneracy (low ESS) unless L is very large or the proposal is well matched to the posterior.",
            "uuid": "e741.1"
        },
        {
            "name_short": "NMC",
            "name_full": "Nested Monte Carlo estimator",
            "brief_description": "A nested Monte Carlo estimator for expected information gain that uses a sampled posterior parameter θ^0 and contrastive posterior samples θ^{1:L} to estimate mutual information via a contrastive likelihood ratio; used as a differentiable objective for design optimization.",
            "citation_title": "",
            "mention_or_use": "use",
            "method_name": "Nested Monte Carlo (NMC) estimator for EIG",
            "method_description": "NMC samples θ^0 ∼ p(θ | h_{t−1}) and contrastive samples θ^{1:L} ∼ p(θ | h_{t−1}) and computes the expected log ratio of p(y | θ^0, ξ) to the average p(y | θ^ℓ, ξ) across contrastive samples, producing an estimator of mutual information that converges as L→∞. When the design space is continuous, gradients of the NMC estimator with respect to ξ can be computed and used to optimize designs via gradient-based methods.",
            "environment_name": "Synthetic SCM simulators (batch experimental design), same environments used for DiffCBED experiments",
            "environment_description": "Batch design setting where NMC is used in an adaptive loop: after executing acquisitions, the posterior p(θ | h) is (approximately) computed and then NMC is used to compute gradients to optimize the next batch of designs.",
            "handles_distractors": false,
            "distractor_handling_technique": null,
            "spurious_signal_types": "Implicitly can help resolve spurious observational correlations by selecting informative interventions (via EIG), but NMC itself is an estimator and does not include dedicated distractor-specific mechanisms.",
            "detection_method": null,
            "downweighting_method": null,
            "refutation_method": "Indirect: by choosing high-EIG experiments based on the posterior, NMC-based optimization promotes interventions that should generate data to rule out spurious causal hypotheses when posterior updating reduces their probability.",
            "uses_active_learning": true,
            "inquiry_strategy": "Adaptive BOED: compute/update approximate posterior p(θ | h_{t−1}), use NMC to estimate gradients of EIG with respect to designs, and perform gradient-based optimization (DiffCBED) to propose the next batch of experiments, then execute and update posterior.",
            "performance_with_robustness": "When paired with an approximate posterior (DAG-Bootstrap/GIES) and DiffCBED policy optimization, NMC-based design yields strong empirical performance across synthetic benchmarks (d up to 50 single-target, d=20 multi-target), outperforming baselines; specific numeric improvements reported for those experiments in the paper.",
            "performance_without_robustness": "If posterior approximation is poor or infeasible, NMC cannot be applied effectively; this motivated the IWNMC alternative that avoids posterior estimation.",
            "has_ablation_study": false,
            "number_of_distractors": null,
            "key_findings": "NMC provides a differentiable EIG objective amenable to gradient-based optimization of designs, enabling adaptive experiment selection that can actively refute spurious causal hypotheses when coupled with posterior approximations; its accuracy depends on quality of posterior samples and number of inner contrastive samples L.",
            "uuid": "e741.2"
        },
        {
            "name_short": "DAG-Bootstrap (GIES)",
            "name_full": "DAG Bootstrap with GIES posterior sampling",
            "brief_description": "A bootstrap-based approximate posterior sampling method that applies the GIES causal discovery algorithm to bootstrap-resampled datasets (observational+interventional) to produce an ensemble of causal graphs used as approximate posterior samples over structures.",
            "citation_title": "",
            "mention_or_use": "use",
            "method_name": "DAG-Bootstrap (GIES-based posterior samples)",
            "method_description": "The method bootstraps the dataset multiple times and runs a causal discovery algorithm adapted to interventional data (GIES) on each bootstrap to produce an ensemble of DAGs; each DAG is treated as a posterior sample and parameter MLEs are computed per graph (under linear Gaussian assumptions in the experiments). These samples are used as approximate p(θ | h) in NMC/EIG estimation and in design optimization.",
            "environment_name": "Synthetic and semi-synthetic SCM datasets used in experiments (observational + interventional data)",
            "environment_description": "Non-interactive bootstrap-based posterior approximation pipeline: repeated resampling of collected data and offline causal discovery (GIES) to generate graph samples that approximate posterior uncertainty over structures; used as input for design estimators (NMC).",
            "handles_distractors": false,
            "distractor_handling_technique": null,
            "spurious_signal_types": "Can implicitly reflect spurious edges via variability across bootstrap graphs; however, no explicit mechanism for identifying/detecting distractor variables is included beyond bootstrap variability.",
            "detection_method": null,
            "downweighting_method": null,
            "refutation_method": "Refutation of spurious edges occurs indirectly when interventional data is added to the dataset and subsequent bootstraps/GIES runs produce fewer graphs containing the spurious edge; no explicit targeted refutation procedure is built into DAG-Bootstrap itself.",
            "uses_active_learning": null,
            "inquiry_strategy": null,
            "performance_with_robustness": "Used as the approximate posterior in the paper's NMC experiments; when combined with DiffCBED, resulted in improved experimental designs and downstream recovery metrics across multiple synthetic and semi-synthetic tasks (numerical performance reported in main results).",
            "performance_without_robustness": null,
            "has_ablation_study": false,
            "number_of_distractors": null,
            "key_findings": "Bootstrap ensembles of GIES graphs provide a practical and widely-used approximate posterior for BOED in causal discovery, enabling NMC-based gradient optimization; however GIES is non-differentiable and needs conversion to tensors for gradient-based design procedures, and bootstrap variability will reflect but not explicitly correct for distractors.",
            "uuid": "e741.3"
        },
        {
            "name_short": "MEC-proposal",
            "name_full": "Proposal distribution restricted to Markov Equivalence Class (MEC) support",
            "brief_description": "A strategy to build an importance-sampling proposal distribution informed by observational data by restricting support to graphs within the Markov Equivalence Class of the observational distribution, improving importance-sampling efficiency for high-dimensional IWNMC.",
            "citation_title": "",
            "mention_or_use": "use",
            "method_name": "MEC-informed proposal distribution (for IWNMC)",
            "method_description": "Construct a proposal distribution by running an observational causal discovery procedure (e.g., DAG-Bootstrap/GIES) to identify graphs consistent with observational data (MEC) and sample candidate graphs/parameters from this restricted support; these samples then serve as the proposal for IWNMC, which weights them by p(h_{t−1} | θ) to estimate EIG without a full posterior.",
            "environment_name": "High-dimensional synthetic SCM experiments (e.g., d=40 constrained multi-target tasks)",
            "environment_description": "Non-adaptive single-batch design where a proposal built from observational samples (800 samples in the paper's experiments) and bootstrap-discovered graphs is used to seed IWNMC optimization to produce an experimental batch.",
            "handles_distractors": true,
            "distractor_handling_technique": "Reduces sampling of implausible/spurious graph hypotheses by restricting proposal support to graphs in or near the MEC of observational data, thereby avoiding wasting importance-sampling mass on spurious models and improving robustness to spurious prior-supported hypotheses.",
            "spurious_signal_types": "Targets spurious graph hypotheses and models that are not in observationally plausible MEC support (i.e., models that explain correlations only in ways incompatible with observational data).",
            "detection_method": "Implicit: by building proposal from observational bootstrap/GIES outputs, graphs not present in MEC are excluded; mismatch is detected by improved ESS and downstream performance.",
            "downweighting_method": "Indirect: by pre-filtering proposal support to MEC graphs, IWNMC's importance weights become less extreme and spurious models receive little or no sampling mass (reduction in need for strong downweighting).",
            "refutation_method": "Designs produced using MEC-informed proposal still execute interventions and update beliefs to refute remaining spurious hypotheses, but the proposal reduces the initial search space of spurious models.",
            "uses_active_learning": false,
            "inquiry_strategy": "Create an informed proposal from observational data, run IWNMC optimization using that proposal to select a high-EIG batch (non-adaptive single batch in experiments), execute interventions, and then (optionally) run posterior-based procedures for downstream evaluation.",
            "performance_with_robustness": "On a 40-variable constrained task (q=5, B=2), using a MEC-informed proposal with IWNMC allowed the method to outperform random and SSGb baselines and produce high-quality designs (see DiffCBED / Table 2 results where methods leveraging informative proposals achieve strong E-SHD/F1/i-MMD).",
            "performance_without_robustness": "Using only the original prior as proposal led to importance-sampling degeneracy in higher dimensions (ESS→1) and poor design performance; MEC-proposal mitigates this.",
            "has_ablation_study": false,
            "number_of_distractors": null,
            "key_findings": "Informative proposals built from observational data (e.g., restricting to MEC support) greatly improve the viability of importance-sampling-based design estimators (IWNMC) in higher-dimensional causal discovery tasks by avoiding extreme weight degeneracy and reducing the influence of spurious prior-supported hypotheses.",
            "uuid": "e741.4"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Near-optimal multi-perturbation experimental design for causal structure learning",
            "rating": 2,
            "sanitized_title": "nearoptimal_multiperturbation_experimental_design_for_causal_structure_learning"
        },
        {
            "paper_title": "Interventions, where and how? experimental design for causal models at scale",
            "rating": 2,
            "sanitized_title": "interventions_where_and_how_experimental_design_for_causal_models_at_scale"
        },
        {
            "paper_title": "Variational bayesian optimal experimental design",
            "rating": 2,
            "sanitized_title": "variational_bayesian_optimal_experimental_design"
        },
        {
            "paper_title": "Gradient-based stochastic optimization methods in bayesian experimental design",
            "rating": 1,
            "sanitized_title": "gradientbased_stochastic_optimization_methods_in_bayesian_experimental_design"
        },
        {
            "paper_title": "Abcd-strategy: Budgeted experimental design for targeted causal structure discovery",
            "rating": 1,
            "sanitized_title": "abcdstrategy_budgeted_experimental_design_for_targeted_causal_structure_discovery"
        }
    ],
    "cost": 0.019026,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Differentiable Multi-Target Causal Bayesian Experimental Design</p>
<p>Yashas Annadani 
Panagiotis Tigas 
Desi R Ivanova 
Andrew Jesson 
Yarin Gal 
Adam Foster 
Stefan Bauer 
Differentiable Multi-Target Causal Bayesian Experimental Design</p>
<p>We introduce a gradient-based approach for the problem of Bayesian optimal experimental design to learn causal models in a batch settinga critical component for causal discovery from finite data where interventions can be costly or risky. Existing methods rely on greedy approximations to construct a batch of experiments while using black-box methods to optimize over a single target-state pair to intervene with. In this work, we completely dispose of the black-box optimization techniques and greedy heuristics and instead propose a conceptually simple end-to-end gradient-based optimization procedure to acquire a set of optimal intervention target-state pairs. Such a procedure enables parameterization of the design space to efficiently optimize over a batch of multi-target-state interventions, a setting which has hitherto not been explored due to its complexity. We demonstrate that our proposed method outperforms baselines and existing acquisition strategies in both single-target and multi-target settings across a number of synthetic datasets.</p>
<p>Introduction</p>
<p>Imagine a scientist entering a wet lab to conduct experiments in order to discover the underlying causal relations within the system of interest. The scientist first comes up with some hypotheses, based on prior knowledge and past observations. Then, based on the formed hypotheses, an experimentation protocol to disambiguate between the competing hypotheses is devised. Additionally, because of the financial and ethical costs and risks involved in such experimentation, it is in the scientist's interest to minimize the number of batches required. This process is known as experimental design, and assuming that the question of interest concerns discovering the causal structure of the system of interest, the process is known as experimental design for causal discovery. A Bayesian framework for this process has been proposed in prior work (Tong &amp; Koller, 2001;Murphy, 2001;Cho et al., 2016;Agrawal et al., 2019;Sussex et al., 2021;Tigas et al., 2022;Toth et al., 2022) which typically consists of updating an approximate posterior with past experimental data and using this updated posterior to compute experiments that are maximally informative, as evaluated by expected information gain-the objective of interest in Bayesian Optimal Experimental Design (BOED) (Lindley, 1956;Chaloner &amp; Verdinelli, 1995).</p>
<p>The problem of Bayesian Optimal Experimental Design for Causal Discovery (BOECD) is hard; computing the Bayesian posterior over Structural Causal Models (SCM)a common framework for capturing causal relationships-is intractable. More importantly, the estimation and optimization of batch BOED objectives are computationally challenging, which has resulted in heuristics like the greedy batch strategy (Agrawal et al., 2019;Sussex et al., 2021) and soft-top-k batch strategy (Tigas et al., 2022). Additionally, in causal discovery, one is interested not only in identifying the variable (target) to intervene on but also the state to set the intervention to, resulting in a design space which is a product space of discrete targets and continuous states, making experimental design even more challenging. Tigas et al. (2022) proposed to use Bayesian Optimization (BO) to optimize over the continuous state-space of the interventions and a soft-top-k heuristic to select a batch.</p>
<p>In this work, we propose a method for estimating and optimizing the BOED objective in a differentiable end-toend manner, alleviating the inefficiencies introduced by the heuristics of the batch selection but also the black-box optimization over the intervening states. Specifically, we introduce estimators of mutual information based on nested estimation (Ryan, 2003;Myung et al., 2013;Huan &amp; Marzouk, 2014;Foster et al., 2019) and importance sampling and extend it to the problem of causal discovery where the optimization is over both discrete nodes and continuous states. We cast the problem of batch experiment selection as a policy optimization where the policy uses either the Gumbel-Softmax or relaxed Bernoulli distribution (Jang et al., 2016;Maddison et al., 2016) for single target and multi-target settings respectively. When combined with the straight-through gradient estimator (Bengio et al., 2013) to optimize over the targets and gradient ascent over corresponding states, we can explore the space of optimal designs efficiently with powerful optimizers (Kingma &amp; Ba, 2014). Our proposed method requires very few assumptions about the causal model and can explore wide range of design settings as compared to prior work (see Table 1), thus opening up possibilities of experimental design for causal discovery in a broader range of applications. Experimental Design for Causal Discovery. One of the earliest works of experimental design for causal discovery in a BOED setting was proposed by (Murphy, 2001) and (Tong &amp; Koller, 2001) in the case of discrete variables for single target acquisition. Since then, a number of works have attempted to address this problem for continuous variables in both the BOED framework (Agrawal et al., 2019;von Kügelgen et al., 2019;Toth et al., 2022;Cho et al., 2016) and other frameworks (Kocaoglu et al., 2017a;Gamella &amp; Heinze-Deml, 2020;Eberhardt et al., 2012;Lindgren et al., 2018;Mokhtarian et al., 2022;Ghassami et al., 2018;Olko et al., 2022;Scherrer et al., 2021). In contrast to the setting studied in this paper, of particular note are the approaches for experimental design for causal discovery in a non-BOED setting in the presence of cycles (Mokhtarian et al., 2022) and latent variables (Kocaoglu et al., 2017b).</p>
<p>Related</p>
<p>Closer to our BOED setting are the approaches of (Tigas et al., 2022) and (Sussex et al., 2021). Specifically, in (Tigas et al., 2022), the authors introduce a method for selecting single target-state pair with stochastic batch acquisition while (Sussex et al., 2021) introduce a method for selecting a batch of multi-target experiments with a greedy strategy, based on a gradient-based approximation to mutual information, without selecting the intervention state. Our presented method in contrast can acquire a batch of multi-target-state pairs.</p>
<p>Bayesian Causal Discovery. Designing experiments involves approximating the posterior of causal models to estimate mutual information. Approximating posterior distributions of causal structures and SCMs is hard due to combinatorially growing graph space (Heinze-Deml et al., 2018).</p>
<p>There are several works which have proposed various methods of approximate inference/ posterior sampling (Friedman et al., 2013;Annadani et al., 2021;Lorch et al., 2021;Cundy et al., 2021;Deleu et al., 2022;Nishikawa-Toomey et al., 2022), which could be used for our proposed design framework.</p>
<p>Background</p>
<p>Causality</p>
<p>Notation. Let V = {1, . . . , d} be the vertex set of any Directed Acyclic Graph (DAG) g = (V, E) and X V = {X 1 , . . . , X d } ⊆ X be the random variables of interest indexed by V.</p>
<p>Structural Causal Model. To deal with questions related to modelling causal relations between variables of interest, we employ the framework of Structural Causal Models (SCM) (Peters et al., 2017). In many fields of empirical sciences like network inference in single cell genomics (Greenfield et al., 2010), inferring protein-signalling networks (Sachs et al., 2005) and medicine (Shen et al., 2020), SCMs provide a framework to model the effects of interventions (Pearl, 2009)-experiments which perturb the state of a variable to a desired state, thereby allowing to study the mechanisms which affect the downstream variables (for example, CRISPR gene knockouts (Meinshausen et al., 2016) in genomics). Under this framework, each variable X i has an associated structural equation, and is assigned a value which is a deterministic function of its direct causes X pa(i) as well as an exogenous noise variable ϵ i with a distribution P ϵi :
X i := f i (X pa(i) , ϵ i ) ∀i ∈ V
f i 's are mechanisms that relate how the direct causes affect the variable X i . If the structural assignments are assumed to be acyclic, these equations induce a DAG g = (V, E) whose vertices correspond to the variables and edges indicate direct causes. An intervention on any variable X i corresponds to changing the structural equation of that variable to the desired state (value), X i := s i , where s i ∈ X i . It is denoted by the do-operator (Pearl, 2009) as do(X i = s i ).</p>
<p>In this work, we assume that the SCM is causally sufficient, i.e. all the variables are measurable, and the noise variables are mutually independent. Though the mechanisms f can be nonparametric in the general case, we assume that there exists a parametric approximation to these mechanisms with parameters γ ∈ Γ. In the case of linear SCMs, γ corresponds to the weights of the edges in E. We further require that the functions f are differentiable with respect to their parameters. Many classes of SCMs fall under this category, including the most commonly studied one -the Gaussian additive noise models (ANM) 1 :
X i := f i (X pa(i) ; γ i ) + ϵ i , ϵ i ∼ N (0, σ 2 i )
Bayesian Causal Discovery. If the SCM for a given set of variables X V is unknown, it has to be estimated from a combination of observational data (data obtained in an unperturbed state of a system) and experimental data under an intervention. This problem is called causal induction or causal discovery (Spirtes et al., 2000). This amounts to learning the parameters of the unknown SCM given by DAG g, parameters of mechanisms, γ = γ 1 , . . . , γ d , and variances, σ 2 = σ 2 1 , . . . , σ 2 d . For notational brevity, henceforth we denote ϕ = (γ, σ 2 ) and all the parameters of interest with θ = (g, ϕ). In Bayesian causal discovery (Heckerman et al., 1997), the parameters of SCM are treated as random variables whose beliefs are updated according to the Bayes rule. A Bayesian method for causal discovery is preferable to model epistemic uncertainty about the model due to finite data as well as characterize equivalence classes of SCM like Markov Equivalence Class (MEC) in the case of non-identifiability (Peters et al., 2012). Interventions improve identifiability, but they have to be planned carefully. After acquiring interventional data, Bayesian methods update the posterior distribution to reduce the uncertainty of the SCM.</p>
<p>Bayesian Optimal Experimental Design</p>
<p>Bayesian Optimal Experimental Design (BOED) (Lindley, 1956;Chaloner &amp; Verdinelli, 1995) is an information theoretic approach to the problem of selecting the optimal experiment to estimate any parameter θ. For BOED, the utility of the experiment ξ is the mutual information (MI) between the observation y and θ:
U BOED (ξ) ≜ I(Y; Θ | ξ) = E p(θ)p(y|θ,ξ) [log p(y | θ, ξ) − log p(y | ξ)]
This objective is also known as the Expected Information Gain (EIG). The goal of BOED is to select the experiment that maximizes this objective ξ * = arg max ξ U BOED (ξ). Unfortunately, evaluating and optimizing this objective is challenging because of the nested expectations (Rainforth et al., 2018) and several estimators have been introduced (Foster et al., 2019;Kleinegesse &amp; Gutmann, 2019), which can be combined with various optimization methods to select the designs (Foster et al., 2020;Ivanova et al., 2021;Foster et al., 2021;Blau et al., 2022).</p>
<p>A common setting, called static, fixed or batch design, is to optimize B designs {ξ 1 , . . . , ξ B } at the same time. The designs are then executed, and the experimental outcomes are collected for a Bayesian update of the model parameters.</p>
<p>Causal Bayesian Experimental Design</p>
<p>Causal Bayesian Experimental Design is concerned with designing the most informative experiments to identify the true SCM so that the number of experiments required is as few as possible. An experiment in causal discovery corresponds to picking the intervention targets I ∈ P(V) and the corresponding states S I ∈ ∪ i∈I X i to set those targets to.</p>
<p>A key component of such methods is computing a posterior over the parameters of the SCM. However, computing the posterior is a difficult task since the number of DAGs grows exponentially in the number of variables. Nevertheless, a plethora of methods exist (Friedman et al., 2013;Annadani et al., 2021;Lorch et al., 2021;Cundy et al., 2021) which can be used with our approach.</p>
<p>Having access to such posterior models, one can estimate the EIG objective. One difficulty that still remains though is that optimizing the EIG objective over the experiments is a mixed discrete and continuous optimization problem, for which previous work has proposed to find the optimal value per candidate target via the use of black-box methods like Bayesian Optimization (BO) (Tigas et al., 2022). Additionally, for the construction of the batch of experimental designs, a greedy approximation is used to incrementally select experiments, a method that is 1 − 1 ϵ -approximate to the optimal solution (Krause &amp; Golovin, 2014).</p>
<p>Differentiable Causal Bayesian Experimental Design</p>
<p>Let Θ be a random variable that models the uncertainty in the parameters of the true SCM, of which θ := (g, ϕ) is a realization. An experiment to identify an intervention is denoted by ξ := {(I, S I )} := do(X I = S I ), where I ∈ P(V) is a set of target indices in the multi-target setting, and S I are the corresponding states of those targets under intervention. The outcome of the experiment is denoted by
y ∼ P X 1 = x 1 , . . . , X d = x d | do X I = S I = p(y | ξ).
Here, y is an instance of the random variable Y ⊆ X distributed according to the interventional distribution 2 . Due to causal sufficiency, the likelihood of data for a given θ satisfies the causal Markov condition:
p(y | θ, ξ) = j∈V\I p x j |ϕ j , x pa g (j) , do X I = S I
(1) Along with a prior p(θ), the above equation defines a generative model of the data.</p>
<p>Design setting. As in prior work (Tigas et al., 2022;Sussex et al., 2021), we are interested in the setting of batch design where we design B experiments at once before collecting experimental data. In other words, we seek a multiset of intervention targets and corresponding states which are jointly maximally informative about the parameters. We denote this multiset as ξ 1:B := (I 1:B , S I 1:B ). After executing a batch of experiments and collecting experimental outcomes, an experimenter might wish to design a new batch of experiments based on collected data (as summarized by the posterior distribution). Let h t denote experimental history (ξ 1 , y 1 ), . . . , (ξ t , y t ) after t batches of acquisition. The BOED objective for this batch setting at any point t is given by the joint mutual information:
I(Y t 1:B ;Θ | ξ t 1:B , h t−1 ) = E p(θ|ht−1) p(y t 1:B |θ,ξ t 1:B ) log p(y t 1:B | θ, ξ t 1:B ) p(y t 1:B | ξ t 1:B , h t−1 )(2)
where Y t 1:B are the random variables corresponding to experimental outcomes for iteration t, y t 1:B are the instances of these random variables and ξ t 1:B is the corresponding multiset of experimental designs. We drop the superscript t from these variables for simplicity of exposition. Ideally, we wish to maximize the above objective by obtaining the gradients ∇ ξ 1:B I and performing gradient ascent. However, the above objective is doubly intractable (Rainforth et al., 2018) and approximations are required. This usually leads to a two-stage procedure where the above objective is first estimated with respect to an inference network and then maximized with respect to designs (Foster et al., 2019), which can be typically inefficient (Foster et al., 2020).</p>
<p>Estimators of the Joint Mutual Information</p>
<p>NESTED MONTE CARLO</p>
<p>Following (Huan &amp; Marzouk, 2014;Foster et al., 2020;, we consider an estimator that allows for approximating the EIG objective while simultaneously optimizing for the experiment ξ that maximizes the objective via gradientbased methods. This estimator, called Nested Monte Carlo (NMC), is based on contrastive estimation of the experimental likelihood and has been extensively used in Bayesian experimental design (Ryan, 2003;Myung et al., 2013). More precisely, assuming some past observational and interventional data h t−1 = {(ξ 1 , y 1 ), . . . , (ξ t−1 , y t−1 )}, for every parameter sample from the posterior distribution θ 0 ∼ p(θ | h t−1 ), a set of contrastive samples θ 1:L ∼ p(θ | h t−1 ) are considered to obtain a unified objective:
U t NMC (ξ1:B) = E p(θ 0:L |h t−1 ) p(y 1:B |θ 0 ,ξ 1:B )) log p(y1:B | ξ1:B, θ0) 1 L L ℓ=1 p(y1:B | ξ1:B, θ ℓ ))(3)
This estimator converges to the true mutual information as L → ∞ (Rainforth et al., 2018). If the design space is continuous, the optimal batch of experiment ξ * 1:B can be found by directly maximizing the NMC objective (ξ * 1:B ← arg max ξ 1:B U t NMC (ξ 1:B )) with gradient-based techniques (Huan &amp; Marzouk, 2014).</p>
<p>The above objective requires estimating the posterior distribution p(θ | h t−1 ) after every acquisition. For causal models, while it is generally hard to estimate this posterior due to DAG space of causal structures being discrete and super-exponential in the number of variables (Tong &amp; Koller, 2001), many approaches exist in the literature (Agrawal et al., 2019;Lorch et al., 2021;Cundy et al., 2021). These approximate posteriors can be nevertheless used for estimating the NMC objective.</p>
<p>IMPORTANCE WEIGHTED NESTED MONTE CARLO</p>
<p>To establish an alternative path to estimating the mutual information, we begin by utilizing an observation from Foster et al. (2019) that it is possible to draw the contrastive samples from a distribution other than p(θ | h t−1 ) and obtain an asymptotically exact estimator, up to a constant C that does not depend on ξ t 1:B . Drawing samples from the original prior p(θ) gives the estimator
I(Y t 1:B ; Θ | ξ t 1:B , h t−1 ) − C = lim L→∞ E p(θ0|ht−1)p(θ 1:L ) p(y 1:B |θ0,ξ 1:B ) log p(y 1:B |ξ 1:B , θ 0 ) 1 L L ℓ=1 p(y 1:B |ξ 1:B , θ ℓ )p(h t−1 |θ ℓ )
The remaining wrinkle is that we must sample θ 0 from p(θ 0 |h t−1 ). We propose the conceptually simplest approach of applying self-normalized importance sampling (SNIS) to the outer expectation. The resulting objective, based on efficiently re-using samples in a leave-one-out manner, can optimize designs by just sampling parameters from the prior, without having to estimate the posterior:
U t IWNMC (ξ 1:B ) = E    L m=1 ω m log p(y m,1:B |θ m , ξ 1:B ) 1 L−1 ℓ̸ =m p(y m,1:B |θ ℓ , ξ 1:B )p(h t−1 |θ ℓ )   (4)
where θ 1:L ∼ p(θ 1:L ) are sampled from the original prior, y m,1:B ∼ p(y 1:B |θ m , ξ 1:B ) are all the experimental outcomes in the batch for parameter θ m and ω m ∝ p(h t−1 |θ m ) are self-normalized weights.</p>
<p>A full derivation is given in Section A.</p>
<p>As IWNMC does not require any posterior estimation but instead relies entirely on the prior, it completely sidesteps the causal discovery process for designing experiments. This is a paradigm change from the NMC estimator which requires causal discovery through the estimation of the posterior.</p>
<p>However, we note that using IWNMC with just the prior (Eq. 4) as opposed to NMC (Eq. 3) comes with trade-offs. IWNMC typically requires a large L to get a good estimate of the EIG. In high dimensions, this can be computationally infeasible. Having a small L on the other hand might result in a failure case if the effective sample size of importance samples becomes 1. We can alleviate this issue if there is some prior information available which could be leveraged to design better proposal distributions. This might consist of knowledge of certain causal mechanisms of the system under study or access to some initial observational data. In such a case, a proposal distribution which encodes this information (for example with support on graphs which are in the Markov Equivalence Class (MEC) of the observational distribution) can be used instead of the prior. If no prior information is available or a good approximate inference technique is at our disposal, NMC is preferable in high dimensions. Surprisingly, we get good results on variables of size up to 5 with IWNMC from just the prior and up to 40 variables from a proposal distribution which has support on the MEC of observational distribution (see Sec 5.5).</p>
<p>Optimizing over Targets and States (DiffCBED)</p>
<p>While the NMC estimator provides a unified objective to directly optimize over the designs ξ 1:B , it requires that the design space is continuous so that the gradients ∂UNMC ∂I 1:B and ∂UNMC ∂S I</p>
<p>1:B</p>
<p>can be computed. However, in the case of designing experiments for causal models, the challenge still remains that optimizing over intervention targets I with gradientbased techniques is not possible because it is a discrete choice.</p>
<p>In order to address this problem, we introduce a design policy π ϕ with learnable parameters ϕ that parameterize a joint distribution over possible intervention targets and corresponding states. Instead of seeking the gradients ∂UNMC , the goal now instead is to estimate UNMC ∂ϕ so that policy can be updated to be close to optimal. Such a characterization of the design space allows us to use continuous relaxations of discrete distributions (Maddison et al., 2016;Jang et al., 2016) to obtain samples of designs and estimate NMC gradients.</p>
<p>Let I and S be the random variables which model all possible intervention target combinations and states for a batch design respectively. While there are many possibilities of instantiating the policy in practice, we consider the simplest case where π ϕ (I, S) ≜ π ϕn (I)π ϕm (S). As the state space is continuous 3 , π ϕm can be either deterministic (a delta Dirac with ϕ m ∈ R B×d ) or Gaussian with ϕ m ∈ R 2×B×d parameterizing its mean and log variance. In this work, we found it sufficient to use a deterministic policy over the state space. For the interventional targets, ϕ n ∈ R B×d parameterizes the logits of different relaxed versions of discrete distributions depending on the setting, which we describe below.</p>
<p>Algorithm 1: Differentiable CBED (DiffCBED)</p>
<p>Input :E SCM Environment, N Initial observational samples, B Batch Size 1 D obs ← E.sample(N ), D int ← ∅ 2 Train q(Θ | D obs ) ≈ p(Θ | D int ) using appropriate algorithm. 3 for batch t = 1 . . . T Batches do 4 Initialize design policy parameters ϕ = {ϕ n , ϕ m }: trainable logits ϕ n for the targets; trainable parameters ϕ m for the states. </p>
<p>SINGLE TARGET (q = 1)</p>
<p>In this setting, the intervention targets are one-hot vectors, as demonstrated in Figure 2. To sample one-hot vectors in a differentiable manner, we parametrize π ϕn as a Gumbel-Softmax distribution (Maddison et al., 2016;Jang et al., Figure 2: A design sample is obtained by first sampling I1:B ∼ π ϕn (I), S1:B ∼ π ϕm (S) and then setting states to be S I 1:B = S1:B ⊙ I1:B. To obtain hard samples of I, we use the straightthrough estimator (Bengio et al., 2013). Illustration for B = 1.</p>
<p>2016) over intervention targets, which is a continuous relaxation of the categorical distribution (in one-hot form).</p>
<p>Additionally, we use the straight-through (ST) gradient estimator (Bengio et al., 2013).</p>
<p>UNCONSTRAINED MULTI-TARGET (q ≤ d)</p>
<p>If instead of a continuous relaxation of the categorical distribution, we parametrise the policy π ϕn as a continuous relaxation of the Bernoulli distribution (Binary Concrete) (Maddison et al., 2016), we can now sample multi-target experiments. Since each interventional target sample will have at most d non-zero entries, this policy is suitable for multi-target experiments with an unconstrained number of interventions per experiment.</p>
<p>CONSTRAINED MULTI-TARGET (q = k)</p>
<p>Finally, when considering a setting where the number of targets per intervention is exactly k. However, this is a significantly more challenging case, since the policy needs to select a subset of k from d nodes. By using a continuous relaxation of subset sampling, as introduced in Xie &amp; Ermon (2019), combined with straight-through gradient estimator, we can efficiently optimize the policy to select a subset of nodes to intervene on. Note that with k = 1, this would be equal to the single-target setting.</p>
<p>The DiffCBED algorithm is outlined in Algorithm 1.</p>
<p>Experiments</p>
<p>We evaluate the performance of our method on synthetic and semi-synthetic datasets and a range of baselines. We aim to investigate the following aspects empirically: (1) To what extent can we design good experiments without performing intermediate causal discovery/ posterior estimation with IWNMC estimator from the prior? (2) Ability to design good experiments with a proposal distribution with IWNMC (3) the performance of our policy-based design in combination with the differentiable NMC estimator in single-target and multi-target settings, as compared to suitable baselines.</p>
<p>Bivariate Setting</p>
<p>First, we demonstrate the method in a two variable setting to qualitatively assess the objective and the optimization method. Since computing the posterior over graphs and parameters is intractable in the general case, as a first step to study how well we can optimize the EIG objective, we assume a simple two-variable SCM. To compute the posterior we enumerate all DAGs with two nodes and parameterize the conditional distributions as neural network parameterized Gaussian distribution (N (X i ; µ NN (X pa(i) ), σ NN (X pa(i) ))). We compute the posterior over the parameters of the conditional distributions via Monte-Carlo dropout (Gal &amp; Ghahra- Figure 4: We test the designs acquired with IWNMC estimator with just the prior as opposed to the random policy (with random target and state acquisition) on variables of 5 dimensions. Plots correspond to unconstrained multi-target setting with B = 2 (shaded area represents 95% confidence intervals -60 seeds). mani, 2016). We parameterize the intervention targets policy with Gumbel-Softmax and interventional states policy with a Gaussian distribution. The final policy consists of the logits of the Gumbel-Softmax and the sufficient statistics of the Gaussian distribution. We use Adam optimizer (Kingma &amp; Ba, 2014) to optimize the parameters of the policy. As we can see in Fig.3(B-C), the optimizer successfully concentrates the policy on the nodes and states that maximize the EIG objective.</p>
<p>Results</p>
<p>We present experimental results in various settings for the following metrics:</p>
<p>EVALUATION METRICS</p>
<p>Expected SHD: This metric evaluates the expected structural hamming distance between the graphs sampled from the posterior model and the ground truth graph.</p>
<p>Expected F1-score: This metric evaluates the expected f1-score of each edge being present or absent in the graphs sampled from the posterior as compared to the ground truth graph.</p>
<p>i-MMD: interventional MMD distance uses the nonparametric distance metric MMD (Gretton et al., 2012). As compared to the graph evaluation metrics, this metric evaluates the interventional distributions induced by both the graph structure and the corresponding conditional distributions. We provide the full definition in Appendix C.</p>
<p>Evaluation of the IWNMC estimator</p>
<p>In this section, we consider optimizing the designs with respect to the IWNMC estimator entirely from the prior, introduced in 4.1, sidestepping the causal discovery procedure. As noted before, estimating posteriors of causal models is hard, so it is important to understand to what extent IWNMC can be considered a suitable candidate for designing good experiments in the absence of a posterior. For this setting, we sample from the prior distribution over graphs by first sampling an ordering of nodes at random and then sampling edges with probability p = 0.25 which adhere to this topological order. We sample the mechanism parameters and noise variances of ANM at random from a Gaussian distribution with mean 0 and variance 1. Figure 4 demonstrates results for 5 variable unconstrained multi-target setting with batch size 2. For evaluation, we train DAG Bootstrap (Friedman et al., 2013) with GIES (Hauser &amp; Bühlmann, 2012) on the data acquired from each policy. We can see that we can recover the ground truth SCM faster than a random strategy. This is a surprising, but positive result given that our policy was trained entirely from samples from the prior. We also tested this approach for 10 variables (results in Appendix E). While this resulted in better performance of the policy as opposed to random in  (Erdős &amp; Rényi, 1959) graphs with d = 20 variables. Each experiment was run with 30 random seeds (shaded area represents 95% CIs)</p>
<p>terms of downstream metrics, we observed effective sample size reach 1, indicating that for 10 dimensions or higher, we might need a better proposal distribution or a posterior estimate.</p>
<p>Baselines</p>
<p>Before we evaluate the IWNMC estimator with a proposal distribution more informative than the prior and the NMC estimator with a posterior estimate of SCM, we present the baselines with which we can compare the designs.</p>
<p>SINGLE TARGET</p>
<p>Random-Fixed: Uniform random selection of target, fixing the state to a value of 0 (as introduced in (Agrawal et al., 2019;Tigas et al., 2022)). Random-Random: Uniform selection of node, uniform selection of state (introduced in (Toth et al., 2022)). SoftCBED: A stochastic approximation of greedy batch selection as introduced in (Tigas et al., 2022).</p>
<p>MULTI-TARGET</p>
<p>Random-Random: Multi-target version of uniform selection of node, uniform selection of value (introduced in (Toth et al., 2022)). Random-Fixed: Multitarget version of uniform selection of node, fixed value to 5 (Sussex et al., 2021), as suggested by the authors. SSGb: Finite sample baseline from (Sussex et al., 2021) with fixed value equal 5. We emphasize that in contrast to our method, the baselines cannot select states, but they either assume a fixed predefined state or select a state at random.</p>
<p>Evaluation in Higher Dimensions</p>
<p>EVALUATION OF IWNMC WITH PROPOSAL DISTRIBUTION</p>
<p>In this experiment, we consider 40 variables, constrained (q = 5) multi-target and batch size B = 2. Further, we use the same setup as Sussex et al. (2021) to make a fair comparison as well as to construct a proposal distribution. For the proposal distribution, we use 800 observational samples to train DAG Bootstrap (Friedman et al., 2013;Agrawal et al., 2019) and augment our posterior samples with samples of DAGs from the MEC of the true graph, to make sure that there is sufficient support within the MEC of the true graph (see Sussex et al. (2021) for details). We then acquire a single batch of experiments from IWNMC estimator for our approach. For the baseline, we acquire a single batch of experiments from the estimator defined in (Sussex et al., 2021).</p>
<p>For random and SSGb baseline, we set the interventional state (value) to 5, as explained in (Sussex et al., 2021). Our approach doesn't fix the state to 5 but optimizes over states to perform the intervention with. In Table 2 we summarize our results. As we can see, our method outperforms random and SSGb by a great margin, indicating that with a good proposal distribution, IWNMC can still be a promising candidate in higher dimensions.</p>
<p>RESULTS WITH NMC ESTIMATOR</p>
<p>For the following results, we use DAG-Bootstrap (Agrawal et al., 2019), an approximate posterior method based on GIES causal discovery method (Hauser &amp; Bühlmann, 2012).  (Greenfield et al., 2010) simulator. The data is generated based on this graph by simulating the noise and mechanisms. We find that our method performs better than the baselines. Shaded area represents 95% CI. As GIES is not a differentiable method, once we compute the posterior, we transfer the posterior samples (the bootstraps) into JAX (jax) tensors to allow for the gradients to be computed with respect to the experiments.</p>
<p>Single-target synthetic graphs: In this experiment, we test against synthetic graphs of 50 variables and batch size 5, where the graph is sampled from the class of Erdos-Renyi (a common benchmark in the literature (Tigas et al., 2022;Toth et al., 2022;Scherrer et al., 2021)). In Figure 10 (A,B,C) we summarize the results. We observe that our method performs significantly better than the baselines.</p>
<p>20 nodes, unconstrained (q ≤ 20), batch size B = 2: In this experiment, we evaluate the performance of our method as compared to the baselines, on sparse graphs over several acquisitions. Figure 10 (D,E,F) summarizes the results of this setting. We observe strong empirical performance as compared to all the baselines. Additional results are given in Section G.1.</p>
<p>Evaluation on Semi-Synthetic Data</p>
<p>We evaluate our proposed design framework on semisynthetic setting based on the DREAM gene networks (Greenfield et al., 2010). In particular, we use the E. Coli gene interaction network, which is real-world inspired gene regulatory network of 10 variables, and simulate the mechanisms (and hence the data generation process). Then we run a random node with a fixed intervention value, a random node with a random value, SSGb finite sample and our algorithm. The results are presented in Figure 6. We find that our algorithm performs better than the baselines, indicating the potential of gradient-based approach to more realistic settings.</p>
<p>Discussion</p>
<p>Limitations: A primary limitation of our method is that it needs to estimate a posterior after every acquisition. While the proposed IWNMC estimator presents an interesting alternative, the designs are still non-adaptive. An interesting direction is to train a policy to design adaptive experiments (Foster et al., 2021;Greenewald et al., 2019).</p>
<p>Conclusion:</p>
<p>We present a gradient-based method for differentiable Bayesian optimal experimental design for causal discovery. Our method allows not only for single-target but also various multi-target (constrained and unconstrained) batch design of experiments. While prior work in relies on greedy approximations for the selection of a batch (Agrawal et al., 2019;Tigas et al., 2022) or black-box methods (Toth et al., 2022;Tigas et al., 2022) for optimizing over interventional states, our method utilizes gradient-based optimization procedures to simultaneously optimize for various design choices. Evaluation on different datasets suggests that our method is competitive with baselines. </p>
<p>A. Derivation of Importance Weighted Nested Monte Carlo Estimator</p>
<p>In this section, we derive the U IWNMC (Eq. 4) estimator. We derive the estimator for a single design with an experiment denoted by ξ, parameters θ and experimental outcome random variable Y and its instance y. Since it is a static design, all the steps of the derivation hold if we replace ξ with ξ 1:B , Y with Y 1:B and y with y 1:B . We begin from the variational NMC (VNMC) estimator, introduced by Foster et al. (2019)
I(Y; Θ | ξ) ≤ UVNMC(ξ) = E p(θ 0 |h t−1 ) p(y|θ 0 ,ξ) q(θ 1:L |h t−1 ,y)   log p(y | ξ, θ0) 1 L L ℓ=1 p(y|ξ,θ ℓ )p(θ ℓ |h t−1 ) q(θ 1:L |h t−1 ,y)   .(5)
This can be rewritten as
UVNMC(ξ) = E p(θ 0 |h t−1 ) p(y|θ 0 ,ξ) q(θ 1:L |h t−1 ,y)   log p(y | ξ, θ0) 1 L L ℓ=1 p(y|ξ,θ ℓ )p(θ ℓ )p(h t−1 |θ ℓ ) q(θ 1:L |h t−1 ,y) + log p(ht−1)  (6)
and Foster et al. (2019) observed that log p(h t−1 ) is a constant that does not depend on ξ and so can be safely neglected when optimizing over designs. If we take the original prior p(θ ℓ ) as our proposal distribution q, then we arrive at
UVNMC-prior(ξ) = E p(θ 0 |h t−1 )p(θ 1:L ) p(y|θ 0 ,ξ) log p(y | ξ, θ0) 1 L L ℓ=1 p(y | ξ, θ ℓ )p(ht−1 | θ ℓ ) + C(7)
where C = log p(h t−1 ). This allows us to sample contrastive samples from any distribution, but does not account for θ 0 . If we were to sample θ 0 from p(θ 0 ), we can correct using an importance weight
UVNMC-prior(ξ) = E p(θ 0:L ) p(y|θ 0 ,ξ) p(θ0 | ht−1) p(θ0) log p(y | ξ, θ0) 1 L L ℓ=1 p(y | ξ, θ ℓ )p(ht−1 | θ ℓ ) + C,(8)
but unfortunately, this relies on knowing the density of the posterior or using the fact that p(θ 0 | h t−1 )/p(θ 0 ) = p(h t−1 | θ 0 )/p(h t−1 ), knowing the marginal likelihood of the data h t−1 . Neither of these is usually tractable. Instead, we can use a self-normalized importance sampling approach, which amounts to estimating p(h t−1 ) by a sum over θ 0:L , giving the approximation IWNMC:
UIWNMC(ξ) = E p(θ 0:L ) p(y|θ 0 ,ξ) p(ht−1 | θ0) 1 L+1 L k=0 p(ht−1 | θ k ) log p(y | ξ, θ0) 1 L L ℓ=1 p(y | ξ, θ ℓ )p(ht−1 | θ ℓ ) + C.(9)
The form that is given in (4) is obtained by first relabelling the θ samples to start from 1
UIWNMC(ξ) = E p(θ 1:L ) p(y|θ 1 ,ξ) p(ht−1 | θ1) 1 L L k=1 p(ht−1 | θ k ) log p(y | ξ, θ1) 1 L−1 L ℓ=2 p(y | ξ, θ ℓ )p(ht−1 | θ ℓ ) + C,(10)
noting that the role of θ 1 is arbitrary and can be replaced by any m ∈ {1, . . . , L}
UIWNMC(ξ) = E p(θ 1:L ) p(y|θm,ξ) p(ht−1 | θm) 1 L L k=1 p(ht−1 | θ k ) log p(y | ξ, θm) 1 L−1 L ℓ̸ =m p(y | ξ, θ ℓ )p(ht−1 | θ ℓ ) + C,(11)
and finally taking the mean over m, noting that this does not change the expected value due to linearity
UIWNMC(ξ) = E p(θ 1:L ) p(y|θm,ξ) L m=1 p(ht−1 | θm) L k=1 p(ht−1 | θ k ) log p(y | ξ, θm) 1 L−1 L ℓ̸ =m p(y | ξ, θ ℓ )p(ht−1 | θ ℓ ) + C.(12)
We finally drop the constant C as it is independent of ξ and take 
ω m = p(h t−1 | θ m ) L k=1 p(h t−1 | θ k ) .(13</p>
<p>C. Metrics</p>
<p>. E-SHD: Defined as the expected structural hamming distance between samples from the posterior model over graphs and the true graph E-SHD := E g∼p(G|D) SHD(g,g)</p>
<p>Expected edges F1: The expected F1 score of the binary classification task of predicting the presence/ absence of all edges.</p>
<p>The expectation is taken over multiple posterior samples.</p>
<p>i-MMD: Interventional MMD is defined as MMD distance (Gretton et al., 2012) between the true interventional distribution and the interventional distribution induced by θ and g (posterior sample). We take an expectation over different posterior samples, interventional targets and interventional states. For the kernel choice, we use the median heuristic as described in (Gretton et al., 2012).</p>
<p>D. DAG Bootstrap</p>
<p>The DAG bootstrap bootstraps observations and interventions to infer a different causal structure per bootstrap. We used GIES as the causal inference algorithm because of the adaptation of GES on interventional data as well. In our experiments, we used the pcalg R implementation https://github.com/cran/pcalg/blob/master/R/gies.R to discover 100 graphs. Each graph can be seen as a posterior sample from p(G | h t−1 ). For each of the sampled graphs G i we compute the appropriate θ MLE under linear Gaussian assumption for the conditional distributions.</p>
<p>E. Importance Weighted Nested Monte Carlo Full Results random diffCBED Figure 8: Multi target-state design setting results for Erdős-Rényi (Erdős &amp; Rényi, 1959) graphs with d = 5 variables. Each experiment was run with 60 random seeds (shaded area represents 95% CIs) random diffCBED Figure 9: Single target-state design setting results for Erdős-Rényi (Erdős &amp; Rényi, 1959) graphs with d = 10 variables. Each experiment was run with 60 random seeds (shaded area represents 95% CIs) F. 20 nodes, unconstrained (q ≤ 20), batch size B = 1:
(A) (B) (C) diffCBED
SSGb random-random random-fixed Figure 10: Multi target-state design setting results for Erdős-Rényi (Erdős &amp; Rényi, 1959) graphs with d = 50 variables. Each experiment was run with 30 random seeds (the shaded area represents 95% CIs). We observe that for batch size 1, the difference between the methods becomes more significant.</p>
<p>G. Datasets and Experiment Details</p>
<p>G.1. Synthetic Graphs Experiments</p>
<p>In the synthetic data experiments, we focus on Erdős-Rényi graph model. We used networkx 4 and method fast_gnp_random_graph (Batagelj &amp; Brandes, 2005) to generate graphs based on the Erdős-Rényi model. We set the expected number of edges per vertex to 1. </p>
<p>H. Optimizer Settings</p>
<p>I. Relaxed Distribution Temperature Sensitivity Analysis</p>
<p>We perform ablation where we empirically test the sensitivity to temperature hyperparameter for the relaxed distribution.</p>
<p>Results are presented in Figure 11 for the unconstrained multi-target setting (d = 20). We find that our approach is fairly robust to different temperatures. Note that for the reported results, we anneal the temperature during the course of training and hence a single choice of temperature is not necessary.</p>
<p>Figure 1 :
1Causal Bayesian Experimental Design optimizes experiments that help disambiguate between competing causal hypotheses.</p>
<p>D
int ← D int ∪ E.intervene(ξ 1:B ) 10Update the posterior q(Θ | D obs ∪ D int ).</p>
<p>Figure 3 :
3Two variables and two experiments scenario. We assume a ground-truth graph GT of two nodes X1 → X2. (A) The conditional distribution p(X2 | X1) is shown in (A). The corresponding SCM (Fig. A) is x1 = Σx 1 and x2 = f (x1) + Σx 2 . The four panels represent the EIG of all possible experiments of batch size two, when intervening on nodes (0, 0), (0, 1), (1, 0), (1, 1). (B, C) Each panel shows how the EIG change on different interventional states. E.g. right top panel shows how EIG changes when applying interventions with states in ranges [−20, 20]. Fig. B Shows the designs before optimizing the objective and Fig. C after. As we can observe that the algorithm successfully places the designs (samples from the policy) on the high EIG (1.95) area of the plot (• on the plot).random diffCBED</p>
<p>Figure 5 :
5(A,B,C) Single target-state design setting results for Erdős-Rényi (Erdős &amp; Rényi, 1959) graphs with d = 50 variables. (D,E,F) Multi target-state design setting results for Erdős-Rényi</p>
<p>Figure 6 :
6Results on the E. Coli gene interaction network (d = 10) of the DREAM</p>
<p>Figure 7 :
7Here we visualize the Expected Information Gain of batch size two, on two nodes over different interventional states of the range [−10, 10].</p>
<p>Table 1 :
1Comparison of different BOED for causal discovery methods based on their design space assumptions.Design Space Assumptions 
Target Acquisition 
(Single Target) </p>
<p>State Acquisition 
(Single Target) </p>
<p>Target Acquisition 
(Multi-target) </p>
<p>State Acquisition 
(Multi-target) </p>
<p>Batch 
Acquisition 
Murphy (2001) 
✓ 
Tong &amp; Koller (2001) 
✓ 
Cho et al. (2016) 
✓ 
Agrawal et al. (2019) 
✓ 
✓ 
Toth et al. (2022) 
✓ 
✓ 
Tigas et al. (2022) 
✓ 
✓ 
✓ 
Sussex et al. (2021) 
✓ 
✓ 
✓ 
Ours 
✓ 
✓ 
✓ 
✓ 
✓ </p>
<p>WorkDifferentiable Bayesian Optimal Experimental Design. 
Huan &amp; Marzouk (2014); Foster et al. (2019; 2020); Klei-
negesse &amp; Gutmann (2020; 2021) developed a unified frame-
work for estimating expected information gain and opti-</p>
<p>mizing the designs with gradient-based methods. More 
recently, Ivanova et al. (2022) applied the Gumbel-Softmax 
relaxation within gradient-based BOED for contextual opti-
mization. In Ivanova et al. (2021); Foster et al. (2021), the 
authors introduced a policy-based method for performing 
adaptive experimentation. More recently, work like Blau 
et al. (2022); Lim et al. (2022) used reinforcement learning 
to train policies for adaptive experimental design. </p>
<p>Table 2 :
2Resultsof multi-target experiments on graphs of size 40 
(30 seeds ± s.e.). Similarly to (Sussex et al., 2021), we are using 
posterior samples trained on observational data and re-weighting 
them with likelihoods. </p>
<p>Method 
ESHD ↓ 
F1 ↑ 
iMMD ↓ </p>
<p>Random 
43.78±46.67 0.91±0.08 0.16±0.07 
SSGb 
15.59±29.66 0.97±0.05 0.10±0.06 
diffCBED 
0.44±0.21 
0.99±0.00 0.07±0.01 </p>
<p>Ivanova, D. R., Foster, A.,Kleinegesse, S., Gutmann, M. U.,  and Rainforth,  T. Implicit deep adaptive design: policybased experimental design without likelihoods. Advances in Neural Information Processing Systems, 34:25785-25798, 2021. 2, 3 Ivanova, D. R., Jennings, J., Zhang, C., and Foster, A. Efficient real-world testing of causal decision making via bayesian experimental design for contextual optimisation. ICML 2022 Workshop on Adaptive Experimental Design and Active Learning in the Real World, 2022. 2</p>
<p>Table 3 :
3Table indicating the hyperparameters and optimizer settings for different experimental results.Optimization settings 
Single Target 
NMC </p>
<p>Multi-Target 
NMC </p>
<p>Multi-Target 
IWNMC with prior </p>
<p>Multi-Target 
IWNMC with proposal </p>
<p>Note that differentiability of f is the only assumption we require with respect to an SCM. We do not require that the noise is additive. For clarity of exposition, we restrict our focus to an ANM as they are the most commonly studied class of SCMs.
Note that when I = ∅, it corresponds to an observational/ non-experimental setting. In this case, Y = X V .
If the state space is discrete, optimizing π ϕm would be similar to π ϕn which involves reparameterized gradients.
https://networkx.org/documentation/networkx-1.10/reference/generated/networkx. generators.random_graphs.fast_gnp_random_graph.html
Acknowledgements:We would like to thank Berzelius computing from NSC Sweden for providing computational resource for some of the experiments of the paper.
. Jax: Autograd and XLA. Jax: Autograd and XLA. https://github.com/ google/jax. 9</p>
<p>Abcd-strategy: Budgeted experimental design for targeted causal structure discovery. R Agrawal, C Squires, K Yang, K Shanmugam, C Uhler, PMLRThe 22nd International Conference on Artificial Intelligence and Statistics. 89Agrawal, R., Squires, C., Yang, K., Shanmugam, K., and Uhler, C. Abcd-strategy: Budgeted experimental de- sign for targeted causal structure discovery. In The 22nd International Conference on Artificial Intelligence and Statistics, pp. 3400-3409. PMLR, 2019. 1, 2, 5, 8, 9</p>
<p>Variational causal networks: Approximate bayesian inference over causal structures. Y Annadani, J Rothfuss, A Lacoste, N Scherrer, A Goyal, Y Bengio, S Bauer, arXiv:2106.0763534arXiv preprintAnnadani, Y., Rothfuss, J., Lacoste, A., Scherrer, N., Goyal, A., Bengio, Y., and Bauer, S. Variational causal networks: Approximate bayesian inference over causal structures. arXiv preprint arXiv:2106.07635, 2021. 3, 4</p>
<p>Efficient generation of large random networks. V Batagelj, U Brandes, Physical Review E. 71316Batagelj, V. and Brandes, U. Efficient generation of large random networks. Physical Review E, 71(3):036113, 2005. 16</p>
<p>Estimating or propagating gradients through stochastic neurons for conditional computation. Y Bengio, N Léonard, A Courville, arXiv:1308.34326arXiv preprintBengio, Y., Léonard, N., and Courville, A. Estimating or propagating gradients through stochastic neurons for con- ditional computation. arXiv preprint arXiv:1308.3432, 2013. 2, 6</p>
<p>Optimizing sequential experimental design with deep reinforcement learning. T Blau, E V Bonilla, I Chades, A Dezfouli, PMLRInternational Conference on Machine Learning. 23Blau, T., Bonilla, E. V., Chades, I., and Dezfouli, A. Op- timizing sequential experimental design with deep re- inforcement learning. In International Conference on Machine Learning, pp. 2107-2128. PMLR, 2022. 2, 3</p>
<p>Bayesian experimental design: A review. K Chaloner, I Verdinelli, Statistical Science. 13Chaloner, K. and Verdinelli, I. Bayesian experimental de- sign: A review. Statistical Science, pp. 273-304, 1995. 1, 3</p>
<p>Reconstructing causal biological networks through active learning. H Cho, B Berger, J Peng, PloS one. 113150611Cho, H., Berger, B., and Peng, J. Reconstructing causal biological networks through active learning. PloS one, 11 (3):e0150611, 2016. 1, 2</p>
<p>Bcd nets: Scalable variational approaches for bayesian causal discovery. C Cundy, A Grover, S Ermon, Advances in Neural Information Processing Systems. 345Cundy, C., Grover, A., and Ermon, S. Bcd nets: Scalable variational approaches for bayesian causal discovery. Ad- vances in Neural Information Processing Systems, 34, 2021. 3, 4, 5</p>
<p>T Deleu, A Góis, C Emezue, M Rankawat, S Lacoste-Julien, S Bauer, Y Bengio, arXiv:2202.13903Bayesian structure learning with generative flow networks. 2022arXiv preprintDeleu, T., Góis, A., Emezue, C., Rankawat, M., Lacoste- Julien, S., Bauer, S., and Bengio, Y. Bayesian structure learning with generative flow networks. arXiv preprint arXiv:2202.13903, 2022. 3</p>
<p>On the number of experiments sufficient and in the worst case necessary to identify all causal relations among n variables. F Eberhardt, C Glymour, R Scheines, arXiv:1207.1389arXiv preprintEberhardt, F., Glymour, C., and Scheines, R. On the number of experiments sufficient and in the worst case necessary to identify all causal relations among n variables. arXiv preprint arXiv:1207.1389, 2012. 2</p>
<p>On random graphs i. publicationes mathematicae (debrecen). P Erdős, A Rényi, 1516Erdős, P. and Rényi, A. On random graphs i. publicationes mathematicae (debrecen). 1959. 8, 15, 16</p>
<p>. A Foster, M Jankowiak, E Bingham, P Horsfall, Y W Teh, T Rainforth, N Goodman, arXiv:1903.05480513arXiv preprintVariational bayesian optimal experimental designFoster, A., Jankowiak, M., Bingham, E., Horsfall, P., Teh, Y. W., Rainforth, T., and Goodman, N. Variational bayesian optimal experimental design. arXiv preprint arXiv:1903.05480, 2019. 2, 3, 4, 5, 13</p>
<p>A unified stochastic gradient approach to designing bayesian-optimal experiments. A Foster, M Jankowiak, M O&apos;meara, Y W Teh, T Rainforth, PMLR, 2020. 2International Conference on Artificial Intelligence and Statistics. 34Foster, A., Jankowiak, M., O'Meara, M., Teh, Y. W., and Rainforth, T. A unified stochastic gradient approach to designing bayesian-optimal experiments. In International Conference on Artificial Intelligence and Statistics, pp. 2959-2969. PMLR, 2020. 2, 3, 4</p>
<p>Deep adaptive design: Amortizing sequential bayesian experimental design. A Foster, D R Ivanova, I Malik, T Rainforth, arXiv:2103.0243849arXiv preprintFoster, A., Ivanova, D. R., Malik, I., and Rainforth, T. Deep adaptive design: Amortizing sequential bayesian experi- mental design. arXiv preprint arXiv:2103.02438, 2021. 2, 3, 4, 9</p>
<p>N Friedman, M Goldszmidt, A Wyner, arXiv:1301.6695Data analysis with bayesian networks: A bootstrap approach. 7arXiv preprintFriedman, N., Goldszmidt, M., and Wyner, A. Data analysis with bayesian networks: A bootstrap approach. arXiv preprint arXiv:1301.6695, 2013. 3, 4, 7, 8</p>
<p>Dropout as a bayesian approximation: Representing model uncertainty in deep learning. Y Gal, Z Ghahramani, PMLRinternational conference on machine learning. Gal, Y. and Ghahramani, Z. Dropout as a bayesian approx- imation: Representing model uncertainty in deep learn- ing. In international conference on machine learning, pp. 1050-1059. PMLR, 2016. 6</p>
<p>Active invariant causal prediction: Experiment selection through stability. J L Gamella, C Heinze-Deml, arXiv:2006.05690arXiv preprintGamella, J. L. and Heinze-Deml, C. Active invariant causal prediction: Experiment selection through stability. arXiv preprint arXiv:2006.05690, 2020. 2</p>
<p>Budgeted experiment design for causal structure learning. A Ghassami, S Salehkaleybar, N Kiyavash, E Bareinboim, PMLRInternational Conference on Machine Learning. Ghassami, A., Salehkaleybar, S., Kiyavash, N., and Barein- boim, E. Budgeted experiment design for causal structure learning. In International Conference on Machine Learn- ing, pp. 1724-1733. PMLR, 2018. 2</p>
<p>Sample efficient active learning of causal trees. K Greenewald, D Katz, K Shanmugam, S Magliacane, M Kocaoglu, E Boix Adsera, G Bresler, Advances in Neural Information Processing Systems. 329Greenewald, K., Katz, D., Shanmugam, K., Magliacane, S., Kocaoglu, M., Boix Adsera, E., and Bresler, G. Sample efficient active learning of causal trees. Advances in Neural Information Processing Systems, 32, 2019. 9</p>
<p>Combining genetic and dynamic information to identify biological networks and dynamical models. A Greenfield, A Madar, H Ostrer, R Bonneau, Dream4, PloS one. 5109Greenfield, A., Madar, A., Ostrer, H., and Bonneau, R. Dream4: Combining genetic and dynamic information to identify biological networks and dynamical models. PloS one, 5(10):e13397, 2010. 3, 9</p>
<p>A kernel two-sample test. A Gretton, K M Borgwardt, M J Rasch, B Schölkopf, A Smola, The Journal of Machine Learning Research. 13115Gretton, A., Borgwardt, K. M., Rasch, M. J., Schölkopf, B., and Smola, A. A kernel two-sample test. The Journal of Machine Learning Research, 13(1):723-773, 2012. 7, 15</p>
<p>Characterization and greedy learning of interventional markov equivalence classes of directed acyclic graphs. A Hauser, P Bühlmann, The Journal of Machine Learning Research. 131Hauser, A. and Bühlmann, P. Characterization and greedy learning of interventional markov equivalence classes of directed acyclic graphs. The Journal of Machine Learning Research, 13(1):2409-2464, 2012. 7, 8</p>
<p>A bayesian approach to causal discovery. D Heckerman, C Meek, Cooper , G , msr-tr-97-05Microsoft ResearchTechnical reportHeckerman, D., Meek, C., and Cooper, G. A bayesian approach to causal discovery. Technical report, Technical report msr-tr-97-05, Microsoft Research, 1997. 3</p>
<p>Invariant causal prediction for nonlinear models. C Heinze-Deml, J Peters, N Meinshausen, Journal of Causal Inference. 62Heinze-Deml, C., Peters, J., and Meinshausen, N. Invariant causal prediction for nonlinear models. Journal of Causal Inference, 6(2), 2018. 2</p>
<p>Gradient-based stochastic optimization methods in bayesian experimental design. X Huan, Y Marzouk, International Journal for Uncertainty Quantification. 465Huan, X. and Marzouk, Y. Gradient-based stochastic opti- mization methods in bayesian experimental design. In- ternational Journal for Uncertainty Quantification, 4(6), 2014. 2, 4, 5</p>
<p>Categorical reparameterization with gumbel-softmax. E Jang, S Gu, B Poole, arXiv:1611.011446arXiv preprintJang, E., Gu, S., and Poole, B. Categorical repa- rameterization with gumbel-softmax. arXiv preprint arXiv:1611.01144, 2016. 2, 5, 6</p>
<p>D P Kingma, J Ba, Adam, arXiv:1412.6980A method for stochastic optimization. 27arXiv preprintKingma, D. P. and Ba, J. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980, 2014. 2, 7</p>
<p>Bayesian experimental design for implicit models by mutual information neural estimation. S Kleinegesse, M Gutmann, PMLR, 2020. 2Proceedings of the 37th International Conference on Machine Learning, Proceedings of Machine Learning Research. the 37th International Conference on Machine Learning, Machine Learning ResearchKleinegesse, S. and Gutmann, M. Bayesian experimental design for implicit models by mutual information neural estimation. In Proceedings of the 37th International Con- ference on Machine Learning, Proceedings of Machine Learning Research, pp. 5316-5326. PMLR, 2020. 2</p>
<p>Efficient bayesian experimental design for implicit models. S Kleinegesse, M U Gutmann, PMLRThe 22nd International Conference on Artificial Intelligence and Statistics. Kleinegesse, S. and Gutmann, M. U. Efficient bayesian experimental design for implicit models. In The 22nd International Conference on Artificial Intelligence and Statistics, pp. 476-485. PMLR, 2019. 3</p>
<p>Gradient-based bayesian experimental design for implicit models using mutual information lower bounds. S Kleinegesse, M U Gutmann, arXiv:2105.04379arXiv preprintKleinegesse, S. and Gutmann, M. U. Gradient-based bayesian experimental design for implicit models us- ing mutual information lower bounds. arXiv preprint arXiv:2105.04379, 2021. 2</p>
<p>Costoptimal learning of causal graphs. M Kocaoglu, A Dimakis, S Vishwanath, PMLRInternational Conference on Machine Learning. Kocaoglu, M., Dimakis, A., and Vishwanath, S. Cost- optimal learning of causal graphs. In International Con- ference on Machine Learning, pp. 1875-1884. PMLR, 2017a. 2</p>
<p>Experimental design for learning causal graphs with latent variables. M Kocaoglu, K Shanmugam, E Bareinboim, Advances in Neural Information Processing Systems. 30Kocaoglu, M., Shanmugam, K., and Bareinboim, E. Ex- perimental design for learning causal graphs with latent variables. Advances in Neural Information Processing Systems, 30, 2017b. 2</p>
<p>Submodular function maximization. A Krause, D Golovin, Tractability. 34Krause, A. and Golovin, D. Submodular function maximiza- tion. Tractability, 3:71-104, 2014. 4</p>
<p>Policy-based bayesian experimental design for non-differentiable implicit models. V Lim, E Novoseller, J Ichnowski, H Huang, K Goldberg, arXiv:2203.04272arXiv preprintLim, V., Novoseller, E., Ichnowski, J., Huang, H., and Goldberg, K. Policy-based bayesian experimental design for non-differentiable implicit models. arXiv preprint arXiv:2203.04272, 2022. 2</p>
<p>Experimental design for cost-aware learning of causal graphs. E Lindgren, M Kocaoglu, A G Dimakis, S Vishwanath, Advances in Neural Information Processing Systems. 31Lindgren, E., Kocaoglu, M., Dimakis, A. G., and Vish- wanath, S. Experimental design for cost-aware learning of causal graphs. Advances in Neural Information Pro- cessing Systems, 31, 2018. 2</p>
<p>On a measure of the information provided by an experiment. The Annals of Mathematical Statistics. D V Lindley, 13Lindley, D. V. On a measure of the information provided by an experiment. The Annals of Mathematical Statistics, pp. 986-1005, 1956. 1, 3</p>
<p>L Lorch, J Rothfuss, B Schölkopf, A Krause, Dibs, arXiv:2105.11839Differentiable bayesian structure learning. 35arXiv preprintLorch, L., Rothfuss, J., Schölkopf, B., and Krause, A. Dibs: Differentiable bayesian structure learning. arXiv preprint arXiv:2105.11839, 2021. 3, 4, 5</p>
<p>The concrete distribution: A continuous relaxation of discrete random variables. C J Maddison, A Mnih, Y W Teh, arXiv:1611.007126arXiv preprintMaddison, C. J., Mnih, A., and Teh, Y. W. The concrete distribution: A continuous relaxation of discrete random variables. arXiv preprint arXiv:1611.00712, 2016. 2, 5, 6</p>
<p>Methods for causal inference from gene perturbation experiments and validation. Proceedings of the National Academy of. N Meinshausen, A Hauser, J M Mooij, J Peters, P Versteeg, P Bühlmann, Sciences. 11327Meinshausen, N., Hauser, A., Mooij, J. M., Peters, J., Ver- steeg, P., and Bühlmann, P. Methods for causal inference from gene perturbation experiments and validation. Pro- ceedings of the National Academy of Sciences, 113(27): 7361-7368, 2016. 3</p>
<p>A unified experiment design approach for cyclic and acyclic causal models. E Mokhtarian, S Salehkaleybar, A Ghassami, N Kiyavash, arXiv:2205.100832022arXiv preprintMokhtarian, E., Salehkaleybar, S., Ghassami, A., and Kiyavash, N. A unified experiment design approach for cyclic and acyclic causal models. arXiv preprint arXiv:2205.10083, 2022. 2</p>
<p>Active learning of causal bayes net structure. K P Murphy, 1Murphy, K. P. Active learning of causal bayes net structure. 2001. 1, 2</p>
<p>A tutorial on adaptive design optimization. J I Myung, D R Cavagnaro, M A Pitt, Journal of mathematical psychology. 573-44Myung, J. I., Cavagnaro, D. R., and Pitt, M. A. A tutorial on adaptive design optimization. Journal of mathematical psychology, 57(3-4):53-67, 2013. 2, 4</p>
<p>M Nishikawa-Toomey, T Deleu, J Subramanian, Y Bengio, L Charlin, arXiv:2211.02763Bayesian learning of causal structure and mechanisms with gflownets and variational bayes. 2022arXiv preprintNishikawa-Toomey, M., Deleu, T., Subramanian, J., Bengio, Y., and Charlin, L. Bayesian learning of causal structure and mechanisms with gflownets and variational bayes. arXiv preprint arXiv:2211.02763, 2022. 3</p>
<p>Trust your ∇: Gradient-based intervention targeting for causal discovery. M Olko, M Zając, A Nowak, N Scherrer, Y Annadani, S Bauer, Ł Kuciński, P Miłoś, arXiv:2211.13715arXiv preprintOlko, M., Zając, M., Nowak, A., Scherrer, N., Annadani, Y., Bauer, S., Kuciński, Ł., and Miłoś, P. Trust your ∇: Gradient-based intervention targeting for causal discov- ery. arXiv preprint arXiv:2211.13715, 2022. 2</p>
<p>. J Pearl, Causality, Cambridge university pressPearl, J. Causality. Cambridge university press, 2009. 3</p>
<p>Identifiability of causal graphs using functional models. J Peters, J Mooij, D Janzing, B Schölkopf, arXiv:1202.3757arXiv preprintPeters, J., Mooij, J., Janzing, D., and Schölkopf, B. Identifi- ability of causal graphs using functional models. arXiv preprint arXiv:1202.3757, 2012. 3</p>
<p>Elements of causal inference: foundations and learning algorithms. J Peters, D Janzing, B Schölkopf, The MIT PressPeters, J., Janzing, D., and Schölkopf, B. Elements of causal inference: foundations and learning algorithms. The MIT Press, 2017. 3</p>
<p>On nesting monte carlo estimators. T Rainforth, R Cornish, H Yang, A Warrington, F Wood, International Conference on Machine Learning. Rainforth, T., Cornish, R., Yang, H., Warrington, A., and Wood, F. On nesting monte carlo estimators. In Interna- tional Conference on Machine Learning, pp. 4267-4276.</p>
<p>Estimating expected information gains for experimental designs with application to the random fatiguelimit model. K J Ryan, Journal of Computational and Graphical Statistics. 1234Ryan, K. J. Estimating expected information gains for exper- imental designs with application to the random fatigue- limit model. Journal of Computational and Graphical Statistics, 12(3):585-603, 2003. 2, 4</p>
<p>Causal protein-signaling networks derived from multiparameter single-cell data. K Sachs, O Perez, D Pe&apos;er, D A Lauffenburger, G P Nolan, Science. 3085721Sachs, K., Perez, O., Pe'er, D., Lauffenburger, D. A., and Nolan, G. P. Causal protein-signaling networks derived from multiparameter single-cell data. Science, 308(5721): 523-529, 2005. 3</p>
<p>Learning neural causal models with active interventions. N Scherrer, O Bilaniuk, Y Annadani, A Goyal, P Schwab, B Schölkopf, M C Mozer, Y Bengio, S Bauer, N R Ke, arXiv:2109.0242929arXiv preprintScherrer, N., Bilaniuk, O., Annadani, Y., Goyal, A., Schwab, P., Schölkopf, B., Mozer, M. C., Bengio, Y., Bauer, S., and Ke, N. R. Learning neural causal models with active interventions. arXiv preprint arXiv:2109.02429, 2021. 2, 9</p>
<p>Challenges and opportunities with causal discovery algorithms: application to alzheimer's pathophysiology. X Shen, S Ma, P Vemuri, G Simon, Scientific reports. 1012975Shen, X., Ma, S., Vemuri, P., and Simon, G. Challenges and opportunities with causal discovery algorithms: applica- tion to alzheimer's pathophysiology. Scientific reports, 10(1):2975, 2020. 3</p>
<p>Causation, prediction, and search. P Spirtes, C N Glymour, R Scheines, D Heckerman, MIT pressSpirtes, P., Glymour, C. N., Scheines, R., and Heckerman, D. Causation, prediction, and search. MIT press, 2000.</p>
<p>Near-optimal multiperturbation experimental design for causal structure learning. S Sussex, C Uhler, A Krause, Advances in Neural Information Processing Systems. 349Sussex, S., Uhler, C., and Krause, A. Near-optimal multi- perturbation experimental design for causal structure learning. Advances in Neural Information Processing Systems, 34:777-788, 2021. 1, 2, 4, 8, 9</p>
<p>Interventions, where and how? experimental design for causal models at scale. P Tigas, Y Annadani, A Jesson, B Schölkopf, Y Gal, S Bauer, Advances in Neural Information Processing Systems. 359Tigas, P., Annadani, Y., Jesson, A., Schölkopf, B., Gal, Y., and Bauer, S. Interventions, where and how? experimen- tal design for causal models at scale. Advances in Neural Information Processing Systems, 35, 2022. 1, 2, 4, 8, 9</p>
<p>Active learning for structure in bayesian networks. S Tong, D Koller, International joint conference on artificial intelligence. Citeseer17Tong, S. and Koller, D. Active learning for structure in bayesian networks. In International joint conference on artificial intelligence, volume 17, pp. 863-869. Citeseer, 2001. 1, 2, 5</p>
<p>. C Toth, L Lorch, C Knoll, A Krause, F Pernkopf, R Peharz, Von Kügelgen, arXiv:2206.02063J. Active bayesian causal inference. 89arXiv preprintToth, C., Lorch, L., Knoll, C., Krause, A., Pernkopf, F., Peharz, R., and von Kügelgen, J. Active bayesian causal inference. arXiv preprint arXiv:2206.02063, 2022. 1, 2, 8, 9</p>
<p>Optimal experimental design via bayesian optimization: active causal structure learning for gaussian process networks. J Von Kügelgen, P K Rubenstein, B Schölkopf, A Weller, arXiv:1910.03962arXiv preprintvon Kügelgen, J., Rubenstein, P. K., Schölkopf, B., and Weller, A. Optimal experimental design via bayesian optimization: active causal structure learning for gaus- sian process networks. arXiv preprint arXiv:1910.03962, 2019. 2</p>
<p>S M Xie, S Ermon, arXiv:1901.10517Reparameterizable subset sampling via continuous relaxations. arXiv preprintXie, S. M. and Ermon, S. Reparameterizable subset sampling via continuous relaxations. arXiv preprint arXiv:1901.10517, 2019. 6</p>
<p>Performance of our proposed design strategy for different temperatures of the relaxed distribution for the unconstrained multi-target setting (d = 20). We find that our method is fairly robust. Figure. 11Figure 11: Performance of our proposed design strategy for different temperatures of the relaxed distribution for the unconstrained multi-target setting (d = 20). We find that our method is fairly robust.</p>            </div>
        </div>

    </div>
</body>
</html>