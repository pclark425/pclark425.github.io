<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-6408 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-6408</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-6408</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-126.html">extraction-schema-126</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including model details, task details, prompting methods, performance results, and any analysis of internal mechanisms or failure modes.</div>
                <p><strong>Paper ID:</strong> paper-258959433</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2305.17306v1.pdf" target="_blank">Chain-of-Thought Hub: A Continuous Effort to Measure Large Language Models' Reasoning Performance</a></p>
                <p><strong>Paper Abstract:</strong> As large language models (LLMs) are continuously being developed, their evaluation becomes increasingly important yet challenging. This work proposes Chain-of-Thought Hub, an open-source evaluation suite on the multi-step reasoning capabilities of large language models. We are interested in this setting for two reasons: (1) from the behavior of GPT and PaLM model family, we observe that complex reasoning is likely to be a key differentiator between weaker and stronger LLMs; (2) we envisage large language models to become the next-generation computational platform and foster an ecosystem of LLM-based new applications, this naturally requires the foundation models to perform complex tasks that often involve the composition of linguistic and logical operations. Our approach is to compile a suite of challenging reasoning benchmarks to track the progress of LLMs. Our current results show that: (1) model scale clearly correlates with reasoning capabilities; (2) As of May 2023, Claude-v1.3 and PaLM-2 are the only two models that are comparable with GPT-4, while open-sourced models still lag behind; (3) LLaMA-65B performs closely to code-davinci-002, indicating that with successful further development such as reinforcement learning from human feedback (RLHF), it has great potential to be close to GPT-3.5-Turbo. Our results also suggest that for the open-source efforts to catch up, the community may focus more on building better base models and exploring RLHF.</p>
                <p><strong>Cost:</strong> 0.014</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e6408.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e6408.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including model details, task details, prompting methods, performance results, and any analysis of internal mechanisms or failure modes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>State-of-the-art large language model from OpenAI reported to achieve high accuracy on multi-step arithmetic word problems (GSM8k) and modest performance on advanced competition math (MATH) under chain-of-thought prompting.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>model_family</strong></td>
                            <td>GPT family (large autoregressive transformer)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>GSM8k; MATH</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>Multi-step arithmetic word problems (GSM8k); advanced competition mathematics (MATH)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Natural-language math word problems (GSM8k); LaTeX-written competition problems (MATH)</td>
                        </tr>
                        <tr>
                            <td><strong>difficulty_level</strong></td>
                            <td>GSM8k: grade-school multi-step arithmetic; MATH: very hard competition-level math</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_method</strong></td>
                            <td>Few-shot chain-of-thought prompting (CoT Hub evaluation uses few-shot CoT)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Final-answer accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>GSM8k: 92.0% accuracy; MATH: 42.5% accuracy (values reported in CoT Hub table)</td>
                        </tr>
                        <tr>
                            <td><strong>internal_analysis</strong></td>
                            <td>Paper does not perform mechanistic probes of GPT-4; authors only report final-answer accuracy and note empirically that correctness of intermediate chain-of-thought steps correlates with final accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>No detailed per-error analysis provided; general observation that weaker or smaller models make more mistakes; no specific arithmetic failure patterns (e.g., off-by-one) are documented in this paper for GPT-4.</td>
                        </tr>
                        <tr>
                            <td><strong>scaling_trend</strong></td>
                            <td>High performance consistent with very large / RLHF-tuned models; authors observe a roughly log-linear correlation between model scale and reasoning performance and note RLHF is common among the top performers.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': "Chain-of-Thought Hub: A Continuous Effort to Measure Large Language Models' Reasoning Performance", 'publication_date_yy_mm': '2023-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6408.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e6408.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including model details, task details, prompting methods, performance results, and any analysis of internal mechanisms or failure modes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-3.5-Turbo</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-3.5-Turbo</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A production-tuned variant of the GPT-3.5 family that achieves strong but lower arithmetic reasoning accuracy than GPT-4 on GSM8k under CoT prompting.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5-Turbo</td>
                        </tr>
                        <tr>
                            <td><strong>model_family</strong></td>
                            <td>GPT family (autoregressive transformer)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>GSM8k; MATH</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>Multi-step arithmetic word problems (GSM8k); advanced math (MATH)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Natural-language math word problems; LaTeX competition problems</td>
                        </tr>
                        <tr>
                            <td><strong>difficulty_level</strong></td>
                            <td>GSM8k: grade-school multi-step arithmetic; MATH: competition-level hard</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_method</strong></td>
                            <td>Few-shot chain-of-thought prompting</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Final-answer accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>GSM8k: 74.9% accuracy (marked * tested by authors); MATH: 67.3% (table reports)</td>
                        </tr>
                        <tr>
                            <td><strong>internal_analysis</strong></td>
                            <td>No internal mechanistic analysis; same comment that intermediate step correctness correlates with final answer accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>Paper does not list model-specific arithmetic error modes; overall lower accuracy relative to GPT-4 indicates more frequent multi-step reasoning failures.</td>
                        </tr>
                        <tr>
                            <td><strong>scaling_trend</strong></td>
                            <td>Per authors, instruction-tuned / RLHF models (like GPT-3.5-Turbo) outperform similarly sized base models; performance generally rises with scale (log-linear trend).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': "Chain-of-Thought Hub: A Continuous Effort to Measure Large Language Models' Reasoning Performance", 'publication_date_yy_mm': '2023-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6408.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e6408.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including model details, task details, prompting methods, performance results, and any analysis of internal mechanisms or failure modes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PaLM-2</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>PaLM-2</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Google's PaLM-2 family reported in CoT Hub to achieve strong arithmetic reasoning performance on GSM8k under few-shot chain-of-thought prompting, comparable to top models.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>PaLM-2</td>
                        </tr>
                        <tr>
                            <td><strong>model_family</strong></td>
                            <td>PaLM family (transformer)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>GSM8k; MMLU (also reported)</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>Multi-step arithmetic word problems (GSM8k)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Natural-language math word problems</td>
                        </tr>
                        <tr>
                            <td><strong>difficulty_level</strong></td>
                            <td>GSM8k: grade-school multi-step arithmetic</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_method</strong></td>
                            <td>Few-shot chain-of-thought prompting</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Final-answer accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>GSM8k: 80.7% accuracy (table)</td>
                        </tr>
                        <tr>
                            <td><strong>internal_analysis</strong></td>
                            <td>No interpretability experiments reported; performance numbers taken from PaLM-2 technical report or CoT Hub aggregation.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>Paper does not enumerate arithmetic failure modes for PaLM-2 specifically.</td>
                        </tr>
                        <tr>
                            <td><strong>scaling_trend</strong></td>
                            <td>PaLM family (large scale) performs well; authors note model scale correlates with reasoning performance and that PaLM variants are among the strongest families.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': "Chain-of-Thought Hub: A Continuous Effort to Measure Large Language Models' Reasoning Performance", 'publication_date_yy_mm': '2023-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6408.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e6408.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including model details, task details, prompting methods, performance results, and any analysis of internal mechanisms or failure modes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Claude-v1.3</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Anthropic Claude v1.3</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Anthropic's Claude v1.3 is reported in CoT Hub as an RLHF-aligned model achieving high GSM8k performance using few-shot CoT prompting.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Claude-v1.3</td>
                        </tr>
                        <tr>
                            <td><strong>model_family</strong></td>
                            <td>Claude family (dialogue / assistant models)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>GSM8k; MATH</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>Multi-step arithmetic word problems (GSM8k)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Natural-language word problems</td>
                        </tr>
                        <tr>
                            <td><strong>difficulty_level</strong></td>
                            <td>GSM8k: grade-school multi-step arithmetic; MATH: competition-level</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_method</strong></td>
                            <td>Few-shot chain-of-thought prompting</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Final-answer accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>GSM8k: 81.8% accuracy (marked * tested by authors); MATH: 74.8% (table entry)</td>
                        </tr>
                        <tr>
                            <td><strong>internal_analysis</strong></td>
                            <td>No internal mechanism analysis in this paper; values are reported/performed as part of the benchmark suite.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>No detailed failure-mode breakdown; authors note RLHF-tuned models (Claude variants) sit among top performers.</td>
                        </tr>
                        <tr>
                            <td><strong>scaling_trend</strong></td>
                            <td>Claude variants are strong and among top models; authors reiterate a positive correlation between model scale and reasoning performance and an advantage for RLHF-tuned models.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': "Chain-of-Thought Hub: A Continuous Effort to Measure Large Language Models' Reasoning Performance", 'publication_date_yy_mm': '2023-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6408.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e6408.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including model details, task details, prompting methods, performance results, and any analysis of internal mechanisms or failure modes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>code-davinci-002</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>code-davinci-002</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An OpenAI code-tuned model (base for early GPT-3.5 family) included in CoT Hub and evaluated on GSM8k using few-shot chain-of-thought prompting, showing mid-level arithmetic reasoning performance.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>code-davinci-002</td>
                        </tr>
                        <tr>
                            <td><strong>model_family</strong></td>
                            <td>davinci/code-tuned family (OpenAI)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td>Trained/tuned on code data (implied by name); paper notes code training as a factor for improved GSM8k performance in some models.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>GSM8k; MMLU</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>Multi-step arithmetic word problems (GSM8k)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Natural-language word problems</td>
                        </tr>
                        <tr>
                            <td><strong>difficulty_level</strong></td>
                            <td>GSM8k: grade-school multi-step arithmetic</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_method</strong></td>
                            <td>Few-shot chain-of-thought prompting</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Final-answer accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>GSM8k: 66.6% accuracy (table)</td>
                        </tr>
                        <tr>
                            <td><strong>internal_analysis</strong></td>
                            <td>No mechanistic probes reported; paper notes models trained on code tend to do better on some math reasoning tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>Relative drop vs top models; specific error modes not enumerated in CoT Hub.</td>
                        </tr>
                        <tr>
                            <td><strong>scaling_trend</strong></td>
                            <td>Placed below largest RLHF models; authors note code-tuned models and RLHF both contribute to improved arithmetic reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': "Chain-of-Thought Hub: A Continuous Effort to Measure Large Language Models' Reasoning Performance", 'publication_date_yy_mm': '2023-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6408.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e6408.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including model details, task details, prompting methods, performance results, and any analysis of internal mechanisms or failure modes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLaMA-65B</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLaMA 65B</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Meta's LLaMA 65B base model (open-source) evaluated in CoT Hub; shows competitive general reasoning (MMLU) but comparatively lower GSM8k performance, speculated to be due to lack of code in pretraining.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLaMA-65B</td>
                        </tr>
                        <tr>
                            <td><strong>model_family</strong></td>
                            <td>LLaMA family (Meta; open-source foundation models)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>65B</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td>Reported in paper as 'trained to Chinchilla-optimal' (Hoffmann et al. reference); paper explicitly notes it is 'not trained on code' which may hurt GSM8k performance.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>GSM8k; MMLU</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>Multi-step arithmetic word problems (GSM8k)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Natural-language word problems</td>
                        </tr>
                        <tr>
                            <td><strong>difficulty_level</strong></td>
                            <td>GSM8k: grade-school multi-step arithmetic</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_method</strong></td>
                            <td>Few-shot chain-of-thought prompting (CoT Hub evaluation)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Final-answer accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>GSM8k: 50.9% accuracy; MMLU: 63.4% (table values reported)</td>
                        </tr>
                        <tr>
                            <td><strong>internal_analysis</strong></td>
                            <td>No fine-grained mechanistic analysis; authors attribute relative GSM8k weakness partially to lack of code in pretraining and note potential for improvement via SFT/RLHF.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>Lower performance on GSM8k compared to code-trained or RLHF models; paper attributes this to training data differences (absence of code) and lack of RLHF tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>scaling_trend</strong></td>
                            <td>Even as a large open-source model, it lags behind RLHF-tuned closed models; authors view LLaMA-65B as having strong potential if followed by SFT and RLHF.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': "Chain-of-Thought Hub: A Continuous Effort to Measure Large Language Models' Reasoning Performance", 'publication_date_yy_mm': '2023-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6408.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e6408.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including model details, task details, prompting methods, performance results, and any analysis of internal mechanisms or failure modes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Minerva (540B SIFT)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Minerva (540B, supervised instruction finetuned)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A math-specialized variant (Minerva) reported from Lewkowycz et al.; included in CoT Hub with measured GSM8k and MATH performance under chain-of-thought style evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Minerva (540B, SIFT)</td>
                        </tr>
                        <tr>
                            <td><strong>model_family</strong></td>
                            <td>PaLM-derived / large math-specialized model</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>540B</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td>Specialized finetuning/data for quantitative reasoning as reported in Lewkowycz et al.; exact CoT Hub description references that source for Minerva's performance.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>GSM8k; MATH</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>Multi-step arithmetic word problems (GSM8k); quantitative reasoning (MATH)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Natural-language word problems; quantitative reasoning prompts</td>
                        </tr>
                        <tr>
                            <td><strong>difficulty_level</strong></td>
                            <td>GSM8k: grade-school multi-step arithmetic; MATH: competition-level</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_method</strong></td>
                            <td>CoT-style prompting / SIFT (as reported in source papers and aggregated by CoT Hub)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Final-answer accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>GSM8k: 58.8% accuracy; MATH: 33.6% (values reported in CoT Hub table, sourced from Lewkowycz et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>internal_analysis</strong></td>
                            <td>CoT Hub does not add mechanistic analysis; Minerva's original work contains more details (see follow-on papers).</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>Not detailed in CoT Hub; Minerva focused on math-specialized finetuning to improve failures seen in general models.</td>
                        </tr>
                        <tr>
                            <td><strong>scaling_trend</strong></td>
                            <td>Large-scale SIFT-specialized models show improved math performance relative to non-specialized counterparts, per aggregated results.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': "Chain-of-Thought Hub: A Continuous Effort to Measure Large Language Models' Reasoning Performance", 'publication_date_yy_mm': '2023-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6408.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e6408.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including model details, task details, prompting methods, performance results, and any analysis of internal mechanisms or failure modes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PaLM (540B)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>PaLM 540B</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Google's 540B PaLM base model is reported in CoT Hub and shows moderate arithmetic reasoning accuracy on GSM8k under CoT prompting.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>PaLM 540B</td>
                        </tr>
                        <tr>
                            <td><strong>model_family</strong></td>
                            <td>PaLM family (large transformer)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>540B</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>GSM8k</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>Multi-step arithmetic word problems (GSM8k)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Natural-language word problems</td>
                        </tr>
                        <tr>
                            <td><strong>difficulty_level</strong></td>
                            <td>GSM8k: grade-school multi-step arithmetic</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_method</strong></td>
                            <td>Few-shot chain-of-thought prompting</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Final-answer accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>GSM8k: 56.9% accuracy (table)</td>
                        </tr>
                        <tr>
                            <td><strong>internal_analysis</strong></td>
                            <td>No internal mechanism probing in CoT Hub; results aggregated from PaLM reporting.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>Not detailed; authors display that base PaLM lags behind its instruction-tuned / SFT variants and RLHF models on reasoning benchmarks.</td>
                        </tr>
                        <tr>
                            <td><strong>scaling_trend</strong></td>
                            <td>Despite large scale, instruction tuning (SFT) and RLHF further improve PaLM-family performance; raw base scale alone is not the only factor.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': "Chain-of-Thought Hub: A Continuous Effort to Measure Large Language Models' Reasoning Performance", 'publication_date_yy_mm': '2023-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Training verifiers to solve math word problems <em>(Rating: 2)</em></li>
                <li>Chain of thought prompting elicits reasoning in large language models <em>(Rating: 2)</em></li>
                <li>Solving quantitative reasoning problems with language models <em>(Rating: 2)</em></li>
                <li>Measuring mathematical problem solving with the MATH dataset <em>(Rating: 2)</em></li>
                <li>Scaling language modeling with pathways <em>(Rating: 1)</em></li>
                <li>GPT-4 technical report <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-6408",
    "paper_id": "paper-258959433",
    "extraction_schema_id": "extraction-schema-126",
    "extracted_data": [
        {
            "name_short": "GPT-4",
            "name_full": "GPT-4",
            "brief_description": "State-of-the-art large language model from OpenAI reported to achieve high accuracy on multi-step arithmetic word problems (GSM8k) and modest performance on advanced competition math (MATH) under chain-of-thought prompting.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "GPT-4",
            "model_family": "GPT family (large autoregressive transformer)",
            "model_size": null,
            "training_data_description": null,
            "benchmark_name": "GSM8k; MATH",
            "task_type": "Multi-step arithmetic word problems (GSM8k); advanced competition mathematics (MATH)",
            "problem_format": "Natural-language math word problems (GSM8k); LaTeX-written competition problems (MATH)",
            "difficulty_level": "GSM8k: grade-school multi-step arithmetic; MATH: very hard competition-level math",
            "prompting_method": "Few-shot chain-of-thought prompting (CoT Hub evaluation uses few-shot CoT)",
            "performance_metric": "Final-answer accuracy",
            "performance_value": "GSM8k: 92.0% accuracy; MATH: 42.5% accuracy (values reported in CoT Hub table)",
            "internal_analysis": "Paper does not perform mechanistic probes of GPT-4; authors only report final-answer accuracy and note empirically that correctness of intermediate chain-of-thought steps correlates with final accuracy.",
            "failure_modes": "No detailed per-error analysis provided; general observation that weaker or smaller models make more mistakes; no specific arithmetic failure patterns (e.g., off-by-one) are documented in this paper for GPT-4.",
            "scaling_trend": "High performance consistent with very large / RLHF-tuned models; authors observe a roughly log-linear correlation between model scale and reasoning performance and note RLHF is common among the top performers.",
            "uuid": "e6408.0",
            "source_info": {
                "paper_title": "Chain-of-Thought Hub: A Continuous Effort to Measure Large Language Models' Reasoning Performance",
                "publication_date_yy_mm": "2023-05"
            }
        },
        {
            "name_short": "GPT-3.5-Turbo",
            "name_full": "GPT-3.5-Turbo",
            "brief_description": "A production-tuned variant of the GPT-3.5 family that achieves strong but lower arithmetic reasoning accuracy than GPT-4 on GSM8k under CoT prompting.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "GPT-3.5-Turbo",
            "model_family": "GPT family (autoregressive transformer)",
            "model_size": null,
            "training_data_description": null,
            "benchmark_name": "GSM8k; MATH",
            "task_type": "Multi-step arithmetic word problems (GSM8k); advanced math (MATH)",
            "problem_format": "Natural-language math word problems; LaTeX competition problems",
            "difficulty_level": "GSM8k: grade-school multi-step arithmetic; MATH: competition-level hard",
            "prompting_method": "Few-shot chain-of-thought prompting",
            "performance_metric": "Final-answer accuracy",
            "performance_value": "GSM8k: 74.9% accuracy (marked * tested by authors); MATH: 67.3% (table reports)",
            "internal_analysis": "No internal mechanistic analysis; same comment that intermediate step correctness correlates with final answer accuracy.",
            "failure_modes": "Paper does not list model-specific arithmetic error modes; overall lower accuracy relative to GPT-4 indicates more frequent multi-step reasoning failures.",
            "scaling_trend": "Per authors, instruction-tuned / RLHF models (like GPT-3.5-Turbo) outperform similarly sized base models; performance generally rises with scale (log-linear trend).",
            "uuid": "e6408.1",
            "source_info": {
                "paper_title": "Chain-of-Thought Hub: A Continuous Effort to Measure Large Language Models' Reasoning Performance",
                "publication_date_yy_mm": "2023-05"
            }
        },
        {
            "name_short": "PaLM-2",
            "name_full": "PaLM-2",
            "brief_description": "Google's PaLM-2 family reported in CoT Hub to achieve strong arithmetic reasoning performance on GSM8k under few-shot chain-of-thought prompting, comparable to top models.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "PaLM-2",
            "model_family": "PaLM family (transformer)",
            "model_size": null,
            "training_data_description": null,
            "benchmark_name": "GSM8k; MMLU (also reported)",
            "task_type": "Multi-step arithmetic word problems (GSM8k)",
            "problem_format": "Natural-language math word problems",
            "difficulty_level": "GSM8k: grade-school multi-step arithmetic",
            "prompting_method": "Few-shot chain-of-thought prompting",
            "performance_metric": "Final-answer accuracy",
            "performance_value": "GSM8k: 80.7% accuracy (table)",
            "internal_analysis": "No interpretability experiments reported; performance numbers taken from PaLM-2 technical report or CoT Hub aggregation.",
            "failure_modes": "Paper does not enumerate arithmetic failure modes for PaLM-2 specifically.",
            "scaling_trend": "PaLM family (large scale) performs well; authors note model scale correlates with reasoning performance and that PaLM variants are among the strongest families.",
            "uuid": "e6408.2",
            "source_info": {
                "paper_title": "Chain-of-Thought Hub: A Continuous Effort to Measure Large Language Models' Reasoning Performance",
                "publication_date_yy_mm": "2023-05"
            }
        },
        {
            "name_short": "Claude-v1.3",
            "name_full": "Anthropic Claude v1.3",
            "brief_description": "Anthropic's Claude v1.3 is reported in CoT Hub as an RLHF-aligned model achieving high GSM8k performance using few-shot CoT prompting.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "Claude-v1.3",
            "model_family": "Claude family (dialogue / assistant models)",
            "model_size": null,
            "training_data_description": null,
            "benchmark_name": "GSM8k; MATH",
            "task_type": "Multi-step arithmetic word problems (GSM8k)",
            "problem_format": "Natural-language word problems",
            "difficulty_level": "GSM8k: grade-school multi-step arithmetic; MATH: competition-level",
            "prompting_method": "Few-shot chain-of-thought prompting",
            "performance_metric": "Final-answer accuracy",
            "performance_value": "GSM8k: 81.8% accuracy (marked * tested by authors); MATH: 74.8% (table entry)",
            "internal_analysis": "No internal mechanism analysis in this paper; values are reported/performed as part of the benchmark suite.",
            "failure_modes": "No detailed failure-mode breakdown; authors note RLHF-tuned models (Claude variants) sit among top performers.",
            "scaling_trend": "Claude variants are strong and among top models; authors reiterate a positive correlation between model scale and reasoning performance and an advantage for RLHF-tuned models.",
            "uuid": "e6408.3",
            "source_info": {
                "paper_title": "Chain-of-Thought Hub: A Continuous Effort to Measure Large Language Models' Reasoning Performance",
                "publication_date_yy_mm": "2023-05"
            }
        },
        {
            "name_short": "code-davinci-002",
            "name_full": "code-davinci-002",
            "brief_description": "An OpenAI code-tuned model (base for early GPT-3.5 family) included in CoT Hub and evaluated on GSM8k using few-shot chain-of-thought prompting, showing mid-level arithmetic reasoning performance.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "code-davinci-002",
            "model_family": "davinci/code-tuned family (OpenAI)",
            "model_size": null,
            "training_data_description": "Trained/tuned on code data (implied by name); paper notes code training as a factor for improved GSM8k performance in some models.",
            "benchmark_name": "GSM8k; MMLU",
            "task_type": "Multi-step arithmetic word problems (GSM8k)",
            "problem_format": "Natural-language word problems",
            "difficulty_level": "GSM8k: grade-school multi-step arithmetic",
            "prompting_method": "Few-shot chain-of-thought prompting",
            "performance_metric": "Final-answer accuracy",
            "performance_value": "GSM8k: 66.6% accuracy (table)",
            "internal_analysis": "No mechanistic probes reported; paper notes models trained on code tend to do better on some math reasoning tasks.",
            "failure_modes": "Relative drop vs top models; specific error modes not enumerated in CoT Hub.",
            "scaling_trend": "Placed below largest RLHF models; authors note code-tuned models and RLHF both contribute to improved arithmetic reasoning.",
            "uuid": "e6408.4",
            "source_info": {
                "paper_title": "Chain-of-Thought Hub: A Continuous Effort to Measure Large Language Models' Reasoning Performance",
                "publication_date_yy_mm": "2023-05"
            }
        },
        {
            "name_short": "LLaMA-65B",
            "name_full": "LLaMA 65B",
            "brief_description": "Meta's LLaMA 65B base model (open-source) evaluated in CoT Hub; shows competitive general reasoning (MMLU) but comparatively lower GSM8k performance, speculated to be due to lack of code in pretraining.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "LLaMA-65B",
            "model_family": "LLaMA family (Meta; open-source foundation models)",
            "model_size": "65B",
            "training_data_description": "Reported in paper as 'trained to Chinchilla-optimal' (Hoffmann et al. reference); paper explicitly notes it is 'not trained on code' which may hurt GSM8k performance.",
            "benchmark_name": "GSM8k; MMLU",
            "task_type": "Multi-step arithmetic word problems (GSM8k)",
            "problem_format": "Natural-language word problems",
            "difficulty_level": "GSM8k: grade-school multi-step arithmetic",
            "prompting_method": "Few-shot chain-of-thought prompting (CoT Hub evaluation)",
            "performance_metric": "Final-answer accuracy",
            "performance_value": "GSM8k: 50.9% accuracy; MMLU: 63.4% (table values reported)",
            "internal_analysis": "No fine-grained mechanistic analysis; authors attribute relative GSM8k weakness partially to lack of code in pretraining and note potential for improvement via SFT/RLHF.",
            "failure_modes": "Lower performance on GSM8k compared to code-trained or RLHF models; paper attributes this to training data differences (absence of code) and lack of RLHF tuning.",
            "scaling_trend": "Even as a large open-source model, it lags behind RLHF-tuned closed models; authors view LLaMA-65B as having strong potential if followed by SFT and RLHF.",
            "uuid": "e6408.5",
            "source_info": {
                "paper_title": "Chain-of-Thought Hub: A Continuous Effort to Measure Large Language Models' Reasoning Performance",
                "publication_date_yy_mm": "2023-05"
            }
        },
        {
            "name_short": "Minerva (540B SIFT)",
            "name_full": "Minerva (540B, supervised instruction finetuned)",
            "brief_description": "A math-specialized variant (Minerva) reported from Lewkowycz et al.; included in CoT Hub with measured GSM8k and MATH performance under chain-of-thought style evaluation.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "Minerva (540B, SIFT)",
            "model_family": "PaLM-derived / large math-specialized model",
            "model_size": "540B",
            "training_data_description": "Specialized finetuning/data for quantitative reasoning as reported in Lewkowycz et al.; exact CoT Hub description references that source for Minerva's performance.",
            "benchmark_name": "GSM8k; MATH",
            "task_type": "Multi-step arithmetic word problems (GSM8k); quantitative reasoning (MATH)",
            "problem_format": "Natural-language word problems; quantitative reasoning prompts",
            "difficulty_level": "GSM8k: grade-school multi-step arithmetic; MATH: competition-level",
            "prompting_method": "CoT-style prompting / SIFT (as reported in source papers and aggregated by CoT Hub)",
            "performance_metric": "Final-answer accuracy",
            "performance_value": "GSM8k: 58.8% accuracy; MATH: 33.6% (values reported in CoT Hub table, sourced from Lewkowycz et al.)",
            "internal_analysis": "CoT Hub does not add mechanistic analysis; Minerva's original work contains more details (see follow-on papers).",
            "failure_modes": "Not detailed in CoT Hub; Minerva focused on math-specialized finetuning to improve failures seen in general models.",
            "scaling_trend": "Large-scale SIFT-specialized models show improved math performance relative to non-specialized counterparts, per aggregated results.",
            "uuid": "e6408.6",
            "source_info": {
                "paper_title": "Chain-of-Thought Hub: A Continuous Effort to Measure Large Language Models' Reasoning Performance",
                "publication_date_yy_mm": "2023-05"
            }
        },
        {
            "name_short": "PaLM (540B)",
            "name_full": "PaLM 540B",
            "brief_description": "Google's 540B PaLM base model is reported in CoT Hub and shows moderate arithmetic reasoning accuracy on GSM8k under CoT prompting.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "PaLM 540B",
            "model_family": "PaLM family (large transformer)",
            "model_size": "540B",
            "training_data_description": null,
            "benchmark_name": "GSM8k",
            "task_type": "Multi-step arithmetic word problems (GSM8k)",
            "problem_format": "Natural-language word problems",
            "difficulty_level": "GSM8k: grade-school multi-step arithmetic",
            "prompting_method": "Few-shot chain-of-thought prompting",
            "performance_metric": "Final-answer accuracy",
            "performance_value": "GSM8k: 56.9% accuracy (table)",
            "internal_analysis": "No internal mechanism probing in CoT Hub; results aggregated from PaLM reporting.",
            "failure_modes": "Not detailed; authors display that base PaLM lags behind its instruction-tuned / SFT variants and RLHF models on reasoning benchmarks.",
            "scaling_trend": "Despite large scale, instruction tuning (SFT) and RLHF further improve PaLM-family performance; raw base scale alone is not the only factor.",
            "uuid": "e6408.7",
            "source_info": {
                "paper_title": "Chain-of-Thought Hub: A Continuous Effort to Measure Large Language Models' Reasoning Performance",
                "publication_date_yy_mm": "2023-05"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Training verifiers to solve math word problems",
            "rating": 2,
            "sanitized_title": "training_verifiers_to_solve_math_word_problems"
        },
        {
            "paper_title": "Chain of thought prompting elicits reasoning in large language models",
            "rating": 2,
            "sanitized_title": "chain_of_thought_prompting_elicits_reasoning_in_large_language_models"
        },
        {
            "paper_title": "Solving quantitative reasoning problems with language models",
            "rating": 2,
            "sanitized_title": "solving_quantitative_reasoning_problems_with_language_models"
        },
        {
            "paper_title": "Measuring mathematical problem solving with the MATH dataset",
            "rating": 2,
            "sanitized_title": "measuring_mathematical_problem_solving_with_the_math_dataset"
        },
        {
            "paper_title": "Scaling language modeling with pathways",
            "rating": 1,
            "sanitized_title": "scaling_language_modeling_with_pathways"
        },
        {
            "paper_title": "GPT-4 technical report",
            "rating": 2,
            "sanitized_title": "gpt4_technical_report"
        }
    ],
    "cost": 0.0144525,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Chain-of-Thought Hub: A Continuous Effort to Measure Large Language Models' Reasoning Performance
26 May 2023</p>
<p>Yao Fu yao.fu@ed.ac.uk 
University of Edinburgh  University of Washington
Allen Institute for AI</p>
<p> Litu 
University of Edinburgh  University of Washington
Allen Institute for AI</p>
<p>Ou  Mingyu 
University of Edinburgh  University of Washington
Allen Institute for AI</p>
<p>Chen  Yuhao yuhaowan@cs.washington.edu 
University of Edinburgh  University of Washington
Allen Institute for AI</p>
<p>Wan  Hao Peng 
University of Edinburgh  University of Washington
Allen Institute for AI</p>
<p>Tushar Khot tushark@allenai.org 
University of Edinburgh  University of Washington
Allen Institute for AI</p>
<p>Chain-of-Thought Hub: A Continuous Effort to Measure Large Language Models' Reasoning Performance
26 May 202365C3D3EFA0CEC1830986A8277513A559arXiv:2305.17306v1[cs.CL]
As large language models (LLMs) are continuously being developed, their evaluation becomes increasingly important yet challenging.This work proposes Chain-of-Thought Hub, an open-source evaluation suite on the multi-step reasoning capabilities of large language models.We are interested in this setting for two reasons: (1) from the behavior of GPT and PaLM model family, we observe that complex reasoning is likely to be a key differentiator between weaker and stronger LLMs;(2) we envisage large language models to become the next-generation computational platform and foster an ecosystem of LLM-based new applications, this naturally requires the foundation models to perform complex tasks that often involve the composition of linguistic and logical operations.Our approach is to compile a suite of challenging reasoning benchmarks to track the progress of LLMs.Our current results show that:(1) model scale clearly correlates with reasoning capabilities; (2) As of May 2023, Claude-v1.3and PaLM-2 are the only two models that are comparable with GPT-4, while open-sourced models still lag behind; (3) LLaMA-65B performs closely to code-davinci-002, indicating that with successful further development such as reinforcement learning from human feedback (RLHF), it has great potential to be close to GPT-3.5-Turbo.Our results also suggest that for the open-source efforts to catch up, the community may focus more on building better base models and exploring RLHF.</p>
<p>Introduction</p>
<p>Recently, the field of AI has been significantly impressed by the advances in large language models.LLMs exhibit multi-dimensional capabilities, and their evaluation is challenging.Generally, tuning a base language model into a chatbot is relatively easy, as demonstrated by the large variety of LLaMA-based (Touvron et al., 2023) models like Alpaca (Taori et al., 2023), Vicuna (Chiang et al., 2023), Koala (Geng et al., 2023), Dolly (Databricks, 2023), and so on.In a chitchat, all these models may perform superficially similarly to GPT-3.5-Turbo (Gudibande et al., 2023).At the current stage, the community is eager to know what are the key factors that clearly differentiate the better-performing models from the underperforming ones.</p>
<p>In this work, we consider the evaluation of complex reasoning.As noted by OpenAI (2023b), "In a casual conversation, the distinction between GPT-3.5 and GPT-4 can be subtle.The difference comes out when the complexity of the task reaches a sufficient threshold".A similar observation is made by the Google PaLM model family, as their developers discover that large models' chain-of-thought reasoning capability is clearly stronger than smaller models (Wei et al., 2022b;a).These observations indicate that the ability to perform complex tasks is a key metric.</p>
<p>The capability of performing complex reasoning is crucial for the models to become the next-generation computation platform.One example initiative is LangChain1 where developers build applications powered by backend LLM engines, which generally require the model to perform complex tasks.Here the vision of pushing LLMs as the foundation of a new computational ecosystem also serves as a strong motivation to measure the models' reasoning performance.</p>
<p>To incentivize the research efforts in improving language models' reasoning performance, we propose the chain-ofthought hub (CoT Hub), a continuous open-source effort that tracks LLMs' reasoning capability using a carefully curated evaluation suite.CoT Hub is the first comprehensive comparison of very large LMs on reasoning benchmarks and currently consists of 19 major language models' (including the GPT, Claude, PaLM and LLaMA) performance on 6 benchmarks and more than 100 subtasks (including bi-lingual reasoning capabilities in Chinese), and we are continuously adding new models and datasets.</p>
<p>Observations made in CoT Hub shed light on many insights into LLM development: (1) the reasoning performance of LLMs highly correlates with models' scales; (2) as of May 2023, PaLM and Claude2 are the only two model families that are comparable to (yet slightly worse than) the GPT model family; (2) LLaMA 65B (Touvron et al., 2023) the strongest open LLM to date, performs closely to codedavinci-002, the base model of GPT-3.5 family3 .This indicates that if aligned properly (by doing supervised finetuning (SFT) and reinforcement learning from human feedback (RLHF) right) LLaMA 65B can potentially improve further and perform on par with ChatGPT-3.5.We hope our work gives meaningful guidance to the community's development of deployable LLMs.</p>
<p>Method</p>
<p>In this section we discuss the construction of Chain-of-Thought Hub.We first discuss our method for test data collection, then we discuss how we obtain the model performance on our test suite.Our main goal is to curate a high-quality collection of datasets that (1) is closely related to the actual usage of LLMs; (2) clearly differentiate the performance of stronger and weaker language models.We consider the following datasets:</p>
<p>GSM8k A widely used math reasoning datasets consisting of 8k problems that jointly test models' ability of arithmetic reasoning and composing math steps using language (Cobbe et al., 2021).</p>
<p>MATH A suite of challenging datasets consisting of 12k problems within 7 categories testing the models' advanced math and science reasoning.The problems in this dataset are very hard because they come from mathematics competitions written in Latex.Even GPT-4 has only 42.5% performance (Hendrycks et al., 2021).</p>
<p>MMLU An evaluation suite of 15k problems within 57 subjects testing model's high-school and college-level knowledge and reasoning (Hendrycks et al., 2020).</p>
<p>BigBench Hard A suite of language and symbolic reasoning tasks consisting 6.5k problems within 23 subsets that are particularly suitable for testing chain-ofthought prompting (Suzgun et al., 2022).</p>
<p>HumanEval A handwritten dataset of 164 Python programming problems with text comments and docstrings testing the models' coding ability (Chen et al., 2021).</p>
<p>C-Eval A Chinese evaluation suite for foundation models consisting of 13k multi-choice questions spanning 52 diverse disciplines and four difficulty levels (Huang et al., 2023).</p>
<p>We note that most of these datasets are already used in the evaluation of leading large language models, such as GPT-4 (OpenAI, 2023a) and PaLM-2 (Anil et al., 2023).</p>
<p>Few-Shot Chain-of-thought Prompting</p>
<p>We use fewshot chain-of-thought prompting to evaluate LLMs.This marks a clear difference between our evaluation and the majority of other concurrent evaluations like HeLM (Liang et al., 2022), as most of them use answer-only prompting.We also emphasize that we use few-shot, rather than zeroshot prompting, because few-shot is a capability that exist in both pretrained and instruction-tuned checkpoints, v.s., zero-shot is more suitable for instruction-tuned checkpoints and may under-estimate the pretrained checkpoints.</p>
<p>Comparison to existing and concurrent work</p>
<p>There are many great existing evaluation suites for large language models, such as HeLM, Chatbot Arena4 , and Open LLM Leaderboard5 .The major difference between this work and these works are: (1) HeLM evaluates a significantly wider spectrum of tasks while we focus on evaluating reasoning.Most of the results from this work use chain-ofthought prompting (hence the name "Chain-of-Thought Hub") whereas HeLM mainly uses answer-only prompting (without CoT).( 2</p>
<p>Using final answer accuracy as a proxy for reasoning capability</p>
<p>Most of the datasets we consider share one pattern: to reach the final answer (either a number for math problems, a choice for multi-choice problems, or a fixed output for coding), the model needs to figure out the intermediate steps toward that answer.When evaluating, we only use the final answer accuracy but do not consider the correctness of intermediate steps.This is because empirically, the correctness of intermediate steps is strongly correlated with the final accuracy.If the intermediate steps are very wrong, the model is less likely to reach the final answer.If the final answer is correct, the intermediate steps are generally good enough (Wei et al., 2022b;Lewkowycz et al., 2022).</p>
<p>Experiments</p>
<p>First we discuss the model families we consider.We focus on the popular models in production, including GPT, Claude, PaLM, LLaMA, and T5 model families, specifically: OpenAI GPT including GPT-4 (currently strongest), GPT-3.5-Turbo(faster but less capable), text-davinci-003, text-davinci-002, and code-davinci-002 (important previous versions before Turbo).See Fu &amp; Khot (2022) for a comprehensive discussion.</p>
<p>Anthropic Claude including claude-v1.3(slower but more capable) and claude-instant-v1.0 (faster but less capable) 6 .Strong competitor's GPT models.Google FlanT5 instruction-tuned T5 models demonstrating strong performance in the smaller model regime.</p>
<p>Google</p>
<p>We report these models' performance on our CoT Hub suite.We note that due to the wide spectrum of the tasks and models we consider, the evaluation is nontrivial and even running inference takes effort.In addition, there are models 6 https://console.anthropic.com/docs/api/reference that do not offer public access (such as PaLM), such that evaluating them is difficult.For these reasons, we report numbers using the following strategy: if the performance of a model is already reported in a paper, we refer to that paper; otherwise, we test them by ourselves.Note that this strategy is not comprehensive, as we still have a fraction of untested non-public models on some datasets.This is partly the reason we view our CoT Hub as a continuous effort.</p>
<p>Table 1 shows the overall results.We rank the models using GSM8k performance because it is a classical benchmark testing models' reasoning capabilities.Numbers marked by an asterisk are tested by ourselves, others are from the following sources: GPT-4 and PaLM-2 results are from their technical report (OpenAI, 2023a;Anil et al., 2023) respectively; GPT-3.5-Turbo'sperformance on HumanEval is also from OpenAI (2023a).Text-davinci-003, code-davinci-002 and text-davinci-002 performance are from the appendix in Chung et al. (2022) and from Fu et al. (2022).Minerva's performance is from Lewkowycz et al. (2022).PaLM's performance is from Chowdhery et al. (2022).Flan-PaLM and FlanT5 performance are from Chung et al. (2022).LLaMA's performance is from Touvron et al. (2023).</p>
<p>The gap between open-source and leading LLMs In Leading LLMs are after RLHF We observe that except for PaLM-2, the top 6 models on the leaderboard are after reinforcement learning from human feedback.This strongly indicates the effectiveness of RLHF.Given that RLHF is still an underexplored area, we strongly encourage the community to study more on this topic.</p>
<p>Correlation between model scale and reasoning</p>
<p>We further study the relationship between model scale and models' reasoning performance by visualizing model performance against model scale.Results are shown in Fig. 1.We see that: (1) generally, model performance is correlated with model scale, showing approximately a log-linear trend;</p>
<p>(2) models that do not disclose their scale generally perform better than models that do, indicating that there is still a gap between open-source and close-source.</p>
<p>On the potential of LLaMA-65B</p>
<p>Finally, we would like to highlight the impressive performance of LLaMA 65B.On MMLU it is close to code-davinci-002, the base model of GPT-3.5 series.On GSM8k, it is worse (presumably because it is not trained on code) but close and much better than other open-sourced models (presumably because it is trained to Chinchilla-optimal Hoffmann et al., 2022).Combining this observation with the fact that GPT-3.5-Turbo(ChatGPT) is an RLHF model based on codedavinci-002, it may be possible to reproduce ChatGPT based on LLaMA 65B by applying the RLHF techniques discussed in DeepMind Sparrow (Glaese et al., 2022) and Anthropic Claude (Askell et al., 2021;Bai et al., 2022a;b).</p>
<p>Conclusion and Future Work</p>
<p>In this work, we propose Chain-of-Thought Hub, an opensource, continuous effort to measure the reasoning capability of very large language models.Our results clearly show the performance differences between smaller and larger models, and between close-source and open-source models.</p>
<p>After carefully examining the results, we show two important directions for further improving open-sourced models: building better base models and exploring RLHF.We also point out the great potential of LLaMA 65B: if aligned properly by better SFT and RLHF, it could be possible to perform on par with ChatGPT-3.5.</p>
<p>In the future, we plan to further extend CoT Hub by: (1) including more carefully chozen reasoning datasets, especially datasets measuring commonsense reasoning, math theorem proving, and the ability to call outside APIs; (2) including more language models, such as LLaMA-based, instructionfinetuned models like Vicuna7 and models through API access like Cohere8 and PaLM-2 chat-bison-0019 .(3) exploring methods for solving MATH, the probably most challenging datasets (recall that it consists of math-ematics competitions written in Latex), by calling APIs that compute symbolic and numerical calculus (like Wolfram Alpha10 ).In summary, we believe our work serves as an evaluation platform that guides the development of open-source large language models.</p>
<p>) Chatbot Arena evaluate the dialog user preference we evaluate reasoning.(3) Open LLM Leaderboard focus on open-sourced LLMs, we jointly consider major LLMs, either open-sourced or not.</p>
<p>PaLM including PaLM, PaLM-2, and their instruction-tuned versions (FLan-PaLM and Flan-U-PaLM).Strong base and instruction-tuned models.Meta LLaMA including the 7B, 13B, 33B and 65B variants.Important open-sourced base models.</p>
<p>Figure 1 .
1
Figure 1.X-axis means the log of the model scale measured in billion parameters.We observe that model performance is generally correlated with scale, approximately showing a log-linear trend.Models without disclosing their scale generally perform better than models disclosing scale information.Our observations also indicate that the open-source community may still needs to explore/ figure out "the moat" about the scaling and RLHF for further improvements.</p>
<p>Table 1 .
1
Overall model performance on Chain-of-Thought Hub.Numbers with an asterisk<em> are from our test scripts.For model types, base means the model checkpoint after pretraining, SIFT means supervised instruction finetuning.Others are from their corresponding papers.We observe: (1) there exist a gap between leading LLMs (GPT, Claude and PaLM) and open-source (LLaMA and FlanT5);(2) most leading LLMs are after RLHF, indicating the opportunity of improving open-sourced models using this technique; (3).model performance is generally correlated with model scale, indicating further opportunities in scaling, especially for open-source models.We further highlight that among open-sourced models, LLaMA 65B performs close to code-davinci-002, the base model of ChatGPT.This suggests that if RLHF is done right on LLaMA 65B, it may become close to ChatGPT.
Model#Params TypeGSM8k MATH MMLU BBH HumanEval C-EvalGPT-4?RLHF92.042.586.4-67.068.7</em>claude-v1.3?RLHF81.8<em>-74.8</em>67.3<em>-54.2</em>PaLM-2?Base80.734.378.378.1--gpt-3.5-turbo?RLHF74.9<em>-67.3</em>70.1<em>48.154.4</em>claude-instant-v1.0 ?RLHF70.8<em>--66.9</em>-54.9<em>text-davinci-003?RLHF--64.670.7--code-davinci-002?Base66.619.164.573.747.0-Minerva540BSIFT58.833.6----Flan-PaLM540BSIFT--70.966.3--Flan-U-PaLM540BSIFT--69.864.9--PaLM540BBase56.98.862.962.026.2-text-davinci-002?SIFT55.4-60.067.2--PaLM64BBase52.44.449.042.3--LLaMA65BBase50.910.663.4-23.738.8</em>LLaMA33BBase35.67.157.8-21.7-LLaMA13BBase17.83.946.9-15.8-Flan-T511BSIFT16.1<em>-48.641.4--LLaMA7BBase11.02.935.1-10.5-Flan-T53BSIFT13.5</em>-45.535.2--
https://github.com/hwchase17/langchain
https://www.anthropic.com/index/introducing-claude
https://platform.openai.com/docs/model-index-forresearchers
https://leaderboard.lmsys.org/
https://huggingface.co/spaces/HuggingFaceH4/open llm leaderboard
https://lmsys.org/blog/2023-03-30-vicuna/
https://cohere.com/generate
https://cloud.google.com/vertex-ai
https://www.wolframalpha.com/</p>
<p>. R Anil, A M Dai, O Firat, M Johnson, D Lepikhin, A Passos, S Shakeri, E Taropa, P Bailey, Z Chen, arXiv:2305.104032023arXiv preprint</p>
<p>A Askell, Y Bai, A Chen, D Drain, D Ganguli, T Henighan, A Jones, N Joseph, B Mann, N Dassarma, arXiv:2112.00861A general language assistant as a laboratory for alignment. 2021arXiv preprint</p>
<p>Training a helpful and harmless assistant with reinforcement learning from human feedback. Y Bai, A Jones, K Ndousse, A Askell, A Chen, N Das-Sarma, D Drain, S Fort, D Ganguli, T Henighan, arXiv:2204.058622022aarXiv preprint</p>
<p>Y Bai, S Kadavath, S Kundu, A Askell, J Kernion, A Jones, A Chen, A Goldie, A Mirhoseini, C Mckinnon, arXiv:2212.08073Constitutional ai: Harmlessness from ai feedback. 2022barXiv preprint</p>
<p>M Chen, J Tworek, H Jun, Q Yuan, H P D O Pinto, J Kaplan, H Edwards, Y Burda, N Joseph, G Brockman, arXiv:2107.03374Evaluating large language models trained on code. 2021arXiv preprint</p>
<p>An open-source chatbot impressing gpt-4 with 90%* chatgpt quality. W.-L Chiang, Z Li, Z Lin, Y Sheng, Z Wu, H Zhang, L Zheng, S Zhuang, Y Zhuang, J E Gonzalez, I Stoica, E P Xing, Vicuna, March 2023</p>
<p>A Chowdhery, S Narang, J Devlin, M Bosma, G Mishra, A Roberts, P Barham, H W Chung, C Sutton, S Gehrmann, arXiv:2204.02311Scaling language modeling with pathways. 2022arXiv preprint</p>
<p>Scaling instruction-finetuned language models. H W Chung, L Hou, S Longpre, B Zoph, Y Tay, W Fedus, E Li, X Wang, M Dehghani, S Brahma, arXiv:2210.114162022arXiv preprint</p>
<p>K Cobbe, V Kosaraju, M Bavarian, M Chen, H Jun, L Kaiser, M Plappert, J Tworek, J Hilton, R Nakano, arXiv:2110.14168Training verifiers to solve math word problems. 2021arXiv preprint</p>
<p>Free dolly: Introducing the world's first truly open instruction-tuned llm. Blog post. Databricks, April 2023</p>
<p>. Yao Fu, </p>
<p>How does gpt obtain its ability? tracing emergent abilities of language models to their sources. Yao Fu's Notion. H Peng, T Khot, Y Fu, H Peng, A Sabharwal, P Clark, T Khot, arXiv:2210.00720Complexity-based prompting for multi-step reasoning. Dec 2022. 2022arXiv preprintHow-does-GPT-Obtain-its-Ability-Tracing-Emergent-</p>
<p>A dialogue model for academic research. Blog post. X Geng, A Gudibande, H Liu, E Wallace, P Abbeel, S Levine, D Song, Koala, April 2023</p>
<p>Improving alignment of dialogue agents via targeted human judgements. A Glaese, N Mcaleese, M Trebacz, J Aslanides, V Firoiu, T Ewalds, M Rauh, L Weidinger, M Chadwick, P Thacker, arXiv:2209.143752022arXiv preprint</p>
<p>The false promise of imitating proprietary llms. A Gudibande, E Wallace, C Snell, X Geng, H Liu, P Abbeel, S Levine, D Song, arXiv:2305.157172023arXiv preprint</p>
<p>D Hendrycks, C Burns, S Basart, A Zou, M Mazeika, D Song, J Steinhardt, arXiv:2009.03300Measuring massive multitask language understanding. 2020arXiv preprint</p>
<p>Measuring mathematical problem solving with the math dataset. D Hendrycks, C Burns, S Kadavath, A Arora, S Basart, E Tang, D Song, J Steinhardt, 2021NeurIPS</p>
<p>Training compute-optimal large language models. J Hoffmann, S Borgeaud, A Mensch, E Buchatskaya, T Cai, E Rutherford, D D L Casas, L A Hendricks, J Welbl, A Clark, arXiv:2203.155562022arXiv preprint</p>
<p>C-eval: A multi-level multi-discipline chinese evaluation suite for foundation models. Y Huang, Y Bai, Z Zhu, J Zhang, J Zhang, T Su, J Liu, C Lv, Y Zhang, J Lei, arXiv:2305.083222023arXiv preprint</p>
<p>Solving quantitative reasoning problems with language models. A Lewkowycz, A Andreassen, D Dohan, E Dyer, H Michalewski, V Ramasesh, A Slone, C Anil, I Schlag, T Gutman-Solo, arXiv:2206.148582022arXiv preprint</p>
<p>P Liang, R Bommasani, T Lee, D Tsipras, D Soylu, M Yasunaga, Y Zhang, D Narayanan, Y Wu, A Kumar, arXiv:2211.09110Holistic evaluation of language models. 2022arXiv preprint</p>
<p>arXiv:2303.08774Gpt-4 technical report. 2023a. OpenAI. Gpt-4, 2023bOpenAIarXiv preprint</p>
<p>Challenging big-bench tasks and whether chain-of-thought can solve them. M Suzgun, N Scales, N Schrli, S Gehrmann, Y Tay, H W Chung, A Chowdhery, Q V Le, E H Chi, D Zhou, arXiv:2210.092612022arXiv preprint</p>
<p>R Taori, I Gulrajani, T Zhang, Y Dubois, X Li, C Guestrin, P Liang, T B Hashimoto, Stanford Alpaca, An instruction-following llama model. 2023</p>
<p>H Touvron, T Lavril, G Izacard, X Martinet, M.-A Lachaux, T Lacroix, B Rozire, N Goyal, E Hambro, F Azhar, arXiv:2302.13971Open and efficient foundation language models. 2023arXiv preprint</p>
<p>J Wei, Y Tay, R Bommasani, C Raffel, B Zoph, S Borgeaud, D Yogatama, M Bosma, D Zhou, D Metzler, arXiv:2206.07682Emergent abilities of large language models. 2022aarXiv preprint</p>
<p>J Wei, X Wang, D Schuurmans, M Bosma, E Chi, Q Le, D Zhou, arXiv:2201.11903Chain of thought prompting elicits reasoning in large language models. 2022barXiv preprint</p>            </div>
        </div>

    </div>
</body>
</html>