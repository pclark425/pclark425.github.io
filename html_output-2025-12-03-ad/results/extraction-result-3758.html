<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-3758 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-3758</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-3758</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-89.html">extraction-schema-89</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) or related AI systems being used to distill, extract, or induce qualitative laws, rules, or scientific principles from large collections of scholarly or scientific papers.</div>
                <p><strong>Paper ID:</strong> paper-874deb5f06f35e52ae13a921b23611eec4abd1da</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/874deb5f06f35e52ae13a921b23611eec4abd1da" target="_blank">ClimaX: A foundation model for weather and climate</a></p>
                <p><strong>Paper Venue:</strong> International Conference on Machine Learning</p>
                <p><strong>Paper TL;DR:</strong> ClimaX is developed and demonstrated, a flexible and generalizable deep learning model for weather and climate science that can be trained using heterogeneous datasets spanning different variables, spatio-temporal coverage, and physical groundings and results in superior performance on benchmarks for weather forecasting and climate projections, even when pretrained at lower resolutions and compute budgets.</p>
                <p><strong>Paper Abstract:</strong> Most state-of-the-art approaches for weather and climate modeling are based on physics-informed numerical models of the atmosphere. These approaches aim to model the non-linear dynamics and complex interactions between multiple variables, which are challenging to approximate. Additionally, many such numerical models are computationally intensive, especially when modeling the atmospheric phenomenon at a fine-grained spatial and temporal resolution. Recent data-driven approaches based on machine learning instead aim to directly solve a downstream forecasting or projection task by learning a data-driven functional mapping using deep neural networks. However, these networks are trained using curated and homogeneous climate datasets for specific spatiotemporal tasks, and thus lack the generality of numerical models. We develop and demonstrate ClimaX, a flexible and generalizable deep learning model for weather and climate science that can be trained using heterogeneous datasets spanning different variables, spatio-temporal coverage, and physical groundings. ClimaX extends the Transformer architecture with novel encoding and aggregation blocks that allow effective use of available compute while maintaining general utility. ClimaX is pre-trained with a self-supervised learning objective on climate datasets derived from CMIP6. The pre-trained ClimaX can then be fine-tuned to address a breadth of climate and weather tasks, including those that involve atmospheric variables and spatio-temporal scales unseen during pretraining. Compared to existing data-driven baselines, we show that this generality in ClimaX results in superior performance on benchmarks for weather forecasting and climate projections, even when pretrained at lower resolutions and compute budgets. The source code is available at https://github.com/microsoft/ClimaX.</p>
                <p><strong>Cost:</strong> 0.005</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <p class="empty-note">No extracted data.</p>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <p class="empty-note">No potentially relevant new papers extracted.</p>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-3758",
    "paper_id": "paper-874deb5f06f35e52ae13a921b23611eec4abd1da",
    "extraction_schema_id": "extraction-schema-89",
    "extracted_data": [],
    "potentially_relevant_new_papers": [],
    "cost": 0.0052882499999999995,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>ClimaX: A foundation model for weather and climate</h1>
<p>Tung Nguyen ${ }^{1}$, Johannes Brandstetter ${ }^{2}$, Ashish Kapoor ${ }^{3}$, Jayesh K. Gupta ${ }^{\circ 2}$, and Aditya Grover ${ }^{\circ 1}$<br>${ }^{1}$ UCLA, ${ }^{2}$ Microsoft, ${ }^{3}$ Scaled Foundations</p>
<h4>Abstract</h4>
<p>Most state-of-the-art approaches for weather and climate modeling are based on physics-informed numerical models of the atmosphere. These approaches aim to model the non-linear dynamics and complex interactions between multiple variables, which are challenging to approximate. Additionally, many such numerical models are computationally intensive, especially when modeling the atmospheric phenomenon at a fine-grained spatial and temporal resolution. Recent data-driven approaches based on machine learning instead aim to directly solve a downstream forecasting or projection task by learning a data-driven functional mapping using deep neural networks. However, these networks are trained using curated and homogeneous climate datasets for specific spatiotemporal tasks, and thus lack the generality of numerical models. We develop and demonstrate ClimaX, a flexible and generalizable deep learning model for weather and climate science that can be trained using heterogeneous datasets spanning different variables, spatio-temporal coverage, and physical groundings. ClimaX extends the Transformer architecture with novel encoding and aggregation blocks that allow effective use of available compute while maintaining general utility. ClimaX is pre-trained with a self-supervised learning objective on climate datasets derived from CMIP6. The pretrained ClimaX can then be fine-tuned to address a breadth of climate and weather tasks, including those that involve atmospheric variables and spatio-temporal scales unseen during pretraining. Compared to existing data-driven baselines, we show that this generality in ClimaX results in superior performance on benchmarks for weather forecasting and climate projections, even when pretrained at lower resolutions and compute budgets. Source code is available at https://github.com/microsoft/ClimaX.</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: ClimaX is built as a foundation model for any weather and climate modeling task. On the weather front, these tasks include standard forecasting tasks for various lead-time horizons at various resolutions, both globally or regionally. On the climate front, making long term projections and obtaining downscaling results from lower resolution model outputs are standard tasks.</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<h1>Contents</h1>
<p>1 Introduction ..... 4
2 Background and Related Work ..... 5
2.1 Data sources ..... 6
2.1.1 CMIP6 ..... 6
2.1.2 ERA5 ..... 6
2.2 Tasks ..... 7
2.3 Foundation models ..... 8
3 Approach ..... 8
3.1 Input representation ..... 8
3.2 Model architecture ..... 8
3.2.1 Variable tokenization ..... 9
3.2.2 Variable aggregation ..... 9
3.2.3 Transformer ..... 10
3.3 Datasets ..... 10
3.3.1 Pretraining ..... 10
3.3.2 Finetuning and evaluation ..... 11
3.4 Training ..... 11
3.4.1 Pretraining ..... 11
3.4.2 Finetuning ..... 11
4 Experiments ..... 12
4.1 Neural baselines ..... 12
4.2 Forecasting ..... 12
4.2.1 Global forecasting ..... 12
4.2.2 Regional forecasting ..... 13
4.2.3 Sub-seasonal to seasonal cumulative prediction ..... 14
4.3 Climate projection ..... 14
4.4 Climate model downscaling ..... 16
4.5 Scaling laws analysis ..... 17
4.6 Ablation studies ..... 18
4.6.1 Should we finetune ClimaX for each variable separately or all at once? ..... 18
4.6.2 Should we do iterative forecast or direct forecast? ..... 18
4.6.3 Can we finetune ClimaX to work for all lead times? ..... 19
5 Discussion and Future Work ..... 19
Acknowledgments ..... 21</p>
<p>A Model ..... 29
A. 1 ClimaX ..... 29
A.1.1 Implementation details ..... 29
A.1.2 Hyperparameters ..... 29
A. 2 CNN Baselines ..... 30
A.2.1 ResNet Hyperparameters ..... 30
A.2.2 UNet Hyperparameters ..... 30
A.2.3 Other implementation details ..... 30
B Training details ..... 30
B. 1 Pretraining ..... 31
B.1.1 Objective ..... 31
B.1.2 Optimization ..... 31
B. 2 Finetuning ..... 31
B.2.1 Objective ..... 31
B.2.2 Optimization ..... 31
C Datasets ..... 31
C. 1 CMIP6-ClimaX ..... 31
C. 2 ERA5 ..... 32
C.2.1 ERA5-NA ..... 32
C.2.2 ERA-S2S ..... 32
C. 3 ClimateBench ..... 32
D Quantitative evaluation ..... 33
D. 1 Metrics ..... 33
D.1.1 Weather forecasting metrics ..... 34
D.1.2 Climate projection metrics ..... 34
D.1.3 Climate downscaling metrics ..... 35
D. 2 Results summary ..... 35
E Qualitative evaluation ..... 38
E. 1 Nowcasting ..... 38
E. 2 Short and medium-range weather forecasting ..... 39
E. 3 Longer horizon instantaneous forecasting ..... 41</p>
<h1>1. Introduction</h1>
<p>Modeling weather and climate is an omnipresent challenge for science and society. With rising concerns around extreme weather events and climate change, there is a growing need for both improved weather forecasts for disaster mitigation and climate projections for long-term policy making and adaptation efforts [MD+21]. Currently, numerical methods for global modeling of weather and climate are parameterized via various general circulation models (GCM) [Lyn08]. GCMs represent system of differential equations relating the flow of energy and matter in the atmosphere, land, and ocean that can be integrated over time to obtain forecasts for relevant atmospheric variables [Lyn08; BTB15]. While extremely useful in practice, GCMs also suffer from many challenges, such as accurately representing physical processes and initial conditions at fine resolutions, as well as technological challenges in large-scale data assimilation and computational simulations [Bau+20]. These factors limit their use in many scenarios, especially in simulating atmospheric variables quickly at very short time scales (e.g., a few hours) or accurately at long time scales (e.g., beyond 5-7 days) [Zha+19].
In contrast, there has been a steady rise in data-driven approaches for forecasting of atmospheric variables, especially for meteorological applications [GKH15; DB18; Web+20; SM19; Sch18; Kas+21; Sch+21; Rei+19; Hun+19; Sch+17]. The key idea here is to train deep neural networks to predict the target atmospheric variables using decades of historical global datasets, such as the ERA-5 reanalysis dataset [Her+20]. Unlike GCMs, these networks are not explicitly grounded in physics, and lack general-purpose utility for Earth system sciences as they are trained for a specific predictive modeling task. Yet, with growing compute and datasets, there is emerging evidence that these models can achieve accuracies competitive with state-of-the-art numerical models in many scenarios, such as nowcasting of precipitation [Rav+21; Son+20] and medium-range forecasting of variables like temperature, wind and humidity [WDC20; RT21; Kei22; Pat+22; Bi+22; Lam+22]. While these trends are encouraging, there remain concerns regarding the generality of such data-driven methods to diverse real-world scenarios, such as forecasting of extreme weather events and longer-term climate projections, especially under limited spatiotemporal supervision and computational budgets.
Variants of the aforementioned challenges apply broadly throughout machine learning (ML). In disciplines such as natural language processing and computer vision, it is well acknowledged that ML models trained to solve a single task using supervised learning are label-hungry during training and brittle when deployed outside their training distribution [Tao+20]. Recent works have shown that it is possible to mitigate the supervision bottleneck by pretraining [Dev+18; He+22] large unsupervised "foundation" models [Bom+21] on huge passive datasets, such as text and images scraped from the internet [Ram+22; Bro+20; Liu+21; Ree+22b]. Post pretraining, there are many ways to finetune the same model on arbitrary target task(s) with little to none (i.e., zero-shot) additional supervision. Besides low target supervision, these models also generalize better to shifts outside their training distribution [Hen+20a; Zha+22b], improving their reliability.
Inspired by the above successes, this work studies the question: how do we design and train a foundation model for weather and climate that can be efficiently adapted for general-purpose tasks concerning the Earth's atmosphere? We propose ClimaX, a foundation model for weather and climate. For pretraining any foundation model, the key recipe is to train a deep architecture on a large dataset using an unsupervised objective. For example, many foundation models for language and vision train large transformers on Internet-scale datasets using generative modeling. While conceptually simple, this scaling recipe is riddled with challenges for weather and climate domains, that we discuss below and propose to resolve with ClimaX.
First, it is unclear what constitutes an Internet-scale passive dataset for pretraining ClimaX. The size of historical weather and climate datasets at any given time is fixed and increases at an almost constant rate everyday, as it corresponds to processed sensor measurements of naturally occurring phenomena. Our first key proposal is to go beyond these datasets to explicitly utilize physics-informed climate simulation models. Many such models are in use today, for example, the CMIP6 collection [Eyr+16] of climate modeling simulations consists of runs of $\sim 100$ distinct climate models from 49 different climate modeling groups. We show that the heterogeneity in these simulation datasets serves as a source of rich and plentiful data for pretraining ClimaX.
Second, we need a model architecture that can aptly embrace the heterogeneity of the above climate datasets. Climate data is highly multimodal, as observations typically correspond to many different, unbounded variables</p>
<p>with varying datatypes (e.g., pressure, temperature, humidity). Moreover, many observational datasets are irregular in the sense that they differ in their spatiotemporal coverage and might correspond to different subsets of atmospheric variables. We resolve the above challenges in ClimaX by repurposing the vision transformer [Dos + 20; Vas + 17]. In contrast to earlier work where the input data is represented as an image with different atmospheric variables treated as the channels thereof [Pat +22 ; Bi+22], we treat them as separate modalities to enable more flexible training even with irregular datasets. This has the side-effect of drastically increasing the sequence length, which we propose to resolve via a cross-attention style channel aggregation scheme prior to the self-attention layers.</p>
<p>Third and last, we need a pretraining objective that can learn complex relationships between the atmospheric variables and permit effective finetuning for downstream tasks. Given the spatiotemporal nature of climate data, we propose a randomized forecasting objective for pretraining ClimaX. Here, the goal of the model is to forecast an arbitrary set of input variables at an arbitrary time into the future. While simple and intuitive, we show that such a pretraining objective aids finetuning to novel tasks and timescales even beyond the pretraining window, such as sub-seasonal to seasonal cumulative predictions, climate projections, and downscaling of climate models. See Figure 1 for a list of tasks considered in this work.</p>
<p>Empirically, we demonstrate that a single pretrained model can be finetuned for many tasks (e.g., multi-scale weather forecasting, climate projections, downscaling) under a range of operating conditions involving different spatiotemporal resolutions, geographical regions, and target prediction variables, including those unseen during training. Notably, our benchmark results are state-of-the-art on ClimateBench [WP+22] and competitive with the operational Integrated Forecasting System (IFS) [Wed +15$]$ on WeatherBench [Ras +20$]$, even when our model is trained on moderate resolutions using only a maximum of 80 NVIDIA V100 GPUs.</p>
<p>Finally, we show promising scaling laws of ClimaX with natural axes of performance improvements for larger number of pre-training datasets, larger models, and scaling to higher resolution gridded datasets. While especially the last is in line with recent and concurrent works on data-driven weather forecasting [Pat +22 ; $\mathrm{Bi}+22$; Lam +22$]$, to the best of our knowledge, ClimaX is the first of its kind data-driven model that can effectively scale using heterogeneous climate datasets during pretraining, and generalize to diverse downstream tasks during finteuning, paving the way for a new generation of data-driven models for Earth systems science.</p>
<h1>2. Background and Related Work</h1>
<p>Current weather and climate models in use today rely extensively on numerical methods and computational simulations to predict and understand the Earth's weather and climate systems. These tasks include various numerical weather prediction (NWP) systems which use computer simulations to make short-term forecasts of weather conditions as well as climate models which use similar techniques to simulate and predict the long-term changes in the Earth's climate. Most notably, at the core of both weather and climate models lie the same set of primitive equations.</p>
<p>For climate modeling, earth system models (ESM) [Hur +13$]$, or "coupled models", that couple together simulations which govern the atmosphere, cryosphere, land, and ocean processes are considered the state-of-the-art. Primarily these simulations are based on general circulation models (GCMs) [Sat04; Lyn08; Ado14; MD +21$]$ which date back to the works of Phillips [Phi56] and Lorenz [Lor67] solving Navier-Stokes equations on a rotation sphere to model fluid circulation. These models are often used to perform various factor sensitivity studies to examine how the changes in certain forcing factors like greenhouse gas concentrations can affect the global or regional climate and help in climate projections to help understand future conditions.</p>
<p>Numerical Weather Prediction (NWP) models share many components of GCMs, especially the atmospheric components [BTB15; Lyn08; Kal03]. However, incorporating data assimilation [LSZ15; Gro22] which involves combining observations and various measurements of the atmosphere and oceans together with these numerical models is important for accurate forecasts and simulations. Another significant distinction between weather and climate models is the framing of the solution for underlying equations: initial value problem for weather, while boundary value problem for climate [BTB15]. Different difficulty levels of these solution approaches results</p>
<p>in the fact where climate models tend to be global often at coarser spatio-temporal resolutions while weather models can range from global to local and regional models of very high spatio-temporal resolutions [War10].
Despite their noted success, including the recent 2021 Nobel Prize in Physics [RRH22], there is considerable debate around the limitations of general circulation models (GCMs), particularly structural errors across models and the fact that current GCMs are designed to reproduce observed climate [Bal+22]. The climate science community has been aware of these challenges which resulted in the creation of Coupled Model Intercomparison Project (CMIP) as a standardized protocol for evaluating and comparing the performance of different climate models [Mee+00]. As we will see in the following sections, not only has CMIP been playing a crucial role in the advancement of our understanding of climate change and its potential impacts, its evaluation procedure has resulted in enormous quantity of data making modern deep learning based approaches quite attractive for many tasks. Notably, encoding this knowledge into a "foundation" machine learning model with much faster inference and data assimilation capabilities can pave the way for a much wider impact.</p>
<h1>2.1. Data sources</h1>
<p>Unlike data in computer vision or natural language processing, weather and climate data is not solely based on sensed data, instead incorporates information from a diverse range of sources. For example, reanalysis weather data blends meteorological observations with past short-range weather forecasts via data assimilation [BTB15]. The data measurements themselves are highly heterogeneous, representing various physical variables with different data types (e.g. pressure, temperature, humidity) that are recorded at different, relatively sparse, spatial locations at different temporal frequencies. These measurements can be integrated together with known physics inform the design of climate simulations, which again produce data with different variables at different scales. From a machine learning perspective, the plethora of available data thus spans multiple axes: from direct weather measurements at land, sea, or atmosphere, over multiple decades of re-analyzed weather data at different spatial scales, to physics-informed climate projections for various scenarios. Most notably, the data shares the same set of primitive equations, but with fairly different characteristics. Below we describe two of the most commonly used data sources for weather and climate modeling.</p>
<h3>2.1.1. CMIP6</h3>
<p>The Coupled Model Intercomparison Project (CMIP) [Mee+00] is an international effort across different individual climate modeling groups to come together to compare and evaluate their global climate models. While the main goal of CMIP is to improve the understanding of Earth's climate system and improve the accuracy of its simulations, the recent data from their experimental runs is easily accessible on the CMIP6 [Eyr+16] archive. In CMIP6, where " 6 " refers to the most recent phase of the project, 49 groups are involved with their experiments covering wide range of climate variables including temperature, precipitation, sea level and others from hundreds of models. This results in global projections of various climate scenarios from as early as 1850 onwards, all following similar governing equations, but with different forcings, e.g., greenhouse gas emissions that affect the climate.</p>
<h3>2.1.2. ERA5</h3>
<p>The ERA5 reanalysis archive [Her +18 ; Her +20 ] of the European Center for Medium-Range Weather Forecasting (ECMWF) is the predominant data source for learning and benchmarking weather forecasting systems. Once completed, the ERA5 reanalysis is set to embody a detailed record of the global atmosphere, land surface and ocean waves from 1950 onwards. The currently available ERA5 reanalysis data combines the state of the art forecasting model called Integrated Forecasting System (IFS) [Wed+15] of ECMWF with available observations to provide the best guess of the state of the atmosphere, ocean-wave and land-surface quantities at any point in time. In its raw form, the available reanalyzed data is huge: 40 years, from 1979 to 2018, on a $0.25^{<em>} \times 0.25^{</em>}$ global latitude-longitude grid of the Earth's sphere, at hourly intervals with different climate variables at 37 different altitude levels plus the Earth's surface. The grid overall contains $721 \times 1440$ grid points for latitude and longitude, respectively. The altitude levels are presented as pressure levels.</p>
<h1>2.2. Tasks</h1>
<p>Given the scale of data availability, increasing compute requirements of current numerical methods despite it being difficult to incorporate real observational data into them, machine learning is increasingly finding applications in many of the tasks related to weather and climate modeling. When it comes to weather, the main task of interest is forecasting the future values of key weather variables. These tasks can take the following forms depending on temporal and spatial horizons of interest:</p>
<ul>
<li>Global forecasting tasks that range from a few hours (i.e., nowcasting) to days and weeks in lead time (i.e., short and medium range forecasting). Often these tasks are evaluated on the ERA5 reanalysis dataset (see Section 2.1.2) with Operational IFS [Wed + 15] of the European Center for Medium-Range Weather Forecasting (ECMWF) being the current state-of-the-art NWP baselines.</li>
<li>Regional forecasting tasks which could range from weather forecasting in continental North America or Europe to individual state, county or city.</li>
<li>Sub-seasonal to seasonal prediction (S2S) [VR18; Vit + 22] which is the task of forecasting the weather with lead times between 2 weeks and 2 months. S2S bridges the gap between weather forecasting and seasonal climate prediction, and is critical to disaster mitigation. Often at such long horizons, predicting instantaneous values of key weather variables can be a difficult task and therefore the focus is often on averaged value of key weather variables over a certain time horizon, e.g. weekly average precipitation.</li>
</ul>
<p>Whereas deep learning approaches for regional or S2S tasks are scarce, most of the recent and concurrent work focuses on global forecasting tasks. Rasp and Thuerey [RT21] were the first to use pretraining on climate simulations to achieve good data-driven medium-range weather prediction with a ResNet [He+16], Weyn, Durran, et al. WDC20] used CNNs on a cubed sphere for global weather prediction, Weyn, Durran, et al. Wey +21 forecast weather sub-seasonally with a large ensemble of deep-learning weather prediction models, Keisler [Kei22 applied a graph neural network based approach to weather forecasting, Ravuri, Lenc, et al. [Rav + 21] use deep generative models of radar for precipitation nowcasting, Arcomano, Szunyogh, et al. [Arc + 20] build a reservoir computing-based, low-resolution, global prediction model, and MetNet [Søn +20 ] takes as input radar and satellite data to forecast probabilistic precipitation maps. These approaches are complemented by general machine learning models for fluid dynamics [Li+20; Koc+21; Lu+21; Bra+22; BWW22]. Finally, recent state-of-the-art neural weather models such as FourCastNet Pat+22, Panguweather [Bi+22], or GraphCast [Lam+22], which also perform global forecasting tasks, use the highest resolution $0.25^{\circ}$ ERA5 data, and are optimized on the respective hardware resources.</p>
<p>On the other hand, climate tasks have to deal with much longer time horizons. Possible categories of tasks where machine learning can help include climate projection and climate model downscaling:</p>
<ul>
<li>Climate projection is the task of generating estimates of climate change under different future socioeconomic scenarios. Usually, this takes the form of figuring out the response of the climate system to different forcing factors such as greenhouse gases and aerosol emissions. Climate projection is a crucial task in understanding and preparing for the potential impacts of climate change.
While the application of machine learning in this field is still in its early stages, recent efforts have been made to standardize evaluation in this domain. One example of this is ClimateBench [WP+22], which is a benchmark dataset drawing on CMIP6 to provide an evaluation framework for machine learning models that aim to improve the accuracy of climate projections. This benchmark aims to provide a consistent and reliable evaluation method for various machine learning models that are applied to climate projections.</li>
<li>A more popular application of ideas in machine learning is towards downscaling of climate model. Global climate models typically have a coarse spatial resolution, which means that they can only provide a rough estimate of climate conditions at a local or regional scale. Moreover, the simulations often reflect systematic biases that deviate from trends in the observation data. The aim of climate model downscaling is to create locally accurate climate information from global climate projections by relating those to observed local climatological conditions. This process improves the spatial and temporal resolution of the data, making it more suitable for use in local and regional analyses. Downscaling methods can be divided into</li>
</ul>
<p>dynamic approaches that relate outputs of global climate models with those of regional climate models, and statistical approaches that infer the desired transformations using data-driven approaches WWW97. Dynamic approaches are physically consistent, but can be slow and have large biases, whereas statistical approaches need large amounts of data to learn expressive mappings that hold for target output scenarios.</p>
<p>Similar to weather forecasting, deep learning has emerged as appealing alternative in climate science as well. Recent approaches comprise surrogate models to emulate climate projections [Web+20; SM19; Sch18; BGS20; $\mathrm{Man}+20$ ], extract contextual cues from existing datasets or simulations [Rei+19; Hun+19; Sch+17], and perform climate model downscaling [Sac+18; Van+17; BMMG20]. Climate model downscaling usually inputs low-resolution reanalysis data and local orographic information to obtain high-resolution local information. Many recent approaches are based on convolutional architectures [Höh+20; Vau+21; Mar+22].</p>
<h1>2.3. Foundation models</h1>
<p>Bommasani, Hudson, et al. [Bom+21] gave the term "foundation models" to the emerging paradigm of training scalable deep learning models on broad data via self-supervision which could then be adapted (often via finetuning) to a wide range of downstream tasks. Current notable examples include BERT [Dev+18], GPT [Bro+20] and PaLM [Cho+22], in language, CLIP [Rad+21], Florence [Yua+21], BEiT [Wan+22] for vision-language. Outside applications on data crawled from web, this paradigm has also started finding success in various scientific domains like protein design [Ver+22]. Key significance of such models has been identified as emergence with respect to model capabilities and homogenization with respect to methodologies for different tasks, domains, and modalities, enabled by the principles of transfer learning [TP12] at scale. While a foundation model itself should be considered incomplete, it can provide a common basis from which various task-specific models can be derived. Current research at the intersection of weather and climate science and ML has largely focused on designing separate models for every task of interest despite potential availability of fairly diverse large scale data with shared underlying physics and geology across these tasks. A few recent works have proposed pretraining techniques for satellite imagery and remote sensing [YL20; Con+22; Ree+22a] but they have so far not been applied to multi-sensory data and variables in weather and climate.</p>
<h2>3. Approach</h2>
<p>Given the availability of large scale data sources, together with shared physics and geology between various weather and climate tasks, we aim to build a generalizable deep learning foundation model. The model needs to be able to input heterogeneous datasets of different variables, and provide spatio-temporal coverage based on physical groundings. We, therefore, first take a closer look at input representations, and next design a model to cope with their heterogeneity - local, global, and across variables.</p>
<h3>3.1. Input representation</h3>
<p>We are interested in gridded prediction tasks, in which the model takes an input of shape $V \times H \times W$ and predicts an output of shape $V^{\prime} \times H^{\prime} \times W^{\prime} . V$ refers to the number of input variables, which can be weather conditions such as geopotential and temperature, or climate forcing factors such as $\mathrm{CO}<em 2="2">{2}$ and $\mathrm{SO}</em>(128 \times 256$ grid points $)$. Semantically, a $H \times W$ map can represent the entire globe or a specific region such as North America.} . H$ and $W$ refer to the spatial resolution of the input data, which depends on how densely we grid the globe. This general representation captures a broad variety of downstream tasks in Earth systems science. Similarly, $V^{\prime}, H^{\prime}, W^{\prime}$ refer to the variables and spatial resolution of the predicted outputs. We mainly work with two spatial resolutions: $5.625^{\circ}(32 \times 64$ grid points $)$ and $1.40625^{\circ</p>
<h3>3.2. Model architecture</h3>
<p>We aim to design a foundation model that we can pretrain on heterogeneous data sources and then finetune to solve various downstream weather and climate tasks. From Section 3.1, one could think of the tasks as</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: Pretraining phase of ClimaX. Variables are encoded using variable-separate tokenization, and subsequently aggregated using variable aggregation. Together with position embedding and lead time embedding those are fed to the ViT backbone.
image-to-image translation problems with $V$ input channels and $V^{\prime}$ output channels. This makes any image architecture a natural fit, such as UNet [RFB15], ResNet [He+16], or Vision Transformers (ViT) [Dos+20]. However, the settings of climate and weather tasks are much broader, where we may want to make predictions for regional or even spatially incomplete data, forecast unseen climate variables, or finetune the model on data at different resolutions from pretraining. Current CNN-based architectures are not applicable in these scenarios, as they require the input to be perfectly gridded, contain a fixed set of variables, and have a fixed spatial resolution. Transformers-based architectures, on the other hand, provide much better flexibility by treating the image-like data as a set of tokens. Therefore, we build ClimaX architecture upon Vision Transformers (ViT) [Dos+20; Vas+17], and propose two major architectural changes, namely variable tokenization and variable aggregation to further improve the flexibility and generality, which we will describe next.</p>
<h1>3.2.1. Variable tokenization</h1>
<p>Given an input of shape $V \times H \times W$, ViT tokenizes the input into a sequence of $(H / p) \times(W / p)=h \times w$ patches, with each patch having a size of $V \times p^{2}$, where $p$ is the patch size. This tokenization scheme works well for image data, as $V$ is always the RGB channels, which is the same for all datasets. However, this is not true for climate and weather data, where the number of physical variables can vary between different datasets. For example, in the CMIP6 project [Eyr+16], each dataset contains simulated data of a different climate model, and thus has a different set of underlying variables. Therefore, we propose variable tokenization, a novel tokenization scheme that tokenizes each variable in the input separately. Specifically, each input variable as a spatial map of shape $H \times W$ is tokenized into a sequence of $h \times w$ patches, which results in $V \times h \times w$ patches in total. Finally, each input patch of size $p^{2}$ is linearly embedded to a vector of dimension $D$, where $D$ is the chosen embedding size. The output of the variable tokenization module therefore has a dimension of $V \times h \times w \times D$. Figure 3 illustrates our proposed tokenization scheme.</p>
<h3>3.2.2. Variable aggregation</h3>
<p>While variable tokenization allows ClimaX to learn from datasets with varying numbers of input variables, it has two inherent problems. First, it results in a sequence of length $V \times h \times w$ which increases linearly with the number of variables. Since we use attention to model the sequence, the memory complexity scales quadratically with the number of variables. This is computationally expensive, as we can have up to 48 input</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3: Variable tokenization. Each variable is independently tokenized.
variables in our experiments. Moreover, because we tokenize each variable separately, the input sequence will contain tokens of different variables with very different physical groundings, which can create difficulties for the attention layers to learn from. We therefore propose variable aggregation to solve the two mentioned challenges. For each spatial position in the $h \times w$ map, we perform a cross-attention operation, in which the query is a learnable vector, and the keys and values are the $V$ embedding vectors of $V$ variables at that position. The cross-attention module outputs a single vector for each spatial position, thus reducing the sequence length to $h \times w$, significantly lowering the computational cost. Moreover, the sequence now contains unified tokens with universal semantics, creating an easier task for the attention layers. Figure 4 shows our proposed variable aggregation.
<img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 4: Position-based variable aggregation reduces a sequence of length $V \times h \times w$ to $h \times w$.</p>
<h1>3.2.3. Transformer</h1>
<p>Post variable aggregation, we need a sequence model for generating the output tokens. While in principle, one could use any general sequence model, we propose to extend a standard Vision Transformer (ViT). Moreover, since the standard ViT treats image modeling as pure sequence-to-sequence problems, it can perform tasks that some other variations cannot [Liu+21; Liu+22], such as learning from spatially incomplete data, where the input does not necessarily form a complete grid. This is useful in the regional forecasting task we consider in Section 4.2.2. In the experiments, we report results with 8 attention layers, an embedding size of 1024, and a hidden dimension of $1024 \times 4$. After the attention layers, we employ a prediction head that takes a token and outputs a vector of size $V^{\prime} \times p^{2}$. The prediction head is a 2-layer MLP with a hidden dimension of 1024. We provide more details in Appendix A.</p>
<h3>3.3. Datasets</h3>
<h3>3.3.1. Pretraining</h3>
<p>We believe that CMIP6's diversity and scale presents an attractive opportunity for pretraining large-scale foundation models. However, handling the inconsistent set of variables across different data sources can be a challenge. In this work we only use a subset of variables from five different data sources (MPI-ESM, TaiESM, AWI-ESM, HAMMOZ, CMCC) containing global projections of climate scenarios from 1850 to 2015 with the time delta of 6 hours as described in Table 8. Due to variable original resolution, we choose to simplify our data-loading by regridding them to commonly used resolutions [Ras+20; RT21] of $5.625^{\circ}(32 \times 64$ grid points) and $1.40625^{\circ}(128 \times 256$ grid points $)^{1}$.</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<h1>3.3.2. Finetuning and evaluation</h1>
<p>We use the ERA5 reanalysis data as described in Appendix C.2, as the source of datasets for finetuning and evaluation for various weather related downstream tasks. Due to its large size, it is common to regrid [Ras +20 ; RT21] the high-resolution data to lower resolutions like $5.625^{\circ}$ ( $32 \times 64$ grid points) and $1.40625^{\circ}$ ( $128 \times 256$ grid points) to fit within the available computational constraints ${ }^{2}$. We follow the evaluation procedure by Rasp and Thuerey [RT21] and use this data to assess the forecasting performance of our ML models at different lead time horizons. More details about the individual datasets are in their appropriate experiment sections.</p>
<h3>3.4. Training</h3>
<h3>3.4.1. Pretraining</h3>
<p>We pretrain ClimaX on CMIP6 data to predict future weather conditions given the current conditions. That is, given the weather snapshot $X_{t}$ of shape $V \times H \times W$ at a particular time $t$, ClimaX learns to predict the future weather scenario $X_{t+\Delta t}$ of the same shape at lead time $\Delta t$. To obtain a pretrained model that is generally applicable to various temporal forecasting tasks, we randomize the lead time from 6 hours to 168 hours (i.e., 1 week) during pretraining. We add the lead time embedding to the tokens to inform the model of how long it is forecasting into the future. The lead time embedding module is a single-layer MLP that maps a scalar to a vector of the embedding size $D$. Figure 2 depicts the forward pass of ClimaX in pretraining. For an input $X_{t}$, we sample a lead time $\Delta t \sim \mathcal{U}[6,168]$ and get the corresponding ground truth $X_{t+\Delta t}$. Input variables are tokenized separately using variable tokenization, and are subsequently aggregated at each spatial location, resulting in a sequence of $h \times w$ unified tokens. We add the tokens with the lead time embedding and positional embedding before feeding the sequence to the ViT backbone. The output of the last attention layer is fed to a prediction head, which transforms the sequence back to the original shape of $V \times H \times W$.
We employ the latitude-weighted mean squared error [Ras +20 ] as our objective function. Given the prediction $\hat{X}<em t="t" t_Delta="t+\Delta">{t+\Delta t}$ and the ground truth $X</em>$, the loss is computed as:</p>
<p>$$
\mathcal{L}=\frac{1}{V \times H \times W} \sum_{v=1}^{V} \sum_{i=1}^{H} \sum_{j=1}^{W} L(i)\left(\hat{X}<em t="t" t_Delta="t+\Delta">{t+\Delta t}^{v, i, j}-X</em>
$$}^{v, i, j}\right)^{2</p>
<p>in which $L(i)$ is the latitude weighting factor:</p>
<p>$$
L(i)=\frac{\cos (\operatorname{lat}(i))}{\frac{1}{H} \sum_{i^{\prime}=1}^{H} \cos \left(\operatorname{lat}\left(i^{\prime}\right)\right)}
$$</p>
<p>where lat $(i)$ is the latitude of the corresponding $i$ th row of the grid. The latitude weighting term accounts for the non-uniformity in areas when we grid the round globe. Grid cells toward the equator have larger areas than the cells near the pole, and thus should be assigned more weights.</p>
<h3>3.4.2. Finetuning</h3>
<p>ClimaX has four learnable components, including the token embedding layers, the variable aggregation module, the attention blocks, and the prediction head. We evaluate the performance of ClimaX on various downstream tasks, which we categorize into two finetuning scenarios: one in which the downstream variables belong to the set of pretraining variables, and the other with variables unseen during pretraining. In the first case, we finetune the entire model, and in the latter, we replace the embedding layers and the prediction head with newly initialized networks, and either finetune or freeze the other two components. We present more details of each downstream task in Section 4.</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<h1>4. Experiments</h1>
<p>We finetune ClimaX on a diverse set of downstream tasks to evaluate its performance and generality. We categorize the tasks into forecasting, climate projection, and climate downscaling. The experiments aim to answer the following questions:</p>
<ul>
<li>How does ClimaX perform on global forecasting compared to the current state-of-the-art NWP system?</li>
<li>Can we finetune ClimaX to make forecasts for a specific region or at different temporal horizons from pretraining?</li>
<li>How well does ClimaX perform on climate tasks that are completely different from pretraining?</li>
</ul>
<p>In addition to the main experiments, we analyze the scaling property of ClimaX, i.e., how the performance of ClimaX improves with increasing data size, model capacity, and data resolution. Finally, we perform comprehensive ablation studies to understand the trade-off between computation and performance when finetuning ClimaX.</p>
<h3>4.1. Neural baselines</h3>
<p>In global forecasting, we compare ClimaX with IFS [Wed +15$]$, the current gold standard in weather forecasting. In tasks we do not have a baseline, we compare with UNet [RFB15; GB22] and ResNet [He+16], two CNN baselines commonly used in vision tasks. We borrow the ResNet architecture from Weatherbench [Ras+20]. The exact architectural details of these baselines are in Appendix A.2.</p>
<h3>4.2. Forecasting</h3>
<h3>4.2.1. Global forecasting</h3>
<p>Given global weather conditions $X_{t}$ at a particular time $t$, we want to forecast the weather at a future time $X_{t+\Delta t}$, in which $\Delta t$ is the lead time. The input variables include 6 atmospheric variables at 7 vertical levels, 3 surface variables, and 3 constant fields, resulting in 48 input variables in total. The details of the variables are in Table 9. We evaluate ClimaX on predicting four target variables: geopotential at 500 hPa (Z500), the temperature at 850 hPa (T850), the temperature at 2 meters from the ground (T2m), and zonal wind speed at 10 meters from the ground (U10). Z500 and T850 are the two standard verification variables for most medium-range NWP models and are often used for benchmarking in previous deep learning works, while the two surface variables, T2m and U10, are relevant to human activities. We consider seven lead times: 6 hours, ${1,3,5,7}$ days, 2 weeks, and 1 month, which range from nowcasting to short and medium-range forecasting and beyond. We consider predicting each target variable at each lead time a separate task, and finetune a separate model for each task. We discuss alternative finetuning protocols in Section 4.6.
We compare ClimaX with IFS and the two CNN baselines on the ERA5 dataset at both $5.625^{\circ}$ and $1.40625^{\circ}$ resolutions. Following [Ras+20], we split the data into three sets, in which the training data is from 1979 to 2015, the validation data is in 2016, and the test data is in 2017 and 2018. We finetune ClimaX and train the other deep learning baselines using the latitude-weighted MSE loss in Equation (1). We perform early stopping on the validation loss for all deep learning models, and evaluate the best checkpoint on the test set. For IFS, we download the predictions from the TIGGE archive [Bou+10] for the year $2018^{3}$. We compare all methods on latitude-weighted root mean squared error (RMSE) and latitude-weighted anomaly correlation coefficient (ACC), two commonly used metrics in previous works. The formulations of the two metrics are in Appendix D.1. Lower RMSE and higher ACC indicates better performance.
Figures 5 and 6 show the performance of ClimaX and the baselines at $5.625^{\circ}$ and $1.40625^{\circ}$, respectively. At low resolution, IFS outperforms ClimaX on 6-hour to 5-day prediction tasks. On longer horizons, however, ClimaX performs comparably to or slightly better than IFS, especially on 14-day prediction. At higher resolution, the</p>
<p><sup id="fnref4:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Figure 5: Performance on global forecasting on ERA5 at $5.625^{\circ}$.
performance of ClimaX closely matches that of IFS even for short horizons, and is superior in forecasting at 7 days and beyond. The trends are similar for both RMSE and ACC. The two CNN baselines perform similarly and achieve reasonable performance, but lag behind ClimaX and IFS on all tasks. We include other additional task-specific baselines [Pat+22; Bi+22; Lam+22] in Appendix D.2. These baselines are trained on higher-resolution ERA5 $\left(0.25^{\circ}\right)$ so are not directly comparable.</p>
<h1>4.2.2. Regional forecasting</h1>
<p>It is not always possible to make global predictions, especially when we only have access to regional data In this section, we evaluate ClimaX on regional forecasting of the relevant variables in North America, where the task is to forecast the future weather in North America given the current weather condition in the same region. We create a new dataset from the ERA5 data at $1.40625^{\circ}$ that has the same set of variables but just focuses on the North America region. We call this dataset ERA5-NA and present details of how to construct it in Appendix C.2. Training, validation, and test splits are done similarly to Section 4.2.1. Figure 7 illustrates the finetuning process of ClimaX on this task, where the only difference from global forecasting is the input now only contains tokens that belong to North America.
Since the task has not been considered in previous works, we compare ClimaX with the two CNN baselines ResNet and UNet, and the scratch-trained version of ClimaX, which we refer to as Cli-ViT. In addition, we finetune two ClimaX models, in which one was pretrained on CMIP6 at $1.40625^{\circ}$, and the other was pretrained on $5.625^{\circ}$ data. To finetune the low-resolution model on higher-resolution data, we follow the common practice of interpolating the positional embedding [Dos+20; Tou+21]. We denote this model as ClimaX-pos-interp. We evaluate all methods on predicting Z500, T2m, and T850 at lead times of 3,5 , and 7 days. Latitude-weighted RMSE is used as the evaluation metric.</p>
<p>Figure 8 compares the performance of ClimaX and the baselines. ClimaX is the best performing method among different target variables and lead times. Interestingly, even though pretrained on data at a lower resolution, ClimaX-pos-interp achieves the second best performance in predicting Z500 and T850, and only underperforms ResNet in predicting T2m at 3-day lead time. This result shows that ClimaX can gain strong</p>
<p><img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Figure 6: Performance on global forecasting on ERA5 at $1.40625^{\circ}$.
performance on tasks that have different spatial coverage or even different spatial resolution from pretraining.</p>
<h1>4.2.3. Sub-seasonal to seasonal cumulative prediction</h1>
<p>Sub-seasonal to seasonal (S2S) prediction is the task of forecasting at a time range between 2 weeks and 2 months [VR18], which bridges the gap between weather forecasting and climate projection. Compared to the other two well-established tasks, S2S prediction has received much less attention, despite having a significant socioeconomic value in disaster mitigation. Recent works have proposed data-driven approaches based on both traditional machine learning [Hwa + 19; Pro + 18; TL18] and deep learning [Wey + 21; Zho +21 ; Ore +19], but their performances often lag behind adaptive bias correction methods [Mou+23a] on standard benchmarks [Mou+23b]. Here, following the S2S competition (https://s2s-ai-challenge.github.io/), we aim to predict the biweekly average statistics of weeks $3-4$ and weeks $5-6$, which correspond to lead times of 2 weeks and 4 weeks, respectively. We construct ERA5-S2S, a new dataset from $5.625^{\circ}$ ERA5 that has the same input variables, but the output variables are averaged from the lead time to 2 weeks ahead into the future.
We compare ClimaX with ResNet, UNet, and Cli-ViT on the S2S prediction of four target variables: T850, T2m, U10, and V10. Table 1 compares the RMSE of ClimaX and the baselines. ClimaX achieves the lowest error for all variables, and the performance gap with the best baseline UNet is larger at increasing lead times. ClimaX also has significant performance gains over its scratch-trained counterpart Cli-ViT, showing the effectiveness of our pretraining procedure in capturing features that are generally useful for various temporal prediction tasks.</p>
<h3>4.3. Climate projection</h3>
<p>To further test the generality of ClimaX, we evaluate the model on ClimateBench [WP + 22], a recent benchmark designed for testing machine learning models for climate projections. The goal of ClimateBench is to predict the annual mean global distributions of surface temperature, diurnal temperature range, precipitation, and the 90th percentile of precipitation, given the four anthropogenic forcing factors: carbon dioxide $\left(\mathrm{CO}<em 2="2">{2}\right)$, sulfur dioxide $\left(\mathrm{SO}</em>\right)$. We note that this is not a temporal modeling task,}\right)$, black carbon $(\mathrm{BC})$, and methane $\left(\mathrm{CH}_{4</p>
<p><img alt="img-6.jpeg" src="img-6.jpeg" /></p>
<p>Figure 7: Finetuning setup for Regional Forecasting in North America.
<img alt="img-7.jpeg" src="img-7.jpeg" /></p>
<p>Figure 8: Performance on Regional (North America) forecasting for key variables.
as we do not predict the future given the past. Instead, we answer questions like what will be the annual mean temperature for a specified $\mathrm{CO}<em _frozen="{frozen" _text="\text">{2}$ level? In particular, note that the input variables and the task itself are completely different from pretraining.
Figure 9 illustrates the finetuning pipeline of ClimaX for ClimateBench. As the input and output variables are unseen during pretraining, we replace the pretrained embedding layers and prediction heads with newly initialized networks, while keeping the attention layers and the variable aggregation module. We consider two finetuning protocols, in which we either freeze ${ }^{4}$ (ClimaX ${ }</em>$ ) or finetune (ClimaX) the attention layers. In addition, we introduce two components to the pipeline in Figure 2. We use a history of the preceding ten years of the forcing factors to make predictions for a particular year, creating an input of shape $T \times V \times H \times W$. Each time slice of the input goes through variable tokenization, variable aggregation, and the attention layers as usual, which output a feature tensor of shape $T \times h \times w \times D$, where $D$ is the embedding size. The feature tensor then goes through a global average pooling layer, reducing the dimension to $T \times D$. Finally, the 10-year history is aggregated using a cross-attention layer before being fed to the prediction head, which linearly transforms the $D$-dimensional feature vector to a $H \times W$ map. The history aggregation and the global pooling modules are the two additions to the original ClimaX architecture. These architectural designs are inspired by the neural network baseline in [WP+22].
We compare ClimaX with ClimaX ${ }}<em s="s">{\text {frozen }}$, Cli-ViT, and the best baseline from ClimateBench. Following [WP+22], we use the standard mean squared error (Equation (1) without the weighting term) as the loss function. We evaluate all methods on RMSE, NRMSE ${ }</em>}$ (Spatial), NRMSE ${ <em s="s">{g}$ (Global), and Total $=\mathrm{NRMSE}</em>+5 \times$ NRMSE $<em _frozen="{frozen" _text="\text">{g}$ [WP+22]. Details of the metrics are in Appendix D.1. Table 2 shows the results. ClimaX ${ }</em>$ performs the best in predicting two temperature-related variables, followed by ClimaX. This shows that}</p>
<p><sup id="fnref5:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>Table 1: RMSE of ClimaX and baselines on $5.625^{\circ}$ ERA5-S2S prediction tasks.</p>
<table>
<thead>
<tr>
<th></th>
<th>T850</th>
<th></th>
<th>T2m</th>
<th></th>
<th>U10</th>
<th></th>
<th>V10</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Weeks 3-4</td>
<td>Weeks 5-6</td>
<td>Weeks 3-4</td>
<td>Weeks 5-6</td>
<td>Weeks 3-4</td>
<td>Weeks 5-6</td>
<td>Weeks 3-4</td>
<td>Weeks 5-6</td>
</tr>
<tr>
<td>Resnet</td>
<td>2.12</td>
<td>2.13</td>
<td>1.88</td>
<td>2.16</td>
<td>1.91</td>
<td>1.94</td>
<td>1.52</td>
<td>1.59</td>
</tr>
<tr>
<td>Unet</td>
<td>1.91</td>
<td>1.95</td>
<td>1.67</td>
<td>1.79</td>
<td>1.85</td>
<td>1.90</td>
<td>1.52</td>
<td>1.57</td>
</tr>
<tr>
<td>Cli-ViT</td>
<td>1.96</td>
<td>1.96</td>
<td>1.79</td>
<td>1.90</td>
<td>1.83</td>
<td>1.92</td>
<td>1.51</td>
<td>1.56</td>
</tr>
<tr>
<td>ClimaX</td>
<td>$\mathbf{1 . 8 9}$</td>
<td>$\mathbf{1 . 9 2}$</td>
<td>$\mathbf{1 . 6 6}$</td>
<td>$\mathbf{1 . 7 0}$</td>
<td>$\mathbf{1 . 8 1}$</td>
<td>$\mathbf{1 . 8 6}$</td>
<td>$\mathbf{1 . 5 0}$</td>
<td>$\mathbf{1 . 5 4}$</td>
</tr>
</tbody>
</table>
<p><img alt="img-8.jpeg" src="img-8.jpeg" /></p>
<p>Figure 9: Finetuning pipeline for ClimateBench. A different set of input and output variables requires different embedding layers and prediction heads. Attention layers can be frozen or finetuned. the pretrained attention layers can serve as a strong feature extractor in seemingly unrelated tasks. Where downstream data is scarce (ClimateBench has only 754 data points), further finetuning the attention layer can lead to overfitting and thus slightly hurt the performance. In two precipitation-related tasks, ClimaX ${ }<em s="s">{\text {frozen }}$ slightly underperforms ClimateBench baseline in terms of NRMSE $</em>$ but outperforms on RMSE. We hypothesize that this was because ClimaX did not observe the precipitation variable during pretraining, which has very different behaviors from other variables.}$ and NRMSE $_{g</p>
<h1>4.4. Climate model downscaling</h1>
<p>Climate models are often run at coarse grids due to their high computational cost. Although these predictions are useful in understanding large-scale climate trends, they do not provide sufficient detail to analyze regional and local phenomena. Downscaling aims to obtain higher-resolution projections and reduce biases from the outputs of these models. To evaluate the applicability of ClimaX to the task of climate model downscaling, we construct a new dataset based on CMIP6 and ERA5 data sources for coarse inputs and higher resolution targets. Specifically, we use all MPI-ESM, a dataset from CMIP6, and its variables listed in Table 8 at $5.625^{\circ}$ as input, and train separate models to downscale to each ERA5 target variable at $1.40625^{\circ}$. We compare ClimaX with Cli-ViT and the two CNN baselines, UNet and ResNet, as most recent deep downscaling methods [Van+17; Rod+18; Höh+20; VKG19; LGD20] are based on convolution. We were not able to compare with YNet [LGD20], the current best method on deep downscaling as we did not have access to high-resolution auxiliary data such as elevation and topographical information. For all methods, we first bilinearly interpolate the input to match the resolution of the desired output before feeding it to the model. We evaluate all methods on RMSE, Pearson correlation, and Mean bias, which were commonly used in existing deep downscaling works [Van+17; LGD20]. Details of the metrics are in Appendix D.1.</p>
<p>Table 3 compares ClimaX and the baselines quantitatively. ClimaX achieves the lowest RMSE and a mean</p>
<p>Table 2: Performance of ClimaX and the baselines on ClimateBench. Spatial and Global denote the normalized root mean squared error NRMSE ${ }<em g="g">{s}$ and the NRMSE of the global mean NRMSE ${ }</em>$, respectively. Total is a weighted combination of Spatial and Global.</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;">Surface temperature</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Diurnal temperature range</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Precipitation</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">90th percentile precipitation</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Spatial</td>
<td style="text-align: center;">Global</td>
<td style="text-align: center;">Total</td>
<td style="text-align: center;">RMSE</td>
<td style="text-align: center;">Spatial</td>
<td style="text-align: center;">Global</td>
<td style="text-align: center;">Total</td>
<td style="text-align: center;">RMSE</td>
<td style="text-align: center;">Spatial</td>
<td style="text-align: center;">Global</td>
<td style="text-align: center;">Total</td>
<td style="text-align: center;">RMSE</td>
<td style="text-align: center;">Spatial</td>
<td style="text-align: center;">Global</td>
<td style="text-align: center;">Total</td>
<td style="text-align: center;">RMSE</td>
</tr>
<tr>
<td style="text-align: center;">ClimateBench-NN (reproduced)</td>
<td style="text-align: center;">0.123</td>
<td style="text-align: center;">0.080</td>
<td style="text-align: center;">0.524</td>
<td style="text-align: center;">0.404</td>
<td style="text-align: center;">7.465</td>
<td style="text-align: center;">1.233</td>
<td style="text-align: center;">13.632</td>
<td style="text-align: center;">0.150</td>
<td style="text-align: center;">2.349</td>
<td style="text-align: center;">0.151</td>
<td style="text-align: center;">3.104</td>
<td style="text-align: center;">0.553</td>
<td style="text-align: center;">3.108</td>
<td style="text-align: center;">0.282</td>
<td style="text-align: center;">4.517</td>
<td style="text-align: center;">1.594</td>
</tr>
<tr>
<td style="text-align: center;">ClimateBench-NN (paper)</td>
<td style="text-align: center;">0.107</td>
<td style="text-align: center;">0.044</td>
<td style="text-align: center;">0.327</td>
<td style="text-align: center;">N/A</td>
<td style="text-align: center;">9.917</td>
<td style="text-align: center;">1.372</td>
<td style="text-align: center;">16.778</td>
<td style="text-align: center;">N/A</td>
<td style="text-align: center;">2.128</td>
<td style="text-align: center;">0.399</td>
<td style="text-align: center;">3.175</td>
<td style="text-align: center;">N/A</td>
<td style="text-align: center;">2.610</td>
<td style="text-align: center;">0.346</td>
<td style="text-align: center;">4.339</td>
<td style="text-align: center;">N/A</td>
</tr>
<tr>
<td style="text-align: center;">$\mathrm{Cl}_{i}-\mathrm{ViT}$</td>
<td style="text-align: center;">0.086</td>
<td style="text-align: center;">0.044</td>
<td style="text-align: center;">0.305</td>
<td style="text-align: center;">0.362</td>
<td style="text-align: center;">6.997</td>
<td style="text-align: center;">1.759</td>
<td style="text-align: center;">15.792</td>
<td style="text-align: center;">0.146</td>
<td style="text-align: center;">2.224</td>
<td style="text-align: center;">0.241</td>
<td style="text-align: center;">3.430</td>
<td style="text-align: center;">0.550</td>
<td style="text-align: center;">2.890</td>
<td style="text-align: center;">0.329</td>
<td style="text-align: center;">4.447</td>
<td style="text-align: center;">1.579</td>
</tr>
<tr>
<td style="text-align: center;">ClimaX</td>
<td style="text-align: center;">0.086</td>
<td style="text-align: center;">0.043</td>
<td style="text-align: center;">0.300</td>
<td style="text-align: center;">0.362</td>
<td style="text-align: center;">7.148</td>
<td style="text-align: center;">0.961</td>
<td style="text-align: center;">11.952</td>
<td style="text-align: center;">0.147</td>
<td style="text-align: center;">2.360</td>
<td style="text-align: center;">0.396</td>
<td style="text-align: center;">3.390</td>
<td style="text-align: center;">0.554</td>
<td style="text-align: center;">2.739</td>
<td style="text-align: center;">0.332</td>
<td style="text-align: center;">4.397</td>
<td style="text-align: center;">1.575</td>
</tr>
<tr>
<td style="text-align: center;">ClimaX ${ }_{\text {feature }}$</td>
<td style="text-align: center;">0.085</td>
<td style="text-align: center;">0.043</td>
<td style="text-align: center;">0.297</td>
<td style="text-align: center;">0.360</td>
<td style="text-align: center;">6.688</td>
<td style="text-align: center;">0.810</td>
<td style="text-align: center;">10.739</td>
<td style="text-align: center;">0.144</td>
<td style="text-align: center;">2.193</td>
<td style="text-align: center;">0.183</td>
<td style="text-align: center;">3.110</td>
<td style="text-align: center;">0.549</td>
<td style="text-align: center;">2.681</td>
<td style="text-align: center;">0.342</td>
<td style="text-align: center;">4.389</td>
<td style="text-align: center;">1.572</td>
</tr>
</tbody>
</table>
<p>Table 3: Performance of ClimaX and the baselines on downscaling from MPI-ESM (5.625<em>) to ERA5 (1.40625</em>).</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Z500</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">T850</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">T2m</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">U10</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">V10</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">RMSE</td>
<td style="text-align: center;">Pearson</td>
<td style="text-align: center;">Mean bias</td>
<td style="text-align: center;">RMSE</td>
<td style="text-align: center;">Pearson</td>
<td style="text-align: center;">Mean bias</td>
<td style="text-align: center;">RMSE</td>
<td style="text-align: center;">Pearson</td>
<td style="text-align: center;">Mean bias</td>
<td style="text-align: center;">RMSE</td>
<td style="text-align: center;">Pearson</td>
<td style="text-align: center;">Mean bias</td>
<td style="text-align: center;">RMSE</td>
<td style="text-align: center;">Pearson</td>
</tr>
<tr>
<td style="text-align: center;">ResNet</td>
<td style="text-align: center;">825.75</td>
<td style="text-align: center;">0.96</td>
<td style="text-align: center;">$-108.54$</td>
<td style="text-align: center;">3.60</td>
<td style="text-align: center;">0.96</td>
<td style="text-align: center;">0.19</td>
<td style="text-align: center;">2.89</td>
<td style="text-align: center;">0.98</td>
<td style="text-align: center;">0.14</td>
<td style="text-align: center;">4.05</td>
<td style="text-align: center;">0.65</td>
<td style="text-align: center;">0.06</td>
<td style="text-align: center;">4.11</td>
<td style="text-align: center;">0.45</td>
</tr>
<tr>
<td style="text-align: center;">UNet</td>
<td style="text-align: center;">858.35</td>
<td style="text-align: center;">0.95</td>
<td style="text-align: center;">25.10</td>
<td style="text-align: center;">3.66</td>
<td style="text-align: center;">0.96</td>
<td style="text-align: center;">$-0.34$</td>
<td style="text-align: center;">2.95</td>
<td style="text-align: center;">0.98</td>
<td style="text-align: center;">0.16</td>
<td style="text-align: center;">4.09</td>
<td style="text-align: center;">0.64</td>
<td style="text-align: center;">$-0.06$</td>
<td style="text-align: center;">4.13</td>
<td style="text-align: center;">0.44</td>
</tr>
<tr>
<td style="text-align: center;">$\mathrm{Cl}_{i}-\mathrm{ViT}$</td>
<td style="text-align: center;">811.61</td>
<td style="text-align: center;">0.96</td>
<td style="text-align: center;">$-54.32$</td>
<td style="text-align: center;">3.58</td>
<td style="text-align: center;">0.97</td>
<td style="text-align: center;">$-0.29$</td>
<td style="text-align: center;">2.80</td>
<td style="text-align: center;">0.99</td>
<td style="text-align: center;">$-0.06$</td>
<td style="text-align: center;">4.01</td>
<td style="text-align: center;">0.66</td>
<td style="text-align: center;">$-0.08$</td>
<td style="text-align: center;">4.07</td>
<td style="text-align: center;">0.47</td>
</tr>
<tr>
<td style="text-align: center;">ClimaX</td>
<td style="text-align: center;">807.43</td>
<td style="text-align: center;">0.96</td>
<td style="text-align: center;">2.70</td>
<td style="text-align: center;">3.49</td>
<td style="text-align: center;">0.97</td>
<td style="text-align: center;">$-0.11$</td>
<td style="text-align: center;">2.79</td>
<td style="text-align: center;">0.99</td>
<td style="text-align: center;">$-0.06$</td>
<td style="text-align: center;">3.99</td>
<td style="text-align: center;">0.66</td>
<td style="text-align: center;">0.04</td>
<td style="text-align: center;">4.06</td>
<td style="text-align: center;">0.47</td>
</tr>
</tbody>
</table>
<p>bias closest to 0 for all three target variables, and performs similarly to the baselines in terms of Pearson correlation. While pretrained to perform forecasting, ClimaX has successfully captured the spatial structure of weather data, which helps in downstream tasks like downscaling. Figure 10 visualizes the downscaled predictions of ClimaX for the three target variables. The input is at a much lower resolution and contains a lot of bias compared to the ground truth. While the prediction is missing some fine details, it has successfully captured the general structure of the ERA5 data and removed input biases.</p>
<h1>4.5. Scaling laws analysis</h1>
<p>Transformers have shown favorable scaling properties for language [Kap+20; Hof+22], vision [Zha+22a], or even multi-modal tasks [Hen+20b; Hen+21; Ree+22b]. That is, their performance improves with respect to data size and model capacity given sufficient compute. In this section, we study the scaling laws of ClimaX in weather forecasting. Figure 11 presents the performance of ClimaX as a function of data size and model capacity. The $x$-axis is the pretraining data size measured in Gigabytes, which corresponds to 1 to 5 CMIP6 datasets, and the $y$-axis shows the RMSE of ClimaX on the 3-day forecasting task. We compare four ClimaX models with different capacities by varying the embedding dimension from 128 to 1024 . All experiments are conducted on the $5.625^{<em>}$ data. The error rate of the two biggest models decreases consistently as we increase the data and model size. This highlights the unique ability of ClimaX in learning from diverse and heterogeneous data sources, which allows us to further improve the performance by simply pretraining on more data. However, the two smaller models do not scale as well as the bigger ones, where increasing data size does not gain much improvement or can sometimes hurt performance. This result shows that larger models not only perform better but are also more data efficient.
In addition to data size and model capacity, data resolution is another important scaling dimension in the context of weather and climate. In many vision tasks such as classification, understanding the general, high-level structure of the image is sufficient to make accurate predictions. To model the underlying complex physical processes that govern weather and climate, however, it is important for a model to look at fine-grained details of the input in order to understand the spatial and temporal structure of data as well as the interactions between different variables. High-resolution data contains finer details and local processes of weather conditions that are not present in the low-resolution data, and thus provides stronger signals for training deep learning models. Figure 12 compares the performance of ClimaX pretrained and finetuned on $5.625^{</em>}$ and $1.40625^{<em>}$ data on global forecasting. Except for T2m at 1 day and 3 days lead times, ClimaX (1.40625</em>) consistently achieves lower RMSE and higher ACC than the low-resolution model. We note that for the high-resolution data we have to use a larger patch size ( 4 compared to 2 for low-resolution data) due to lack of memory issue. We can further improve the performance of ClimaX on the $1.40625^{*}$ data by reducing the patch size, as the</p>
<p><img alt="img-9.jpeg" src="img-9.jpeg" /></p>
<p>Figure 10: Example visualizations of downscaled prediction of key variables by ClimaX.
<img alt="img-10.jpeg" src="img-10.jpeg" /></p>
<p>Figure 11: Error on ERA5 3-day forecasting for different variables with respect to CMIP6 $5.625^{\circ}$ data seen during pre-training. Bigger models are more sample efficient.
model is able to capture better details.</p>
<h1>4.6. Ablation studies</h1>
<p>In the main forecasting results, we finetune a separate ClimaX model for each target variable at each lead time, as we found this protocol led to the best performance. However, this can be computationally expensive, as finetuning cost scales linearly with respect to the number of target variables and lead times. In this section, we consider different finetuning alternatives to investigate the trade-off between computation and performance.</p>
<h3>4.6.1. Should we finetune ClimaX for each variable separately or all at once?</h3>
<p>Instead of finetuning ClimaX for each target variable separately, we could alternatively finetune once to predict all variables in the input simultaneously, which we denote as ClimaX-all-vars. Figure 13 shows that ClimaX-all-vars achieves comparable performance to ClimaX in most of the tasks and only underperforms for forecasting T2m. This suggests that with a limited budget, one can finetune ClimaX to predict all target variables at the same time without losing much performance.</p>
<h3>4.6.2. Should we do iterative forecast or direct forecast?</h3>
<p>To avoid finetuning a different model for each lead time, we can finetune ClimaX to make predictions at a short horizon such as 6 hours, and roll out the predictions during inference to make forecasts at longer</p>
<p><img alt="img-11.jpeg" src="img-11.jpeg" /></p>
<p>Figure 12: Scaling performance with respect to data resolution. Despite a larger patch size, ClimaX (1.40625*) achieves consistently better performance than the low-resolution model on almost all tasks, except for T2m forecast at 1 day and 3 days lead times.
horizons. We call this model ClimaX-iter, where iter stands for iterative prediction [Ras+20]. We note that in order to roll out more than one step, ClimaX-iter must predict for all input variables, or in other words. This provides the benefit of finetuning a single model that can predict for any target variable at any lead time. Figure 13 shows that ClimaX-iter works reasonably well up to 1-day prediction, but the performance degrades significantly at longer lead times. This is not surprising, because ClimaX-iter is not finetuned to predict multiple steps into the future, leading to quick error accumulation. One can employ a multi-step objective for finetuning as in Pathak, Subramanian, et al. [Pat+22] to achieve better results.</p>
<h1>4.6.3. Can we finetune ClimaX to work for all lead times?</h1>
<p>Another way to avoid finetuning for each lead time separately is to finetune a lead-time-conditioned model. Specifically, during finetuning, we randomize the lead time from 6 hours to 7 days, resembling the pretraining setting. Note that unlike ClimaX-iter, we still have to finetune a separate model for each target variable. We call this model ClimaX-cont, wherein cont stands for continuous, a standard term used in previous works [Ras+20]. Figure 13 shows that ClimaX-cont performs competitively on 6 -hour to 7 -day forecasting, but fails to extrapolate to 2 weeks and 1 month lead times that are unseen during training. One can also randomize the lead time from 6 hours to 1 month, but that means the model sees much fewer data points for each target lead time, potentially hurting the performance.
The cost for finetuning each set of weights is a constant $C$, which is about 15 hours on an $8 \times$ V100s. Among different finetuning protocols, ClimaX is the most expensive, whose total cost is $C \times #$ variables $\times #$ lead_times, scaling linearly with the number of target variables and lead times. Following ClimaX are ClimaX-all-vars and ClimaX-cont, whose total costs are $C \times #$ lead_times and $C \times #$ variables, respectively. Finally, ClimaX-iter is the cheapest finetuning protocol, where we only have to finetune a single model that works for all target variables and at all lead times. The performance is proportional to the computational cost, as ClimaX is the best performing model, while ClimaX-iter is the worst.</p>
<h2>5. Discussion and Future Work</h2>
<p>The scaling of datasets, model architectures, and computation has resulted in a transformative impact in various subdisciplines of artificial intelligence, from natural language and speech processing to computer vision, as well as scientific applications in biology and chemistry. In particular, it has led to the emergence of general-purpose foundation models that are trained on large datasets and compute clusters, and can be easily adapted to a variety of downstream tasks efficiently, both in terms of compute and data supervision. Our work</p>
<p><img alt="img-12.jpeg" src="img-12.jpeg" /></p>
<p>Figure 13: Performance of ClimaX and its variations on weather forecasting. ClimaX-cont is a lead-timeconditioned model that we finetune to make predictions at 6 hours to 7 days. ClimaX-iter forecasts at a 6 -hour lead time and rolls out the predictions to forecast at longer horizons. ClimaX-all-vars predicts the future conditions of all variables in the input at particular lead-times.
represents a pioneering effort to enable such broad scaling and generality in data-driven models for weather and climate. This approach goes beyond the limitations of both traditional numerical modeling and existing data-driven forecasting methods. Unlike ClimaX, numerical models scale only in terms of computation and not in terms of dataset size, whereas existing data-driven models are typically limited to specific tasks and lack general-purpose applicability across a wide range of tasks.</p>
<p>In addition to traditional considerations in language and vision, foundation models like ClimaX open up new opportunities for scaling through the use of simulation datasets and grid resolutions. To simplify our approach, we chose to use pretraining datasets that include standard variables that have been benchmarked in previous research on data-driven forecasting [Ras+20; Pat+22]. Additionally, we avoided datasets that simulate future scenarios under different forcings to prevent any potential leakage for the climate projection task. Future research could explore incorporating both observational and simulated datasets that include a wider range of climate variables, higher spatiotemporal resolutions, and even extend into future scenarios. Further, we showed that resolution plays a crucial role in scaling of ClimaX. Due to our compute restrictions, we trained ClimaX on low to moderate resolutions. Nevertheless, our empirical trends suggest that scaling to higher resolutions $\left(0.25^{\circ}\right)$ is likely to lead to even better results.</p>
<p>Scaling efforts in the future can benefit from better sequence modeling architectures, especially those designed for multimodal spatiotemporal inputs. As we saw in ClimaX, the number of channels for climate datasets is much greater than those handled for standard multimodal settings (e.g., audio-video, vision-language models). Moreover, in practice, there is also a significant range of resolutions across different climate datasets. This heterogeneity drastically increases the raw length of input sequences for standard architectures such as ViT. In the future, we believe that investigating single multi-scale architectures (e.g., [Fan+21]) can potentially aid in scaling to such diverse multi-resolution and multi-modal datasets by learning to infer features relevant to atmospheric phenomena at increasing spatial resolutions.</p>
<p>In conclusion, we believe that the generality of our approach has potential applications beyond the tasks considered in this work. It would be interesting to explore the generalization of a pretrained ClimaX backbone to other Earth systems science tasks, such as predicting extreme weather events [Mir+19; Sil+17] and assessing anthropogenic contributions to climate change [Ros+08; HT13], as well as broader domains that are closely tied to weather and climate conditions, such as agriculture, demography, and actuarial sciences.</p>
<h1>Acknowledgments</h1>
<p>We would like to thank ECMWF for enabling this line of research with accessible public datasets, contributors of WebPlotDigitizer [Roh22] for making it easier to build Tables 10 and 11, and numerous other open-source libraries, notably numpy [Har+20] and PyTorch [Pas+19b]. Some icons in Fig. 1 by Freepik, smalllikeart, and GOWI from flaticon.com.</p>
<h2>References</h2>
<p>[Ado14] IPCC Adopted. "Climate change 2014 synthesis report." In: IPCC: Geneva, Szwitzerland (2014).
[Arc+20] Troy Arcomano, Istvan Szunyogh, Jaideep Pathak, Alexander Wikner, Brian R Hunt, and Edward Ott. "A machine learning-based global atmospheric forecast model." In: Geophysical Research Letters 47.9 (2020), e2020GL087776.
[Bal+22] V Balaji, Fleur Couvreux, Julie Deshayes, Jacques Gautrais, Frédéric Hourdin, and Catherine Rio. "Are general circulation models obsolete?" In: Proceedings of the National Academy of Sciences 119.47 (2022), e2202075119.
[Bau+20] Peter Bauer, Tiago Quintino, Nils Wedi, Antonio Bonanni, Marcin Chrust, Willem Deconinck, Michail Diamantakis, Peter Düben, Stephen English, Johannes Flemming, et al. The ecmwf scalability programme: Progress and plans. European Centre for Medium Range Weather Forecasts, 2020 .
[BGS20] Lea Beusch, Lukas Gudmundsson, and Sonia I Seneviratne. "Emulating Earth system model temperatures with MESMER: from global mean temperature trajectories to grid-point-level realizations on land." In: Earth System Dynamics 11.1 (2020), pp. 139-159.
[Bi+22] Kaifeng Bi, Lingxi Xie, Hengheng Zhang, Xin Chen, Xiaotao Gu, and Qi Tian. "Pangu-Weather: A 3D High-Resolution Model for Fast and Accurate Global Weather Forecast." In: arXiv preprint arXiv:2211.02556 (2022).
[BMMG20] Jorge Baño-Medina, Rodrigo Manzanas, and José Manuel Gutiérrez. "Configuration and intercomparison of deep learning neural models for statistical downscaling." In: Geoscientific Model Development 13.4 (2020), pp. 2109-2124.
[Bom+21] Rishi Bommasani, Drew A. Hudson, et al. "On the Opportunities and Risks of Foundation Models." In: ArXiv (2021). URL: https://crfm.stanford.edu/assets/report.pdf.
[Bou+10] Philippe Bougeault, Zoltan Toth, Craig Bishop, Barbara Brown, David Burridge, De Hui Chen, Beth Ebert, Manuel Fuentes, Thomas M Hamill, Ken Mylne, et al. "The THORPEX interactive grand global ensemble." In: Bulletin of the American Meteorological Society 91.8 (2010), pp. 10591072 .
[Bra+22] Johannes Brandstetter, Rianne van den Berg, Max Welling, and Jayesh K Gupta. "Clifford Neural Layers for PDE Modeling." In: arXiv preprint arXiv:2209.04934 (2022).
[Bro+20] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. "Language models are few-shot learners." In: Advances in neural information processing systems 33 (2020), pp. 18771901 .</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{4}$ We finetune the LayerNorm in ClimaX ${ }_{\text {frozen }}$, as suggested by Lu, Grover, et al. [Lu+22].&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref4:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref5:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>