<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-3471 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-3471</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-3471</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-80.html">extraction-schema-80</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <p><strong>Paper ID:</strong> paper-226842721</p>
                <p><strong>Paper Title:</strong> <a href="https://api.elsevier.com/content/article/pii/S1389041720300784" target="_blank">Cogmic space for narrative-based world representation</a></p>
                <p><strong>Paper Abstract:</strong> Representing a world or a physical/social environment in an agent’s cognitive system is essential for creating human-like artiﬁcial intelligence. This study takes a story-centered approach to this issue. In this context, a story refers to an internal representation involving a narrative structure, which is assumed to be a common form of organizing past, present, future, and ﬁctional events and situations. In the artiﬁcial intelligence ﬁeld, a story or narrative is traditionally treated as a symbolic representation. However, a symbolic story representation is limited in its representational power to construct a rich world. For example, a symbolic story representation is unﬁt to handle the sensory/bodily dimension of a world. In search of a computational theory for narrative-based world representation, this study proposes the conceptual framework of a Cogmic Space for a comic strip-like representation of a world. In the proposed framework, a story is positioned as a mid-level representation, in which the conceptual and sensory/bodily dimensions of a world are uniﬁed. The events and their background situations that constitute a story are uniﬁed into a sequence of panels. Based on this structure, a representation (i.e., a story) and the represented environment are connected via an isomorphism of their temporal, spatial, and relational structures. Furthermore, the framework of a Cogmic Space is associated with the generative aspect of representations, which is conceptualized in terms of unconscious-and conscious-level processes/representations. Finally, a proof-of-concept implementation is presented to provide a concrete account of the proposed framework.</p>
                <p><strong>Cost:</strong> 0.016</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e3471.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e3471.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Cogmic Space</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Cogmic Space (comic-strip-like story representation)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A mid-level, comic-strip-like representational framework that encodes world knowledge as a sequence of panels (events+situations) unifying conceptual and sensory/bodily information, supporting conscious ('inner discourse') and unconscious ('story') generative processes.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Cogmic Space (panel-based narrative representation)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Conceptual knowledge about events and situations is represented as sequences of 2-D 'panels' where each panel contains objects, motions, and background; panels map isomorphically onto temporal segments of sensory/bodily space (temporal, spatial/physical, and conceptual relations). Stories are stored representations (unconscious) and inner discourses are momentary conscious narrations generated via 'inner narrating'.</td>
                        </tr>
                        <tr>
                            <td><strong>level_of_analysis</strong></td>
                            <td>functional</td>
                        </tr>
                        <tr>
                            <td><strong>supporting_evidence</strong></td>
                            <td>Argumentative and conceptual support within the paper plus a proof-of-concept implementation that encodes simple stories into panels, generates associated structures, detects changes, produces causal/intentional relations, and renders simple language output; aligns with cognitive phenomena of narrative memory, event segmentation, and multimodal recall.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence_or_challenges</strong></td>
                            <td>Implementation is preliminary: sensory/bodily details are only broadly addressed; object categories are ad-hoc; panels limited to four in the prototype; commonsense inference for plausibility is missing; unconscious-level generative processes are not implemented; scalability and perceptual grounding are unproven.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_theories</strong></td>
                            <td>Explicitly contrasted with: (1) symbolic (amodal) representations which lack sensory grounding (paper argues Cogmic Space unifies conceptual and sensory/bodily dimensions); (2) state-based representations which the paper argues are too restrictive (Cogmic Space is event-centric and unifies events with situations); (3) perceptual symbol systems and conceptual spaces whose ideas about perceptual grounding and geometric semantics are acknowledged as related inspirations.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_limitations_or_open_questions</strong></td>
                            <td>How to integrate detailed sensory/bodily imagery (visual features, posture, facial expression) with panels; how to develop the unconscious generative (self-organizing) story processes; how to scale beyond small, hand-encoded stories; how to compute story similarity including sensory dimensions; how to represent self-as-narrator vs self-as-character qualitatively differently.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3471.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e3471.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Symbolic Representation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Symbolic (amodal) story representation / case-frame representations</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Traditional AI account where conceptual knowledge and events are encoded as amodal symbols, predicate-argument structures, frames, scripts, or semantic networks (e.g., [Eat (agent Lisa) (object Apple)]).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Scripts, plans, goals, and understanding: An inquiry into human knowledge structures</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Symbolic (amodal) representation</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Concepts and events are represented by discrete, language-like symbols and structured frames (predicates with arguments, scripts, schemas); meaning arises from symbolic relationships and manipulation rather than perceptual simulation.</td>
                        </tr>
                        <tr>
                            <td><strong>level_of_analysis</strong></td>
                            <td>functional</td>
                        </tr>
                        <tr>
                            <td><strong>supporting_evidence</strong></td>
                            <td>Historically successful in explicit reasoning, planning, script-based story systems and many symbolic story-generation and comprehension systems (Schank & Abelson; planning-based story generation).</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence_or_challenges</strong></td>
                            <td>Paper argues symbolic formats have low representational power for perceptual/sensory/bodily content, fail to capture appearance, dynamics, fine-grained situational detail, and are disconnected from perception; they exacerbate the frame problem and make encoding rich experiential memory difficult.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_theories</strong></td>
                            <td>Contrasted with perceptual-symbol and hybrid mid-level representations: symbolic is amodal and arbitrary whereas perceptual-symbol systems and Cogmic Space emphasize modality and analogical structure; contrasted with state-based models, where symbolic state-change accounts may miss event richness.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_limitations_or_open_questions</strong></td>
                            <td>How to augment symbolic structures to include rich sensory/bodily detail without exploding complexity; how to bridge symbolic representations with perceptual data for integrative episodic memory.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3471.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e3471.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Perceptual Symbol Systems</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Perceptual Symbol Systems (Barsalou, 1999)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Theory that conceptual knowledge is grounded in modality-specific perceptual systems and represented via dynamic, analogical 'perceptual symbols' that support simulation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Perceptual symbol systems</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Perceptual Symbol Systems</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Concepts are represented as distributed, modality-specific patterns (perceptual symbols) derived from sensory/motor experience; conceptual processing involves reenactment or simulation of perceptual states rather than manipulation of amodal symbols.</td>
                        </tr>
                        <tr>
                            <td><strong>level_of_analysis</strong></td>
                            <td>functional</td>
                        </tr>
                        <tr>
                            <td><strong>supporting_evidence</strong></td>
                            <td>Empirical support from cognitive psychology on modality-specific activations during conceptual tasks, simulation effects in comprehension, and the importance of perceptual features in concept use; used as a theoretical basis in the paper to justify linking stories with sensory/bodily space.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence_or_challenges</strong></td>
                            <td>Computational realization is challenging; paper notes many existing neural/episodic-memory models emphasize perception but neglect higher-level conceptual structure; integrating dynamic simulation with higher-level narrative structure remains open.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_theories</strong></td>
                            <td>Presented as an alternative to amodal symbolic representations and complementary to Cogmic Space: Barsalou emphasizes perceptual grounding whereas Cogmic Space attempts a mid-level narrative format that unifies perceptual and conceptual dimensions; conceptual spaces (Gärdenfors) provide an orthogonal geometric view.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_limitations_or_open_questions</strong></td>
                            <td>How to implement modality-grounded, dynamic perceptual symbols that also support abstract narrative relations, how to combine bottom-up perception with top-down narrative generation in a computational system.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3471.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e3471.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Conceptual Spaces</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Conceptual Spaces (Gärdenfors)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Geometric, vector-based account of conceptual representation where concepts are regions in metric spaces defined by quality dimensions (e.g., color, shape, action parameters).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Conceptual spaces: The geometry of thought</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Conceptual Spaces (geometric representation)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Concepts are represented as points or regions in continuous, multi-dimensional metric spaces (quality dimensions capture perceptual and conceptual features); similarity and prototype effects arise from geometric relations.</td>
                        </tr>
                        <tr>
                            <td><strong>level_of_analysis</strong></td>
                            <td>functional</td>
                        </tr>
                        <tr>
                            <td><strong>supporting_evidence</strong></td>
                            <td>Explains graded similarity, prototypes, and metric-based judgments; provides a computationally useful representation for action and event semantics (cited as potentially relevant to motion representation).</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence_or_challenges</strong></td>
                            <td>Does not by itself specify dynamics of narrative generation or how to represent complex multi-entity events and relations; integrating high-dimensional perceptual features into compact conceptual spaces and linking them to narrative structure remains an open engineering problem.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_theories</strong></td>
                            <td>Complementary to perceptual-symbol accounts (both emphasize grounding) and contrasted indirectly with symbolic/amodal representations; Cogmic Space could use conceptual-space style vector semantics for sensory/bodily aspects within panels.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_limitations_or_open_questions</strong></td>
                            <td>How to scale to richly structured events, how to represent causal/intentional relations and temporal sequencing in geometric spaces, and how to tie vector-based semantics to symbolic narrative relations.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3471.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e3471.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Picture Theory / Structural Isomorphism</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Picture theory of representation / structural isomorphism (Cummins, 1996)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Idea that representations function by preserving structural relations (isomorphisms) between representation and represented world (e.g., maps preserve geographic structure).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Representations, targets, and attitudes</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Structural isomorphism / picture theory</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Conceptual knowledge is represented via structures that are isomorphic (structurally analogous) to relations in the world: parts and relations in the representation mirror parts and relations in the represented domain, enabling analogy-like processes and mapping.</td>
                        </tr>
                        <tr>
                            <td><strong>level_of_analysis</strong></td>
                            <td>functional</td>
                        </tr>
                        <tr>
                            <td><strong>supporting_evidence</strong></td>
                            <td>Provides a principled account for representational fidelity in spatial and relational domains; motivates mapping-based cognition and analogical reasoning; in the paper, underpins the Cogmic Space claim that panels map to temporal/spatial segments of sensory/bodily space.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence_or_challenges</strong></td>
                            <td>Exact isomorphism rarely obtains for complex or abstract domains; the paper notes only partial/componential information is abstracted into stories and isomorphism is selective and driven by narrative relevance.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_theories</strong></td>
                            <td>Sits between fully symbolic and purely perceptual accounts: unlike amodal symbols, it emphasizes structural correspondence; Cogmic Space adopts this perspective to link panels with sensory/bodily segments while allowing conceptual projection.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_limitations_or_open_questions</strong></td>
                            <td>How to operationalize partial isomorphisms for rich, noisy sensory inputs; how to determine which aspects of the world are preserved in the representational mapping (selection criteria).</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3471.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e3471.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Event / Situation Models</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Event representation / Situation models (Radvansky & Zacks; Zwaan & Radvansky)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Models positing that events are complex, multi-dimensional representations integrating spatiotemporal context, entities, attributes, goals, causal and temporal relations—often called event or situation models.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Event perception</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Event / Situation models</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Conceptual knowledge about occurrences is structured as richly interrelated representations containing spatiotemporal locations, entities, physical and internal properties, structural relations among entities, and inter-event linking relations (temporal, causal).</td>
                        </tr>
                        <tr>
                            <td><strong>level_of_analysis</strong></td>
                            <td>functional</td>
                        </tr>
                        <tr>
                            <td><strong>supporting_evidence</strong></td>
                            <td>Cognitive psychology evidence on event segmentation, narrative comprehension, and memory showing people encode spatiotemporal and causal structure of events; referenced as a descriptive basis for the panel contents in Cogmic Space.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence_or_challenges</strong></td>
                            <td>Computationally representing all these multimodal, relational dimensions is difficult; the paper notes event models provide a useful taxonomy but are still hard to operationalize in rich, scalable AI systems.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_theories</strong></td>
                            <td>More descriptive and integrative than simple symbolic frames; overlaps with perceptual-symbol accounts in emphasizing perceptual and situational detail; Cogmic Space aims to operationalize event-model components within a panel-based format.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_limitations_or_open_questions</strong></td>
                            <td>How to automatically extract and compress relevant event dimensions from continuous sensory input; how to balance completeness and tractability in stored event models.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3471.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e3471.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Distributed / Neural End-to-End Models</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Neural network / distributional semantic / end-to-end models (e.g., hierarchical neural story generation)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Connectionist approaches where conceptual knowledge is encoded as distributed activation patterns across network weights; end-to-end models learn task mappings (e.g., text generation) without explicit intermediate symbolic representations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Hierarchical neural story generation</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Distributed / neural end-to-end representations</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Conceptual knowledge and events are implicitly encoded in high-dimensional distributed patterns within neural network parameters and activations; generation or comprehension is performed by learned mappings rather than explicit symbolic structures.</td>
                        </tr>
                        <tr>
                            <td><strong>level_of_analysis</strong></td>
                            <td>functional</td>
                        </tr>
                        <tr>
                            <td><strong>supporting_evidence</strong></td>
                            <td>Strong empirical success in NLP tasks including narrative generation and episodic encoding/retrieval in deep models; cited as a contemporary approach in narrative processing.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence_or_challenges</strong></td>
                            <td>Paper argues end-to-end systems are typically task-specific and do not reveal internal generative story dynamics; they may lack explicit, interpretable mid-level representations required for integrative cognitive architecture and for explaining internal narrative processes.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_theories</strong></td>
                            <td>Contrasted with symbolic and perceptual-symbol approaches: distributed models provide grounding and pattern-based generalization but often lack explicit, manipulable story structure; Cogmic Space proposes an explicit mid-level format that could complement distributed representations.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_limitations_or_open_questions</strong></td>
                            <td>How to extract interpretable mid-level narrative structures from distributed models; how to combine the strengths of end-to-end learning (scalability) with explicit representational formats (explainability, narrative structure).</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3471.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e3471.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>State-based Representation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>State-based world representation (classical AI / problem-space)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Representation approach where worlds are encoded as sets of states and events/actions are transitions between states (preconditions/effects); used in planning and problem solving.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Human problem solving</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>State-based representation (problem-space)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>World knowledge is represented as discrete states; actions/events are modeled as operators that change state; planning constructs sequences of actions transforming an initial state into a goal state.</td>
                        </tr>
                        <tr>
                            <td><strong>level_of_analysis</strong></td>
                            <td>functional</td>
                        </tr>
                        <tr>
                            <td><strong>supporting_evidence</strong></td>
                            <td>Highly successful for constrained domains (games, classical planning) where state spaces are well-defined; underlies many symbolic planning/story-generation systems.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence_or_challenges</strong></td>
                            <td>Paper highlights fundamental drawbacks: cannot represent an unlimited world (frame problem), restricts range of world information, and may not capture the qualitative nature of events which are not easily characterized as state transitions.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_theories</strong></td>
                            <td>Contrasted with event-centric/story-centric representations (like Cogmic Space) which place events and situations at the core rather than treating events merely as state changes; state-based methods are task-effective but less suitable for rich, open-ended narrative memory.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_limitations_or_open_questions</strong></td>
                            <td>How to represent open-ended, context-rich events and background situations without exponential state-space blowup; how to encode intentions, causality, and narrative-level structures within state frameworks.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3471.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e3471.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Damasio Narrative Map</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Damasio's core and extended consciousness (narrative/nonverbal neural map account)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Theory that core consciousness constructs a nonverbal neural map of organized events (a kind of narrative) and extended consciousness builds autobiographical identity across time.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>The feeling of what happens: Body and emotion in the making of consciousness</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Damasio's narrative neural-map account (core/extended consciousness)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Representations underlying consciousness are organized as neural maps that compose organized events into narrative structures; core consciousness generates a momentary 'story' (nonverbal map) about here-and-now, while extended consciousness composes autobiographical narratives.</td>
                        </tr>
                        <tr>
                            <td><strong>level_of_analysis</strong></td>
                            <td>functional</td>
                        </tr>
                        <tr>
                            <td><strong>supporting_evidence</strong></td>
                            <td>Neuropsychological and theoretical arguments linking bodily states, emotional processing, and organized event maps to the sense of self and narrative; used in the paper to motivate narrative-based representational framing.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence_or_challenges</strong></td>
                            <td>The account is partly metaphorical; operationalizing 'nonverbal neural maps' into concrete computational representations is nontrivial; the paper notes conceptual parallels but does not provide neural-level validation.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_theories</strong></td>
                            <td>Aligned with narrative-focused theories of consciousness (Dennett) and with story-centric representational proposals like Cogmic Space; differs from purely symbol-manipulation accounts by grounding in bodily/emotional mapping.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_limitations_or_open_questions</strong></td>
                            <td>How to map Damasio's conceptual neural maps to implementable data structures; how to reconcile metaphorical descriptions with concrete mechanisms for narrative memory generation and retrieval.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Perceptual symbol systems <em>(Rating: 2)</em></li>
                <li>Conceptual spaces: The geometry of thought <em>(Rating: 2)</em></li>
                <li>Event perception <em>(Rating: 2)</em></li>
                <li>Scripts, plans, goals, and understanding: An inquiry into human knowledge structures <em>(Rating: 2)</em></li>
                <li>Hierarchical neural story generation <em>(Rating: 1)</em></li>
                <li>Representations, targets, and attitudes <em>(Rating: 1)</em></li>
                <li>The feeling of what happens: Body and emotion in the making of consciousness <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-3471",
    "paper_id": "paper-226842721",
    "extraction_schema_id": "extraction-schema-80",
    "extracted_data": [
        {
            "name_short": "Cogmic Space",
            "name_full": "Cogmic Space (comic-strip-like story representation)",
            "brief_description": "A mid-level, comic-strip-like representational framework that encodes world knowledge as a sequence of panels (events+situations) unifying conceptual and sensory/bodily information, supporting conscious ('inner discourse') and unconscious ('story') generative processes.",
            "citation_title": "here",
            "mention_or_use": "use",
            "theory_name": "Cogmic Space (panel-based narrative representation)",
            "theory_description": "Conceptual knowledge about events and situations is represented as sequences of 2-D 'panels' where each panel contains objects, motions, and background; panels map isomorphically onto temporal segments of sensory/bodily space (temporal, spatial/physical, and conceptual relations). Stories are stored representations (unconscious) and inner discourses are momentary conscious narrations generated via 'inner narrating'.",
            "level_of_analysis": "functional",
            "supporting_evidence": "Argumentative and conceptual support within the paper plus a proof-of-concept implementation that encodes simple stories into panels, generates associated structures, detects changes, produces causal/intentional relations, and renders simple language output; aligns with cognitive phenomena of narrative memory, event segmentation, and multimodal recall.",
            "counter_evidence_or_challenges": "Implementation is preliminary: sensory/bodily details are only broadly addressed; object categories are ad-hoc; panels limited to four in the prototype; commonsense inference for plausibility is missing; unconscious-level generative processes are not implemented; scalability and perceptual grounding are unproven.",
            "comparison_to_other_theories": "Explicitly contrasted with: (1) symbolic (amodal) representations which lack sensory grounding (paper argues Cogmic Space unifies conceptual and sensory/bodily dimensions); (2) state-based representations which the paper argues are too restrictive (Cogmic Space is event-centric and unifies events with situations); (3) perceptual symbol systems and conceptual spaces whose ideas about perceptual grounding and geometric semantics are acknowledged as related inspirations.",
            "notable_limitations_or_open_questions": "How to integrate detailed sensory/bodily imagery (visual features, posture, facial expression) with panels; how to develop the unconscious generative (self-organizing) story processes; how to scale beyond small, hand-encoded stories; how to compute story similarity including sensory dimensions; how to represent self-as-narrator vs self-as-character qualitatively differently.",
            "uuid": "e3471.0"
        },
        {
            "name_short": "Symbolic Representation",
            "name_full": "Symbolic (amodal) story representation / case-frame representations",
            "brief_description": "Traditional AI account where conceptual knowledge and events are encoded as amodal symbols, predicate-argument structures, frames, scripts, or semantic networks (e.g., [Eat (agent Lisa) (object Apple)]).",
            "citation_title": "Scripts, plans, goals, and understanding: An inquiry into human knowledge structures",
            "mention_or_use": "mention",
            "theory_name": "Symbolic (amodal) representation",
            "theory_description": "Concepts and events are represented by discrete, language-like symbols and structured frames (predicates with arguments, scripts, schemas); meaning arises from symbolic relationships and manipulation rather than perceptual simulation.",
            "level_of_analysis": "functional",
            "supporting_evidence": "Historically successful in explicit reasoning, planning, script-based story systems and many symbolic story-generation and comprehension systems (Schank & Abelson; planning-based story generation).",
            "counter_evidence_or_challenges": "Paper argues symbolic formats have low representational power for perceptual/sensory/bodily content, fail to capture appearance, dynamics, fine-grained situational detail, and are disconnected from perception; they exacerbate the frame problem and make encoding rich experiential memory difficult.",
            "comparison_to_other_theories": "Contrasted with perceptual-symbol and hybrid mid-level representations: symbolic is amodal and arbitrary whereas perceptual-symbol systems and Cogmic Space emphasize modality and analogical structure; contrasted with state-based models, where symbolic state-change accounts may miss event richness.",
            "notable_limitations_or_open_questions": "How to augment symbolic structures to include rich sensory/bodily detail without exploding complexity; how to bridge symbolic representations with perceptual data for integrative episodic memory.",
            "uuid": "e3471.1"
        },
        {
            "name_short": "Perceptual Symbol Systems",
            "name_full": "Perceptual Symbol Systems (Barsalou, 1999)",
            "brief_description": "Theory that conceptual knowledge is grounded in modality-specific perceptual systems and represented via dynamic, analogical 'perceptual symbols' that support simulation.",
            "citation_title": "Perceptual symbol systems",
            "mention_or_use": "mention",
            "theory_name": "Perceptual Symbol Systems",
            "theory_description": "Concepts are represented as distributed, modality-specific patterns (perceptual symbols) derived from sensory/motor experience; conceptual processing involves reenactment or simulation of perceptual states rather than manipulation of amodal symbols.",
            "level_of_analysis": "functional",
            "supporting_evidence": "Empirical support from cognitive psychology on modality-specific activations during conceptual tasks, simulation effects in comprehension, and the importance of perceptual features in concept use; used as a theoretical basis in the paper to justify linking stories with sensory/bodily space.",
            "counter_evidence_or_challenges": "Computational realization is challenging; paper notes many existing neural/episodic-memory models emphasize perception but neglect higher-level conceptual structure; integrating dynamic simulation with higher-level narrative structure remains open.",
            "comparison_to_other_theories": "Presented as an alternative to amodal symbolic representations and complementary to Cogmic Space: Barsalou emphasizes perceptual grounding whereas Cogmic Space attempts a mid-level narrative format that unifies perceptual and conceptual dimensions; conceptual spaces (Gärdenfors) provide an orthogonal geometric view.",
            "notable_limitations_or_open_questions": "How to implement modality-grounded, dynamic perceptual symbols that also support abstract narrative relations, how to combine bottom-up perception with top-down narrative generation in a computational system.",
            "uuid": "e3471.2"
        },
        {
            "name_short": "Conceptual Spaces",
            "name_full": "Conceptual Spaces (Gärdenfors)",
            "brief_description": "Geometric, vector-based account of conceptual representation where concepts are regions in metric spaces defined by quality dimensions (e.g., color, shape, action parameters).",
            "citation_title": "Conceptual spaces: The geometry of thought",
            "mention_or_use": "mention",
            "theory_name": "Conceptual Spaces (geometric representation)",
            "theory_description": "Concepts are represented as points or regions in continuous, multi-dimensional metric spaces (quality dimensions capture perceptual and conceptual features); similarity and prototype effects arise from geometric relations.",
            "level_of_analysis": "functional",
            "supporting_evidence": "Explains graded similarity, prototypes, and metric-based judgments; provides a computationally useful representation for action and event semantics (cited as potentially relevant to motion representation).",
            "counter_evidence_or_challenges": "Does not by itself specify dynamics of narrative generation or how to represent complex multi-entity events and relations; integrating high-dimensional perceptual features into compact conceptual spaces and linking them to narrative structure remains an open engineering problem.",
            "comparison_to_other_theories": "Complementary to perceptual-symbol accounts (both emphasize grounding) and contrasted indirectly with symbolic/amodal representations; Cogmic Space could use conceptual-space style vector semantics for sensory/bodily aspects within panels.",
            "notable_limitations_or_open_questions": "How to scale to richly structured events, how to represent causal/intentional relations and temporal sequencing in geometric spaces, and how to tie vector-based semantics to symbolic narrative relations.",
            "uuid": "e3471.3"
        },
        {
            "name_short": "Picture Theory / Structural Isomorphism",
            "name_full": "Picture theory of representation / structural isomorphism (Cummins, 1996)",
            "brief_description": "Idea that representations function by preserving structural relations (isomorphisms) between representation and represented world (e.g., maps preserve geographic structure).",
            "citation_title": "Representations, targets, and attitudes",
            "mention_or_use": "mention",
            "theory_name": "Structural isomorphism / picture theory",
            "theory_description": "Conceptual knowledge is represented via structures that are isomorphic (structurally analogous) to relations in the world: parts and relations in the representation mirror parts and relations in the represented domain, enabling analogy-like processes and mapping.",
            "level_of_analysis": "functional",
            "supporting_evidence": "Provides a principled account for representational fidelity in spatial and relational domains; motivates mapping-based cognition and analogical reasoning; in the paper, underpins the Cogmic Space claim that panels map to temporal/spatial segments of sensory/bodily space.",
            "counter_evidence_or_challenges": "Exact isomorphism rarely obtains for complex or abstract domains; the paper notes only partial/componential information is abstracted into stories and isomorphism is selective and driven by narrative relevance.",
            "comparison_to_other_theories": "Sits between fully symbolic and purely perceptual accounts: unlike amodal symbols, it emphasizes structural correspondence; Cogmic Space adopts this perspective to link panels with sensory/bodily segments while allowing conceptual projection.",
            "notable_limitations_or_open_questions": "How to operationalize partial isomorphisms for rich, noisy sensory inputs; how to determine which aspects of the world are preserved in the representational mapping (selection criteria).",
            "uuid": "e3471.4"
        },
        {
            "name_short": "Event / Situation Models",
            "name_full": "Event representation / Situation models (Radvansky & Zacks; Zwaan & Radvansky)",
            "brief_description": "Models positing that events are complex, multi-dimensional representations integrating spatiotemporal context, entities, attributes, goals, causal and temporal relations—often called event or situation models.",
            "citation_title": "Event perception",
            "mention_or_use": "mention",
            "theory_name": "Event / Situation models",
            "theory_description": "Conceptual knowledge about occurrences is structured as richly interrelated representations containing spatiotemporal locations, entities, physical and internal properties, structural relations among entities, and inter-event linking relations (temporal, causal).",
            "level_of_analysis": "functional",
            "supporting_evidence": "Cognitive psychology evidence on event segmentation, narrative comprehension, and memory showing people encode spatiotemporal and causal structure of events; referenced as a descriptive basis for the panel contents in Cogmic Space.",
            "counter_evidence_or_challenges": "Computationally representing all these multimodal, relational dimensions is difficult; the paper notes event models provide a useful taxonomy but are still hard to operationalize in rich, scalable AI systems.",
            "comparison_to_other_theories": "More descriptive and integrative than simple symbolic frames; overlaps with perceptual-symbol accounts in emphasizing perceptual and situational detail; Cogmic Space aims to operationalize event-model components within a panel-based format.",
            "notable_limitations_or_open_questions": "How to automatically extract and compress relevant event dimensions from continuous sensory input; how to balance completeness and tractability in stored event models.",
            "uuid": "e3471.5"
        },
        {
            "name_short": "Distributed / Neural End-to-End Models",
            "name_full": "Neural network / distributional semantic / end-to-end models (e.g., hierarchical neural story generation)",
            "brief_description": "Connectionist approaches where conceptual knowledge is encoded as distributed activation patterns across network weights; end-to-end models learn task mappings (e.g., text generation) without explicit intermediate symbolic representations.",
            "citation_title": "Hierarchical neural story generation",
            "mention_or_use": "mention",
            "theory_name": "Distributed / neural end-to-end representations",
            "theory_description": "Conceptual knowledge and events are implicitly encoded in high-dimensional distributed patterns within neural network parameters and activations; generation or comprehension is performed by learned mappings rather than explicit symbolic structures.",
            "level_of_analysis": "functional",
            "supporting_evidence": "Strong empirical success in NLP tasks including narrative generation and episodic encoding/retrieval in deep models; cited as a contemporary approach in narrative processing.",
            "counter_evidence_or_challenges": "Paper argues end-to-end systems are typically task-specific and do not reveal internal generative story dynamics; they may lack explicit, interpretable mid-level representations required for integrative cognitive architecture and for explaining internal narrative processes.",
            "comparison_to_other_theories": "Contrasted with symbolic and perceptual-symbol approaches: distributed models provide grounding and pattern-based generalization but often lack explicit, manipulable story structure; Cogmic Space proposes an explicit mid-level format that could complement distributed representations.",
            "notable_limitations_or_open_questions": "How to extract interpretable mid-level narrative structures from distributed models; how to combine the strengths of end-to-end learning (scalability) with explicit representational formats (explainability, narrative structure).",
            "uuid": "e3471.6"
        },
        {
            "name_short": "State-based Representation",
            "name_full": "State-based world representation (classical AI / problem-space)",
            "brief_description": "Representation approach where worlds are encoded as sets of states and events/actions are transitions between states (preconditions/effects); used in planning and problem solving.",
            "citation_title": "Human problem solving",
            "mention_or_use": "mention",
            "theory_name": "State-based representation (problem-space)",
            "theory_description": "World knowledge is represented as discrete states; actions/events are modeled as operators that change state; planning constructs sequences of actions transforming an initial state into a goal state.",
            "level_of_analysis": "functional",
            "supporting_evidence": "Highly successful for constrained domains (games, classical planning) where state spaces are well-defined; underlies many symbolic planning/story-generation systems.",
            "counter_evidence_or_challenges": "Paper highlights fundamental drawbacks: cannot represent an unlimited world (frame problem), restricts range of world information, and may not capture the qualitative nature of events which are not easily characterized as state transitions.",
            "comparison_to_other_theories": "Contrasted with event-centric/story-centric representations (like Cogmic Space) which place events and situations at the core rather than treating events merely as state changes; state-based methods are task-effective but less suitable for rich, open-ended narrative memory.",
            "notable_limitations_or_open_questions": "How to represent open-ended, context-rich events and background situations without exponential state-space blowup; how to encode intentions, causality, and narrative-level structures within state frameworks.",
            "uuid": "e3471.7"
        },
        {
            "name_short": "Damasio Narrative Map",
            "name_full": "Damasio's core and extended consciousness (narrative/nonverbal neural map account)",
            "brief_description": "Theory that core consciousness constructs a nonverbal neural map of organized events (a kind of narrative) and extended consciousness builds autobiographical identity across time.",
            "citation_title": "The feeling of what happens: Body and emotion in the making of consciousness",
            "mention_or_use": "mention",
            "theory_name": "Damasio's narrative neural-map account (core/extended consciousness)",
            "theory_description": "Representations underlying consciousness are organized as neural maps that compose organized events into narrative structures; core consciousness generates a momentary 'story' (nonverbal map) about here-and-now, while extended consciousness composes autobiographical narratives.",
            "level_of_analysis": "functional",
            "supporting_evidence": "Neuropsychological and theoretical arguments linking bodily states, emotional processing, and organized event maps to the sense of self and narrative; used in the paper to motivate narrative-based representational framing.",
            "counter_evidence_or_challenges": "The account is partly metaphorical; operationalizing 'nonverbal neural maps' into concrete computational representations is nontrivial; the paper notes conceptual parallels but does not provide neural-level validation.",
            "comparison_to_other_theories": "Aligned with narrative-focused theories of consciousness (Dennett) and with story-centric representational proposals like Cogmic Space; differs from purely symbol-manipulation accounts by grounding in bodily/emotional mapping.",
            "notable_limitations_or_open_questions": "How to map Damasio's conceptual neural maps to implementable data structures; how to reconcile metaphorical descriptions with concrete mechanisms for narrative memory generation and retrieval.",
            "uuid": "e3471.8"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Perceptual symbol systems",
            "rating": 2,
            "sanitized_title": "perceptual_symbol_systems"
        },
        {
            "paper_title": "Conceptual spaces: The geometry of thought",
            "rating": 2,
            "sanitized_title": "conceptual_spaces_the_geometry_of_thought"
        },
        {
            "paper_title": "Event perception",
            "rating": 2,
            "sanitized_title": "event_perception"
        },
        {
            "paper_title": "Scripts, plans, goals, and understanding: An inquiry into human knowledge structures",
            "rating": 2,
            "sanitized_title": "scripts_plans_goals_and_understanding_an_inquiry_into_human_knowledge_structures"
        },
        {
            "paper_title": "Hierarchical neural story generation",
            "rating": 1,
            "sanitized_title": "hierarchical_neural_story_generation"
        },
        {
            "paper_title": "Representations, targets, and attitudes",
            "rating": 1,
            "sanitized_title": "representations_targets_and_attitudes"
        },
        {
            "paper_title": "The feeling of what happens: Body and emotion in the making of consciousness",
            "rating": 1,
            "sanitized_title": "the_feeling_of_what_happens_body_and_emotion_in_the_making_of_consciousness"
        }
    ],
    "cost": 0.015532749999999998,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Cogmic space for narrative-based world representation Action editor: Alexei Samsonovich
13 November 2020</p>
<p>Taisuke Akimoto akimoto@ai.kyutech.ac.jp 
Kyushu Institute of Technology
680-4, 820-8502Kawazu, IizukaFukuokaJapan</p>
<p>Cogmic space for narrative-based world representation Action editor: Alexei Samsonovich
13 November 2020043AF70E71F31F035F6C82660E5C980B10.1016/j.cogsys.2020.10.005Received 20 July 2020; accepted 28 October 2020World representationStoryMultimodal representationMemoryArtificial cognitive system
Representing a world or a physical/social environment in an agent's cognitive system is essential for creating human-like artificial intelligence.This study takes a story-centered approach to this issue.In this context, a story refers to an internal representation involving a narrative structure, which is assumed to be a common form of organizing past, present, future, and fictional events and situations.In the artificial intelligence field, a story or narrative is traditionally treated as a symbolic representation.However, a symbolic story representation is limited in its representational power to construct a rich world.For example, a symbolic story representation is unfit to handle the sensory/bodily dimension of a world.In search of a computational theory for narrative-based world representation, this study proposes the conceptual framework of a Cogmic Space for a comic strip-like representation of a world.In the proposed framework, a story is positioned as a mid-level representation, in which the conceptual and sensory/bodily dimensions of a world are unified.The events and their background situations that constitute a story are unified into a sequence of panels.Based on this structure, a representation (i.e., a story) and the represented environment are connected via an isomorphism of their temporal, spatial, and relational structures.Furthermore, the framework of a Cogmic Space is associated with the generative aspect of representations, which is conceptualized in terms of unconscious-and conscious-level processes/representations. Finally, a proof-of-concept implementation is presented to provide a concrete account of the proposed framework.</p>
<p>This study addresses the issue of representing a world in an artificial cognitive system.This issue is essential for creating a comprehensive cognitive system that acts in a world or physical/social environment.As described in our previous works (Akimoto, 2018(Akimoto, , 2019)), our basic concept is that a world is represented as a collection of stories.In this context, a story refers to an internal representation or memory item involving a narrative structure, where a ''narrative" generally refers to information expressed or communicated between individuals.Conceptually, stories in a cognitive system include past, present, future, and fictional events and situations.A story is assumed to have a form that integrates concrete events, objects, and situations, comprising various types of information, including both conceptual and perceptual dimensions.Furthermore, because a narrative is a common communication method in human societies, it can be considered that stories inside an individual mind or cognitive system naturally involve sociocultural aspects.</p>
<p>However, a concrete representational framework for such an integrative world representation has not yet been provided.In this paper, we propose the conceptual design of a representational framework for a story in a cognitive system.The term ''design" is used in this study because our primary objective is not to elucidate the human mind, but to develop an artificial cognitive system.This study focuses on creating a conceptual-level framework, and an initial proof-of-concept implementation is presented.Hence, the main contribution of this work is to provide a computational theory for world representation in a cognitive system or architecture.The proposed representational framework is referred to as a Cogmic Space.The term ''Cogmic" is a word of our own invention, indicating that the framework is designed via an analogy with narrative comics as a comprehensive sign system.</p>
<p>The remainder of this paper is organized as follows.Section 2 presents key issues in designing a world representation.Sections 3 and 4, respectively, describe the conceptual design and systematic formulation of a Cogmic Space in a cognitive system.Section 5 presents a proof-ofconcept implementation based on this design.Sections 6 and 7, respectively, discuss future issues and conclude this paper.</p>
<p>Background and problems</p>
<p>This section raises key issues in designing a story representation as a uniform world representation by reviewing relevant studies in various fields.Our primary question here is how to represent an event-centric, concrete, and meaningful world in a unified form.</p>
<p>Symbolic representation</p>
<p>In the fields of artificial intelligence, stories or narratives have generally been based on symbolic representations.Major examples can be seen in studies on story-based intelligence by Schank and his colleagues (Schank, 1982;Schank &amp; Abelson, 1977); the Genesis storyunderstanding project conducted by Winston and his colleagues (Winston, 2012(Winston, , 2014); Kintsch's (1998) integrative cognitive model of narrative comprehension; computational models of analogies (e.g., Falkenhainer, Forbus, &amp; Gentner, 1989;Holyoak &amp; Thagard, 1995); commonsense knowledge bases (e.g., Singh, Barry, &amp; Liu, 2004); and story or narrative generation systems (e.g., Bringsjord &amp; Ferrucci, 1999;Gerva ´s, Dı ´az-Agudo, Peinado, &amp; Herva ´s, 2005;Meehan, 1980;Riedl &amp; Young, 2010;Pe ´rez y Pe ´rez &amp; Sharples, 2001;Turner, 1994).Additionally, a connectionist mechanism, distributional semantics model, or other non-symbolic mechanism may be used for the semantic basis of story processing, where the body of a story is generally represented by a symbolic framework.</p>
<p>In the past decade, end-to-end frameworks based on neural network models have become a trend in the field of natural language processing.This type of technology is also applied to narrative processing, including narrative text generation (e.g., Fan, Lewis, &amp; Dauphin, 2018).It may be considered as story cognition with no explicit representation.However, an end-to-end framework is generally oriented toward a specific task or function.In our opinion, the essence of generative story cognition is in the internal dynamics of the mind; it cannot be elucidated in the framework of an input-output relationship.Hence, this study emphasizes the issue of representation.</p>
<p>However, a symbolic representation is insufficient for realizing the notion of a story as a unified world representation.This is mainly because a symbolic representation has low representational power.Here, we provide an example of a symbolic representation of an event as the basic story element.In a symbolic representation, a simple event can be represented as a case frame or predicate-argument structure, such as [Eat (agent Lisa) (object Apple)].This description represents the event expressed as ''Lisa eats an apple."However, it does not contain the physical appearances of Lisa and the apple, how Lisa eats the apple, or other types of situational information.Even if an agent can autonomously construct a story about an experience using such a format, it will be qualitatively and quantitatively inferior to a person's memory of the experience.Radvansky and Zacks (2011) presented an eventrepresentation model (i.e., an event model) from a cognitive psychological perspective based on previous studies of situation models in narrative comprehension (Wyer &amp; Radvansky, 1999;Zwaan &amp; Radvansky, 1998).They propose that events are complex information composed of different interrelated types of information, including spatiotemporal locations, entities, physical characteristics and internal properties of entities (e.g., emotions and goals), structural relations among entities, and linking relations between events (e.g., temporal and causal relations).Although this is not a perfect list of event information, computationally representing such complex information is still a difficult issue.</p>
<p>In a symbolic representation, modal and situational information, including those exemplified above, may be represented by a sophisticated and complicated frame structure and/or combined with another data structure, e.g., states of a world.However, even a sophisticated symbolic representation differs widely from an external world or environment.Furthermore, the division between events and states may complicate the problem of world representation.These two challenges are further discussed in the next two subsections.</p>
<p>Gap between symbolic representation and sensory/bodily space</p>
<p>The perceptual or bodily basis of conceptual cognition has been widely discussed in cognitive studies, including image schemas (Johnson, 1987), perceptual symbol systems (Barsalou, 1999), and conceptual spaces (Ga ¨rdenfors, 2000(Ga ¨rdenfors, , 2014)).Here, we focus on Barsalou's (1999) theory.He criticized the divergence between studies on perception and conceptual cognition in the cognitive-science field and argued that conceptual cognition inherently involves a perceptual dimension.From this standpoint, he proposed the theory of perceptual symbol systems for a conceptual-level representation involving dynamic natures (known as simulation).The perceptual symbols are assumed to be (multi) modal and analogical representations interdependently coupled with the perceptual dimension, whereas a traditional symbolic representation is amodal and arbitrary.His claim can be applied to the story-representation issue; namely the drawback of a symbolic story representation is its disconnection from a perceived external environment.</p>
<p>In describing this issue, we introduce the term ''sensory/bodily space" to refer to the perceptual or sensory/bodily dimension of a world.Our assumption here is that a story and sensory/bodily space have a complementary relationship.A story is mentally constructed information, including subjective meanings, whereas a sensory/bodily space directly overlaps with an external environment.Hence, a sensory/bodily space is necessary for action-perception processes, for example, picking up a cup on a table.However, an action or event inherently involves a concrete context, including relationships with a custom, reason, intent, or goal.A story forms such higher-level structures in a world.Furthermore, a story forms not only real but also imagined events and situations.</p>
<p>In a symbolic story representation, the conceptual dimension of a world is generally reflected in a story; however, the sensory/bodily information is largely cut off.Therefore, the conceptual and sensory/bodily dimensions of a world are separated into a story and sensory/bodily space, as illustrated in Fig. 1(a).However, this separated relationship seems inadequate for supporting integrative story cognition in which both the conceptual and sensory/bodily dimensions are involved.In contrast, a story based on a Cogmic Space tends to be a mid-level representation, involving both the conceptual and sensory/bodily dimensions, as illustrated in Fig. 1 (b).Because this mid-level story overlaps with a sensory/bodily space, it is advanta-geous for seamlessly integrating a story and sensory/bodily space.</p>
<p>Over the past decade, the neural network-based modeling of an episodic memory or memory system has been addressed using various approaches, such as Balkenius, Tjøstheim, Johansson, and Ga ¨rdenfors (2018), Chang and Tan (2017), Rothfuss, Ferreira, Aksoy, Zhou, and Asfour (2018), Wang, Tan, and Miao (2016), and Wang, Subagdja, Tan, and Starzyk (2012).These studies commonly focus on encoding time-series data based on sensation or perception, with or without explicit episodic representations.However, from our perspective, these studies give weight to the perceptual or sensory/bodily dimension, and neglect most of the conceptual, higherlevel cognition.In contrast, our study more strongly emphasizes higher-level cognition in stories.Because story cognition and memory systems are complex issues, we should seek to integrate these different perspectives.</p>
<p>Division between states and events</p>
<p>In most artificial intelligence studies, state-based world representations are explicitly or implicitly used.In a typical formulation, states are positioned as the fundamental dimensions of a world, and events or actions are regarded as changes in states.Fig. 2(a) illustrates this form of relationship between states and events.Representative examples of this relationship can be seen in goal-oriented problem solving (Newell &amp; Simon, 1972).The basic form of problem solving or planning involves organizing a course of actions to reach a goal state from an initial state.This process is based on knowledge of the relationships among actions, preconditions, and effects on a state.A similar formulation is observed in cognitive architectures, for example, the problem space in Soar (Laird, 2012).A discretized game environment, such as those of chess and Go, fits well with state-based modeling and is an area in which current artificial intelligence performs well.Furthermore, planning is a traditional approach for computational story generation, involving the characters' goal-oriented actions (Meehan, 1980;Riedl &amp; Young, 2010).A state-based representation may be well suited for formulating a predefined, limited problem space, for example, a game environment.However, the state of an unlimited world, from an absolute perspective, cannot be represented.Hence, a fundamental drawback of a state-based representation is autonomously restricting the range of world information.It corresponds to the frame problem in artificial intelligence; please refer to criticisms by Dreyfus (1979) and Winograd and Flores (1986).Another concern regarding a state-based representation is that the nature of an event, for example, ''a child plays with toys," cannot be characterized by a change in state.</p>
<p>A potential approach to solving this problem is to regard events as the principal dimension of a world and position the stative dimension as their background.From this perspective, the stative dimension is restricted based on its relevance to events.Hence, the ability to autonomously generate stories becomes the basis for constructing a restricted world.Here, to emphasize the dynamic aspect, we use the term ''situation," rather than ''state," to refer to the stative information associated with events.From the above perspective, events and situations are inseparable elements of a world.Thus, the primary issue in designing a representational framework is unifying these elements as an alternative to a state-based representation.Fig. 2(b) illustrates the structure of such an event-centric world representation.Here, a situational representation without events is also acceptable by positioning it in the context of a story, as with Situation 3 in Fig. 2(b).</p>
<p>Dynamics of stories</p>
<p>When dealing with the basic nature of a story as a world representation, the following two kinds of time should be distinguished:</p>
<p>(A) Time formed by a story: In a story, events and situations are organized via their anteroposterior relationships.This temporal structure can be considered as the basis for forming the temporal extent of a world.This kind of time is involved in a story.(B) Time of generation: This corresponds to the dynamics of a story.Because external environments change over time, a story as a world representation should be dynamically generated and reedited.The recall or remembrance of a story should also be a generative process, in which the story is reorganized at that moment, in relation to the present environment and mental state.Hence, a story is always involved in the time of story generation in a cognitive system.</p>
<p>The issue raised here considers the latter kind of time, i.e., the generative aspect of a story.This is not regarding only the representation issue but regarding the total operation of a cognitive system.However, the dynamics should be considered as the basic nature of a story.This issue is closely related to consciousness and unconsciousness in the functional sense, or more precisely, the consciousand unconscious-level processes of a cognitive system.In this respect, several philosophical and neurological theories characterize consciousness in terms of story or narrative generation (including a metaphorical sense).</p>
<p>First, Dennett (1991) proposed the multiple-drafts model of consciousness.This model explains that all varieties of perception, thought, or mental activity are accomplished using a parallel process of interpretation and elaboration, or the continuous editorial revision of multiple drafts of narrative fragments.This distributed, continuous process can be considered as the unconscious level; the part of the draft that appears as a conscious experience is indefinite.Furthermore, Dennett conceptualized the self as a center of narrative gravity, i.e., as the virtual source of narratives.However, this self is not the source of narratives, but a product that emerges through the generation of narratives.</p>
<p>Second, in Damasio's (1999Damasio's ( , 2010) ) theory on consciousness and self, two levels of consciousness are posited: core and extended.The core consciousness, i.e., the lower level, provides the organism with a sense of self about here and now.The mental process or phenomenon of the core consciousness is explained in terms of ''making a narrative" or ''telling a story."In this context, a narrative or story is considered to be a nonverbal neural map of organized events.The self coupled with the core consciousness is referred to as the core self.The extended consciousness is considered to be the upper level of the core consciousness.It provides the organism with an elaborate sense of self (i.e., an identity and a persona) based on an autobiographical time or memory across the past and future.The self coupled with the extended consciousness is referred to as the autobiographical self.</p>
<p>Our view of story generation is similar to Dennett's theory.We consider that a large part of a story's generative processes is a self-organizational, parallel distributed process at an unconscious level.This assumption is also inspired by Minsky's complex-systems view of the mind (Minsky, 1986(Minsky, , 2006)).The internal structure of a story involves complicated part-part and part-whole interdependencies.It is similar to typical complex systems, such as biological and social systems.Generating such a complex structure is difficult to understand in the form of a centrally controlled system.Instead, story generation can be seen as a parallel distributed process involving a story, including mutual interactions with other stories.Various types of structural operations will be involved in this process, for example, connection, disconnection, abstraction, concretization, generalization, complementation, transformation, combination, analogy, and blending.</p>
<p>However, a conscious-level process is also required for intentionally organizing a story in relation to the present environment.This process level is distinguished from the aforementioned unconscious internal operations of a story.To clarify this process, the relationship between a story and self-possibly corresponding to a center of narrative gravity (Dennett, 1991) or core self (Damasio, 1999)should also be formalized.</p>
<p>In this study, the terms ''conscious" and ''unconscious" are used to distinguish the two different aspects of story generation.However, there is a close relationship between generative story cognition and artificial or machine consciousness.According to Reggia's (2013) systematic review, artificial consciousness studies are classified into five broad categories based on their centrally focused dimensions of consciousness: global workspace, information integration, internal self-model, higher-level representations, and attention mechanisms.We consider that generative story cognition is relevant to various aspects of consciousness, in particular, higher-level representations and internal selfmodels, including Chella, Frixione, and Gaglio (2008), Chella, Pipitone, Morin, and Racy (2020), Samsonovich and Nadel (2005), Samsonovich, De Jong, andKitsantas (2009), andSun (2002).However, to the best of our knowledge, the story-or narrative-based approach to artificial consciousness has not yet been fully explored.</p>
<p>Conceptual design</p>
<p>This section describes the conceptual design of a Cogmic Space for a story-form world representation.This design intends to provide a solution to the problems posed in the previous section.Specifically, the design directions of a Cogmic Space framework include the following items:</p>
<p>A story should involve both the conceptual and sensory/bodily dimensions of a world (as described in Section 2.2).An event and the background situation should be unified (as described in Section 2.3).A story should be generative at both the unconscious and conscious process levels (as described in Section 2.4).</p>
<p>For the last item, the present framework provides only the relationship between a story and its conscious-level process.The unconscious generative process is not addressed in the present work.</p>
<p>The basic concept of a Cogmic Space is simple: it is a comic strip-like representation of a story.According to semiotic or semiology on comics, for example, Groensteen (2007) and Takeuchi (2005), comics can be considered as a comprehensive sign1 system for composing narratives.From our perspective, comic expression has the following characteristics:</p>
<p>The basic expressional unit of a narrative comic is a panel (also known as a frame).</p>
<p>A narrative is composed of a spatial arrangement of panels.This arrangement involves the sequential order of the panels.In a panel, various types of information, including the characters, bodies, objects, actions or motions, words, thoughts, sounds, emotions or feelings, effects, and background, are expressed using pictures, pictorial signs, and letters.Comic expression involves the aspect of a sign, rather than a realistic image.In a narrative comic, expressed (signified) objects or scenes are highly abstracted and deformed.Non-visual objects, such as sounds, feelings, and effects, are also drawn using pictorial signs or letters.</p>
<p>In this study, a comic expression as a comprehensive sign system is analogically transferred to the framework of a Cogmic Space.In this context, a ''sign" is a communication medium between individuals, whereas a ''representation" is inside an individual cognitive system.However, signs and representations are similar because their essence is in the relationship with a signified/represented object, event, situation, or concept.This similarity forms the basis of an analogy from a sign system (i.e., comics) to the representational framework of a Cogmic Space.It should be noted that a story based on a Cogmic Space is not simply a sequence of images but a hybrid representation, including symbolic, pictorial, spatial, and relational information.This point differs from a comic strip or book, which ultimately consists of printed papers or image data.</p>
<p>In the following subsections, the basic concepts of a Cogmic Space are described according to the aforementioned design directions.Section 3.1 describes the general properties of a Cogmic Space.Section 3.2 conceptualizes the relationship between a representation and the represented.Section 3.3 describes the conscious-level generative process of a story.</p>
<p>Basic concepts</p>
<p>The basic concepts of a Cogmic Space are simply derived from comic characteristics:</p>
<p>(A) The basic representational unit of a story is a panel, that is, a two-dimensional spatial frame.(B) A panel can contain various types of information, including characters, bodies, objects, actions or motions, words, thoughts, sounds, emotions or feelings, effects, and background, irrespective of the presence of physical substances in the information.(C) A panel forms a unified representation of an event(s) and a situation via the spatial and relational composition of the above information elements.A panel may contain a situation without an event, depending on its context.</p>
<p>(D) A story is composed of a sequence of panels.2This also means that the panel's meaning depends on its context or relationship with other panels.3This contextual meaning of a panel includes the essential elements of an event, specifically, causality and intent.(E) The conscious-level generative process of a story is similar to reading a story.This notion is further discussed in Section 3.3.</p>
<p>In the above list, concepts A-C are solutions for the problems posed in Sections 2.1,2.3.Concept D provides the basic nature of a story and world, that is, the temporal dimension, and concept E corresponds to the dynamics of a representation, as described in Section 2.4.</p>
<p>Structural isomorphism between a story and sensory/bodily space</p>
<p>The issue discussed here is how a story based on a Cogmic Space represents a world.In this respect, a Cogmic Space follows Barsalou's (1999) theory of perceptual symbol systems, which assumes an analogical relationship between a conceptual-level representation (i.e., perceptual symbols) and a perceptual state.Moreover, relevant theories can be found in the fields of philosophical and cognitive studies on how a representation represents an object or thing.For example, Cummins's (1996) picture theory of representation characterizes the basic nature of representation in terms of a structural isomorphism between a representation and the represented.According to this theory, a typical example of a representation is a map representing the geographical structure of a city.</p>
<p>The basic principle of the relationship between a story and sensory/bodily space is characterized as a structural isomorphism.The isomorphic relationship between a story and sensory/bodily space is illustrated in Fig. 3.This isomorphism is formed by the following three types of relations:</p>
<p>Temporal relation: A panel corresponds to a temporal segment of a sensory/bodily space, and the anteroposterior relationship of panels corresponds to the temporal dimension of the sensory/bodily space.Spatial/physical relation: Positions, postures, figures, and directions of objects and motions in a panel can correspond to those in a temporal segment of the sensory/bodily space.Conceptual relation: A story involves conceptual relationships between objects, e.g., ''X eats Y" or ''X plays with Y," where this type of conceptualized relationship has no physical existence in the external environment.Hence, conceptual relationships are generated in the dimension of a story and projected to the sensory/bodily space.</p>
<p>Here, the qualitative difference between a story (Cogmic Space) and sensory/bodily space should also be characterized.Only partial or componential information of a sensory/bodily space is abstracted into a story.It is dominantly driven by the movement of generating a story, that is, sensory/bodily information is abstracted in its relevance to a story.In this respect, a sensory/bodily space contains richer information than a story does.However, a story contains information derived from an environment via the sensory/bodily space as well as internally generated, imagined, or remembered information.In this respect, a story is rich in meaning.</p>
<p>The above isomorphic relationship assumes a physical environment.However, it also becomes the basis for the representation and cognition of mental and social events/ situations, in terms of metaphorical cognition (Lakoff &amp; Johnson, 1980), image schema (Johnson, 1987), analogy (Holyoak &amp; Thagard, 1995), conceptual blending (Fauconnier &amp; Turner, 2002), etc.</p>
<p>Conscious-level generative process</p>
<p>Terminology</p>
<p>To conceptualize the generative aspect of a story, we introduce different terms, shown in Table 1, to distinguish between the unconscious and conscious levels of representations and processes.The term ''story" is used to refer to an unconscious-level representation.As described in Section 2.4, the unconscious generative process of a story is considered to be ''self-organization."A conscious-level representation based on a story is particularly referred to as an ''inner discourse."The conscious-level process of generating an inner discourse based on a story is referred to as ''inner narrating."Both a story and an inner discourse are Fig. 3. Structural isomorphism between a story and sensory/bodily space.represented based on a Cogmic Space.The difference between them will be explained later.</p>
<p>Theoretical background</p>
<p>The above terminology has a narratological background.The terms ''story," ''discourse," and ''narrating" are originally rooted in Genette's (1980) narratology.In the original narratological meaning, a discourse refers to an expressed narrative (i.e., a text) itself, and a story refers to the content recounted in the discourse.Narrating is the action of producing a narrative (discourse) by a narrator(s) and narratee(s).In this context, a narrator and narratee correspond to the persons inscribed in the narrative discourse.</p>
<p>In our previous work (Akimoto, 2019), these narratological notions were transferred into the framework of a cognitive system.In this framework, both a story and a discourse are considered as representations involving narrative structure.However, a story is positioned as a memory representation, and a discourse corresponds to the representation of an expressive structure based on a story.Narrating is the process of generating a discourse structure based on a story.</p>
<p>In the present study, our previous framework is incorporated into the framework of a Cogmic Space with partial modifications.In particular, the relationship between a story and an inner discourse is reinterpreted as the relationship between unconscious and conscious levels.The term ''inner" is added to ''discourse" and ''narrating" to emphasize that these are an internal representation and the process of a cognitive system.The notions of inner discourse and inner narrating are further described below.</p>
<p>Inner narrating as reading a story</p>
<p>As described previously, the present framework of a Cogmic Space is particularly associated with the conscious-level generative process, that is, inner narrating.For the sake of simplicity, the following discussion assumes inner narrating to be the mental activity during the recollection of a given (static) story.Conceptually, inner narrating is considered to dynamically generate a more integrative meaning, that is, an inner discourse, from a story.The issue discussed here considers ways of formulating this process.In this respect, we also adopt an analogy from a comic.In this analogy, the relationship between a comic or narrative and the act of reading is transferred to the relationship between a story as an unconscious-level representation and inner narrating as the generation of a conscious-level representation.</p>
<p>In the field of literary studies, the reception-theory movement (Iser, 1980;Jauss, 1982) emphasizes the generative aspect of readers and the act of reading in the reception and production of literary works, respectively.Cognitive and computational studies on narrative understanding also deal with the processes in which the meaning or representation is mentally constructed through reading a narrative (Kintsch, 1998;Schank &amp; Abelson, 1977;Winston, 2014;Zwaan &amp; Radvansky, 1998).Similar to the above perspectives on reading, the inner-narrating process is formulated to generate an inner discourse through reading a story.</p>
<p>In terms of narratology, narrating (by a narrator) and reading (by a reader) are entirely different notions.However, from a cognitive perspective, narrating something involves the (re-)interpretation, (re-)understanding, or (re) cognition of the events or situations being told.In this respect, narrating is similar to reading or comprehension.</p>
<p>Self as a narrator</p>
<p>Based on the above concept, the self as the conductor of inner narrating can be conceptualized as a narrator, or as a narrator-self.A narrator-self can be conceptually associated with the notion of the core self in Damasio's (1999) theory.As mentioned in Section 2.4, the core self is coupled with the core consciousness, which is (partially metaphorically) explained in terms of ''telling a story."Here, it should be noted that the core self is distinguished from the classical notion of a transcendental homunculus in the brain: ''The story contained in the images of [the] core consciousness is not told by some clever homunculus.Nor is the story really told by you as a self because the core you is only born as the story is told, within the story itself" (Damasio, 1999, p.191).Here, ''story" and ''core consciousness," in Damasio's terms, correspond to an ''inner discourse" and ''inner narrating" in our framework.Following his theory, a narrator-self is positioned not as a procedural module of a cognitive system, but as a representational structure involved in an inner discourse.More precisely, a narrator-self is coupled with the source story as its meta-level structure that appears in the process of inner narrating.</p>
<p>Meanwhile, in an agent's memory, a story may contain the agent itself as a (first-person) character.This type of self can be distinguished from the narrator-self, as a character-self.Hence, the agent in a story and the narrator-self are organized in a nesting structure [narrator-self (character-self in a story)].In narratology, this type of nesting structure is conceptualized in terms of the narrative level (Genette, 1980) and further discussed in Akimoto (2019).Based on this structure, the agent can be contained in different stories, including present (ongoing) experiences, past experiences, future visions, and hypothetical imaginations.Thus, there is a gap or overlap of the temporal positions between the narrator-and characterselves.This mental structure will be the foundation of a rich temporal extent of the self or the extended consciousness and autobiographical self, in Damasio's terms.</p>
<p>Systematic formulation</p>
<p>Based on the above conceptual design, this section formulates the framework of a Cogmic Space in a cognitive system.This formulation is also a conceptual account, rather than an implementation.A partial implementation in a proof-of-concept fashion will be presented later in Section 5.</p>
<p>Cognitive-system structure</p>
<p>First, we describe a cognitive-system structure in which Cogmic Space-based representations are involved.The overall system structure presented here is shown in Fig. 4. Based on the concepts in Section 3.3, this cognitive system involves two representational dimensions: a story at the unconscious level and an inner discourse at the conscious level.These representations have a certain continuity in the operation of a cognitive system, while both a story and an inner discourse have a dynamic nature.An inner discourse is a relatively short-term or momentary representation.Thus, a story and an inner discourse are included in a memory system as a major part of the cognitive system.</p>
<p>Inner narrating is positioned as a procedural unit mediating between a story and an inner discourse.Specifically, an inner discourse is constructed from a story via inner narrating.Concurrently, the structure of an inner discourse may be partly reflected in the source story and held longterm.In Fig. 4, this mutual relationship is denoted by the cyclic arrows between a story and an inner discourse.Interactions with physical/social environments are mediated by language and action-perception systems, through the sensory/bodily space.Here, the sensory/bodily space is considered as the entirety of the sensory information.</p>
<p>In this paper, our primary focus is on three parts: a story, an inner discourse, and inner narrating.Hence, a detailed formulation of the other parts-the memory system (e.g., how stories are organized and associated), language system, action-perception system, and sensory/bodily space-is outside the scope of the present study.</p>
<p>Representational framework of a Cogmic Space</p>
<p>In the above system structure, a Cogmic Space is applied to both a story and an inner discourse.This means that the essential difference between a story and an inner discourse is not in form, but in informational quality.Specifically, a story is fragmentary or incomplete, and an inner discourse is generated as a more integrative, well-organized representation with particular attention to a piece (i.e., an event or object) of a story.Hence, the basic representational framework of a Cogmic Space is formulated as a common format for a story and an inner discourse.In the following formulation, we emphasize the relatively macroscopic, organizational structure of a representation, rather than relatively microscopic, object-level issues (e.g., how to represent a human body).</p>
<p>The basic representational elements of a Cogmic Space are defined as follows:</p>
<p>A story consists of a sequence of panels: S ¼ ðP 1 ; . . .; P n Þ.This sequence is typically in chronological order.This structure is also reflected in an inner discourse.A panel has a two-dimensional spatial frame.The contents of a panel are defined as a tuple: P ¼ hO; M; bi, where O is a set of objects, O ¼ fo i g; M is a set of motions, M ¼ fm j g, and b is background information.An object o corresponds to a pictorial or linguistic sign placed at a certain spatial position in a panel.It represents a perceptual or conceptual element, e.g., a charac- ter, physical object, word, thought, sound, feeling, or effect.Furthermore, an object can have additional information, including symbolic signs (proper name, concept, etc.) and relationships (subordination, inclusion, etc.) with other objects or motions.A motion m represents a physical, mental, or social action in which one or more objects are involved.A motion consists of a predicate symbol (typically a verbal concept) and relational arrows from its agent (object) to other relevant objects, e.g., ½Eat : Lisa !objectðAppleÞ.An arrow may represent a spatial direction of the action, e.g., ½Walk : Lisa !directionðLeftÞ.Hence, a motion has a meaning similar to the predicate-argument structure of a language, e.g., [Eat (agent Lisa) (object Apple)].Furthermore, a motion involves spatial or physical properties based on the spatial composition of the relevant objects in a panel.A background b consists of conceptual information of the place (where) and time (when).The place and/or time of a panel may be blank, i.e., they may be unconceptualized, omitted, or forgotten.</p>
<p>The following relational structures are added to form the contextual meaning of an event (i.e., motion) or object in a panel based on the relationship with other panels: Continuity and change of objects or motions across panels.This continuity includes various senses, e.g., an identical object, similar objects, a commonality of objects, and a course of motions across panels.In contrast, a change corresponds to a difference in continuous objects or motions across panels.Relationships between motions and/or objects.These include a causal relation between a motion/change (as a result) and a preceding motion/change (as a cause) and an intention from a motion to a subsequent motion/change.</p>
<p>Because these inter-panel connections and relationships are highly complex, they are considered to be dynamically generated structures in the process of inner narrating.</p>
<p>Example representations of a story and inner discourses are presented in Section 5, using an implemented system.</p>
<p>Inner narrating</p>
<p>As described previously, inner narrating is the process of generating a more integrative, well-organized representation with particular attention to a part of a story.Hence, an inner discourse is always generated based on a story, as if reading it.Although this generative process requires a complicated mechanism, the basic procedural elements constituting inner narrating can be categorized as follows:</p>
<p>Attention: To draw attention to a motion or object in a panel, making it the central point of an inner discourse.</p>
<p>Association: With the central focus on an attended object or motion, relevant objects and motions are organized as a subset of the story.Two types of processes are involved here: (a) intra-panel associations, based on the relational structure among objects and motions in a panel; and (b) inter-panel mappings between objects or motions across panels, based on their continuity.Change detection: Changes across panels are detected in terms of the differences between mapped objects or motions, based on an inter-panel mapping.Relation: Causal and intentional relationships are produced between motions or changes across panels or in a panel.This relational structure is also based on the associated area of a story that focuses on an object or motion.</p>
<p>Using the above operations, the content of a story will be relatively faithfully reflected in an inner discourse.However, more transformative or re-interpretive story operations are also included in inner narrating, for example, the complementation of blanks or information lacking in a story and the transformation of a story's content itself.Similar transformative operations also exist in the unconscious-level story-generative process.Thus, this type of indeterminacy or fluidity of a memory is considered as a phenomenon produced via both unconscious-and conscious-level generative processes.</p>
<p>Initial proof-of-concept implementation</p>
<p>This section presents a proof-of-concept implementation of a part of the above formulation. 4This implementation includes a story representation, based on a Cogmic Space, and the conscious-level generative process in which inner discourses are generated via inner narrating.This process corresponds to the mental activity during the recollection of a given story.</p>
<p>Outline</p>
<p>First, we describe the surface behavior of the system.Fig. 5 shows an example window-capture in which the system's internal representations are visualized.Note that this window is simply an interface for a human.However, because a Cogmic Space is a comic strip-like representation, its representational structure can be directly reflected by a visual image.</p>
<p>The system's surface behavior is outlined as follows:</p>
<p>(1) When starting the system, a story is displayed at the top of the window.This story is manually provided in the format described later.</p>
<p>(2) The initial target of attention is indicated when the human operator clicks the mouse on an object or motion in a panel.(3) An inner discourse is generated, centered on the selected object or motion, and displayed in the middle of the window.(4) Sentences expressing the inner discourse, i.e., the agent's speech, are presented in the word balloon at the bottom of the window.Each sentence expresses a different aspect of the inner discourse.(5) The system automatically shifts the selected target forward to an activated object or motion in the next panel.Then, it returns to Step (3).If there is no next panel, the system stops.</p>
<p>Examples of inner discourses through the flow of attention (i.e., the cycle of Steps 3-5) will be shown later in Section 5.5.</p>
<p>The internal system structure is shown in Fig. 6.The overall procedural flow is parallel to the aforementioned surface flow.A story is manually presented in the form of a Cogmic Space.Inner narrating is the process of generating an inner discourse based on a story with attention to its parts.However, this generative process is modeled not as a solo operation of the inner-narrating module, but as cooperation between the inner-narrating module and the internal story mechanism.In particular, a story itself has an associative power that organizes relevant information with attention to an object or a motion in a panel.This associative power is part of the story's self-organization.Conversely, the role of the inner-narrating module is to drive the inner narrating by drawing attention to the story and producing a higher-level, relational meaning based on the associated structure.A detailed explanation of each system element is provided in the following subsections.</p>
<p>Story representation based on Cogmic Space</p>
<p>A story is represented by the representational framework presented in Section 4.2.However, several implementation-level constraints exist, as listed below:</p>
<p>The number of panels in a story is limited to four, although there is theoretically no limitation.A panel has a fixed size: the width and height of a panel are set to 400 and 300 pixels, respectively.An object is defined as one of eight predefined categories, which are provided on an ad-hoc basis: HUMAN, ANIMAL, PLANT, OBJECT (non-living things, including A linguistic summary of this story, focusing on motions, is as follows: ''P 1 : I find an apple (on a tree).Gonta (raccoon dog) eats an apple (on the ground).P 2 : I kick Gonta.P 3 : Gonta runs away.P 4 : I pick the apple (from the tree)."Additional information is contained in this story, as annotated with yellow labels.(b) The presented inner discourse in the middle is generated with attention to the motion, ''I kick Gonta," in P 2 .(c) The sentences at the bottom are linguistic expressions generated from the inner discourse.The English translation of this part is presented later in Table 4, item (2).</p>
<p>artifacts and natural things), FEELING, SOUND, SPEECH, and CONTAINER.Each category corresponds to a highly abstracted iconic picture, as shown in Fig. 7.An object in a panel includes the seven properties listed in Table 2.Note that the above object representation is a highly simplified method.Predefining the object categories is not ideal.Ideally, visual features should be generated for each object via imagination and/or perception.</p>
<p>Representational elements of a story-objects and motions for each panel-are constructed based on an input text file that describes the story content in commaseparated values (CSV) format.Table 3 shows an example input text, corresponding to P 1 in the story in Fig. 5.</p>
<p>Inner narrating</p>
<p>The process of inner narrating includes the basic procedural elements presented in Section 4.3: attention, association, change detection, and relation.This process is implemented as a cyclic process, consisting of the following four phases: (i) select an object or motion in a panel as the target of attention, (ii) associate relevant objects and motions centered on the selected target, (iii) produce an inner discourse in which a relational meaning is added to the associated structure, and (iv) change the selected target and return to the first phase.An inner discourse is a temporal representation that is (re)generated through the transition of attention.</p>
<p>Transition of attention</p>
<p>The initial target of attention is manually selected by clicking the mouse on an element (generally in the first panel).Thereafter, the attention transitions forward automatically by selecting the element with the highest activation value in the next panel.The activation values of  objects and motions are calculated in the association process, as described next.</p>
<p>Association in a story</p>
<p>When an element in a panel is selected, the story automatically organizes a packet of relevant elements, referred to as an associated structure, based on the distance from the selected element.In this context, the distance is a relational distance based on the path length from the attended element.Relational paths are formed via intra-panel associations and inter-panel mapping, as described below:</p>
<p>Intra-panel association: This is formed by conceptual relations between elements in a panel.Intra-panel relations are not only produced in the present panel (i.e., the panel containing the selected element) but also in each of the preceding and subsequent panels via the inter-panel mapping.In the present implementation, the following three types of relations become edges constituting a relational path from the selected element:</p>
<p>-Motion: A bidirectional edge between a motion and an involved object.-Link: A bidirectional edge between elements connected via a subordinate link.-Contain: A bidirectional edge between a CONTAINER object and a contained object.</p>
<p>Inter-panel mapping: This connects elements in the present panel to elements in the adjacent preceding and subsequent panels. 5The continuity across panels is formed by these inter-panel connections.In an interface window (see Fig. 5), an inter-panel connection is depicted by a curved line across panels.The following five rules are used to produce inter-panel connections:</p>
<p>-Name: Matches the name properties of objects in different panels (e.g., ''Gonta" in P 2 to ''Gonta" in P 1 ).-Subordination: Matches the basic categories and linked objects, based on their names (e.g., ''FEELING linked to Gonta" in P 2 to ''FEELING linked to Gonta" in P 1 ).-Position: Matches the position properties between objects in different panels.-Motion: Connects a motion in the present panel to a motion in the preceding or subsequent panel.If two or more motions are present in the preceding or subsequent panel, all possible connections are produced.-Appearance and disappearance: These are special connections where one side of an inter-panel connection is empty.An appearance connection is added when an associated object in a panel has no corresponding object in the previous panel.In contrast, a disappearance connection is added when an associated object in a panel has no corresponding object in the next panel.</p>
<p>Based on the above connective structure, elements within a certain distance range, centered on the selected element, and their connective structure are gathered in an associated structure.Here, the cost of every edge is 1.In the examples in this paper, the distance range is set to 2.</p>
<p>Furthermore, activation values are allocated to objects and motions in an associated structure.These create a gradation in an inner discourse as the strengths of the appearances of motions and objects.In an interface window, these values are reflected as the color strengths of objects and motions.Activation values are particularly used in the transition of attention, as described previously.The activation value, a, of an element is simply calculated based on the minimum distance, d, from the selected element:
a ¼ 1 2 d :ð1Þ</p>
<p>Changes and relationships</p>
<p>After an associated structure is organized, the innernarrating module interpretively adds a relational meaning to it.The relational meaning includes two types: changes and causal/intentional relationships.In the interface window (see Fig. 5), a change is depicted by a red-pin icon (a bar with a small triangle), and a causal or intentional relationship is depicted by a straight-line bridge between two motions/changes.Change detection.A change is determined based on the difference in properties from a past object to a present object that is connected via an inter-panel connection.The appearance or disappearance of an object (i.e., if one side of an inter-panel connection is empty) is also detected Table 3 Example input text corresponding to the first panel, P 1 , of the story in Fig. 5. Square brackets denote annotations of English translations.The line starting with ''$P" denotes the start of a panel and contains the background properties, including a time and place.A line starting with ''#o" defines an object and includes the following information: (i) an identical symbol in a panel, (ii) basic category, (iii) X-axis position, (iv) Yaxis position, (v) size, (vi) name, (vii) concept, and (viii) link.For a CONTAINER object, a contents list is added at the end.A line starting with ''#m" defines a motion using a verbal concept and involved objects.$P, [mountain], [last_summer],null #o,o1,human,140,200,60, [I], [boy],null #o,o2,human,80,200,40,[Taro], [boy],null #o,o3,animal,280,240,50,[Gonta], [raccoon_dog],null #o,o4,feeling,140,130,50,null, [hungry],accompany:o1 #o,o5,feeling,280,200,30,null, [happy],accompany:o3 #o,o6,plant,350,150,200,null, [tree],null #o,o7,monoA,240,250,20,null, [apple],null #o,o8,monoA,330,80,20,null, [apple],on:o6 #o,o9,monoA,370,110,20,null, [apple],on:o6 #m,m1, [eat] agent:o3 object:o7 #m,m2, [find] agent:o1 object:o8 Note: ''monoA" denotes a circle OBJECT.as a change.For example, the inner discourse presented in Fig. 5 contains the disappearance of the ''apple" (eaten by Gonta).In an inner discourse, changes are also determined in each of the preceding and subsequent panels on the same basis to produce causal and intentional relationships.</p>
<p>Relations.A causal or intentional relationship is added between two motions/changes.In this context, a motion and a change are treated as similar elements because both can be related to a motion, as its cause or intention.The relationship from a past motion/change to a present motion/change is assumed to be a causal relationship (i.e., the past one is related as a cause of the present one).The relationship from a present motion to a future motion/change is assumed to be an intentional relationship (i.e., the future one is related as an intent of the present one).In this process, causal and intentional relationships are added to all possible combinations of motions/changes, whether or not it is commonsensically plausible from a human perspective. 6The possible combinations of motions/changes are defined as follows:</p>
<p>Causal relationship: From a motion or change in the preceding panel to a motion or change in the present panel, or from a motion to a change in the present panel (assuming a case in which a motion and the change caused by that motion are compressed into one panel).Intentional relationship: A motion in the present panel connects to a motion or change in the subsequent panel.</p>
<p>Simple language generation</p>
<p>The simple language-generation module produces sentences as linguistic expressions of part of an inner discourse.This module employs an easy template-based method for composing sentences.Each sentence expresses a different aspect of an inner discourse, that is, an object, motion, change, or relationship between motions/changes.</p>
<p>Example flow of inner narrating</p>
<p>An example flow of inner narrating is presented in Fig. 8.The source story is the same as in Fig. 5.In this example, the initial selected target of attention is set as the motion ''find" in P 1 .Then, the transition of attention occurs automatically from P 1 to P 4 , and an inner discourse is generated in each step, as shown in (1) to (4) in Fig. 8. Linguistic expressions corresponding to these inner discourses are shown in Table 4.The center of the above flow of inner narrating can be seen as a course of motions.Moreover, different inner discourses can be generated by focusing on different elements.For example, Fig. 9 shows the inner discourse with attention to ''Gonta" in P 2 .This inner discourse contains different information from Fig. 8 (2), e.g., a change of Gonta's FEELING from ''happy" in P 1 to ''surprise" in P 2 and a causal relationship between a motion ''I kick Gonta" and this change.</p>
<p>Future issues</p>
<p>The framework of a Cogmic Space and its generative process should be further refined in the future.In this section, several theoretical issues are discussed.</p>
<p>Sensory/bodily dimension of a story</p>
<p>One of the characteristics of the proposed framework is that it represents a temporal segment of a world with a panel.In a panel, an event(s) with its background situation is formed by a spatial and relational composition of conceptual objects and motions.This framework has the potential to acquire a rich representational power for the internal construction of a world, with an isomorphic or analogical relationship to an external environment.However, this potential is not fully realized in the present framework.In particular, the present framework provides only a broad account of the mechanism of the sensory/bodily dimension of a story.For example, a human's bodily features, including looks, posture, facial expression, and clothes become a rich information source for constructing the representation or memory of events and situations.Such physical-imagery features must be integrated with the conceptual dimension.However, the detailed mechanism that represents and generates these conceptually organized physical features of an object or scene is not yet sufficiently conceptualized.</p>
<p>For this issue, the relationship between a story and the perceptual process should be further refined.Relevant studies on this issue can be found in various fields.In the cognitive theory of perceptual symbol systems (Barsalou, 1999), the perceptual process is described as a generative process in which a perceptual symbol representation is dynamically produced via bidirectional top-down and bottom-up processes.The event-segmentation theory by Zacks, Speer, Swallow, Braver, and Reynolds (2007) provides a cognitive theory on the temporal segmentation of continuous sensory or perceptual information; see also Anderson (2015).At the computational level, applying object recognition and visual feature extraction based on convolutional neural networks will be an immediate solution for generating object representation, including visual features.Computational mechanisms for the symbolic recognition of objects or scenes (e.g., Chella et al., 2008) and symbol emergence through interacting environments (see Taniguchi et al. (2018) for a review) have been studied in the field of cognitive robotics.On the sensory/bodily dimension of an event, conceptual space theory by Ga ¨rdenfors (2014) presents vector-based semantics of an action and event.Besold, Hedblom, and Kutz (2017) proposed a formal event representation based on image (2) the motion ''I kick Gonta" in P 2 ;</p>
<p>(3) the motion ''Gonta runs away" in P 3 ; and (4) the motion ''I pick the apple" in P 4 .</p>
<p>schemas.These theories may be associated with motion representation in a Cogmic Space.Moreover, sensory/bodily information involved in a story must be available for use in various cognitive processes.In other words, the spatial, physical, and imagery features in a story become valuable when they are involved in various cognitive contexts.From our standpoint, the following two cognitive processes or abilities are considered as basic issues.The first issue is the ability to tell (or verbalize) a story with rich scene descriptions because this task requires an interpretive process for the story's sensory/bodily dimension.This ability also becomes a measure for evaluating the qualitative richness of an agent's internal representation from an external perspective through narratives told by the agent.</p>
<p>The second issue is computing the similarity between stories or events based not only on the conceptual dimension but also on the sensory/bodily dimension.In the field of cognitive science, the cognition of similarity is widely known as the common foundation of various cognitive processes, including the operation of a memory system and creativity.Cognitive and computational studies on visual narratives (e.g., Cohn, 2013Cohn, , 2019) ) and sketch understanding (e.g., Forbus, Usher, Lovett, Lockwood, &amp; Wetzel, 2011) may be associated with the above issues.</p>
<p>Generative story process</p>
<p>An in-depth theory of the story-generation process in the form of a Cogmic Space has not yet been developed, particularly in the unconscious-level process.Although this is a complex issue, there is a rich accumulation of studies on computational story generation.Computational story generation involves various sub-issues: how to represent a story, what types of knowledge are required, what core processes are, what ''good" stories are in a specific context or purpose, etc.In terms of core processes, the major approaches to computational story generation can be categorized as follows:</p>
<p>(a) Planning-based modeling, in which the story generation is formulated as the characters' goal-oriented actions (e.g., Meehan, 1980;Riedl &amp; Young, 2010); (b) Schematic modeling of the structure of specific types of stories (e.g., Bringsjord &amp; Ferrucci, 1999;Gerva ´s, 2016;Pemberton, 1989) Sharples, 2001;Turner, 1994); and (d) Data-driven approaches based on statistical learning or neural network technologies (e.g., Fan et al., 2018;McIntyre &amp; Lapata, 2009).</p>
<p>Because the total story-generation system can be considered as a synthesis of various cognitive processes, the per-spective of a cognitive system or architecture is required for computational story generation.From our cognitivesystem perspective, a memory system (as a part of a cognitive system) plays an essential role in integrative story generation.In this context, the fundamental role of the memory system is to form generative-story forces through physical, social, and mental experiences, including communication via narratives.The productivity of various types of connections between story elements (events, entities, concepts, etc.), based on temporal, causal, semantic, and associative relationships, is the foundation of story generation.In a cognitive system, such generative forces should be formed through experience.Schemas for top-down story cognition are also considered as experientially developed structures.In the context of case-based or analogical reasoning, stories in a memory accumulated through experiences become the basis of story generation.As described previously (see Section 2.4), we consider that the integration of the above different cognitive processes and the formation of generative forces are predominantly performed via the unconscious-level, parallel distributed process.</p>
<p>Based on the above view, another ongoing study of ours (Akimoto, 2021) addresses the development of a parallel distributed memory system in which concrete stories and general-level memory items, including concepts and schemas, are mutually connected in a network form.The Cogmic Space has not yet been introduced to this memory system.However, assuming that a memory organization involving generative forces is formed through experiences, the qualitative richness of stories as experiential world representations is an important issue for story generation.Hence, a major issue in the future is to consider how Cogmic Space-based stories can be generalized into a memory organization and how these stories can be reused in the processes of analogical or combinational story generation.</p>
<p>Self as a character</p>
<p>Representing a self as the central character of a story (i.e., a character-self, see Section 3.3.4)may become a concern in a comic strip-like representation of a world.In the present framework, a self (''I") is contained in a panel as a character object, in the same manner as other characters or objects.However, it should be noted that a story is a midlevel representation, distinguished from a sensory/bodily space or a perceived environment itself.At that level, partially objectifying the self into a character similar to others can be seen as an essential nature for human-like intelligence, in terms of self-consciousness, meta-cognition, distinction between self and others, etc. Pictures or diaries illustrated by young children naturally include their bodies.Thus, we consider that a major problem of the present framework is that there is no qualitative difference between the character-self and others.This issue should be further considered in the future.</p>
<p>Conclusion</p>
<p>A computational theory of a unified world representation with rich representational power is an essential issue for creating human-like artificial intelligence.Regarding this issue, the conceptual framework of a Cogmic Space and its proof-of-concept implementation are presented in this paper.The key properties of a Cogmic Space are summarized as follows:</p>
<p>A Cogmic Space represents a (piece of) world as a story in a form similar to narrative comics.A story is a mid-level representation in which the conceptual and sensory/bodily dimensions of a world are unified.The events and background situations that constitute a story are unified into a sequence of panels.A story and the represented environment are connected by an isomorphic relationship.The conscious-level generative process of a representation, referred to as inner narrating, is characterized via an analogy with the reading of a comic or narrative.</p>
<p>Although a full-fledged implementation of the proposed concept is yet a distant goal, we believe that the proposed concept has the potential to become the basis for a computational representation of a rich world.</p>
<p>Fig. 1 .
1
Fig. 1.(a) Symbolic story representation versus (b) conceptual, sensory/bodily story representation.Fig. 2. (a) State-based versus (b) event-centric world representations.</p>
<p>Fig. 4 .
4
Fig. 4. Cognitive-system structure on Cogmic Space-based world representations.</p>
<p>Fig. 5 .
5
Fig. 5. Example window-capture.(a) A story is displayed at the top of the window.A linguistic summary of this story, focusing on motions, is as follows: ''P 1 : I find an apple (on a tree).Gonta (raccoon dog) eats an apple (on the ground).P 2 : I kick Gonta.P 3 : Gonta runs away.P 4 : I pick the apple (from the tree)."Additional information is contained in this story, as annotated with yellow labels.(b) The presented inner discourse in the middle is generated with attention to the motion, ''I kick Gonta," in P 2 .(c) The sentences at the bottom are linguistic expressions generated from the inner discourse.The English translation of this part is presented later in Table4, item (2).</p>
<p>Fig. 7 .
7
Fig. 7. Iconic pictures for the eight object categories: (a) HUMAN, (b) ANIMAL, (c) PLANT, (d) OBJECT (circle, rectangle, triangle, or bar), (e) FEELING (with a concept, e.g., ''anger"), (f) SOUND (as an onomatopoeia), (g) SPEECH (e.g., ''Hello"), and (h) CONTAINER.</p>
<p>Fig.9.Another example: Inner discourse with attention to ''Gonta" in P 2 .</p>
<p>Table 1
1
Distinction between the unconscious and conscious levels of narrativebased representations and their generative processes.
Unconscious levelConscious levelRepresentationStoryInner discourseGenerative processSelf-organizationInner narrating</p>
<p>Table 2
2
Properties of an object.
TypeExplanationBasic categoryOne of the eight object categories.PositionX-and Y-axis positions in a panel.
SizeNumerical value denoting the object size.It may represent the conceptual size of an object (e.g., the strength of a feeling).Name * Symbol corresponding to a proper name.In the case of a SOUND or SPEECH, onomatopoetic letters or an utterance is contained here.Concept * Symbol corresponding to a linguistic concept.A FEELING is also represented as a concept.Link * Subordinate relationship to another object or motion.Contents * List of contained objects.This property is only available for a CONTAINER.*OptionalFig.6.Implemented system structure.</p>
<p>; (c) Case-based or analogical modeling to generate a new story based on existing stories (e.g., Gerva ´s et al., 2005; Ontan ˜o ´n &amp; Zhu, 2011; Pe ´rez y Pe ´rez &amp;</p>
<p>T. Akimoto / Cognitive Systems Research 65 (2021) 167-183
Signs in comics include all aspects of icons, indexes, and symbols, in terms of the semiotics by C. S. Peirce. T. Akimoto / Cognitive Systems Research 65 (2021) 167-183
In this paper, only single-line stories are considered, for the sake of simplicity. However, branched and parallel panel organizations are more adequate for emulating the mind's complexity.
The term ''context" is used to refer to the relationship of a panel with other panels (before and after), whereas a ''situation" is contained within a panel.
The system is implemented with Processing, an object-oriented programming language. This language is employed because it is suitable for the rapid prototyping of a program, including visual drawing, although it is unfit for developing the body of an artificial cognitive system.T.Akimoto / Cognitive Systems Research 65 (2021) 167-183<br />
For simplicity, only adjacent panels are associated using inter-panel mapping, although the contextual structure in a story should ideally have a wider range.
To enable a plausible interpretation of causal/intentional relationships between motions/changes, a sophisticated commonsense system will be required.
T.Akimoto / Cognitive Systems Research 65 (2021) 167-183<br />
FundingThis work was supported by JSPS KAKENHI Grant No. JP18K18344 and Support Center for Advanced Telecommunications Technology Research, Foundation.Declaration of Competing InterestThe authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.
Stories as mental representations of an agent's subjective world: A structural overview. T Akimoto, 10.1016/j.bica.2018.07.003Biologically Inspired Cognitive Architectures. 252018</p>
<p>Narrative structure in the mind: Translating Genette's narrative discourse theory into a cognitive system. T Akimoto, 10.1016/j.cogsys.2019.08.007Cognitive Systems Research. 582019</p>
<p>T Akimoto, Developing a parallel distributed memory system of stories: A preliminary report. Elsevier2021in press</p>
<p>From episodic memory to narrative in a cognitive architecture. T S Anderson, Proceedings of 6th Workshop on Computational Models of Narrative. 6th Workshop on Computational Models of Narrative2015</p>
<p>From focused thought to reveries: A memory system for a conscious robot. C Balkenius, T A Tjøstheim, B Johansson, P Ga ¨rdenfors, 10.3389/frobt.2018.00029Frontiers in Robotics and AI. 5292018</p>
<p>Perceptual symbol systems. L W Barsalou, 10.1017/S0140525X99002149Behavioral and Brain Sciences. 221999</p>
<p>A narrative in three acts: Using combinations of image schemas to model events. T R Besold, M M Hedblom, O Kutz, 10.1016/j.bica.2016.11.001Biologically Inspired Cognitive Architectures. 192017</p>
<p>Artificial intelligence and literary creativity: Inside the mind of BRUTUS, a storytelling machine. S Bringsjord, D A Ferrucci, 1999Lawrence ErlbaumNJ</p>
<p>Encoding and recall of spatiotemporal episodic memory in real time. P.-H Chang, A.-H Tan, 10.24963/ijcai.2017/206Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence. the Twenty-Sixth International Joint Conference on Artificial Intelligence2017</p>
<p>A cognitive architecture for robot self-consciousness. A Chella, M Frixione, S Gaglio, 10.1016/j.artmed.2008.07.003Artificial Intelligence in Medicine. 442008</p>
<p>Developing selfawareness in robots via inner speech. A Chella, A Pipitone, A Morin, F Racy, 10.3389/frobt.2020.00016Frontiers in Robotics and AI. 7162020</p>
<p>Visual narrative structure. N Cohn, 10.1111/cogs.12016Cognitive Science. 372013</p>
<p>Visual narratives and the mind: Comprehension, cognition, and learning. N Cohn, Psychology of learning and motivation: Knowledge and vision. K Federmeier, D Beck, LondonAcademic Press201970</p>
<p>Representations, targets, and attitudes. R Cummins, 1996MIT PressMA</p>
<p>The feeling of what happens: Body and emotion in the making of consciousness. A R Damasio, 1999Harcourt BraceNY</p>
<p>Self comes to mind: Constructing the conscious brain. A R Damasio, 2010Pantheon BooksNY</p>
<p>Consciousness explained. D C Dennett, 1991NY: Little, Brown and Company</p>
<p>What computers can't do: The limits of artificial intelligence. H L Dreyfus, 1979Harper &amp; RowNYrevised ed.</p>
<p>The structuremapping engine: Algorithm and examples. B Falkenhainer, K D Forbus, D Gentner, 10.1016/0004-3702(89)90077-5Artificial Intelligence. 411989</p>
<p>Hierarchical neural story generation. A Fan, M Lewis, Y Dauphin, 10.18653/v1/P18-1082Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics. the 56th Annual Meeting of the Association for Computational Linguistics20181</p>
<p>The way we think: Conceptual blending and the mind's hidden complexities. G Fauconnier, M Turner, 2002NY: Basic Books</p>
<p>CogSketch: Sketch understanding for cognitive science research and for education. K Forbus, J Usher, A Lovett, K Lockwood, J Wetzel, 10.1111/j.1756-8765.2011.01149.xTopics in Cognitive Science. 32011</p>
<p>Conceptual spaces: The geometry of thought. P Ga ¨rdenfors, 2000MIT PressMA</p>
<p>The geometry of meaning: Semantics based on conceptual spaces. P Ga ¨rdenfors, 2014MIT PressMA</p>
<p>Narrative discourse: An essay in method. G Genette, Trans. J.E. Lewin. Original work published. 1980. 1972Cornell University Press</p>
<p>Computational drafting of plot structures for Russian folk tales. P Gerva ´s, 10.1007/s12559-015-9338-8Cognitive Computation. 82016</p>
<p>Story plot generation based on CBR. Knowledge-Based Systems. P Gerva ´s, B Dı ´az-Agudo, F Peinado, R Herva ´s, 10.1016/j.knosys.2004.10.011200518</p>
<p>MS: The University Press of Mississippi. T Groensteen, Trans. B. Beaty &amp; N. Nguyen2007. 1999The system of comics</p>
<p>Mental leaps: Analogy in creative thought. K J Holyoak, P Thagard, 1995MIT PressMA</p>
<p>The act of reading: A theory of aesthetic response. W Iser, 1980. 1976Johns Hopkins University PressMD</p>
<p>Toward an aesthetic of reception. H R Jauss, Trans. T. Bahti. Original work published. 1982. 1970MN: The University of Minnesota Press</p>
<p>The body in the mind: The bodily basis of meaning, imagination, and reason. M Johnson, 1987The University of Chicago PressIL</p>
<p>Comprehension: A paradigm for cognition. W Kintsch, 1998Cambridge University PressCambridge</p>
<p>The Soar cognitive architecture. J E Laird, G Lakoff, M Johnson, Metaphors we live by. MA; ILUniversity of Chicago Press2012. 1980</p>
<p>Learning to tell tales: A data-driven approach to story generation. N Mcintyre, M Lapata, Proceedings of Joint Conference of the 47th Annual Meeting of the Association for Computational Linguistics and the 4th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing. Joint Conference of the 47th Annual Meeting of the Association for Computational Linguistics and the 4th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing2009</p>
<p>The metanovel: Writing stories by computer. J R Meehan, 1980Garland PublishingNY</p>
<p>The society of mind. M Minsky, 1986Simon &amp; SchusterNY</p>
<p>The emotion machine: Commonsense thinking, artificial intelligence, and the future of the human mind. M Minsky, 2006Simon &amp; SchusterNY</p>
<p>Human problem solving. A Newell, H A Simon, 1972Prentice-HallNJ</p>
<p>The SAM algorithm for analogy-based story generation. S Ontan ˜o ´n, J Zhu, Proceedings of 7th AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment. 7th AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment2011</p>
<p>A modular approach to story generation. L Pemberton, Proceedings of 4th Conference on European Chapter. 4th Conference on European Chapterthe Association for Computational Linguistics1989</p>
<p>MEXICA: A computer model of a cognitive account of creative writing. R Pe ´rez Y Pe ´rez, M Sharples, 10.1080/09528130010029820Journal of Experimental &amp; Theoretical Artificial Intelligence. 132001</p>
<p>Event perception. G A Radvansky, J M Zacks, 10.1002/wcs.133Wiley Interdisciplinary Reviews: Cognitive Science. 22011</p>
<p>The rise of machine consciousness: Studying consciousness with computational models. J A Reggia, 10.1016/j.neunet.2013.03.011Neural Networks. 442013</p>
<p>Narrative planning: Balancing plot and character. M O Riedl, R M Young, 10.1613/jair.2989Journal of Artificial Intelligence Research. 392010</p>
<p>Deep episodic memory: Encoding, recalling, and predicting episodic experiences for robot action execution. J Rothfuss, F Ferreira, E E Aksoy, Y Zhou, T Asfour, 10.1109/LRA.2018.2860057IEEE Robotics and Automation Letters. 32018</p>
<p>Fundamental principles and mechanisms of the conscious self. A V Samsonovich, Jong De, K A Kitsantas, A Samsonovich, A V Nadel, L , 10.1016/S0010-9452(08)70284-3International Journal of Machine Consciousness. 12009. 2005Cortex</p>
<p>Dynamic memory: A theory of reminding and learning in computers and people. R C Schank, 1982Cambridge University PressNY</p>
<p>Scripts, plans, goals, and understanding: An inquiry into human knowledge structures. R C Schank, R P Abelson, 1977Lawrence ErlbaumNJ</p>
<p>Teaching machines about everyday life. P Singh, B Barry, H Liu, 10.1023/B:BTTJ.0000047601.53388.74BT Technology Journal. 222004</p>
<p>Duality of the mind: A bottom-up approach toward cognition. R Sun, 2002Lawrence Erlbaum Associates PublishersNJ</p>
<p>Manga hyougengaku nyuumon [An introduction to comic expression study. O Takeuchi, Chikuma Shoten2005TokyoIn Japanese</p>
<p>Symbol emergence in cognitive developmental systems: A survey. T Taniguchi, E Ugur, M Hoffmann, L Jamone, T Nagai, B Rosman, F , 10.1109/TCDS.2018.2867772IEEE Transactions on Cognitive and Developmental Systems. 112018Wo ¨rgo ¨tter</p>
<p>The creative process: A computer model of storytelling and creativity. S R Turner, 1994Lawrence ErlbaumNJ</p>
<p>Modeling autobiographical memory in human-like autonomous agents. D Wang, A.-H Tan, C Miao, Proceedings of the 15th International Conference on Autonomous Agents and Multiagent Systems. the 15th International Conference on Autonomous Agents and Multiagent Systems2016</p>
<p>Neural modeling of episodic memory: Encoding, retrieval, and forgetting. W Wang, B Subagdja, A.-H Tan, J A Starzyk, 10.1109/TNNLS.2012.2208477IEEE Transactions on Neural Networks and Learning Systems. 232012</p>
<p>Understanding computers and cognition: A new foundation for design. T Winograd, F Flores, 1986Ablex PublishingNY</p>
<p>The right way. P H Winston, Advances in Cognitive Systems. 12012</p>
<p>The Genesis story understanding and story telling system: A 21st century step toward artificial intelligence. P H Winston, Center for Brains Minds and Machines, MIT. 2014Technical Report</p>
<p>The comprehension and validation of social information. R S Wyer, G A Radvansky, 10.1037/0033-295X.106.1.89Psychological Review. 1061999</p>
<p>Event perception: A mind/brain perspective. J M Zacks, N K Speer, K M Swallow, T S Braver, J R Reynolds, 10.1037/0033-2909.133.2.273Psychological Bulletin. 1332007</p>
<p>Situation models in language comprehension and memory. R A Zwaan, G A Radvansky, 10.1037/0033-2909.123.2.162Psychological Bulletin. 1231998</p>            </div>
        </div>

    </div>
</body>
</html>