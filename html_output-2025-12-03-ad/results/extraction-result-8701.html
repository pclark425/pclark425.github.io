<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-8701 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-8701</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-8701</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-156.html">extraction-schema-156</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of representational formats of conceptual knowledge at a functional (not neural) level, including descriptions of the format, supporting or challenging evidence, cognitive tasks or phenomena used as evidence, comparisons between formats, and theoretical claims or implications.</div>
                <p><strong>Paper ID:</strong> paper-267364904</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2402.00591v3.pdf" target="_blank">Sandra - A Neuro-Symbolic Reasoner Based On Descriptions And Situations</a></p>
                <p><strong>Paper Abstract:</strong> This paper presents sandra , a neuro-symbolic rea-soner combining vectorial representations with deductive reasoning. Sandra builds a vector space constrained by an ontology and performs reasoning over it. The geometric nature of the reasoner allows its combination with neural networks, bridging the gap with symbolic knowledge representations. Sandra is based on the Description and Situation (DnS) ontology design pattern, a formalization of frame semantics. Given a set of facts (a situation) it allows to infer all possible perspectives (descriptions) that can provide a plausible interpretation for it, even in presence of incomplete information. We prove that our method is correct with respect to the DnS model. We experiment with two different tasks and their standard benchmarks, demonstrating that, without increasing complexity, sandra (i) outperforms all the baselines (ii) provides interpretability in the classification process, and (iii) allows control over the vector space, which is designed a priori.</p>
                <p><strong>Cost:</strong> 0.015</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e8701.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e8701.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of representational formats of conceptual knowledge at a functional (not neural) level, including descriptions of the format, supporting or challenging evidence, cognitive tasks or phenomena used as evidence, comparisons between formats, and theoretical claims or implications.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DnS</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Description and Situation (DnS) ontology design pattern</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A frame-semantics based symbolic ontology pattern that models conceptual perspectives as descriptions (intensional n-ary relations of roles) and observed data as situations (extensional sets of entities), with a satisfaction relation that links situations to plausible descriptions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_name</strong></td>
                            <td>frame-based description/situation representation (DnS)</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_description</strong></td>
                            <td>Conceptual knowledge is represented symbolically as two kinds of first-order entities: descriptions (intensional n-ary relations composed of roles) and situations (extensional tuples/sets of entities and nested situations). A binary relation 'satisfies' (d |= s) holds when each role of a description can be filled by some entity in the situation (allowing nested situations); a weaker 'near-satisfaction' relation permits partial fulfillment. Descriptions can nest and roles can subsume one another, enabling hierarchy and reuse.</td>
                        </tr>
                        <tr>
                            <td><strong>format_type</strong></td>
                            <td>symbolic / frame-based / relational</td>
                        </tr>
                        <tr>
                            <td><strong>cognitive_task_or_phenomenon</strong></td>
                            <td>Perspective-taking, multi-hypothesis interpretation of the same data (examples discussed conceptually include medical diagnosis, legal interpretation, political framing); operationalized in this paper via visual reasoning (Raven Progressive Matrices / I-RAVEN) and image classification / domain generalization (Rotated-FashionMNIST) when embedded in the sandra pipeline.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>The paper uses DnS as the intensional layer for sandra and formalizes DnS semantics (Definitions 1–4) and proves properties (Corollaries/Theorems) about satisfaction and near-satisfaction. Empirically, encoding an ontology of descriptions and roles (DnS) as constraints improved interpretability and did not reduce — and in some configurations improved — task accuracy when integrated into neural models on I-RAVEN and Rotated-FashionMNIST. The DnS formalization enables expressing multiple (possibly incompatible) descriptions that can each plausibly interpret the same situation, something that standard strict-logic classification would mark inconsistent.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_formats</strong></td>
                            <td>Contrasted explicitly with pure logic-based (Description Logic / OWL) representations — which enforce consistency and may reject multiple incompatible classifications — and with black-box neural distributed representations — which can ingest unstructured data but lack logical completeness and may miss valid alternative descriptions. DnS provides symbolic structure allowing intensional/extensional reasoning; however, without sandra it is strictly symbolic and can suffer from strict inconsistency constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_counter_evidence</strong></td>
                            <td>DnS by itself requires an explicitly engineered ontology and structured data; mapping other ontologies into a DnS form may require reification and can introduce backward inconsistencies. The power of DnS depends on the quality and design of the ontology (ODP) and can be computationally heavy when ontologies grow (f_s complexity linear in |D ∪ R|). The original DnS formalization does not provide a graded probabilistic satisfaction measure (the paper extends it to do so).</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_claims_or_implications</strong></td>
                            <td>DnS offers a principled way to represent multiple perspectives (descriptions) over the same extensional data (situations) and supports both intensional and extensional reasoning in the same formal domain; when given as the ontology layer it can serve as the scaffold for hybrid/neuro-symbolic systems that need to reason about alternative plausible interpretations of the same input.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Sandra - A Neuro-Symbolic Reasoner Based On Descriptions And Situations', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8701.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e8701.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of representational formats of conceptual knowledge at a functional (not neural) level, including descriptions of the format, supporting or challenging evidence, cognitive tasks or phenomena used as evidence, comparisons between formats, and theoretical claims or implications.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>sandra (vectorized DnS)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>sandra — DnS-based neuro-symbolic vector-space representation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A hybrid representational format introduced in this paper that constructs a vector space isomorphic to a DnS ontology: each description corresponds to a linear subspace spanned by role-derived basis vectors, and situations are encoded as vectors whose membership (or partial membership) in these subspaces yields (probabilistic) satisfaction of descriptions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_name</strong></td>
                            <td>ontology-constrained geometric (subspace) representation of descriptions and situations</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_description</strong></td>
                            <td>Functional description: build a vector space V of dimension |D ∪ R|; map each role/description to a vector via f_d and let each description d define a subspace V_d spanned by its role vectors B_d. Map situations to vectors v_s via f_s by aggregating vectors of roles that classify entities (or recursively mapping nested situations). A situation satisfies description d iff v_s lies in subspace V_d; near-satisfaction is a graded (multinomial/probabilistic) measure computed from the decomposition coefficients. The model replaces a non-differentiable Heaviside indicator with ReLU to make the satisfaction operator differentiable and usable as a neural network layer.</td>
                        </tr>
                        <tr>
                            <td><strong>format_type</strong></td>
                            <td>hybrid: symbolic (ontology) + distributed/geometric (vector/subspace)</td>
                        </tr>
                        <tr>
                            <td><strong>cognitive_task_or_phenomenon</strong></td>
                            <td>Evaluated on visual reasoning (I-RAVEN / RPM tasks) and domain-generalization image classification (Rotated-FashionMNIST); functionally targeted at perspective-taking (multiple plausible interpretations), robustness to partial/ambiguous data, and interpretability of classification decisions.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>The paper proves formal correctness: Theorem 2 shows d |= s iff f_s(s) ∈ V_d and Theorem 3 extends correctness to probabilistic (near-)satisfaction. Practically, integrating the sandra layer into baseline neural architectures constrained the learned internal representations to lie in ontology-defined subspaces, improving interpretability and (in reported experiments) improving or at least not degrading accuracy while adding only modest parameter overhead. The sandra layer is differentiable (via ReLU approximation) enabling end-to-end training. Complexity of computing f_d and bases B_d is polynomial (the authors state O(|D|^2) for B_d computation and linear scaling of f_s with |D ∪ R|).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_formats</strong></td>
                            <td>Compared against: (i) strict logic-based reasoners (symbolic): sandra permits co-existing incompatible descriptions by mapping them to different subspaces rather than causing logical inconsistency; (ii) pure neural distributed representations: sandra enforces ontology-induced structure in the embedding space, aiming to retain neural flexibility while restoring interpretability and deductive guarantees; (iii) other neuro-symbolic probabilistic approaches: those often retain consistency assumptions or rely on probabilistic logic — sandra claims to be tolerant to inconsistency among descriptions and to provide a deterministic mapping between symbolic descriptions and geometric subspaces.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_counter_evidence</strong></td>
                            <td>Dependence on availability and design of a DnS ontology (ODP); scalability concerns as ontology size grows (the dimension of V equals |D ∪ R| and f_s is linear in that dimension); inability in current formulation to invert f_s to recover which specific entity was mapped to which role (loss of per-entity assignment); initial Heaviside-based satisfaction is non-differentiable requiring approximations (ReLU) which modify exact gradients; mapping arbitrary ontologies into DnS via reification may be backward-inconsistent (inferred satisfied descriptions may map to disjoint classes in original ontology).</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_claims_or_implications</strong></td>
                            <td>The paper claims a theoretically-correct bridge between symbolic DnS semantics and continuous geometric representations: descriptions correspond to linear subspaces and satisfaction to subspace membership, enabling graded probabilistic interpretation and differentiable neuro-symbolic integration. Functionally, this format is claimed to support perspective-based reasoning, interpretability of intermediate neural representations, tolerance to partial and conflicting information, and the combination of deductive and inductive inference without increasing computational complexity asymptotically.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Sandra - A Neuro-Symbolic Reasoner Based On Descriptions And Situations', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8701.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e8701.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of representational formats of conceptual knowledge at a functional (not neural) level, including descriptions of the format, supporting or challenging evidence, cognitive tasks or phenomena used as evidence, comparisons between formats, and theoretical claims or implications.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Conceptual spaces</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Conceptual Spaces (geometric representation of concepts)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A geometric theory of concepts (Gärdenfors) representing concepts as convex regions in a metric/feature space where dimensions correspond to quality attributes; mentioned as an inspiration and point of comparison for sandra's geometric encoding.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_name</strong></td>
                            <td>conceptual spaces (region-based geometric representation)</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_description</strong></td>
                            <td>Concepts are represented as convex regions in a continuous geometric space whose axes (dimensions) correspond to interpretable quality criteria; similarity and concept combination correspond to geometric proximity and region operations, enabling interpretable feature-based concept representation without purely symbolic structure.</td>
                        </tr>
                        <tr>
                            <td><strong>format_type</strong></td>
                            <td>geometric / feature-based / interpretable continuous</td>
                        </tr>
                        <tr>
                            <td><strong>cognitive_task_or_phenomenon</strong></td>
                            <td>Used in cognitive theory to explain graded category membership, similarity-based judgments, concept combination and prototypicality effects; in this paper it is invoked as background motivation rather than experimentally tested. The authors point to two common challenges for conceptual spaces: deriving region-based representations from real-world data, and expressing relational knowledge.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>The paper argues that sandra follows the intuition of conceptual spaces (geometric representations) but extends it by providing a mechanism to express relational/n-ary relations (via DnS) and to ingest unstructured data through a neural situation-approximator; the authors state that this overcomes the two main problems highlighted in recent conceptual-spaces implementations (Bouraoui et al., 2022): region derivation from real data and expressing relational knowledge.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_formats</strong></td>
                            <td>Conceptual spaces are contrasted with purely symbolic frame/ontology-based representations and with sandra's hybrid approach: conceptual spaces are praised for interpretability but criticized for difficulty representing relations; sandra claims to retain geometric interpretability while covering relational structure by construction (subspaces tied to role-based descriptions).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_counter_evidence</strong></td>
                            <td>Conceptual spaces struggle to derive suitable region-based representations from messy real-world inputs and to represent relational (n-ary) structure inherent in many cognitive domains; the paper cites these as reasons to adopt a DnS+geometric approach instead.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_claims_or_implications</strong></td>
                            <td>Geometric representations can serve as an intermediate layer between sub-symbolic inputs and symbolic knowledge, but to be practical they need mechanisms for relational expressivity and for mapping unstructured real-world data into regions; sandra is presented as an operationalization that addresses these theoretical gaps.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Sandra - A Neuro-Symbolic Reasoner Based On Descriptions And Situations', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>A framework for representing knowledge <em>(Rating: 2)</em></li>
                <li>RAVEN: A dataset for relational and analogical visual reasoning. <em>(Rating: 1)</em></li>
                <li>Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms. <em>(Rating: 1)</em></li>
                <li>Cone semantics for logics with negation. <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-8701",
    "paper_id": "paper-267364904",
    "extraction_schema_id": "extraction-schema-156",
    "extracted_data": [
        {
            "name_short": "DnS",
            "name_full": "Description and Situation (DnS) ontology design pattern",
            "brief_description": "A frame-semantics based symbolic ontology pattern that models conceptual perspectives as descriptions (intensional n-ary relations of roles) and observed data as situations (extensional sets of entities), with a satisfaction relation that links situations to plausible descriptions.",
            "citation_title": "",
            "mention_or_use": "use",
            "representational_format_name": "frame-based description/situation representation (DnS)",
            "representational_format_description": "Conceptual knowledge is represented symbolically as two kinds of first-order entities: descriptions (intensional n-ary relations composed of roles) and situations (extensional tuples/sets of entities and nested situations). A binary relation 'satisfies' (d |= s) holds when each role of a description can be filled by some entity in the situation (allowing nested situations); a weaker 'near-satisfaction' relation permits partial fulfillment. Descriptions can nest and roles can subsume one another, enabling hierarchy and reuse.",
            "format_type": "symbolic / frame-based / relational",
            "cognitive_task_or_phenomenon": "Perspective-taking, multi-hypothesis interpretation of the same data (examples discussed conceptually include medical diagnosis, legal interpretation, political framing); operationalized in this paper via visual reasoning (Raven Progressive Matrices / I-RAVEN) and image classification / domain generalization (Rotated-FashionMNIST) when embedded in the sandra pipeline.",
            "key_findings": "The paper uses DnS as the intensional layer for sandra and formalizes DnS semantics (Definitions 1–4) and proves properties (Corollaries/Theorems) about satisfaction and near-satisfaction. Empirically, encoding an ontology of descriptions and roles (DnS) as constraints improved interpretability and did not reduce — and in some configurations improved — task accuracy when integrated into neural models on I-RAVEN and Rotated-FashionMNIST. The DnS formalization enables expressing multiple (possibly incompatible) descriptions that can each plausibly interpret the same situation, something that standard strict-logic classification would mark inconsistent.",
            "comparison_with_other_formats": "Contrasted explicitly with pure logic-based (Description Logic / OWL) representations — which enforce consistency and may reject multiple incompatible classifications — and with black-box neural distributed representations — which can ingest unstructured data but lack logical completeness and may miss valid alternative descriptions. DnS provides symbolic structure allowing intensional/extensional reasoning; however, without sandra it is strictly symbolic and can suffer from strict inconsistency constraints.",
            "limitations_or_counter_evidence": "DnS by itself requires an explicitly engineered ontology and structured data; mapping other ontologies into a DnS form may require reification and can introduce backward inconsistencies. The power of DnS depends on the quality and design of the ontology (ODP) and can be computationally heavy when ontologies grow (f_s complexity linear in |D ∪ R|). The original DnS formalization does not provide a graded probabilistic satisfaction measure (the paper extends it to do so).",
            "theoretical_claims_or_implications": "DnS offers a principled way to represent multiple perspectives (descriptions) over the same extensional data (situations) and supports both intensional and extensional reasoning in the same formal domain; when given as the ontology layer it can serve as the scaffold for hybrid/neuro-symbolic systems that need to reason about alternative plausible interpretations of the same input.",
            "uuid": "e8701.0",
            "source_info": {
                "paper_title": "Sandra - A Neuro-Symbolic Reasoner Based On Descriptions And Situations",
                "publication_date_yy_mm": "2024-02"
            }
        },
        {
            "name_short": "sandra (vectorized DnS)",
            "name_full": "sandra — DnS-based neuro-symbolic vector-space representation",
            "brief_description": "A hybrid representational format introduced in this paper that constructs a vector space isomorphic to a DnS ontology: each description corresponds to a linear subspace spanned by role-derived basis vectors, and situations are encoded as vectors whose membership (or partial membership) in these subspaces yields (probabilistic) satisfaction of descriptions.",
            "citation_title": "here",
            "mention_or_use": "use",
            "representational_format_name": "ontology-constrained geometric (subspace) representation of descriptions and situations",
            "representational_format_description": "Functional description: build a vector space V of dimension |D ∪ R|; map each role/description to a vector via f_d and let each description d define a subspace V_d spanned by its role vectors B_d. Map situations to vectors v_s via f_s by aggregating vectors of roles that classify entities (or recursively mapping nested situations). A situation satisfies description d iff v_s lies in subspace V_d; near-satisfaction is a graded (multinomial/probabilistic) measure computed from the decomposition coefficients. The model replaces a non-differentiable Heaviside indicator with ReLU to make the satisfaction operator differentiable and usable as a neural network layer.",
            "format_type": "hybrid: symbolic (ontology) + distributed/geometric (vector/subspace)",
            "cognitive_task_or_phenomenon": "Evaluated on visual reasoning (I-RAVEN / RPM tasks) and domain-generalization image classification (Rotated-FashionMNIST); functionally targeted at perspective-taking (multiple plausible interpretations), robustness to partial/ambiguous data, and interpretability of classification decisions.",
            "key_findings": "The paper proves formal correctness: Theorem 2 shows d |= s iff f_s(s) ∈ V_d and Theorem 3 extends correctness to probabilistic (near-)satisfaction. Practically, integrating the sandra layer into baseline neural architectures constrained the learned internal representations to lie in ontology-defined subspaces, improving interpretability and (in reported experiments) improving or at least not degrading accuracy while adding only modest parameter overhead. The sandra layer is differentiable (via ReLU approximation) enabling end-to-end training. Complexity of computing f_d and bases B_d is polynomial (the authors state O(|D|^2) for B_d computation and linear scaling of f_s with |D ∪ R|).",
            "comparison_with_other_formats": "Compared against: (i) strict logic-based reasoners (symbolic): sandra permits co-existing incompatible descriptions by mapping them to different subspaces rather than causing logical inconsistency; (ii) pure neural distributed representations: sandra enforces ontology-induced structure in the embedding space, aiming to retain neural flexibility while restoring interpretability and deductive guarantees; (iii) other neuro-symbolic probabilistic approaches: those often retain consistency assumptions or rely on probabilistic logic — sandra claims to be tolerant to inconsistency among descriptions and to provide a deterministic mapping between symbolic descriptions and geometric subspaces.",
            "limitations_or_counter_evidence": "Dependence on availability and design of a DnS ontology (ODP); scalability concerns as ontology size grows (the dimension of V equals |D ∪ R| and f_s is linear in that dimension); inability in current formulation to invert f_s to recover which specific entity was mapped to which role (loss of per-entity assignment); initial Heaviside-based satisfaction is non-differentiable requiring approximations (ReLU) which modify exact gradients; mapping arbitrary ontologies into DnS via reification may be backward-inconsistent (inferred satisfied descriptions may map to disjoint classes in original ontology).",
            "theoretical_claims_or_implications": "The paper claims a theoretically-correct bridge between symbolic DnS semantics and continuous geometric representations: descriptions correspond to linear subspaces and satisfaction to subspace membership, enabling graded probabilistic interpretation and differentiable neuro-symbolic integration. Functionally, this format is claimed to support perspective-based reasoning, interpretability of intermediate neural representations, tolerance to partial and conflicting information, and the combination of deductive and inductive inference without increasing computational complexity asymptotically.",
            "uuid": "e8701.1",
            "source_info": {
                "paper_title": "Sandra - A Neuro-Symbolic Reasoner Based On Descriptions And Situations",
                "publication_date_yy_mm": "2024-02"
            }
        },
        {
            "name_short": "Conceptual spaces",
            "name_full": "Conceptual Spaces (geometric representation of concepts)",
            "brief_description": "A geometric theory of concepts (Gärdenfors) representing concepts as convex regions in a metric/feature space where dimensions correspond to quality attributes; mentioned as an inspiration and point of comparison for sandra's geometric encoding.",
            "citation_title": "",
            "mention_or_use": "mention",
            "representational_format_name": "conceptual spaces (region-based geometric representation)",
            "representational_format_description": "Concepts are represented as convex regions in a continuous geometric space whose axes (dimensions) correspond to interpretable quality criteria; similarity and concept combination correspond to geometric proximity and region operations, enabling interpretable feature-based concept representation without purely symbolic structure.",
            "format_type": "geometric / feature-based / interpretable continuous",
            "cognitive_task_or_phenomenon": "Used in cognitive theory to explain graded category membership, similarity-based judgments, concept combination and prototypicality effects; in this paper it is invoked as background motivation rather than experimentally tested. The authors point to two common challenges for conceptual spaces: deriving region-based representations from real-world data, and expressing relational knowledge.",
            "key_findings": "The paper argues that sandra follows the intuition of conceptual spaces (geometric representations) but extends it by providing a mechanism to express relational/n-ary relations (via DnS) and to ingest unstructured data through a neural situation-approximator; the authors state that this overcomes the two main problems highlighted in recent conceptual-spaces implementations (Bouraoui et al., 2022): region derivation from real data and expressing relational knowledge.",
            "comparison_with_other_formats": "Conceptual spaces are contrasted with purely symbolic frame/ontology-based representations and with sandra's hybrid approach: conceptual spaces are praised for interpretability but criticized for difficulty representing relations; sandra claims to retain geometric interpretability while covering relational structure by construction (subspaces tied to role-based descriptions).",
            "limitations_or_counter_evidence": "Conceptual spaces struggle to derive suitable region-based representations from messy real-world inputs and to represent relational (n-ary) structure inherent in many cognitive domains; the paper cites these as reasons to adopt a DnS+geometric approach instead.",
            "theoretical_claims_or_implications": "Geometric representations can serve as an intermediate layer between sub-symbolic inputs and symbolic knowledge, but to be practical they need mechanisms for relational expressivity and for mapping unstructured real-world data into regions; sandra is presented as an operationalization that addresses these theoretical gaps.",
            "uuid": "e8701.2",
            "source_info": {
                "paper_title": "Sandra - A Neuro-Symbolic Reasoner Based On Descriptions And Situations",
                "publication_date_yy_mm": "2024-02"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "A framework for representing knowledge",
            "rating": 2,
            "sanitized_title": "a_framework_for_representing_knowledge"
        },
        {
            "paper_title": "RAVEN: A dataset for relational and analogical visual reasoning.",
            "rating": 1,
            "sanitized_title": "raven_a_dataset_for_relational_and_analogical_visual_reasoning"
        },
        {
            "paper_title": "Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms.",
            "rating": 1,
            "sanitized_title": "fashionmnist_a_novel_image_dataset_for_benchmarking_machine_learning_algorithms"
        },
        {
            "paper_title": "Cone semantics for logics with negation.",
            "rating": 1,
            "sanitized_title": "cone_semantics_for_logics_with_negation"
        }
    ],
    "cost": 0.015282249999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Sandra -A Neuro-Symbolic Reasoner Based On Descriptions And Situations
25 Mar 2024</p>
<p>Nicolas Lazzari nicolas.lazzari3@unibo.it 
University of Bologna</p>
<p>Stefano De Giorgis stefano.degiorgis2@unibo.it 
University of Bologna</p>
<p>Aldo Gangemi aldo.gangemi@unibo.it 
University of Bologna</p>
<p>Valentina Presutti valentina.presutti@unibo.it 
University of Bologna</p>
<p>Sandra -A Neuro-Symbolic Reasoner Based On Descriptions And Situations
25 Mar 2024C3C6262082EDD9DD2CBA6E4E990C48B4arXiv:2402.00591v3[cs.AI]
This paper presents sandra, a neuro-symbolic reasoner combining vectorial representations with deductive reasoning.Sandra builds a vector space constrained by an ontology and performs reasoning over it.The geometric nature of the reasoner allows its combination with neural networks, bridging the gap with symbolic knowledge representations.Sandra is based on the Description and Situation (DnS) ontology design pattern, a formalization of frame semantics.Given a set of facts (a situation) it allows to infer all possible perspectives (descriptions) that can provide a plausible interpretation for it, even in presence of incomplete information.We prove that our method is correct with respect to the DnS model.We experiment with two different tasks and their standard benchmarks, demonstrating that, without increasing complexity, sandra (i) outperforms all the baselines (ii) provides interpretability in the classification process, and (iii) allows control over the vector space, which is designed a priori.</p>
<p>Introduction</p>
<p>Reasoning on perspectives is relevant in many contexts and applications.In very rigorous domains such as medicine or jurisprudence, the same case can be interpreted through more than one description: a patient's situation can be analyzed through different diagnostic hypotheses; a legal state of affairs can be interpreted by applying different, possibly conflicting, norms.In storytelling techniques, spin doctors can frame the same topic in different ways to support alternative political scenarios: "Conservatives claim that we need relief from taxes vs. Democrats claim that taxes are investments for us."[Vossen and Fokkens, 2022].</p>
<p>Informally, a set of facts (situation) can be described through more than one -potentially conflicting -perspective, which can be inferred even in presence of partial data.This paper proposes a method and a neuro-symbolic reasoner, named sandra, able to infer all perspectives that are plausible descriptions for a given situation.Associating different plausible descriptions to a situation requires the capability to reason at both the intensional and the extensional level, i.e., with both concepts and facts, posing a challenge on how to formally represent the knowledge required, as well as on the reasoning technique to apply.</p>
<p>From a knowledge representation perspective, the Description and Situation (DnS) [Gangemi and Mika, 2003] ontology design pattern addresses this problem.DnS provides a formalization of frame semantics, generalizing over Fillmore's [Fillmore and others, 2006] and Minsky's [Minsky, 1974] proposals.It has been largely used in many ontology projects (mainly using its OWL formalization) [Scherp et al., 2009;Boyan Brodaric and Femke Reitsma and Yi Qiang, 2008;Porzel and Cangalovic, 2020;Bikakis et al., 2021].DnS defines a general vocabulary for n-ary relations, introducing the concepts of description and situation.A situation is a set of facts, as it is described by an observer, involving a set of entities.In Figure 1 a situation involving three entities is represented: Bob, ENCOM, and Laptop.A description is a perspective (a theory, a schema) defining concepts that can classify, hence interpret, the entities observed in a situation.In Figure 1 two descriptions are represented, Commerce buy and Contest winning.With DnS, both descriptions and situations are formalized as first-order entities in an ontology, therefore potentially enabling reasoning over them both at the intensional (description) and extensional (situation) level, in the same domain of discourse.In DnS terms, we say that a situation s satisfies a description d, when d is a plausible or correct interpretation of s.In Figure 1 both descriptions (Commerce buy and Contest winning) are satisfied by the situation s 1 involving Bob, ENCOM, and Laptop, even if they are conceptually incompatible.A perspectivebased reasoner shall be able to detect this conceptual difference and yet infer both satisfies relations.</p>
<p>To the best of our knowledge, this behaviour is unobtainable with existing logic-based reasoners.Within a traditional logic approach, conflicting concepts (such as Commerce buy and Contest winning) are correctly modelled as disjoint classes.Therefore, classifying the situation from the example of Figure 1 in both descriptions would lead to an inconsistency.Furthermore, no classification would be provided if the extensional data available is partial.Fuzzy reasoners, such as [Kamide, 2022], may be more tolerant but would show the same problem (inconsistency) adding an issue of possible undecidability.Logic-based representations and reasoning have also benefits: a clear, formal model of descriptions is defined and the inference is always sound and complete with respect to that model.At the same time, the data representing situations must be structured and compliant with such model, requiring significant effort.</p>
<p>Neural Network models are a solution to both obtaining an approximate classification, and being able to inject any type of data (images, text, etc.), not only structured data.Nevertheless, they may need a large sample including both descriptions and situations, and the results may be incompatible with the formal model, for example it might happen that only some of the plausible descriptions are retrieved.In short, logic reasoning lacks inconsistency and partial-data-tolerant deductions, while neural network models lack the completeness of deductive inference.</p>
<p>Neuro-symbolic methods, such as [Manhaeve et al., 2018;Geh et al., 2023;van Krieken et al., 2022], combine important benefits of logic-based and approximate reasoning, and (very important) they can ingest unstructured data.Nevertheless, they rely on the same consistency assumption, which is undesirable in a perspective-reasoning scenario.</p>
<p>The approach proposed in this research (sandra) relies on the neuro-symbolic paradigm but addresses this issue.It formalizes and implements the inference of the satisfies relation between situations and descriptions and, at the same time, it provides a probability score and a deductive, interpretable inference.</p>
<p>It includes: (i) a theoretical framework formalizing DnS in a differentiable and probabilistic fashion, which we prove to be correct with respect to DnS.It creates a vector space V isomorphic to a DnS-based ontology (defining a set of descriptions); (ii) the implementation of a neuro-symbolic architecture, where the neural network is constrained to position any detected situation (from any source type) in one or more subspaces of V , each corresponding to a description defined in the ontology.The intuition is that this constraint makes the network less prone to noise.Our formulation allows efficient inference in the DnS domain.Our hypothesis is that by constraining the representation learning process to a DnS-based ontology we can perform perspective-based reasoning without performance loss or increase of computational complexity.</p>
<p>To evaluate our hypothesis we experiment our method on two different tasks: visual reasoning on the I-RAVEN benchmark [Hu et al., 2021] and domain generalization on Fashion-MNIST [Xiao et al., 2017].For each task, we asses the influence of adding sandra to a standard baseline model and find increased performances with polynomial complexity1 .</p>
<p>Our contribution can be summarized as follows: 1.A correct differentiable probabilistic formalization of DnS; 2. A neuro-symbolic reasoner that combines deductive and inductive reasoning to classify arbitrary situations extracted by a neural network into the descriptions (perspectives) that can plausibly interpret them.</p>
<p>The rest of the paper provides a formalization of DnS (Section 2) and of our method (Section 3).Section 4 describes our experiments and results, which are further discussed, along with future work in Section 5. Section 6 discusses relevant related work, while Section 7 concludes the paper.</p>
<p>Descriptions &amp; Situations</p>
<p>In DnS, descriptions and situations are n-ary relations.We refer to the arguments of a description as roles, and to those of a situation as entities.For example, in Figure 1, Business, Consumer, and Item are the roles of the Commerce buy description, while ENCOM, Bob, and Laptop are the entities of the situation s 1 .A situation s satisfies a description d, if each entity of s can be classified by one role of d2 .</p>
<p>A formalization of DnS in First Order Logic is given in [Gangemi and Mika, 2003].We extend it to allow roles as n-ary relations and provide here the resulting formal semantics.With O a DnS-based ontology, we define D as the set of descriptions in the ontology, with R the set of roles and E the set of entities and assume that D
∪ R ∪ E ⊂ O. Definition 1. A description d is a set d = {r 1 , • • • , r n } ∈ D with r i ∈ R ∪ (D − {d}).
In Figure 2, Refund = {Consumer, Business, Item} ∈ D. Notice that descriptions can be used as roles as well.</p>
<p>For instance, Customer care policy = {Commerce buy, Refund, Reason} ∈ D, where Commerce buy, Refund ∈ D.
Definition 2. A situation s is a set s = (e 1 , • • • , e n ) ∈ S with e i ∈ D ∪ R ∪ E ∪ S.
For example, the set {Bob, ENCOM, Laptop} of Figure 2 is a situation.</p>
<p>A situation can also involve other situations as its entities.For example, in Figure 2 In Figure 2 the situation s = {Bob, ENCOM, Laptop} satisfies the descriptions Commerce buy and Contest winning.Both descriptions are perspectives from which s can be interpreted.</p>
<p>Assuming that O asserts that Consumer, Business ⊆ Agent (i.e.Agent is a broader role than Consumer and Business), we have that Commercial transaction |= s as well, since the two roles are also Agents.
Corollary 1. Given d, d ′ ∈ D with d ′ ⊆ d and s ∈ S then d ′ |= s ⇒ d |= s.
Corollary 1 trivially follows from definition 3. Definition 3 states the condition such that a perspective is valid for a situation.However, a description can be a plausible perspective for a situation even if only some of its roles are fulfilled.In this case, we say that a description nearly satisfies a situation, written as d |=s.Definition 4 (near-satisfaction).With d ∈ D and s ∈ S,
d |=s ⇔ ∃r ∈ d.(∃e ∈ s.e ∈ r) ∨ (∃s ′ ∈ s.r |= s ′ )
From Definition 4 it follows that if a situation satisfies a description, then it also nearly-satisfies it.The corollary trivially follows from Definitions 3 and 4.</p>
<p>Method</p>
<p>With reference to Section 2 we define a vector space V over the field R with dim(V ) = |R ∪ D|.For each description d ∈ D a subspace V d is identified by its roles.Assuming that v s is a vector representing s ∈ S and that d |= s with d ∈ D, the intuition following from Definition 3 (and 4) is that v s must be defined by (some) entities classified by the roles in D that identify the subspace V d .</p>
<p>In this section, we describe how a subspace V d is defined and how to deduce when a description is (nearly-)satisfied by a situation.Notation-wise, we assume that s ∈ S and for some d ∈ D, V d is the subspace associated with d and B d is a spanning set of V d .Subspace definition The set B d , defined as
B d = {b 1 , • • • , b n } is a(f d ). Given x ∈ D ∪ R, f d : D ∪ R → V is defined as f d (x) = ϕ(x) + 1 [x∈D] r∈x f d (r) where ϕ(x) = [1 [x⊆y1] || • • • ||1 [x⊆yn] ] with y 1 , • • • , y n ∈ R∪ D and n = |D ∪ R|.
The function ϕ(x) considers D ∪ R as an ordered set with n = |D ∪ R| elements.It creates a vector of dimension n where the i th element is 1 if x is equal or a subset of the i th element in D ∪ R. For example, consider
D ∪ R = {Agent, Item, Consumer, • • • } with |D ∪ R| = 10 and Consumer ⊆ Agent as in Figure 2. Then f d (Agent) = ϕ(a) = [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], f d (Consumer) = ϕ(d) = [1, 0, 1, 0, 0, 0, 0, 0, 0, 0] and f d (Commercial transaction) = ϕ(Agent) + ϕ(Item) = [1, 1, 0, 0, 0, 0, 0, 0, 0, 0]. Theorem 1. Given a description d ∈ D, the vectors in B = {f d (r 1 ), • • • , f d (r n )} with r 1 , • • • , r n ∈ d are linearly independent.
Proof.Without loss of generality, assume that O is converted to a Directed Acyclic Graph (DAG) where edges connect descriptions to their roles.Consider
α 1 f d (x 1 )+• • •+α n f d (x n ) with x 1 ̸ = • • • ̸ = x n ∈ R ∪ D and α 1 , • • • , α n ∈ R. Each term α i f d (x i ) = r∈Xi α i ϕ(r)
where X i is the union of x i \ D and of the roles recursively collected from the nested descriptions in x i .Since ϕ is positive-definite and injective (∃x.ϕ
(x) = a ̸ = b = ϕ(x) → ∃ŷ.1 [x⊆ŷ] ̸ = 1 [x⊆ŷ] → ⊥) then α 1 f d (x 1 )+• • •+α n f d (x n ) = 0 ⇔ α 1 = • • • = α n = 0. Thus, f d (x 1 ), • • • , f d (x n ) are linearly independent.
By taking B d as the spanning set of V d , it forms a basis of the subspace associated with the description d.It will be possible to represent a situation s that satisfy d as a linear combination of the vectors in B d .Situation encoding Given the definition of the subspace V d , the intuition is that its vectors are those representing all the situations s such that d |= s.To obtain v s ∈ V , the vector representation of s, we introduce the function f s , which maps a situation s ∈ S into a vector.
Definition 6 (B d and V d ). Given a description d ∈ D, V has a subspace V d spanned by the basis B d = {f d (r 1 ), • • • , f d (r n )} with r 1 , • • • , r n ∈ d.
Definition 7. Given s ∈ S, e ∈ E and r ∈ R, and with ψ : E → R defined such that e ∈ r ⇒ ψ(e) = r, the function
f s : S → V is defined as f s (s) = e∈s f s (e) if e ∈ S f d (ψ(e)) otherwise
The function ψ can be implemented by a deductive reasoner (e.g.[Glimm et al., 2014]) or provided externally.</p>
<p>The vector v s produced by the function f s is the aggregation of the vector representation of the roles that classifies the entities in s and its nested situations.Nested situations are recursively converted into a vector using the same function f s .For example from Figure 2 Item).Note that from Definition 5 it follows that f s is a positive definite function, i.e. f s (x) ≥ 0 ∀s ∈ S, since ϕ is positive definite.We model the satisfaction of a description as a multinomial probability distribution, hence the probability that s satisfies d is
, f s ({Bob, ENCOM, Laptop}) = f d (Consumer) + f d (Business) + f d (</p>
<p>Description satisfaction
p(d |= s) = |d| i=0 1 [&gt;0] (x) i |d|(1)
Definition 8. Given d ∈ D, s ∈ S we say that s nearlysatisfies d with probability p, written as
d |= ps, if p(d |= s) = p.
Given Definition 8, we can now state Theorem 3, which generalizes Theorem 2 to nearly-satisfied descriptions according to Definition 4.
Theorem 3. With s ∈ S, d ∈ D then (i) d |= ps ⇒ d |=s with p = p(d |= s) &gt; 0; (ii) d |= 1 s ⇒ d |= s; (iii) d |= 0 s ⇒ d ̸ |= s.
Proof.(i) d |= ps then, according to Definition 8, there is some r ∈ d such that, given the coefficient i that corresponds to r in x, (x) i &gt; 0. Hence v s is a linear combination of f d (r).Similarly to proof of Theorem 2, given Definition 7 it can be proven that exists e ∈ s with e ∈ r.Thus, from Definition 4, d |=s.Theorem 3 enables a crucial property of our formalization: to infer to which degree a description is satisfied by a situation, while retaining correctness with respect to Definitions 3 (satisfaction) and 4 (near-satisfaction).
(ii) d |= 1 s then |d| i=0 1 [&gt;0] (x) i = 1 and v s is linear combi- nation of
dP-sandra (Differentiable P-sandra) By virtue of Theorem 3, the process of deducing which descriptions are satisfied (or nearly-satisfied) by a situation is a function
H : V → R |D| , with H(s) = [p(d 1 |= s)∥ • • • ∥p(d n |= s)] (2) with d 1 , • • • , d n ∈ D.
H is differentiable with respect to the input vector v s (it is composition of differentiable functions) and in particular
∇H = [δ(v s )∥ • • • ∥δ(v s ))] where δ is Dirac's delta and d 1 , • • • , d n ∈ D.
Due to the use of the Heaviside function, the gradient is zero everywhere except for the descriptions with probability zero, since δ(x) = 0 ∀x ̸ = 0.This prevents an effective use of H in Machine Learning methods that rely on gradients to learn the model's parameters, such as in Deep Learning, where the back-propagation algorithm is used [Le-Cun et al., 2015].</p>
<p>To overcome this issue, we replace the Heaviside function 1 [&gt;0] (x) with the ReLU function [Glorot et al., 2011].We argue, without any loss in generality, that the behaviour of the ReLU function is comparable to the Heaviside function in our setting, since ReLU (x) &gt; 0 ⇔ x &gt; 0. Indeed, we can interpret the ReLU function as a smooth version of 1 &gt;0 (x).Other functions could be used for the same purpose, such as continuous approximations of the Heaviside function, tanh, logistic function etc.In this case, we rely on ReLU since empirically it suffers less from the exploding/vanishing gradient problem.Nonetheless, we will perform a systematic assessment of other functions in the future, as different functions might lead to different useful properties.</p>
<p>Neuro-symbolic integration</p>
<p>Since dP-sandra is differentiable with respect to its input vector, it can be used as a standard neural network layer.We define the function H by replacing the Heaviside function in H (as defined in Equation 2) with the ReLU function.The function H allows a seamless integration of a DnS-based ontology O within any arbitrary neural network N N .</p>
<p>The N N approximates the function f s from a nonstructured source.Consider x the output of a neural network, for instance the features extracted by a Convolutional Neural Network (CNN) from an image or the embedding of a sentence computed by a Transformer, then the N N approximates the result of f s (x) as if x was created from a structured source.</p>
<p>Hence, we can check if the situation represented by x satisfies d by relying on Definition 1.Moreover, since H is fully differentiable with respect to its input, it is possible to define an objective function that optimizes the output of the N N such that the representation learned for x lies in V d as if it was produced by f s .</p>
<p>We highlight that our experiments (c.f.Section 4) show that the representation learned by N N (a vector x originating from any source) approximates the vector representation of a situation s manually curated for modeling or representing that source, such as in a Knowledge Graph.This provides us with a means to interpret the intermediate output of the N N , and better understand its internal representation, without influencing the process to solve the down-stream task.For ex-ample, given the image of a lung X-ray, sandra infers all the possible diagnoses without compromising the freedom of the model to formulate the final prediction.</p>
<p>Experiments</p>
<p>We experiment the integration of dP-sandra in different neural network architectures.Our goal is to assess whether sandra allows to perform perspective-based reasoning without any performance loss or increase in computational complexity, as hyphotesized in Section 1.We test our method on two benchmarks: I-RAVEN [Hu et al., 2021], a visual reasoning task, and RotatedFashionMNIST, a domain generalisation task based on FashionMNIST [Xiao et al., 2017].The choice of the tasks is motivated by the suitability of the data to be modeled according to DnS with a reasonable effort.All the experiments have been trained with the AdamW optimizer on a NVIDIA RTX3090 with 24Gb of RAM.</p>
<p>Visual Reasoning</p>
<p>The I-RAVEN dataset, based on Raven Progressive Matrices (RPMs) is a repository of images for visual reasoning tasks, designed to examine abstract reasoning capabilities in neural networks [Hu et al., 2021].An RPM is a 3 × 3 grid of images where the last image has been removed.The task is to predict the removed image among 8 possible alternatives [Małkiński and Mańdziuk, 2022].Each image might be composed of multiple (nested) figures, which are simple geometric shapes where the color, size and rotation are varied [Hu et al., 2021].Recent approaches frame the task as a classification problem and tailor the model to the RPM problem.This has been done by structuring the models such that the relationship between the images is captured [Santoro et al., 2017;Barrett et al., 2018;Zhang et al., 2019a;He et al., 2023] or by reasoning upon the extracted visual features through neuro-symbolic methods [Xu et al., 2023;Hersche et al., 2023].Our approach extends the baseline model proposed by [Zhang et al., 2019a] with sandra.The baseline model is composed by an LSTM that combines the visual features extracted by a CNN on each image.Details on the architecture are in the Appendix 3 .We integrate sandra within the baseline model by adding a linear layer W that projects the representation obtained by the CNN in the vector space V .W is meant to approximate the function f s .</p>
<p>Given an image within an RPM, s R is the situation extracted from the XML provided by the dataset accordingly to Definition 1 (c.f.Appendix for details on the extraction process) and x the vector representing the visual features of the image extracted by the CNN.We approximate f s (s R ) by minimizing the binary cross entropy
L BCE ( Ĥ(f s (s)), Ĥ(ReLU (W x))(3)
where H is computed as explained in Section 3.1.Our model classifies an image using linear regression on x∥ Ĥ(ReLU (W x)).The loss function is hence
L = L CE + L BCE ( Ĥ(ReLU (W x)), H(f s (s)))(4)
3 Included in the additional material.where L CE is the cross-entropy loss as defined in [Zhang et al., 2019a].</p>
<p>Our approach radically differs from the others since, by relying on sandra, the visual features extracted from an image are geometrically constrained such that it is possible to infer valid descriptions from them.The model learns to accurately classify an image, while capturing the semantics of the ontology in its internal representation.The influence of sandra is a regularization with respect to a DnS-based ontology.We manually compile a DnS-based ontology (detailed in Appendix) that models the RAVEN dataset.Each image is then converted into a situation compliant to the ontology.Relying on sandra allows the inference of which shapes are contained within a figure.A comparison of sandra with the baseline is shown in Table 1a, we report the of number of parameters of the network (first column) and accuracy (the other columns) of the classification.Each model has been trained using a batch size of 32, a learning rate of 0.001 and the gradient is clipped to have a norm ≤ 0.5.The results show that integrating sandra does not compromise performances (improving them in some cases) nor it requires a significant increase in the number of parameters.We also compare sandra with other approaches tailored for this task and for the sake of space, the comparison is reported in the Appendix.We remark that, despite its generality, our method is competitive with other methods4 .</p>
<p>Domain Generalization</p>
<p>The domain generalization task aims at testing how a model is able to learn representations that are independent of a specific domain, i.e. they are effective on distributions never seen during the training process [Zhou et al., 2022].This includes, for example, correctly classifying images seen from a different angle than the one in the training set.Many approaches have been investigated, from learning representations that specifically tackles the problem [Mahajan et al., 2021], to different training techniques [Vedantam et al., 2021].A wide selection of architectures and techniques is analysed in [Zhou et al., 2023].Similarly to [Mahajan et al., 2021], we rely on the Rotated-FashionMNIST (R-FMNIST) dataset.R-FMNIST is an image classification task where the training images are rotated in three configurations: The first image has a high probability of satisfying the FootWear description, which is reasonable considering the target label.In the second image, we can understand that the wrong classification is associated with the similar probability given to the LowerBodyClothes and UpperBodyClothes descriptions, leading to an unreliable result.are rotated by {0 • , 90 • }.
A = {30 • , 45 • }, B ≡ A ∪ {60 • }, C ≡ B ∪ {15 • , 75 • }. The testing set images
The final prediction is computed using linear regression over the features extracted by a CNN or a MLP.The architectures are described in the Appendix.We manually create a DnS-based ontology, detailed in the Appendix, that models the dataset.Table 1b describes the results in terms of number of parameters of the network (in the caption) and accuracy of the classification.Each model has been trained with a batch size of 32 and a fixed learning rate of 1e −4 .The use of sandra proves to be beneficial also in this experiment even though the images of R-FMNIST are only described with a single label, leading to a fairly simple ontology.</p>
<p>These experiments allow us to empirically show the sandra improves the interpretability of the model and of its results, as addressed in Section 3. Figure 3 shows the effect of sandra in the interpretation of two images, one correctly labeled and one misclassified.By looking at the inferred descriptions, it is possible to interpret the motivation of the mistake.</p>
<p>Discussion and Future Works</p>
<p>Sandra approaches the problem of reasoning on different persepectives by formalizing DnS in a vector space.Through the formulation described in Section 3 it is possible to infer the descriptions satisfied by a situation.Most importantly, it is possible to quantify the degree of satisfiability as a probability distribution, enabling the inference of valid interpretations of a situation regardless of their compatibility and of the amount of information available.This is an important aspect that finds application in many domains where rigorous reasoning with limited information is a key requirement such as robotics, medicine or jurisprudence.We discuss some limitations and interesting aspects that are worth further investigation.DnS-shape Compatibility Sandra's dependency on DnS ontologies, which underpins V , presents a non-trivial limitation.This is relevant if one wants to integrate it with ontologies using different (if any) ODP.However, we argue that it is possible to find an isomorphism between any arbitrary ontology and a DnS ontology.Informally, we can use reification.Each binary predicate (property) p can become a class expressing a n-ary relation, whose arguments are its domain and range.Any axiom involving the property p can be reified as a description including p as role.When reversed -as expected -this transformation may be backward inconsistent, since the inferred satisfied descriptions may correspond to disjoint classes in the original ontology.We will explore how to formally define such isomorphic transformation, alongside its properties and limitations.Another consideration is that the existence of an ontology compatible with DnS does not always guarantee improved performance.We need further research to identify the most effective DnS transformation patterns for integration with sandra.We plan to study sandra's behavior with other ontologies, particularly with complex ones, to find correlations between ontology design solutions and sandra's performance.Ontology Complexity and Scalability Another issue is the inherent computational complexity.The function f s is linear in space with the dimension of the ontology.While this might seem an ideal condition, as the ontology gets more complex (e.g.thousands of descriptions) this might result in a large overhead, especially if f s is approximated through a neural network.Further research is required to identify if it is possible to obtain more compact representations, for instance by exploiting the hierarchical structure of the ontology or by exploring methods that pre-process the ontology removing nonessential elements.Methodological Improvements The definitions of f d and f s might be improved to obtain additional useful properties.For instance, our current method overlooks a procedure to retrieve the original situation s from f s .This precludes useful outcomes, such as uniquely identifying which entity of s has been classified by which role in d.An interesting approach is to extend the method of Section 3 to some parts of Description Logic as well.In that case, it might be possible to benefit from additional features that have been formalized in the ontology but that are unexploited since they are missing in the DnS pattern.Neurosymbolic integration The results of Section 4 provide a positive insight on how sandra can be beneficial to neural architectures.Nonetheless, the variance in performance gains between different tasks requires a systematic analysis, in order to better understand which kind of architectures can benefit the most from sandra and how they should be integrated.Investigating the ODPs that lead to increased performances is an important step towards tighter integration be-tween Machine Learning (ML) and Knowledge Representation (KR).Notably, this aspect has the potential to catalyse a novel paradigm in the realm of KR, since different ML techniques might behave differently with different ontologies.</p>
<p>Related Works</p>
<p>The idea of using geometric representation for cognitive theory was originally proposed by Peter Gärdenfors [2004] as an intermediate representation layer between sub-symbolic and symbolic knowledge.A conceptual space depicts concepts as convex regions.Each region is shaped by the attributes that characterise that concept.Our method follows the intuition of conceptual spaces.Two main problems on conceptual spaces are highlighted by [Bouraoui et al., 2022].One is the derivation of region-based representations for concepts that is difficult when data comes from real-world scenarios; another issue is that the representations in conceptual spaces are not amenable to expressing relational knowledge.Given the integration of a neural network as a situation approximator, as proposed in Section 3.1, and the DnS formalization ( Section 2), our method overcomes both limitations.Other approaches that implement conceptual spaces, such as [Bouraoui et al., 2022], propose to interpret embeddings as conceptual spaces.Others approximate ontologies based on their graph representation or rely on specific neural architectures, like Logic Tensor Networks to obtain deductive inferences [Chen et al., 2021;Ebrahimi et al., 2021].Differently to these approaches, our representation is not an approximation of the ontology.The ontology is used to obtain a vector space in which concepts are represented.This is similar to the approach described in [ Özc ¸ep et al., 2020], where geometrical properties are exploited to obtain sound knowledge representation methods.</p>
<p>Other related approaches integrate symbolic representations in geometrical spaces to support reasoning such as in [Geh et al., 2023] where the authors complement Answer Set Programming with neural networks; in [Manhaeve et al., 2018] ProbLog is extended to the use of neural predicates; and [van Krieken et al., 2022] implements approximate logical inference.These approaches are inherently dependent on probabilistic logic, suffering from a lack of inconsistency tolerance.</p>
<p>Conclusion</p>
<p>We contribute a novel neuro-symbolic approach named sandra to address perspective-based reasoning based on the DnS ontology design pattern.Our experiments show that sandra brings benefits to the representation learning process without loss of performances or increase in computational complexity.</p>
<p>Each RPM configurations is modeled as a situation.The situation is compiled starting from the original XML generated alongside the images, which contains structured information on the RPM such as the specific composition of each panel.</p>
<p>We use SPARQL Anything [Asprino et al., 2022] to interpret and transform the XML data into situations, serialized in RDF using Turtle notation [Beckett et al., 2014].SPARQL Anything is a querying tool for Semantic Web reengineering.It allows users to query several data formats with the SPARQL query language.Through the use of the CONSTRUCT clause it is possible to compile a Knowledge Graph from the data formats supported by it.</p>
<p>The complexity of the ontology accommodates various meta-levels of deductions pertaining to different situations.For example, according to the above description, we add the axiom rv:hasComponent some rv: The I-RAVEN ontology models a description by declaring universal restrictions on the classes representing a role.This is done through the use of the rdfs:subClassOf predicate.For instance, rv:FT5 rdfs:subClassOf some rv:T5, which translates to (rv:FT5) ⊑ ∀(rdfs:subClassOf).(rv:T5) in Description Logic.In total, the ontology contains 144 classes (|D ∪ R| = 144).Table 5 provides a detailed description of all the descriptions and roles in the ontology.</p>
<p>Model Architecture</p>
<p>The model's architecture used for the visual reasoning experiments is a straightforward CNN followed by a single-layer LSTM.The last hidden state of the LSTM is used to perform the classification using a linear classification head.The architecture is described in detail in Table 2 Comparison with state of the art models In Table 6 a comparison of the results of Section 4 with recent works is reported.An estimate of the number of parameters is also described.Sandra performs better than the baseline but is outperformed by the other approaches.We remark that the other approaches are optimized to solve the I-RAVEN task and, differently to the baseline and to our method, they implement an architecture that considers all the nuances of the task (e.g.explicitly modeling panels on the same row).As already mentioned, outperforming specific solutions to the I-RAVEN task is out of scope of our research, rather we want to demonstrate that sandra is a competitive generalized reasoner, which is supported by its performance results against the baseline.</p>
<p>A.2 Domain Generalisation</p>
<p>In this section we describe the ontology developed for Fash-ionMNIST (Section A.2) and the architectures used for the experiments (Section A.2.The code to reproduce the experiments is available at https://anonymous.4open.science/r/sandra-fashionmnist-EEF0/. The original Fashion-MNIST dataset provides 10 labels, one per each type of clothes: T-shirt/top, Trousers, Pullover, Dress, Coat, Sandal, Shirt, Sneaker, Bag, and Ankle boot.No further semantics is provided about the entities, therefore the ontology developed for FashionMNIST is a straightforward representation modeled after intuitive and common-sense features of the clothes represented in the dataset.</p>
<p>Fashion-MNIST ontology</p>
<p>We re-engineer the Fashion-MNIST dataset to represent its intensional layer.The 10 types of clothes are represented as rdfs:subClassOf four top classes: :FootWear, :LowerBodyClothes, :UpperBodyClothes, and :Accessories.The semantics is introduced in the ontology via several object properties, listed in Table 7.</p>
<p>For example, the description :Pullover ∈ D has roles :LongSleeves, :Neckhole ∈ R and it is expressed as a subclass of :UpperBodyClothes ∈ D.</p>
<p>Model's architecture</p>
<p>For the domain generalisation experiments two baseline architectures have been used: a straightforward CNN followed by a linear classification head, described in</p>
<p>Figure 1 :
1
Figure 1: Example of two descriptions (Commerce buy and Contest winning) that are satisfied by a situation that involves the entities Bob, ENCOM, Laptop.The two descriptions define the same roles, hence they provide two different perspectives from which the situation can be interpreted.</p>
<p>Figure 2 :
2
Figure 2: Examples of some descriptions and situations alongside the conversion of a situation into V to detect the satisfied descriptions.The process of deducing which descriptions are satisfied by fs is shown on the right.</p>
<p>Corollary 2 .
2
With d ∈ D and s ∈ S, d |= s ⇒ d |=s</p>
<p>basis for the subspace V d , i.e. the vectors in B d form a minimal spanning set of V d .Hence every v ∈ V d can be expressed as a linear combination (a weighted sum) of the vectors in B d [Meyer and Stewart, 2023].Given Definitions 3 and 4, it follows that the vectors in B d must originate from the description d and its roles r ∈ d.We define f d as the function that converts each description d ∈ D to a vector f d (d) ∈ B d .Informally, f d (d) is obtained by recursively aggregating the vector representations v r of the roles r ∈ d.A function ϕ computes v r ensuring that f d (d) ∈ B d and that v r reflects subsumption relations between roles.Definition 5</p>
<p>It follows from Definition 5 that for any d ∈ D, B d can be computed in polynomial time O(|D| 2 ).The proof follows from Definition 5: by converting O to a DAG, for each description we have to loop through every other description in the worst case.</p>
<p>Given Theorem 1 and function f s , we can check whether the vector representation v s lies in the subspace V d by checking whether v s is linear combination of the vectors in B d .Consider A d as the |R ∪ D| × |d| matrix whose row-space is B d (i.e. the rows are formed by the vectors b ∈ B d ).The solution x to the linear system A d x = v s contains the coefficients to obtain the vector v s as the linear combination of the vectors b ∈ B d .With A + d the Moore-Penrose pseudo-inverse of A d , the unique solution x = A + d v s always exists, since the rows of A d are linearly independent by definition [Meyer and Stewart, 2023].If x i ̸ = 0 for all x i ∈ x then v s is linear combination of the vectors in B d meaning that v s ∈ V d .Since B d is directly defined after the roles of d (Definition 5), then the roles each role in d must classify an entity in s.Based on this, we define how to deduce the descriptions satisfied by s according to Definition 3. Theorem 2. Given s ∈ S, d ∈ D, and v s = f s (s) we have that d |= s ⇔ v s ∈ V d Proof.With d |= s, then ∀r ∈ d ∃e ∈ s.ψ(e) = r (i.e.exists an e ∈ s classified by r for all r ∈ d).If e ∈ S, then r ∈ D and r |= e.Given Definition 7 (f s ), v s = f s (s) is obtained by aggregating the encoding of the roles that classify the individuals of s.Hence v s ∈ V d , since it is linear combination of B d by construction.Thus, d |= s ⇒ v s ∈ V d .To prove that v s ∈ V d ⇒ d |= s, assume that v s ∈ V d .Hence, v s is linear combination of B d .Given Definition 7, ∀r ∈ d ∃e ∈ s. ψ(e) ∈ r ∨ r |= e.It follows from Definition 3 (description satisfaction) that d |= s.Thus, d |= s ⇔ f s (s) ∈ V d .P-sandra (Probabilistic sandra) According to Theorem 2 each element of the vector x (with x = A + d v s ) indicates the presence (or absence) of an entity e ∈ s with e ∈ r and r ∈ d.By applying the Heaviside function 1 [&gt;0] to x we can interpret it as a boolean vector.</p>
<p>the vector representation of all the roles r ∈ d.Thus, d |= s follows from Theorem 2. (iii) d |= 0 s then |d| i=0 1 [&gt;0] (x) i = 0 and v s can not be expressed as a linear combination of any of the vector representation of the roles r ∈ d.Thus, d ̸ |= s follows from Theorem 2.</p>
<p>Figure 3 :
3
Figure 3: Example of two images and the descriptions they satisfy.The first image has a high probability of satisfying the FootWear description, which is reasonable considering the target label.In the second image, we can understand that the wrong classification is associated with the similar probability given to the LowerBodyClothes and UpperBodyClothes descriptions, leading to an unreliable result.</p>
<p>Figure to the rv:Panel class.This results in Panel being a description (rv:Panel ∈ D) that includes the description rv:Figure (rv:Figure ∈ D and rv:Figure ∈ rv:Panel).:Figure is modeled as a description which includes the roles :Angle, :Color and :Size.In order to model the semantics within the I-RAVEN dataset and to allow for better understanding of the data, we model the combinatorial permutation of figures within panels as descriptions as well.For instance, a figure containing a circle satisfies the description rv:FT5 ∈ D, with rv:T5 ∈ rv:FT5.The role rv:T5 ∈ R is instantiated in a situation if the situation (i.e. the figure) contains a circle.</p>
<p>D Sequence of 3 panels on a row rv:hasPanel some rv:Panel rv:Panel D Represents each of the 9 panels in an RPM (16 if considering the 8 alternatives to choose from) as shown in Figure 4 rv:hasNumberValue some rv:Number, rv:hasComponent some rv:Figure Classes of the form rv:PFXY where X ∈ {rv:A, rv:C, rv:S, rv:T} and Y depends on X.For example, rv:A refers to the angle with X ∈ {0, 1, 2, 3, 4, 5, 6, 7}.D Implements the possible permutations of elements composing and qualifying the panel rv:hasComponent some rv:PXY rv:Figure D Represents each figure in each panel.As shown in Figure 4 a figure can vary for several dimensions (color, shape, etc.) rv:hasAngle some rv:Angle, rv:hasColor some rv:Color, rv:hasShape some rv:Shape, rv:hasSize some rv:Size rv:Number R Represents the number of the panel in the RPM.rv:Color R Represents the color of a figure.There are 10 possible color variations, expressed via 10 subclasses of the rv:Color class.rv:Shape R Represents the shape of a figure.There are 5 possible shapes, modeled as subclasses: rv:Triangle, rv:Square, rv:Pentagon, rv:Hexagon, and rv:Circle.rv:Angle R Represents the angle orientation of a figure.There are 8 possible orientations, expressed as subclasses of the rv:Angle class.rv:Size R Represents the size of a figure.There are 6 possible sizes, expressed as subclasses of the rv:Size class.</p>
<p>Alice bought a Laptop from ENCOM, ENCOM received it back from Alice and a Battery-Defect reason is specified.Both Alice buying and ENCOM receiving the Laptop are two separate situations that are part of another situation, which also involves BatteryDefect.When a description d explains a situation s, we say that s satisfies d, written as d |= s.
, the sets = {{ENCOM, Alice, Laptop},{Alice, ENCOM, Laptop},{BatteryDefect}}represents a situation in which Definition 3 (satisfaction). With d ∈ D and s ∈ Sd |= s ⇔ ∀r ∈ d.(∃e ∈ s.e ∈ r) ∨ (∃s ′ ∈ s.r |= s ′ )</p>
<p>Table 1 :
1
Results on the accuracy in R-FMNIST benchmark.The parameters in the CNN are 30k and 85.6k using sandra while 268.7k and 278k using sandra in the MLP.Experimental results.
ModelABC#ParamsC2×23×3 O-IC O-IGL-RU-DCNN16.02 17.21 43.13Baseline205k26.85 14.55 12.15 12.313.4 11.85 13.15sandra 15.74 18.62 52.49sandra275k45.75 16.15 14.114.8 14.85 13.05 13.15MLP14.56 16.64 31.34sandra 16.96 18.11 32.88(b)
(a) Results on the accuracy in the I-RAVEN dataset.Number of parameters of the baseline (first column) is compared with the addition of sandra.The remaining columns refer to the specific configuration of the I-RAVEN dataset (number of shapes and their position).</p>
<p>Table 2 :
2
. 3x3 conv., 16 filters, 2 stride, BN, ReLU 3x3 conv., 16 filters, 2 stride, BN, ReLU 3x3 conv., 16 filters, 2 stride, BN, ReLU 3x3 conv., 16 filters, 2 stride, BN, ReLU Linear layer for projection in sandra's V Architecture used for the experiments in the I-RAVEN dataset.
LSTM, 1 layer, 128 hidden dimensionLinear layerTotal of 205 K parametersTotal of 275 K parameters with sandra</p>
<p>Table 3
3, and an</p>
<p>Table 3 :
3
CNN architecture used for the experiments in the Rotated-FashionMNIST dataset.Linear layer, 256 hidden dimension, ReLU Linear layer, 256 hidden dimension, ReLU Linear layer for projection in sandra's V Linear layer Total of 268.7 K parameters Total of 278 K parameters with sandra</p>
<p>Table 4 :
4
MLP architecture used for the experiments in the Rotated-FashionMNIST dataset.</p>
<p>Table 5 :
5
Detailed description of each class in the I-RAVEN ontology.The Set column describes the type of each description, the purpose comments on the class while the axiomatisation is reported using Manchester syntax[Horridge and Patel-Schneider, 2009].</p>
<h1>ParamsC2×23×3 O-IC O-IGL-RU-DBaseline [Zhang et al., 2019a]205k26.85 14.55 12.15 12.313.4 11.85 13.15WReN [Santoro et al., 2018]&gt; 1.5M29.426.823.522.521.521.921.4ResNet [Zhang et al., 2019a]&gt; 25M44.729.327.946.235.851.247.4ResNet + DRT [Zhang et al., 2019a]&gt; 25M46.528.827.34634.250.149.8LEN [Zheng et al., 2019]&gt; 5M56.431.729.752.131.744.144.2CoPINet [Zhang et al., 2019b]&gt; 5M54.436.831.952.242.851.952.5DCNet [Zhuo and Kankanhalli, 2021]&gt; 5M57.834.135.55742.958.560NCD [Zhuo et al., 2021]&gt; 11M6031.23062.43958.957.2SRAN [Hu et al., 2021]&gt; 33M78.250.142.468.246.370.170.3PrAE [Zhang et al., 2021]  †&gt; 150k90.5 85.35 45.60 74.799.799.597.4ConViT [He et al., 2023]&gt; 5M99.996.275.599.499.699.587.3[Hersche et al., 2023]  †&gt; 11M10099.597.110010010096.4Baseline + sandra275k45.75 16.15 14.114.8 14.85 13.05 13.15</h1>
<p>Table 6 :
6
Results on the accuracy in the I-RAVEN dataset.The number of parameters for related works is a rough estimation based on the architecture used -e.g.we assume that when using a ResNet18 the model will have at least 11M parameters.It serves as a comparison between the number of parameters of the implemented baseline and those on related works.Results are retrieved from the corresponding papers.Models with † include the use of external solvers, such as planning algorithms.
F-MNIST propertyPurposeManchester syntax axiom example:coversExpresses which part of the body is:Dress :covers somecovered by a piece of clothing, if any:WholeBody, :Sandal :coverssome :Feet:hasClosureExpresses the type of closure of the:Coat :hasClosure somepiece of clothing (e.g. zip, buttons,:ButtonClosurelaces, etc.), if any:hasShapeExpresses if the entity covers entirely:Sandal :hasShapethe body part or if it leaves some un-some :OpenShape,covered parts:Sneaker :hasShape some:ClosedShape:hasSleevesExpresses the entity's kind of sleeves,:Pullover :hasSleevesif anysome :LongSleeves,:T-shirt top :hasSleevessome :ShortSleeves:wearingContextExpresses the prototypical context in:AnkleBoot :wearingContextwhich a certain entity can be wornsome :FormalContext,:T-shirt top:wearingContext some:InformalContext:wearingPointExpresses the part of the body from:Coat :wearingPoint somewhich an item of clothing is first worn:SleevesHole,:Pullover:wearingPoint some:NeckHole</p>
<p>Table 7 :
7
Details of each property used to axiomatize each description in the ontology.Axioms examples can be seen in the Axiomatization column, written in Manchester syntax [Horridge and Patel-Schneider, 2009].</p>
<p>In time and space with respect to the number of entities within an ontology.
In the original formalization of DnS this is called maximal satisfaction. We capture all possible types of satisfaction although the terminology is simplified.
We remind that our primary goal is to test our hypothesis rather than solving the downstream task.
Available at https://github.com/husheng12345/SRAN/
AcknowledgmentsThis project has received funding from the FAIR -Future Artificial Intelligence Research foundation as part of the grant agreement MUR n. 341 and from the European Union's Horizon 2020 research and innovation programme under grant agreement No 101004746.AppendixThe Appendix provides the details omitted from the manuscript due to space limitations and the links to the implementations to reproduce the results.In Section A we explain in details the architectures and ontologies used in Section 4 (experiments).The python implementation of sandra is available at https://anonymous.4open.science/r/sandra-C3D3/.A ExperimentsThis section provides additional details on the experiments performed in Section 4. Section A.1 describes the model's architecture and the ontology used in Section 4.1.Section A.2 we describes the models' architectures and the ontology used in Section A.2.A.1 Visual ReasoningThe original I-RAVEN dataset includes three main types of entities: Matrices, Panels, andI-RAVEN ontologyWe reverse-engineer the I-RAVEN conceptual module to model the I-RAVEN intensional layer.We define the set of components that can appear in an image (see Figure4) based on the I-RAVEN official code 5 .We model a set of descriptions based on these components.
Knowledge graph construction with a fac ¸ade: A unified method to access heterogeneous data sources on the web. Asprino, ACM Trans. Internet Technol. 2022. 2022</p>
<p>Eric Prud'hommeaux, and Gavin Carothers. Rdf 1.1 turtle. World Wide Web Consortium. Barrett, A challenge for historical research: Making data fair using a collaborative ontology management environment. Carola Eschenbach, Michael, Boyan Brodaric and Femke Reitsma and Yi Qiang2018. 2018. 2014. 2014. 2021. jan 2021. 2022. 200812Semant. Web. SKIing with DOLCE : toward an e-Science knowledge infrastructure</p>
<p>Igor Cataneo Silveira, Denis Deratani Mauá, and Fabio Gagliardi Cozman. dpasp: A comprehensive differentiable probabilistic answer set programming environment for neurosymbolic learning and reasoning. Chen Gruninger, arXiv:2308.02944Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics, AISTATS 2011. Geoffrey J Gordon, David B Dunson, Miroslav Dudík, the Fourteenth International Conference on Artificial Intelligence and Statistics, AISTATS 2011Fort Lauderdale, USAJMLR.org2008. 2021. 2021. 2021. 2006. 2006. 2003. 2004. 2004. 2023. 2014. 2011. April 11-13, 2011. 2011183arXiv preprintJMLR Proceedings</p>
<p>Hierarchical convit with attention-based relational reasoner for visual analogical reasoning. He, Thirteenth Symposium on Educational Advances in Artificial Intelligence, EAAI 2023. Sheng Hu, Yuqing Ma, Xianglong Liu, Yanlu Wei, Shihao Bai, Washington, DC, USAAAAI Press2023. February 7-14, 2023. 2023. 2023. 2023. 2009. 2021. 20212023W3C Working Group NoteProceedings of the AAAI Conference on Artificial Intelligence</p>
<p>Małkiński and Mańdziuk, 2022] Mikołaj Małkiński and Jacek Mańdziuk. Deep learning methods for abstract visual reasoning: A survey on raven's progressive matrices. Norihiro Kamide, Kamide ; Lecun, arXiv:2201.12382Proceedings of the 14th International Conference on Agents and Artificial Intelligence, ICAART 2022. Robin Manhaeve, Sebastijan Dumancic, Angelika Kimmig, Thomas Demeester, Luc De, Raedt , the 14th International Conference on Agents and Artificial Intelligence, ICAART 2022Meyer and Stewart2022. February 3-5, 2022. 2022. 2015. 2015. 2021. 2021. 2022. 2018. 2018. 2023. 19743arXiv preprintAdvances in neural information processing systems. Matrix analysis and applied linear algebra. SIAM, 2023. [Minsky, 1974] Marvin Minsky. A framework for representing knowledge</p>
<p>Cone semantics for logics with negation. Özc ¸ep, Özgür Lütfü Özc ¸ep, Mena Leemhuis. 2020. 2020IJCAI</p>
<p>Robert Porzel and Vanja Sophie Cangalovic. What say you: An ontological representation of imperative meaning for human-robot interaction. Cangalovic Porzel, Joint Ontology Workshops. 2020. 2020</p>
<p>F-a model of events based on the foundational ontology dolce+dns ultralight. Santoro, Proceedings of the Fifth International Conference on Knowledge Capture, K-CAP '09. Ansgar Scherp, Thomas Franz, Carsten Saathoff, Steffen Staab, the Fifth International Conference on Knowledge Capture, K-CAP '09Stockholmsmässan, Stockholm, Sweden; New York, NY, USAAssociation for Computing Machinery2017. 2017. 2018. July 10-15, 2018. 2018. 200980Proceedings of the 35th International Conference on Machine Learning, ICML 2018</p>
<p>An empirical investigation of domain generalization with empirical risk minimizers. Van Krieken, arXiv:2212.12393Advances in Neural Information Processing Systems 34: Annual Conference on Neural Information Processing Systems 2021, NeurIPS 2021. Aurelio Marc, Alina Ranzato, Yann N Beygelzimer, Percy Dauphin, Jennifer Wortman Liang, Vaughan, Cambridge University Press2022. 2022. 2021. December 6-14, 2021. 2021. 2022arXiv preprintStudies in Natural Language Processing</p>
<p>Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms. Xiao , arXiv:2308.029442017. 2017arXiv preprint</p>
<p>Abstract visual reasoning: An algebraic approach for solving raven's progressive matrices. Xu, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern Recognition2023. 2023</p>
<p>RAVEN: A dataset for relational and analogical visual reasoning. Zhang, Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems 2019. M Hanna, Hugo Wallach, Alina Larochelle, Beygelzimer, Emily B Florence D'alché-Buc, Roman Fox, Garnett, Long Beach, CA, USA; NeurIPS; BC, Canada2019a. June 16-20, 2019. 2019. 2019b. 2019. December 8-14, 2019. 2019Vancouver</p>
<p>Abstract spatial-temporal reasoning via probabilistic abduction and execution. Zhang, Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems. M Hanna, Hugo Wallach, Alina Larochelle, Beygelzimer, Emily B Florence D'alché-Buc, Roman Fox, Garnett, NeurIPS; Vancouver, BC, CanadaComputer Vision Foundation / IEEE2021. June 19-25, 2021. 2021. 2019. 2019. 2019. December 8-14, 2019. 2019. 2022. 2022IEEE Transactions on Pattern Analysis and Machine Intelligence</p>
<p>Unsupervised abstract reasoning for raven's problem matrices. Zhou, 9th International Conference on Learning Representations, ICLR 2021, Virtual Event, Austria. 2023. 2023. May 3-7, 2021. OpenReview.net, 2021. 202145IEEE Trans. Image Process.</p>            </div>
        </div>

    </div>
</body>
</html>