<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-5391 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-5391</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-5391</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-110.html">extraction-schema-110</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models using self-reflection, self-critique, or iterative generate-then-reflect methods to improve answer quality, including details of the methods, tasks, performance with and without reflection, and any evidence of answer quality improvement or limitations.</div>
                <p><strong>Paper ID:</strong> paper-ced421275d05c28c241a5980ac4c8dd51b6103b6</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/ced421275d05c28c241a5980ac4c8dd51b6103b6" target="_blank">Self-improving algorithms</a></p>
                <p><strong>Paper Venue:</strong> ACM-SIAM Symposium on Discrete Algorithms</p>
                <p><strong>Paper TL;DR:</strong> This work investigates ways in which an algorithm can improve its expected performance by fine-tuning itself automatically with respect to an arbitrary, unknown input distribution, and gives self-improving algorithms for sorting and clustering.</p>
                <p><strong>Paper Abstract:</strong> We investigate ways in which an algorithm can improve its expected performance by fine-tuning itself automatically with respect to an arbitrary, unknown input distribution. We give such self-improving algorithms for sorting and clustering. The highlights of this work: (i) a sorting algorithm with optimal expected limiting running time; and (ii) a k-median algorithm over the Hamming cube with linear expected limiting running time. In all cases, the algorithm begins with a learning phase during which it adjusts itself to the input distribution (typically in a logarithmic number of rounds), followed by a stationary regime in which the algorithm settles to its optimized incarnation.</p>
                <p><strong>Cost:</strong> 0.007</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <p class="empty-note">No extracted data.</p>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <p class="empty-note">No potentially relevant new papers extracted.</p>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-5391",
    "paper_id": "paper-ced421275d05c28c241a5980ac4c8dd51b6103b6",
    "extraction_schema_id": "extraction-schema-110",
    "extracted_data": [],
    "potentially_relevant_new_papers": [],
    "cost": 0.00711175,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>SELF-IMPROVING ALGORITHMS*</h1>
<p>NIR AILON ${ }^{\dagger}$, BERNARD CHAZELLE ${ }^{\ddagger}$, KENNETH L. CLARKSON ${ }^{\S}$, DING LIU ${ }^{\ddagger}$,<br>WOLFGANG MULZER ${ }^{\text {, }}$, AND C. SESHADHRI ${ }^{\S}$</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<h2>Abstract</h2>
<p>We investigate ways in which an algorithm can improve its expected performance by fine-tuning itself automatically with respect to an unknown input distribution $\mathcal{D}$. We assume here that $\mathcal{D}$ is of product type. More precisely, suppose that we need to process a sequence $I_{1}, I_{2}, \ldots$ of inputs $I=\left(x_{1}, x_{2}, \ldots, x_{n}\right)$ of some fixed length $n$, where each $x_{i}$ is drawn independently from some arbitrary, unknown distribution $\mathcal{D}<em i="i">{i}$. The goal is to design an algorithm for these inputs so that eventually the expected running time will be optimal for the input distribution $\mathcal{D}=\prod</em>$.} \mathcal{D}_{i</p>
<p>We give such self-improving algorithms for two problems: (i) sorting a sequence of numbers and (ii) computing the Delaunay triangulation of a planar point set. Both algorithms achieve optimal expected limiting complexity. The algorithms begin with a training phase during which they collect information about the input distribution, followed by a stationary regime in which the algorithms settle to their optimized incarnations.</p>
<p>Key words. average case analysis, Delaunay triangulation, low entropy, sorting
AMS subject classifications. 68Q25, 68W20, 68W40</p>
<ol>
<li>Introduction. The classical approach to analyzing algorithms draws a familiar litany of complaints: worst-case bounds are too pessimistic in practice, say the critics, while average-case complexity too often rests on unrealistic assumptions. The charges are not without merit. Hard as it is to argue that the only permutations we ever want to sort are random, it is a different level of implausibility altogether to pretend that the sites of a Voronoi diagram should always follow a Poisson process or that ray tracing in a BSP tree should be spawned by a Gaussian. Efforts have been made to analyze algorithms under more complex models (eg, Gaussian mixtures, Markov model outputs) but with limited success and lingering doubts about the choice of priors.</li>
</ol>
<p>Suppose we wish to compute a function $f$ that takes $I$ as input. We get a sequence of inputs $I_{1}, I_{2}, \ldots$, and wish to compute $f\left(I_{1}\right), f\left(I_{2}\right), \ldots$ It is quite plausible to assume that all these inputs are somehow related to each other. This relationship, though exploitable, may be very difficult to express concisely. One way of modeling this situation is to postulate a fixed (but complicated) unknown distribution $\mathcal{D}$ of inputs. Each input $I_{j}$ is chosen independently at random from $\mathcal{D}$. Is it possible to learn quickly something about $\mathcal{D}$ so that we can compute $f(I)$ ( $I$ chosen from $\mathcal{D}$ ) faster? (Naturally, this is by no means the only possible input model. For example, we could have a memoryless Markov source, where each $I_{j}$ depends only on $I_{j-1}$. However, for simplicity we will here focus on a fixed source that generates the inputs independently.)</p>
<p>That is what a self-improving algorithm attempts to do. Initially, since nothing is know about $\mathcal{D}$, our self-improving algorithm can only provide some worst-case</p>
<p><sup id="fnref:1"><a class="footnote-ref" href="#fn:1">2</a></sup></p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Fig. 1.1. A self-improving algorithm $\mathcal{A}$ processes a sequence $I_{1}, I_{2}, \ldots$ of inputs drawn independently from a random source $\mathcal{D}$.
guarantee. As the algorithm sees more and more inputs, it can learn something about the structure of $\mathcal{D}$. We call this the training phase of the self-improving algorithm. During this phase, the algorithm collects and organizes information about the inputs in the hope that it can be used to improve the running time (with respect to inputs from $\mathcal{D}$ ). The algorithm then moves to the limiting phase. Having decided that enough has been learned about $\mathcal{D}$, the algorithm uses this information to compute $f(I)$ faster. Note that this behavior is tuned to the distribution $\mathcal{D}$.</p>
<p>Obviously, there is no reason why we should get a faster running time for all $\mathcal{D}$. Indeed, if $f$ is the sorting function and $\mathcal{D}$ is the uniform distribution over permutations, then we require expected $\Omega(n \log n)$ time to sort. On the other hand, if $\mathcal{D}$ was a low-entropy source of inputs, it is quite reasonable to hope for a faster algorithm. So when can we improve our running time? An elegant way of expressing this is to associate (using information theory) an "optimal" running time for each distribution. This is a sort of estimate of the best expected running time we can hope for, given inputs chosen from a fixed distribution $\mathcal{D}$. Naturally, the lower the entropy of $\mathcal{D}$, the lower this running time will be. In the limiting phase, our self-improving algorithm should achieve this optimal running time.</p>
<p>To expect a good self-improving algorithm that can handle all distributions $\mathcal{D}$ seems a bit ambitious, and indeed we show that even for the sorting problem there can be no space-efficient such algorithm (even when the entropy is low). Hence, it seems necessary to impose some kind of restriction on $\mathcal{D}$. However, if we required $\mathcal{D}$ to be, say, uniform or a Gaussian, we would again be stuck with the drawbacks of traditional average case analysis. Hence, for self-improvement to be of any interest, the restricted class of distributions should still be fairly general. One such class is given by product distributions.
1.1. Model and Results. We will focus our attention on distributions $\mathcal{D}$ of product type. Think of each input as an $n$-dimensional vector $\left(x_{1}, \ldots, x_{n}\right)$ over some appropriate domain. This could be a list of numbers (in the case of sorting) or a list of points (for Delaunay triangulations). Each $x_{i}$ is generated independently at random from an arbitrary distribution $\mathcal{D}<em i="i">{i}$, so $\mathcal{D}=\prod</em>} \mathcal{D<em i="i">{i}$. All the $\mathcal{D}</em>$ 's are independent of each other. It is fairly natural to think of various portions of the input as being generated by independent sources. For example, in computational geometry, the convex hull of uniformly independently distributed points in the unit square is a well studied problem.</p>
<p>Note that all our inputs are of the same size $n$. This might appear to be a rather unnatural requirement for (say) a sorting algorithm. Why must the 10th number in our input come from the same distribution? We argue that this is not a major issue (for concreteness, let us focus on sorting). The right way to think of the input is as a set of sources $\mathcal{D}<em 2="2">{1}, \mathcal{D}</em>, \ldots$, each independently generating a single number. The actual "order" in which we get these numbers is not important. What is important is that for each number, we know its source. For a given input, it is realistic to suppose that some sources may be active, and some may not (so the input may have less than $n$</p>
<p>numbers). Our self-improving sorters essentially perform an independent processing on each input number, after which $O(n)$ time is enough to sort. ${ }^{1}$ The algorithm is completely unaffected by the inactive sources. To complete the training phase, we only need to get enough information about each source. What if new sources are introduced during the stationary phase? Note that as long as $O(n / \log n)$ new sources (and hence new numbers) are added, we can always include these extra numbers in the sorted list in $O(n)$ time. Once the number of new sources becomes too large, we will have to go back to the training phase. This is, of course, quite acceptable: if the underlying distribution of inputs changes significantly, we have to recalibrate the algorithm. For these reasons, we feel that it is no loss of generality to deal with a fixed input length, especially for product distributions.</p>
<p>Our first result is a self-improving sorter. Given a source $\mathcal{D}=\prod_{i} \mathcal{D}<em 1="1">{i}$ of realnumber sequences $I=\left(x</em>$, and the limiting complexity of our algorithm will depend on $H(\pi(I))$. Note this quantity may be much smaller than the entropy of the source itself but can never exceed it.}, \ldots, x_{n}\right)$, let $\pi(I)$ denote the permutation induced by the ranks of the $x_{i}$ 's, using the indices $i$ to break ties. Observe that since $I$ is a random variable, so is $\pi(I)$. We can define the entropy $H(\pi(I))$, over the randomness of $\mathcal{D</p>
<p>As we mentioned earlier, the self-improving algorithm initially undergoes a training phase. At the end of this phase, some data structures storing information about the distributions are constructed. In the limiting phase, the self-improving algorithm is fixed, and these data structures do not change. In the context of sorting, the self-improving sorter becomes some fixed comparison tree.</p>
<p>THEOREM 1.1. There exists a self-improving sorter of $O(n+H(\pi(I)))$ limiting complexity, for any input distribution $\mathcal{D}=\prod_{i} \mathcal{D}_{i}$. Its worst case running time is $O(n \log n)$. No comparison-based algorithm can sort an input from $\mathcal{D}$ in less than $H(\pi(I))$ time. For any constant $\varepsilon&gt;0$, the storage can be made $O\left(n^{1+\varepsilon}\right)$ for an expected running time of $O\left(\varepsilon^{-1}(n+H(\pi(I)))\right)$. The training phase lasts $O\left(n^{\varepsilon}\right)$ rounds and the probability that it fails is at most $1 / n$.</p>
<p>Why do we need a restriction on the input distribution? In $\S 3.3$, we show that a self-improving sorter that can handle any distribution requires an exponentially large data structure. Fredman [31] gave an algorithm that could optimally sort permutations from any distribution $\mathcal{D}$. His algorithm needs to know $\mathcal{D}$ explicitly, and it constructs lookup tables of exponential size. Our bound shows that Fredman's algorithm cannot be improved. Furthermore, we show that even for product distributions any self-improving sorter needs super-linear space. Hence, our time-space tradeoffs are essentially optimal. We remind the reader that we focus on comparison-based algorithms.</p>
<p>Theorem 1.2. Consider a self-improving algorithm that, given any fixed distribution $\mathcal{D}$, can sort a random input from $\mathcal{D}$ in expected $O(n+H(\pi(I)))$ time. Such an algorithm requires $2^{\Omega(n \log n)}$ bits of storage.</p>
<p>Let $\varepsilon \in(0,1)$. Consider a self-improving algorithm that, given any product distribution $\mathcal{D}=\prod_{i} \mathcal{D}_{i}$, can sort a random input from $\mathcal{D}$ in expected $\varepsilon^{-1}(n+H(\pi(I)))$ time. Such an algorithm requires a data structure of bit size $n^{1+\Omega(\varepsilon)}$.</p>
<p>For our second result, we take the notion of self-improving algorithms to the geometric realm and address the classical problem of computing the Delaunay tri-</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>angulation of a set of points in the Euclidean plane. Given a source $\mathcal{D}=\prod_{i} \mathcal{D}<em 1="1">{i}$ of sequences $I=\left(x</em>$, let $T(I)$ denote the Delaunay triangulation of $I$. If we interpret $T(I)$ as a random variable on the set of all undirected graphs with vertex set ${1, \ldots, n}$, then $T(I)$ has an entropy $H(T(I))$, and the limiting complexity of our algorithm depends on this entropy.}, \ldots, x_{n}\right)$ of points in $\mathbb{R}^{2</p>
<p>THEOREM 1.3. There exists a self-improving algorithm for planar Delaunay triangulations of $O(n+H(T(I)))$ limiting complexity, for any input distribution $\mathcal{D}=\prod \mathcal{D}_{i}$. Its worst case running time is $O(n \log n)$. For any constant $\varepsilon&gt;0$, the storage can be made $O\left(n^{1+\varepsilon}\right)$ for an expected running time of $O\left(\varepsilon^{-1}(n+H(T(I)))\right)$. The training phase lasts $O\left(n^{\varepsilon}\right)$ rounds and the probability that it fails is at most $1 / n$.</p>
<p>From the linear time reduction from sorting to computing Delaunay triangulations [14, Theorems 8.2.2 and 12.1.1], the lower bounds of Theorem 1.2 carry over to Delaunay triangulations.</p>
<p>Both our algorithms follow the same basic strategy. During the training phase, we collect data about the inputs in order to obtain a typical input instance $V$ for $\mathcal{D}$ with $|V|=O(n)$, and we compute the desired structure $S$ (a sorted list or a Delaunay triangulation) on $V$. Then for each distribution $\mathcal{D}<em i="i">{i}$, we construct an entropy optimal search structure $D</em>$-searches, and the heart of the analysis lies in relating this search time to the entropies $H(\pi(I))$ and $H(T(I))$, respectively.
1.2. Previous Work. Related concepts to self-improving algorithms have been studied before. List accessing algorithms and splay trees are textbook examples of how simple updating rules can speed up searching with respect to an adversarial request sequence $[5,15,35,45,46]$. It is interesting to note that self-organizing data structures were investigated over stochastic input models first $[4,6,13,32,40,44]$. It was the observation [11] that memoryless sources for list accessing are not terribly realistic that partly motivated work on the adversarial models. It is highly plausible that both approaches are superseded by more sophisticated stochastic models: for example, hidden Markov models for gene finding or speech recognition or time-coherent models for self-customized BSP trees [8] or for randomized incremental constructions [23]. Recently, Afshani et al. [1] introduced the notion of instance optimality, which can be seen as a generalization of output-sensitivity. They consider the inputs as sets and try to exploit the structure within each input for faster algorithms.}$ for $S$ (ie, an entropy optimal binary search tree or a distribution sensitive planar point location structure). In the limiting phase, we use the $D_{i}$ 's in order to locate the components of a given input $I$ in $S$. The fact that $V$ is a typical input ensures that $I$ will be broken into individual subproblems of expected constant size that can be solved separately, so we can obtain the desired structure for the input $V \cup I$ in expected linear time (plus the time for the $D_{i}$-searches). Finally, for both sorting and Delaunay triangulation it suffices to know the solution for $V \cup I$ in order to derive the solution for $I$ in linear expected time [21,22]. Thus, the running time of our algorithms is dominated by the $D_{i</p>
<p>Much research has been done on adaptive sorting [30], especially on algorithms that exploit near-sortedness. Our approach is conceptually different: we seek to exploit properties, not of individual inputs, but of their distribution. Algorithmic self-improvement differs from past work on self-organizing data structures and online computation in two fundamental ways. First, there is no notion of an adversary: the inputs are generated by a fixed, oblivious, random source $\mathcal{D}$, and we compare ourselves against an optimal comparison-based algorithm for $\mathcal{D}$. In particular, there is no concept of competitiveness. Second, self-improving algorithms do not exploit structure</p>
<p>within any given input but, rather, within the ensemble of input distributions.
A simple example highlights this difference between previous sorters and the selfimproving versions. For $1 \leq i \leq n$, fix two random integers $a_{i}, b_{i}$ from $\left{1, \ldots, n^{2}\right}$. The distribution $\mathcal{D}<em i="i">{i}$ is such that $\operatorname{Pr}\left[x</em>}=a_{i}\right]=\operatorname{Pr}\left[x_{i}=b_{i}\right]=1 / 2$, and we take $\mathcal{D}=$ $\prod_{i=1}^{n} \mathcal{D<em i="i">{i}$. Observe that every permutation generated by $\mathcal{D}$ is a random permutation, since the $a</em>$ different permutations, we have $H(\pi(I))=O(n)$.
2. Entropy and Comparison-based Algorithms. Before we consider sorting and Delaunay triangulations, let us first recall some useful properties of information theoretic entropy [28] and explain how it relates to our notion of comparison-based algorithms.}$ 's and $b_{i}$ 's are chosen randomly. Hence, any solution in the adaptive, selforganizing/adjusting framework requires $\Omega(n \log n)$ time, because no input $I_{j}$ exhibits any special structure to be exploited. On the other hand, our self-improving sorter will sort a permutation from $\mathcal{D}$ in expected linear time during the limiting phase: since $\mathcal{D}$ generates at most $2^{n</p>
<p>Let $X$ be a random variable with a finite range $\mathcal{X}$. The entropy of $X, H(X)$, is defined as $H(X):=\sum_{x \in \mathcal{X}} \operatorname{Pr}[X=x] \log (1 / \operatorname{Pr}[X=x])$. Intuitively, the event that $X=x$ gives us $\log (1 / \operatorname{Pr}[X=x])$ bits of information about the underlying elementary event, and $H(X)$ represents the expected amount of information that can be obtained from observing $X$. We recall the following well-known property of the entropy of the Cartesian product of independent random variables [28, Theorem 2.5.1].</p>
<p>Claim 2.1. Let $H\left(X_{1}, \ldots, X_{n}\right)$ be the joint entropy of independent random variables $X_{1}, \ldots, X_{n}$. Then</p>
<p>$$
H\left(X_{1}, \ldots, X_{n}\right)=\sum_{i} H\left(X_{i}\right)
$$</p>
<p>We now define our notion of a comparison-based algorithm. Let $\mathcal{U}$ be an arbitrary universe, and let $\mathcal{X}$ be a finite set. A comparison-based algorithm to compute a function $X: \mathcal{U} \rightarrow \mathcal{X}$ is a rooted binary tree $\mathcal{A}$ such that (i) every internal node of $\mathcal{A}$ represents a comparison of the form $f(I) \leq g(I)$, where $f, g: \mathcal{U} \rightarrow \mathbb{R}$ are arbitrary functions on the input universe $\mathcal{U}$; and (ii) the leaves of $\mathcal{A}$ are labeled with outputs from $\mathcal{X}$ such that for every input $I \in \mathcal{U}$, following the appropriate path for $I$ leads to the correct output $X(I)$. If $\mathcal{A}$ has maximum depth $d$, we say that $\mathcal{A}$ needs $d$ comparisons (in the worst case). For a distribution $\mathcal{D}$ on $\mathcal{U}$, the expected number of comparisons (with respect to $\mathcal{D}$ ) is the expected length of a path from the root to a leaf in $\mathcal{A}$, where the leaves are sampled according to the distribution that $\mathcal{D}$ induces on $\mathcal{X}$ via $X$.</p>
<p>Note that our comparison-based algorithms generalize both the traditional notion of comparison-based algorithms [27, Chapter 8.1], where the functions $f$ and $g$ are required to be projections, as well as the notion of algebraic computation trees [9, Chapter 16.2]. Here the functions $f$ and $g$ must be composed of elementary functions (addition, multiplication, square root) such that the complexity of the composition is proportional to the depth of the node. Naturally, our comparison-based algorithms can be much stronger. For example, deciding whether a sequence $x_{1}, x_{2}, \ldots, x_{n}$ of real numbers consists of $n$ distinct elements needs one comparison in our model, whereas every algebraic computation tree for the problem has depth $\Omega(n \log n)$ [9, Chapter 16.2]. However, for our problems of interest, we can still derive meaningful lower bounds.</p>
<p>Claim 2.2. Let $\mathcal{D}$ be a distribution on a universe $\mathcal{U}$ and let $X: \mathcal{U} \rightarrow \mathcal{X}$ be a</p>
<p>random variable. Then any comparison-based algorithm to compute $X$ needs at least $H(X)$ expected comparisons.</p>
<p>Proof. This is an immediate consequence of Shannon's noiseless coding theorem [28, Theorem 5.4.1] which states that any binary encoding of an information source such as $X(I)$ must have an expected code length of at least $H(X)$. Any comparison-based algorithm $\mathcal{A}$ represents a coding scheme: the encoder sends the sequence of comparison outcomes, and the decoder descends along the tree $\mathcal{A}$, using the transmitted sequence to determine comparison outcomes. Thus, any comparisonbased algorithm must perform at least $H(X)$ comparisons in expectation.</p>
<p>Note that our comparison-based algorithms include all the traditional sorting algorithms [27] (selection sort, insertion sort, quicksort, etc) as well as classic algorithms for Delaunay triangulations [12] (randomized incremental construction, divide and conquer, plane sweep). A notable exception are sorting algorithms that rely on table lookup or the special structure of the input values (such as bucket sort or radix sort) as well as transdichotomous algorithms for sorting [33,34] or Delaunay triangulations [16-18].</p>
<p>The following lemma shows how we can use the running times of comparisonbased algorithms to relate the entropy of different random variables. This is a very important tool that will be used to prove the optimality of our algorithms.</p>
<p>Lemma 2.3. Let $\mathcal{D}$ be a distribution on a universe $\mathcal{U}$, and let $X: \mathcal{U} \rightarrow \mathcal{X}$ and $Y: \mathcal{U} \rightarrow \mathcal{Y}$ be two random variables. Suppose that the function $f$ defined by $f$ : $(I, X(I)) \mapsto Y(I)$ can be computed by a comparison-based algorithm with $C$ expected comparisons (where the expectation is over $\mathcal{D}$ ). Then $H(Y)=C+O(H(X))$, where all the entropies are with respect to $\mathcal{D}$.</p>
<p>Proof. Let $s: X(\mathcal{U}) \rightarrow{0,1}^{<em>}$ be a unique binary encoding of $X(\mathcal{U})$. By unique encoding, we mean that the encoding is $1-1$. We denote the expected code length of $s$ with respect to $\mathcal{D}, \mathbf{E}<em s="s">{\mathcal{D}}[|s(X(I))|]$, by $E</em>)$, and there exists a unique encoding $s^{}$. By another application of Shannon's noiseless coding theorem [28, Theorem 5.4.1]), we have $E_{s} \geq H(X)$ for any unique encoding $s$ of $X(\mathcal{U</em>}$ of $X(\mathcal{U})$ with $E_{s^{*}}=O(H(X))$.</p>
<p>Using $f$, we can convert $s^{<em>}$ into a unique encoding $t$ of $Y(\mathcal{U})$. Indeed, for every $I \in \mathcal{U}, Y(I)$ can be uniquely identified by a string $t(I)$ that is the concatenation of $s^{</em>}(X(I))$ and additional bits that represent the outcomes of the comparisons for the algorithm to compute $f(I, X(I))$. Thus, for every element $y \in Y(\mathcal{U})$, we can define $t(y)$ as the lexicographically smallest string $t(I)$ for which $Y(I)=y$, and we obtain a unique encoding $t$ for $Y(\mathcal{U})$. For the expected code length $E_{t}$ of $t$, we get</p>
<p>$$
E_{t}=E_{\mathcal{D}}[|t(Y(I))|] \leq E_{\mathcal{D}}\left[C+\left|s^{<em>}(X(I))\right|\right]=C+E_{s^{</em>}}=C+O(H(X))
$$</p>
<p>Since Shannon's theorem implies $E_{t} \geq H(Y)$, the claim follows.
3. A Self-Improving Sorter. We are now ready to describe our self-improving sorter. The algorithm takes an input $I=\left(x_{1}, x_{2}, \ldots, x_{n}\right)$ of real numbers drawn from a distribution $\mathcal{D}=\prod_{i} \mathcal{D}<em i="i">{i}$ (ie, each $x</em>}$ is chosen independently from $\mathcal{D<em i="i">{i}$ ). Let $\pi(I)$ denote the permutation induced by the ranks of the $x</em>$ the set of all permutations on ${1, \ldots, n}$, and $X(I)=\pi(I)$, we see that any sorter must make at least $H(\pi(I))$ expected comparisons. Since it takes $\Omega(n)$ steps to write the output, any sorter needs $\Omega(H(\pi(I))+n)$ steps. This is, indeed, the bound that our self-improving sorter achieves.}$ 's, using the indices $i$ to break ties. By applying Claim 2.2 with $\mathcal{U}=\mathbb{R}^{n}, \mathcal{X</p>
<p>For simplicity, we begin with the steady-state algorithm and discuss the training phase later. We also assume that the distribution $\mathcal{D}$ is known ahead of time and that we are allowed some amount of preprocessing before having to deal with the first input instance (ยง3.1). Both assumptions are unrealistic, so we show how to remove them to produce a bona fide self-improving sorter (ยง3.2). The surprise is how strikingly little of the distribution needs to be learned for effective self-improvement.
3.1. Sorting with Full Knowledge. We consider the problem of sorting $I=$ $\left(x_{1}, \ldots, x_{n}\right)$, where each $x_{i}$ is a real number drawn from a distribution $\mathcal{D}<em i="i">{i}$. We can assume without loss of generality that all the $x</em>+i \delta$ for an infinitesimally small $\delta&gt;0$, so that ties are broken according to the index $i$.)}$ 's are distinct. (If not, simply replace $x_{i}$ by $x_{i</p>
<p>The first step of the self-improving sorter is to sample $\mathcal{D}$ a few times (the training phase) and create a "typical" instance to divide the real line into a set of disjoint, sorted intervals. Next, given some input $I$, the algorithm sorts $I$ by using the typical instance, placing each input number in its respective interval. All numbers falling into the same intervals are then sorted in a standard fashion. The algorithm needs a few supporting data structures.</p>
<ul>
<li>The $V$-List: Fix an integer parameter $\lambda=\lceil\log n\rceil$, and sample $\lambda$ input instances from $\prod \mathcal{D}<em 1="1">{i}$. Form their union and sort the resulting $\lambda n$-element multiset into a single list $u</em>$ in the $V$-list is linearly equivalent to sorting $I$. We cannot afford to search the $V$-list directly, however. To do that, we need auxiliary search structures.} \leq \cdots \leq u_{\lambda n}$. Next, extract from it every $\lambda$ th item and form the list $V=\left(v_{0}, \ldots, v_{n+1}\right)$, where $v_{0}=0, v_{n+1}=\infty$, and $v_{i}=u_{i \lambda}$ for $1 \leq i \leq n$. Keep the resulting $V$-list in a sorted table as a snapshot of a "typical" input instance. We will prove the remarkable fact that, with high probability, locating each $x_{i</li>
<li>The $D_{i}$-trees: For any $i \geq 1$, let $\mathcal{B}<em i="i">{i}^{V}$ be the predecessor ${ }^{2}$ of a random $y$ from $\mathcal{D}</em>}$ in the $V$-list, and let $H_{i}^{V}$ be the entropy of $\mathcal{B<em i="i">{i}^{V}$. The $D</em>}$-tree is defined to be an optimum binary search tree [41] over the keys of the $V$-list, where the access probability of $v_{k}$ is $\operatorname{Pr<em i="i">{\mathcal{D}</em>}}\left[x_{i} \in\left[v_{k}, v_{k+1}\right)\right]=\operatorname{Pr}\left[\mathcal{B<em i="i">{i}^{V}=k\right]$, for any $0 \leq k \leq n$. This allows us to compute $\mathcal{B}</em>+1\right)$ expected comparisons.
The self-improving sorter. The input $I$ is sorted by a two-phase procedure. First we locate each $x_{i}$ in the $V$-list using the $D_{i}$-trees. This allows us to partition $I$ into groups $Z_{0}&lt;Z_{1}&lt;\cdots$ of $x_{i}$ 's sharing the same predecessor in the $V$-list. The first phase of the algorithm takes $O\left(n+\sum_{i} H_{i}^{V}\right)$ expected time. ${ }^{3}$ The next phase involves going through each $Z_{k}$ and sorting their elements naively, say using insertion sort, in total time $O\left(\sum_{k}\left|Z_{k}\right|^{2}\right)$. See Fig. 3.1.}^{V}$ using $O\left(H_{i}^{V</li>
</ul>
<p>The expected running time is $O\left(n+\mathbf{E}<em i="i">{\mathcal{D}}\left[\sum</em>\right)$ for any constant $\varepsilon&gt;0$; we describe how at the end of this section. First, we show how to bound the running time of the first phase. This is where we really show the optimality of our sorter.} H_{i}^{V}+\sum_{k}\left|Z_{k}\right|^{2}\right]\right)$, and the total space used is $O\left(n^{2}\right)$. This can be decreased to $O\left(n^{1+\varepsilon</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Fig. 3.1. The self-improving sorter: during the training phase, the algorithm constructs a typical sorted list, the $V$-list, and a sequence $D_{1}, D_{2}, \ldots$ of optimal search trees for $V$ with respect to $\mathcal{D}<em 2="2">{1}, \mathcal{D}</em>$ 's in the $V$-list, sorts the individual buckets, and removes the elements from $V$.}, \ldots$. In the limiting phase, the algorithm uses the $D_{i}$ 's to locate the $x_{i</p>
<p>LEMMA 3.1.</p>
<p>$$
\sum_{i} H_{i}^{V}=O(n+H(\pi(I)))
$$</p>
<p>Proof. Our proof actually applies to any linear sized sorted list $V$. Let $\mathcal{B}^{V}:=$ $\left(\mathcal{B}<em n="n">{1}^{V}, \ldots, \mathcal{B}</em>(I)$ from $(I, \pi(I))$ with $O(n)$ comparisons. But this is easy: just use $\pi(I)$ to sort $I$ (which needs no further comparisons) and then merge the sorted list $I$ with $V$. Now the lemma follows from Claim 2.1.}^{V}\right)$ be the sequence of predecessors for all elements in $I$. By Claim 2.1, we have $H\left(\mathcal{B}^{V}\right)=\sum_{i} H_{i}^{V}$, so it suffices to bound the entropy of $H\left(\mathcal{B}^{V}\right)$. By Lemma 2.3 applied with $\mathcal{U}=\mathbb{R}^{n}, X(I)=\pi(I)$ and $Y(I)=\mathcal{B}^{V}$, it suffices to give a comparisonbased algorithm that can determine $\mathcal{B}^{V</p>
<p>Next we deal with the running time of the second phase. As long as the groups $Z_{k}$ are small, the time to sort each group will be small. The properties of the $V$-list ensure that this is the case.</p>
<p>Lemma 3.2. For $0 \leq k \leq n$, let $Z_{k}=\left{x_{i} \mid v_{k} \leq x_{i}&lt;v_{k+1}\right}$ be the elements with predecessor $k$. With probability at least $1-n^{-2}$ over the construction of the $V$-list, we have $\mathbf{E}<em k="k">{\mathcal{D}}\left[\left|Z</em>}\right|\right]=O(1)$ and $\mathbf{E<em k="k">{\mathcal{D}}\left[\left|Z</em>\right]=O(1)$, for all $0 \leq k \leq n$.}\right|^{2</p>
<p>Proof. Remember that the $V$-list was formed by taking certain elements from a sequence $\hat{I}=s_{1}, s_{2}, \ldots, s_{\lambda n}$ that was obtained by concatenating $\lambda=\lceil\log n\rceil$ inputs $I_{1}, I_{2}, \ldots$ Let $s_{i} \leq s_{j}$ be any two elements from $\hat{I}$, and let $t=\left[s_{i}, s_{j}\right)$. Note that all the other $\lambda n-2$ numbers are independent of $s_{i}$ and $s_{j}$. Suppose we fix the values of $s_{i}$ and $s_{j}$ (in other words, we condition on the values of $s_{i}$ and $s_{j}$ ). For every $\ell \in{1, \ldots, \lambda n} \backslash{i, j}$, let $Y_{\ell}^{(t)}$ be the indicator random variable for the event that $s_{\ell} \in t$, and let $Y^{(t)}:=\sum_{\ell} Y_{\ell}^{(t)}$. Since all the $Y_{\ell}^{(t)}$ 's are independent, by Chernoff's bound [42, Theorem 4.2], for any $\beta \in[0,1]$,</p>
<p>$$
\operatorname{Pr}\left[Y^{(t)} \leq(1-\beta) \mathbf{E}\left[Y^{(t)}\right]\right] \leq \exp \left(-\beta^{2} \mathbf{E}\left[Y^{(t)}\right] / 2\right)
$$</p>
<p>Setting $\beta=10 / 11$, we see that if $\mathbf{E}\left[Y^{(t)}\right]&gt;11\lceil\log n\rceil$, then $Y^{(t)}&gt;\lceil\log n\rceil$ with probability at least $1-1 /\left(\lambda^{2} n^{4}\right)$. Note that this is true for every fixing of $s_{i}$ and $s_{j}$.</p>
<p>Therefore, we get the above statement even with the unconditioned random variable $Y^{(t)}$. Now, by applying the same argument to any pair $s_{i}, s_{j}$ with $i \neq j$ and taking a union bound over all $\binom{ \lambda_{0}}{2}$ such pairs, we get that with probability at least $1-n^{-2}$ over the construction of $\hat{I}$ the following holds for all half-open intervals $t$ defined by pairs $s_{i}, s_{j}$ with $i \neq j$ : if $\mathbf{E}\left[Y^{(t)}\right]&gt;11\lceil\log n\rceil$, then $Y^{(t)}&gt;\lceil\log n\rceil$. From now on we assume that this implication holds.</p>
<p>The $V$-list is constructed such that for $t_{k}=\left[v_{k}, v_{k+1}\right), Y^{\left(t_{k}\right)} \leq\lceil\log n\rceil$, and hence $\mathbf{E}\left[Y^{\left(t_{k}\right)}\right]=O(\log n)$. Let $X_{i}^{\left(t_{k}\right)}$ be the indicator random variable for the event that $x_{i} \in_{R} \mathcal{D}<em k="k">{i}$ lies in $t</em>$ )}$, and $X^{\left(t_{k}\right)}:=\sum_{i} X_{i}^{\left(t_{k}\right)}=\left|Z_{k}\right|$. Note that (where $a$ and $b$ denote the indices of $v_{k}$ and $v_{k+1}$ in $\hat{I</p>
<p>$$
\mathbf{E}\left[Y^{\left(t_{k}\right)}\right]=\sum_{\ell \neq a, b} \mathbf{E}\left[Y_{\ell}^{\left(t_{k}\right)}\right] \geq \sum_{i} \lambda \mathbf{E}\left[X_{i}^{\left(t_{k}\right)}\right]-2=\lceil\log n\rceil \mathbf{E}\left[X^{\left(t_{k}\right)}\right]-2
$$</p>
<p>and therefore $\mathbf{E}\left[X^{\left(t_{k}\right)}\right]=O(1)$. Now, since the expectation of $X^{\left(t_{k}\right)}$ is constant, and since $X^{\left(t_{k}\right)}$ is a sum of independent indicator random variables, we can apply the following standard claim in order to show that the second moment of $X^{\left(t_{k}\right)}$ is also constant.</p>
<p>Claim 3.3. Let $X=\sum_{i} X_{i}$ be a sum of independent positive random variables with $X_{i}=O(1)$ for all $i$ and $\mathbf{E}[X]=O(1)$. Then $\mathbf{E}\left[X^{2}\right]=O(1)$.</p>
<p>Proof. By linearity of expectation,</p>
<p>$$
\begin{aligned}
&amp; \mathbf{E}\left[X^{2}\right]=\mathbf{E}\left[\left(\sum_{i} X_{i}\right)^{2}\right]=\sum_{i} \mathbf{E}\left[X_{i}^{2}\right]+2 \sum_{i&lt;j} \mathbf{E}\left[X_{i}\right] \mathbf{E}\left[X_{j}\right] \
&amp; \leq \sum_{i} O\left(\mathbf{E}\left[X_{i}\right]\right)+\left(\sum_{i} \mathbf{E}\left[X_{i}\right]\right)^{2}=O(1)
\end{aligned}
$$</p>
<p>This concludes the proof of Lemma 3.2.
Combining Lemmas 3.1 and 3.2, we get the running time of our self-improving sorter to be $O(n+H(\pi(I)))$. This proves the optimality of time taken by the sorter.</p>
<p>We now show that the storage can be reduced to $O\left(n^{1+\varepsilon}\right)$, for any constant $\varepsilon&gt;0$. The main idea is to prune each $D_{i}$-tree to depth $\varepsilon \log n$. This ensures that tree has size $O\left(n^{\varepsilon}\right)$, so the total storage used is $O\left(n^{1+\varepsilon}\right)$. We also construct a completely balanced binary tree $T$ for searching in the $V$-list. Now, when we wish to search for $x_{i}$ in the $V$-list, we first search using the pruned $D_{i}$-tree. At the end, if we reach a leaf of the unpruned $D_{i}$-tree, we stop since we have found the right interval of the $V$-list which contains $x_{i}$. On the other hand, if the search in the $D_{i}$-tree was unsuccessful, then we use $T$ for searching.</p>
<p>In the first case, the time taken for searching is simply the same as with unpruned $D_{i}$-trees. In the second case, the time taken is $O((1+\varepsilon) \log n)$. But note that the time taken with unpruned $D_{i}$-trees is at least $\varepsilon \log n$ (since the search on the pruned $D_{i}$-tree failed, we must have reached some internal node of the unpruned tree). Therefore, the extra time taken is only a $O\left(\varepsilon^{-1}\right)$ factor of the original time. As a result, the space can be reduced to $O\left(n^{1+\varepsilon}\right)$ with only a constant factor increase in running time (for any fixed $\varepsilon&gt;0$ ).
3.2. Learning the Distribution. In the last section we showed how to obtain a self-improving sorter if $\mathcal{D}$ is known. We now explain how to remove this assumption.</p>
<p>The $V$-list is built in the first $\lceil\log n\rceil$ rounds, as before. The $D_{i}$-trees will be built after $O\left(n^{\varepsilon}\right)$ additional rounds, which will complete the training phase. During that phase, sorting is handled via, say, mergesort to guarantee $O(n \log n)$ complexity. The training part per se consists of learning basic information about $\mathcal{B}<em k="k">{i}^{V}$ for each $i$. For notational simplicity, fix $i$ and let $p</em>}=\operatorname{Pr}\left[\mathcal{B<em _mathcal_D="\mathcal{D">{i}^{V}=k\right]=\operatorname{Pr}</em><em k="k">{i}}\left[v</em>\right)\right)$. We apply this procedure for each $i=1, \ldots, n$.} \leq x_{i}<v_{k+1}\right]$. Let $M=c n^{\varepsilon}$, for a large enough constant $c$. For any $k$, let $\chi_{k}$ be the number of times, over the first $M$ rounds, that $v_{k}$ is found to be the $V$-list predecessor of $x_{i}$. (We use standard binary search to compute predecessors in the training phase.) Finally, define the $D_{i}$-tree to be a weighted binary search tree defined over all the $v_{k}$ 's such that $\chi_{k}>0$. Recall that the crucial property of such a tree is that the node associated with a key of weight $\chi_{k}$ is at depth $O\left(\log \left(M / \chi_{k</p>
<p>This $D_{i}$-tree is essentially the pruned version of the tree we used in $\S 4.1$. Like before, its size is $O(M)=O\left(n^{\varepsilon}\right)$, and it is used in a similar way as in $\S 4.1$, with a few minor differences. For completeness, we go over it again: given $x_{i}$, we perform a search down the $D_{i}$-tree. If we encounter a node whose associated key $v_{k}$ is such that $x_{i} \in\left[v_{k}, v_{k+1}\right)$, we have determined $\mathcal{B}<em i="i">{i}^{V}$ and we stop the search. If we reach a leaf of the $D</em>$-tree without success, we simply perform a standard binary search in the $V$-list.</p>
<p>Lemma 3.4. Fix $i$. With probability at least $1-1 / n^{3}$, for any $k$, if $p_{k}&gt;n^{-\varepsilon / 3}$ then $M p_{k} / 2&lt;\chi_{k}&lt;3 M p_{k} / 2$.</p>
<p>Proof. The expected value of $\chi_{k}$ is $M p_{k}$. If $p_{k}&gt;n^{-\varepsilon / 3}$ then, by Chernoff's bound [7, Corollary A.17] the count $\chi_{k}$ deviates from its expectation by more than $a=M p_{k} / 2$ with probability less than (recall that $M=c n^{\varepsilon}$ )</p>
<p>$$
2 \exp \left(-2 a^{2} / M\right)=2 \exp \left(-M p_{k}^{2} / 2\right)&lt;2 \exp \left(-(c / 2) n^{2 \varepsilon / 3}\right) \leq n^{-4}
$$</p>
<p>for $c$ large enough. A union bound over all $k$ completes the proof.
Suppose now the implication of Lemma 3.4 holds for all $k$ (and fixed $i$ ). We show now that the expected search time for $x_{i}$ is $O\left(\varepsilon^{-1} H_{i}^{V}+1\right)$. Consider each element in the sum $H_{i}^{V}=\sum_{k} p_{k} \log \left(1 / p_{k}\right)$. We distinguish two cases.</p>
<ul>
<li>Case 1: $p_{k}&gt;n^{-\varepsilon / 3}$. In this case, $v_{k}$ must be in $D_{i}$, as otherwise we would have $\chi_{k}=0$ by the definition of $D_{i}$, a contradiction (for $n$ large enough) to Lemma 3.4, which states that $\chi_{k}&gt;M n^{-\varepsilon / 3} / 2$. Hence, the cost of the search is $O\left(\log \left(M / \chi_{k}\right)\right)$, and its contribution to the expected search time is $O\left(p_{k} \log \left(M / \chi_{k}\right)\right)$. By Lemma 3.4, this is also $O\left(p_{k}\left(1+\log p_{k}^{-1}\right)\right)$, as desired.</li>
<li>Case 2: $p_{k} \leq n^{-\varepsilon}$. The search time is always $O(\log n)$; hence the contribution to the expected search time is $O\left(\varepsilon^{-1} p_{k} \log p_{k}^{-1}\right)$.
By summing up over all $k$, we find that the expected search time is $O\left(\varepsilon^{-1} H_{i}^{V}+1\right)$. This assumes the implication of Lemma 3.4 for all $i$. By a union bound, this holds with probability at least $1-1 / n^{2}$. The training phase fails when either this does not hold, or if the $V$-list does not have the desired properties (Lemma 3.2). The total probability of this is at most $1 / n$.
3.3. Lower Bounds. Can we hope for a result similar to Theorem 1.1 if we drop the independence assumption? The short answer is no. As we mentioned earlier, Fredman [31] gave a comparison-based algorithm that can optimally sort any distribution of permutations. This uses an exponentially large data structure to decide which comparisons to perform. Our lower bound shows that the storage used by Fredman's algorithm is essentially optimal.</li>
</ul>
<p>To understand the lower bound, let us try to abstract out the behavior of a self-improving sorter. Given inputs from a distribution $\mathcal{D}$, at each round, the selfimproving sorter is just a comparison tree for sorting. After any round, the selfimproving sorter may wish to update the comparison tree. At some round (eventually), the self-improving sorter must be able to sort with expected $O(n+H(\pi(I)))$ comparisons: the algorithm has "converged" to the optimal comparison tree. The algorithm uses some data structure to represent (implicitly) this comparison tree.</p>
<p>We can think of a more general situation. The algorithm is explicitly given an input distribution $\mathcal{D}$. It is allowed some space where it stores information about $\mathcal{D}$ (we do not care about the time spent to do this). Then, (using this stored information) it must be able to sort a permutation from $\mathcal{D}$ in expected $O(n+H(\pi(I)))$ comparisons. So the information encodes some fixed comparison based procedure. As a shorthand for the above, we will say that the algorithm, on input distribution $\mathcal{D}$, optimally sorts $\mathcal{D}$. How much space is required to deal with all possible $\mathcal{D}$ 's? Or just to deal with product distributions? These are the questions that we shall answer.</p>
<p>Lemma 3.5. Let $h=(n \log n) / \alpha$, for some sufficiently large constant $\alpha&lt;0$, and let $\mathcal{A}$ be an algorithm that can optimally sort any input distribution $\mathcal{D}$ with $H(\pi(I)) \leq$ $h$. Then $\mathcal{A}$ requires $2^{\Omega(n \log n)}$ bits of storage.</p>
<p>Proof. Consider the set of all $n$ ! permutations of ${1, \ldots, n}$. Every subset $\Pi$ of $2^{h}$ permutations induces a distribution $\mathcal{D}^{\Pi}$ defined by picking every permutation in $\Pi$ with equal probability and none other. Note that the total number such distributions $\mathcal{D}^{\Pi}$ is $\binom{n!}{2^{h}}&gt;\left(n!/ 2^{h}\right)^{2^{h}}$ and $H\left(\mathcal{D}<em _="&lt;">{&lt;}^{\Pi}\right)=h$, where $\mathcal{D}</em>}^{\Pi}$ is the distribution on the output $\pi(I)$ induced by $\mathcal{D}^{\Pi}$. Suppose there exists a comparison-based procedure $\mathcal{A<em _Pi="\Pi">{\Pi}$ that sorts a random input from $\mathcal{D}^{\Pi}$ in expected time at most $c(n+h)$, for some constant $c&gt;0$. By Markov's inequality this implies that at least half of the permutations in $\Pi$ are sorted by $\mathcal{A}</em>}$ in at most $2 c(n+h)$ comparisons. But, within $2 c(n+h)$ comparisons, the procedure $\mathcal{A<em _Pi_prime="\Pi^{\prime">{\Pi}$ can only sort a set $P$ of at most $2^{2 c(n+h)}$ permutations. Therefore, any other $\Pi^{\prime}$ such that $\mathcal{A}</em>$ to}}=\mathcal{A}_{\Pi}$ will have to draw at least half of its elements from $P$. This limits the number of such $\Pi^{\prime</p>
<p>$$
\binom{n!}{2^{h} / 2}\binom{2^{2 c(n+h)}}{2^{h} / 2}&lt;(n!)^{2^{h-1}} 2^{c(n+h) 2^{h}}
$$</p>
<p>This means that the number of distinct procedures needed exceeds</p>
<p>$$
\left(n!/ 2^{h}\right)^{2^{h}} /\left((n!)^{2^{h-1}} 2^{c(n+h) 2^{h}}\right)&gt;(n!)^{2^{h-1}} 2^{-(c+1)(n+h) 2^{h}}=2^{\Omega\left(2^{h} n \log n\right)}
$$</p>
<p>assuming that $h /(n \log n)$ is small enough. A procedure is entirely specified by a string of bits; therefore at least one such procedure must require storage logarithmic in the previous bound.</p>
<p>We now show that a self-improving sorter dealing with product distributions requires super-linear size. In fact, the achieved tradeoff between the $O\left(n^{1+\varepsilon}\right)$ storage bound and an expected running time off the optimal by a factor of $O(1 / \varepsilon)$ is optimal.</p>
<p>Lemma 3.6. Let $c&gt;0$ be a large enough parameter, and let $\mathcal{A}$ be an algorithm that, given a product distribution $\mathcal{D}$, can sort a random permutation from $\mathcal{D}$ in expected time $c(n+H(\pi(I)))$. Then $\mathcal{A}$ requires a data structure of bit size $n^{1+\Omega(1 / c)}$.</p>
<p>Proof. The proof is a specialization of the argument used for proving Lemma 3.5. Let $h=(n \log n) /(3 c)$ and $\kappa=2^{\lfloor h / n\rfloor}$. We define $\mathcal{D}_{i}$ by choosing $\kappa$ distinct integers</p>
<p>in ${1, \ldots, n}$ and making them equally likely to be picked as $x_{i}$. (For convenience, we use the tie-breaking rule that maps $x_{i} \mapsto n x_{i}+i-1$. This ensures that $\pi(I)$ is unique.) We then set $\mathcal{D}:=\prod_{i} \mathcal{D}_{i}$. By Claim 2.1, $\mathcal{D}$ has entropy $n \cdot\lfloor h / n\rfloor=\Theta(h)$. This leads to $\binom{n}{\kappa}^{n}&gt;(n / \kappa)^{\kappa n}$ choices of distinct distributions $\mathcal{D}$. Suppose that $\mathcal{A}$ uses $s$ bits of storage and can sort each such distribution in $c(n+h)$ expected comparisons. Some fixing $\mathcal{S}$ of the bits must be able to accommodate this running time for a set $\mathcal{G}$ of at least $(n / \kappa)^{\kappa n} 2^{-s}$ distributions $\mathcal{D}$. In other words, some comparison-based procedure can deal with $(n / \kappa)^{\kappa n} 2^{-s}$ distributions $\mathcal{D}$. Any input instance that is sorted in at most $2 c(h+n)$ time by $\mathcal{S}$ is called easy: the set of easy instances is denoted by $\mathcal{E}$.</p>
<p>Because $\mathcal{S}$ has to deal with many distributions, there must be many instances that are easy for $\mathcal{S}$. This gives a lower bound for $|\mathcal{E}|$. On the other hand, since easy instances are those that are sorted extremely quickly by $\mathcal{S}$, there cannot be too many of them. This gives an upper bound for $|\mathcal{E}|$. Combining these two bounds, we get a lower bound for $s$. We will begin with the easier part: the upper bound for $|\mathcal{E}|$.</p>
<p>Claim 3.7. $|\mathcal{E}| \leq 2^{2 c(h+n)+2}$
Proof: In the comparison-based algorithm represented by $\mathcal{S}$, each instance $I \in \mathcal{E}$ is associated with a leaf of a binary decision tree of depth at most $2 c(h+n)$, ie, with one of at most $2^{2 c(h+n)}$ leaves. This would give us an upper bound on $s$ if each $I \in \mathcal{E}$ was assigned a distinct leaf. However, it may well be that two distinct inputs $I, I^{\prime} \in \mathcal{E}$ have $\pi(I)=\pi\left(I^{\prime}\right)$ and lead to the same leaf. Nonetheless, we have a collision bound, saying that for any permutation $\pi$, there are at most $4^{n}$ instances $I \in \mathcal{E}$ with $\pi(I)=\pi$. This implies that $|\mathcal{E}| \leq 4^{n} 2^{2 c(h+n)}$.</p>
<p>To prove the collision bound, first fix a permutation $\pi$. How many instances can map to this permutation? We argue that knowing that $\pi(I)=\pi$ for an instance $I \in \mathcal{E}$, we only need $2 n-1$ additional bits to encode $I$. This immediately shows that there must be less than $4^{n}$ such instances $I$. Write $I=\left(x_{1}, \ldots, x_{n}\right)$, and let $I$ be sorted to give the vector $\bar{I}=\left(y_{1}, \ldots, y_{n}\right)$. Represent the ground set of $I$ as an $n$-bit vector $\alpha\left(\alpha_{i}=1\right.$ if some $\left.x_{j}=i\right.$, else $\left.\alpha_{i}=0\right)$. For $i=2, \ldots, n$, let $\beta_{i}=1$ if $y_{i}=y_{i-1}$, else $\beta_{i}=0$. Now, given $\alpha$ and $\beta$, we can immediately deduce the vector $\bar{I}$, and by applying $\pi^{-1}$ to $\bar{I}$, we get $I$. This proves the collision bound.</p>
<p>Claim 3.8. $|\mathcal{E}| \geq n^{n} \kappa^{-2 n} 2^{-2 s / \kappa}$
Proof: Each $\mathcal{D}<em i="i">{i}$ is characterized by a vector $v</em>$ is at most $c(h+n)$, by Markov's inequality, there exists a choice of permutations (one for each $1 \leq i \leq n$ ) for which at least half of the projections of the vector obtained by applying these permutations are easy.}=\left(a_{i, 1}, \ldots, a_{i, \kappa}\right)$, so that $\mathcal{D}$ itself is specified by $v=\left(v_{1}, \ldots, v_{n}\right) \in \mathbb{R}^{n \kappa}$. (From now on, we view $v$ both as a vector and a distribution of input instances.) Define the $j$-th projection of $v$ as $v^{j}=\left(a_{1, j}, \ldots, a_{n, j}\right)$. Even if $v \in \mathcal{G}$, it could well be that none of the projections of $v$ are easy. However, if we consider the projections obtained by permuting the coordinates of each vector $v_{i}=\left(a_{i, 1}, \ldots, a_{i, \kappa}\right)$ in all possible ways we enumerate each input instance from $v$ the same number of times. Note that applying these permutations gives us different vectors which also represent $\mathcal{D}$. Since the expected time to sort an input chosen from $\mathcal{D} \in \mathcal{G</p>
<p>Let us count how many distributions have a vector representation with a choice of permutations placing half its projections in $\mathcal{E}$. There are fewer than $|\mathcal{E}|^{\kappa / 2}$ choices of such instances and, for any such choice, each $v_{i}^{\prime}=\left(a_{i, 1}, \ldots, a_{i, \kappa}\right)$ has half its entries already specified, so the remaining choices are fewer than $n^{\kappa n / 2}$. This gives an upper bound of $n^{\kappa n / 2}|\mathcal{E}|^{\kappa / 2}$ on the number of such distributions. This number cannot be smaller than $|\mathcal{G}| \geq(n / \kappa)^{\kappa n} 2^{-s}$; therefore $|\mathcal{E}| \geq n^{n} \kappa^{-2 n} 2^{-2 s / \kappa}$, as desired.</p>
<p>It now just remains to put the bounds together.</p>
<p>$$
\begin{aligned}
&amp; n^{n} \kappa^{-2 n} 2^{-2 s / \kappa} \
&amp; \Longrightarrow \quad n \log n-2 n \log \kappa-2 s / \kappa \
&amp; \Longrightarrow \quad \kappa n(\log n-2 \log \kappa)-2 c \kappa h-2 c \kappa n-2 \kappa
\end{aligned}
$$</p>
<p>$$
\begin{aligned}
&amp; \leq \quad 2^{2 c(h+n)+2} \
&amp; \leq \quad 2 c h+2 c n+2 \
&amp; \leq \quad 2 s .
\end{aligned}
$$</p>
<p>We have $\kappa=n^{\Theta(1 / c)}$ and $h=(n \log n) /(3 c)$. Since $c$ is sufficiently large, we get $s=n^{1+\Omega(1 / c)}$.</p>
<h1>4. Delaunay Triangulations. We now consider self-improving algorithms for</h1>
<p>Delaunay triangulations. The aim of this section is to prove Theorem 1.3. Let $I=$ $\left(x_{1}, \ldots, x_{n}\right)$ denote an input instance, where each $x_{i}$ is a point in the plane, generated by a point distribution $\mathcal{D}<em i="i">{i}$. The distributions $\mathcal{D}</em>$ in any way, because we can always simulate the bounding triangle symbolically by adding virtual points at infinity.}$ are arbitrary, and may be continuous, although we never explicitly use such a condition. Each $x_{i}$ is independent of the others, so in each round the input $I$ is drawn from the product distribution $\mathcal{D}=\prod_{i} \mathcal{D}_{i}$, and we wish to compute the Delaunay triangulation of $I, T(I)$. To keep our arguments simple, we will assume that the points of $I$ are in general position (ie, no four points in $I$ lie on a common circle). This is no loss of generality and does not restrict the distribution $\mathcal{D}$, because the general position assumption can always be enforced by standard symbolic perturbation techniques [29]. Also we will assume that there is a bounding triangle that always contains all the points in $I$. Again, this does not restrict the distribution $\mathcal{D</p>
<p>The distribution $\mathcal{D}$ induces a (discrete) distribution on the set of Delaunay triangulations, viewed as undirected graphs with vertex set ${1, \ldots, n}$. Consider the entropy of this distribution: for each graph $G$ on ${1, \ldots, n}$, let $p_{G}$ be the probability that it represents the Delaunay triangulation of $I \in_{R} \mathcal{D}$. We have the output entropy $H(T(I)):=-\sum_{G} p_{G} \log p_{G}$. By Claim 2.2 , any comparison-based algorithm to compute the Delaunay triangulation of $I \in_{R} \mathcal{D}$ needs at least $H(T(I))$ expected comparisons. Hence, an optimal algorithm will be one that has an expected running time of $O(n+H(T(I)))$ (since it takes $O(n)$ steps to write the output).</p>
<p>We begin by describing the basic self-improving algorithm. (As before, we shall first assume that some aspects of the distribution $\mathcal{D}$ are known.) Then, we shall analyze the running time using our information theory tools to argue that the expected running time is optimal. Finally, we remove the assumption that $\mathcal{D}$ is known and give the time-space tradeoff in Theorem 1.3.
4.1. The algorithm. We describe the algorithm in two parts. The first part explains the learning phase and the data structures that are constructed (ยง4.1.1). Then, we explain how these data structures are used to speed up the computation in the limiting phase ( $\S 4.1 .2$ ). As before, the expected running time will be expressed in terms of certain parameters of the data structures obtained in the learning phase. In the next section (ยง4.2), we will prove that these parameters are comparable to the output entropy $H(T(I))$. First, we will assume that the distributions $\mathcal{D}_{i}$ are known to us, and the data structures described will use $O\left(n^{2}\right)$ space. Section 4.3 repeats the arguments of $\S 3.2$ to remove this assumption and to give the space-time tradeoff bounds of Theorem 1.3.</p>
<p>As outlined in Fig. 4.1, our algorithm for Delaunay triangulation is roughly a generalization of our algorithm for sorting. This is not surprising, but note that while the steps of the two algorithms, and their analyses, are analogous, in several cases a</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Sorting</th>
<th style="text-align: left;">Delaunay Triangulation</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Intervals $\left(x_{i}, x_{i^{\prime}}\right)$ containing no values <br> of $I$</td>
<td style="text-align: left;">Delaunay disks</td>
</tr>
<tr>
<td style="text-align: left;">Typical set $V$</td>
<td style="text-align: left;">Range space $\varepsilon$-net $V[26,39]$, ranges are <br> disks, $\varepsilon=1 / n$</td>
</tr>
<tr>
<td style="text-align: left;">$\log n$ training instance points with the <br> same $\mathcal{B}_{V}$ value</td>
<td style="text-align: left;">$\log n$ training instance points in each <br> Delaunay disk</td>
</tr>
<tr>
<td style="text-align: left;">Expect $O(1)$ values of $I$ within each <br> bucket (of the same $\mathcal{B}^{V}$ index)</td>
<td style="text-align: left;">Expect $O(1)$ points of $I$ in each Delau- <br> nay disk of $V$</td>
</tr>
<tr>
<td style="text-align: left;">Optimal weighted binary trees $D_{i}$</td>
<td style="text-align: left;">Entropy-optimal planar point location <br> data structures $D_{i}[10]$</td>
</tr>
<tr>
<td style="text-align: left;">Sorting within buckets</td>
<td style="text-align: left;">Triangulation within $\mathcal{V}\left(Z_{s}\right) \cap s$ (Claim <br> 4.5)</td>
</tr>
<tr>
<td style="text-align: left;">Sorted list of $V \cup I$</td>
<td style="text-align: left;">$T(V \cup I)$</td>
</tr>
<tr>
<td style="text-align: left;">Build sorted $V$ from sorted $V \cup I$ (triv- <br> ial)</td>
<td style="text-align: left;">Build $T(I)$ from $T(V \cup I)[21,22]$</td>
</tr>
<tr>
<td style="text-align: left;">(analysis) merge sorted $V$ and $I$ <br> (analysis) recover the indices $\mathcal{B}_{i}^{V}$ from <br> the sorted $I$ (trivial)</td>
<td style="text-align: left;">(analysis) merge $T(V)$ and $T(I)$ [19] <br> (analysis) recover the triangles $\mathcal{B}_{i}^{V}$ in <br> $T(V)$ from $T(I)$ (Lemma 4.8)</td>
</tr>
</tbody>
</table>
<p>Fig. 4.1. Delaunay triangulation algorithm as a generalization of the sorting algorithm
step for sorting is trivial, but the corresponding step for Delaunay triangulation uses some relatively recent and sophisticated prior work.
4.1.1. Learning Phase. For each round in the learning phase, we use a standard algorithm to compute the output Delaunay triangulation. We also perform some extra computation to build some data structures that will allow speedup in the limiting phase.</p>
<p>The learning phase is as follows. Take the first $\lambda:=\lceil\log n\rceil$ input lists $I_{1}, I_{2}, \ldots$, $I_{\lambda}$. Merge them into one list $\hat{I}$ of $\lambda n=n\lceil\log n\rceil$ points. Setting $\varepsilon:=1 / n$, find an $\varepsilon$-net $V \subseteq \hat{I}$ for the set of all open disks. In other words, find a set $V$ such that for any open disk $C$ that contains more than $\varepsilon \lambda n=\lceil\log n\rceil$ points of $\hat{I}, C$ contains at least one point of $V$. It is well known that that there exist $\varepsilon$-nets of size $O(1 / \varepsilon)$ for disks $[26,38,39,43]$, which here is $O(n)$. Furthermore, it is folklore that our desired $\varepsilon$-net $V$ can be constructed in time $n(\log n)^{O(1)}$, but there seems to be no explicit description of such an algorithm for our precise setting. Thus, we present an algorithm based on a construction by Pyrga and Ray [43] in Appendix A</p>
<p>Having obtained $V$, we construct the Delaunay triangulation of $V$, which we denote by $T(V)$. This is the analog of the $V$-list for the self-improving sorter. We also build an optimal planar point location structure (called $D$ ) for $T(V)$ : given a point, we can find in $O(\log n)$ time the triangle of $T(V)$ that it lies in [12, Chapter 6]. Define the random variable $\mathcal{B}<em i="i">{i}^{V}$ to be the triangle of $T(V)$ that $x</em>}$ falls into. ${ }^{4}$ Now let the entropy of $\mathcal{B<em i="i">{i}^{V}$ be $H</em>}^{V}$. If the probability that $x_{i}$ falls in triangle $t$ of $T(V)$ is $p_{i}^{t}$, then $H_{i}^{V}=-\sum_{t} p_{i}^{t} \log p_{i}^{t}$. For each $i$, we construct a search structure $D_{i}$ of size $O(n)$ that finds $\mathcal{B<em i="i">{i}^{V}$ in expected $O\left(H</em>$ 's can be constructed using the results of Arya et al. [10], for which the expected number of primitive comparisons}^{V}\right)$ time. These $D_{i</p>
<p><sup id="fnref4:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Fig. 4.2. Conflicts between $T(V)$ and the inputs: the input point $x$ conflicts with triangles $t_{1}$ and $t_{2}, y$ conflicts with $t_{1}, t_{2}$, and $t_{3}$, and $z$ conflicts only with $t_{3}$.
is $H_{i}^{V}+o\left(H_{i}^{V}\right)$. These correspond to the $D_{i}$-trees used for sorting.
We will now prove an analog to Lemma 3.2 which shows that the triangles of $T(V)$ do not contain many points of a new input $I \in_{R} \mathcal{D}$ on the average. Consider a triangle $t$ of $T(V)$ and let $C_{t}$ be its circumscribed disk; $C_{t}$ is a Delaunay disk of $V$. If a point $x_{i} \in I$ lies in $C_{t}$, we say that $x_{i}$ is in conflict with $t$ and call $t$ a conflict triangle for $x_{i}$. Refer to Fig. 4.2. (The "conflict" terminology arises from the fact that if $x_{i}$ were added to $V$, triangles with which it conflicts would no longer be in the Delaunay triangulation.) Let $Z_{t}:=I \cap C_{t}$, the random variable that represents the points of $I \in_{R} \mathcal{D}$ that fall inside $C_{t}$, the conflict set of $t$. Furthermore, let $X_{t}:=\left|Z_{t}\right|$. Note that the randomness comes from the random distribution of $\hat{I}$ (on which $V$ and $T(V)$ depend), as well as the randomness of $I$. We are interested in the expectation $\mathbf{E}\left[X_{t}\right]$ over $I$ of $X_{t}$. All expectations are taken over a random input $I$ chosen from $\mathcal{D}$.</p>
<p>Lemma 4.1. For any triangle $t$ of $T(V)$, let $Z_{t}=\left{x_{i} \mid x_{i} \in C_{t}\right}$ be the conflict set of $t$, and define $X_{t}:=\left|Z_{t}\right|$. With probability at least $1-n^{-2}$ over the construction of $T(V)$, we have $\mathbf{E}\left[X_{t}\right]=O(1)$ and $\mathbf{E}\left[X_{t}^{2}\right]=O(1)$, for all triangles $t$ of $T(V)$.</p>
<p>Proof. This is similar to the argument given in Lemma 3.2 with a geometric twist. Let the list of points $\hat{I}$ be $s_{1}, \ldots, s_{\lambda n}$, the concatenation of $I_{1}$ through $I_{\lambda}$. Fix three distinct indices $i, j, k$ and the triangle $t$ with vertices $s_{i}, s_{j}, s_{k}$ (so we are effectively conditioning on $s_{i}, s_{j}, s_{k}$ ). Note that all the remaining $\lambda n-3$ points are chosen independently of $s_{i}, s_{j}, s_{k}$, from some distribution $\mathcal{D}<em _ell="\ell">{\ell}$. For each $\ell \in{1, \ldots, \lambda n} \backslash$ ${i, j, k}$, let $Y</em>&gt;\lceil\log n\rceil$. We henceforth assume that this event happens.}^{(t)}$ be the indicator variable for the event that $s_{\ell}$ is inside $C_{t}$. Let $Y^{(t)}=\sum_{\ell} Y_{\ell}^{(t)}$. Setting $\beta=11 / 12$ in (3.1), we get that if $\mathbf{E}\left[Y^{(t)}\right]&gt;12\lceil\log n\rceil$, then $Y^{(t)}&gt;\lceil\log n\rceil$ with probability at least $1-1 /\left(\lambda^{3} n^{5}\right)$. This is true for every fixing of $s_{i}, s_{j}, s_{k}$, so it is also true unconditionally. By applying the same argument to any triple $i, j, k$ of distinct indices, and taking a union bound over all $\binom{\lambda n}{5}$ triples, we obtain that with probability at least $1-n^{-2}$, for any triangle $t$ generated by the points of $\hat{I}$, if $\mathbf{E}\left[Y^{(t)}\right]&gt;12\lceil\log n\rceil$, then $Y^{(t)</p>
<p>Consider a triangle $t$ of $T(V)$ and its circumcircle $C_{t}$. Since $T(V)$ is Delaunay, $C_{t}$ contains no point of $V$ in its interior. Since $V$ is a $(1 / n)$-net for all disks with respect to $\hat{I}, C_{t}$ contains at most $\lceil\log n\rceil$ points of $\hat{I}$, that is, $Y^{(t)} \leq\lceil\log n\rceil$. This implies that $\mathbf{E}\left[Y^{(t)}\right]=O(\log n)$, as in the previous paragraph. Since $\mathbf{E}\left[Y^{(t)}\right]&gt;\log n \mathbf{E}\left[X_{t}\right]-3$, we obtain $\mathbf{E}\left[X_{t}\right]=O(1)$, as claimed. Furthermore, since $X_{t}$ can be written as a sum of</p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Fig. 4.3. Determining the conflict set for $x_{i}$ : the triangle $\mathcal{B}<em i="i">{i}^{V}$ containing $x</em>}$ is found via $D_{i}$. Then we perform a breadth-first search from $\mathcal{B<em i="i">{i}^{V}$ until we encounter triangles that no longer conflict with $x</em>\right|\right)$ steps.
independent indicator random variables, Claim 3.3 shows that $\mathbf{E}\left[X_{t}^{2}\right]=O(1)$.
4.1.2. Limiting Phase. We assume that we are done with the learning phase, and have $T(V)$ with the property given in Lemma 4.1: for every triangle $t \in T(V)$, $\mathbf{E}\left[X_{t}\right]=O(1)$ and $\mathbf{E}\left[X_{t}^{2}\right]=O(1)$. We have reached the limiting phase where the algorithm is expected to compute the Delaunay triangulation with the optimal running time. We will prove the following lemma in this section.}$. The dark gray triangles form the conflict set of $x_{i}$, the light gray triangles mark the end of the BFS. Since the conflict set $S_{i}$ is connected, and since the dual graph has bounded degree, this takes $O\left(\left|S_{i</p>
<p>Lemma 4.2. Using the data structures from the learning phase, and the properties of them that hold with probability at least $1-1 / n^{2}$, in the limiting phase the Delaunay triangulation of input $I$ can be generated in expected $O\left(n+\sum_{i=1}^{n} H_{i}^{V}\right)$ time.</p>
<p>The algorithm, and the proof of this lemma, has two steps. In the first step, $T(V)$ is used to quickly compute $T(V \cup I)$, with the time bounds of the lemma. In the second step, $T(I)$ is computed from $T(V \cup I)$, using a randomized splitting algorithm proposed by Chazelle et al. [21], who provide the following theorem.</p>
<p>Theorem 4.3. [21, Theorem 3] Given a set of $n$ points $P$ and its Delaunay triangulation, for any partition of $P$ into two disjoint subsets $P_{1}$ and $P_{2}$, the Delaunay triangulations $T\left(P_{1}\right)$ and $T\left(P_{2}\right)$ can be computed in $O(n)$ expected time, using a randomized algorithm.</p>
<p>The remainder of this section is devoted to showing that $T(V \cup I)$ can be computed in expected time $O\left(n+\sum_{i=1}^{n} H_{i}^{V}\right)$. The algorithm is as follows. For each $x_{i} \in I$, we use $D_{i}$ to find the triangle $\mathcal{B}<em i="i">{i}^{V}$ of $T(V)$ that contains it. By the properties of the $D</em>}$ 's as described in $\S 4.1 .1$, this takes $O\left(\sum_{i=1}^{n} H_{i}^{V}\right)$ expected time. We now need to argue that given the $\mathcal{B<em i="i">{i}^{V}$ 's, the Delaunay triangulation $T(V \cup I)$ can be computed in expected linear time. For each $x</em>}$, we walk through $T(V)$ and find all the Delaunay disks of $T(V)$ that contain $x_{i}$, as in incremental constructions of Delaunay triangulations [12, Chapter 9]. This is done by breadth-first search of the dual graph of $T(V)$, starting from $\mathcal{B<em i="i">{i}^{V}$. Refer to Fig. 4.3. Let $S</em>$ is the conflict set of triangle $t$.}$ denote the set of triangles whose circumcircles contain $x_{i}$. We remind the reader that $Z_{t</p>
<p>Claim 4.4. Given all $\mathcal{B}<em i="i">{i}^{V}$ 's, all $S</em>$ sets can be found in expected linear time.}$ and $Z_{t</p>
<p>Proof. To find all Delaunay disks containing $x_{i}$, do a breadth-first search from $\mathcal{B}<em t="t">{i}^{V}$. For any triangle $t$ encountered, check if $C</em>$ and continue.}$ contains $x_{i}$. If it does not, then we do not look at the neighbors of $t$. Otherwise, add $t$ to $S_{i}$ and $x_{i}$ to $Z_{t</p>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Fig. 4.4. (a) $\mathcal{V}(V)$ is dual to $T(V)$. Each vertex $t$ of $\mathcal{V}(V)$ corresponds to the center of the circumcircle of a triangle $t$ of $T(V)$, and it has the same conflict set $Z_{t}$ of size $X_{t}$. (b) The geode triangulation $G_{I}(V)$ is obtained by connecting the vertices of each region of $\mathcal{V}(V)$ to the lexicographically smallest incident vertex with the smallest $X_{t}$. The conflict set of a triangle $s$ is the union of the conflict sets of its vertices and point $v$ defining the region.</p>
<p>Since $S_{i}$ is connected in the dual graph of $T(V),{ }^{5}$ we will visit all $C_{t}$ 's that contain $x_{i}$. The time taken to find $S_{i}$ is $O\left(\left|S_{i}\right|\right)$. The total time taken to find all $S_{i}$ 's (once all the $\mathcal{B}<em i="1">{i}^{V}$ 's are found) is $O\left(\sum</em>$ and zero otherwise. We have}^{n}\left|S_{i}\right|\right)$. Define the indicator function $\chi(t, i)$ that takes value 1 if $x_{i} \in C_{t</p>
<p>$$
\sum_{i=1}^{n}\left|S_{i}\right|=\sum_{i=1}^{n} \sum_{t \in T(V)} \chi(t, i)=\sum_{t \in T(V)} \sum_{i=1}^{n} \chi(t, i)=\sum_{t} X_{t}
$$</p>
<p>Therefore, by Lemma 4.1,</p>
<p>$$
\mathbf{E}\left[\sum_{i=1}^{n}\left|S_{i}\right|\right]=\mathbf{E}\left[\sum_{t} X_{t}\right]=\sum_{t} \mathbf{E}\left[X_{t}\right]=O(n)
$$</p>
<p>This implies that all $S_{i}$ 's and $Z_{t}$ 's can be found in expected linear time.
Our aim is to build the Delaunay triangulation $T(V \cup I)$ in linear time using the conflict sets $Z_{t}$. To that end, we will use divide-and-conquer to compute the Voronoi diagram $\mathcal{V}(V \cup I)$, using a scheme that has been used for nearest neighbor searching [24] and for randomized convex hull constructions [20,25]. It is well known that the Voronoi diagram of a point set is dual to the Delaunay triangulation, and that we can go from one to the other in linear time [12, Chapter 9]. Refer to Fig. 4.4(a). Consider the Voronoi diagram of $V, \mathcal{V}(V)$. By duality, the vertices of $\mathcal{V}(V)$ correspond to the triangles in $T(V)$, and we identify the two. In particular, each vertex $t$ of $\mathcal{V}(V)$ has a conflict set $Z_{t}$, the conflict set for the corresponding triangle in $T(V)$, and $\left|Z_{t}\right|=X_{t}$, by our definition of $X_{t}$ (see Fig. 4.4(a)). We triangulate the Voronoi diagram as follows: for each region $r$ of $\mathcal{V}(V)$, determine the lexicographically smallest Voronoi vertex $t_{r}$ in $r$ with minimum $X_{t}$. Add edges from all the Voronoi vertices in $r$ to $t_{r}$. Since each region of $\mathcal{V}(V)$ is convex, this yields a triangulation ${ }^{6}$ of $\mathcal{V}(V)$. We call it the geode triangulation of $\mathcal{V}(V)$ with respect to $I, G_{I}(V)[20,24]$. Refer to</p>
<p><sup id="fnref5:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p><img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Fig. 4.5. The nearest neighbor of a point $y \in s$ is either $v$ or needs to be in the conflict set of one of its vertices.</p>
<p>Fig. 4.4(b). Clearly, $G_{I}(V)$ can be computed in linear time. We extend the notion of conflict set to the triangles in $G_{I}(V)$ : Let $s$ be a triangle in $G_{I}(V)$ and let $t_{1}$, $t_{2}, t_{3}$ be its incident Voronoi vertices. Then the conflict set of $s, Z_{s}$, is defined as $Z_{s}:=Z_{t_{1}} \cup Z_{t_{2}} \cup Z_{t_{3}} \cup{v}$, where $v \in V$ is the point whose Voronoi region contains the triangle $s$. In the following, for any two points $x$ and $y,|x-y|$ denotes the Euclidean distance between them.</p>
<p>Claim 4.5. Let $s$ be a triangle of $G_{I}(V)$ and let $Z_{s}$ be its conflict set. Then the Voronoi diagram of $V \cup I$ restricted to $s, \mathcal{V}(V \cup I) \cap s$, is the same as the Voronoi diagram of $Z_{s}$ restricted to $s, \mathcal{V}\left(Z_{s}\right) \cap s$.</p>
<p>Proof. Consider a point $p$ in the triangle $s$, and let $y$ be the nearest neighbor of $p$ in $V \cup I$. If $y \in V$, then $y$ has to be $v$, since $s$ lies in the Voronoi region of $v$ with respect to $V$. Now suppose that $y \in I$. Let $B(v, y)$ be the perpendicular bisector of the line segment $(v, y)$ (ie, the line containing all points in the plane that have equal distance from $v$ and $y$ ). Refer to Figure 4.5. Let $B^{+}$be the halfplane defined by $B(v, y)$ that contains $y$. Since $B^{+}$intersects $s$, by convexity it also contains a vertex of $s$, say $t_{1}$. Because $t_{1}$ and $y$ are on the same side $\left(B^{+}\right),\left|y-t_{1}\right|&lt;\left|v-t_{1}\right|$. Note that $C_{t_{1}}$ has center $t_{1}$ and radius $\left|v-t_{1}\right|$, because $t_{1}$ is a vertex of the Voronoi region corresponding to $v$ (in $\mathcal{V}(V)$ ). Hence, $y \in Z_{t_{1}}$. It follows that $y \in Z_{s}$, so $\mathcal{V}(V \cup I) \cap s=\mathcal{V}\left(Z_{s}\right) \cap s$, as claimed.</p>
<p>Claim 4.5 implies that $\mathcal{V}(V \cup I)$ can be found as follows: for each triangle $s$ of $G_{I}(V)$, compute $\mathcal{V}\left(Z_{s}\right) \cap s$, the Voronoi diagram of $Z_{s}$ restricted to $s$. Then, traverse the edges of $G_{I}(V)$ and fuse the bisectors of the adjacent diagrams, yielding $\mathcal{V}(V \cup I)$.</p>
<p>Lemma 4.6. Given $\mathcal{V}(V)$, the Voronoi diagram $\mathcal{V}(V \cup I)$ can be computed in expected $O(n)$ time.</p>
<p>Proof. The time to find $\mathcal{V}\left(Z_{s}\right) \cap s$ for a triangle $s$ in $G_{I}(V)$ is $O\left(\left|Z_{s}\right| \log \left|Z_{s}\right|\right)=$ $O\left(\left|Z_{s}\right|^{2}\right)[12$, Chapter 7]. For a region $r$ of $\mathcal{V}(V)$, let $S(r)$ denote the set of triangles of $G_{I}(V)$ contained in $r$, and let $E(r)$ denote the set of edges in $\mathcal{V}(V)$ incident to $r$. Recall that $t_{r}$ denotes the common vertex of all triangles in $S(r)$. The total running</p>
<p><sup id="fnref6:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>time is $O\left(\mathbf{E}\left[\sum_{s \in G_{I}(V)}\left|Z_{s}\right|^{2}\right]\right)$, which is proportional to</p>
<p>$$
\begin{aligned}
&amp; \mathbf{E}\left[\sum_{r \in \mathcal{V}(V)} \sum_{s \in S(r)}\left|Z_{s}\right|^{2}\right] \leq \mathbf{E}\left[\sum_{r \in \mathcal{V}(V)} \sum_{\left(t_{1}, t_{2}\right) \in E(r)}\left(1+X_{t_{r}}+X_{t_{1}}+X_{t_{2}}\right)^{2}\right] \
&amp; \leq \mathbf{E}\left[\sum_{r \in \mathcal{V}(V)} \sum_{\left(t_{1}, t_{2}\right) \in E(r)}\left(1+2 X_{t_{1}}+X_{t_{2}}\right)^{2}\right]
\end{aligned}
$$</p>
<p>since $X_{t_{r}} \leq \min \left(X_{t_{1}}, X_{t_{2}}\right)$. For $e=\left(t_{1}, t_{2}\right)$, let $Y_{e}=1+2 X_{t_{1}}+X_{t_{2}}$. Note that $\mathbf{E}\left[Y_{e}\right]=O(1)$, by Lemma 4.1. We can write $Y_{e}=\sum_{i}\left(1 / n+2 \chi\left(t_{1}, i\right)+\chi\left(t_{2}, i\right)\right)$, where $\chi(t, i)$ was the indicator random variable for the event that $x_{i} \in C_{t}$. Hence, since $1 / n+2 \chi\left(t_{1}, i\right)+\chi\left(t_{2}, i\right)&lt;4$, Claim 3.3 implies that $\mathbf{E}\left[Y_{e}^{2}\right]=O(1)$. Thus,</p>
<p>$$
\mathbf{E}\left[\sum_{s \in G_{I}(V)}\left|Z_{s}\right|^{2}\right] \leq \sum_{r \in \mathcal{V}(V)} \sum_{\substack{e \in E(r) \ e=\left(t_{1}, t_{2}\right)}} \mathbf{E}\left[\left(Y_{e}\right)^{2}\right]=\sum_{r \in \mathcal{V}(V)} \sum_{\substack{e \in E(r) \ e=\left(t_{1}, t_{2}\right)}} O(1)
$$</p>
<p>The number of edges in $\mathcal{V}(V)$ is linear, and each edge $e$ is incident to exactly two Voronoi regions $r$. Therefore, $\mathbf{E}\left[\sum_{s \in G_{I}(V)}\left|Z_{s}\right|^{2}\right]=O(n)$. Furthermore, assembling the restricted diagrams takes time $O\left(\mathbf{E}\left[\sum_{s \in G_{I}(V)}\left|Z_{s}\right|\right]\right)$, and as $\left|Z_{s}\right| \leq\left|Z_{s}\right|^{2}$, this is also linear.
4.2. Running time analysis. In this section, we prove that the running time bound in Lemma 4.2 is indeed optimal. As discussed at the beginning of $\S 4$, Claim 2.2 implies that any comparison-based algorithm for computing the Delaunay triangulation of input $I \in_{R} \mathcal{D}$ needs at least $H(T(I))$ expected comparisons. Recall that by Lemma 4.2, the expected running time of our algorithm is $O\left(n+\sum_{i} H_{i}^{V}\right)$. The following is the main theorem of this section.</p>
<p>Theorem 4.7. For $H_{i}^{V}$, the entropy of the triangle $\mathcal{B}<em i="i">{i}^{V}$ of $T(V)$ containing $x</em>$, and $H(T(I))$, the entropy of the Delaunay triangulation of $I$, considered as a labeled graph,</p>
<p>$$
\sum_{i} H_{i}^{V}=O(n+H(T(I)))
$$</p>
<p>Proof. Let $\mathcal{B}^{V}:=\left(\mathcal{B}<em n="n">{1}^{V}, \ldots, \mathcal{B}</em>}^{V}\right)$ be the vector of all the triangles that contain the $x_{i}$ 's. By Claim 2.1, we have $H\left(\mathcal{B}^{V}\right)=\sum_{i} H_{i}^{V}$. Now we apply Lemma 2.3 with $\mathcal{U}=\left(\mathbb{R}^{2}\right)^{+}, X=T(I)$ and $Y$. In Lemma 4.8 we will show that the function $f$ : $(I, T(I)) \mapsto\left(\mathcal{B<em n="n">{1}^{V}, \ldots, \mathcal{B}</em>\right)=O(n+H(T(I))$, by Lemma 2.3. This proves the theorem.}^{V}\right)$ can be computed in linear time, so $H\left(\mathcal{B}_{i}^{V</p>
<p>We first define some notation - for a point set $P \subseteq V \cup I$ and $p \in P$, let $\Gamma_{P}(p)$ denote the neighbors of $p$ in $T(P)$. It remains to prove the following lemma. ${ }^{7}$</p>
<p>Lemma 4.8. Given $I$ and $T(I)$, for every $x_{i}$ in $I$ we can compute the triangle $\mathcal{B}<em i="i">{i}^{V}$ in $T(V)$ that contains $x</em>$ in total expected time $O(n)$.</p>
<p>Proof. First, we compute $T(V \cup I)$ from $T(V)$ and $T(I)$ in linear time $[19,36]$. Thus, we now know $T(V \cup I)$ and $T(V)$, and we want to find for every point $x_{i} \in I$</p>
<p><sup id="fnref7:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>the triangle $\mathcal{B}<em i="i">{i}^{V}$ of $T(V)$ that contains it. For the moment, let us be a little less ambitious and try to determine for each $x</em>} \in I$, a conflict triangle $\mathcal{C<em i="i">{i}^{V}$ in $T(V)$, ie, $\mathcal{C}</em>$, except for one problem: there might be inputs $x \in I$ that are not adjacent to any $v \in V$ in $T(V \cup I)$. Thus, we need to dynamically modify $T(V)$ to ensure that there is always a neighbor present. Details follow.}^{V}$ is a triangle $t$ with $x_{i} \in Z_{t}$. If $x \in I$ and $v \in V$ such that $\overline{x v}$ is an edge of $T(V \cup I)$, we can find a conflict triangle for $x$ in $T(V)$ in time $O(n)$ by inspecting all the incident triangles of $v$ in $T(V)$. Actually, we can find conflict triangles for all neighbors of $v$ in $T(V \cup I)$ that lie in $I$, by merging the two neighbor lists (see below). Noting that on average the size of these lists will be constant, we could almost determine all the $\mathcal{C}_{i}^{V</p>
<p>Claim 4.9. Let $p \in V \cup I$ and write $V_{p}:=V \cup{p}$. Suppose that $T(V \cup I)$ and $T\left(V_{p}\right)$ are known. Then, in total time $O\left(\left|\Gamma_{V \cup I}(p)\right|+\left|\Gamma_{V_{p}}(p)\right|\right)$, for every $x_{i} \in$ $\Gamma_{V \cup I}(p) \backslash V_{p}$, we can compute a conflict triangle $\mathcal{C}<em p="p">{i}^{V</em>\right)$.}}$ of $x_{i}$ in $T\left(V_{p</p>
<p>Proof. Let $x_{i} \in \Gamma_{V \cup I}(p) \backslash V_{p}$, and let $\mathcal{C}<em p="p">{i}^{V</em>}}$ be the triangle of $T\left(V_{p}\right)$ incident to $p$ that is intersected by line segment $\overline{p x_{i}}$. We claim that $\mathcal{C<em p="p">{i}^{V</em>}}$ is a conflict triangle for $x_{i}$. Indeed, since $\overline{p x_{i}}$ is an edge of $T(V \cup I)$, by the characterization of Delaunay edges (eg, [12, Theorem 9.6(ii)]), there exists an circle $C$ through $p$ and $x_{i}$ which does not contain any other points from $V \cup I$. In particular, $C$ does not contain any other points from $V_{p} \cup\left{x_{i}\right}$. Hence $\overline{p x_{i}}$ is also an edge of $T\left(V_{p} \cup\left{x_{i}\right}\right)$, again by the characterization of Delaunay edges applied in the other direction. Therefore, triangle $\mathcal{C<em p="p">{i}^{V</em>(p)$. This requires a number of steps that is linear of the size of the two lists, as claimed.}}$ is destroyed when $x_{i}$ is inserted into $T(V \cup J)$, and is a conflict triangle for $x_{i}$ in $T\left(V_{p}\right)$. It follows that the conflict triangles for $\Gamma_{V \cup I}(p) \backslash V_{p}$ can be computed by merging the cyclically ordered lists $\Gamma_{V \cup I}(p)$ and $\Gamma_{V_{p}</p>
<p>For certain pairs of points $p, x_{i}$, the previous claim provides a conflict triangle $\mathcal{C}<em p="p">{i}^{V</em>$ from this, which is what we wanted in the first place.}}$. The next claim allows us to get $\mathcal{C}_{i}^{V</p>
<p>Claim 4.10. Let $x_{i} \in I$ and let $p \in V \cup I$. Let $\mathcal{C}<em p="p">{i}^{V</em>}}$ be the conflict triangle for $x_{i}$ in $T\left(V_{p}\right)$ incident to $p$, as determined in Step 2c. Then we can find a conflict triangle $\mathcal{C<em i="i">{i}^{V}$ for $x</em>$ in $T(V)$ in constant time.</p>
<p>Proof. If $p \in V$, there is nothing to prove, so assume that $p \in I$. If $\mathcal{C}<em p="p">{i}^{V</em>}}$ has all vertices in $V$, then it is also a triangle in $T(V)$, and we are trivially done. So assume that one vertex of $\mathcal{C<em p="p">{i}^{V</em>}}$ is $p$. Let $e$ be the edge of $\mathcal{C<em p="p">{i}^{V</em>$ is in conflict with at least one of the two triangles in $T(V)$ that are incident to $e$. Given $e$, such a triangle can clearly be found in constant time. Refer to Fig. 4.6 for a depiction of the following arguments.}}$ not incident to $p$, and let $v, w$ be the endpoints of $e$. We will show that $x_{i</p>
<p>Since $v, w \in V$, by the characterization of Delaunay edges, it follows that $e$ is also an edge of $T(V)$. If $x_{i}$ does not lie in $\mathcal{C}<em p="p">{i}^{V</em>$ ). Note that $t$ cannot have $p$ as a vertex and is a triangle of $T(V)$.}}$, then $x_{i}$ must also be in conflict with the other triangle $t$ that is incident to $e$ (since $t$ is intersected by the Delaunay edge $\overline{p x_{i}</p>
<p>Suppose $x_{i}$ lies in $\mathcal{C}<em p="p">{i}^{V</em>}}$. Since $\mathcal{C<em p="p">{i}^{V</em>}}$ is a triangle in $T\left(V_{p}\right)$, the interior has no points other than $x_{i}$. Thus, the segments $\overline{v x_{i}}$ and $\overline{w x_{i}}$ are edges of $T\left(V_{p} \cup\left{x_{i}\right}\right)$. These must also be edges of $T\left(V \cup\left{x_{i}\right}\right)$. But this means that $x_{i}$ must conflict with the triangle in $T(V)$ incident to $e$ at the same side as $\mathcal{C<em p="p">{i}^{V</em>$.}</p>
<p>The conflict triangles for all points in $I$ can now be computed using breadth-first search (see Algorithm 1). The loop in Step 2 maintains the invariant that for each point $x_{i} \in Q \cap I$, a conflict triangle $\mathcal{C}_{i}^{V}$ in $T(V)$ is known. Step 2 b is performed as in</p>
<p>Algorithm 1 Determining the conflict triangles.</p>
<ol>
<li>Let $Q$ be a queue containing the elements in $V$.</li>
<li>While $Q \neq \emptyset$.
(a) Let $p$ be the next point in $Q$.
(b) If $p=x_{i} \in I$, then insert $p$ into $T(V)$ using the conflict triangle $\mathcal{C}<em i="i">{i}^{V}$ for $x</em>\right)=T(V)$.
(c) Using Claim 4.9, for each unvisited neighbor $x_{j} \in \Gamma_{V \cup I}(p) \cap I$, compute a conflict triangle $\mathcal{C}}$, to obtain $T\left(V_{p}\right)$. If $p \in V$, then $T\left(V_{p<em p="p">{j}^{V</em>\right)$.
(d) For each unvisited neighbor $x_{j} \in \Gamma_{V \cup I}(p) \cap I$, using $\mathcal{C}}}$ in $T\left(V_{p<em p="p">{j}^{V</em>}}$, compute a conflict triangle $\mathcal{C<em j="j">{j}^{V}$ of $x</em>$ into $Q$, and mark it as visited.
}$ in $T(V)$. Then insert $x_{j<img alt="img-6.jpeg" src="img-6.jpeg" /></li>
</ol>
<p>FIG. 4.6. (a) If $x_{i}$ is outside $\mathcal{C}<em p="p">{i}^{V</em>}}$, it conflicts with the triangle $t$ of $T(V)$ on the other side of e. (b) If $x_{i}$ lies inside $\mathcal{C<em p="p">{i}^{V</em>$ are both edges of $T(V)$.
the traditional randomized incremental construction of Delaunay triangulations [12, Chapter 9]: walk from $\mathcal{C}}}$, it conflicts with the triangle $t^{\prime}$ of $T(V)$ at the same side of $e$, since $\overline{v x_{i}}$ and $\overline{w x_{i}<em i="i">{i}^{V}$ through the dual graph if $T(V)$ to determine the conflict set $S</em>$, and remove all the old edges that are intersected by these new edges. The properties of the conflict set ensure that this yields a valid Delaunay triangulation. By Claim 4.10, Step 2d can be performed in constant time.}$ of $x_{i}$ (as in the proof of Claim 4.4), insert new edges from all points incident to the triangles in $S_{i}$ to $x_{i</p>
<p>The loop in Step 2 is executed at most once for each $p \in V \cup I$. It is also executed at least once for each point, since $T(V \cup I)$ is connected and in Step 2d we perform a BFS. The insertion in Step 2b takes $O\left(\left|\Gamma_{V_{p_{i}}}\left(x_{i}\right)\right|\right)$ time. Furthermore, by Claim 4.9, the conflict triangles of $p$ 's neighbors in $T(V \cup I)$ can be computed in $O\left(\left|\Gamma_{V_{p}}(p)\right|+\left|\Gamma_{V \cup I}(p)\right|\right)$ time. Finally, as we argued above, Step 2d can be carried out in total $O\left(\left|\Gamma_{V \cup I}(p)\right|\right)$ time. Now note that for $x_{i} \in I,\left|\Gamma_{V_{x_{i}}}\left(x_{i}\right)\right|$ is proportional to $\left|S_{i}\right|$, the number of triangles in $T(V)$ in conflict with $x_{i}$. Hence, the total expected running time is proportional to</p>
<p>$$
\begin{aligned}
&amp; \mathbf{E}\left[\sum_{p \in V \cup I}\left(\left|\Gamma_{V_{p}}(p)\right|+\left|\Gamma_{V \cup I}(p)\right|\right)\right] \
&amp; \quad=\mathbf{E}\left[\sum_{v \in V}\left|\Gamma_{V}(v)\right|+\sum_{i=1}^{n}\left|S_{i}\right|+\sum_{p \in V \cup I}\left|\Gamma_{V \cup I}(p)\right|\right]=O(n)
\end{aligned}
$$</p>
<p>Finally, using BFS as in the proof of Claim 4.4, given the conflict triangles $\mathcal{C}<em i="i">{i}^{V}$, the triangles $\mathcal{B}</em>$ 's can be found in $O(n)$ expected time, and the result follows.}^{V}$ that contain the $x_{i</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{7} \mathrm{~A}$ similar lemma is used in [22] in the context of hereditary algorithms for three-dimensional polytopes.&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref4:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref5:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref6:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref7:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
<li id="fn:1">
<p>${ }^{\text {ยฎ }}$ Preliminary versions appeared as N. Ailon, B. Chazelle, S. Comandur, and D. Liu, Self-improving Algorithms in Proc. 17th SODA, pp. 261-270, 2006; and K. L. Clarkson and C. Seshadhri, Selfimproving Algorithms for Delaunay Triangulations in Proc. 24th SoCG, pp. 148-155, 2008. This work was supported in part by NSF grants CCR-998817, 0306283, ARO Grant DAAH04-96-1-0181. ${ }^{\dagger}$ Computer Science Faculty, Technion, Haifa, Israel
${ }^{\ddagger}$ Department of Computer Science, Princeton University, Princeton, NJ, USA
ยงIBM Almaden Research Center, San Jose, CA, USA
${ }^{\text {H }}$ Institut fรผr Informatik, Freie Universitรคt Berlin, 14195 Berlin, Germany&#160;<a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 2 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>